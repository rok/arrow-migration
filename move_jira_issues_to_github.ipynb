{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86965e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "JIRA_CREDENTIALS = {\n",
    "    \"token_auth\": \"\",\n",
    "    \"server\": \"https://issues.apache.org/jira/\",\n",
    "    \"async_\": True\n",
    "}\n",
    "\n",
    "GITHUB_CREDENTIALS = {\n",
    "    \"Authorization\": \"\", \"User-Agent\": \"rok\",\n",
    "    \"Accept\": \"application/vnd.github.golden-comet-preview+json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557cfd68",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "1. Download issues, comments, watchers and external links (~20min)\n",
    "2. Create full GitHub issues (with Jira referring issue links) (~3hrs 20min)\n",
    "2. Collect Jira Issue url to GitHub issue url map (~30min)\n",
    "3. Post GitHub issue links to Jira issue comments (?)\n",
    "4. Lock Jira issues (manual)\n",
    "5. Update GitHub issues with corrected related issue / subtask links (?)\n",
    "\n",
    "# NOTES\n",
    "\n",
    "* Only active milestones can be added to. Activate relevant github milestones before import.\n",
    "\n",
    "# Questions\n",
    "\n",
    "* Which labels should still be added?\n",
    "* Should assignees be transferred?\n",
    "* Should watchers be pinged in a post import comment? Should watchers be assignees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1688cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, pickle, re, time\n",
    "from string import punctuation\n",
    "import jira2markdown\n",
    "from jira2markdown.markup.links import Mention\n",
    "from jira2markdown.markup.base import AbstractMarkup\n",
    "from jira import JIRA\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pyparsing import (\n",
    "    CaselessLiteral,\n",
    "    Char,\n",
    "    Combine,\n",
    "    FollowedBy,\n",
    "    Optional,\n",
    "    ParserElement,\n",
    "    ParseResults,\n",
    "    PrecededBy,\n",
    "    SkipTo,\n",
    "    StringEnd,\n",
    "    StringStart,\n",
    "    Suppress,\n",
    "    White,\n",
    "    Word,\n",
    "    alphanums,\n",
    ")\n",
    "import requests\n",
    "\n",
    "\n",
    "def is_completed(item):\n",
    "    return item.fields.status.name in [\"Closed\", \"Resolved\"]\n",
    "\n",
    "\n",
    "def extract_linked_issues(linked_issue):\n",
    "    if hasattr(linked_issue, \"outwardIssue\"):\n",
    "        return {\n",
    "            \"key\": linked_issue.outwardIssue.key,\n",
    "            \"relationship\": linked_issue.type.outward,\n",
    "            \"summary\": linked_issue.outwardIssue.fields.summary,\n",
    "            \"url\": linked_issue.outwardIssue.permalink(),\n",
    "            \"completed\": is_completed(linked_issue.outwardIssue)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"key\": linked_issue.inwardIssue.key,\n",
    "            \"relationship\": linked_issue.type.inward,\n",
    "            \"summary\": linked_issue.inwardIssue.fields.summary,\n",
    "            \"url\": linked_issue.inwardIssue.permalink(),\n",
    "            \"completed\": is_completed(linked_issue.inwardIssue)\n",
    "        }\n",
    "\n",
    "\n",
    "def get_user_string(jira_author, jira_url):\n",
    "    if jira_author.name in USER_MAPPING:\n",
    "        github_id = f\" / @{USER_MAPPING[jira_author.name]}\"\n",
    "    else:\n",
    "        github_id = \"\"\n",
    "    return f\"[{jira_author.displayName}]({jira_url})\" + github_id\n",
    "\n",
    "\n",
    "def get_comments(issue):\n",
    "    comments = []\n",
    "    for comment in issue.fields.comment.comments:\n",
    "        # Skip ASF GitHub Bot comments per https://github.com/apache/arrow/issues/14648\n",
    "        if comment.author.name == \"githubbot\":\n",
    "            continue\n",
    "\n",
    "        jira_url = f\"{issue.permalink()}?focusedCommentId={comment.id}\"\n",
    "        user_string = get_user_string(comment.author, jira_url)\n",
    "        \n",
    "        fixed_comments = TRANSLATED_MARKUP[issue.key][\"comments\"]\n",
    "        comments.append({\n",
    "            \"body\": f\"{user_string}:\\n{fixed_comments[comment.id]}\",\n",
    "            \"created_at\": comment.created[:-5] + \"Z\"\n",
    "        })\n",
    "    return comments\n",
    "\n",
    "\n",
    "def request_to_github(params, session):\n",
    "    while True:\n",
    "        r = session.request(**params)\n",
    "\n",
    "        if r.status_code in (200, 202, 204):\n",
    "            # all is good\n",
    "            return r\n",
    "        elif r.status_code == 403:\n",
    "            # throttling\n",
    "            print(\"Response was: \", r.json())\n",
    "            reset_time = int(r.headers[\"X-RateLimit-Reset\"])\n",
    "            wait_time = reset_time - round(time.time() + .5)\n",
    "            if wait_time > 0:\n",
    "                print(f\"Throttled on {params} call. Sleeping for {wait_time // 60} minutes.\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "        else:\n",
    "            # something is wrong\n",
    "            print(f\"Request {params} returned status code {r.status_code} and \", r.text)\n",
    "\n",
    "\n",
    "class MigratedMention(AbstractMarkup):\n",
    "    def action(self, tokens: ParseResults) -> str:\n",
    "        username = self.usernames.get(tokens.accountid)\n",
    "        return f\"`[~{tokens.accountid}]`\" if username is None else f\"@{username}\"\n",
    "\n",
    "    @property\n",
    "    def expr(self) -> ParserElement:\n",
    "        MENTION = Combine(\n",
    "            \"[\"\n",
    "            + Optional(\n",
    "                SkipTo(\"|\", failOn=\"]\") + Suppress(\"|\"),\n",
    "                default=\"\",\n",
    "                )\n",
    "            + \"~\"\n",
    "            + Optional(CaselessLiteral(\"accountid:\"))\n",
    "            + Word(alphanums + \":-\").setResultsName(\"accountid\")\n",
    "            + \"]\",\n",
    "            )\n",
    "        return (\n",
    "                (StringStart() | Optional(PrecededBy(White(), retreat=1), default=\" \"))\n",
    "                + MENTION.setParseAction(self.action)\n",
    "                + (StringEnd() | Optional(FollowedBy(White() | Char(punctuation, excludeChars=\"[\") | MENTION), default=\" \"))\n",
    "        )\n",
    "\n",
    "\n",
    "LEADING_SPACE_HASH_PATTERN = re.compile(r\"\\n\\s(#+\\s+\\S.*)\")\n",
    "ELEMENTS = jira2markdown.elements.MarkupElements()\n",
    "ELEMENTS.replace(Mention, MigratedMention)\n",
    "\n",
    "\n",
    "def translate_markup(issue):\n",
    "    if issue.fields.description:\n",
    "        description = issue.fields.description\n",
    "    else:\n",
    "        description = \"\"\n",
    "\n",
    "    description = re.sub(LEADING_SPACE_HASH_PATTERN, r\"\\n\\1\", description)\n",
    "    text = jira2markdown.convert(description, elements=ELEMENTS, usernames=USER_MAPPING)\n",
    "\n",
    "    for attachment in issue.fields.attachment:\n",
    "        text = text.replace(f\"![{attachment.filename}]({attachment.filename})\",\n",
    "                            f\"![{attachment.filename}]({attachment.content})\")\n",
    "\n",
    "    comments = {}\n",
    "    for comment in issue.fields.comment.comments:\n",
    "        # Skip ASF GitHub Bot comments per https://github.com/apache/arrow/issues/14648\n",
    "        if comment.author.name == \"githubbot\":\n",
    "            continue\n",
    "        comment_body = re.sub(LEADING_SPACE_HASH_PATTERN, r\"\\n\\1\", comment.body)\n",
    "        comment_text = jira2markdown.convert(comment_body, elements=ELEMENTS, usernames=USER_MAPPING)\n",
    "\n",
    "        for attachment in issue.fields.attachment:\n",
    "            comment_text = comment_text.replace(f\"![{attachment.filename}]({attachment.filename})\",\n",
    "                                                f\"![{attachment.filename}]({attachment.content})\")\n",
    "        comments[comment.id] = comment_text\n",
    "\n",
    "    return (issue.key, {\"description\": text, \"comments\": comments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c4202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_jira_issues_filename = 'raw_jira_issues.pickle'\n",
    "raw_jira_watchers_filename = 'raw_jira_watchers.pickle'\n",
    "raw_jira_remote_links_filename = \"raw_jira_remote_links.pickle\"\n",
    "raw_github_prs_filename = \"raw_github_prs.pickle\"\n",
    "translated_markup_filename = \"translated_markdown.pickle\"\n",
    "jira_to_github_user_mapping_file = 'jira-to-github-user-mapping.csv'\n",
    "\n",
    "RELEASE_ORDER = (\n",
    "    '0.1.0', '0.2.0', '0.3.0', 'JS-0.3.0', 'JS-0.3.1', '0.4.0', 'JS-0.4.0',\n",
    "    '0.4.1', 'JS-0.4.1', '0.5.0', '0.6.0', '0.7.0', '0.7.1', '0.8.0',\n",
    "    '0.9.0', '0.10.0', '0.11.0', '0.11.1', '0.12.0', '0.12.1', '0.13.0',\n",
    "    '0.14.0', '0.14.1', '0.15.0', '0.15.1', '0.16.0', '0.17.0', '0.17.1',\n",
    "    '1.0.0', '1.0.1', '2.0.0', '3.0.0', '3.0.1', '4.0.0', '4.0.1', '5.0.0',\n",
    "    '5.0.1', '6.0.0', '6.0.1', '6.0.2', '6.0.3', '7.0.0', '7.0.1', '7.0.2',\n",
    "    '8.0.0', '8.0.1', '9.0.0', '9.0.1', '10.0.0', '10.0.1', '10.0.2',\n",
    "    '11.0.0', '12.0.0'\n",
    ")\n",
    "\n",
    "ISSUETYPE_MAP = {\n",
    "    \"Bug\": \"Type: bug\",\n",
    "    \"Improvement\": \"Type: enhancement\",\n",
    "    \"Wish\": \"Type: enhancement\",\n",
    "    \"New Feature\": \"Type: enhancement\",\n",
    "    \"Task\": \"Type: task\",\n",
    "    \"Sub-task\": \"Type: task\",\n",
    "    \"Test\": \"Type: test\"\n",
    "}\n",
    "\n",
    "GITHUB_LABELS = (\n",
    "    \"Component: Archery\", \"Component: Benchmarking\", \"Component: C\",\n",
    "    \"Component: C#\", \"Component: C++\", \"Component: C++ - Gandiva\",\n",
    "    \"Component: C++ - Plasma\", \"Component: Continuous Integration\",\n",
    "    \"Component: Developer Tools\", \"Component: Documentation\",\n",
    "    \"Component: FlightRPC\", \"Component: Format\", \"Component: GLib\",\n",
    "    \"Component: Go\", \"Component: GPU\", \"Component: Integration\",\n",
    "    \"Component: Java\", \"Component: JavaScript\", \"Component: Julia\",\n",
    "    \"Component: MATLAB\", \"Component: Other\", \"Component: Packaging\",\n",
    "    \"Component: Parquet\", \"Component: Python\", \"Component: R\",\n",
    "    \"Component: Release\", \"Component: Ruby\", \"Component: Rust\",\n",
    "    \"Component: Rust - Ballista\", \"Component: Rust - DataFusion\",\n",
    "    \"Component: Website\", \"Component: Wiki\", \"dependencies\",\n",
    "    \"good-first-issue\", \"hacktoberfest-accepted\", \"java\", \"javascript\",\n",
    "    \"lang-go\", \"needs-rebase\", \"ready-for-review\", \"Type: bug\",\n",
    "    \"Type: enhancement\", \"Type: task\", \"Type: test\", \"Type: usage\",\n",
    "    \"WIP\"\n",
    ")\n",
    "\n",
    "milestone_url = \"https://api.github.com/repos/apache/arrow/milestones\"\n",
    "raw_milestone_map = requests.get(milestone_url, params={\"state\": \"all\"}, headers=GITHUB_CREDENTIALS)\n",
    "MILESTONE_MAP = {x[\"title\"]: x[\"number\"] for x in raw_milestone_map.json()}\n",
    "\n",
    "testing_milestone_url = \"https://api.github.com/repos/datatart/import_dry_run_4/milestones\"\n",
    "raw_testing_milestone_map = requests.get(testing_milestone_url, params={\"state\": \"all\"}, headers=GITHUB_CREDENTIALS)\n",
    "TESTING_MILESTONE_MAP = {x[\"title\"]: x[\"number\"] for x in raw_testing_milestone_map.json()}\n",
    "\n",
    "MILESTONE_MAP = TESTING_MILESTONE_MAP\n",
    "\n",
    "MIGRATION_NOTE = \"\\n\\n**Note**: *This issue was originally created as [{issue_key}]({jira_url}). \" \\\n",
    "    \"Please see the \" \\\n",
    "    \"[migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) \" \\\n",
    "    \"for further details.*\"\n",
    "\n",
    "JIRA_MIGRATION_NOTE = \"This issue has been migrated to [issue #{gh_id}|{gh_url}] on GitHub. \" \\\n",
    "    \"Please see the \" \\\n",
    "    \"[migration documentation|https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3] \" \\\n",
    "    \"for further details.\"\n",
    "\n",
    "USER_MAPPING = {}\n",
    "with open(jira_to_github_user_mapping_file, newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        USER_MAPPING[row[0]] = row[2]\n",
    "        USER_MAPPING[row[1]] = row[2]\n",
    "\n",
    "\n",
    "OWNER = \"datatart\"\n",
    "REPO = \"import_dry_run_4\"\n",
    "IMPORT_URL = f\"https://api.github.com/repos/{OWNER}/{REPO}/import/issues\"\n",
    "\n",
    "GITHUB_PROJECT_URL = \"https://github.com/apache/arrow/pull/\"\n",
    "\n",
    "PROJECT_NAME = \"ARROW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c6d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to check for GitHubs assignable users. We currently don't need it.\n",
    "#\n",
    "# def get_assignable_users(users):\n",
    "#     user_can_be_assignee = []\n",
    "#     with requests.Session() as s:\n",
    "#         for user in users:\n",
    "#             url = f\"https://api.github.com/repos/apache/arrow/assignees/{user}\"\n",
    "#             params = {\"method\": \"GET\", \"url\": url, \"headers\": GITHUB_CREDENTIALS}\n",
    "#             response = request_to_github(params, s)\n",
    "#             if response.status_code == 204:\n",
    "#                 user_can_be_assignee.append(user)\n",
    "#\n",
    "# USER_CAN_BE_ASSIGNEE = get_assignable_users(USER_MAPPING.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c59d3a",
   "metadata": {},
   "source": [
    "# Get Jira issue data and cache it to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "CONN = JIRA(**JIRA_CREDENTIALS)\n",
    "\n",
    "\n",
    "ISSUES = CONN.search_issues(f\"project = {PROJECT_NAME} order by key\", maxResults = False, fields = '*all')\n",
    "with open(raw_jira_issues_filename, 'wb') as handle:\n",
    "    pickle.dump(ISSUES, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "WATCHERS = {}\n",
    "for i, issue in enumerate(ISSUES):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Getting watchers for {issue.key} [{i}/{len(ISSUES)}].\")\n",
    "    WATCHERS[issue.id] = CONN.watchers(issue.id)\n",
    "with open(raw_jira_watchers_filename, 'wb') as handle:\n",
    "    pickle.dump(WATCHERS, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "REMOTE_LINKS = {}\n",
    "for i, issue in enumerate(ISSUES):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Getting remote links for {issue.key} [{i}/{len(ISSUES)}].\")\n",
    "    REMOTE_LINKS[issue.id] = CONN.remote_links(issue)\n",
    "with open(raw_jira_remote_links_filename, 'wb') as handle:\n",
    "    pickle.dump(REMOTE_LINKS, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "with open(raw_jira_issues_filename, 'rb') as handle:\n",
    "    ISSUES = pickle.load(handle)\n",
    "\n",
    "with open(raw_jira_watchers_filename, 'rb') as handle:\n",
    "    WATCHERS = pickle.load(handle)\n",
    "\n",
    "with open(raw_jira_remote_links_filename, 'rb') as handle:\n",
    "    REMOTE_LINKS = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1957b2b",
   "metadata": {},
   "source": [
    "# Jira -> GitHub markdown translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with Pool(processes=int(cpu_count() / 2)) as pool:\n",
    "    TRANSLATED_MARKUP = pool.map_async(translate_markup, ISSUES, chunksize=100).get()\n",
    "TRANSLATED_MARKUP = {k: v for k, v in TRANSLATED_MARKUP}\n",
    "\n",
    "with open(translated_markup_filename, 'wb') as handle:\n",
    "    pickle.dump(TRANSLATED_MARKUP, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(translated_markup_filename, 'rb') as handle:\n",
    "    TRANSLATED_MARKUP = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ad6c3",
   "metadata": {},
   "source": [
    "# Generate import payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_import_payload(issue):\n",
    "    issue_type = ISSUETYPE_MAP[issue.fields.issuetype.name]\n",
    "    labels = [f\"Component: {c.name}\" for c in issue.fields.components] + issue.fields.labels + [issue_type]\n",
    "    # Filter out nonexisting labels\n",
    "    labels = [label for label in labels if label in GITHUB_LABELS]\n",
    "    \n",
    "    # Get the earliest fix version and map it to a milestone\n",
    "    fix_versions = sorted((x.name for x in issue.fields.fixVersions), key=lambda x: RELEASE_ORDER.index(x))\n",
    "    fix_version = fix_versions[0] if fix_versions else None\n",
    "    milestone = MILESTONE_MAP.get(fix_version, None)\n",
    "    \n",
    "    jira_url = issue.permalink()\n",
    "\n",
    "    # Get watchers \n",
    "    watchers = [get_user_string(watcher, jira_url) for watcher in WATCHERS[issue.id].watchers]\n",
    "    watchers = \", \".join(watchers)\n",
    "   \n",
    "    remote_links = [remote_link.object for remote_link in REMOTE_LINKS[issue.id]]\n",
    "\n",
    "    body = TRANSLATED_MARKUP[issue.key][\"description\"] + \"\\n\"\n",
    "\n",
    "    if issue.fields.environment:\n",
    "        body += \"\\n**Environment**: \" + issue.fields.environment\n",
    "    if issue.fields.reporter:\n",
    "        body += \"\\n**Reporter**: \" + get_user_string(issue.fields.reporter, jira_url)\n",
    "    if issue.fields.assignee:\n",
    "        body += \"\\n**Assignee**: \" + get_user_string(issue.fields.assignee, jira_url)\n",
    "    if watchers:\n",
    "        body += f\"\\n**Watchers**: {watchers}\"\n",
    "    \n",
    "    if issue.fields.subtasks:\n",
    "        body += \"\\n#### Subtasks:\"\n",
    "        for subtask in issue.fields.subtasks:\n",
    "            body += f\"\\n- [{'X' if is_completed(subtask) else ' '}] \" \\\n",
    "                f\"[{subtask.fields.summary}]({subtask.permalink()})\"\n",
    "\n",
    "    linked_issues = [extract_linked_issues(linked_issue) for linked_issue in issue.fields.issuelinks]\n",
    "    \n",
    "    if linked_issues:\n",
    "        body += \"\\n#### Related issues:\"\n",
    "        for li in linked_issues:\n",
    "            body += \\\n",
    "                f\"\\n- [{li['summary']}]({li['url']}) ({li['relationship']})\"\n",
    "    \n",
    "\n",
    "    if issue.fields.attachment:\n",
    "        body += f\"\\n#### Original Issue Attachments:\"\n",
    "\n",
    "        for attachment in issue.fields.attachment:\n",
    "            body += f\"\\n- [{attachment.filename}]({attachment.content})\"\n",
    "\n",
    "    if issue.fields.customfield_12311020:\n",
    "        body += \"\\n#### Externally tracked issue: \" \\\n",
    "            f\"[{issue.fields.customfield_12311020}]({issue.fields.customfield_12311020})\"\n",
    "\n",
    "    if remote_links:\n",
    "        body += \"\\n#### PRs and other links:\"\n",
    "        for pr in remote_links:\n",
    "            body += f\"\\n- [{pr.title}]({pr.url})\"\n",
    "\n",
    "    body += MIGRATION_NOTE.format(issue_key=issue.key, jira_url=jira_url)\n",
    "    \n",
    "    data = {\n",
    "        \"issue\": {\n",
    "            \"title\": f\"{issue.fields.summary}\",\n",
    "            \"labels\": labels,\n",
    "            \"body\": body,\n",
    "            \"created_at\": issue.fields.created[:-5] + \"Z\",\n",
    "            \"updated_at\": issue.fields.updated[:-5] + \"Z\",\n",
    "            \"closed\": is_completed(issue),\n",
    "        },\n",
    "      \"comments\": get_comments(issue)\n",
    "    }\n",
    "\n",
    "    if issue.fields.resolutiondate:\n",
    "        data[\"issue\"][\"closed_at\"] = issue.fields.resolutiondate[:-5] + \"Z\"\n",
    "    if milestone:\n",
    "        data[\"issue\"][\"milestone\"] = milestone\n",
    "#     if issue.fields.assignee:\n",
    "#         data[\"issue\"][\"assignee\"] = USER_MAPPING.get(issue.fields.assignee.name, None)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_payloads = [(issue.key, generate_import_payload(issue)) for issue in ISSUES]\n",
    "import_responses = {}\n",
    "payloads = all_payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_payloads[0][1][\"issue\"][\"body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c1c88",
   "metadata": {},
   "source": [
    "# Import issues into GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acccd477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with requests.Session() as s:\n",
    "    for i, (key, payload) in enumerate(payloads):\n",
    "        if key in import_responses:\n",
    "            continue\n",
    "        if (i % 100 == 0):\n",
    "            print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] importing \", i, \"/\", len(payloads))\n",
    "\n",
    "        params = {\"method\": \"POST\", \"url\": IMPORT_URL, \"json\": payload, \"headers\": GITHUB_CREDENTIALS}\n",
    "        response = request_to_github(params, s)\n",
    "        import_responses[key] = {\"import_response\": response, \"status\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Check import statuses to get github issue links\n",
    "with requests.Session() as s:\n",
    "    for i, key in enumerate(import_responses.keys()):\n",
    "        if (i % 100 == 0):\n",
    "            print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] importing \", i, \"/\", len(payloads))\n",
    "\n",
    "        if import_responses[key][\"status\"] != \"imported\":\n",
    "            status_url = import_responses[key][\"import_response\"].json()[\"url\"]\n",
    "\n",
    "            params = {\"method\": \"GET\", \"url\": status_url, \"headers\": GITHUB_CREDENTIALS}\n",
    "            response = request_to_github(params, s)\n",
    "            import_responses[key][\"status\"] = response.json()[\"status\"]\n",
    "\n",
    "            if import_responses[key][\"status\"] == \"imported\":\n",
    "                import_responses[key][\"issue_url\"] = \\\n",
    "                    response.json()[\"issue_url\"].replace(\"https://api.github.com/repos/\", \"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c40aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, HTML\n",
    "\n",
    "# for url in [x['issue_url'] for x in import_responses.values() if 'issue_url' in x]:\n",
    "#     display(HTML(\"\"\"<a href=\"{}\">{}</a>\"\"\".format(url, url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ba3a8",
   "metadata": {},
   "source": [
    "# Update Jira issues to link to new GitHub Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this is untested\n",
    "\n",
    "def update_source_jira(issue, gh_url):\n",
    "    gh_id = gh_url.split(\"/\")[-1]\n",
    "    comment = JIRA_MIGRATION_NOTE.format(gh_id=gh_id, gh_url=gh_url)\n",
    "    CONN.add_comment(issue, comment)\n",
    "\n",
    "    if not issue.fields.customfield_12311020:\n",
    "        issue.update(fields={\"customfield_12311020\" : gh_url})\n",
    "\n",
    "# if all([x[\"status\"] == \"imported\" for x in import_responses.values()]):\n",
    "#     # All issues were imported we can post links to Jira\n",
    "    \n",
    "#     for issue in ISSUES:\n",
    "#         update_source_jira(issue, import_responses[issue.key][\"issue_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceedcd0",
   "metadata": {},
   "source": [
    "# Update cross issue linking to link GitHub instead of Jira issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645f628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fix_issue_bodies(issues, payloads, import_responses):\n",
    "    issue_bodies = {key: payload[\"issue\"][\"body\"] for key, payload in payloads}\n",
    "    github_urls = {k: v[\"issue_url\"] for k, v in import_responses.items() if \"issue_url\" in v}\n",
    "    \n",
    "    new_issue_bodies = {}\n",
    "    for issue in issues:\n",
    "        print(issue.key)\n",
    "        print(issue.fields.subtasks)\n",
    "        if issue.fields.issuelinks or issue.fields.subtasks:\n",
    "            body = issue_bodies[key]\n",
    "\n",
    "            if issue.fields.issuelinks:\n",
    "                for linked_issue in issue.fields.issuelinks:\n",
    "                    print(linked_issue)\n",
    "                    attr = \"inwardIssue\"\n",
    "                    if not hasattr(linked_issue, attr):\n",
    "                        attr = \"outwardIssue\"\n",
    "\n",
    "                    li = linked_issue.__getattribute__(attr)\n",
    "                    jira_url = li.permalink()\n",
    "                    github_url = github_urls[li.key]\n",
    "                    body.replace(jira_url, github_url)\n",
    "\n",
    "            if issue.fields.subtasks:\n",
    "                for subtask in issue.fields.subtasks:\n",
    "\n",
    "                    jira_url = subtask.permalink()\n",
    "                    github_url = github_urls[subtask.key]\n",
    "                    body.replace(jira_url, github_url)\n",
    "\n",
    "            new_issue_bodies[key] = body\n",
    "\n",
    "    return new_issue_bodies\n",
    "\n",
    "def update_gh_issue_links(issue_bodies, import_responses):\n",
    "    github_urls = {k: v[\"issue_url\"].replace(\"https://github.com/\", \"https://api.github.com/repos/\")\n",
    "         for k, v in import_responses.items() if \"issue_url\" in v}\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        for key, body in issue_bodies.items():\n",
    "            issue_id = import_responses[key][\"issue_url\"].split(\"/\")[-1]\n",
    "            url = github_urls[key]\n",
    "            \n",
    "            params = {\"method\": \"POST\", \"url\": url, \"json\": {\"body\": body}, \"headers\": GITHUB_CREDENTIALS}\n",
    "            request_to_github(params, s)\n",
    "\n",
    "\n",
    "tmp_issues = [i for i in ISSUES if import_responses[i.key][\"status\"] == \"imported\"]\n",
    "# new_issue_bodies = fix_issue_bodies(ISSUES, payloads, import_responses)\n",
    "new_issue_bodies = fix_issue_bodies(tmp_issues, payloads, import_responses)\n",
    "\n",
    "\n",
    "# TODO: this is untested\n",
    "# update_gh_issue_links(new_issue_bodies, import_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e40f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
