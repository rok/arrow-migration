{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "JIRA_CREDENTIALS = {\n",
    "    \"token_auth\": \"\",\n",
    "    \"server\": \"https://issues.apache.org/jira/\",\n",
    "    \"async_\": True\n",
    "}\n",
    "\n",
    "GITHUB_CREDENTIALS = {\n",
    "    \"X-Github-Next-Global-ID\": \"1\",\n",
    "    \"Authorization\": \"\",\n",
    "    \"User-Agent\": \"asfimport\",\n",
    "    \"Accept\": \"application/vnd.github.golden-comet-preview+json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef339bc",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "1. Download issues, comments, watchers and external links (~20min)\n",
    "2. Lock Jira issues (manual)\n",
    "3. Set all milestones to open (manual, not 100% sure it's needed)\n",
    "4. Create full GitHub issues (with Jira referring issue links) (~4hrs 20min)\n",
    "5. Restore pre-import milestone state (manual)\n",
    "6. Collect Jira Issue id to GitHub issue url map (~30min)\n",
    "7. Update GitHub issues with corrected issue / subtask links (20min?)\n",
    "8. Post GitHub issue links to Jira issue comments (30min?)\n",
    "9. Create self subscribe dataset (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e74b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, pickle, re, time\n",
    "from datetime import datetime\n",
    "from string import punctuation\n",
    "\n",
    "from dateutil.rrule import rrule, MONTHLY\n",
    "import jira2markdown\n",
    "from jira2markdown.markup.links import Mention\n",
    "from jira2markdown.markup.base import AbstractMarkup\n",
    "from jira import JIRA\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pyparsing import (\n",
    "    CaselessLiteral,\n",
    "    Char,\n",
    "    Combine,\n",
    "    FollowedBy,\n",
    "    Optional,\n",
    "    ParserElement,\n",
    "    ParseResults,\n",
    "    PrecededBy,\n",
    "    SkipTo,\n",
    "    StringEnd,\n",
    "    StringStart,\n",
    "    Suppress,\n",
    "    White,\n",
    "    Word,\n",
    "    alphanums,\n",
    ")\n",
    "import requests\n",
    "\n",
    "\n",
    "def is_completed(item):\n",
    "    return item.fields.status.name in [\"Closed\", \"Resolved\"]\n",
    "\n",
    "\n",
    "def extract_linked_issues(linked_issue):\n",
    "    if hasattr(linked_issue, \"outwardIssue\"):\n",
    "        return {\n",
    "            \"key\": linked_issue.outwardIssue.key,\n",
    "            \"relationship\": linked_issue.type.outward,\n",
    "            \"summary\": linked_issue.outwardIssue.fields.summary,\n",
    "            \"url\": linked_issue.outwardIssue.permalink(),\n",
    "            \"completed\": is_completed(linked_issue.outwardIssue)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"key\": linked_issue.inwardIssue.key,\n",
    "            \"relationship\": linked_issue.type.inward,\n",
    "            \"summary\": linked_issue.inwardIssue.fields.summary,\n",
    "            \"url\": linked_issue.inwardIssue.permalink(),\n",
    "            \"completed\": is_completed(linked_issue.inwardIssue)\n",
    "        }\n",
    "\n",
    "\n",
    "def get_user_string(jira_author, jira_url):\n",
    "    if jira_author.name in USER_MAPPING:\n",
    "        github_id = f\" / @{USER_MAPPING[jira_author.name]}\"\n",
    "    else:\n",
    "        github_id = \"\"\n",
    "    return f\"[{jira_author.displayName}]({jira_url})\" + github_id\n",
    "\n",
    "\n",
    "def get_comments(issue):\n",
    "    comments = []\n",
    "    for comment in issue.fields.comment.comments:\n",
    "        # Skip ASF GitHub Bot comments per https://github.com/apache/arrow/issues/14648\n",
    "        if comment.author.name == \"githubbot\":\n",
    "            continue\n",
    "\n",
    "        jira_url = f\"{issue.permalink()}?focusedCommentId={comment.id}\"\n",
    "        user_string = get_user_string(comment.author, jira_url)\n",
    "        \n",
    "        fixed_comments = TRANSLATED_MARKUP[issue.key][\"comments\"]\n",
    "        comments.append({\n",
    "            \"body\": f\"{user_string}:\\n{fixed_comments[comment.id]}\",\n",
    "            \"created_at\": comment.created[:-5] + \"Z\"\n",
    "        })\n",
    "    return comments\n",
    "\n",
    "\n",
    "def request_to_github(params, session):\n",
    "    while True:\n",
    "        r = session.request(**params)\n",
    "        request_data = \", \".join((params[\"method\"], params[\"url\"], params.get(\"body\", \"\")))\n",
    "\n",
    "        if r.status_code in (200, 202, 204):\n",
    "            # all is good\n",
    "            return r\n",
    "        elif r.status_code == 403:\n",
    "            # throttling\n",
    "            print(\"Response was: \", r.json())\n",
    "            reset_time = int(r.headers[\"X-RateLimit-Reset\"])\n",
    "            wait_time = reset_time - round(time.time() + .5)\n",
    "            if wait_time > 0:\n",
    "                print(f\"Throttled on {request_data}, call:  {r.text}\\nSleeping for {wait_time // 60} minutes.\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "        else:\n",
    "            # something is wrong\n",
    "            print(f\"Request {request_data} returned status code {r.status_code} and {r.text}\")\n",
    "            response.raise_for_status() \n",
    "\n",
    "\n",
    "def run_query(query): # A simple function to use requests.post to make the API call. Note the json= section.\n",
    "    request = requests.post('https://api.github.com/graphql', json={'query': query}, headers=GITHUB_CREDENTIALS)\n",
    "    if request.status_code == 200:\n",
    "        return request.json()\n",
    "    else:\n",
    "        raise Exception(\"Query failed to run by returning code of {}. {}\".format(request.status_code, query))\n",
    "\n",
    "\n",
    "def get_issues(owner, repo, interval, created_by=\"asfimport\"):\n",
    "    get_issue_texts = \"\"\"\n",
    "    query get_issue_texts {{\n",
    "      search(query: \"repo:{owner}/{repo} author:{created_by} is:issue created:{interval}\",\n",
    "                     type: ISSUE, first: 100{cursor}) {{\n",
    "        edges {{\n",
    "          node {{\n",
    "            ... on Issue {{\n",
    "              id\n",
    "              bodyText\n",
    "              url\n",
    "              databaseId\n",
    "              milestone {{\n",
    "                id\n",
    "                number\n",
    "                title\n",
    "              }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        pageInfo {{\n",
    "          endCursor\n",
    "          hasNextPage\n",
    "        }}\n",
    "        issueCount\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    cursor = \"\"\n",
    "    has_next_page = True\n",
    "    responses = []\n",
    "    page = 0\n",
    "\n",
    "    while has_next_page:\n",
    "        page += 1\n",
    "\n",
    "        q = get_issue_texts.format(owner=owner, repo=repo, cursor=cursor, interval=interval)\n",
    "        response = run_query(q)\n",
    "        responses.append(response)\n",
    "\n",
    "        if int(response['data'][\"search\"][\"issueCount\"]) > 1000:\n",
    "            print(f\"Query for {interval} is not granular enough and will not capture all isssues!\")\n",
    "\n",
    "        has_next_page = response[\"data\"][\"search\"][\"pageInfo\"][\"hasNextPage\"]\n",
    "        cursor = f', after: \"{response[\"data\"][\"search\"][\"pageInfo\"][\"endCursor\"]}\"'\n",
    "\n",
    "    return [e[\"node\"] for x in responses for e in x[\"data\"][\"search\"][\"edges\"]]\n",
    "\n",
    "            \n",
    "def get_assignable_users(users):\n",
    "    user_can_be_assignee = []\n",
    "    with requests.Session() as s:\n",
    "        for user in users:\n",
    "            url = f\"https://api.github.com/repos/apache/arrow/assignees/{user}\"\n",
    "            params = {\"method\": \"GET\", \"url\": url, \"headers\": GITHUB_CREDENTIALS}\n",
    "            response = session.request(**params)\n",
    "            if response.status_code == 204:\n",
    "                user_can_be_assignee.append(user)\n",
    "\n",
    "    return user_can_be_assignee\n",
    "\n",
    "\n",
    "class MigratedMention(AbstractMarkup):\n",
    "    def action(self, tokens: ParseResults) -> str:\n",
    "        username = self.usernames.get(tokens.accountid)\n",
    "        return f\"`[~{tokens.accountid}]`\" if username is None else f\"@{username}\"\n",
    "\n",
    "    @property\n",
    "    def expr(self) -> ParserElement:\n",
    "        MENTION = Combine(\n",
    "            \"[\"\n",
    "            + Optional(\n",
    "                SkipTo(\"|\", failOn=\"]\") + Suppress(\"|\"),\n",
    "                default=\"\",\n",
    "                )\n",
    "            + \"~\"\n",
    "            + Optional(CaselessLiteral(\"accountid:\"))\n",
    "            + Word(alphanums + \":-\").setResultsName(\"accountid\")\n",
    "            + \"]\",\n",
    "            )\n",
    "        return (\n",
    "                (StringStart() | Optional(PrecededBy(White(), retreat=1), default=\" \"))\n",
    "                + MENTION.setParseAction(self.action)\n",
    "                + (StringEnd() | Optional(FollowedBy(White() | Char(punctuation, excludeChars=\"[\") | MENTION), default=\" \"))\n",
    "        )\n",
    "\n",
    "\n",
    "LEADING_SPACE_HASH_PATTERN = re.compile(r\"\\n\\s(#+\\s+\\S.*)\")\n",
    "ELEMENTS = jira2markdown.elements.MarkupElements()\n",
    "ELEMENTS.replace(Mention, MigratedMention)\n",
    "\n",
    "\n",
    "def translate_markup(issue):\n",
    "    if issue.fields.description:\n",
    "        description = issue.fields.description\n",
    "    else:\n",
    "        description = \"\"\n",
    "\n",
    "    description = re.sub(LEADING_SPACE_HASH_PATTERN, r\"\\n\\1\", description)\n",
    "    text = jira2markdown.convert(description, elements=ELEMENTS, usernames=USER_MAPPING)\n",
    "\n",
    "    for attachment in issue.fields.attachment:\n",
    "        text = text.replace(f\"![{attachment.filename}]({attachment.filename})\",\n",
    "                            f\"![{attachment.filename}]({attachment.content})\")\n",
    "\n",
    "    comments = {}\n",
    "    for comment in issue.fields.comment.comments:\n",
    "        # Skip ASF GitHub Bot comments per https://github.com/apache/arrow/issues/14648\n",
    "        if comment.author.name == \"githubbot\":\n",
    "            continue\n",
    "        comment_body = re.sub(LEADING_SPACE_HASH_PATTERN, r\"\\n\\1\", comment.body)\n",
    "        comment_text = jira2markdown.convert(comment_body, elements=ELEMENTS, usernames=USER_MAPPING)\n",
    "\n",
    "        for attachment in issue.fields.attachment:\n",
    "            comment_text = comment_text.replace(f\"![{attachment.filename}]({attachment.filename})\",\n",
    "                                                f\"![{attachment.filename}]({attachment.content})\")\n",
    "        comments[comment.id] = comment_text\n",
    "\n",
    "    return (issue.key, {\"description\": text, \"comments\": comments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b27891",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_jira_issues_filename = 'raw_jira_issues.pickle'\n",
    "raw_jira_watchers_filename = 'raw_jira_watchers.pickle'\n",
    "raw_jira_remote_links_filename = \"raw_jira_remote_links.pickle\"\n",
    "translated_markup_filename = \"translated_markdown.pickle\"\n",
    "issue_subscriptions_file = \"issue_subscriptions.csv\"\n",
    "\n",
    "RELEASE_ORDER = (\n",
    "    '0.1.0', '0.2.0', '0.3.0', 'JS-0.3.0', 'JS-0.3.1', '0.4.0', 'JS-0.4.0',\n",
    "    '0.4.1', 'JS-0.4.1', '0.5.0', '0.6.0', '0.7.0', '0.7.1', '0.8.0',\n",
    "    '0.9.0', '0.10.0', '0.11.0', '0.11.1', '0.12.0', '0.12.1', '0.13.0',\n",
    "    '0.14.0', '0.14.1', '0.15.0', '0.15.1', '0.16.0', '0.17.0', '0.17.1',\n",
    "    '1.0.0', '1.0.1', '2.0.0', '3.0.0', '4.0.0', '3.0.1', '4.0.1', '5.0.0',\n",
    "    '6.0.0', '5.0.1', '6.0.1', '6.0.2', '6.0.3', '7.0.0', '7.0.1', '7.0.2',\n",
    "    '8.0.0', '8.0.1', '9.0.0', '9.0.1', '10.0.0', '10.0.1', '10.0.2',\n",
    "    '11.0.0', '12.0.0'\n",
    ")\n",
    "\n",
    "ISSUETYPE_MAP = {\n",
    "    \"Bug\": \"Type: bug\",\n",
    "    \"Improvement\": \"Type: enhancement\",\n",
    "    \"Wish\": \"Type: enhancement\",\n",
    "    \"New Feature\": \"Type: enhancement\",\n",
    "    \"Task\": \"Type: task\",\n",
    "    \"Sub-task\": \"Type: task\",\n",
    "    \"Test\": \"Type: test\"\n",
    "}\n",
    "\n",
    "GITHUB_LABELS = (\n",
    "    \"Component: Archery\", \"Component: Benchmarking\", \"Component: C\",\n",
    "    \"Component: C#\", \"Component: C++\", \"Component: C++ - Gandiva\",\n",
    "    \"Component: C++ - Plasma\", \"Component: Continuous Integration\",\n",
    "    \"Component: Developer Tools\", \"Component: Documentation\",\n",
    "    \"Component: FlightRPC\", \"Component: Format\", \"Component: GLib\",\n",
    "    \"Component: Go\", \"Component: GPU\", \"Component: Integration\",\n",
    "    \"Component: Java\", \"Component: JavaScript\", \"Component: Julia\",\n",
    "    \"Component: MATLAB\", \"Component: Other\", \"Component: Packaging\",\n",
    "    \"Component: Parquet\", \"Component: Python\", \"Component: R\",\n",
    "    \"Component: Release\", \"Component: Ruby\", \"Component: Rust\",\n",
    "    \"Component: Rust - Ballista\", \"Component: Rust - DataFusion\",\n",
    "    \"Component: Website\", \"Component: Wiki\", \"dependencies\",\n",
    "    \"good-first-issue\", \"hacktoberfest-accepted\", \"java\", \"javascript\",\n",
    "    \"lang-go\", \"needs-rebase\", \"ready-for-review\", \"Type: bug\",\n",
    "    \"Type: enhancement\", \"Type: task\", \"Type: test\", \"Type: usage\",\n",
    "    \"WIP\",\n",
    "    \"good-second-issue\", \"Priority: Critical\", \"Priority: Blocker\"\n",
    ")\n",
    "\n",
    "# OWNER = \"test_user\"\n",
    "# REPO = \"test_repo\"\n",
    "OWNER = \"apache\"\n",
    "REPO = \"arrow\"\n",
    "IMPORT_URL = f\"https://api.github.com/repos/{OWNER}/{REPO}/import/issues\"\n",
    "ISSUE_URL_TEMPLATE = f\"https://github.com/{OWNER}/{REPO}/issues/{{}}\"\n",
    "GITHUB_PROJECT_URL = \"https://github.com/apache/arrow/pull/\"\n",
    "JIRA_PROJECT_NAME = \"ARROW\"\n",
    "\n",
    "milestone_url = \"https://api.github.com/repos/apache/arrow/milestones\"\n",
    "raw_milestone_map = requests.get(milestone_url, params={\"state\": \"all\", \"per_page\": 100},\n",
    "                                 headers=GITHUB_CREDENTIALS)\n",
    "MILESTONE_MAP = {x[\"title\"]: x[\"number\"] for x in raw_milestone_map.json()}\n",
    "\n",
    "# testing_milestone_url = f\"https://api.github.com/repos/{OWNER}/{REPO}/milestones\"\n",
    "# raw_milestone_map = requests.get(milestone_url, params={\"state\": \"all\", \"per_page\": 100},\n",
    "#                                  headers=GITHUB_CREDENTIALS)\n",
    "# TESTING_MILESTONE_MAP = {x[\"title\"]: x[\"number\"] for x in raw_testing_milestone_map.json()}\n",
    "\n",
    "# MILESTONE_MAP = TESTING_MILESTONE_MAP\n",
    "\n",
    "MIGRATION_NOTE = \"\\n\\n<sub>**Note**: *This issue was originally created as [{issue_key}]({jira_url}). \" \\\n",
    "    \"Please see the \" \\\n",
    "    \"[migration documentation](https://github.com/apache/arrow/issues/14542) \" \\\n",
    "    \"for further details.*</sub>\"\n",
    "\n",
    "JIRA_MIGRATION_NOTE = \"This issue has been migrated to [issue #{gh_id}|{gh_url}] on GitHub. \" \\\n",
    "    \"Please see the \" \\\n",
    "    \"[migration documentation|https://github.com/apache/arrow/issues/14542] \" \\\n",
    "    \"for further details.\"\n",
    "\n",
    "USER_MAPPING = {}\n",
    "with open(jira_to_github_user_mapping_file, newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        USER_MAPPING[row[0]] = row[2]\n",
    "        USER_MAPPING[row[1]] = row[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64ce13",
   "metadata": {},
   "source": [
    "# Find assignable users on GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f495add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER_CAN_BE_ASSIGNEE = get_assignable_users(USER_MAPPING.values())\n",
    "\n",
    "USER_CAN_BE_ASSIGNEE = ('AlenkaF', 'BryanCutler', 'Dandandan', 'Jimexist', 'TheNeuralBit', 'alamb', 'amol-',\n",
    "    'andygrove', 'assignUser', 'bkietz', 'cpcloud', 'cyb70289', 'domoritz', 'eerhardt', 'emkornfield',\n",
    "    'fsaintjacques', 'houqp', 'ianmcook', 'icexelloss', 'jacques-n', 'jonkeane', 'jorgecarleitao',\n",
    "    'jorisvandenbossche', 'julienledem', 'kiszk', 'kou', 'kszucs', 'lidavidm', 'liukun4515', 'liyafan82',\n",
    "    'majetideepak', 'milesgranger', 'mrkn', 'nealrichardson', 'nevi-me', 'paddyhoran', 'paleolimbot',\n",
    "    'pcmoritz', 'pitrou', 'praveenbingo', 'pravindra', 'ptgoetz', 'quinnj', 'raulcd', 'robertnishihara',\n",
    "    'rok', 'romainfrancois', 'sbinet', 'shiro615', 'siddharthteotia', 'sunchao', 'thisisnic', 'tianchen92',\n",
    "    'trxcllnt', 'tustvold', 'wesm', 'westonpace', 'wjones127', 'xhochy',  'zeroshade')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a0ecb",
   "metadata": {},
   "source": [
    "# Lock Jira comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c59d3a",
   "metadata": {},
   "source": [
    "# Get Jira issue data and cache it to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "CONN = JIRA(**JIRA_CREDENTIALS)\n",
    "\n",
    "\n",
    "ISSUES = CONN.search_issues(f\"project = {JIRA_PROJECT_NAME} order by key\", maxResults = False, fields = '*all')\n",
    "with open(raw_jira_issues_filename, 'wb') as handle:\n",
    "    pickle.dump(ISSUES, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "WATCHERS = {}\n",
    "for i, issue in enumerate(ISSUES):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Getting watchers for {issue.key} [{i}/{len(ISSUES)}].\")\n",
    "    WATCHERS[issue.id] = CONN.watchers(issue.id)\n",
    "with open(raw_jira_watchers_filename, 'wb') as handle:\n",
    "    pickle.dump(WATCHERS, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "REMOTE_LINKS = {}\n",
    "for i, issue in enumerate(ISSUES):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Getting remote links for {issue.key} [{i}/{len(ISSUES)}].\")\n",
    "    REMOTE_LINKS[issue.id] = CONN.remote_links(issue)\n",
    "with open(raw_jira_remote_links_filename, 'wb') as handle:\n",
    "    pickle.dump(REMOTE_LINKS, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "with open(raw_jira_issues_filename, 'rb') as handle:\n",
    "    ISSUES = pickle.load(handle)\n",
    "\n",
    "with open(raw_jira_watchers_filename, 'rb') as handle:\n",
    "    WATCHERS = pickle.load(handle)\n",
    "\n",
    "with open(raw_jira_remote_links_filename, 'rb') as handle:\n",
    "    REMOTE_LINKS = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1957b2b",
   "metadata": {},
   "source": [
    "# Jira -> GitHub markdown translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5089c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with Pool(processes=int(cpu_count() / 2)) as pool:\n",
    "    TRANSLATED_MARKUP = pool.map_async(translate_markup, ISSUES, chunksize=100).get()\n",
    "TRANSLATED_MARKUP = {k: v for k, v in TRANSLATED_MARKUP}\n",
    "\n",
    "with open(translated_markup_filename, 'wb') as handle:\n",
    "    pickle.dump(TRANSLATED_MARKUP, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(translated_markup_filename, 'rb') as handle:\n",
    "    TRANSLATED_MARKUP = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34846730",
   "metadata": {},
   "source": [
    "# Generate GitHub import payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_import_payload(issue):\n",
    "    issue_type = ISSUETYPE_MAP[issue.fields.issuetype.name]\n",
    "    labels = [f\"Component: {c.name}\" for c in issue.fields.components] + issue.fields.labels + \\\n",
    "        [issue_type, f\"Priority: {issue.fields.priority.name}\"]\n",
    "    labels = [label for label in labels if label in GITHUB_LABELS]\n",
    "    \n",
    "    # Get the earliest fix version and map it to a milestone\n",
    "    fix_versions = sorted((x.name for x in issue.fields.fixVersions), key=lambda x: RELEASE_ORDER.index(x))\n",
    "    fix_version = fix_versions[0] if fix_versions else None\n",
    "    milestone = MILESTONE_MAP.get(fix_version, None)\n",
    "    \n",
    "    jira_url = issue.permalink()\n",
    "\n",
    "    # Get watchers \n",
    "    watchers = [get_user_string(watcher, jira_url) \\\n",
    "                for watcher in WATCHERS[issue.id].watchers if watcher.name != \"arrowjira\"]\n",
    "    watchers = \", \".join(watchers)\n",
    "   \n",
    "    remote_links = [remote_link.object for remote_link in REMOTE_LINKS[issue.id]]\n",
    "\n",
    "    body = TRANSLATED_MARKUP[issue.key][\"description\"] + \"\\n\"\n",
    "\n",
    "    if issue.fields.environment:\n",
    "        body += \"\\n**Environment**: \" + issue.fields.environment\n",
    "    if issue.fields.reporter:\n",
    "        body += \"\\n**Reporter**: \" + get_user_string(issue.fields.reporter, jira_url)\n",
    "    if issue.fields.assignee:\n",
    "        body += \"\\n**Assignee**: \" + get_user_string(issue.fields.assignee, jira_url)\n",
    "    if watchers:\n",
    "        body += f\"\\n**Watchers**: {watchers}\"\n",
    "    \n",
    "    if issue.fields.subtasks:\n",
    "        body += \"\\n#### Subtasks:\"\n",
    "        for subtask in issue.fields.subtasks:\n",
    "            body += f\"\\n- [{'X' if is_completed(subtask) else ' '}] \" \\\n",
    "                f\"[{subtask.fields.summary}]({subtask.permalink()})\"\n",
    "\n",
    "    linked_issues = [extract_linked_issues(linked_issue) for linked_issue in issue.fields.issuelinks]\n",
    "    \n",
    "    if linked_issues:\n",
    "        body += \"\\n#### Related issues:\"\n",
    "        for li in linked_issues:\n",
    "            body += \\\n",
    "                f\"\\n- [{li['summary']}]({li['url']}) ({li['relationship']})\"\n",
    "    \n",
    "\n",
    "    if issue.fields.attachment:\n",
    "        body += f\"\\n#### Original Issue Attachments:\"\n",
    "\n",
    "        for attachment in issue.fields.attachment:\n",
    "            body += f\"\\n- [{attachment.filename}]({attachment.content})\"\n",
    "\n",
    "    if issue.fields.customfield_12311020:\n",
    "        body += \"\\n#### Externally tracked issue: \" \\\n",
    "            f\"[{issue.fields.customfield_12311020}]({issue.fields.customfield_12311020})\"\n",
    "\n",
    "    if remote_links:\n",
    "        body += \"\\n#### PRs and other links:\"\n",
    "        for pr in remote_links:\n",
    "            body += f\"\\n- [{pr.title}]({pr.url})\"\n",
    "\n",
    "    body += MIGRATION_NOTE.format(issue_key=issue.key, jira_url=jira_url)\n",
    "    \n",
    "    data = {\n",
    "        \"issue\": {\n",
    "            \"title\": f\"{issue.fields.summary}\",\n",
    "            \"labels\": labels,\n",
    "            \"body\": body,\n",
    "            \"created_at\": issue.fields.created[:-5] + \"Z\",\n",
    "            \"updated_at\": issue.fields.updated[:-5] + \"Z\",\n",
    "            \"closed\": is_completed(issue),\n",
    "        },\n",
    "      \"comments\": get_comments(issue)\n",
    "    }\n",
    "\n",
    "    if issue.fields.resolutiondate:\n",
    "        data[\"issue\"][\"closed_at\"] = issue.fields.resolutiondate[:-5] + \"Z\"\n",
    "    if milestone:\n",
    "        data[\"issue\"][\"milestone\"] = milestone\n",
    "    if issue.fields.assignee and issue.fields.assignee.name in USER_MAPPING:\n",
    "        assignee = USER_MAPPING[issue.fields.assignee.name]\n",
    "        if assignee in USER_CAN_BE_ASSIGNEE:\n",
    "            data[\"issue\"][\"assignee\"] = assignee\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payloads = [(issue.key, generate_import_payload(issue)) for issue in ISSUES]\n",
    "import_responses = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(payloads[0][1][\"issue\"][\"body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e586c",
   "metadata": {},
   "source": [
    "# Import issues into GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with requests.Session() as s:\n",
    "    for i, (key, payload) in enumerate(payloads):\n",
    "        if key in import_responses:\n",
    "            continue\n",
    "        if (i % 100 == 0):\n",
    "            print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] importing \", i, \"/\", len(payloads))\n",
    "\n",
    "        params = {\"method\": \"POST\", \"url\": IMPORT_URL, \"json\": payload, \"headers\": GITHUB_CREDENTIALS}\n",
    "        response = request_to_github(params, s)\n",
    "        import_responses[key] = {\"import_response\": response, \"status\": \"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07edd832",
   "metadata": {},
   "source": [
    "# Get created issues to map them to Jira tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dates = rrule(MONTHLY, interval=1, dtstart=datetime.strptime(\"2016\", \"%Y\"),\n",
    "              until=datetime.strptime(\"2023-02\", \"%Y-%m\"))\n",
    "fmt = \"%Y-%m-%d\"\n",
    "intervals = [f\"{x.strftime(fmt)}..{y.strftime(fmt)}\" for x, y in zip(dates, dates[1:])]\n",
    "\n",
    "results = []\n",
    "for interval in intervals:\n",
    "    results += get_issues(owner=OWNER, repo=REPO, interval=interval)\n",
    "#     print(interval, len(results))\n",
    "\n",
    "p = re.compile(r\"(ARROW-\\d+).\")\n",
    "GITHUB_URLS = {p.findall(x[\"bodyText\"])[-1]: x[\"url\"] for x in results}\n",
    "GITHUB_IDS = {x[\"url\"]: x[\"id\"] for x in results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b391540",
   "metadata": {},
   "source": [
    "# Update cross issue links on GitHub to link to GitHub issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ff2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def fix_issue_bodies(issues, payloads):\n",
    "    issue_bodies = {key: payload[\"issue\"][\"body\"] for key, payload in payloads}    \n",
    "    new_issue_bodies = {}\n",
    "\n",
    "    for issue in issues:\n",
    "        if issue.fields.issuelinks or issue.fields.subtasks:\n",
    "            body = issue_bodies[issue.key]\n",
    "\n",
    "            if issue.fields.issuelinks:\n",
    "                for li in issue.fields.issuelinks:\n",
    "                    linked_issue = li.outwardIssue if hasattr(li, \"outwardIssue\") else li.inwardIssue\n",
    "                    jira_url = linked_issue.permalink()\n",
    "                    github_url = GITHUB_URLS.get(linked_issue.key, jira_url)\n",
    "                    body = body.replace(jira_url, github_url)\n",
    "\n",
    "\n",
    "            if issue.fields.subtasks:\n",
    "                for subtask in issue.fields.subtasks:\n",
    "                    jira_url = subtask.permalink()\n",
    "                    github_url = GITHUB_URLS.get(subtask.key, jira_url)\n",
    "                    body = body.replace(jira_url, github_url)\n",
    "\n",
    "            new_issue_bodies[issue.key] = body\n",
    "\n",
    "    return new_issue_bodies\n",
    "\n",
    "def update_gh_issue_links(issue_bodies):\n",
    "    responses = {}\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        for i, (key, body) in enumerate(issue_bodies.items()):\n",
    "            url = GITHUB_URLS[key].replace(\"https://github.com/\", \"https://api.github.com/repos/\")\n",
    "            params = {\"method\": \"POST\", \"url\": url, \"json\": {\"body\": body}, \"headers\": GITHUB_CREDENTIALS}\n",
    "            print(i, \"/\", len(issue_bodies), params[\"url\"])\n",
    "            responses[key] = request_to_github(params, s)\n",
    "\n",
    "    return responses\n",
    "\n",
    "new_issue_bodies = fix_issue_bodies(ISSUES, payloads)\n",
    "print(f\"Updating {len(new_issue_bodies)} issue bodies with corrected links.\")\n",
    "_ = update_gh_issue_links(new_issue_bodies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c594d",
   "metadata": {},
   "source": [
    "# Unlock Jira comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc32af",
   "metadata": {},
   "source": [
    "# Update Jira issues to link to new GitHub Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def update_source_jira(issue, gh_url):\n",
    "    gh_id = gh_url.split(\"/\")[-1]\n",
    "    comment = JIRA_MIGRATION_NOTE.format(gh_id=gh_id, gh_url=gh_url)\n",
    "    CONN.add_comment(issue, comment)\n",
    "\n",
    "    if not issue.fields.customfield_12311020:\n",
    "        issue.update(fields={\"customfield_12311020\" : gh_url})\n",
    "\n",
    "for issue in ISSUES:\n",
    "    # Please verify all issues were successfully imported before running this so links can be posted to Jira\n",
    "    print(issue.key)\n",
    "    update_source_jira(issue, GITHUB_URLS[issue.key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e69b8",
   "metadata": {},
   "source": [
    "# Lock Jira comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3587f",
   "metadata": {},
   "source": [
    "# Create a self subscription dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb81c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_subscriptions = [\n",
    "    *[(watcher.key, \"watcher\", issue.key) for issue in ISSUES for watcher in WATCHERS[issue.id].watchers],\n",
    "    *[(issue.fields.reporter.key, \"reporter\", issue.key) for issue in ISSUES if issue.fields.reporter],\n",
    "    *[(issue.fields.creator.key, \"creator\", issue.key) for issue in ISSUES if issue.fields.creator],\n",
    "    *[(issue.fields.assignee.key, \"assignee\", issue.key) for issue in ISSUES if issue.fields.assignee]\n",
    "]\n",
    "issue_subscriptions = [(USER_MAPPING[x], y, GITHUB_URLS[z], GITHUB_IDS[GITHUB_URLS[key]], z)\n",
    "                       for x, y, z in issue_subscriptions if x in USER_MAPPING]\n",
    "\n",
    "with open(issue_subscriptions_file, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for issue_subscription in issue_subscriptions:\n",
    "        writer.writerow(issue_subscription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
