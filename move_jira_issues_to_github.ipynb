{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc42f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "JIRA_CREDENTIALS = {\n",
    "    \"token_auth\": \"\",\n",
    "    \"server\": \"https://issues.apache.org/jira/\"\n",
    "}\n",
    "\n",
    "GITHUB_CREDENTIALS = {\n",
    "    \"Authorization\": \"\", \"User-Agent\": \"rok\",\n",
    "    \"Accept\": \"application/vnd.github.golden-comet-preview+json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23e8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, pickle, re, time\n",
    "from string import punctuation\n",
    "import jira2markdown\n",
    "from jira2markdown.markup.links import Mention\n",
    "from jira2markdown.markup.base import AbstractMarkup\n",
    "from jira import JIRA\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pyparsing import (\n",
    "    CaselessLiteral,\n",
    "    Char,\n",
    "    Combine,\n",
    "    FollowedBy,\n",
    "    Optional,\n",
    "    ParserElement,\n",
    "    ParseResults,\n",
    "    PrecededBy,\n",
    "    SkipTo,\n",
    "    StringEnd,\n",
    "    StringStart,\n",
    "    Suppress,\n",
    "    White,\n",
    "    Word,\n",
    "    alphanums,\n",
    ")\n",
    "import requests\n",
    "\n",
    "\n",
    "raw_jira_issues_filename = 'raw_jira_issues.pickle'\n",
    "raw_jira_watchers_filename = 'raw_jira_watchers.pickle'\n",
    "raw_jira_remote_links_filename = \"raw_jira_remote_links.pickle\"\n",
    "raw_github_prs_filename = \"raw_github_prs.pickle\"\n",
    "translated_markup_filename = \"translated_markdown.pickle\"\n",
    "jira_to_github_user_mapping_file = 'jira-to-github-user-mapping.csv'\n",
    "\n",
    "RELEASE_ORDER = (\n",
    "    '0.1.0', '0.2.0', '0.3.0', 'JS-0.3.0', 'JS-0.3.1', '0.4.0', 'JS-0.4.0',\n",
    "    '0.4.1', 'JS-0.4.1', '0.5.0', '0.6.0', '0.7.0', '0.7.1', '0.8.0',\n",
    "    '0.9.0', '0.10.0', '0.11.0', '0.11.1', '0.12.0', '0.12.1', '0.13.0',\n",
    "    '0.14.0', '0.14.1', '0.15.0', '0.15.1', '0.16.0', '0.17.0', '0.17.1',\n",
    "    '1.0.0', '1.0.1', '2.0.0', '3.0.0', '3.0.1', '4.0.0', '4.0.1', '5.0.0',\n",
    "    '5.0.1', '6.0.0', '6.0.1', '6.0.2', '6.0.3', '7.0.0', '7.0.1', '7.0.2',\n",
    "    '8.0.0', '8.0.1', '9.0.0', '9.0.1', '10.0.0', '10.0.1', '10.0.2',\n",
    "    '11.0.0', '12.0.0'\n",
    ")\n",
    "\n",
    "ISSUETYPE_MAP = {\n",
    "    \"Bug\": \"Type: bug\",\n",
    "    \"Improvement\": \"Type: enhancement\",\n",
    "    \"Wish\": \"Type: enhancement\",\n",
    "    \"New Feature\": \"Type: enhancement\",\n",
    "    \"Task\": \"Type: task\",\n",
    "    \"Sub-task\": \"Type: task\",\n",
    "    \"Test\": \"Type: test\"\n",
    "}\n",
    "\n",
    "GITHUB_LABELS = (\n",
    "    \"Component: Archery\", \"Component: Benchmarking\", \"Component: C\",\n",
    "    \"Component: C#\", \"Component: C++\", \"Component: C++ - Gandiva\",\n",
    "    \"Component: C++ - Plasma\", \"Component: Continuous Integration\",\n",
    "    \"Component: Developer Tools\", \"Component: Documentation\",\n",
    "    \"Component: FlightRPC\", \"Component: Format\", \"Component: GLib\",\n",
    "    \"Component: Go\", \"Component: GPU\", \"Component: Integration\",\n",
    "    \"Component: Java\", \"Component: JavaScript\", \"Component: Julia\",\n",
    "    \"Component: MATLAB\", \"Component: Other\", \"Component: Packaging\",\n",
    "    \"Component: Parquet\", \"Component: Python\", \"Component: R\",\n",
    "    \"Component: Release\", \"Component: Ruby\", \"Component: Rust\",\n",
    "    \"Component: Rust - Ballista\", \"Component: Rust - DataFusion\",\n",
    "    \"Component: Website\", \"Component: Wiki\", \"dependencies\",\n",
    "    \"good-first-issue\", \"hacktoberfest-accepted\", \"java\", \"javascript\",\n",
    "    \"lang-go\", \"needs-rebase\", \"ready-for-review\", \"Type: bug\",\n",
    "    \"Type: enhancement\", \"Type: task\", \"Type: test\", \"Type: usage\",\n",
    "    \"WIP\"\n",
    ")\n",
    "\n",
    "milestone_url = \"https://api.github.com/repos/apache/arrow/milestones\"\n",
    "raw_milestone_map = requests.get(milestone_url, params={\"state\": \"all\"}, headers=GITHUB_CREDENTIALS)\n",
    "MILESTONE_MAP = {x[\"title\"]: x[\"number\"] for x in raw_milestone_map.json()}\n",
    "\n",
    "testing_milestone_url = \"https://api.github.com/repos/datatart/import_dry_run_3/milestones\"\n",
    "raw_testing_milestone_map = requests.get(testing_milestone_url, params={\"state\": \"all\"}, headers=GITHUB_CREDENTIALS)\n",
    "TESTING_MILESTONE_MAP = {x[\"title\"]: x[\"number\"] for x in raw_testing_milestone_map.json()}\n",
    "\n",
    "MILESTONE_MAP = TESTING_MILESTONE_MAP\n",
    "\n",
    "MIGRATION_NOTE = \"\\n\\n**Note**: *This issue was originally created as [{issue_key}]({jira_url}). \" \\\n",
    "    \"Please see the \" \\\n",
    "    \"[migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) \" \\\n",
    "    \"for further details.*\"\n",
    "\n",
    "USER_MAPPING = {}\n",
    "with open(jira_to_github_user_mapping_file, newline=\"\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        USER_MAPPING[row[0]] = row[2]\n",
    "        USER_MAPPING[row[1]] = row[2]\n",
    "\n",
    "\n",
    "OWNER = \"datatart\"\n",
    "REPO = \"import_dry_run_2\"\n",
    "IMPORT_URL = f\"https://api.github.com/repos/{OWNER}/{REPO}/import/issues\"\n",
    "\n",
    "GITHUB_PROJECT_URL = \"https://github.com/apache/arrow/pull/\"\n",
    "\n",
    "PROJECT_NAME = \"ARROW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a069c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to check for assignable users. We currently don't need it.\n",
    "\n",
    "# def get_assignable_users(users):\n",
    "#     user_can_be_assignee = []\n",
    "\n",
    "#     with requests.Session() as s:\n",
    "#         for user in users:\n",
    "#             url = f\"https://api.github.com/repos/apache/arrow/assignees/{user}\"\n",
    "#             response = s.get(url, headers=GITHUB_CREDENTIALS)\n",
    "\n",
    "#             if response.status_code == 204:\n",
    "#                 user_can_be_assignee.append(user)\n",
    "\n",
    "#             elif response.status_code == 404:\n",
    "#                 continue\n",
    "\n",
    "#             elif response.status_code == 403:\n",
    "#                 reset_time = int(response.headers[\"X-RateLimit-Reset\"])\n",
    "#                 wait_time = reset_time - round(time.time() + .5)\n",
    "#                 if wait_time > 0:\n",
    "#                     print(f\"Throttled on getting {url}, sleeping for {wait_time} seconds.\")\n",
    "#                     print(\"Response was: \", response.json())\n",
    "#                     time.sleep(wait_time)\n",
    "\n",
    "#             else:\n",
    "#                 response.raise_for_status()\n",
    "\n",
    "# USER_CAN_BE_ASSIGNEE = get_assignable_users(USER_MAPPING.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c59d3a",
   "metadata": {},
   "source": [
    "# Get Jira issue data and cache it to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5137bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# conn = JIRA(**JIRA_CREDENTIALS)\n",
    "# issues = conn.search_issues(f\"project = {PROJECT_NAME} order by key\", maxResults = False, fields = '*all')\n",
    "\n",
    "# watchers = {}\n",
    "# for i, issue in enumerate(issues):\n",
    "#     if i % 1000 == 0:\n",
    "#         print(f\"Getting watchers for {issue.key} [{i}/{len(issues)}].\")\n",
    "#     watchers[issue.id] = conn.watchers(issue.id)\n",
    "\n",
    "# remote_links = {}\n",
    "# for i, issue in enumerate(issues):\n",
    "#     if i % 1000 == 0:\n",
    "#         print(f\"Getting remote links for {issue.key} [{i}/{len(issues)}].\")\n",
    "#     remote_links[issue.id] = conn.remote_links(issue)\n",
    "\n",
    "\n",
    "# with open(raw_jira_issues_filename, 'wb') as handle:\n",
    "#     pickle.dump(issues, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open(raw_jira_watchers_filename, 'wb') as handle:\n",
    "#     pickle.dump(watchers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open(raw_jira_remote_links_filename, 'wb') as handle:\n",
    "#     pickle.dump(remote_links, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(raw_jira_issues_filename, 'rb') as handle:\n",
    "    issues = pickle.load(handle)\n",
    "\n",
    "with open(raw_jira_watchers_filename, 'rb') as handle:\n",
    "    WATCHERS = pickle.load(handle)\n",
    "\n",
    "with open(raw_jira_remote_links_filename, 'rb') as handle:\n",
    "    REMOTE_LINKS = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1957b2b",
   "metadata": {},
   "source": [
    "# Markdown correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3428f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MigratedMention(AbstractMarkup):\n",
    "    def action(self, tokens: ParseResults) -> str:\n",
    "        username = self.usernames.get(tokens.accountid)\n",
    "        return f\"`[~{tokens.accountid}]`\" if username is None else f\"@{username}\"\n",
    "\n",
    "    @property\n",
    "    def expr(self) -> ParserElement:\n",
    "        MENTION = Combine(\n",
    "            \"[\"\n",
    "            + Optional(\n",
    "                SkipTo(\"|\", failOn=\"]\") + Suppress(\"|\"),\n",
    "                default=\"\",\n",
    "                )\n",
    "            + \"~\"\n",
    "            + Optional(CaselessLiteral(\"accountid:\"))\n",
    "            + Word(alphanums + \":-\").setResultsName(\"accountid\")\n",
    "            + \"]\",\n",
    "            )\n",
    "        return (\n",
    "                (StringStart() | Optional(PrecededBy(White(), retreat=1), default=\" \"))\n",
    "                + MENTION.setParseAction(self.action)\n",
    "                + (StringEnd() | Optional(FollowedBy(White() | Char(punctuation, excludeChars=\"[\") | MENTION), default=\" \"))\n",
    "        )\n",
    "\n",
    "LEADING_SPACE_HASH_PATTERN = re.compile(r\"\\n\\s(#+\\s+\\S.*)\")\n",
    "ELEMENTS = jira2markdown.elements.MarkupElements()\n",
    "ELEMENTS.replace(Mention, MigratedMention)\n",
    "\n",
    "def handle_leading_space_before_hash(txt):\n",
    "    return txt\n",
    "\n",
    "def translate_markup(issue):\n",
    "    if issue.fields.description:\n",
    "        description = issue.fields.description\n",
    "    else:\n",
    "        description = \"\"\n",
    "\n",
    "    description = re.sub(LEADING_SPACE_HASH_PATTERN, r\"\\n\\1\", description)\n",
    "    text = jira2markdown.convert(description, elements=ELEMENTS, usernames=USER_MAPPING)\n",
    "\n",
    "    for attachment in issue.fields.attachment:\n",
    "        text = text.replace(f\"![{attachment.filename}]({attachment.filename})\",\n",
    "                            f\"![{attachment.filename}]({attachment.content})\")\n",
    "\n",
    "    comments = {}\n",
    "    for comment in issue.fields.comment.comments:\n",
    "        # Skip ASF GitHub Bot comments per https://github.com/apache/arrow/issues/14648\n",
    "        if comment.author.name == \"githubbot\":\n",
    "            continue\n",
    "        comment_body = re.sub(LEADING_SPACE_HASH_PATTERN, r\"\\n\\1\", comment.body)\n",
    "        comment_text = jira2markdown.convert(comment_body, elements=ELEMENTS, usernames=USER_MAPPING)\n",
    "\n",
    "        for attachment in issue.fields.attachment:\n",
    "            comment_text = comment_text.replace(f\"![{attachment.filename}]({attachment.filename})\",\n",
    "                                                f\"![{attachment.filename}]({attachment.content})\")\n",
    "        comments[comment.id] = comment_text\n",
    "\n",
    "    return (issue.key, {\"description\": text, \"comments\": comments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40bb65c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 ms, sys: 12 ms, total: 39.9 ms\n",
      "Wall time: 39.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# with Pool(processes=int(cpu_count() / 2)) as pool:\n",
    "#     TRANSLATED_MARKUP = pool.map_async(translate_markup, issues, chunksize=100).get()\n",
    "# TRANSLATED_MARKUP = {k: v for k, v in TRANSLATED_MARKUP}\n",
    "\n",
    "# with open(translated_markup_filename, 'wb') as handle:\n",
    "#     pickle.dump(TRANSLATED_MARKUP, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(translated_markup_filename, 'rb') as handle:\n",
    "    TRANSLATED_MARKUP = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87095336",
   "metadata": {},
   "source": [
    "# Generate import payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260f9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_getting_key(obj, attr, subattr):\n",
    "    if (hasattr(obj, attr)):\n",
    "        attribute = obj.__getattribute__(attr)\n",
    "        if (hasattr(attribute, subattr)):\n",
    "            return attribute.__getattribute__(subattr)\n",
    "\n",
    "\n",
    "def is_completed(item):\n",
    "    return item.fields.status.name in [\"Closed\", \"Resolved\"]\n",
    "\n",
    "\n",
    "def extract_linked_issues(linked_issue):\n",
    "    if hasattr(linked_issue, \"outwardIssue\"):\n",
    "        return {\n",
    "            \"key\": linked_issue.outwardIssue.key,\n",
    "            \"relationship\": linked_issue.type.outward,\n",
    "            \"summary\": linked_issue.outwardIssue.fields.summary,\n",
    "            \"url\": linked_issue.outwardIssue.permalink(),\n",
    "            \"completed\": is_completed(linked_issue.outwardIssue)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"key\": linked_issue.inwardIssue.key,\n",
    "            \"relationship\": linked_issue.type.inward,\n",
    "            \"summary\": linked_issue.inwardIssue.fields.summary,\n",
    "            \"url\": linked_issue.inwardIssue.permalink(),\n",
    "            \"completed\": is_completed(linked_issue.inwardIssue)\n",
    "        }\n",
    "\n",
    "\n",
    "def get_user_string(jira_author, jira_url):\n",
    "    if jira_author.name in USER_MAPPING:\n",
    "        github_id = f\" / @{USER_MAPPING[jira_author.name]}\"\n",
    "    else:\n",
    "        github_id = \"\"\n",
    "    return f\"[{jira_author.displayName}]({jira_url})\" + github_id\n",
    "\n",
    "\n",
    "def get_comments(issue):\n",
    "    comments = []\n",
    "    for comment in issue.fields.comment.comments:\n",
    "        # Skip ASF GitHub Bot comments per https://github.com/apache/arrow/issues/14648\n",
    "        if comment.author.name == \"githubbot\":\n",
    "            continue\n",
    "\n",
    "        jira_url = f\"{issue.permalink()}?focusedCommentId={comment.id}\"\n",
    "        user_string = get_user_string(comment.author, jira_url)\n",
    "        \n",
    "        fixed_comments = TRANSLATED_MARKUP[issue.key][\"comments\"]\n",
    "        comments.append({\n",
    "            \"body\": f\"{user_string}:\\n{fixed_comments[comment.id]}\",\n",
    "            \"created_at\": comment.created[:-5] + \"Z\"\n",
    "        })\n",
    "    return comments\n",
    "\n",
    "\n",
    "def generate_import_payload(issue):\n",
    "    issue_type = ISSUETYPE_MAP[try_getting_key(issue.fields, \"issuetype\", \"name\")]\n",
    "    labels = [f\"Component: {c.name}\" for c in issue.fields.components] + issue.fields.labels + [issue_type]\n",
    "    # Filter out nonexisting labels\n",
    "    labels = [label for label in labels if label in GITHUB_LABELS]\n",
    "    \n",
    "    # Get the earliest fix version and map it to a milestone\n",
    "    fix_versions = sorted((x.name for x in issue.fields.fixVersions), key=lambda x: RELEASE_ORDER.index(x))\n",
    "    fix_version = fix_versions[0] if fix_versions else None\n",
    "    milestone = MILESTONE_MAP.get(fix_version, None)\n",
    "    \n",
    "    jira_url = issue.permalink()\n",
    "\n",
    "    # Get watchers \n",
    "    watchers = [get_user_string(watcher, jira_url) for watcher in WATCHERS[issue.id].watchers]\n",
    "    watchers = \", \".join(watchers)\n",
    "   \n",
    "    remote_links = [remote_link.object for remote_link in REMOTE_LINKS[issue.id]]\n",
    "\n",
    "    body = TRANSLATED_MARKUP[issue.key][\"description\"] + \"\\n\"\n",
    "\n",
    "    if issue.fields.reporter:\n",
    "        body += \"\\n**Reporter**: \" + get_user_string(issue.fields.reporter, jira_url)\n",
    "    if issue.fields.assignee:\n",
    "        body += \"\\n**Assignee**: \" + get_user_string(issue.fields.assignee, jira_url)\n",
    "    if watchers:\n",
    "        body += f\"\\n**Watchers**: {watchers}\"\n",
    "    \n",
    "    if issue.fields.subtasks:\n",
    "        body += \"\\n#### Subtasks:\"\n",
    "        for subtask in issue.fields.subtasks:\n",
    "            body += f\"\\n- [{'X' if is_completed(subtask) else ' '}] \" \\\n",
    "                f\"[{subtask.fields.summary}]({subtask.permalink()})\"\n",
    "\n",
    "    linked_issues = [extract_linked_issues(linked_issue) for linked_issue in issue.fields.issuelinks]\n",
    "    \n",
    "    if linked_issues:\n",
    "        body += \"\\n#### Related issues:\"\n",
    "        for li in linked_issues:\n",
    "            body += \\\n",
    "                f\"\\n- #[{li['summary']}]({li['url']}) ({li['relationship']})\"\n",
    "    \n",
    "\n",
    "    if issue.fields.attachment:\n",
    "        body += f\"\\n#### Original Issue Attachments:\"\n",
    "\n",
    "        for attachment in issue.fields.attachment:\n",
    "            body += f\"\\n- [{attachment.filename}]({attachment.content})\"\n",
    "\n",
    "    if issue.fields.customfield_12311020:\n",
    "        body += \"\\n#### Externally tracked issue: \" \\\n",
    "            f\"[{issue.fields.customfield_12311020}]({issue.fields.customfield_12311020})\"\n",
    "\n",
    "    if remote_links:\n",
    "        body += \"\\n#### PRs and other links:\"\n",
    "        for pr in remote_links:\n",
    "            body += f\"\\n- [{pr.title}]({pr.url})\"\n",
    "\n",
    "    body += MIGRATION_NOTE.format(issue_key=issue.key, jira_url=jira_url)\n",
    "    \n",
    "    data = {\n",
    "        \"issue\": {\n",
    "            \"title\": f\"{issue.fields.summary}\",\n",
    "            \"labels\": labels,\n",
    "            \"body\": body,\n",
    "            \"created_at\": issue.fields.created[:-5] + \"Z\",\n",
    "            \"updated_at\": issue.fields.updated[:-5] + \"Z\",\n",
    "            \"closed\": is_completed(issue),\n",
    "        },\n",
    "      \"comments\": get_comments(issue)\n",
    "    }\n",
    "\n",
    "    if issue.fields.resolutiondate:\n",
    "        data[\"issue\"][\"closed_at\"] = issue.fields.resolutiondate[:-5] + \"Z\"\n",
    "    if milestone:\n",
    "        data[\"issue\"][\"milestone\"] = milestone\n",
    "#     if issue.fields.assignee:\n",
    "#         data[\"issue\"][\"assignee\"] = USER_MAPPING.get(issue.fields.assignee.name, None)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "067d369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_payloads = [(issue.key, generate_import_payload(issue)) for issue in issues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ac4640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Drill vector module\n",
      "\n",
      "**Reporter**: [Jacques Nadeau](https://issues.apache.org/jira/browse/ARROW-1) / @jacques-n\n",
      "**Assignee**: [Steven Phillips](https://issues.apache.org/jira/browse/ARROW-1) / @StevenMPhillips\n",
      "**Watchers**: [Jacques Nadeau](https://issues.apache.org/jira/browse/ARROW-1) / @jacques-n\n",
      "\n",
      "**Note**: *This issue was originally created as [ARROW-1](https://issues.apache.org/jira/browse/ARROW-1). Please see the [migration documentation](https://gist.github.com/toddfarmer/12aa88361532d21902818a6044fda4c3) for further details.*\n"
     ]
    }
   ],
   "source": [
    "print(all_payloads[0][1][\"issue\"][\"body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cfec4",
   "metadata": {},
   "source": [
    "# Import issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def import_issue(payload, session):\n",
    "    while True:\n",
    "        response = session.post(IMPORT_URL, json=payload, headers=GITHUB_CREDENTIALS)\n",
    "\n",
    "        if response.status_code == 202:\n",
    "            return response\n",
    "        elif response.status_code == 403:\n",
    "            reset_time = int(response.headers[\"X-RateLimit-Reset\"])\n",
    "            wait_time = reset_time - round(time.time() + .5)\n",
    "            if wait_time > 0:\n",
    "                print(f\"Throttled on importing {key}, sleeping for {wait_time} seconds.\")\n",
    "                print(\"Response was: \", response.json())\n",
    "                time.sleep(wait_time)\n",
    "        else:\n",
    "            response.raise_for_status()\n",
    "\n",
    "def get_import_status(url, session):\n",
    "    while True:\n",
    "        response = session.get(url, headers=GITHUB_CREDENTIALS)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        elif response.status_code == 403:\n",
    "            reset_time = int(response.headers[\"X-RateLimit-Reset\"])\n",
    "            wait_time = reset_time - round(time.time() + .5)\n",
    "            if wait_time > 0:\n",
    "                print(f\"Throttled on getting {url}, sleeping for {wait_time} seconds.\")\n",
    "                print(\"Response was: \", response.json())\n",
    "                time.sleep(wait_time)\n",
    "        else:\n",
    "            response.raise_for_status()\n",
    "\n",
    "payloads = all_payloads\n",
    "import_responses = {}\n",
    "\n",
    "with requests.Session() as s:\n",
    "    for i, (key, payload) in enumerate(payloads):\n",
    "        if (i % 100 == 0):\n",
    "            print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] importing \", i, \"/\", len(payloads))\n",
    "        import_responses[key] = {\"import_response\": import_issue(payload, s), \"status\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ca6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Check for import statuses \n",
    "with requests.Session() as s:\n",
    "    for key in import_responses.keys():\n",
    "        status_url = import_responses[key][\"import_response\"].json()[\"url\"]\n",
    "\n",
    "        if import_responses[key][\"status\"] != \"imported\":\n",
    "            response = get_import_status(status_url, s)\n",
    "            import_responses[key][\"status\"] = response.json()[\"status\"]\n",
    "\n",
    "            if import_responses[key][\"status\"] == \"imported\":\n",
    "                import_responses[key][\"issue_url\"] = \\\n",
    "                    response.json()[\"issue_url\"].replace(\"https://api.github.com/repos/\", \"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d12b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "for url in [x['issue_url'] for x in import_responses.values() if 'issue_url' in x]:\n",
    "    display(HTML(\"\"\"<a href=\"{}\">{}</a>\"\"\".format(url, url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa5071",
   "metadata": {},
   "source": [
    "# todo\n",
    "* subscribe people?\n",
    "* Issue type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21712b22",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "1. Create issue with comments included\n",
    "2. Collect key to github url map\n",
    "3. Post jira comments with github links\n",
    "4. Lock Jira\n",
    "5. Update github issue with corrected related issue / subtask links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
