{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13226289",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289",
    "key": "ARROW-5123",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12345977",
                "id": "12345977",
                "description": "",
                "name": "2.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2020-10-19"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": null,
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333773",
                "id": "12333773",
                "name": "Rust"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=xrl",
            "name": "xrl",
            "key": "xrl",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Xavier Lange",
            "active": true,
            "timeZone": "America/Puerto_Rico"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=xrl",
            "name": "xrl",
            "key": "xrl",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Xavier Lange",
            "active": true,
            "timeZone": "America/Puerto_Rico"
        },
        "aggregateprogress": {
            "progress": 52200,
            "total": 52200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 52200,
            "total": 52200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-5123/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 101,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/225898",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "xrl commented on pull request #4140: [ARROW-5123][RUST] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140\n \n \n   A rebase and significant rewrite of https://github.com/sunchao/parquet-rs/pull/197\r\n   \r\n   Big improvement: I now use a more natural nested enum style, it helps break out what patterns of data types are . The rest of the broad strokes still apply.\r\n   \r\n   Goal\r\n   ===\r\n   \r\n   Writing many columns to a file is a chore. If you can put your values in to a struct which mirrors the schema of your file, this `derive(ParquetRecordWriter)` will write out all the fields, in the order in which they are defined, to a row_group.\r\n   \r\n   How to Use\r\n   ===\r\n   \r\n   ```\r\n   extern crate parquet;\r\n   #[macro_use] extern crate parquet_derive;\r\n   \r\n   #[derive(ParquetRecordWriter)]\r\n   struct ACompleteRecord<'a> {\r\n     pub a_bool: bool,\r\n     pub a_str: &'a str,\r\n   }\r\n   ```\r\n   \r\n   RecordWriter trait\r\n   ===\r\n   \r\n   This is the new trait which `parquet_derive` will implement for your structs.\r\n   \r\n   ```\r\n   use super::RowGroupWriter;\r\n   \r\n   pub trait RecordWriter<T> {\r\n     fn write_to_row_group(&self, row_group_writer: &mut Box<RowGroupWriter>);\r\n   }\r\n   ```\r\n   \r\n   How does it work?\r\n   ===\r\n   \r\n   The `parquet_derive` crate adds code generating functionality to the rust compiler. The code generation takes rust syntax and emits additional syntax. This macro expansion works on rust 1.15+ stable. This is a dynamic plugin, loaded by the machinery in cargo. Users don't have to do any special `build.rs` steps or anything like that, it's automatic by including `parquet_derive` in their project. The `parquet_derive/src/Cargo.toml` has a section saying as much:\r\n   \r\n   ```\r\n   [lib]\r\n   proc-macro = true\r\n   ```\r\n   \r\n   The rust struct tagged with `#[derive(ParquetRecordWriter)]` is provided to the `parquet_record_writer` function in `parquet_derive/src/lib.rs`. The `syn` crate parses the struct from a string-representation to a AST (a recursive enum value). The AST contains all the values I care about when generating a `RecordWriter` impl:\r\n   \r\n    - the name of the struct\r\n    - the lifetime variables of the struct\r\n    - the fields of the struct\r\n   \r\n   The fields of the struct are translated from AST to a flat `FieldInfo` struct. It has the bits I care about for writing a column: `field_name`, `field_lifetime`, `field_type`, `is_option`, `column_writer_variant`.\r\n   \r\n   The code then does the equivalent of templating to build the `RecordWriter` implementation. The templating functionality is provided by the `quote` crate. At a high-level the template for `RecordWriter` looks like:\r\n   \r\n   ```\r\n   impl RecordWriter for $struct_name {\r\n     fn write_row_group(..) {\r\n       $({\r\n         $column_writer_snippet\r\n       })\r\n     } \r\n   }\r\n   ```\r\n   \r\n   this template is then added under the struct definition, ending up something like:\r\n   \r\n   ```\r\n   struct MyStruct {\r\n   }\r\n   impl RecordWriter for MyStruct {\r\n     fn write_row_group(..) {\r\n       {\r\n          write_col_1();\r\n       };\r\n      {\r\n          write_col_2();\r\n      }\r\n     }\r\n   }\r\n   ```\r\n   \r\n   and finally _THIS_ is the code passed to rustc. It's just code now, fully expanded and standalone. If a user ever changes their `struct MyValue` definition the `ParquetRecordWriter` will be regenerated. There's no intermediate values to version control or worry about.\r\n   \r\n   Viewing the Derived Code\r\n   ===\r\n   \r\n   To see the generated code before it's compiled, one very useful bit is to install `cargo expand` [more info on gh](https://github.com/dtolnay/cargo-expand), then you can do:\r\n   \r\n   ```\r\n   $WORK_DIR/parquet-rs/parquet_derive_test\r\n   cargo expand --lib > ../temp.rs\r\n   ```\r\n   \r\n   then you can dump the contents:\r\n   \r\n   ```\r\n   struct DumbRecord {\r\n       pub a_bool: bool,\r\n       pub a2_bool: bool,\r\n   }\r\n   impl RecordWriter<DumbRecord> for &[DumbRecord] {\r\n       fn write_to_row_group(\r\n           &self,\r\n           row_group_writer: &mut Box<parquet::file::writer::RowGroupWriter>,\r\n       ) {\r\n           let mut row_group_writer = row_group_writer;\r\n           {\r\n               let vals: Vec<bool> = self.iter().map(|x| x.a_bool).collect();\r\n               let mut column_writer = row_group_writer.next_column().unwrap().unwrap();\r\n               if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =\r\n                   column_writer\r\n               {\r\n                   typed.write_batch(&vals[..], None, None).unwrap();\r\n               }\r\n               row_group_writer.close_column(column_writer).unwrap();\r\n           };\r\n           {\r\n               let vals: Vec<bool> = self.iter().map(|x| x.a2_bool).collect();\r\n               let mut column_writer = row_group_writer.next_column().unwrap().unwrap();\r\n               if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =\r\n                   column_writer\r\n               {\r\n                   typed.write_batch(&vals[..], None, None).unwrap();\r\n               }\r\n               row_group_writer.close_column(column_writer).unwrap();\r\n           }\r\n       }\r\n   }\r\n   ```\r\n   \r\n   now I need to write out all the combinations of types we support and make sure it writes out data.\r\n   \r\n   Procedural Macros\r\n   ===\r\n   \r\n   The `parquet_derive` crate can ONLY export the derivation functionality. No traits, nothing else. The derive crate can not host test cases. It's kind of like a \"dummy\" crate which is only used by the compiler, never the code.\r\n   \r\n   The parent crate cannot use the derivation functionality, which is important because it means test code cannot be in the parent crate. This forces us to have a third crate, `parquet_derive_test`.\r\n   \r\n   I'm open to being wrong on any one of these finer points. I had to bang on this for a while to get it to compile!\r\n   \r\n   Potentials For Better Design\r\n   ===\r\n   \r\n    - [x] Recursion could be limited by generating the code as \"snippets\" instead of one big `quote!` AST generator. Or so I think. It might be nicer to push generating each columns writing code to another loop.\r\n    - [X] ~~It would be nicer if I didn't have to be so picky about data going in to the `write_batch` function. Is it possible we could make a version of the function which accept `Into<DataType>` or similar? This would greatly simplify this derivation code as it would not need to enumerate all the supported types. Something like `write_generic_batch(&[impl Into<DataType>])` would be neat.~~ (not tackling in this generation of the plugin)\r\n    - [X] ~~Another idea to improving writing columns, could we have a write function for `Iterator`s? I already have a `Vec<DumbRecord>`, if I could just write a mapping for accessing the one value, we could skip the whole intermediate vec for `write_batch`. Should have some significant memory advantages.~~ (not tackling in this generation of the plugin, it's a bigger parquet-rs enhancement)\r\n    - [X] ~~It might be worthwhile to derive a parquet schema directly from a struct definition. That should stamp out opportunities for type errors.~~ (moved to #203)\r\n   \r\n   Status\r\n   ===\r\n   \r\n   I have successfully integrated this work with my own data exporter (takes postgres/couchdb and outputs a single parquet file).\r\n   \r\n   I think this code is worth including in the project, with the caveat that it only generates simplistic `RecordWriter`s. As people start to use we can add code generation for more complex, nested structs. We can convert the nested matching style to a fancier looping style. But for now, this explicit nesting is easier to debug and understand (to me at least!).\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-11T01:03:10.630+0000",
                    "updated": "2019-04-11T01:03:10.630+0000",
                    "started": "2019-04-11T01:03:10.630+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "225898",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/225915",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "xrl commented on issue #4140: [ARROW-5123][RUST] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#issuecomment-481934328\n \n \n   @sadikovi @sunchao I hope we can pick up where we left off on the last PR \ud83d\ude06 \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-11T01:51:16.462+0000",
                    "updated": "2019-04-11T01:51:16.462+0000",
                    "started": "2019-04-11T01:51:16.461+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "225915",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/225919",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io commented on issue #4140: [ARROW-5123][RUST] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#issuecomment-481938278\n \n \n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/4140?src=pr&el=h1) Report\n   > Merging [#4140](https://codecov.io/gh/apache/arrow/pull/4140?src=pr&el=desc) into [master](https://codecov.io/gh/apache/arrow/commit/1ff1bcada82b14cc3299b8562e320e6028696d2e?src=pr&el=desc) will **decrease** coverage by `0.06%`.\n   > The diff coverage is `n/a`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/4140/graphs/tree.svg?width=650&token=LpTCFbqVT1&height=150&src=pr)](https://codecov.io/gh/apache/arrow/pull/4140?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #4140      +/-   ##\n   ==========================================\n   - Coverage   87.85%   87.79%   -0.07%     \n   ==========================================\n     Files         745      745              \n     Lines       91468    91468              \n     Branches     1252     1252              \n   ==========================================\n   - Hits        80361    80302      -59     \n   - Misses      10988    11045      +57     \n   - Partials      119      121       +2\n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/4140?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [go/arrow/math/int64\\_avx2\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC9pbnQ2NF9hdngyX2FtZDY0Lmdv) | `0% <0%> (-100%)` | :arrow_down: |\n   | [go/arrow/memory/memory\\_avx2\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWVtb3J5L21lbW9yeV9hdngyX2FtZDY0Lmdv) | `0% <0%> (-100%)` | :arrow_down: |\n   | [go/arrow/math/float64\\_avx2\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC9mbG9hdDY0X2F2eDJfYW1kNjQuZ28=) | `0% <0%> (-100%)` | :arrow_down: |\n   | [go/arrow/math/uint64\\_avx2\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC91aW50NjRfYXZ4Ml9hbWQ2NC5nbw==) | `0% <0%> (-100%)` | :arrow_down: |\n   | [go/arrow/math/float64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC9mbG9hdDY0X2FtZDY0Lmdv) | `33.33% <0%> (-33.34%)` | :arrow_down: |\n   | [go/arrow/math/int64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC9pbnQ2NF9hbWQ2NC5nbw==) | `33.33% <0%> (-33.34%)` | :arrow_down: |\n   | [go/arrow/math/uint64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC91aW50NjRfYW1kNjQuZ28=) | `33.33% <0%> (-33.34%)` | :arrow_down: |\n   | [go/arrow/math/math\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC9tYXRoX2FtZDY0Lmdv) | `31.57% <0%> (-31.58%)` | :arrow_down: |\n   | [go/arrow/memory/memory\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWVtb3J5L21lbW9yeV9hbWQ2NC5nbw==) | `28.57% <0%> (-28.58%)` | :arrow_down: |\n   | [js/src/ipc/metadata/message.ts](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree#diff-anMvc3JjL2lwYy9tZXRhZGF0YS9tZXNzYWdlLnRz) | `92.99% <0%> (-1.28%)` | :arrow_down: |\n   | ... and [1 more](https://codecov.io/gh/apache/arrow/pull/4140/diff?src=pr&el=tree-more) | |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/4140?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/4140?src=pr&el=footer). Last update [1ff1bca...c1c73de](https://codecov.io/gh/apache/arrow/pull/4140?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-11T02:13:29.254+0000",
                    "updated": "2019-04-11T02:13:29.254+0000",
                    "started": "2019-04-11T02:13:29.253+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "225919",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/225939",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on issue #4140: [ARROW-5123][RUST] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#issuecomment-481946370\n \n \n   Thanks for the PR @xrl ! will take a look at it soon.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-11T03:00:16.757+0000",
                    "updated": "2019-04-11T03:00:16.757+0000",
                    "started": "2019-04-11T03:00:16.756+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "225939",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227015",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "xrl commented on issue #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#issuecomment-482750439\n \n \n   I'm not now adding support for casting `NaiveDateTime` to a `i64` to support `TIMESTAMP_MILLIS`. This is a feature that could use some design work, or feedback. I think I can support other timestamp types too but NaiveDateTime is the \"most accurate\" because it assumes UTC which I think is the most compatible with how parquet treats timestamps?\r\n   \r\n   In any case, to be clear, the follow now automatically works:\r\n   \r\n   ```\r\n   #[derive(ParquetRecordWriter)]\r\n   struct MyStruct {\r\n     timestamp: NaiveDateTime\r\n   }\r\n   ```\r\n   \r\n   are there are other logical types that would be useful in this preliminary release? Timestamps scratch my itch since I'm translating records from postgres over to parquet and our app uses a lot of timezone-free timestamps.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-12T23:16:49.650+0000",
                    "updated": "2019-04-12T23:16:49.650+0000",
                    "started": "2019-04-12T23:16:49.650+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227015",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227454",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275177715\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n+        let is_a_timestamp = self.ty.last_part() == \"NaiveDateTime\";// TODO\n+        let copy_to_vec = match self.ty.physical_type() {\n+            parquet::basic::Type::BYTE_ARRAY\n+            | parquet::basic::Type::FIXED_LEN_BYTE_ARRAY => false,\n+            _ => true,\n+        };\n+\n+        fn option_into_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+            copy_to_vec: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let binding = if copy_to_vec {\n+                quote! { let Some(inner) = x.#id }\n+            } else {\n+                quote! { let Some(ref inner) = x.#id }\n+            };\n+\n+            let some = if is_a_byte_buf {\n+                quote! { Some((&inner[..]).into())}\n \n Review comment:\n   Do we need to use `quote!` in these cases?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:11.867+0000",
                    "updated": "2019-04-15T06:18:11.867+0000",
                    "started": "2019-04-15T06:18:11.866+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227454",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227455",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275175561\n \n \n\n ##########\n File path: rust/parquet_derive/README.md\n ##########\n @@ -0,0 +1,91 @@\n+<!---\n+  Licensed to the Apache Software Foundation (ASF) under one\n+  or more contributor license agreements.  See the NOTICE file\n+  distributed with this work for additional information\n+  regarding copyright ownership.  The ASF licenses this file\n+  to you under the Apache License, Version 2.0 (the\n+  \"License\"); you may not use this file except in compliance\n+  with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+  Unless required by applicable law or agreed to in writing,\n+  software distributed under the License is distributed on an\n+  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+  KIND, either express or implied.  See the License for the\n+  specific language governing permissions and limitations\n+  under the License.\n+-->\n+\n+# parquet_derive-rs\n+\n+A crate for automatically deriving `RecordWriter` for arbitrary, _simple_ structs. This does not generate writers for nested structures but it will work great for shallow structures.\n+\n+## Usage\n+Add this to your Cargo.toml:\n+```toml\n+[dependencies]\n+parquet = \"0.4\"\n \n Review comment:\n   These version need to be updated to 0.13.0, to be consistent with Arrow version.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:11.888+0000",
                    "updated": "2019-04-15T06:18:11.888+0000",
                    "started": "2019-04-15T06:18:11.887+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227455",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227456",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275176288\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n+        let is_a_timestamp = self.ty.last_part() == \"NaiveDateTime\";// TODO\n \n Review comment:\n   nit: remove `TODO` or add more text stating what's need to be done.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:11.988+0000",
                    "updated": "2019-04-15T06:18:11.988+0000",
                    "started": "2019-04-15T06:18:11.988+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227456",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227457",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275175616\n \n \n\n ##########\n File path: rust/parquet_derive/README.md\n ##########\n @@ -0,0 +1,91 @@\n+<!---\n+  Licensed to the Apache Software Foundation (ASF) under one\n+  or more contributor license agreements.  See the NOTICE file\n+  distributed with this work for additional information\n+  regarding copyright ownership.  The ASF licenses this file\n+  to you under the Apache License, Version 2.0 (the\n+  \"License\"); you may not use this file except in compliance\n+  with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+  Unless required by applicable law or agreed to in writing,\n+  software distributed under the License is distributed on an\n+  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+  KIND, either express or implied.  See the License for the\n+  specific language governing permissions and limitations\n+  under the License.\n+-->\n+\n+# parquet_derive-rs\n \n Review comment:\n   Can we change this to something like \"Parquet Derive\"? \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:11.989+0000",
                    "updated": "2019-04-15T06:18:11.989+0000",
                    "started": "2019-04-15T06:18:11.988+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227457",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227458",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275175625\n \n \n\n ##########\n File path: rust/parquet_derive/Cargo.toml\n ##########\n @@ -0,0 +1,34 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+[package]\n+name = \"parquet_derive\"\n+version = \"0.2.0\"\n \n Review comment:\n   Version should be 0.13.0\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:11.990+0000",
                    "updated": "2019-04-15T06:18:11.990+0000",
                    "started": "2019-04-15T06:18:11.990+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227458",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227459",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275175696\n \n \n\n ##########\n File path: rust/parquet_derive/src/lib.rs\n ##########\n @@ -0,0 +1,88 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#![recursion_limit = \"128\"]\n+\n+extern crate proc_macro;\n+extern crate proc_macro2;\n+extern crate syn;\n+#[macro_use]\n+extern crate quote;\n+\n+extern crate parquet;\n+\n+use syn::{parse_macro_input, Data, DataStruct, DeriveInput};\n+\n+mod parquet_field;\n+\n+/// Derive flat, simple RecordWriter implementations. Works by parsing\n+/// a struct tagged with `#[derive(ParquetRecordWriter)]` and emitting\n+/// the correct writing code for each field of the struct, in\n+/// the order fields are defined.\n+///\n+/// It is up to the programmer to keep the order of the struct\n+/// fields lined up with the schema.\n+///\n+/// Example:\n+///\n+/// ```ignore\n+/// use parquet;\n+/// use parquet::record::RecordWriter;\n+//\n+/// #[derive(ParquetRecordWriter)]\n \n Review comment:\n   It would be great if we can also have an example that shows how to write some simple data using the derived writer.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:11.999+0000",
                    "updated": "2019-04-15T06:18:11.999+0000",
                    "started": "2019-04-15T06:18:11.999+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227459",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227460",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275175657\n \n \n\n ##########\n File path: rust/parquet_derive/Cargo.toml\n ##########\n @@ -0,0 +1,34 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+[package]\n+name = \"parquet_derive\"\n+version = \"0.2.0\"\n+authors = [\"Xavier Lange <xrlange@gmail.com>\"]\n \n Review comment:\n   Could we also change the authors to be \"\"Apache Arrow <dev@arrow.apache.org>\"\" - just follow the standard.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.005+0000",
                    "updated": "2019-04-15T06:18:12.005+0000",
                    "started": "2019-04-15T06:18:12.005+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227460",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227461",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275215442\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n+        let is_a_timestamp = self.ty.last_part() == \"NaiveDateTime\";// TODO\n+        let copy_to_vec = match self.ty.physical_type() {\n+            parquet::basic::Type::BYTE_ARRAY\n+            | parquet::basic::Type::FIXED_LEN_BYTE_ARRAY => false,\n+            _ => true,\n+        };\n+\n+        fn option_into_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+            copy_to_vec: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let binding = if copy_to_vec {\n+                quote! { let Some(inner) = x.#id }\n+            } else {\n+                quote! { let Some(ref inner) = x.#id }\n+            };\n+\n+            let some = if is_a_byte_buf {\n+                quote! { Some((&inner[..]).into())}\n+            } else if is_a_timestamp {\n+                quote! { Some(inner.timestamp_millis()) }\n+            } else {\n+                quote! { Some(inner) }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().filter_map(|x| {\n+                    if #binding {\n+                        #some\n+                    } else {\n+                        None\n+                    }\n+                }).collect();\n+            }\n+        }\n+\n+        fn copied_direct_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let access = if is_a_byte_buf {\n+                quote! { (&x.#id[..]).into() }\n+            } else if is_a_timestamp {\n+                quote!( x.#id.timestamp_millis() )\n+            } else {\n+                quote! { x.#id }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().map(|x| #access).collect();\n+            }\n+        }\n+\n+        let vals_builder = match &self.ty {\n+            Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => option_into_vals(ident, is_a_byte_buf, is_a_timestamp,copy_to_vec),\n+                Type::Reference(_, ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    _ => unimplemented!(\"sorry charlie\"),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+                Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    Type::Reference(_, ref second_type) => match **second_type {\n+                        Type::TypePath(_) => {\n+                            option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                        }\n+                        _ => unimplemented!(\"sorry charlie\"),\n+                    },\n+                    ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            f @ _ => unimplemented!(\"don't support {:#?}\", f),\n+        };\n+\n+        fn optional_definition_levels(id: &syn::Ident) -> proc_macro2::TokenStream {\n+            quote! {\n+                let definition_levels: Vec<i16> = self\n+                  .iter()\n+                  .map(|x| if x.#id.is_some() { 1 } else { 0 })\n+                  .collect();\n+            }\n+        }\n+\n+        let definition_levels = match &self.ty {\n+            Type::TypePath(_) => None,\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                Type::Option(_) => unimplemented!(\"nested options? that's weird\"),\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    _ => unimplemented!(\"a little too much nesting. bailing out.\"),\n+                },\n+            },\n+            Type::Reference(_, ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type) => match **first_type {\n+                Type::TypePath(_) => None,\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type)\n+                | Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    Type::Reference(_, ref third_type) => match **third_type {\n+                        Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                        _ => unimplemented!(\n+                            \"we don't do some more complex definition levels... yet!\"\n+                        ),\n+                    },\n+                    _ => unimplemented!(\n+                        \"we don't do more complex definition levels... yet!\"\n+                    ),\n+                },\n+            },\n+        };\n+\n+        let write_batch_expr = if definition_levels.is_some() {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], Some(&definition_levels[..]), None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        } else {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], None, None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        };\n+\n+        quote! {\n+            {\n+                #definition_levels\n+\n+                #vals_builder\n+\n+                #write_batch_expr\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Debug, PartialEq)]\n+pub enum Type {\n+    Array(Box<Type>),\n+    Option(Box<Type>),\n+    Vec(Box<Type>),\n+    TypePath(syn::Type),\n+    Reference(Option<syn::Lifetime>, Box<Type>),\n+}\n+\n+impl Type {\n+    pub fn column_writer(&self) -> syn::TypePath {\n+        use parquet::basic::Type as BasicType;\n+\n+        let path = match self.physical_type() {\n+            BasicType::BOOLEAN => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::BoolColumnWriter\")\n+            }\n+            BasicType::INT32 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int32ColumnWriter\")\n+            }\n+            BasicType::INT64 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int64ColumnWriter\")\n+            }\n+            BasicType::INT96 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int96ColumnWriter\")\n+            }\n+            BasicType::FLOAT => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::FloatColumnWriter\")\n+            }\n+            BasicType::DOUBLE => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::DoubleColumnWriter\",\n+            ),\n+            BasicType::BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::ByteArrayColumnWriter\",\n+            ),\n+            BasicType::FIXED_LEN_BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::FixedLenByteArrayColumnWriter\",\n+            ),\n+        };\n+        path.unwrap()\n+    }\n+\n+    fn inner_type(&self) -> &syn::Type {\n+        let leaf_type = self.leaf_type();\n+\n+        match leaf_type {\n+            Type::TypePath(ref type_) => type_,\n+            Type::Option(ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type)\n+            | Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(ref type_) => type_,\n+                _ => unimplemented!(\"leaf_type() should only return shallow types\"),\n+            },\n+        }\n+    }\n+\n+    pub fn leaf_type(&self) -> &Type {\n+        match &self {\n+            Type::TypePath(_) => &self,\n+            Type::Option(ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type)\n+            | Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(_) => &self,\n+                Type::Option(ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type)\n+                | Type::Reference(_, ref second_type) => match **second_type {\n+                    Type::TypePath(_) => first_type,\n+                    Type::Option(ref third_type)\n+                    | Type::Vec(ref third_type)\n+                    | Type::Array(ref third_type)\n+                    | Type::Reference(_, ref third_type) => match **third_type {\n+                        Type::TypePath(_) => second_type,\n+                        Type::Option(ref fourth_type)\n+                        | Type::Vec(ref fourth_type)\n+                        | Type::Array(ref fourth_type)\n+                        | Type::Reference(_, ref fourth_type) => match **fourth_type {\n+                            Type::TypePath(_) => third_type,\n+                            _ => unimplemented!(\"sorry, I don't descend this far\"),\n+                        },\n+                    },\n+                },\n+            },\n+        }\n+    }\n+\n+    pub fn last_part(&self) -> String {\n+        let inner_type = self.inner_type();\n+        let inner_type_str = (quote! { #inner_type }).to_string();\n+\n+        inner_type_str.split(\"::\").last().unwrap().trim().to_string()\n+    }\n+\n+    pub fn physical_type(&self) -> parquet::basic::Type {\n+        use parquet::basic::Type as BasicType;\n+\n+        let last_part = self.last_part();\n+        let leaf_type = self.leaf_type();\n+\n+        match leaf_type {\n+            Type::Array(ref first_type) => {\n+                if let Type::TypePath(_) = **first_type {\n+                    if last_part == \"u8\" {\n+                        return BasicType::FIXED_LEN_BYTE_ARRAY;\n+                    }\n+                }\n+            }\n+            Type::Vec(ref first_type) => {\n+                if let Type::TypePath(_) = **first_type {\n+                    if last_part == \"u8\" {\n+                        return BasicType::BYTE_ARRAY;\n+                    }\n+                }\n+            }\n+            _ => (),\n+        }\n+\n+        match last_part.trim() {\n+            \"bool\" => BasicType::BOOLEAN,\n+            \"u8\" | \"u16\" | \"u32\" => BasicType::INT32,\n+            \"i8\" | \"i16\" | \"i32\" => BasicType::INT32,\n+            \"u64\" | \"i64\" | \"usize\" | \"NaiveDateTime\" => BasicType::INT64,\n+            \"f32\" => BasicType::FLOAT,\n+            \"f64\" => BasicType::DOUBLE,\n+            \"String\" | \"str\" => BasicType::BYTE_ARRAY,\n+            f @ _ => unimplemented!(\"sorry, don't handle {} yet!\", f),\n+        }\n+    }\n+\n+    pub fn from_type_path(f: &syn::Field, p: &syn::TypePath) -> Self {\n+        let segments_iter = p.path.segments.iter();\n+        let segments: Vec<syn::PathSegment> = segments_iter.map(|x| x.clone()).collect();\n+        let last_segment = segments.last().unwrap();\n \n Review comment:\n   Can this be simplified to the following?\r\n   ```rust\r\n           let last_segment = p.path.segments.last().unwrap().into_value();\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.005+0000",
                    "updated": "2019-04-15T06:18:12.005+0000",
                    "started": "2019-04-15T06:18:12.005+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227461",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227462",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275177640\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n+        let is_a_timestamp = self.ty.last_part() == \"NaiveDateTime\";// TODO\n+        let copy_to_vec = match self.ty.physical_type() {\n+            parquet::basic::Type::BYTE_ARRAY\n+            | parquet::basic::Type::FIXED_LEN_BYTE_ARRAY => false,\n+            _ => true,\n+        };\n+\n+        fn option_into_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+            copy_to_vec: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let binding = if copy_to_vec {\n+                quote! { let Some(inner) = x.#id }\n \n Review comment:\n   Could you explain what `x` is and what `#id` is? I can't find it in the context..\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.008+0000",
                    "updated": "2019-04-15T06:18:12.008+0000",
                    "started": "2019-04-15T06:18:12.008+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227462",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227463",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275217149\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n+        let is_a_timestamp = self.ty.last_part() == \"NaiveDateTime\";// TODO\n+        let copy_to_vec = match self.ty.physical_type() {\n+            parquet::basic::Type::BYTE_ARRAY\n+            | parquet::basic::Type::FIXED_LEN_BYTE_ARRAY => false,\n+            _ => true,\n+        };\n+\n+        fn option_into_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+            copy_to_vec: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let binding = if copy_to_vec {\n+                quote! { let Some(inner) = x.#id }\n+            } else {\n+                quote! { let Some(ref inner) = x.#id }\n+            };\n+\n+            let some = if is_a_byte_buf {\n+                quote! { Some((&inner[..]).into())}\n+            } else if is_a_timestamp {\n+                quote! { Some(inner.timestamp_millis()) }\n+            } else {\n+                quote! { Some(inner) }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().filter_map(|x| {\n+                    if #binding {\n+                        #some\n+                    } else {\n+                        None\n+                    }\n+                }).collect();\n+            }\n+        }\n+\n+        fn copied_direct_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let access = if is_a_byte_buf {\n+                quote! { (&x.#id[..]).into() }\n+            } else if is_a_timestamp {\n+                quote!( x.#id.timestamp_millis() )\n+            } else {\n+                quote! { x.#id }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().map(|x| #access).collect();\n+            }\n+        }\n+\n+        let vals_builder = match &self.ty {\n+            Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => option_into_vals(ident, is_a_byte_buf, is_a_timestamp,copy_to_vec),\n+                Type::Reference(_, ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    _ => unimplemented!(\"sorry charlie\"),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+                Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    Type::Reference(_, ref second_type) => match **second_type {\n+                        Type::TypePath(_) => {\n+                            option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                        }\n+                        _ => unimplemented!(\"sorry charlie\"),\n+                    },\n+                    ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            f @ _ => unimplemented!(\"don't support {:#?}\", f),\n+        };\n+\n+        fn optional_definition_levels(id: &syn::Ident) -> proc_macro2::TokenStream {\n+            quote! {\n+                let definition_levels: Vec<i16> = self\n+                  .iter()\n+                  .map(|x| if x.#id.is_some() { 1 } else { 0 })\n+                  .collect();\n+            }\n+        }\n+\n+        let definition_levels = match &self.ty {\n+            Type::TypePath(_) => None,\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                Type::Option(_) => unimplemented!(\"nested options? that's weird\"),\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    _ => unimplemented!(\"a little too much nesting. bailing out.\"),\n+                },\n+            },\n+            Type::Reference(_, ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type) => match **first_type {\n+                Type::TypePath(_) => None,\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type)\n+                | Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    Type::Reference(_, ref third_type) => match **third_type {\n+                        Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                        _ => unimplemented!(\n+                            \"we don't do some more complex definition levels... yet!\"\n+                        ),\n+                    },\n+                    _ => unimplemented!(\n+                        \"we don't do more complex definition levels... yet!\"\n+                    ),\n+                },\n+            },\n+        };\n+\n+        let write_batch_expr = if definition_levels.is_some() {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], Some(&definition_levels[..]), None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        } else {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], None, None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        };\n+\n+        quote! {\n+            {\n+                #definition_levels\n+\n+                #vals_builder\n+\n+                #write_batch_expr\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Debug, PartialEq)]\n+pub enum Type {\n+    Array(Box<Type>),\n+    Option(Box<Type>),\n+    Vec(Box<Type>),\n+    TypePath(syn::Type),\n+    Reference(Option<syn::Lifetime>, Box<Type>),\n+}\n+\n+impl Type {\n+    pub fn column_writer(&self) -> syn::TypePath {\n+        use parquet::basic::Type as BasicType;\n+\n+        let path = match self.physical_type() {\n+            BasicType::BOOLEAN => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::BoolColumnWriter\")\n+            }\n+            BasicType::INT32 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int32ColumnWriter\")\n+            }\n+            BasicType::INT64 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int64ColumnWriter\")\n+            }\n+            BasicType::INT96 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int96ColumnWriter\")\n+            }\n+            BasicType::FLOAT => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::FloatColumnWriter\")\n+            }\n+            BasicType::DOUBLE => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::DoubleColumnWriter\",\n+            ),\n+            BasicType::BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::ByteArrayColumnWriter\",\n+            ),\n+            BasicType::FIXED_LEN_BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::FixedLenByteArrayColumnWriter\",\n+            ),\n+        };\n+        path.unwrap()\n+    }\n+\n+    fn inner_type(&self) -> &syn::Type {\n \n Review comment:\n   Can you add comments on what this and `leaf_type` below is doing?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.011+0000",
                    "updated": "2019-04-15T06:18:12.011+0000",
                    "started": "2019-04-15T06:18:12.011+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227463",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227464",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275175917\n \n \n\n ##########\n File path: rust/parquet_derive/src/lib.rs\n ##########\n @@ -0,0 +1,88 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#![recursion_limit = \"128\"]\n+\n+extern crate proc_macro;\n+extern crate proc_macro2;\n+extern crate syn;\n+#[macro_use]\n+extern crate quote;\n+\n+extern crate parquet;\n+\n+use syn::{parse_macro_input, Data, DataStruct, DeriveInput};\n+\n+mod parquet_field;\n+\n+/// Derive flat, simple RecordWriter implementations. Works by parsing\n+/// a struct tagged with `#[derive(ParquetRecordWriter)]` and emitting\n+/// the correct writing code for each field of the struct, in\n+/// the order fields are defined.\n+///\n+/// It is up to the programmer to keep the order of the struct\n+/// fields lined up with the schema.\n+///\n+/// Example:\n+///\n+/// ```ignore\n+/// use parquet;\n+/// use parquet::record::RecordWriter;\n+//\n+/// #[derive(ParquetRecordWriter)]\n+/// struct ACompleteRecord<'a> {\n+///   pub a_bool: bool,\n+///   pub a_str: &'a str,\n+/// }\n+/// ```\n+///\n+#[proc_macro_derive(ParquetRecordWriter)]\n+pub fn parquet_record_writer(input: proc_macro::TokenStream) -> proc_macro::TokenStream {\n+    let input: DeriveInput = parse_macro_input!(input as DeriveInput);\n+    let fields = match input.data {\n+        Data::Struct(DataStruct { fields, .. }) => fields,\n+        Data::Enum(_) => unimplemented!(\"don't support enum\"),\n+        Data::Union(_) => unimplemented!(\"don't support union\"),\n+    };\n+\n+    let field_infos: Vec<_> = fields\n+        .iter()\n+        .map(|f: &syn::Field| parquet_field::Field::from(f))\n+        .collect();\n+\n+    let writer_snippets: Vec<proc_macro2::TokenStream> =\n+        field_infos.iter().map(|x| x.writer_snippet()).collect();\n+\n+    let derived_for = input.ident;\n+    let generics = input.generics;\n+\n+    (quote! {\n+    impl#generics RecordWriter<#derived_for#generics> for &[#derived_for#generics] {\n+      fn write_to_row_group(&self, row_group_writer: &mut Box<parquet::file::writer::RowGroupWriter>) {\n+        let mut row_group_writer = row_group_writer;\n+        let records = &self;\n+        #(\n+          {\n+              let mut column_writer = row_group_writer.next_column().unwrap().unwrap();\n \n Review comment:\n   Should we surface the error from this method, instead of `unwrap`? Also curious how does it know it has iterated through all the column writers?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.014+0000",
                    "updated": "2019-04-15T06:18:12.014+0000",
                    "started": "2019-04-15T06:18:12.014+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227464",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227465",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275217735\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n+        let is_a_timestamp = self.ty.last_part() == \"NaiveDateTime\";// TODO\n+        let copy_to_vec = match self.ty.physical_type() {\n+            parquet::basic::Type::BYTE_ARRAY\n+            | parquet::basic::Type::FIXED_LEN_BYTE_ARRAY => false,\n+            _ => true,\n+        };\n+\n+        fn option_into_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+            copy_to_vec: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let binding = if copy_to_vec {\n+                quote! { let Some(inner) = x.#id }\n+            } else {\n+                quote! { let Some(ref inner) = x.#id }\n+            };\n+\n+            let some = if is_a_byte_buf {\n+                quote! { Some((&inner[..]).into())}\n+            } else if is_a_timestamp {\n+                quote! { Some(inner.timestamp_millis()) }\n+            } else {\n+                quote! { Some(inner) }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().filter_map(|x| {\n+                    if #binding {\n+                        #some\n+                    } else {\n+                        None\n+                    }\n+                }).collect();\n+            }\n+        }\n+\n+        fn copied_direct_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let access = if is_a_byte_buf {\n+                quote! { (&x.#id[..]).into() }\n+            } else if is_a_timestamp {\n+                quote!( x.#id.timestamp_millis() )\n+            } else {\n+                quote! { x.#id }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().map(|x| #access).collect();\n+            }\n+        }\n+\n+        let vals_builder = match &self.ty {\n+            Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => option_into_vals(ident, is_a_byte_buf, is_a_timestamp,copy_to_vec),\n+                Type::Reference(_, ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    _ => unimplemented!(\"sorry charlie\"),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+                Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    Type::Reference(_, ref second_type) => match **second_type {\n+                        Type::TypePath(_) => {\n+                            option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                        }\n+                        _ => unimplemented!(\"sorry charlie\"),\n+                    },\n+                    ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            f @ _ => unimplemented!(\"don't support {:#?}\", f),\n+        };\n+\n+        fn optional_definition_levels(id: &syn::Ident) -> proc_macro2::TokenStream {\n+            quote! {\n+                let definition_levels: Vec<i16> = self\n+                  .iter()\n+                  .map(|x| if x.#id.is_some() { 1 } else { 0 })\n+                  .collect();\n+            }\n+        }\n+\n+        let definition_levels = match &self.ty {\n+            Type::TypePath(_) => None,\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                Type::Option(_) => unimplemented!(\"nested options? that's weird\"),\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    _ => unimplemented!(\"a little too much nesting. bailing out.\"),\n+                },\n+            },\n+            Type::Reference(_, ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type) => match **first_type {\n+                Type::TypePath(_) => None,\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type)\n+                | Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    Type::Reference(_, ref third_type) => match **third_type {\n+                        Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                        _ => unimplemented!(\n+                            \"we don't do some more complex definition levels... yet!\"\n+                        ),\n+                    },\n+                    _ => unimplemented!(\n+                        \"we don't do more complex definition levels... yet!\"\n+                    ),\n+                },\n+            },\n+        };\n+\n+        let write_batch_expr = if definition_levels.is_some() {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], Some(&definition_levels[..]), None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        } else {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], None, None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        };\n+\n+        quote! {\n+            {\n+                #definition_levels\n+\n+                #vals_builder\n+\n+                #write_batch_expr\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Debug, PartialEq)]\n+pub enum Type {\n+    Array(Box<Type>),\n+    Option(Box<Type>),\n+    Vec(Box<Type>),\n+    TypePath(syn::Type),\n+    Reference(Option<syn::Lifetime>, Box<Type>),\n+}\n+\n+impl Type {\n+    pub fn column_writer(&self) -> syn::TypePath {\n+        use parquet::basic::Type as BasicType;\n+\n+        let path = match self.physical_type() {\n+            BasicType::BOOLEAN => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::BoolColumnWriter\")\n+            }\n+            BasicType::INT32 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int32ColumnWriter\")\n+            }\n+            BasicType::INT64 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int64ColumnWriter\")\n+            }\n+            BasicType::INT96 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int96ColumnWriter\")\n+            }\n+            BasicType::FLOAT => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::FloatColumnWriter\")\n+            }\n+            BasicType::DOUBLE => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::DoubleColumnWriter\",\n+            ),\n+            BasicType::BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::ByteArrayColumnWriter\",\n+            ),\n+            BasicType::FIXED_LEN_BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::FixedLenByteArrayColumnWriter\",\n+            ),\n+        };\n+        path.unwrap()\n+    }\n+\n+    fn inner_type(&self) -> &syn::Type {\n+        let leaf_type = self.leaf_type();\n+\n+        match leaf_type {\n+            Type::TypePath(ref type_) => type_,\n+            Type::Option(ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type)\n+            | Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(ref type_) => type_,\n+                _ => unimplemented!(\"leaf_type() should only return shallow types\"),\n+            },\n+        }\n+    }\n+\n+    pub fn leaf_type(&self) -> &Type {\n+        match &self {\n+            Type::TypePath(_) => &self,\n+            Type::Option(ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type)\n+            | Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(_) => &self,\n+                Type::Option(ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type)\n+                | Type::Reference(_, ref second_type) => match **second_type {\n+                    Type::TypePath(_) => first_type,\n+                    Type::Option(ref third_type)\n+                    | Type::Vec(ref third_type)\n+                    | Type::Array(ref third_type)\n+                    | Type::Reference(_, ref third_type) => match **third_type {\n+                        Type::TypePath(_) => second_type,\n+                        Type::Option(ref fourth_type)\n+                        | Type::Vec(ref fourth_type)\n+                        | Type::Array(ref fourth_type)\n+                        | Type::Reference(_, ref fourth_type) => match **fourth_type {\n+                            Type::TypePath(_) => third_type,\n+                            _ => unimplemented!(\"sorry, I don't descend this far\"),\n+                        },\n+                    },\n+                },\n+            },\n+        }\n+    }\n+\n+    pub fn last_part(&self) -> String {\n+        let inner_type = self.inner_type();\n+        let inner_type_str = (quote! { #inner_type }).to_string();\n+\n+        inner_type_str.split(\"::\").last().unwrap().trim().to_string()\n+    }\n+\n+    pub fn physical_type(&self) -> parquet::basic::Type {\n+        use parquet::basic::Type as BasicType;\n+\n+        let last_part = self.last_part();\n+        let leaf_type = self.leaf_type();\n+\n+        match leaf_type {\n+            Type::Array(ref first_type) => {\n+                if let Type::TypePath(_) = **first_type {\n+                    if last_part == \"u8\" {\n+                        return BasicType::FIXED_LEN_BYTE_ARRAY;\n+                    }\n+                }\n+            }\n+            Type::Vec(ref first_type) => {\n+                if let Type::TypePath(_) = **first_type {\n+                    if last_part == \"u8\" {\n+                        return BasicType::BYTE_ARRAY;\n+                    }\n+                }\n+            }\n+            _ => (),\n+        }\n+\n+        match last_part.trim() {\n+            \"bool\" => BasicType::BOOLEAN,\n+            \"u8\" | \"u16\" | \"u32\" => BasicType::INT32,\n+            \"i8\" | \"i16\" | \"i32\" => BasicType::INT32,\n+            \"u64\" | \"i64\" | \"usize\" | \"NaiveDateTime\" => BasicType::INT64,\n+            \"f32\" => BasicType::FLOAT,\n+            \"f64\" => BasicType::DOUBLE,\n+            \"String\" | \"str\" => BasicType::BYTE_ARRAY,\n+            f @ _ => unimplemented!(\"sorry, don't handle {} yet!\", f),\n+        }\n+    }\n+\n+    pub fn from_type_path(f: &syn::Field, p: &syn::TypePath) -> Self {\n+        let segments_iter = p.path.segments.iter();\n+        let segments: Vec<syn::PathSegment> = segments_iter.map(|x| x.clone()).collect();\n+        let last_segment = segments.last().unwrap();\n+\n+        let is_vec =\n+            last_segment.ident == syn::Ident::new(\"Vec\", proc_macro2::Span::call_site());\n+        let is_option = last_segment.ident\n+            == syn::Ident::new(\"Option\", proc_macro2::Span::call_site());\n+\n+        if is_vec || is_option {\n+            let generic_type = match &last_segment.arguments {\n+                syn::PathArguments::AngleBracketed(angle_args) => {\n+                    let mut gen_args_iter = angle_args.args.iter();\n+                    let first_arg = gen_args_iter.next().unwrap();\n+                    assert!(gen_args_iter.next().is_none());\n \n Review comment:\n   Can these be simplified to?\r\n   ```rust\r\n   let first_arg = &angle_args.args[0];\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.021+0000",
                    "updated": "2019-04-15T06:18:12.021+0000",
                    "started": "2019-04-15T06:18:12.020+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227465",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227466",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275217204\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n+        let is_a_timestamp = self.ty.last_part() == \"NaiveDateTime\";// TODO\n+        let copy_to_vec = match self.ty.physical_type() {\n+            parquet::basic::Type::BYTE_ARRAY\n+            | parquet::basic::Type::FIXED_LEN_BYTE_ARRAY => false,\n+            _ => true,\n+        };\n+\n+        fn option_into_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+            copy_to_vec: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let binding = if copy_to_vec {\n+                quote! { let Some(inner) = x.#id }\n+            } else {\n+                quote! { let Some(ref inner) = x.#id }\n+            };\n+\n+            let some = if is_a_byte_buf {\n+                quote! { Some((&inner[..]).into())}\n+            } else if is_a_timestamp {\n+                quote! { Some(inner.timestamp_millis()) }\n+            } else {\n+                quote! { Some(inner) }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().filter_map(|x| {\n+                    if #binding {\n+                        #some\n+                    } else {\n+                        None\n+                    }\n+                }).collect();\n+            }\n+        }\n+\n+        fn copied_direct_vals(\n+            id: &syn::Ident,\n+            is_a_byte_buf: bool,\n+            is_a_timestamp: bool,\n+        ) -> proc_macro2::TokenStream {\n+            let access = if is_a_byte_buf {\n+                quote! { (&x.#id[..]).into() }\n+            } else if is_a_timestamp {\n+                quote!( x.#id.timestamp_millis() )\n+            } else {\n+                quote! { x.#id }\n+            };\n+\n+            quote! {\n+                let vals: Vec<_> = records.iter().map(|x| #access).collect();\n+            }\n+        }\n+\n+        let vals_builder = match &self.ty {\n+            Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => option_into_vals(ident, is_a_byte_buf, is_a_timestamp,copy_to_vec),\n+                Type::Reference(_, ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    _ => unimplemented!(\"sorry charlie\"),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(_) => copied_direct_vals(ident, is_a_byte_buf, is_a_timestamp),\n+                Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => {\n+                        option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                    }\n+                    Type::Reference(_, ref second_type) => match **second_type {\n+                        Type::TypePath(_) => {\n+                            option_into_vals(ident, is_a_byte_buf, is_a_timestamp, copy_to_vec)\n+                        }\n+                        _ => unimplemented!(\"sorry charlie\"),\n+                    },\n+                    ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+                },\n+                ref f @ _ => unimplemented!(\"whoa: {:#?}\", f),\n+            },\n+            f @ _ => unimplemented!(\"don't support {:#?}\", f),\n+        };\n+\n+        fn optional_definition_levels(id: &syn::Ident) -> proc_macro2::TokenStream {\n+            quote! {\n+                let definition_levels: Vec<i16> = self\n+                  .iter()\n+                  .map(|x| if x.#id.is_some() { 1 } else { 0 })\n+                  .collect();\n+            }\n+        }\n+\n+        let definition_levels = match &self.ty {\n+            Type::TypePath(_) => None,\n+            Type::Option(ref first_type) => match **first_type {\n+                Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                Type::Option(_) => unimplemented!(\"nested options? that's weird\"),\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    _ => unimplemented!(\"a little too much nesting. bailing out.\"),\n+                },\n+            },\n+            Type::Reference(_, ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type) => match **first_type {\n+                Type::TypePath(_) => None,\n+                Type::Reference(_, ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type)\n+                | Type::Option(ref second_type) => match **second_type {\n+                    Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                    Type::Reference(_, ref third_type) => match **third_type {\n+                        Type::TypePath(_) => Some(optional_definition_levels(ident)),\n+                        _ => unimplemented!(\n+                            \"we don't do some more complex definition levels... yet!\"\n+                        ),\n+                    },\n+                    _ => unimplemented!(\n+                        \"we don't do more complex definition levels... yet!\"\n+                    ),\n+                },\n+            },\n+        };\n+\n+        let write_batch_expr = if definition_levels.is_some() {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], Some(&definition_levels[..]), None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        } else {\n+            quote! {\n+                if let #column_writer(ref mut typed) = column_writer {\n+                    typed.write_batch(&vals[..], None, None).unwrap();\n+                } else {\n+                    panic!(\"schema and struct disagree on type for {}\", stringify!{#ident})\n+                }\n+            }\n+        };\n+\n+        quote! {\n+            {\n+                #definition_levels\n+\n+                #vals_builder\n+\n+                #write_batch_expr\n+            }\n+        }\n+    }\n+}\n+\n+#[derive(Debug, PartialEq)]\n+pub enum Type {\n+    Array(Box<Type>),\n+    Option(Box<Type>),\n+    Vec(Box<Type>),\n+    TypePath(syn::Type),\n+    Reference(Option<syn::Lifetime>, Box<Type>),\n+}\n+\n+impl Type {\n+    pub fn column_writer(&self) -> syn::TypePath {\n+        use parquet::basic::Type as BasicType;\n+\n+        let path = match self.physical_type() {\n+            BasicType::BOOLEAN => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::BoolColumnWriter\")\n+            }\n+            BasicType::INT32 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int32ColumnWriter\")\n+            }\n+            BasicType::INT64 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int64ColumnWriter\")\n+            }\n+            BasicType::INT96 => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::Int96ColumnWriter\")\n+            }\n+            BasicType::FLOAT => {\n+                syn::parse_str(\"parquet::column::writer::ColumnWriter::FloatColumnWriter\")\n+            }\n+            BasicType::DOUBLE => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::DoubleColumnWriter\",\n+            ),\n+            BasicType::BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::ByteArrayColumnWriter\",\n+            ),\n+            BasicType::FIXED_LEN_BYTE_ARRAY => syn::parse_str(\n+                \"parquet::column::writer::ColumnWriter::FixedLenByteArrayColumnWriter\",\n+            ),\n+        };\n+        path.unwrap()\n+    }\n+\n+    fn inner_type(&self) -> &syn::Type {\n+        let leaf_type = self.leaf_type();\n+\n+        match leaf_type {\n+            Type::TypePath(ref type_) => type_,\n+            Type::Option(ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type)\n+            | Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(ref type_) => type_,\n+                _ => unimplemented!(\"leaf_type() should only return shallow types\"),\n+            },\n+        }\n+    }\n+\n+    pub fn leaf_type(&self) -> &Type {\n+        match &self {\n+            Type::TypePath(_) => &self,\n+            Type::Option(ref first_type)\n+            | Type::Vec(ref first_type)\n+            | Type::Array(ref first_type)\n+            | Type::Reference(_, ref first_type) => match **first_type {\n+                Type::TypePath(_) => &self,\n+                Type::Option(ref second_type)\n+                | Type::Vec(ref second_type)\n+                | Type::Array(ref second_type)\n+                | Type::Reference(_, ref second_type) => match **second_type {\n+                    Type::TypePath(_) => first_type,\n+                    Type::Option(ref third_type)\n+                    | Type::Vec(ref third_type)\n+                    | Type::Array(ref third_type)\n+                    | Type::Reference(_, ref third_type) => match **third_type {\n+                        Type::TypePath(_) => second_type,\n+                        Type::Option(ref fourth_type)\n+                        | Type::Vec(ref fourth_type)\n+                        | Type::Array(ref fourth_type)\n+                        | Type::Reference(_, ref fourth_type) => match **fourth_type {\n+                            Type::TypePath(_) => third_type,\n+                            _ => unimplemented!(\"sorry, I don't descend this far\"),\n+                        },\n+                    },\n+                },\n+            },\n+        }\n+    }\n+\n+    pub fn last_part(&self) -> String {\n+        let inner_type = self.inner_type();\n+        let inner_type_str = (quote! { #inner_type }).to_string();\n+\n+        inner_type_str.split(\"::\").last().unwrap().trim().to_string()\n+    }\n+\n+    pub fn physical_type(&self) -> parquet::basic::Type {\n+        use parquet::basic::Type as BasicType;\n+\n+        let last_part = self.last_part();\n+        let leaf_type = self.leaf_type();\n+\n+        match leaf_type {\n+            Type::Array(ref first_type) => {\n+                if let Type::TypePath(_) = **first_type {\n+                    if last_part == \"u8\" {\n+                        return BasicType::FIXED_LEN_BYTE_ARRAY;\n+                    }\n+                }\n+            }\n+            Type::Vec(ref first_type) => {\n+                if let Type::TypePath(_) = **first_type {\n+                    if last_part == \"u8\" {\n+                        return BasicType::BYTE_ARRAY;\n+                    }\n+                }\n+            }\n+            _ => (),\n+        }\n+\n+        match last_part.trim() {\n+            \"bool\" => BasicType::BOOLEAN,\n+            \"u8\" | \"u16\" | \"u32\" => BasicType::INT32,\n+            \"i8\" | \"i16\" | \"i32\" => BasicType::INT32,\n+            \"u64\" | \"i64\" | \"usize\" | \"NaiveDateTime\" => BasicType::INT64,\n+            \"f32\" => BasicType::FLOAT,\n+            \"f64\" => BasicType::DOUBLE,\n+            \"String\" | \"str\" => BasicType::BYTE_ARRAY,\n+            f @ _ => unimplemented!(\"sorry, don't handle {} yet!\", f),\n+        }\n+    }\n+\n+    pub fn from_type_path(f: &syn::Field, p: &syn::TypePath) -> Self {\n+        let segments_iter = p.path.segments.iter();\n+        let segments: Vec<syn::PathSegment> = segments_iter.map(|x| x.clone()).collect();\n+        let last_segment = segments.last().unwrap();\n+\n+        let is_vec =\n+            last_segment.ident == syn::Ident::new(\"Vec\", proc_macro2::Span::call_site());\n+        let is_option = last_segment.ident\n+            == syn::Ident::new(\"Option\", proc_macro2::Span::call_site());\n+\n+        if is_vec || is_option {\n+            let generic_type = match &last_segment.arguments {\n+                syn::PathArguments::AngleBracketed(angle_args) => {\n+                    let mut gen_args_iter = angle_args.args.iter();\n+                    let first_arg = gen_args_iter.next().unwrap();\n+                    assert!(gen_args_iter.next().is_none());\n+\n+                    match first_arg {\n+                        syn::GenericArgument::Type(ref typath) => typath.clone(),\n+                        other @ _ => unimplemented!(\"don't know {:#?}\", other),\n+                    }\n+                }\n+                other @ _ => unimplemented!(\"don't know: {:#?}\", other),\n+            };\n+\n+            if is_vec {\n+                Type::Vec(Box::new(Type::from_type(f, &generic_type)))\n+            } else {\n+                Type::Option(Box::new(Type::from_type(f, &generic_type)))\n+            }\n+        } else {\n+            Type::TypePath(syn::Type::Path(p.clone()))\n+        }\n+    }\n+\n+    pub fn from_type_reference(f: &syn::Field, tr: &syn::TypeReference) -> Self {\n \n Review comment:\n   Can these `from_type_XXX` be private methods?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.032+0000",
                    "updated": "2019-04-15T06:18:12.032+0000",
                    "started": "2019-04-15T06:18:12.032+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227466",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227467",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275175857\n \n \n\n ##########\n File path: rust/parquet_derive/src/lib.rs\n ##########\n @@ -0,0 +1,88 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#![recursion_limit = \"128\"]\n+\n+extern crate proc_macro;\n+extern crate proc_macro2;\n+extern crate syn;\n+#[macro_use]\n+extern crate quote;\n+\n+extern crate parquet;\n+\n+use syn::{parse_macro_input, Data, DataStruct, DeriveInput};\n+\n+mod parquet_field;\n+\n+/// Derive flat, simple RecordWriter implementations. Works by parsing\n+/// a struct tagged with `#[derive(ParquetRecordWriter)]` and emitting\n+/// the correct writing code for each field of the struct, in\n+/// the order fields are defined.\n+///\n+/// It is up to the programmer to keep the order of the struct\n+/// fields lined up with the schema.\n+///\n+/// Example:\n+///\n+/// ```ignore\n+/// use parquet;\n+/// use parquet::record::RecordWriter;\n+//\n+/// #[derive(ParquetRecordWriter)]\n+/// struct ACompleteRecord<'a> {\n+///   pub a_bool: bool,\n+///   pub a_str: &'a str,\n+/// }\n+/// ```\n+///\n+#[proc_macro_derive(ParquetRecordWriter)]\n+pub fn parquet_record_writer(input: proc_macro::TokenStream) -> proc_macro::TokenStream {\n+    let input: DeriveInput = parse_macro_input!(input as DeriveInput);\n+    let fields = match input.data {\n+        Data::Struct(DataStruct { fields, .. }) => fields,\n+        Data::Enum(_) => unimplemented!(\"don't support enum\"),\n+        Data::Union(_) => unimplemented!(\"don't support union\"),\n+    };\n+\n+    let field_infos: Vec<_> = fields\n+        .iter()\n+        .map(|f: &syn::Field| parquet_field::Field::from(f))\n+        .collect();\n+\n+    let writer_snippets: Vec<proc_macro2::TokenStream> =\n+        field_infos.iter().map(|x| x.writer_snippet()).collect();\n+\n+    let derived_for = input.ident;\n+    let generics = input.generics;\n+\n+    (quote! {\n+    impl#generics RecordWriter<#derived_for#generics> for &[#derived_for#generics] {\n+      fn write_to_row_group(&self, row_group_writer: &mut Box<parquet::file::writer::RowGroupWriter>) {\n+        let mut row_group_writer = row_group_writer;\n+        let records = &self;\n \n Review comment:\n   nit: is this needed? `records` is not used anywhere. Same for `row_group_writer` in the line above.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.035+0000",
                    "updated": "2019-04-15T06:18:12.035+0000",
                    "started": "2019-04-15T06:18:12.034+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227467",
                    "issueId": "13226289"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/worklog/227468",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "sunchao commented on pull request #4140: ARROW-5123: [Rust] Parquet derive for simple structs\nURL: https://github.com/apache/arrow/pull/4140#discussion_r275176254\n \n \n\n ##########\n File path: rust/parquet_derive/src/parquet_field.rs\n ##########\n @@ -0,0 +1,790 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#[derive(Debug, PartialEq)]\n+pub struct Field {\n+    ident: syn::Ident,\n+    ty: Type,\n+}\n+\n+impl Field {\n+    pub fn from(f: &syn::Field) -> Self {\n+        Field {\n+            ident: f\n+                .ident\n+                .clone()\n+                .expect(\"we only support structs with named fields\"),\n+            ty: Type::from(f),\n+        }\n+    }\n+\n+    /// Takes the parsed field of the struct and emits a valid\n+    /// column writer snippet.\n+    ///\n+    /// Can only generate writers for basic structs, for example:\n+    ///\n+    /// struct Record {\n+    ///   a_bool: bool,\n+    ///   maybe_a_bool: Option<bool>\n+    /// }\n+    ///\n+    /// but not\n+    ///\n+    /// struct UnsupportedNestedRecord {\n+    ///   a_property: bool,\n+    ///   nested_record: Record\n+    /// }\n+    ///\n+    /// because this parsing logic is not sophisticated enough for definition\n+    /// levels beyond 2.\n+    pub fn writer_snippet(&self) -> proc_macro2::TokenStream {\n+        let ident = &self.ident;\n+        let column_writer = self.ty.column_writer();\n+        let is_a_byte_buf = self.ty.physical_type() == parquet::basic::Type::BYTE_ARRAY;\n \n Review comment:\n   Can we make these as fields for the `Field` struct? so we don't have to pass them as parameters in `writer_snippet` and `copied_into_vals`.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-15T06:18:12.042+0000",
                    "updated": "2019-04-15T06:18:12.042+0000",
                    "started": "2019-04-15T06:18:12.041+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "227468",
                    "issueId": "13226289"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": 52200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2dd917e8[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@64515fbd[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@73321781[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@1df012ed[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5e87e86f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@410e91b3[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@22e3180c[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@3f9911c7[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5ebc52cb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@6b8ad3a6[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@511395a3[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@2673a16f[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 52200,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Sep 14 11:50:35 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-09-14T11:49:53.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-5123/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2019-04-05T01:38:24.000+0000",
        "updated": "2020-09-14T11:53:39.000+0000",
        "timeoriginalestimate": null,
        "description": "Migrated from previous github issue (which saw a lot of comments but at a rough transition time in the project): https://github.com/sunchao/parquet-rs/pull/197\r\n\r\n\u00a0\r\n\r\nGoal\r\n\r\n===\r\n\r\nWriting many columns to a file is a chore. If you can put your values in to a struct which mirrors the schema of your file, this `derive(ParquetRecordWriter)` will write out all the fields, in the order in which they are defined, to a row_group.\r\n\r\nHow to Use\r\n===\r\n\r\n```\r\nextern crate parquet;\r\n#[macro_use] extern crate parquet_derive;\r\n\r\n#[derive(ParquetRecordWriter)]\r\nstruct ACompleteRecord<'a> {\r\n\u00a0 pub a_bool: bool,\r\n\u00a0 pub a_str: &'a str,\r\n}\r\n```\r\n\r\nRecordWriter trait\r\n===\r\n\r\nThis is the new trait which `parquet_derive` will implement for your structs.\r\n\r\n```\r\nuse super::RowGroupWriter;\r\n\r\npub trait RecordWriter<T> {\r\n\u00a0 fn write_to_row_group(&self, row_group_writer: &mut Box<RowGroupWriter>);\r\n}\r\n```\r\n\r\nHow does it work?\r\n===\r\n\r\nThe `parquet_derive` crate adds code generating functionality to the rust compiler. The code generation takes rust syntax and emits additional syntax. This macro expansion works on rust 1.15+ stable. This is a dynamic plugin, loaded by the machinery in cargo. Users don't have to do any special `build.rs` steps or anything like that, it's automatic by including `parquet_derive` in their project. The `parquet_derive/src/Cargo.toml` has a section saying as much:\r\n\r\n```\r\n[lib]\r\nproc-macro = true\r\n```\r\n\r\nThe rust struct tagged with `#[derive(ParquetRecordWriter)]` is provided to the `parquet_record_writer` function in `parquet_derive/src/lib.rs`. The `syn` crate parses the struct from a string-representation to a AST (a recursive enum value). The AST contains all the values I care about when generating a `RecordWriter` impl:\r\n\r\n\u00a0- the name of the struct\r\n\u00a0- the lifetime variables of the struct\r\n\u00a0- the fields of the struct\r\n\r\nThe fields of the struct are translated from AST to a flat `FieldInfo` struct. It has the bits I care about for writing a column: `field_name`, `field_lifetime`, `field_type`, `is_option`, `column_writer_variant`.\r\n\r\nThe code then does the equivalent of templating to build the `RecordWriter` implementation. The templating functionality is provided by the `quote` crate. At a high-level the template for `RecordWriter` looks like:\r\n\r\n```\r\nimpl RecordWriter for $struct_name {\r\n\u00a0 fn write_row_group(..) {\r\n\u00a0\u00a0\u00a0 $({\r\n\u00a0\u00a0\u00a0\u00a0\u00a0 $column_writer_snippet\r\n\u00a0\u00a0\u00a0 })\r\n\u00a0 } \r\n}\r\n```\r\n\r\nthis template is then added under the struct definition, ending up something like:\r\n\r\n```\r\nstruct MyStruct {\r\n}\r\nimpl RecordWriter for MyStruct {\r\n\u00a0 fn write_row_group(..) {\r\n\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 write_col_1();\r\n\u00a0\u00a0\u00a0 };\r\n\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 write_col_2();\r\n\u00a0\u00a0 }\r\n\u00a0 }\r\n}\r\n```\r\n\r\nand finally _THIS_ is the code passed to rustc. It's just code now, fully expanded and standalone. If a user ever changes their `struct MyValue` definition the `ParquetRecordWriter` will be regenerated. There's no intermediate values to version control or worry about.\r\n\r\nViewing the Derived Code\r\n===\r\n\r\nTo see the generated code before it's compiled, one very useful bit is to install `cargo expand` [more info on gh](https://github.com/dtolnay/cargo-expand), then you can do:\r\n\r\n```\r\n$WORK_DIR/parquet-rs/parquet_derive_test\r\ncargo expand --lib > ../temp.rs\r\n```\r\n\r\nthen you can dump the contents:\r\n\r\n```\r\nstruct DumbRecord {\r\n\u00a0\u00a0\u00a0 pub a_bool: bool,\r\n\u00a0\u00a0\u00a0 pub a2_bool: bool,\r\n}\r\nimpl RecordWriter<DumbRecord> for &[DumbRecord] {\r\n\u00a0\u00a0\u00a0 fn write_to_row_group(\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 &self,\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 row_group_writer: &mut Box<parquet::file::writer::RowGroupWriter>,\r\n\u00a0\u00a0\u00a0 ) {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let mut row_group_writer = row_group_writer;\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let vals: Vec<bool> = self.iter().map(|x| x.a_bool).collect();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let mut column_writer = row_group_writer.next_column().unwrap().unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 column_writer\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 typed.write_batch(&vals[..], None, None).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 row_group_writer.close_column(column_writer).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 };\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let vals: Vec<bool> = self.iter().map(|x| x.a2_bool).collect();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 let mut column_writer = row_group_writer.next_column().unwrap().unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 column_writer\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 {\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 typed.write_batch(&vals[..], None, None).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 row_group_writer.close_column(column_writer).unwrap();\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\r\n\u00a0\u00a0\u00a0 }\r\n}\r\n```\r\n\r\nnow I need to write out all the combinations of types we support and make sure it writes out data.\r\n\r\nProcedural Macros\r\n===\r\n\r\nThe `parquet_derive` crate can ONLY export the derivation functionality. No traits, nothing else. The derive crate can not host test cases. It's kind of like a \"dummy\" crate which is only used by the compiler, never the code.\r\n\r\nThe parent crate cannot use the derivation functionality, which is important because it means test code cannot be in the parent crate. This forces us to have a third crate, `parquet_derive_test`.\r\n\r\nI'm open to being wrong on any one of these finer points. I had to bang on this for a while to get it to compile!\r\n\r\nPotentials For Better Design\r\n===\r\n\r\n\u00a0- [x] Recursion could be limited by generating the code as \"snippets\" instead of one big `quote!` AST generator. Or so I think. It might be nicer to push generating each columns writing code to another loop.\r\n\u00a0- [X] ~~It would be nicer if I didn't have to be so picky about data going in to the `write_batch` function. Is it possible we could make a version of the function which accept `Into<DataType>` or similar? This would greatly simplify this derivation code as it would not need to enumerate all the supported types. Something like `write_generic_batch(&[impl Into<DataType>])` would be neat.~~ (not tackling in this generation of the plugin)\r\n\u00a0- [X] ~~Another idea to improving writing columns, could we have a write function for `Iterator`s? I already have a `Vec<DumbRecord>`, if I could just write a mapping for accessing the one value, we could skip the whole intermediate vec for `write_batch`. Should have some significant memory advantages.~~ (not tackling in this generation of the plugin, it's a bigger parquet-rs enhancement)\r\n\u00a0- [X] ~~It might be worthwhile to derive a parquet schema directly from a struct definition. That should stamp out opportunities for type errors.~~ (moved to #203)\r\n\r\nStatus\r\n===\r\n\r\nI have successfully integrated this work with my own data exporter (takes postgres/couchdb and outputs a single parquet file).\r\n\r\nI think this code is worth including in the project, with the caveat that it only generates simplistic `RecordWriter`s. As people start to use we can add code generation for more complex, nested structs.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "14.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 52200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Rust] derive RecordWriter from struct definitions",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/comment/17195405",
                    "id": "17195405",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=nevi_me",
                        "name": "nevi_me",
                        "key": "nevi_me",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=nevi_me&avatarId=24271",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=nevi_me&avatarId=24271",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=nevi_me&avatarId=24271",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=nevi_me&avatarId=24271"
                        },
                        "displayName": "Neville Dipale",
                        "active": true,
                        "timeZone": "Africa/Johannesburg"
                    },
                    "body": "Issue resolved by pull request 4140\n[https://github.com/apache/arrow/pull/4140]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=nevi_me",
                        "name": "nevi_me",
                        "key": "nevi_me",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=nevi_me&avatarId=24271",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=nevi_me&avatarId=24271",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=nevi_me&avatarId=24271",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=nevi_me&avatarId=24271"
                        },
                        "displayName": "Neville Dipale",
                        "active": true,
                        "timeZone": "Africa/Johannesburg"
                    },
                    "created": "2020-09-14T11:49:53.516+0000",
                    "updated": "2020-09-14T11:49:53.516+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13226289/comment/17195410",
                    "id": "17195410",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=nevi_me",
                        "name": "nevi_me",
                        "key": "nevi_me",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=nevi_me&avatarId=24271",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=nevi_me&avatarId=24271",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=nevi_me&avatarId=24271",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=nevi_me&avatarId=24271"
                        },
                        "displayName": "Neville Dipale",
                        "active": true,
                        "timeZone": "Africa/Johannesburg"
                    },
                    "body": "I'm unable to assign to Xavier",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=nevi_me",
                        "name": "nevi_me",
                        "key": "nevi_me",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=nevi_me&avatarId=24271",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=nevi_me&avatarId=24271",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=nevi_me&avatarId=24271",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=nevi_me&avatarId=24271"
                        },
                        "displayName": "Neville Dipale",
                        "active": true,
                        "timeZone": "Africa/Johannesburg"
                    },
                    "created": "2020-09-14T11:50:35.459+0000",
                    "updated": "2020-09-14T11:50:35.459+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z01hk0:",
        "customfield_12314139": null
    }
}