{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13110997",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997",
    "key": "ARROW-1693",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341352",
                "id": "12341352",
                "name": "0.8.0",
                "archived": false,
                "released": true,
                "releaseDate": "2017-12-18"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "3.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12518092",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12518092",
                "type": {
                    "id": "10032",
                    "name": "Blocker",
                    "inward": "is blocked by",
                    "outward": "blocks",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"
                },
                "outwardIssue": {
                    "id": "13100945",
                    "key": "ARROW-1501",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13100945",
                    "fields": {
                        "summary": "[JS] JavaScript integration tests",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12518119",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12518119",
                "type": {
                    "id": "12310010",
                    "name": "Incorporates",
                    "inward": "is part of",
                    "outward": "incorporates",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310010"
                },
                "outwardIssue": {
                    "id": "13111085",
                    "key": "ARROW-1698",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13111085",
                    "fields": {
                        "summary": "[JS] File reader attempts to load the same dictionary batch more than once",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12519718",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12519718",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13117385",
                    "key": "ARROW-1785",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117385",
                    "fields": {
                        "summary": "[Format/C++/Java] Remove VectorLayout metadata from Flatbuffers metadata",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=paul.e.taylor",
            "name": "paul.e.taylor",
            "key": "paul.e.taylor",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Paul Taylor",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12332552",
                "id": "12332552",
                "name": "JavaScript"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
            "name": "bhulette",
            "key": "bhulette",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Brian Hulette",
            "active": true,
            "timeZone": "America/Vancouver"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
            "name": "bhulette",
            "key": "bhulette",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Brian Hulette",
            "active": true,
            "timeZone": "America/Vancouver"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1693/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "id": "1",
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "name": "Bug",
            "subtask": false,
            "avatarId": 21133
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@1f18bc17[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@680b1aff[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5408ce57[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@6464facb[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2b8597c9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@746c9f13[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@66049dbf[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@25758116[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@22c971ae[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@324de6e3[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@70e66c70[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@79922e4b[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Nov 20 19:32:29 UTC 2017",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2017-11-20T14:23:05.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1693/watchers",
            "watchCount": 5,
            "isWatching": false
        },
        "created": "2017-10-20T14:22:01.000+0000",
        "updated": "2017-11-20T19:32:29.000+0000",
        "timeoriginalestimate": null,
        "description": "The JS implementation crashes when reading the dictionary test case from the integration tests.\r\n\r\nTo replicate, first generate the test files with java and cpp impls:\r\n{code}\r\n$ cd ${ARROW_HOME}/integration/\r\n$ python -c 'from integration_test import generate_dictionary_case; generate_dictionary_case().write(\"dictionary.json\")'\r\n$ ../cpp/debug/debug/json-integration-test --integration --json=dictionary.json --arrow=dictionary-cpp.arrow --mode=JSON_TO_ARROW\r\n$ java -cp ../java/tools/target/arrow-tools-0.8.0-SNAPSHOT-jar-with-dependencies.jar org.apache.arrow.tools.Integration -c JSON_TO_ARROW -a dictionary-java.arrow -j dictionary.json\r\n{code}\r\n\r\nAttempt to read the files with the JS impl:\r\n{code}\r\n$ cd ${ARROW_HOME}/js/\r\n$ ./bin/arrow2csv.js -s dict1_0 -f ../integration/dictionary-{java,cpp}.arrow\r\n{code}\r\n\r\nBoth files result in an error for me on [a8f51858|https://github.com/apache/arrow/commit/a8f518588fda471b2e3cc8e0f0064e7c4bb99899]:\r\n{{TypeError: Cannot read property 'buffer' of undefined}}",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/attachment/12893272",
                "id": "12893272",
                "filename": "dictionary.json",
                "author": {
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                    "name": "bhulette",
                    "key": "bhulette",
                    "avatarUrls": {
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                        "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                        "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                    },
                    "displayName": "Brian Hulette",
                    "active": true,
                    "timeZone": "America/Vancouver"
                },
                "created": "2017-10-20T14:21:48.304+0000",
                "size": 8025,
                "mimeType": "application/json",
                "content": "https://issues.apache.org/jira/secure/attachment/12893272/dictionary.json"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/attachment/12893271",
                "id": "12893271",
                "filename": "dictionary-cpp.arrow",
                "author": {
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                    "name": "bhulette",
                    "key": "bhulette",
                    "avatarUrls": {
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                        "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                        "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                    },
                    "displayName": "Brian Hulette",
                    "active": true,
                    "timeZone": "America/Vancouver"
                },
                "created": "2017-10-20T14:21:48.314+0000",
                "size": 2682,
                "mimeType": "application/octet-stream",
                "content": "https://issues.apache.org/jira/secure/attachment/12893271/dictionary-cpp.arrow"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/attachment/12893270",
                "id": "12893270",
                "filename": "dictionary-java.arrow",
                "author": {
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                    "name": "bhulette",
                    "key": "bhulette",
                    "avatarUrls": {
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                        "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                        "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                    },
                    "displayName": "Brian Hulette",
                    "active": true,
                    "timeZone": "America/Vancouver"
                },
                "created": "2017-10-20T14:21:48.341+0000",
                "size": 2802,
                "mimeType": "application/octet-stream",
                "content": "https://issues.apache.org/jira/secure/attachment/12893270/dictionary-java.arrow"
            }
        ],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[JS] Error reading dictionary-encoded integration test files",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16212697",
                    "id": "16212697",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                        "name": "bhulette",
                        "key": "bhulette",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Brian Hulette",
                        "active": true,
                        "timeZone": "America/Vancouver"
                    },
                    "body": "Pretty sure this is related to the vector layout representing the index vs. the dictionary data",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                        "name": "bhulette",
                        "key": "bhulette",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Brian Hulette",
                        "active": true,
                        "timeZone": "America/Vancouver"
                    },
                    "created": "2017-10-20T14:22:56.032+0000",
                    "updated": "2017-10-20T14:22:56.032+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16212893",
                    "id": "16212893",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "This was fixed in the C++ implementation in ARROW-1363 https://github.com/apache/arrow/commit/0ced74e1e39587c0ee10ac5979fefbaac97446f5",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-10-20T17:03:53.598+0000",
                    "updated": "2017-10-20T17:03:59.408+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16213165",
                    "id": "16213165",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                        "name": "bhulette",
                        "key": "bhulette",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Brian Hulette",
                        "active": true,
                        "timeZone": "America/Vancouver"
                    },
                    "body": "ARROW-1698 is only part of the problem. After fixing that bug, we can successfully read dictionary-java.arrow, but not dictionary-cpp.arrow. It looks like there's actually a difference in the schema between these two files: dictionary-java.arrow has 3 items in dict1_0's buffer layout (validity, offset, data - reflects the value type), but dictionary-cpp.arrow has 2 (validity, data - reflects the index type).\r\n\r\n[~wesmckinn] Is this a bug in the java writer?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                        "name": "bhulette",
                        "key": "bhulette",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Brian Hulette",
                        "active": true,
                        "timeZone": "America/Vancouver"
                    },
                    "created": "2017-10-20T20:16:40.292+0000",
                    "updated": "2017-10-20T20:16:40.292+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16213199",
                    "id": "16213199",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "That's interesting. I'm surprised that the integration tests work -- it must be that Java is not using the buffer layout information. Frankly, having the JS reader be so sensitive to the buffer layout is a source of brittleness. We do not use this data in C++, it is there for informational purposes. \r\n\r\nBecause the buffer structure of record batches will contain only the indexes, I think using the index buffer layout is the \"right\" answer, though nowhere are we encoding the buffer layout for the dictionary values. So this is a deficiency in the Arrow format that we may contemplate fixing. ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-10-20T20:40:25.742+0000",
                    "updated": "2017-10-20T20:40:35.001+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16213247",
                    "id": "16213247",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=paul.e.taylor",
                        "name": "paul.e.taylor",
                        "key": "paul.e.taylor",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Paul Taylor",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "[~bhulette] thanks I can dig into this too. FYI there's a workaround for Dictionary vectors written before ARROW-1363 was fixed [here|https://github.com/apache/arrow/blob/a8f518588fda471b2e3cc8e0f0064e7c4bb99899/js/src/reader/vector.ts#L64] and [here|https://github.com/apache/arrow/blob/a8f518588fda471b2e3cc8e0f0064e7c4bb99899/js/src/reader/vector.ts#L108].\r\n\r\nIf the Java writer encodes a data buffer that isn't the offsets, that totally invalidates this assumption in the comment under line 108:\r\n\r\n{quote}\r\n...if we're parsing an Arrow file written by a version of the library published before ARROW-1363 was fixed, the IntVector's data buffer will be null, and the offset buffer will be the actual data. If data is null, it's safe to assume the offset buffer is the data, because IntVectors don't have offsets.\r\n{quote}",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=paul.e.taylor",
                        "name": "paul.e.taylor",
                        "key": "paul.e.taylor",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Paul Taylor",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2017-10-20T21:09:41.131+0000",
                    "updated": "2017-10-20T21:10:02.134+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16213275",
                    "id": "16213275",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                        "name": "bhulette",
                        "key": "bhulette",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Brian Hulette",
                        "active": true,
                        "timeZone": "America/Vancouver"
                    },
                    "body": "[~paul.e.taylor] feel free to dig into this, I'm wrapping up the ARROW-1698 PR and then I probably won't get to it any more over the weekend.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bhulette",
                        "name": "bhulette",
                        "key": "bhulette",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Brian Hulette",
                        "active": true,
                        "timeZone": "America/Vancouver"
                    },
                    "created": "2017-10-20T21:29:45.842+0000",
                    "updated": "2017-10-20T21:29:45.842+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16236855",
                    "id": "16236855",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=paul.e.taylor",
                        "name": "paul.e.taylor",
                        "key": "paul.e.taylor",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Paul Taylor",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "[~wesmckinn] digging into this now, yeah it looks like the the DictionaryBatch UTF8Vector field layout doesn't include the offsets buffer. Sounds like I should get those integration tests up and running.\r\n\r\nI wanna offer some push back on your comment about brittleness though. Maybe I'm alone on this, but seems like a cross-platform ipc format should strictly enforce its own spec -- anything less and end up with a bunch of maybe-compatible implementations, right?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=paul.e.taylor",
                        "name": "paul.e.taylor",
                        "key": "paul.e.taylor",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Paul Taylor",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2017-11-03T00:05:03.295+0000",
                    "updated": "2017-11-03T00:05:20.304+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16236902",
                    "id": "16236902",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I think the idea of including the buffer layouts was hypothetically to permit an implementation to, say, omit the validity bitmap buffer without consequences. In practice, both the Java and C++ implementations are presuming to be sent the same buffer layout that the emit -- i.e. with the buffers in same order (so in the case of strings, you would have validity, offsets, then data). But validating our presumptions is useful. So what we probably need to do is implement buffer layout validation in both Java and C++ so that we can assert that a sender has prepared the buffers in the way that are supported. I was wrong to call the JS implementation \"brittle\" in this regard, really it's that the more rigorous checking exposed bugs in the other implementations",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-11-03T00:57:15.598+0000",
                    "updated": "2017-11-03T00:57:15.598+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16236908",
                    "id": "16236908",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "See ARROW-1362",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-11-03T01:00:04.720+0000",
                    "updated": "2017-11-03T01:00:04.720+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16244812",
                    "id": "16244812",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jnadeau",
                        "name": "jnadeau",
                        "key": "jnadeau",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jacques Nadeau",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "I actually think having the vector layout was a mistake. I think we should remove it. It is a constant that is defined by the spec. We actually implemented an alternative representation internally where we skip inclusion of it because we don't want to send around information that is useless (and can be fairly substantial when talking about five record, several thousand field datasets).",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jnadeau",
                        "name": "jnadeau",
                        "key": "jnadeau",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jacques Nadeau",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2017-11-08T22:08:36.800+0000",
                    "updated": "2017-11-08T22:08:36.800+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16245180",
                    "id": "16245180",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt opened a new pull request #1294: WIP ARROW-1693: Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294\n \n \n   This PR adds a workaround for reading the metadata layout for C++ dictionary-encoded vectors.\r\n   \r\n   I added tests that validate against the C++/Java integration suite. In order to make the new tests pass, I had to update the generated flatbuffers format and add a few types the JS version didn't have yet (Bool, Date32, and Timestamp). It also uses the new `isDelta` flag on DictionaryBatches to determine whether the DictionaryBatch vector should replace or append to the existing dictionary.\r\n   \r\n   I also added a script for generating test arrow files from the C++ and Java implementations, so we don't break the tests updating the format in the future. I saved the generated Arrow files in with the tests because I didn't see a way to pipe the JSON test data through the C++/Java json-to-arrow commands without writing to a file. If I missed something and we can do it all in-memory, I'd be happy to make that change!\r\n   \r\n   This PR is marked WIP because I added an [integration test](https://github.com/apache/arrow/commit/6e98874d9f4bfae7758f8f731212ae7ceb3f1321#diff-18c6be12406c482092d4b1f7bd70a8e1R22) that validates the JS reader reads C++ and Java files the same way, but unfortunately it doesn't. Debugging, I noticed a number of other differences between the buffer layout metadata between the C++ and Java versions. If we go ahead with @jacques-n [comment in ARROW-1693](https://issues.apache.org/jira/browse/ARROW-1693?focusedCommentId=16244812&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16244812) and remove/ignore the metadata, this test should pass too.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-09T04:20:19.963+0000",
                    "updated": "2017-11-09T04:20:19.963+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16246435",
                    "id": "16246435",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors (WIP)\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-343277677\n \n \n   Want to go ahead and ignore the vector layout metadata? Per ARROW-1785. I will wait a day or so for further feedback to circulate, then proceed with a removal of this metadata. We'll need to update the Flatbuffers files in JS again as part of this, I will give you write access on my fork so you can push directly to the PR branch as needed\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-09T20:13:52.817+0000",
                    "updated": "2017-11-09T20:13:52.817+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16246481",
                    "id": "16246481",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors (WIP)\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-343284914\n \n \n   @wesm yep, working on this tonight. do you mind if I add to this PR vs starting a new branch?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-09T20:42:07.556+0000",
                    "updated": "2017-11-09T20:42:07.556+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16246518",
                    "id": "16246518",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors (WIP)\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-343290645\n \n \n   no problem, feel free to keep adding here. I will take a little time to review also\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-09T21:03:36.400+0000",
                    "updated": "2017-11-09T21:03:36.400+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16248920",
                    "id": "16248920",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors (WIP)\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-343752026\n \n \n   @wesm I believe this branch is ready. We should revalidate datetime and dictionary once we can get Pandas to generate a CSV from the test data. Even the [integration tests](https://github.com/trxcllnt/arrow/blob/64e318cec96345d71c4c1f08e028a14b5dd3dd3d/js/test/integration-tests.ts#L81) are finally passing, so I feel good about this one:\r\n   ```\r\n   Test Suites: 4 passed, 4 total\r\n   Tests:       404 passed, 404 total\r\n   Snapshots:   113940 passed, 113940 total\r\n   ```\r\n   \r\n   The last commit re-enables node_js job in travis so we can verify the above.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-12T17:14:08.691+0000",
                    "updated": "2017-11-12T17:14:08.691+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16248921",
                    "id": "16248921",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors (WIP)\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-343752026\n \n \n   @wesm I believe this branch is ready. We should revalidate datetime and dictionary once we can get Pandas to generate a CSV from the test data. The [integration tests](https://github.com/trxcllnt/arrow/blob/64e318cec96345d71c4c1f08e028a14b5dd3dd3d/js/test/integration-tests.ts#L81) are finally passing, so I feel good about this one:\r\n   ```\r\n   Test Suites: 4 passed, 4 total\r\n   Tests:       404 passed, 404 total\r\n   Snapshots:   113940 passed, 113940 total\r\n   ```\r\n   \r\n   The last commit re-enables node_js job in travis so we can verify the above.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-12T17:14:33.922+0000",
                    "updated": "2017-11-12T17:14:33.922+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16248969",
                    "id": "16248969",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-343760757\n \n \n   awesome, thanks @trxcllnt! I'm going to work through the patch to leave any comments that jump out but this is really exciting\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-12T19:28:53.621+0000",
                    "updated": "2017-11-12T19:28:53.621+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249118",
                    "id": "16249118",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150420344\n \n \n\n ##########\n File path: js/gulp/test-task.js\n ##########\n @@ -42,3 +54,78 @@ const testTask = ((cache, execArgv, testOptions) => memoizeTask(cache, function\n \n module.exports = testTask;\n module.exports.testTask = testTask;\n+module.exports.cleanTestData = cleanTestData;\n+module.exports.createTestData = createTestData;\n+\n+async function cleanTestData() {\n+    return await del([\n+        `${path.resolve('./test/arrows/cpp')}/**`,\n+        `${path.resolve('./test/arrows/java')}/**`,\n+    ]);\n+}\n+\n+async function createTestData() {\n+    const base = path.resolve('./test/arrows');\n+    await mkdirp(path.join(base, 'cpp/file'));\n+    await mkdirp(path.join(base, 'java/file'));\n+    await mkdirp(path.join(base, 'cpp/stream'));\n+    await mkdirp(path.join(base, 'java/stream'));\n+    const errors = [];\n+    const names = await glob(path.join(base, 'json/*.json'));\n+    for (let jsonPath of names) {\n+        const name = path.parse(path.basename(jsonPath)).name;\n+        const arrowCppFilePath = path.join(base, 'cpp/file', `${name}.arrow`);\n+        const arrowJavaFilePath = path.join(base, 'java/file', `${name}.arrow`);\n+        const arrowCppStreamPath = path.join(base, 'cpp/stream', `${name}.arrow`);\n+        const arrowJavaStreamPath = path.join(base, 'java/stream', `${name}.arrow`);\n+        try {\n+            await generateCPPFile(jsonPath, arrowCppFilePath);\n+            await generateCPPStream(arrowCppFilePath, arrowCppStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+        try {\n+            await generateJavaFile(jsonPath, arrowJavaFilePath);\n+            await generateJavaStream(arrowJavaFilePath, arrowJavaStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+    }\n+    if (errors.length) {\n+        console.error(errors.join(`\\n`));\n+        process.exit(1);\n+    }\n+}\n+\n+async function generateCPPFile(jsonPath, filePath) {\n+    await rimraf(filePath);\n+    return await exec(\n+        `../cpp/build/release/json-integration-test ${\n+        `--integration --mode=JSON_TO_ARROW`} ${\n+        `--json=${path.resolve(jsonPath)} --arrow=${filePath}`}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateCPPStream(filePath, streamPath) {\n+    await rimraf(streamPath);\n+    return await exec(\n+        `../cpp/build/release/file-to-stream ${filePath} > ${streamPath}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateJavaFile(jsonPath, filePath) {\n+    await rimraf(filePath);\n+    return await exec(\n+        `java -cp ../java/tools/target/arrow-tools-0.8.0-SNAPSHOT-jar-with-dependencies.jar ${\n+        `org.apache.arrow.tools.Integration -c JSON_TO_ARROW`} ${\n+        `-j ${path.resolve(jsonPath)} -a ${filePath}`}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateJavaStream(filePath, streamPath) {\n+    await rimraf(streamPath);\n+    return await exec(\n+        `java -cp ../java/tools/target/arrow-tools-0.8.0-SNAPSHOT-jar-with-dependencies.jar ${\n \n Review comment:\n   Can this version number here be gotten from the environment / pom file per chance?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T05:33:34.847+0000",
                    "updated": "2017-11-13T05:33:34.847+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249119",
                    "id": "16249119",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150448976\n \n \n\n ##########\n File path: js/src/reader/arrow.ts\n ##########\n @@ -15,64 +15,135 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+import { Vector } from '../vector/vector';\n import { flatbuffers } from 'flatbuffers';\n+import { readVector, readValueVector } from './vector';\n+import {\n+    readFileFooter, readFileMessages,\n+    readStreamSchema, readStreamMessages\n+} from './format';\n+\n+import * as File_ from '../format/File_generated';\n import * as Schema_ from '../format/Schema_generated';\n import * as Message_ from '../format/Message_generated';\n-export import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n-export import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n-\n-import { readFile } from './file';\n-import { readStream } from './stream';\n-import { readVector } from './vector';\n-import { readDictionary } from './dictionary';\n-import { Vector, Column } from '../types/types';\n \n import ByteBuffer = flatbuffers.ByteBuffer;\n+import Footer = File_.org.apache.arrow.flatbuf.Footer;\n import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-export type Dictionaries = { [k: string]: Vector<any> } | null;\n-export type IteratorState = { nodeIndex: number; bufferIndex: number };\n-\n-export function* readRecords(...bytes: ByteBuffer[]) {\n-    try {\n-        yield* readFile(...bytes);\n-    } catch (e) {\n-        try {\n-            yield* readStream(...bytes);\n-        } catch (e) {\n-            throw new Error('Invalid Arrow buffer');\n-        }\n+import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n+import Message = Message_.org.apache.arrow.flatbuf.Message;\n+import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n+import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n+import DictionaryBatch = Message_.org.apache.arrow.flatbuf.DictionaryBatch;\n+import DictionaryEncoding = Schema_.org.apache.arrow.flatbuf.DictionaryEncoding;\n+\n+export type ArrowReaderContext = {\n+    schema?: Schema;\n+    footer?: Footer | null;\n+    dictionaries: Map<string, Vector>;\n+    dictionaryEncodedFields: Map<string, Field>;\n+    readMessages: (bb: ByteBuffer, footer: Footer) => Iterable<Message>;\n+};\n+\n+export type VectorReaderContext = {\n+    node: number;\n+    buffer: number;\n+    offset: number;\n+    bytes: Uint8Array;\n+    batch: RecordBatch;\n+    dictionaries: Map<string, Vector>;\n+};\n+\n+export function* readVectors(buffers: Iterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n     }\n }\n \n-export function* readBuffers(...bytes: Array<Uint8Array | Buffer | string>) {\n-    const dictionaries: Dictionaries = {};\n-    const byteBuffers = bytes.map(toByteBuffer);\n-    for (let { schema, batch } of readRecords(...byteBuffers)) {\n-        let vectors: Column<any>[] = [];\n-        let state = { nodeIndex: 0, bufferIndex: 0 };\n-        let fieldsLength = schema.fieldsLength();\n-        let index = -1, field: Field, vector: Vector<any>;\n-        if (batch.id) {\n-            // A dictionary batch only contain a single vector. Traverse each\n-            // field and its children until we find one that uses this dictionary\n-            while (++index < fieldsLength) {\n-                if (field = schema.fields(index)!) {\n-                    if (vector = readDictionary<any>(field, batch, state, dictionaries)!) {\n-                        dictionaries[batch.id] = dictionaries[batch.id] && dictionaries[batch.id].concat(vector) || vector;\n-                        break;\n-                    }\n+export async function* readVectorsAsync(buffers: AsyncIterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for await (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n+    }\n+}\n+\n+function* readBuffer(bb: ByteBuffer, readerContext: ArrowReaderContext) {\n \n Review comment:\n   What do you recommend as a resource for getting up to speed on TypeScript? Where is the line between TypeScript and ES6? \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T05:33:34.876+0000",
                    "updated": "2017-11-13T05:33:34.876+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249120",
                    "id": "16249120",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150420450\n \n \n\n ##########\n File path: js/npm-release.sh\n ##########\n @@ -17,10 +17,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-npm run clean\n-npm run lint\n-npm run build\n-npm run test\n-npm --no-git-tag-version version patch &>/dev/null\n-npm run bundle\n-npm run lerna:publish\n\\ No newline at end of file\n+bump=${1:-patch} && echo \"semantic-version bump: $bump\"\n+\n+run-s --silent lint build test\n+lerna publish --yes --skip-git --cd-version $bump --force-publish=*\n \n Review comment:\n   Aside: what we're going to want to do for ASF release purposes: one script to produce a tarball of the JS project that is sufficient to publish to NPM after. Then a script in the tarball that can publish the project to NPM. So the ASF signed artifact that we upload to SVN will have everything that's needed to publish the project to NPM\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T05:33:34.877+0000",
                    "updated": "2017-11-13T05:33:34.877+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249121",
                    "id": "16249121",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150450626\n \n \n\n ##########\n File path: js/test/arrows/json/datetime.json\n ##########\n @@ -0,0 +1,1091 @@\n+{\n \n Review comment:\n   I'm not sure about checking in all these .json and .arrow files, is there some way we can automate their generation as part of the integration testing? Then they don't have to be modified when we expand the integration test suite\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T05:33:34.878+0000",
                    "updated": "2017-11-13T05:33:34.878+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249122",
                    "id": "16249122",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150420366\n \n \n\n ##########\n File path: js/gulp/test-task.js\n ##########\n @@ -42,3 +54,78 @@ const testTask = ((cache, execArgv, testOptions) => memoizeTask(cache, function\n \n module.exports = testTask;\n module.exports.testTask = testTask;\n+module.exports.cleanTestData = cleanTestData;\n+module.exports.createTestData = createTestData;\n+\n+async function cleanTestData() {\n+    return await del([\n+        `${path.resolve('./test/arrows/cpp')}/**`,\n+        `${path.resolve('./test/arrows/java')}/**`,\n+    ]);\n+}\n+\n+async function createTestData() {\n+    const base = path.resolve('./test/arrows');\n+    await mkdirp(path.join(base, 'cpp/file'));\n+    await mkdirp(path.join(base, 'java/file'));\n+    await mkdirp(path.join(base, 'cpp/stream'));\n+    await mkdirp(path.join(base, 'java/stream'));\n+    const errors = [];\n+    const names = await glob(path.join(base, 'json/*.json'));\n+    for (let jsonPath of names) {\n+        const name = path.parse(path.basename(jsonPath)).name;\n+        const arrowCppFilePath = path.join(base, 'cpp/file', `${name}.arrow`);\n+        const arrowJavaFilePath = path.join(base, 'java/file', `${name}.arrow`);\n+        const arrowCppStreamPath = path.join(base, 'cpp/stream', `${name}.arrow`);\n+        const arrowJavaStreamPath = path.join(base, 'java/stream', `${name}.arrow`);\n+        try {\n+            await generateCPPFile(jsonPath, arrowCppFilePath);\n+            await generateCPPStream(arrowCppFilePath, arrowCppStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+        try {\n+            await generateJavaFile(jsonPath, arrowJavaFilePath);\n+            await generateJavaStream(arrowJavaFilePath, arrowJavaStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+    }\n+    if (errors.length) {\n+        console.error(errors.join(`\\n`));\n+        process.exit(1);\n+    }\n+}\n+\n+async function generateCPPFile(jsonPath, filePath) {\n+    await rimraf(filePath);\n+    return await exec(\n+        `../cpp/build/release/json-integration-test ${\n+        `--integration --mode=JSON_TO_ARROW`} ${\n+        `--json=${path.resolve(jsonPath)} --arrow=${filePath}`}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateCPPStream(filePath, streamPath) {\n+    await rimraf(streamPath);\n+    return await exec(\n+        `../cpp/build/release/file-to-stream ${filePath} > ${streamPath}`,\n \n Review comment:\n   Simple way to make this file path more easily configurable / less hard-coded? \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T05:33:34.881+0000",
                    "updated": "2017-11-13T05:33:34.881+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249123",
                    "id": "16249123",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150451049\n \n \n\n ##########\n File path: js/test/integration-tests.ts\n ##########\n @@ -0,0 +1,114 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import Arrow from './Arrow';\n+import { zip } from 'ix/iterable/zip';\n+import { config, formats } from './test-config';\n+\n+const { Table, readVectors } = Arrow;\n+\n+expect.extend({\n+    toEqualVector(v1: any, v2: any) {\n+\n+        const format = (x: any, y: any, msg= ' ') => `${\n+            this.utils.printExpected(x)}${\n+                msg}${\n+            this.utils.printReceived(y)\n+        }`;\n+\n+        let getFailures = new Array<string>();\n+        let propsFailures = new Array<string>();\n+        let iteratorFailures = new Array<string>();\n+        let allFailures = [\n+            { title: 'get', failures: getFailures },\n+            { title: 'props', failures: propsFailures },\n+            { title: 'iterator', failures: iteratorFailures }\n+        ];\n+\n+        let props = ['name', 'type', 'length', 'nullable', 'nullCount', 'metadata'];\n+        for (let i = -1, n = props.length; ++i < n;) {\n+            const prop = props[i];\n+            if (this.utils.stringify(v1[prop]) !== this.utils.stringify(v2[prop])) {\n+                propsFailures.push(`${prop}: ${format(v1[prop], v2[prop], ' !== ')}`);\n+            }\n+        }\n+\n+        for (let i = -1, n = v1.length; ++i < n;) {\n+            let x1 = v1.get(i), x2 = v2.get(i);\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                getFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        let i = -1;\n+        for (let [x1, x2] of zip(v1, v2)) {\n+            ++i;\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                iteratorFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        return {\n+            pass: allFailures.every(({ failures }) => failures.length === 0),\n+            message: () => [\n+                `${v1.name}: (${format('cpp', 'java', ' !== ')})\\n`,\n+                ...allFailures.map(({ failures, title }) =>\n+                    !failures.length ? `` : [`${title}:`, ...failures].join(`\\n`))\n+            ].join('\\n')\n+        };\n+    }\n+});\n+\n+describe(`Integration`, () => {\n+    for (const format of formats) {\n+        describe(format, () => {\n+            for (const [cppArrow, javaArrow] of zip(config.cpp[format], config.java[format])) {\n+                describe(`${cppArrow.name}`, () => {\n+                    testReaderIntegration(cppArrow.buffers, javaArrow.buffers);\n+                    testTableFromBuffersIntegration(cppArrow.buffers, javaArrow.buffers);\n+                });\n+            }\n+        });\n+    }\n+});\n+\n+function testReaderIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java vectors report the same values`, () => {\n+        expect.hasAssertions();\n+        for (const [cppVectors, javaVectors] of zip(readVectors(cppBuffers), readVectors(javaBuffers))) {\n+            expect(cppVectors.length).toEqual(javaVectors.length);\n+            for (let i = -1, n = cppVectors.length; ++i < n;) {\n+                (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+            }\n+        }\n+    });\n+}\n+\n+function testTableFromBuffersIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java tables report the same values`, () => {\n+        expect.hasAssertions();\n+        const cppTable = Table.from(cppBuffers);\n+        const javaTable = Table.from(javaBuffers);\n+        const cppVectors = cppTable.columns;\n+        const javaVectors = javaTable.columns;\n+        expect(cppTable.length).toEqual(javaTable.length);\n+        expect(cppVectors.length).toEqual(javaVectors.length);\n+        for (let i = -1, n = cppVectors.length; ++i < n;) {\n+            (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+        }\n+    });\n+}\n \n Review comment:\n   I'm a bit confused by these integration tests, maybe I'm missing something. Shouldn't JavaScript be reading the JSON and comparing what it thinks are the contents of the JSON with the binary coming from Java and C++? Here it looks like it is reading the C++ and Java binary files and comparing them. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T05:33:34.881+0000",
                    "updated": "2017-11-13T05:33:34.881+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249124",
                    "id": "16249124",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150451049\n \n \n\n ##########\n File path: js/test/integration-tests.ts\n ##########\n @@ -0,0 +1,114 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import Arrow from './Arrow';\n+import { zip } from 'ix/iterable/zip';\n+import { config, formats } from './test-config';\n+\n+const { Table, readVectors } = Arrow;\n+\n+expect.extend({\n+    toEqualVector(v1: any, v2: any) {\n+\n+        const format = (x: any, y: any, msg= ' ') => `${\n+            this.utils.printExpected(x)}${\n+                msg}${\n+            this.utils.printReceived(y)\n+        }`;\n+\n+        let getFailures = new Array<string>();\n+        let propsFailures = new Array<string>();\n+        let iteratorFailures = new Array<string>();\n+        let allFailures = [\n+            { title: 'get', failures: getFailures },\n+            { title: 'props', failures: propsFailures },\n+            { title: 'iterator', failures: iteratorFailures }\n+        ];\n+\n+        let props = ['name', 'type', 'length', 'nullable', 'nullCount', 'metadata'];\n+        for (let i = -1, n = props.length; ++i < n;) {\n+            const prop = props[i];\n+            if (this.utils.stringify(v1[prop]) !== this.utils.stringify(v2[prop])) {\n+                propsFailures.push(`${prop}: ${format(v1[prop], v2[prop], ' !== ')}`);\n+            }\n+        }\n+\n+        for (let i = -1, n = v1.length; ++i < n;) {\n+            let x1 = v1.get(i), x2 = v2.get(i);\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                getFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        let i = -1;\n+        for (let [x1, x2] of zip(v1, v2)) {\n+            ++i;\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                iteratorFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        return {\n+            pass: allFailures.every(({ failures }) => failures.length === 0),\n+            message: () => [\n+                `${v1.name}: (${format('cpp', 'java', ' !== ')})\\n`,\n+                ...allFailures.map(({ failures, title }) =>\n+                    !failures.length ? `` : [`${title}:`, ...failures].join(`\\n`))\n+            ].join('\\n')\n+        };\n+    }\n+});\n+\n+describe(`Integration`, () => {\n+    for (const format of formats) {\n+        describe(format, () => {\n+            for (const [cppArrow, javaArrow] of zip(config.cpp[format], config.java[format])) {\n+                describe(`${cppArrow.name}`, () => {\n+                    testReaderIntegration(cppArrow.buffers, javaArrow.buffers);\n+                    testTableFromBuffersIntegration(cppArrow.buffers, javaArrow.buffers);\n+                });\n+            }\n+        });\n+    }\n+});\n+\n+function testReaderIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java vectors report the same values`, () => {\n+        expect.hasAssertions();\n+        for (const [cppVectors, javaVectors] of zip(readVectors(cppBuffers), readVectors(javaBuffers))) {\n+            expect(cppVectors.length).toEqual(javaVectors.length);\n+            for (let i = -1, n = cppVectors.length; ++i < n;) {\n+                (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+            }\n+        }\n+    });\n+}\n+\n+function testTableFromBuffersIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java tables report the same values`, () => {\n+        expect.hasAssertions();\n+        const cppTable = Table.from(cppBuffers);\n+        const javaTable = Table.from(javaBuffers);\n+        const cppVectors = cppTable.columns;\n+        const javaVectors = javaTable.columns;\n+        expect(cppTable.length).toEqual(javaTable.length);\n+        expect(cppVectors.length).toEqual(javaVectors.length);\n+        for (let i = -1, n = cppVectors.length; ++i < n;) {\n+            (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+        }\n+    });\n+}\n \n Review comment:\n   I'm a bit confused by these integration tests, maybe I'm missing something. Shouldn't JavaScript be reading the JSON and comparing what it thinks are the contents of the JSON with the binary coming from Java and C++? Here it looks like it is reading the C++ and Java binary files and comparing them with each other rather than its own version of the truth. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T05:36:20.984+0000",
                    "updated": "2017-11-13T05:36:20.984+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249781",
                    "id": "16249781",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "TheNeuralBit commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150558328\n \n \n\n ##########\n File path: js/src/vector/arrow.ts\n ##########\n @@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import * as Schema_ from '../format/Schema_generated';\n+import * as Message_ from '../format/Message_generated';\n+import Field = Schema_.org.apache.arrow.flatbuf.Field;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+\n+import { Vector } from './vector';\n+import { Utf8Vector as Utf8VectorBase } from './utf8';\n+import { StructVector as StructVectorBase } from './struct';\n+import { DictionaryVector as DictionaryVectorBase } from './dictionary';\n+import {\n+    ListVector as ListVectorBase,\n+    BinaryVector as BinaryVectorBase,\n+    FixedSizeListVector as FixedSizeListVectorBase\n+} from './list';\n+\n+import {\n+    BoolVector as BoolVectorBase,\n+    Int8Vector as Int8VectorBase,\n+    Int16Vector as Int16VectorBase,\n+    Int32Vector as Int32VectorBase,\n+    Int64Vector as Int64VectorBase,\n+    Uint8Vector as Uint8VectorBase,\n+    Uint16Vector as Uint16VectorBase,\n+    Uint32Vector as Uint32VectorBase,\n+    Uint64Vector as Uint64VectorBase,\n+    Float16Vector as Float16VectorBase,\n+    Float32Vector as Float32VectorBase,\n+    Float64Vector as Float64VectorBase,\n+    Date32Vector as Date32VectorBase,\n+    Date64Vector as Date64VectorBase,\n+    Time32Vector as Time32VectorBase,\n+    Time64Vector as Time64VectorBase,\n+    DecimalVector as DecimalVectorBase,\n+    TimestampVector as TimestampVectorBase,\n+} from './numeric';\n+\n+import { nullableMixin, fieldMixin } from './traits';\n+\n+function MixinArrowTraits<T extends Vector<any>, TArgv>(\n+    Base: new (argv: TArgv) => T,\n+    Field: new (argv: TArgv & { field: Field, fieldNode: FieldNode }) => T,\n+    Nullable: new (argv: TArgv & { validity: Uint8Array }) => T,\n+    NullableField: new (argv: TArgv & { validity: Uint8Array, field: Field, fieldNode: FieldNode }) => T,\n+) {\n \n Review comment:\n   Why move the calls to `nullableMixin` and `fieldMixin` from here and out to each individual call? Are there some subtle differences in some vectors that I'm missing?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T16:23:59.266+0000",
                    "updated": "2017-11-13T16:23:59.266+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249782",
                    "id": "16249782",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "TheNeuralBit commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150583457\n \n \n\n ##########\n File path: js/gulpfile.js\n ##########\n @@ -86,9 +86,9 @@ const buildConcurrent = (tasks) => () =>\n             .merge(...knownTargets.map((target) =>\n                 del(`${targetDir(target, `cls`)}/**`)))));\n   \n-gulp.task( `test`, gulp.series(getTasks(`test`)));\n-gulp.task(`debug`, gulp.series(getTasks(`debug`)));\n-gulp.task(`clean`, gulp.parallel(getTasks(`clean`)));\n+gulp.task( `test`, gulp.series(/*createTestData,*/ getTasks(`test`)/*, cleanTestData*/));\n+gulp.task(`debug`, gulp.series(/*createTestData,*/ getTasks(`debug`)/*, cleanTestData*/));\n+gulp.task(`clean`, gulp.parallel(/*cleanTestData,*/ getTasks(`clean`)));\n \n Review comment:\n   Should `createTestData` and `cleanTestData` be uncommented so we can remove the arrow files from the repo? I'm thinking these are probably commented now so that other contributors will be able to run the tests without building the Java and C++ impls - if that's the case, maybe we should separate out integration tests, which require the other libraries, and unit tests, which can be run stand-alone?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T16:23:59.268+0000",
                    "updated": "2017-11-13T16:23:59.268+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16249783",
                    "id": "16249783",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "TheNeuralBit commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150566841\n \n \n\n ##########\n File path: js/test/integration-tests.ts\n ##########\n @@ -0,0 +1,114 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import Arrow from './Arrow';\n+import { zip } from 'ix/iterable/zip';\n+import { config, formats } from './test-config';\n+\n+const { Table, readVectors } = Arrow;\n+\n+expect.extend({\n+    toEqualVector(v1: any, v2: any) {\n+\n+        const format = (x: any, y: any, msg= ' ') => `${\n+            this.utils.printExpected(x)}${\n+                msg}${\n+            this.utils.printReceived(y)\n+        }`;\n+\n+        let getFailures = new Array<string>();\n+        let propsFailures = new Array<string>();\n+        let iteratorFailures = new Array<string>();\n+        let allFailures = [\n+            { title: 'get', failures: getFailures },\n+            { title: 'props', failures: propsFailures },\n+            { title: 'iterator', failures: iteratorFailures }\n+        ];\n+\n+        let props = ['name', 'type', 'length', 'nullable', 'nullCount', 'metadata'];\n+        for (let i = -1, n = props.length; ++i < n;) {\n+            const prop = props[i];\n+            if (this.utils.stringify(v1[prop]) !== this.utils.stringify(v2[prop])) {\n+                propsFailures.push(`${prop}: ${format(v1[prop], v2[prop], ' !== ')}`);\n+            }\n+        }\n+\n+        for (let i = -1, n = v1.length; ++i < n;) {\n+            let x1 = v1.get(i), x2 = v2.get(i);\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                getFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        let i = -1;\n+        for (let [x1, x2] of zip(v1, v2)) {\n+            ++i;\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                iteratorFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        return {\n+            pass: allFailures.every(({ failures }) => failures.length === 0),\n+            message: () => [\n+                `${v1.name}: (${format('cpp', 'java', ' !== ')})\\n`,\n+                ...allFailures.map(({ failures, title }) =>\n+                    !failures.length ? `` : [`${title}:`, ...failures].join(`\\n`))\n+            ].join('\\n')\n+        };\n+    }\n+});\n+\n+describe(`Integration`, () => {\n+    for (const format of formats) {\n+        describe(format, () => {\n+            for (const [cppArrow, javaArrow] of zip(config.cpp[format], config.java[format])) {\n+                describe(`${cppArrow.name}`, () => {\n+                    testReaderIntegration(cppArrow.buffers, javaArrow.buffers);\n+                    testTableFromBuffersIntegration(cppArrow.buffers, javaArrow.buffers);\n+                });\n+            }\n+        });\n+    }\n+});\n+\n+function testReaderIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java vectors report the same values`, () => {\n+        expect.hasAssertions();\n+        for (const [cppVectors, javaVectors] of zip(readVectors(cppBuffers), readVectors(javaBuffers))) {\n+            expect(cppVectors.length).toEqual(javaVectors.length);\n+            for (let i = -1, n = cppVectors.length; ++i < n;) {\n+                (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+            }\n+        }\n+    });\n+}\n+\n+function testTableFromBuffersIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java tables report the same values`, () => {\n+        expect.hasAssertions();\n+        const cppTable = Table.from(cppBuffers);\n+        const javaTable = Table.from(javaBuffers);\n+        const cppVectors = cppTable.columns;\n+        const javaVectors = javaTable.columns;\n+        expect(cppTable.length).toEqual(javaTable.length);\n+        expect(cppVectors.length).toEqual(javaVectors.length);\n+        for (let i = -1, n = cppVectors.length; ++i < n;) {\n+            (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+        }\n+    });\n+}\n \n Review comment:\n   @wesm I think for this PR the goal was more to just replace the binary files in the repo with generated files, and adding tests to make sure our reader works the same for both C++ and Java generated files is just an added bonus. It might be a bit of a misnomer to call it an integration test.\r\n   \r\n   I think the next step will be to add a JSON reader/writer and an Arrow IPC writer so we can integrate with the actual integration tests.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T16:23:59.269+0000",
                    "updated": "2017-11-13T16:23:59.269+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250051",
                    "id": "16250051",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150642270\n \n \n\n ##########\n File path: js/test/integration-tests.ts\n ##########\n @@ -0,0 +1,114 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import Arrow from './Arrow';\n+import { zip } from 'ix/iterable/zip';\n+import { config, formats } from './test-config';\n+\n+const { Table, readVectors } = Arrow;\n+\n+expect.extend({\n+    toEqualVector(v1: any, v2: any) {\n+\n+        const format = (x: any, y: any, msg= ' ') => `${\n+            this.utils.printExpected(x)}${\n+                msg}${\n+            this.utils.printReceived(y)\n+        }`;\n+\n+        let getFailures = new Array<string>();\n+        let propsFailures = new Array<string>();\n+        let iteratorFailures = new Array<string>();\n+        let allFailures = [\n+            { title: 'get', failures: getFailures },\n+            { title: 'props', failures: propsFailures },\n+            { title: 'iterator', failures: iteratorFailures }\n+        ];\n+\n+        let props = ['name', 'type', 'length', 'nullable', 'nullCount', 'metadata'];\n+        for (let i = -1, n = props.length; ++i < n;) {\n+            const prop = props[i];\n+            if (this.utils.stringify(v1[prop]) !== this.utils.stringify(v2[prop])) {\n+                propsFailures.push(`${prop}: ${format(v1[prop], v2[prop], ' !== ')}`);\n+            }\n+        }\n+\n+        for (let i = -1, n = v1.length; ++i < n;) {\n+            let x1 = v1.get(i), x2 = v2.get(i);\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                getFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        let i = -1;\n+        for (let [x1, x2] of zip(v1, v2)) {\n+            ++i;\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                iteratorFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        return {\n+            pass: allFailures.every(({ failures }) => failures.length === 0),\n+            message: () => [\n+                `${v1.name}: (${format('cpp', 'java', ' !== ')})\\n`,\n+                ...allFailures.map(({ failures, title }) =>\n+                    !failures.length ? `` : [`${title}:`, ...failures].join(`\\n`))\n+            ].join('\\n')\n+        };\n+    }\n+});\n+\n+describe(`Integration`, () => {\n+    for (const format of formats) {\n+        describe(format, () => {\n+            for (const [cppArrow, javaArrow] of zip(config.cpp[format], config.java[format])) {\n+                describe(`${cppArrow.name}`, () => {\n+                    testReaderIntegration(cppArrow.buffers, javaArrow.buffers);\n+                    testTableFromBuffersIntegration(cppArrow.buffers, javaArrow.buffers);\n+                });\n+            }\n+        });\n+    }\n+});\n+\n+function testReaderIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java vectors report the same values`, () => {\n+        expect.hasAssertions();\n+        for (const [cppVectors, javaVectors] of zip(readVectors(cppBuffers), readVectors(javaBuffers))) {\n+            expect(cppVectors.length).toEqual(javaVectors.length);\n+            for (let i = -1, n = cppVectors.length; ++i < n;) {\n+                (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+            }\n+        }\n+    });\n+}\n+\n+function testTableFromBuffersIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java tables report the same values`, () => {\n+        expect.hasAssertions();\n+        const cppTable = Table.from(cppBuffers);\n+        const javaTable = Table.from(javaBuffers);\n+        const cppVectors = cppTable.columns;\n+        const javaVectors = javaTable.columns;\n+        expect(cppTable.length).toEqual(javaTable.length);\n+        expect(cppVectors.length).toEqual(javaVectors.length);\n+        for (let i = -1, n = cppVectors.length; ++i < n;) {\n+            (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+        }\n+    });\n+}\n \n Review comment:\n   Got it. I think here we should comment exactly what's being tested (since these tests will pass if (and only if?) the Java <-> C++ integration tests are passing). If we can run these particular JS tests only in the Travis CI entry where we are already running the `integration_test.py` then we don't need to be checking in binary/JSON files to git\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T19:34:41.294+0000",
                    "updated": "2017-11-13T19:34:41.294+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250143",
                    "id": "16250143",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150648586\n \n \n\n ##########\n File path: js/test/integration-tests.ts\n ##########\n @@ -0,0 +1,114 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import Arrow from './Arrow';\n+import { zip } from 'ix/iterable/zip';\n+import { config, formats } from './test-config';\n+\n+const { Table, readVectors } = Arrow;\n+\n+expect.extend({\n+    toEqualVector(v1: any, v2: any) {\n+\n+        const format = (x: any, y: any, msg= ' ') => `${\n+            this.utils.printExpected(x)}${\n+                msg}${\n+            this.utils.printReceived(y)\n+        }`;\n+\n+        let getFailures = new Array<string>();\n+        let propsFailures = new Array<string>();\n+        let iteratorFailures = new Array<string>();\n+        let allFailures = [\n+            { title: 'get', failures: getFailures },\n+            { title: 'props', failures: propsFailures },\n+            { title: 'iterator', failures: iteratorFailures }\n+        ];\n+\n+        let props = ['name', 'type', 'length', 'nullable', 'nullCount', 'metadata'];\n+        for (let i = -1, n = props.length; ++i < n;) {\n+            const prop = props[i];\n+            if (this.utils.stringify(v1[prop]) !== this.utils.stringify(v2[prop])) {\n+                propsFailures.push(`${prop}: ${format(v1[prop], v2[prop], ' !== ')}`);\n+            }\n+        }\n+\n+        for (let i = -1, n = v1.length; ++i < n;) {\n+            let x1 = v1.get(i), x2 = v2.get(i);\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                getFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        let i = -1;\n+        for (let [x1, x2] of zip(v1, v2)) {\n+            ++i;\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                iteratorFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        return {\n+            pass: allFailures.every(({ failures }) => failures.length === 0),\n+            message: () => [\n+                `${v1.name}: (${format('cpp', 'java', ' !== ')})\\n`,\n+                ...allFailures.map(({ failures, title }) =>\n+                    !failures.length ? `` : [`${title}:`, ...failures].join(`\\n`))\n+            ].join('\\n')\n+        };\n+    }\n+});\n+\n+describe(`Integration`, () => {\n+    for (const format of formats) {\n+        describe(format, () => {\n+            for (const [cppArrow, javaArrow] of zip(config.cpp[format], config.java[format])) {\n+                describe(`${cppArrow.name}`, () => {\n+                    testReaderIntegration(cppArrow.buffers, javaArrow.buffers);\n+                    testTableFromBuffersIntegration(cppArrow.buffers, javaArrow.buffers);\n+                });\n+            }\n+        });\n+    }\n+});\n+\n+function testReaderIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java vectors report the same values`, () => {\n+        expect.hasAssertions();\n+        for (const [cppVectors, javaVectors] of zip(readVectors(cppBuffers), readVectors(javaBuffers))) {\n+            expect(cppVectors.length).toEqual(javaVectors.length);\n+            for (let i = -1, n = cppVectors.length; ++i < n;) {\n+                (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+            }\n+        }\n+    });\n+}\n+\n+function testTableFromBuffersIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java tables report the same values`, () => {\n+        expect.hasAssertions();\n+        const cppTable = Table.from(cppBuffers);\n+        const javaTable = Table.from(javaBuffers);\n+        const cppVectors = cppTable.columns;\n+        const javaVectors = javaTable.columns;\n+        expect(cppTable.length).toEqual(javaTable.length);\n+        expect(cppVectors.length).toEqual(javaVectors.length);\n+        for (let i = -1, n = cppVectors.length; ++i < n;) {\n+            (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+        }\n+    });\n+}\n \n Review comment:\n   @wesm yes they should. @TheNeuralBit is right, the goal here was to get the JS version reading C++ and Java arrows identically, and this test is how I validate that it does. Right now it _doesn't_ validate that it reads correctly (that's what the other tests do), just that there's no difference between the two. I think the plan is to update this test when we do have the JSON reader/writer in JS\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T19:58:50.518+0000",
                    "updated": "2017-11-13T19:58:50.518+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250148",
                    "id": "16250148",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150649634\n \n \n\n ##########\n File path: js/gulpfile.js\n ##########\n @@ -86,9 +86,9 @@ const buildConcurrent = (tasks) => () =>\n             .merge(...knownTargets.map((target) =>\n                 del(`${targetDir(target, `cls`)}/**`)))));\n   \n-gulp.task( `test`, gulp.series(getTasks(`test`)));\n-gulp.task(`debug`, gulp.series(getTasks(`debug`)));\n-gulp.task(`clean`, gulp.parallel(getTasks(`clean`)));\n+gulp.task( `test`, gulp.series(/*createTestData,*/ getTasks(`test`)/*, cleanTestData*/));\n+gulp.task(`debug`, gulp.series(/*createTestData,*/ getTasks(`debug`)/*, cleanTestData*/));\n+gulp.task(`clean`, gulp.parallel(/*cleanTestData,*/ getTasks(`clean`)));\n \n Review comment:\n   @TheNeuralBit yes, definitely. I put these in to remind us to generate test data on the fly (and how to do it) for the tests, and remove the arrow files from the test directory. Making sure the CI environment had the C++ and Java libs built before the JS tests run was a bit more than I could bite off yesterday on my flight home :)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T20:03:06.830+0000",
                    "updated": "2017-11-13T20:03:06.830+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250158",
                    "id": "16250158",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150652141\n \n \n\n ##########\n File path: js/src/reader/arrow.ts\n ##########\n @@ -15,64 +15,135 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+import { Vector } from '../vector/vector';\n import { flatbuffers } from 'flatbuffers';\n+import { readVector, readValueVector } from './vector';\n+import {\n+    readFileFooter, readFileMessages,\n+    readStreamSchema, readStreamMessages\n+} from './format';\n+\n+import * as File_ from '../format/File_generated';\n import * as Schema_ from '../format/Schema_generated';\n import * as Message_ from '../format/Message_generated';\n-export import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n-export import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n-\n-import { readFile } from './file';\n-import { readStream } from './stream';\n-import { readVector } from './vector';\n-import { readDictionary } from './dictionary';\n-import { Vector, Column } from '../types/types';\n \n import ByteBuffer = flatbuffers.ByteBuffer;\n+import Footer = File_.org.apache.arrow.flatbuf.Footer;\n import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-export type Dictionaries = { [k: string]: Vector<any> } | null;\n-export type IteratorState = { nodeIndex: number; bufferIndex: number };\n-\n-export function* readRecords(...bytes: ByteBuffer[]) {\n-    try {\n-        yield* readFile(...bytes);\n-    } catch (e) {\n-        try {\n-            yield* readStream(...bytes);\n-        } catch (e) {\n-            throw new Error('Invalid Arrow buffer');\n-        }\n+import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n+import Message = Message_.org.apache.arrow.flatbuf.Message;\n+import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n+import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n+import DictionaryBatch = Message_.org.apache.arrow.flatbuf.DictionaryBatch;\n+import DictionaryEncoding = Schema_.org.apache.arrow.flatbuf.DictionaryEncoding;\n+\n+export type ArrowReaderContext = {\n+    schema?: Schema;\n+    footer?: Footer | null;\n+    dictionaries: Map<string, Vector>;\n+    dictionaryEncodedFields: Map<string, Field>;\n+    readMessages: (bb: ByteBuffer, footer: Footer) => Iterable<Message>;\n+};\n+\n+export type VectorReaderContext = {\n+    node: number;\n+    buffer: number;\n+    offset: number;\n+    bytes: Uint8Array;\n+    batch: RecordBatch;\n+    dictionaries: Map<string, Vector>;\n+};\n+\n+export function* readVectors(buffers: Iterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n     }\n }\n \n-export function* readBuffers(...bytes: Array<Uint8Array | Buffer | string>) {\n-    const dictionaries: Dictionaries = {};\n-    const byteBuffers = bytes.map(toByteBuffer);\n-    for (let { schema, batch } of readRecords(...byteBuffers)) {\n-        let vectors: Column<any>[] = [];\n-        let state = { nodeIndex: 0, bufferIndex: 0 };\n-        let fieldsLength = schema.fieldsLength();\n-        let index = -1, field: Field, vector: Vector<any>;\n-        if (batch.id) {\n-            // A dictionary batch only contain a single vector. Traverse each\n-            // field and its children until we find one that uses this dictionary\n-            while (++index < fieldsLength) {\n-                if (field = schema.fields(index)!) {\n-                    if (vector = readDictionary<any>(field, batch, state, dictionaries)!) {\n-                        dictionaries[batch.id] = dictionaries[batch.id] && dictionaries[batch.id].concat(vector) || vector;\n-                        break;\n-                    }\n+export async function* readVectorsAsync(buffers: AsyncIterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for await (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n+    }\n+}\n+\n+function* readBuffer(bb: ByteBuffer, readerContext: ArrowReaderContext) {\n \n Review comment:\n   @wesm anything type-related (type annotations, interfaces, generics, and declarations like `type = { foo: string }`) is TypeScript, the rest is ES. If you're curious about an individual feature, you can run the build `npm run build` and compare the transpiled output (in the `targets` directory) with the TS source. We transpile to multiple JS versions and module formats, but it's probably easiest to compare against the `targets/es2015/esm` or `targets/esnext/esm`.\r\n   \r\n   TS code-gens/polyfills missing features depending on the target environment. For example, ES5 doesn't have generators, so TS code-gens an iterator state machine into generator functions, but the ES2015 target leaves them as-is. And ES2015 doesn't have async iterator functions, so TS coge-gens the async iterator state machine with Promises.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T20:13:48.144+0000",
                    "updated": "2017-11-13T20:13:48.144+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250159",
                    "id": "16250159",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150652141\n \n \n\n ##########\n File path: js/src/reader/arrow.ts\n ##########\n @@ -15,64 +15,135 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+import { Vector } from '../vector/vector';\n import { flatbuffers } from 'flatbuffers';\n+import { readVector, readValueVector } from './vector';\n+import {\n+    readFileFooter, readFileMessages,\n+    readStreamSchema, readStreamMessages\n+} from './format';\n+\n+import * as File_ from '../format/File_generated';\n import * as Schema_ from '../format/Schema_generated';\n import * as Message_ from '../format/Message_generated';\n-export import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n-export import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n-\n-import { readFile } from './file';\n-import { readStream } from './stream';\n-import { readVector } from './vector';\n-import { readDictionary } from './dictionary';\n-import { Vector, Column } from '../types/types';\n \n import ByteBuffer = flatbuffers.ByteBuffer;\n+import Footer = File_.org.apache.arrow.flatbuf.Footer;\n import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-export type Dictionaries = { [k: string]: Vector<any> } | null;\n-export type IteratorState = { nodeIndex: number; bufferIndex: number };\n-\n-export function* readRecords(...bytes: ByteBuffer[]) {\n-    try {\n-        yield* readFile(...bytes);\n-    } catch (e) {\n-        try {\n-            yield* readStream(...bytes);\n-        } catch (e) {\n-            throw new Error('Invalid Arrow buffer');\n-        }\n+import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n+import Message = Message_.org.apache.arrow.flatbuf.Message;\n+import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n+import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n+import DictionaryBatch = Message_.org.apache.arrow.flatbuf.DictionaryBatch;\n+import DictionaryEncoding = Schema_.org.apache.arrow.flatbuf.DictionaryEncoding;\n+\n+export type ArrowReaderContext = {\n+    schema?: Schema;\n+    footer?: Footer | null;\n+    dictionaries: Map<string, Vector>;\n+    dictionaryEncodedFields: Map<string, Field>;\n+    readMessages: (bb: ByteBuffer, footer: Footer) => Iterable<Message>;\n+};\n+\n+export type VectorReaderContext = {\n+    node: number;\n+    buffer: number;\n+    offset: number;\n+    bytes: Uint8Array;\n+    batch: RecordBatch;\n+    dictionaries: Map<string, Vector>;\n+};\n+\n+export function* readVectors(buffers: Iterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n     }\n }\n \n-export function* readBuffers(...bytes: Array<Uint8Array | Buffer | string>) {\n-    const dictionaries: Dictionaries = {};\n-    const byteBuffers = bytes.map(toByteBuffer);\n-    for (let { schema, batch } of readRecords(...byteBuffers)) {\n-        let vectors: Column<any>[] = [];\n-        let state = { nodeIndex: 0, bufferIndex: 0 };\n-        let fieldsLength = schema.fieldsLength();\n-        let index = -1, field: Field, vector: Vector<any>;\n-        if (batch.id) {\n-            // A dictionary batch only contain a single vector. Traverse each\n-            // field and its children until we find one that uses this dictionary\n-            while (++index < fieldsLength) {\n-                if (field = schema.fields(index)!) {\n-                    if (vector = readDictionary<any>(field, batch, state, dictionaries)!) {\n-                        dictionaries[batch.id] = dictionaries[batch.id] && dictionaries[batch.id].concat(vector) || vector;\n-                        break;\n-                    }\n+export async function* readVectorsAsync(buffers: AsyncIterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for await (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n+    }\n+}\n+\n+function* readBuffer(bb: ByteBuffer, readerContext: ArrowReaderContext) {\n \n Review comment:\n   @wesm anything type-related (type annotations, interfaces, generics, and declarations like `type = { foo: string }`) is TypeScript, the rest is ES. If you're curious about an individual feature, you can run the build (`npm run build`) and compare the transpiled output (in the `targets` directory) with the TS source. We transpile to multiple JS versions and module formats, but it's probably easiest to compare against the `targets/es2015/esm` or `targets/esnext/esm`.\r\n   \r\n   TS code-gens/polyfills missing features depending on the target environment. For example, ES5 doesn't have generators, so TS code-gens an iterator state machine into generator functions, but the ES2015 target leaves them as-is. And ES2015 doesn't have async iterator functions, so TS coge-gens the async iterator state machine with Promises.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T20:14:02.244+0000",
                    "updated": "2017-11-13T20:14:02.244+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250162",
                    "id": "16250162",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150652141\n \n \n\n ##########\n File path: js/src/reader/arrow.ts\n ##########\n @@ -15,64 +15,135 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+import { Vector } from '../vector/vector';\n import { flatbuffers } from 'flatbuffers';\n+import { readVector, readValueVector } from './vector';\n+import {\n+    readFileFooter, readFileMessages,\n+    readStreamSchema, readStreamMessages\n+} from './format';\n+\n+import * as File_ from '../format/File_generated';\n import * as Schema_ from '../format/Schema_generated';\n import * as Message_ from '../format/Message_generated';\n-export import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n-export import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n-\n-import { readFile } from './file';\n-import { readStream } from './stream';\n-import { readVector } from './vector';\n-import { readDictionary } from './dictionary';\n-import { Vector, Column } from '../types/types';\n \n import ByteBuffer = flatbuffers.ByteBuffer;\n+import Footer = File_.org.apache.arrow.flatbuf.Footer;\n import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-export type Dictionaries = { [k: string]: Vector<any> } | null;\n-export type IteratorState = { nodeIndex: number; bufferIndex: number };\n-\n-export function* readRecords(...bytes: ByteBuffer[]) {\n-    try {\n-        yield* readFile(...bytes);\n-    } catch (e) {\n-        try {\n-            yield* readStream(...bytes);\n-        } catch (e) {\n-            throw new Error('Invalid Arrow buffer');\n-        }\n+import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n+import Message = Message_.org.apache.arrow.flatbuf.Message;\n+import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n+import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n+import DictionaryBatch = Message_.org.apache.arrow.flatbuf.DictionaryBatch;\n+import DictionaryEncoding = Schema_.org.apache.arrow.flatbuf.DictionaryEncoding;\n+\n+export type ArrowReaderContext = {\n+    schema?: Schema;\n+    footer?: Footer | null;\n+    dictionaries: Map<string, Vector>;\n+    dictionaryEncodedFields: Map<string, Field>;\n+    readMessages: (bb: ByteBuffer, footer: Footer) => Iterable<Message>;\n+};\n+\n+export type VectorReaderContext = {\n+    node: number;\n+    buffer: number;\n+    offset: number;\n+    bytes: Uint8Array;\n+    batch: RecordBatch;\n+    dictionaries: Map<string, Vector>;\n+};\n+\n+export function* readVectors(buffers: Iterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n     }\n }\n \n-export function* readBuffers(...bytes: Array<Uint8Array | Buffer | string>) {\n-    const dictionaries: Dictionaries = {};\n-    const byteBuffers = bytes.map(toByteBuffer);\n-    for (let { schema, batch } of readRecords(...byteBuffers)) {\n-        let vectors: Column<any>[] = [];\n-        let state = { nodeIndex: 0, bufferIndex: 0 };\n-        let fieldsLength = schema.fieldsLength();\n-        let index = -1, field: Field, vector: Vector<any>;\n-        if (batch.id) {\n-            // A dictionary batch only contain a single vector. Traverse each\n-            // field and its children until we find one that uses this dictionary\n-            while (++index < fieldsLength) {\n-                if (field = schema.fields(index)!) {\n-                    if (vector = readDictionary<any>(field, batch, state, dictionaries)!) {\n-                        dictionaries[batch.id] = dictionaries[batch.id] && dictionaries[batch.id].concat(vector) || vector;\n-                        break;\n-                    }\n+export async function* readVectorsAsync(buffers: AsyncIterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for await (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n+    }\n+}\n+\n+function* readBuffer(bb: ByteBuffer, readerContext: ArrowReaderContext) {\n \n Review comment:\n   @wesm anything type-related (type annotations, interfaces, generics, and declarations like `type = { foo: string }`) is TypeScript, the rest is ES. If you're curious about an individual feature, you can run the build (`npm run build`) and compare the transpiled output (in the `targets` directory) with the TS source. We transpile to multiple JS versions and module formats, but it's probably easiest to compare against the `targets/es2015/esm` or `targets/esnext/esm`.\r\n   \r\n   TS code-gens/polyfills missing features depending on the target environment. For example, ES5 doesn't have generators, so TS code-gens an iterator state machine into generator functions, but the ES2015 target leaves them as-is. And ES2015 doesn't have async iterator functions, so TS coge-gens the async iterator state machine with Promises, but the ESNext target leaves them as-is.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T20:14:31.150+0000",
                    "updated": "2017-11-13T20:14:31.150+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250171",
                    "id": "16250171",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150653618\n \n \n\n ##########\n File path: js/src/vector/arrow.ts\n ##########\n @@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import * as Schema_ from '../format/Schema_generated';\n+import * as Message_ from '../format/Message_generated';\n+import Field = Schema_.org.apache.arrow.flatbuf.Field;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+\n+import { Vector } from './vector';\n+import { Utf8Vector as Utf8VectorBase } from './utf8';\n+import { StructVector as StructVectorBase } from './struct';\n+import { DictionaryVector as DictionaryVectorBase } from './dictionary';\n+import {\n+    ListVector as ListVectorBase,\n+    BinaryVector as BinaryVectorBase,\n+    FixedSizeListVector as FixedSizeListVectorBase\n+} from './list';\n+\n+import {\n+    BoolVector as BoolVectorBase,\n+    Int8Vector as Int8VectorBase,\n+    Int16Vector as Int16VectorBase,\n+    Int32Vector as Int32VectorBase,\n+    Int64Vector as Int64VectorBase,\n+    Uint8Vector as Uint8VectorBase,\n+    Uint16Vector as Uint16VectorBase,\n+    Uint32Vector as Uint32VectorBase,\n+    Uint64Vector as Uint64VectorBase,\n+    Float16Vector as Float16VectorBase,\n+    Float32Vector as Float32VectorBase,\n+    Float64Vector as Float64VectorBase,\n+    Date32Vector as Date32VectorBase,\n+    Date64Vector as Date64VectorBase,\n+    Time32Vector as Time32VectorBase,\n+    Time64Vector as Time64VectorBase,\n+    DecimalVector as DecimalVectorBase,\n+    TimestampVector as TimestampVectorBase,\n+} from './numeric';\n+\n+import { nullableMixin, fieldMixin } from './traits';\n+\n+function MixinArrowTraits<T extends Vector<any>, TArgv>(\n+    Base: new (argv: TArgv) => T,\n+    Field: new (argv: TArgv & { field: Field, fieldNode: FieldNode }) => T,\n+    Nullable: new (argv: TArgv & { validity: Uint8Array }) => T,\n+    NullableField: new (argv: TArgv & { validity: Uint8Array, field: Field, fieldNode: FieldNode }) => T,\n+) {\n \n Review comment:\n   @TheNeuralBit yeah so the ES6 class spec states that the `name` property of a class constructor is immutable (and they're also not allowed to be computed properties, like `let x = 'myClass'; class [x] extends Foo {}`). And anonymous class names default to \"Object\", reading as `Object { data: Int32Array }` instead of `Int32Vector` when debugging. While this is ugly and hard to scale if we want to add more mixin behaviors, I figure it's a win for anyone using the library in the real world to see descriptive class names.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T20:20:04.218+0000",
                    "updated": "2017-11-13T20:20:04.218+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250225",
                    "id": "16250225",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "TheNeuralBit commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150661882\n \n \n\n ##########\n File path: js/src/vector/arrow.ts\n ##########\n @@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import * as Schema_ from '../format/Schema_generated';\n+import * as Message_ from '../format/Message_generated';\n+import Field = Schema_.org.apache.arrow.flatbuf.Field;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+\n+import { Vector } from './vector';\n+import { Utf8Vector as Utf8VectorBase } from './utf8';\n+import { StructVector as StructVectorBase } from './struct';\n+import { DictionaryVector as DictionaryVectorBase } from './dictionary';\n+import {\n+    ListVector as ListVectorBase,\n+    BinaryVector as BinaryVectorBase,\n+    FixedSizeListVector as FixedSizeListVectorBase\n+} from './list';\n+\n+import {\n+    BoolVector as BoolVectorBase,\n+    Int8Vector as Int8VectorBase,\n+    Int16Vector as Int16VectorBase,\n+    Int32Vector as Int32VectorBase,\n+    Int64Vector as Int64VectorBase,\n+    Uint8Vector as Uint8VectorBase,\n+    Uint16Vector as Uint16VectorBase,\n+    Uint32Vector as Uint32VectorBase,\n+    Uint64Vector as Uint64VectorBase,\n+    Float16Vector as Float16VectorBase,\n+    Float32Vector as Float32VectorBase,\n+    Float64Vector as Float64VectorBase,\n+    Date32Vector as Date32VectorBase,\n+    Date64Vector as Date64VectorBase,\n+    Time32Vector as Time32VectorBase,\n+    Time64Vector as Time64VectorBase,\n+    DecimalVector as DecimalVectorBase,\n+    TimestampVector as TimestampVectorBase,\n+} from './numeric';\n+\n+import { nullableMixin, fieldMixin } from './traits';\n+\n+function MixinArrowTraits<T extends Vector<any>, TArgv>(\n+    Base: new (argv: TArgv) => T,\n+    Field: new (argv: TArgv & { field: Field, fieldNode: FieldNode }) => T,\n+    Nullable: new (argv: TArgv & { validity: Uint8Array }) => T,\n+    NullableField: new (argv: TArgv & { validity: Uint8Array, field: Field, fieldNode: FieldNode }) => T,\n+) {\n \n Review comment:\n   Ah makes sense, I figured there must be a good reason. This seems like a great application for some kind of preprocessor with macros or a code generator... but I don't know of any that would integrate well with JS build/dev tools\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T20:55:17.093+0000",
                    "updated": "2017-11-13T20:55:17.093+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250682",
                    "id": "16250682",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150721453\n \n \n\n ##########\n File path: js/test/arrows/json/datetime.json\n ##########\n @@ -0,0 +1,1091 @@\n+{\n \n Review comment:\n   @wesm yes, that would be ideal.\r\n   \r\n   <details><summary>I generated the JSON from the python integration tests like this (click to expand)</summary>\r\n   \r\n   ```python\r\n   from integration_test import generate_nested_case\r\n   from integration_test import generate_decimal_case\r\n   from integration_test import generate_datetime_case\r\n   from integration_test import generate_primitive_case\r\n   from integration_test import generate_dictionary_case\r\n   \r\n   generate_nested_case().write(\"../js/test/arrows/json/nested.json\")\r\n   generate_decimal_case().write(\"../js/test/arrows/json/decimal.json\")\r\n   generate_datetime_case().write(\"../js/test/arrows/json/datetime.json\")\r\n   generate_dictionary_case().write(\"../js/test/arrows/json/dictionary.json\")\r\n   generate_primitive_case([7, 10]).write(\"../js/test/arrows/json/primitive.json\")\r\n   generate_primitive_case([0, 0, 0]).write(\"../js/test/arrows/json/primitive-empty.json\")\r\n   ```\r\n   </details>\r\n   \r\n   <details><summary>Then I had to manually edit the \"primitive.json\" file to remove the \"binary_nullable\" and \"binary_nonnullable\" columns, because the C++ command fails if they're present (click to expand)\r\n   </summary>\r\n   \r\n   ```sh\r\n   $ ../cpp/build/release/json-integration-test \\\r\n     --integration --mode=JSON_TO_ARROW \\\r\n     --json=./test/arrows/json/primitive.json \\\r\n     --arrow=./test/arrows/cpp/file/primitive.arrow\r\n   Found schema: bool_nullable: bool\r\n   bool_nonnullable: bool not null\r\n   int8_nullable: int8\r\n   int8_nonnullable: int8 not null\r\n   int16_nullable: int16\r\n   int16_nonnullable: int16 not null\r\n   int32_nullable: int32\r\n   int32_nonnullable: int32 not null\r\n   int64_nullable: int64\r\n   int64_nonnullable: int64 not null\r\n   uint8_nullable: uint8\r\n   uint8_nonnullable: uint8 not null\r\n   uint16_nullable: uint16\r\n   uint16_nonnullable: uint16 not null\r\n   uint32_nullable: uint32\r\n   uint32_nonnullable: uint32 not null\r\n   uint64_nullable: uint64\r\n   uint64_nonnullable: uint64 not null\r\n   float32_nullable: float\r\n   float32_nonnullable: float not null\r\n   float64_nullable: double\r\n   float64_nonnullable: double not null\r\n   binary_nullable: binary\r\n   binary_nonnullable: binary not null\r\n   utf8_nullable: string\r\n   utf8_nonnullable: string not null\r\n   Error message: Invalid: Encountered non-hex digit\r\n   ```\r\n   </details>\r\n   \r\n   The unit tests rely heavily on [snapshot testing](https://facebook.github.io/jest/docs/en/snapshot-testing.html) to validate the actual values in the vectors. I manually validated the data in the snapshots against the buffers using pyarrow and pandas, but that approach won't scale. Typically the snapshot files get checked into version control, but now that we have 11k snapshots, the snapshot files are around 21mb. I removed them from the repo b/c we don't want huge files. Now the CI server generates the snapshots once up front, then validates the compilation targets against those.\r\n   \r\n   This will catch any cases where compiling the JS to different targets leads to failures (e.g. if the minifiers mangle names they weren't supposed to), but since we're not checking in the snapshot files, the CI server won't be able to tell us if a new PR causes a snapshot test to break. We _can_ know that if we run the tests locally, but we can't rely us running the tests for each PR locally before merging.\r\n   \r\n   I'm a bit torn here. On the one hand, I don't want to check in 21mb worth of tests to source control. On the other hand, I don't want to hand-write the 11k assertions that the snapshot tests represent (and would also presumably be many-MBs worth of tests anyway).\r\n   \r\n   I believe git compresses files across the network? And if space-on-disk is an issue, I could add a post-clone script to automatically compress the snapshot files after checkout (about 3mb gzipped). Jest doesn't work with compressed snapshot files out of the box, but I could add some steps to the test runner to decompress the snapshots before running.\r\n   \r\n   To your point about using the C++/Java writers to convert the JSON to Arrow buffers on the fly, we should 100% do that. This PR is marginally better since we can at least regenerate the arrow files easily enough, but ideally we don't have them at all and we can pipe them to the node process on the fly, or at a minimum, write to files then clean up after. We'll want a mode for local dev that skips this step, as incurring the JVM overhead to convert JSON to Arrow files is painful for debugging.\r\n   \r\n   I left the code in there (commented out) to draw attention to this idea. I was on a plane when I checked this in and didn't have bandwidth to debug the CI scripts, otherwise I would have. We can pass the paths to the C++ and Java executables as CLI and/or env variables no problem.\r\n   \r\n   I wasn't sure if the executables were already available in CI, or whether I would need to build them before running the JS tests. Building the C++ and Java projects in order to run the JS tests doesn't seem ideal, but I'm fine doing it if we have to.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T02:17:22.973+0000",
                    "updated": "2017-11-14T02:17:22.973+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250695",
                    "id": "16250695",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150723322\n \n \n\n ##########\n File path: js/src/vector/arrow.ts\n ##########\n @@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import * as Schema_ from '../format/Schema_generated';\n+import * as Message_ from '../format/Message_generated';\n+import Field = Schema_.org.apache.arrow.flatbuf.Field;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+\n+import { Vector } from './vector';\n+import { Utf8Vector as Utf8VectorBase } from './utf8';\n+import { StructVector as StructVectorBase } from './struct';\n+import { DictionaryVector as DictionaryVectorBase } from './dictionary';\n+import {\n+    ListVector as ListVectorBase,\n+    BinaryVector as BinaryVectorBase,\n+    FixedSizeListVector as FixedSizeListVectorBase\n+} from './list';\n+\n+import {\n+    BoolVector as BoolVectorBase,\n+    Int8Vector as Int8VectorBase,\n+    Int16Vector as Int16VectorBase,\n+    Int32Vector as Int32VectorBase,\n+    Int64Vector as Int64VectorBase,\n+    Uint8Vector as Uint8VectorBase,\n+    Uint16Vector as Uint16VectorBase,\n+    Uint32Vector as Uint32VectorBase,\n+    Uint64Vector as Uint64VectorBase,\n+    Float16Vector as Float16VectorBase,\n+    Float32Vector as Float32VectorBase,\n+    Float64Vector as Float64VectorBase,\n+    Date32Vector as Date32VectorBase,\n+    Date64Vector as Date64VectorBase,\n+    Time32Vector as Time32VectorBase,\n+    Time64Vector as Time64VectorBase,\n+    DecimalVector as DecimalVectorBase,\n+    TimestampVector as TimestampVectorBase,\n+} from './numeric';\n+\n+import { nullableMixin, fieldMixin } from './traits';\n+\n+function MixinArrowTraits<T extends Vector<any>, TArgv>(\n+    Base: new (argv: TArgv) => T,\n+    Field: new (argv: TArgv & { field: Field, fieldNode: FieldNode }) => T,\n+    Nullable: new (argv: TArgv & { validity: Uint8Array }) => T,\n+    NullableField: new (argv: TArgv & { validity: Uint8Array, field: Field, fieldNode: FieldNode }) => T,\n+) {\n \n Review comment:\n   @TheNeuralBit yeah we could use [babel-codegen](https://github.com/kentcdodds/babel-plugin-codegen), [babel-preval](https://github.com/kentcdodds/babel-plugin-preval), or [babel-macros](https://github.com/kentcdodds/babel-macros) if we want. I was hoping to avoid babel if possible, but since we're webpacking the es2015+ UMD bundles anyway, it wouldn't be too much of a headache.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T02:32:36.484+0000",
                    "updated": "2017-11-14T02:32:36.484+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250718",
                    "id": "16250718",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150725447\n \n \n\n ##########\n File path: js/src/vector/arrow.ts\n ##########\n @@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import * as Schema_ from '../format/Schema_generated';\n+import * as Message_ from '../format/Message_generated';\n+import Field = Schema_.org.apache.arrow.flatbuf.Field;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+\n+import { Vector } from './vector';\n+import { Utf8Vector as Utf8VectorBase } from './utf8';\n+import { StructVector as StructVectorBase } from './struct';\n+import { DictionaryVector as DictionaryVectorBase } from './dictionary';\n+import {\n+    ListVector as ListVectorBase,\n+    BinaryVector as BinaryVectorBase,\n+    FixedSizeListVector as FixedSizeListVectorBase\n+} from './list';\n+\n+import {\n+    BoolVector as BoolVectorBase,\n+    Int8Vector as Int8VectorBase,\n+    Int16Vector as Int16VectorBase,\n+    Int32Vector as Int32VectorBase,\n+    Int64Vector as Int64VectorBase,\n+    Uint8Vector as Uint8VectorBase,\n+    Uint16Vector as Uint16VectorBase,\n+    Uint32Vector as Uint32VectorBase,\n+    Uint64Vector as Uint64VectorBase,\n+    Float16Vector as Float16VectorBase,\n+    Float32Vector as Float32VectorBase,\n+    Float64Vector as Float64VectorBase,\n+    Date32Vector as Date32VectorBase,\n+    Date64Vector as Date64VectorBase,\n+    Time32Vector as Time32VectorBase,\n+    Time64Vector as Time64VectorBase,\n+    DecimalVector as DecimalVectorBase,\n+    TimestampVector as TimestampVectorBase,\n+} from './numeric';\n+\n+import { nullableMixin, fieldMixin } from './traits';\n+\n+function MixinArrowTraits<T extends Vector<any>, TArgv>(\n+    Base: new (argv: TArgv) => T,\n+    Field: new (argv: TArgv & { field: Field, fieldNode: FieldNode }) => T,\n+    Nullable: new (argv: TArgv & { validity: Uint8Array }) => T,\n+    NullableField: new (argv: TArgv & { validity: Uint8Array, field: Field, fieldNode: FieldNode }) => T,\n+) {\n \n Review comment:\n   @TheNeuralBit but if we do want to do more compilation steps beyond what the TS compiler does, it'd be neat to also run [preval on the flatbuffers generated code](https://gist.github.com/trxcllnt/84bb4893b6db957925ed7625fd0f34e5)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T02:51:12.101+0000",
                    "updated": "2017-11-14T02:51:12.101+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250723",
                    "id": "16250723",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150725447\n \n \n\n ##########\n File path: js/src/vector/arrow.ts\n ##########\n @@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import * as Schema_ from '../format/Schema_generated';\n+import * as Message_ from '../format/Message_generated';\n+import Field = Schema_.org.apache.arrow.flatbuf.Field;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+\n+import { Vector } from './vector';\n+import { Utf8Vector as Utf8VectorBase } from './utf8';\n+import { StructVector as StructVectorBase } from './struct';\n+import { DictionaryVector as DictionaryVectorBase } from './dictionary';\n+import {\n+    ListVector as ListVectorBase,\n+    BinaryVector as BinaryVectorBase,\n+    FixedSizeListVector as FixedSizeListVectorBase\n+} from './list';\n+\n+import {\n+    BoolVector as BoolVectorBase,\n+    Int8Vector as Int8VectorBase,\n+    Int16Vector as Int16VectorBase,\n+    Int32Vector as Int32VectorBase,\n+    Int64Vector as Int64VectorBase,\n+    Uint8Vector as Uint8VectorBase,\n+    Uint16Vector as Uint16VectorBase,\n+    Uint32Vector as Uint32VectorBase,\n+    Uint64Vector as Uint64VectorBase,\n+    Float16Vector as Float16VectorBase,\n+    Float32Vector as Float32VectorBase,\n+    Float64Vector as Float64VectorBase,\n+    Date32Vector as Date32VectorBase,\n+    Date64Vector as Date64VectorBase,\n+    Time32Vector as Time32VectorBase,\n+    Time64Vector as Time64VectorBase,\n+    DecimalVector as DecimalVectorBase,\n+    TimestampVector as TimestampVectorBase,\n+} from './numeric';\n+\n+import { nullableMixin, fieldMixin } from './traits';\n+\n+function MixinArrowTraits<T extends Vector<any>, TArgv>(\n+    Base: new (argv: TArgv) => T,\n+    Field: new (argv: TArgv & { field: Field, fieldNode: FieldNode }) => T,\n+    Nullable: new (argv: TArgv & { validity: Uint8Array }) => T,\n+    NullableField: new (argv: TArgv & { validity: Uint8Array, field: Field, fieldNode: FieldNode }) => T,\n+) {\n \n Review comment:\n   @TheNeuralBit but if we do want to do more compilation steps beyond what the TS compiler does, it'd be neat to also run [prepack on the flatbuffers generated code](https://gist.github.com/trxcllnt/84bb4893b6db957925ed7625fd0f34e5)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T02:54:33.375+0000",
                    "updated": "2017-11-14T02:54:33.375+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250730",
                    "id": "16250730",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344130863\n \n \n   > I'm a bit torn here. On the one hand, I don't want to check in 21mb worth of tests to source control. On the other hand, I don't want to hand-write the 11k assertions that the snapshot tests represent (and would also presumably be many-MBs worth of tests anyway).\r\n   \r\n   > I believe git compresses files across the network? And if space-on-disk is an issue, I could add a post-clone script to automatically compress the snapshot files after checkout (about 3mb gzipped). Jest doesn't work with compressed snapshot files out of the box, but I could add some steps to the test runner to decompress the snapshots before running.\r\n   \r\n   I guess I'm not quite understanding what snapshot tests accomplish here that normal array comparisons would not. In Java and C++ we have functions that compare the contents of arrays. So when you say hand-writing the snapshot test assertions, what's being tested and why is that the only way to test that behavior? Is there a concern that a programmatic comparison like\r\n   \r\n   https://github.com/apache/arrow/blob/master/cpp/src/arrow/ipc/json-integration-test.cc#L180\r\n   \r\n   might not be as strong of an assertion as a UI-based test (what the values from the arrays would actually appear as in the DOM)?\r\n   \r\n   Having the possibility of a single PR bloating the git history by whatever the snap files gzip down to doesn't seem like a good idea. Even having large diffs as the result of automatically generated files on commit isn't ideal\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T02:57:34.361+0000",
                    "updated": "2017-11-14T02:57:34.361+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250732",
                    "id": "16250732",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150726475\n \n \n\n ##########\n File path: js/gulp/test-task.js\n ##########\n @@ -42,3 +54,78 @@ const testTask = ((cache, execArgv, testOptions) => memoizeTask(cache, function\n \n module.exports = testTask;\n module.exports.testTask = testTask;\n+module.exports.cleanTestData = cleanTestData;\n+module.exports.createTestData = createTestData;\n+\n+async function cleanTestData() {\n+    return await del([\n+        `${path.resolve('./test/arrows/cpp')}/**`,\n+        `${path.resolve('./test/arrows/java')}/**`,\n+    ]);\n+}\n+\n+async function createTestData() {\n+    const base = path.resolve('./test/arrows');\n+    await mkdirp(path.join(base, 'cpp/file'));\n+    await mkdirp(path.join(base, 'java/file'));\n+    await mkdirp(path.join(base, 'cpp/stream'));\n+    await mkdirp(path.join(base, 'java/stream'));\n+    const errors = [];\n+    const names = await glob(path.join(base, 'json/*.json'));\n+    for (let jsonPath of names) {\n+        const name = path.parse(path.basename(jsonPath)).name;\n+        const arrowCppFilePath = path.join(base, 'cpp/file', `${name}.arrow`);\n+        const arrowJavaFilePath = path.join(base, 'java/file', `${name}.arrow`);\n+        const arrowCppStreamPath = path.join(base, 'cpp/stream', `${name}.arrow`);\n+        const arrowJavaStreamPath = path.join(base, 'java/stream', `${name}.arrow`);\n+        try {\n+            await generateCPPFile(jsonPath, arrowCppFilePath);\n+            await generateCPPStream(arrowCppFilePath, arrowCppStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+        try {\n+            await generateJavaFile(jsonPath, arrowJavaFilePath);\n+            await generateJavaStream(arrowJavaFilePath, arrowJavaStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+    }\n+    if (errors.length) {\n+        console.error(errors.join(`\\n`));\n+        process.exit(1);\n+    }\n+}\n+\n+async function generateCPPFile(jsonPath, filePath) {\n+    await rimraf(filePath);\n+    return await exec(\n+        `../cpp/build/release/json-integration-test ${\n+        `--integration --mode=JSON_TO_ARROW`} ${\n+        `--json=${path.resolve(jsonPath)} --arrow=${filePath}`}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateCPPStream(filePath, streamPath) {\n+    await rimraf(streamPath);\n+    return await exec(\n+        `../cpp/build/release/file-to-stream ${filePath} > ${streamPath}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateJavaFile(jsonPath, filePath) {\n+    await rimraf(filePath);\n+    return await exec(\n+        `java -cp ../java/tools/target/arrow-tools-0.8.0-SNAPSHOT-jar-with-dependencies.jar ${\n+        `org.apache.arrow.tools.Integration -c JSON_TO_ARROW`} ${\n+        `-j ${path.resolve(jsonPath)} -a ${filePath}`}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateJavaStream(filePath, streamPath) {\n+    await rimraf(streamPath);\n+    return await exec(\n+        `java -cp ../java/tools/target/arrow-tools-0.8.0-SNAPSHOT-jar-with-dependencies.jar ${\n \n Review comment:\n   I included this in my [response below](https://github.com/apache/arrow/pull/1294#discussion_r150721453)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T02:59:57.278+0000",
                    "updated": "2017-11-14T02:59:57.278+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250733",
                    "id": "16250733",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150726479\n \n \n\n ##########\n File path: js/gulp/test-task.js\n ##########\n @@ -42,3 +54,78 @@ const testTask = ((cache, execArgv, testOptions) => memoizeTask(cache, function\n \n module.exports = testTask;\n module.exports.testTask = testTask;\n+module.exports.cleanTestData = cleanTestData;\n+module.exports.createTestData = createTestData;\n+\n+async function cleanTestData() {\n+    return await del([\n+        `${path.resolve('./test/arrows/cpp')}/**`,\n+        `${path.resolve('./test/arrows/java')}/**`,\n+    ]);\n+}\n+\n+async function createTestData() {\n+    const base = path.resolve('./test/arrows');\n+    await mkdirp(path.join(base, 'cpp/file'));\n+    await mkdirp(path.join(base, 'java/file'));\n+    await mkdirp(path.join(base, 'cpp/stream'));\n+    await mkdirp(path.join(base, 'java/stream'));\n+    const errors = [];\n+    const names = await glob(path.join(base, 'json/*.json'));\n+    for (let jsonPath of names) {\n+        const name = path.parse(path.basename(jsonPath)).name;\n+        const arrowCppFilePath = path.join(base, 'cpp/file', `${name}.arrow`);\n+        const arrowJavaFilePath = path.join(base, 'java/file', `${name}.arrow`);\n+        const arrowCppStreamPath = path.join(base, 'cpp/stream', `${name}.arrow`);\n+        const arrowJavaStreamPath = path.join(base, 'java/stream', `${name}.arrow`);\n+        try {\n+            await generateCPPFile(jsonPath, arrowCppFilePath);\n+            await generateCPPStream(arrowCppFilePath, arrowCppStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+        try {\n+            await generateJavaFile(jsonPath, arrowJavaFilePath);\n+            await generateJavaStream(arrowJavaFilePath, arrowJavaStreamPath);\n+        } catch (e) { errors.push(e.message); }\n+    }\n+    if (errors.length) {\n+        console.error(errors.join(`\\n`));\n+        process.exit(1);\n+    }\n+}\n+\n+async function generateCPPFile(jsonPath, filePath) {\n+    await rimraf(filePath);\n+    return await exec(\n+        `../cpp/build/release/json-integration-test ${\n+        `--integration --mode=JSON_TO_ARROW`} ${\n+        `--json=${path.resolve(jsonPath)} --arrow=${filePath}`}`,\n+        { maxBuffer: Math.pow(2, 53) - 1 }\n+    );\n+}\n+\n+async function generateCPPStream(filePath, streamPath) {\n+    await rimraf(streamPath);\n+    return await exec(\n+        `../cpp/build/release/file-to-stream ${filePath} > ${streamPath}`,\n \n Review comment:\n   I included this in my [response below](https://github.com/apache/arrow/pull/1294#discussion_r150721453)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T02:59:59.921+0000",
                    "updated": "2017-11-14T02:59:59.921+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250761",
                    "id": "16250761",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150728634\n \n \n\n ##########\n File path: js/npm-release.sh\n ##########\n @@ -17,10 +17,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-npm run clean\n-npm run lint\n-npm run build\n-npm run test\n-npm --no-git-tag-version version patch &>/dev/null\n-npm run bundle\n-npm run lerna:publish\n\\ No newline at end of file\n+bump=${1:-patch} && echo \"semantic-version bump: $bump\"\n+\n+run-s --silent lint build test\n+lerna publish --yes --skip-git --cd-version $bump --force-publish=*\n \n Review comment:\n   @wesm That makes sense. The way I have things set up, we compile and publish multiple modules to npm:\r\n   - one [large-ish module](https://www.npmjs.com/package/apache-arrow) that you can get via `npm install apache-arrow`\r\n   - the rest as smaller/specialized modules under the [`@apache-arrow`](https://www.npmjs.com/org/apache-arrow) [npm organization](https://www.npmjs.com/docs/orgs/), which can be installed via the formula `npm install @apache-arrow/<target-name>`. For example, `npm install @apache-arrow/es5-cjs` installs the slimmed down ES5/CommonJS target\r\n   \r\n   The `npm run build` command compiles all the output targets to the (gitignored) `targets` directory. The `lerna publish --yes --skip-git --cd-version $bump --force-publish=*` command publishes all the targets to npm. So from the sound of it, all we need to do is tar up the `targets` directory with a shell script that installs and runs `lerna publish`, and we're good to go? If so, I can do that tonight.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T03:19:24.959+0000",
                    "updated": "2017-11-14T03:19:24.959+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250803",
                    "id": "16250803",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344140344\n \n \n   @wesm the Jest docs on snapshot testing highlight its utility testing React components, but it's really just a form of test code generation. The tests evaluate [all combinations](https://github.com/trxcllnt/arrow/blob/generate-js-test-files/js/test/table-tests.ts#L22) of `source lib x arrow format` (in reality: `[c++, java] x [file, stream]`) for each of the generated files (nested, simple, decimal, datetime, primitive, primitive-empty, dictionary, and struct_example), so there are quite a few assertions.\r\n   \r\n   <details><summary>\r\n   Snapshots capture a bit of runtime type info that would otherwise have to be asserted explicitly, for example that calling `uint64Vector.get(i)` returns a `Uint32Array` of two elements:</summary>\r\n   \r\n   ```\r\n   exports[`readBuffers cpp stream primitive reads each batch as an Array of Vectors 167`] = `\r\n   Uint32Array [\r\n     12840890,\r\n     0,\r\n   ]\r\n   `;\r\n   ```\r\n   </details>\r\n   \r\n   <details><summary>\r\n   They're also helpful catching regressions (or comparing against pandas) in `Table.toString()`:\r\n   </summary><p>\r\n   \r\n   ```\r\n   exports[`Table cpp file nested toString({ index: true }) prints a pretty Table with an Index column 1`] = `\r\n   \"Index,                            list_nullable,        struct_nullable\r\n       0,                                     null,       [null,\\\\\"tmo7qBM\\\\\"]\r\n       1,                             [1685103474],      [-583988484,null]\r\n       2,                             [1981297353], [-749108100,\\\\\"yGRfkmw\\\\\"]\r\n       3,     [-2032422645,-2111456179,-895490422],       [820115077,null]\r\n       4,                                     null,                   null\r\n       5,             [null,-434891054,-864560986],                   null\r\n       6,                                     null,  [986507083,\\\\\"U6xvhr7\\\\\"]\r\n       7,                                     null,                   null\r\n       8,                                     null,            [null,null]\r\n       9,                                     null,                   null\r\n      10,                             [-498865952],                   null\r\n      11,                                     null,       [null,\\\\\"ctyWPJf\\\\\"]\r\n      12,                                     null,            [null,null]\r\n      13, [-1076160763,-792439045,-656549144,null],                   null\r\n      14,                                     null,      [1234093448,null]\r\n      15,                   [null,null,1882910932],                   null\r\n      16,                                     null,  [934007407,\\\\\"9QUyEm5\\\\\"]\"\r\n   `;\r\n   ```\r\n   </p></details>\r\n   <h6></h6>\r\n   \r\n   That said, it sounds like the JSON reader should be able to do most of this validation.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T04:06:07.730+0000",
                    "updated": "2017-11-14T04:06:07.730+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250810",
                    "id": "16250810",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150733769\n \n \n\n ##########\n File path: js/npm-release.sh\n ##########\n @@ -17,10 +17,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-npm run clean\n-npm run lint\n-npm run build\n-npm run test\n-npm --no-git-tag-version version patch &>/dev/null\n-npm run bundle\n-npm run lerna:publish\n\\ No newline at end of file\n+bump=${1:-patch} && echo \"semantic-version bump: $bump\"\n+\n+run-s --silent lint build test\n+lerna publish --yes --skip-git --cd-version $bump --force-publish=*\n \n Review comment:\n   Seems reasonable. The other side of this is creating the signed tarball for voting, and making sure the tarball is sufficient for the post-release upload to NPM. We'll need to copy some files from the root directory (like the license and notice files). I can help with this\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T04:13:49.753+0000",
                    "updated": "2017-11-14T04:13:49.753+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250811",
                    "id": "16250811",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344140344\n \n \n   @wesm the Jest docs on snapshot testing highlight its utility testing React components, but it's really just a form of test code generation. The tests evaluate [all combinations](https://github.com/trxcllnt/arrow/blob/generate-js-test-files/js/test/table-tests.ts#L22) of `source lib x arrow format` (in reality: `[c++, java] x [file, stream]`) for each of the generated files (nested, simple, decimal, datetime, primitive, primitive-empty, dictionary, and struct_example), so there are quite a few assertions.\r\n   \r\n   <details><summary>\r\n   Snapshots capture a bit of runtime type info that would otherwise have to be asserted explicitly, for example that calling `uint64Vector.get(i)` returns a `Uint32Array` of two elements:</summary>\r\n   \r\n   ```\r\n   exports[`readBuffers cpp stream primitive reads each batch as an Array of Vectors 167`] = `\r\n   Uint32Array [\r\n     12840890,\r\n     0,\r\n   ]\r\n   `;\r\n   ```\r\n   </details>\r\n   \r\n   <details><summary>\r\n   They're also helpful catching regressions (or comparing against pandas) in `Table.toString()`:\r\n   </summary><p>\r\n   \r\n   ```\r\n   exports[`Table cpp file nested toString({ index: true }) prints a pretty Table with an Index column 1`] = `\r\n   \"Index,                            list_nullable,        struct_nullable\r\n       0,                                     null,       [null,\\\\\"tmo7qBM\\\\\"]\r\n       1,                             [1685103474],      [-583988484,null]\r\n       2,                             [1981297353], [-749108100,\\\\\"yGRfkmw\\\\\"]\r\n       3,     [-2032422645,-2111456179,-895490422],       [820115077,null]\r\n       4,                                     null,                   null\r\n       5,             [null,-434891054,-864560986],                   null\r\n       6,                                     null,  [986507083,\\\\\"U6xvhr7\\\\\"]\r\n       7,                                     null,                   null\r\n       8,                                     null,            [null,null]\r\n       9,                                     null,                   null\r\n      10,                             [-498865952],                   null\r\n      11,                                     null,       [null,\\\\\"ctyWPJf\\\\\"]\r\n      12,                                     null,            [null,null]\r\n      13, [-1076160763,-792439045,-656549144,null],                   null\r\n      14,                                     null,      [1234093448,null]\r\n      15,                   [null,null,1882910932],                   null\r\n      16,                                     null,  [934007407,\\\\\"9QUyEm5\\\\\"]\"\r\n   `;\r\n   ```\r\n   </p></details>\r\n   <h6></h6>\r\n   \r\n   It also gives reviewers a chance to see what the tests produce, so if `get` on a Uint64Array starts returning a `Long` object instead of a `Uint32Array`, we can flag that in a code review. That said, it sounds like the JSON reader should be able to do most of this validation.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T04:13:50.399+0000",
                    "updated": "2017-11-14T04:13:50.399+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250826",
                    "id": "16250826",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344143063\n \n \n   It sounds like this is useful for catching code regressions from PR to PR, but it clashes with my sensibilities about testing data libraries, which is that we should have explicit unit tests asserting the correct behavior. In the example you gave (\"Snapshots capture a bit of runtime type info that would otherwise have to be asserted explicitly, for example that calling `uint64Vector.get(i)` returns a `Uint32Array` of two elements:\"), my prior would be that this behavior should be asserted in a unit test. \r\n   \r\n   I'm no expert, so there may be things I'm missing -- are some of the test assertions dependent on the flavor of the deployment target?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T04:28:35.518+0000",
                    "updated": "2017-11-14T04:28:35.518+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250841",
                    "id": "16250841",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150736649\n \n \n\n ##########\n File path: js/npm-release.sh\n ##########\n @@ -17,10 +17,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-npm run clean\n-npm run lint\n-npm run build\n-npm run test\n-npm --no-git-tag-version version patch &>/dev/null\n-npm run bundle\n-npm run lerna:publish\n\\ No newline at end of file\n+bump=${1:-patch} && echo \"semantic-version bump: $bump\"\n+\n+run-s --silent lint build test\n+lerna publish --yes --skip-git --cd-version $bump --force-publish=*\n \n Review comment:\n   The build also copies extra files from the `js` folder into each of the packages, so we just need to change [this line](https://github.com/apache/arrow/blob/master/js/gulp/util.js#L30) to `['../LICENSE.txt', '../NOTICE.txt', 'README.md']`. Do we also need to add the info in [`js/LICENSE`](https://github.com/apache/arrow/blob/master/js/LICENSE) to the top-level notice.txt? \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T04:47:23.289+0000",
                    "updated": "2017-11-14T04:47:23.289+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250874",
                    "id": "16250874",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344148302\n \n \n   Snapshots are just a different, data-centric way of writing assertions. Give it a lot of test data, validate the tests results once, then compare diffs after that. If you can eyeball test results and know whether it works, then the computer codegens all the dreadful bits about comparing types, values, etc. (even when it's late and you might otherwise forget to test an edge case).\r\n   \r\n   > I'm no expert, so there may be things I'm missing -- are some of the test assertions dependent on the flavor of the deployment target?\r\n   \r\n   No, the assertions should be identical regardless of the compilation target -- they're generated [once at the beginning](https://travis-ci.org/apache/arrow/jobs/301012418#L1177), then all the targets are compared against the same snapshots.\r\n   \r\n   I may have mentioned this before, but they've also helped catching minification bugs. Like before when we did return Long instances, Closure Compiler minified the class name down to something like \"zw\", so the snapshot tests failed for just the ES5/UMD target.\r\n   \r\n   But on the whole I can't argue with your position. All I can say is I'm proably pretty lazy by normal standards, so I try to make my computer do as much of my homework as possible.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T05:09:49.850+0000",
                    "updated": "2017-11-14T05:09:49.850+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250885",
                    "id": "16250885",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344149960\n \n \n   Maybe another way to phrase it is, disk and network are cheap, my/our time is not. ;-)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T05:22:39.165+0000",
                    "updated": "2017-11-14T05:22:39.165+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16250894",
                    "id": "16250894",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344149960\n \n \n   Maybe another way to phrase it is, disk and network are cheap, my/our time is not. ;-)\r\n   \r\n   edit: shit, I misread the snapshot count; we have _113,940_ snapshots, not 11,394\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T05:30:03.378+0000",
                    "updated": "2017-11-14T05:30:03.378+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16251733",
                    "id": "16251733",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150897358\n \n \n\n ##########\n File path: js/npm-release.sh\n ##########\n @@ -17,10 +17,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-npm run clean\n-npm run lint\n-npm run build\n-npm run test\n-npm --no-git-tag-version version patch &>/dev/null\n-npm run bundle\n-npm run lerna:publish\n\\ No newline at end of file\n+bump=${1:-patch} && echo \"semantic-version bump: $bump\"\n+\n+run-s --silent lint build test\n+lerna publish --yes --skip-git --cd-version $bump --force-publish=*\n \n Review comment:\n   Yes, what's in `js/LICENSE` should go in the top level `LICENSE.txt` at the bottom. Then we can copy that one license into the JS tarball\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T17:02:46.615+0000",
                    "updated": "2017-11-14T17:02:46.615+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16252166",
                    "id": "16252166",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on a change in pull request #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#discussion_r150960731\n \n \n\n ##########\n File path: js/npm-release.sh\n ##########\n @@ -17,10 +17,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-npm run clean\n-npm run lint\n-npm run build\n-npm run test\n-npm --no-git-tag-version version patch &>/dev/null\n-npm run bundle\n-npm run lerna:publish\n\\ No newline at end of file\n+bump=${1:-patch} && echo \"semantic-version bump: $bump\"\n+\n+run-s --silent lint build test\n+lerna publish --yes --skip-git --cd-version $bump --force-publish=*\n \n Review comment:\n   @wesm done\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T20:58:04.772+0000",
                    "updated": "2017-11-14T20:58:04.772+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16252557",
                    "id": "16252557",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344420875\n \n \n   > Snapshots are just a different, data-centric way of writing assertions. Give it a lot of test data, validate the tests results once, then compare diffs after that. If you can eyeball test results and know whether it works, then the computer codegens all the dreadful bits about comparing types, values, etc. (even when it's late and you might otherwise forget to test an edge case).\r\n   \r\n   This \"validate the tests results once\" part is where I'm getting lost. How do you know whether anything is correct if you don't write down what you expect to be true? I can help with rallying the troops to write more tests. I am a bit bandwidth constrained at the moment with all the 0.8.0 stuff in progress, but I am hopeful that some others can get involved and this will also help with beating on the API and finding rough edges. cc @leifwalsh @scottdraves \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T22:29:05.284+0000",
                    "updated": "2017-11-14T22:29:05.284+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16252658",
                    "id": "16252658",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344431051\n \n \n   > @wesm This \"validate the tests results once\" part is where I'm getting lost. How do you know whether anything is correct if you don't write down what you expect to be true?\r\n   \r\n   Ah right, in this case the JSON files are the initial source of truth. In this case I compared the snapshots against the Arrow files read via pandas/pyarrow, and it looked correct. After this (assuming stable test data), the snapshots are the source of truth. If we decide to change the test data, then we have to re-validate the snapshots are what we expect them to be.\r\n   \r\n   But I want to stress, I'm not against doing it differently. I'm also bandwidth constrained, and snapshots get high coverage with minimal effort. It sounds like the JSON reader should provide all the same benefits as snapshot testing. From that perspective, I see snapshots as a stop-gap until the JS JSON reader is done (unless there's a way we can validate columns with the C++ or Java JSON readers from the JS tests?)\r\n   \r\n   With that in mind, I agree it's best not to commit the snapshots to the git history, if we're just going to remove them once the JSON reader is ready. In the interim, I don't mind validating any new JS PR's against my local snapshots, as the volume of JS PR's isn't that high yet.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T23:10:12.304+0000",
                    "updated": "2017-11-14T23:10:12.304+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16252659",
                    "id": "16252659",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344431051\n \n \n   > @wesm This \"validate the tests results once\" part is where I'm getting lost. How do you know whether anything is correct if you don't write down what you expect to be true?\r\n   \r\n   Ah right, in this case the JSON files are the initial source of truth. I compared the snapshots against the Arrow files read via pandas/pyarrow, and it looked correct. After this (assuming stable test data), the snapshots are the source of truth. If we decide to change the test data, then we have to re-validate the snapshots are what we expect them to be.\r\n   \r\n   But I want to stress, I'm not against doing it differently. I'm also bandwidth constrained, and snapshots get high coverage with minimal effort. It sounds like the JSON reader should provide all the same benefits as snapshot testing. From that perspective, I see snapshots as a stop-gap until the JS JSON reader is done (unless there's a way we can validate columns with the C++ or Java JSON readers from the JS tests?)\r\n   \r\n   With that in mind, I agree it's best not to commit the snapshots to the git history, if we're just going to remove them once the JSON reader is ready. In the interim, I don't mind validating any new JS PR's against my local snapshots, as the volume of JS PR's isn't that high yet.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T23:10:25.113+0000",
                    "updated": "2017-11-14T23:10:25.113+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16252868",
                    "id": "16252868",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344472045\n \n \n   Yes, definitely, we are in agreement. We should push for a JSON reader ASAP -- following the C++ reader as a guide, I do not think it is that big of a project, to be honest, when you consider all the hardship of dealing with parsing JSON in C++, which is a complete non-issue in JavaScript. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-15T03:06:10.626+0000",
                    "updated": "2017-11-15T03:06:10.626+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16252903",
                    "id": "16252903",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344477823\n \n \n   @wesm that sounds good to me. In the meantime can we get this PR merged + finish ASF release scripts, and push a new version to npm? I'm at the point where not having the latest on npm is going to be a problem for projects at work soon, @TheNeuralBit may be feeling this too.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-15T03:49:36.442+0000",
                    "updated": "2017-11-15T03:49:36.442+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16252920",
                    "id": "16252920",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-344481293\n \n \n   That's good for me. As soon as the release scripts are good to go I can conduct the release vote on the mailing list. We can close the vote in less than the usual 72 hours so long as we get 3 PMC votes. So we'll need a quick \"here's how to verify the release candidate\" blurb to direct people do when we start the release vote\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-15T04:17:50.266+0000",
                    "updated": "2017-11-15T04:17:50.266+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16256019",
                    "id": "16256019",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345074775\n \n \n   Does anything still need to be done on this branch? If we are still not close to being able to cut a JS release by early next week I will rearrange my priorities to help out \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-16T21:53:22.021+0000",
                    "updated": "2017-11-16T21:53:22.021+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16256022",
                    "id": "16256022",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345075467\n \n \n   @wesm nope, only thing left to do is the ASF release scripts I think\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-16T21:56:10.912+0000",
                    "updated": "2017-11-16T21:56:10.912+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16257568",
                    "id": "16257568",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345364755\n \n \n   @wesm I understand you may be busy, so do you mind if I go ahead and merge this?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-17T21:04:07.537+0000",
                    "updated": "2017-11-17T21:04:07.537+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16257587",
                    "id": "16257587",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345368042\n \n \n   Sorry I have been dragging my feet because I\u2019m not really on board with checking in data files that can be generated as part of CI. Per Slack conversation it seems there are some roadblocks so I\u2019m available as needed today and tomorrow to get this sorted out\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-17T21:19:11.638+0000",
                    "updated": "2017-11-17T21:19:11.638+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16257644",
                    "id": "16257644",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345377333\n \n \n   Sorry that I missed the thing. I will figure out what's going on here:\r\n   \r\n   > Then I had to manually edit the \"primitive.json\" file to remove the \"binary_nullable\" and \"binary_nonnullable\" columns, because the C++ command fails if they're present (click to expand)\r\n   \r\n   ```\r\n   $ ../cpp/build/release/json-integration-test \\\r\n     --integration --mode=JSON_TO_ARROW \\\r\n     --json=./test/arrows/json/primitive.json \\\r\n     --arrow=./test/arrows/cpp/file/primitive.arrow\r\n   Found schema: bool_nullable: bool\r\n   bool_nonnullable: bool not null\r\n   int8_nullable: int8\r\n   int8_nonnullable: int8 not null\r\n   int16_nullable: int16\r\n   int16_nonnullable: int16 not null\r\n   int32_nullable: int32\r\n   int32_nonnullable: int32 not null\r\n   int64_nullable: int64\r\n   int64_nonnullable: int64 not null\r\n   uint8_nullable: uint8\r\n   uint8_nonnullable: uint8 not null\r\n   uint16_nullable: uint16\r\n   uint16_nonnullable: uint16 not null\r\n   uint32_nullable: uint32\r\n   uint32_nonnullable: uint32 not null\r\n   uint64_nullable: uint64\r\n   uint64_nonnullable: uint64 not null\r\n   float32_nullable: float\r\n   float32_nonnullable: float not null\r\n   float64_nullable: double\r\n   float64_nonnullable: double not null\r\n   binary_nullable: binary\r\n   binary_nonnullable: binary not null\r\n   utf8_nullable: string\r\n   utf8_nonnullable: string not null\r\n   Error message: Invalid: Encountered non-hex digit\r\n   ```\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-17T22:00:32.777+0000",
                    "updated": "2017-11-17T22:00:32.777+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16257649",
                    "id": "16257649",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345378644\n \n \n   This doesn't fail for me locally:\r\n   \r\n   ```\r\n   $ ../cpp/build/debug/json-integration-test --integration --json=/tmp/tmp0jga4tt5/generated_primitive.json --arrow=foo.arrow --mode=JSON_TO_ARROW\r\n   Found schema: bool_nullable: bool\r\n   bool_nonnullable: bool not null\r\n   int8_nullable: int8\r\n   int8_nonnullable: int8 not null\r\n   int16_nullable: int16\r\n   int16_nonnullable: int16 not null\r\n   int32_nullable: int32\r\n   int32_nonnullable: int32 not null\r\n   int64_nullable: int64\r\n   int64_nonnullable: int64 not null\r\n   uint8_nullable: uint8\r\n   uint8_nonnullable: uint8 not null\r\n   uint16_nullable: uint16\r\n   uint16_nonnullable: uint16 not null\r\n   uint32_nullable: uint32\r\n   uint32_nonnullable: uint32 not null\r\n   uint64_nullable: uint64\r\n   uint64_nonnullable: uint64 not null\r\n   float32_nullable: float\r\n   float32_nonnullable: float not null\r\n   float64_nullable: double\r\n   float64_nonnullable: double not null\r\n   binary_nullable: binary\r\n   binary_nonnullable: binary not null\r\n   utf8_nullable: string\r\n   utf8_nonnullable: string not null\r\n   ```\r\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-17T22:06:33.447+0000",
                    "updated": "2017-11-17T22:06:33.447+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258227",
                    "id": "16258227",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345472682\n \n \n   Here's what I'm seeing in the diff in the test directory:\r\n   \r\n   ```\r\n    js/test/Arrow.ts                                 |    57 +-\r\n    js/test/__snapshots__/reader-tests.ts.snap       |   497 -\r\n    js/test/__snapshots__/table-tests.ts.snap        |  1815 ---\r\n    js/test/arrows/cpp/file/datetime.arrow           |   Bin 0 -> 6490 bytes\r\n    js/test/arrows/cpp/file/decimal.arrow            |   Bin 0 -> 259090 bytes\r\n    js/test/arrows/cpp/file/dictionary.arrow         |   Bin 0 -> 2562 bytes\r\n    js/test/arrows/cpp/file/nested.arrow             |   Bin 0 -> 2218 bytes\r\n    js/test/arrows/cpp/file/primitive-empty.arrow    |   Bin 0 -> 9498 bytes\r\n    js/test/arrows/cpp/file/primitive.arrow          |   Bin 0 -> 9442 bytes\r\n    js/test/arrows/cpp/file/simple.arrow             |   Bin 0 -> 1154 bytes\r\n    js/test/arrows/cpp/file/struct_example.arrow     |   Bin 0 -> 1538 bytes\r\n    js/test/arrows/cpp/stream/datetime.arrow         |   Bin 0 -> 5076 bytes\r\n    js/test/arrows/cpp/stream/decimal.arrow          |   Bin 0 -> 255228 bytes\r\n    js/test/arrows/cpp/stream/dictionary.arrow       |   Bin 0 -> 2004 bytes\r\n    js/test/arrows/cpp/stream/nested.arrow           |   Bin 0 -> 1636 bytes\r\n    js/test/arrows/cpp/stream/primitive-empty.arrow  |   Bin 0 -> 6852 bytes\r\n    js/test/arrows/cpp/stream/primitive.arrow        |   Bin 0 -> 7020 bytes\r\n    js/test/arrows/cpp/stream/simple.arrow           |   Bin 0 -> 748 bytes\r\n    js/test/arrows/cpp/stream/struct_example.arrow   |   Bin 0 -> 1124 bytes\r\n    js/test/arrows/file/dictionary.arrow             |   Bin 2522 -> 0 bytes\r\n    js/test/arrows/file/dictionary2.arrow            |   Bin 2762 -> 0 bytes\r\n    js/test/arrows/file/multi_dictionary.arrow       |   Bin 3482 -> 0 bytes\r\n    js/test/arrows/file/simple.arrow                 |   Bin 1642 -> 0 bytes\r\n    js/test/arrows/file/struct.arrow                 |   Bin 2354 -> 0 bytes\r\n    js/test/arrows/java/file/datetime.arrow          |   Bin 0 -> 6746 bytes\r\n    js/test/arrows/java/file/decimal.arrow           |   Bin 0 -> 259730 bytes\r\n    js/test/arrows/java/file/dictionary.arrow        |   Bin 0 -> 2666 bytes\r\n    js/test/arrows/java/file/nested.arrow            |   Bin 0 -> 2314 bytes\r\n    js/test/arrows/java/file/primitive-empty.arrow   |   Bin 0 -> 9778 bytes\r\n    js/test/arrows/java/file/primitive.arrow         |   Bin 0 -> 10034 bytes\r\n    js/test/arrows/java/file/simple.arrow            |   Bin 0 -> 1210 bytes\r\n    js/test/arrows/java/file/struct_example.arrow    |   Bin 0 -> 1602 bytes\r\n    js/test/arrows/java/stream/datetime.arrow        |   Bin 0 -> 5196 bytes\r\n    js/test/arrows/java/stream/decimal.arrow         |   Bin 0 -> 255564 bytes\r\n    js/test/arrows/java/stream/dictionary.arrow      |   Bin 0 -> 2036 bytes\r\n    js/test/arrows/java/stream/nested.arrow          |   Bin 0 -> 1676 bytes\r\n    js/test/arrows/java/stream/primitive-empty.arrow |   Bin 0 -> 6916 bytes\r\n    js/test/arrows/java/stream/primitive.arrow       |   Bin 0 -> 7404 bytes\r\n    js/test/arrows/java/stream/simple.arrow          |   Bin 0 -> 772 bytes\r\n    js/test/arrows/java/stream/struct_example.arrow  |   Bin 0 -> 1148 bytes\r\n    js/test/arrows/json/datetime.json                |  1091 ++\r\n    js/test/arrows/json/decimal.json                 | 33380 +++++++++++++++++++++++++++++++++++++++++++++++++++\r\n    js/test/arrows/json/dictionary.json              |   424 +\r\n    js/test/arrows/json/nested.json                  |   384 +\r\n    js/test/arrows/json/primitive-empty.json         |  1099 ++\r\n    js/test/arrows/json/primitive.json               |  1788 +++\r\n    js/test/arrows/json/simple.json                  |    66 +\r\n    js/test/arrows/json/struct_example.json          |   237 +\r\n    js/test/arrows/multi/count/records.arrow         |   Bin 224 -> 0 bytes\r\n    js/test/arrows/multi/count/schema.arrow          |   Bin 184 -> 0 bytes\r\n    js/test/arrows/multi/latlong/records.arrow       |   Bin 352 -> 0 bytes\r\n    js/test/arrows/multi/latlong/schema.arrow        |   Bin 264 -> 0 bytes\r\n    js/test/arrows/multi/origins/records.arrow       |   Bin 224 -> 0 bytes\r\n    js/test/arrows/multi/origins/schema.arrow        |   Bin 1604 -> 0 bytes\r\n    js/test/arrows/stream/dictionary.arrow           |   Bin 1776 -> 0 bytes\r\n    js/test/arrows/stream/simple.arrow               |   Bin 1188 -> 0 bytes\r\n    js/test/arrows/stream/struct.arrow               |   Bin 1884 -> 0 bytes\r\n    js/test/integration-tests.ts                     |   114 +\r\n    js/test/reader-tests.ts                          |    69 +-\r\n    js/test/table-tests.ts                           |   175 +-\r\n    js/test/test-config.ts                           |    61 +-\r\n    js/test/tsconfig.json                            |     2 +-\r\n    js/test/vector-tests.ts                          |   109 +-\r\n    63 files changed, 38864 insertions(+), 2504 deletions(-)\r\n   ```\r\n   \r\n   Can we remove the JSON files and the large decimal arrow files? I'm sorry to be OCD about the git history\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-18T21:29:58.798+0000",
                    "updated": "2017-11-18T21:29:58.798+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258489",
                    "id": "16258489",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345518069\n \n \n   @wesm after rebasing master, I removed the test data and added some lines to auto-generate the files and run the snapshot tests to the integration runner. I'm getting these errors converting the JSON to arrows both locally and in travis: https://travis-ci.org/apache/arrow/jobs/304302317#L4476. It's strange the normal integration tests run and all seem to pass. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T13:46:04.458+0000",
                    "updated": "2017-11-19T13:46:04.458+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258511",
                    "id": "16258511",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345525031\n \n \n   I\u2019ll take a look to see if I can figure it out\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T15:29:13.290+0000",
                    "updated": "2017-11-19T15:29:13.290+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258558",
                    "id": "16258558",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345539857\n \n \n   See \r\n   \r\n   ```\r\n   Error message: Invalid: /home/travis/build/apache/arrow/cpp/src/arrow/ipc/json-integration-test.cc:89 code: reader->ReadRecordBatch(i, &batch)\r\n   /home/travis/build/apache/arrow/cpp/src/arrow/ipc/json-internal.cc:1435 code: ReadArray(pool, json_columns[i], type, &columns[i])\r\n   /home/travis/build/apache/arrow/cpp/src/arrow/ipc/json-internal.cc:1287 code: ParseTypeValues(*type_)\r\n   /home/travis/build/apache/arrow/cpp/src/arrow/ipc/json-internal.cc:1055 code: ParseHexValue(hex_data + j * 2, &byte_buffer_data[j])\r\n   Encountered non-hex digit\r\n   Command failed: /home/travis/build/apache/arrow/cpp-build/debug/json-integration-test --integration --mode=JSON_TO_ARROW --json=/home/travis/build/apache/arrow/js/test/data/json/primitive.json --arrow=/home/travis/build/apache/arrow/js/test/data/cpp/file/primitive.arrow\r\n   ```\r\n   \r\n   It looks like there is something wrong with the JSON files that have been written to that directory. I will take a closer look\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T18:48:15.496+0000",
                    "updated": "2017-11-19T18:48:15.496+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258587",
                    "id": "16258587",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "TheNeuralBit commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345543675\n \n \n   I'm seeing this same error locally:\r\n   ```\r\n   com.fasterxml.jackson.core.JsonParseException: Numeric value (50261) out of range of Java short\r\n   ```\r\n   \r\n   Strangely, `python integration_test.py` runs just fine. I only run into this issue when I use the java integration test directly to generate a test file. My process:\r\n   \r\n   - ran `generate_primitive_case(..).write('primitive.json)` from a python shell to get a JSON file\r\n   - ran `java -cp ${ARROW_HOME}/java/tools/target/arrow-tools-0.8.0-SNAPSHOT-jar-with-dependencies.jar org.apache.arrow.tools.Integration -c JSON_TO_ARROW -a primitive.java.arrow -j primitive.json`\r\n   \r\n   Not sure what is causing this discrepancy, but it seems like the same thing that's affecting @trxcllnt's generator.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T19:43:33.424+0000",
                    "updated": "2017-11-19T19:43:33.424+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258588",
                    "id": "16258588",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "TheNeuralBit commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345543675\n \n \n   I'm seeing this same error locally:\r\n   ```\r\n   com.fasterxml.jackson.core.JsonParseException: Numeric value (50261) out of range of Java short\r\n   ```\r\n   \r\n   Strangely, `python integration_test.py` runs just fine. I only run into this issue when I use the java integration test directly to generate a test file. My process:\r\n   \r\n   - ran `generate_primitive_case(..).write('primitive.json)` from a python shell to get a JSON file\r\n   - ran `java -cp ${ARROW_HOME}/java/tools/target/arrow-tools-0.8.0-SNAPSHOT-jar-with-dependencies.jar org.apache.arrow.tools.Integration -c JSON_TO_ARROW -a primitive.java.arrow -j primitive.json`\r\n   \r\n   Not sure what is causing this discrepancy, but it seems like the same thing that's affecting @trxcllnt's generator.\r\n   \r\n   EDIT: Note I haven't had any issues generating C++ files yet, I'm only seeing the java issue.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T19:45:06.864+0000",
                    "updated": "2017-11-19T19:45:06.864+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258602",
                    "id": "16258602",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345546104\n \n \n   Super weird. I am traveling today so I hope to find some downtime in a little while to look at this, before EOD is the goal\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T20:18:13.692+0000",
                    "updated": "2017-11-19T20:18:13.692+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258640",
                    "id": "16258640",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345553066\n \n \n   I found the problem -- one of the primitive integration test files was being clobbered and not run, which was suppressing a failure that should have been raised a long time ago.\r\n   \r\n   In the meantime, there was also a regression from the Java refactor, and we are no longer able to fully read unsigned integer types anymore. I will hack the integration tests for now and open a JIRA about fixing, \r\n   \r\n   here's an example of trying to read a `uint16` vector:\r\n   \r\n   ```\r\n   16:49:51.051 [main] DEBUG io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8\r\n   Error accessing files\r\n   Numeric value (65350) out of range of Java short\r\n    at [Source: /tmp/tmpwgopllpl/generated_primitive.json; line: 1111, column: 18]\r\n   16:49:51.065 [main] ERROR org.apache.arrow.tools.Integration - Error accessing files\r\n   com.fasterxml.jackson.core.JsonParseException: Numeric value (65350) out of range of Java short\r\n   ```\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T21:55:29.184+0000",
                    "updated": "2017-11-19T21:55:29.184+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258642",
                    "id": "16258642",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345554173\n \n \n   OK, integration tests should pass now, fingers crossed. I will merge once the build is green, thanks @trxcllnt and @TheNeuralBit for the patience, it is appreciated\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T22:10:53.038+0000",
                    "updated": "2017-11-19T22:10:53.038+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258665",
                    "id": "16258665",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345557542\n \n \n   @wesm awesome, thanks! After my latest commit, the integration tests all pass now for me locally. Are you fine with this PR as-is, or should I close it and do one from a new branch w/o the test data commits?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T22:59:44.126+0000",
                    "updated": "2017-11-19T22:59:44.126+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258669",
                    "id": "16258669",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345557709\n \n \n   The PR tool should squash out those commits, so I don't think it's a problem. I'll let you know if I run into any issues after the build runs\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-19T23:02:23.661+0000",
                    "updated": "2017-11-19T23:02:23.661+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258701",
                    "id": "16258701",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345566713\n \n \n   There was a non-deterministic Plasma failure in the C++/Python entry, but the integration test entry also failed:\r\n   \r\n   ```\r\n   [00:23:46] Starting 'test:es5:umd'...\r\n    FAIL  test/table-tests.ts\r\n     \u25cf Test suite failed to run\r\n       Cannot find module '/home/travis/build/apache/arrow/js/targets/es5/umd/Arrow' from 'Arrow.ts'\r\n         \r\n         at Resolver.resolveModule (node_modules/jest-resolve/build/index.js:191:17)\r\n         at Object.<anonymous> (test/Arrow.ts:50:17)\r\n    FAIL  test/reader-tests.ts\r\n     \u25cf Test suite failed to run\r\n       Cannot find module '/home/travis/build/apache/arrow/js/targets/es5/umd/Arrow' from 'Arrow.ts'\r\n         \r\n         at Resolver.resolveModule (node_modules/jest-resolve/build/index.js:191:17)\r\n         at Object.<anonymous> (test/Arrow.ts:50:17)\r\n    FAIL  test/integration-tests.ts\r\n     \u25cf Test suite failed to run\r\n       Cannot find module '/home/travis/build/apache/arrow/js/targets/es5/umd/Arrow' from 'Arrow.ts'\r\n         \r\n         at Resolver.resolveModule (node_modules/jest-resolve/build/index.js:191:17)\r\n         at Object.<anonymous> (test/Arrow.ts:50:17)\r\n    FAIL  test/vector-tests.ts\r\n     \u25cf Test suite failed to run\r\n       Cannot find module '/home/travis/build/apache/arrow/js/targets/es5/umd/Arrow' from 'Arrow.ts'\r\n         \r\n         at Resolver.resolveModule (node_modules/jest-resolve/build/index.js:191:17)\r\n         at Object.<anonymous> (test/Arrow.ts:50:17)\r\n   Test Suites: 4 failed, 4 total\r\n   Tests:       0 total\r\n   Snapshots:   0 total\r\n   Time:        2.409s, estimated 24s\r\n   Ran all test suites.\r\n   [00:23:49] 'test:es5:umd' errored after 2.64 s\r\n   [00:23:49] Error: exited with error code: 1\r\n       at ChildProcess.onexit (/home/travis/build/apache/arrow/js/node_modules/end-of-stream/index.js:39:36)\r\n       at ChildProcess.emit (events.js:159:13)\r\n       at Process.ChildProcess._handle.onexit (internal/child_process.js:209:12)\r\n   [00:23:49] 'test' errored after 3.42 min\r\n   npm ERR! Test failed.  See above for more details.\r\n   ```\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T01:09:08.855+0000",
                    "updated": "2017-11-20T01:09:08.855+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258702",
                    "id": "16258702",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345567116\n \n \n   @wesm yeah, looks like Closure Compiler threw an exception building the ES5 UMD target: https://travis-ci.org/apache/arrow/jobs/304499884#L4649. I'm not certain, but it could be related to the integration tests running with JDK7 instead of 8.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T01:12:43.311+0000",
                    "updated": "2017-11-20T01:12:43.311+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258703",
                    "id": "16258703",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345567116\n \n \n   @wesm yeah, looks like Closure Compiler threw an exception building the ES5 UMD target: https://travis-ci.org/apache/arrow/jobs/304499884#L4649. I'm not certain, but it could be related to the integration tests running with JDK7 instead of 8. I'll switch the job to use the JS version of the Closure Compiler which, while slower, won't be affected by Java externalities.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T01:14:16.238+0000",
                    "updated": "2017-11-20T01:14:16.238+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258789",
                    "id": "16258789",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345585644\n \n \n   @wesm actually this might be tough -- the JS version of closure-compiler is a bit outdated, and the Java version [hasn't supported Java 7 since October](https://github.com/google/closure-compiler/issues/2672).\r\n   \r\n   I don't want to skip running the tests on the ES5 UMD bundle, as that's the lowest-common-denominator for anyone wanting to experiment with Arrow in the browser, and the integration tests validate that public methods and properties don't get minified away.\r\n   \r\n   Is it possible to update the integration job to openjdk8 (like the java version)? If not, I can create a sibling `integration-java8` job that includes the JS tests.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T03:58:56.497+0000",
                    "updated": "2017-11-20T03:58:56.497+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258790",
                    "id": "16258790",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345585644\n \n \n   @wesm actually this might be tough -- the JS version of closure-compiler is a bit outdated and broken, and the Java version [hasn't supported Java 7 since October](https://github.com/google/closure-compiler/issues/2672).\r\n   \r\n   I don't want to skip running the tests on the ES5 UMD bundle, as that's the lowest-common-denominator for anyone wanting to experiment with Arrow in the browser, and the integration tests validate that public methods and properties don't get minified away.\r\n   \r\n   Is it possible to update the integration job to openjdk8 (like the java version)? If not, I can create a sibling `integration-java8` job that includes the JS tests.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T03:59:12.650+0000",
                    "updated": "2017-11-20T03:59:12.650+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258799",
                    "id": "16258799",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345587677\n \n \n   Totally fine to move the integration tests to jdk8\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T04:17:21.956+0000",
                    "updated": "2017-11-20T04:17:21.956+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258885",
                    "id": "16258885",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345610464\n \n \n   @wesm alright! now that the integration tests are passing, I re-enabled the datetime tests and removed the generated arrow files from the performance tests. Should be good to go pending this last CI build.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T07:17:08.762+0000",
                    "updated": "2017-11-20T07:17:08.762+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16258887",
                    "id": "16258887",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Fix reading C++ dictionary-encoded vectors\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345610464\n \n \n   @wesm alright! now that the integration tests are passing, I added backwards-compatibility for Arrow files written before 0.8, re-enabled the datetime tests, and removed the generated arrow files from the performance tests. Should be good to go pending this last CI build.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T07:20:13.802+0000",
                    "updated": "2017-11-20T07:20:13.802+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16259278",
                    "id": "16259278",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Expand JavaScript implementation, build system, fix integration tests\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345708786\n \n \n   Sweet thanks! So after we get the release scripts set up, we can release this, but one problem to be aware of is that the library in its current state cannot read 0.7.1 binary data and possibly not 0.8.0 (in its final form) binary data. Hopefully we can get ARROW-1785 sorted out soon \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T14:19:55.246+0000",
                    "updated": "2017-11-20T14:19:55.246+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16259281",
                    "id": "16259281",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm closed pull request #1294: ARROW-1693: [JS] Expand JavaScript implementation, build system, fix integration tests\nURL: https://github.com/apache/arrow/pull/1294\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/.travis.yml b/.travis.yml\nindex 9917a2614..9c714a689 100644\n--- a/.travis.yml\n+++ b/.travis.yml\n@@ -87,7 +87,7 @@ matrix:\n     - $TRAVIS_BUILD_DIR/ci/travis_script_manylinux.sh\n   - language: java\n     os: linux\n-    jdk: openjdk8\n+    jdk: openjdk7\n     script:\n     - $TRAVIS_BUILD_DIR/ci/travis_script_java.sh\n   - language: java\n@@ -103,23 +103,24 @@ matrix:\n   - language: java\n     os: linux\n     env: ARROW_TEST_GROUP=integration\n-    jdk: openjdk7\n+    jdk: openjdk8\n     before_script:\n     - source $TRAVIS_BUILD_DIR/ci/travis_install_clang_tools.sh\n     - export CC=\"clang-4.0\"\n     - export CXX=\"clang++-4.0\"\n+    - nvm install node\n     - $TRAVIS_BUILD_DIR/ci/travis_lint.sh\n+    - $TRAVIS_BUILD_DIR/ci/travis_before_script_js.sh\n     - $TRAVIS_BUILD_DIR/ci/travis_before_script_cpp.sh\n     script:\n     - $TRAVIS_BUILD_DIR/ci/travis_script_integration.sh\n-  # TODO(wesm): Re-enable after issues in ARROW-1409 resolved\n-  # - language: node_js\n-  #   os: linux\n-  #   node_js: node\n-  #   before_script:\n-  #   - $TRAVIS_BUILD_DIR/ci/travis_before_script_js.sh\n-  #   script:\n-  #   - $TRAVIS_BUILD_DIR/ci/travis_script_js.sh\n+  - language: node_js\n+    os: linux\n+    node_js: node\n+    before_script:\n+    - $TRAVIS_BUILD_DIR/ci/travis_before_script_js.sh\n+    script:\n+    - $TRAVIS_BUILD_DIR/ci/travis_script_js.sh\n   - compiler: gcc\n     language: cpp\n     os: linux\ndiff --git a/LICENSE.txt b/LICENSE.txt\nindex 038518a5d..84e6a4e2a 100644\n--- a/LICENSE.txt\n+++ b/LICENSE.txt\n@@ -457,3 +457,98 @@ LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+\n+--------------------------------------------------------------------------------\n+\n+This project includes code from the Boost project\n+\n+Boost Software License - Version 1.0 - August 17th, 2003\n+\n+Permission is hereby granted, free of charge, to any person or organization\n+obtaining a copy of the software and accompanying documentation covered by\n+this license (the \"Software\") to use, reproduce, display, distribute,\n+execute, and transmit the Software, and to prepare derivative works of the\n+Software, and to permit third-parties to whom the Software is furnished to\n+do so, all subject to the following:\n+\n+The copyright notices in the Software and this entire statement, including\n+the above license grant, this restriction and the following disclaimer,\n+must be included in all copies of the Software, in whole or in part, and\n+all derivative works of the Software, unless such copies or derivative\n+works are solely in the form of machine-executable object code generated by\n+a source language processor.\n+\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT\n+SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE\n+FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,\n+ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n+DEALINGS IN THE SOFTWARE.\n+\n+--------------------------------------------------------------------------------\n+\n+This project includes code from the mapbox/variant project, BSD 3-clause\n+license\n+\n+Copyright (c) MapBox\n+All rights reserved.\n+\n+Redistribution and use in source and binary forms, with or without modification,\n+are permitted provided that the following conditions are met:\n+\n+- Redistributions of source code must retain the above copyright notice, this\n+  list of conditions and the following disclaimer.\n+- Redistributions in binary form must reproduce the above copyright notice, this\n+  list of conditions and the following disclaimer in the documentation and/or\n+  other materials provided with the distribution.\n+- Neither the name \"MapBox\" nor the names of its contributors may be\n+  used to endorse or promote products derived from this software without\n+  specific prior written permission.\n+\n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+\n+--------------------------------------------------------------------------------\n+\n+This project includes code from the FlatBuffers project\n+\n+Copyright 2014 Google Inc.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+--------------------------------------------------------------------------------\n+\n+This project includes code from the tslib project\n+\n+Copyright 2015 Microsoft Corporation. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\ndiff --git a/ci/travis_script_integration.sh b/ci/travis_script_integration.sh\nindex be025512f..105a0cc60 100755\n--- a/ci/travis_script_integration.sh\n+++ b/ci/travis_script_integration.sh\n@@ -44,3 +44,22 @@ conda install -y pip numpy six\n python integration_test.py --debug\n \n popd\n+\n+pushd $ARROW_JS_DIR\n+\n+# lint and compile JS source\n+npm run lint\n+npm run build\n+# create initial test data\n+npm run test:createTestData\n+# run once to write the snapshots\n+npm test -- -t ts -u --integration\n+# run again to test all builds against the snapshots\n+npm test -- --integration\n+# run tests against source to generate coverage data\n+npm run test:coverage -- --integration\n+# Uncomment to upload to coveralls\n+# cat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.js;\n+\n+\n+popd\n\\ No newline at end of file\ndiff --git a/ci/travis_script_js.sh b/ci/travis_script_js.sh\nindex 9f77dec8c..1871b4265 100755\n--- a/ci/travis_script_js.sh\n+++ b/ci/travis_script_js.sh\n@@ -17,16 +17,15 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-set -e\n+set -ex\n \n-JS_DIR=${TRAVIS_BUILD_DIR}/js\n+source $TRAVIS_BUILD_DIR/ci/travis_env_common.sh\n \n-pushd $JS_DIR\n+pushd $ARROW_JS_DIR\n \n-npm run validate\n-\n-# Uncomment to use coveralls\n-# npm run test:coverage\n-# cat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.js;\n+npm run lint\n+npm run build\n+# run the non-snapshot unit tests\n+npm test\n \n popd\ndiff --git a/integration/integration_test.py b/integration/integration_test.py\nindex 46d010608..a063fb36f 100644\n--- a/integration/integration_test.py\n+++ b/integration/integration_test.py\n@@ -28,6 +28,7 @@\n import subprocess\n import tempfile\n import uuid\n+import errno\n \n import numpy as np\n \n@@ -198,9 +199,18 @@ def __init__(self, name, is_signed, bit_width, nullable=True,\n         self.min_value = min_value\n         self.max_value = max_value\n \n-    @property\n-    def numpy_type(self):\n-        return ('int' if self.is_signed else 'uint') + str(self.bit_width)\n+    def _get_generated_data_bounds(self):\n+        signed_iinfo = np.iinfo('int' + str(self.bit_width))\n+        if self.is_signed:\n+            min_value, max_value = signed_iinfo.min, signed_iinfo.max\n+        else:\n+            # ARROW-1837 Remove this hack and restore full unsigned integer\n+            # range\n+            min_value, max_value = 0, signed_iinfo.max\n+\n+        lower_bound = max(min_value, self.min_value)\n+        upper_bound = min(max_value, self.max_value)\n+        return lower_bound, upper_bound\n \n     def _get_type(self):\n         return OrderedDict([\n@@ -210,9 +220,7 @@ def _get_type(self):\n         ])\n \n     def generate_column(self, size, name=None):\n-        iinfo = np.iinfo(self.numpy_type)\n-        lower_bound = max(iinfo.min, self.min_value)\n-        upper_bound = min(iinfo.max, self.max_value)\n+        lower_bound, upper_bound = self._get_generated_data_bounds()\n         return self.generate_range(size, lower_bound, upper_bound, name=name)\n \n     def generate_range(self, size, lower, upper, name=None):\n@@ -521,7 +529,7 @@ def get_json(self):\n class BinaryColumn(PrimitiveColumn):\n \n     def _encode_value(self, x):\n-        return frombytes(binascii.hexlify(x))\n+        return frombytes(binascii.hexlify(x).upper())\n \n     def _get_buffers(self):\n         offset = 0\n@@ -785,7 +793,7 @@ def _generate_file(name, fields, batch_sizes, dictionaries=None):\n     return JsonFile(name, schema, batches, dictionaries)\n \n \n-def generate_primitive_case(batch_sizes):\n+def generate_primitive_case(batch_sizes, name='primitive'):\n     types = ['bool', 'int8', 'int16', 'int32', 'int64',\n              'uint8', 'uint16', 'uint32', 'uint64',\n              'float32', 'float64', 'binary', 'utf8']\n@@ -796,7 +804,7 @@ def generate_primitive_case(batch_sizes):\n         fields.append(get_field(type_ + \"_nullable\", type_, True))\n         fields.append(get_field(type_ + \"_nonnullable\", type_, False))\n \n-    return _generate_file(\"primitive\", fields, batch_sizes)\n+    return _generate_file(name, fields, batch_sizes)\n \n \n def generate_decimal_case():\n@@ -874,8 +882,8 @@ def _temp_path():\n         return\n \n     file_objs = [\n-        generate_primitive_case([7, 10]),\n-        generate_primitive_case([0, 0, 0]),\n+        generate_primitive_case([17, 20], name='primitive'),\n+        generate_primitive_case([0, 0, 0], name='primitive_zerolength'),\n         generate_decimal_case(),\n         generate_datetime_case(),\n         generate_nested_case(),\n@@ -1079,11 +1087,33 @@ def run_all_tests(debug=False):\n     print('-- All tests passed!')\n \n \n+def write_js_test_json(directory):\n+    generate_nested_case().write(os.path.join(directory, 'nested.json'))\n+    generate_decimal_case().write(os.path.join(directory, 'decimal.json'))\n+    generate_datetime_case().write(os.path.join(directory, 'datetime.json'))\n+    (generate_dictionary_case()\n+     .write(os.path.join(directory, 'dictionary.json')))\n+    (generate_primitive_case([7, 10])\n+     .write(os.path.join(directory, 'primitive.json')))\n+    (generate_primitive_case([0, 0, 0])\n+     .write(os.path.join(directory, 'primitive-empty.json')))\n+\n+\n if __name__ == '__main__':\n     parser = argparse.ArgumentParser(description='Arrow integration test CLI')\n+    parser.add_argument('--write_generated_json', dest='generated_json_path',\n+                        action='store', default=False,\n+                        help='Generate test JSON')\n     parser.add_argument('--debug', dest='debug', action='store_true',\n                         default=False,\n                         help='Run executables in debug mode as relevant')\n-\n     args = parser.parse_args()\n-    run_all_tests(debug=args.debug)\n+    if args.generated_json_path:\n+        try:\n+            os.makedirs(args.generated_json_path)\n+        except OSError as e:\n+            if e.errno != errno.EEXIST:\n+                raise\n+        write_js_test_json(args.generated_json_path)\n+    else:\n+        run_all_tests(debug=args.debug)\ndiff --git a/js/.gitignore b/js/.gitignore\nindex 88c612d8f..f705f2510 100644\n--- a/js/.gitignore\n+++ b/js/.gitignore\n@@ -83,3 +83,8 @@ package-lock.json\n # compilation targets\n dist\n targets\n+\n+# test data files\n+test/data/\n+# jest snapshots (too big)\n+test/__snapshots__/\n\\ No newline at end of file\ndiff --git a/js/DEVELOP.md b/js/DEVELOP.md\nindex 5b4ac14ed..9f586e1b3 100644\n--- a/js/DEVELOP.md\n+++ b/js/DEVELOP.md\n@@ -50,91 +50,220 @@ Once generated, the flatbuffers format code needs to be adjusted for our TS and\n \n 1. Generate the flatbuffers TypeScript source from the Arrow project root directory:\n     ```sh\n+    cd $ARROW_HOME\n+\n     flatc --ts -o ./js/src/format ./format/*.fbs\n+\n+    cd ./js/src/format\n+\n+    # Delete Tensor_generated.js (skip this when we support Tensors)\n+    rm ./Tensor_generated.ts\n+\n+    # Remove \"_generated\" suffix from TS files\n+    mv ./File_generated.ts .File.ts\n+    mv ./Schema_generated.ts .Schema.ts\n+    mv ./Message_generated.ts .Message.ts\n     ```\n-1. Change all the `flatbuffers` imports to\n+1. Remove Tensor import from `Schema.ts`\n+1. Fix all the `flatbuffers` imports\n     ```ts\n-    import { flatbuffers } from \"flatbuffers\"\n+    import { flatbuffers } from \"./flatbuffers\" // <-- change\n+    import { flatbuffers } from \"flatbuffers\" // <-- to this\n     ```\n-1. Delete `Tensor_generated.ts` (remove this step once we support Tensors)\n-1. Remove Tensor import from `Schema_generated.ts`\n-1. Add `/* tslint:disable:class-name */` to the top of `Schema_generated.ts`\n+1. Remove `_generated` from the ES6 imports of the generated files\n+    ```ts\n+    import * as NS16187549871986683199 from \"./Schema_generated\"; // <-- change\n+    import * as NS16187549871986683199 from \"./Schema\"; // <------- to this\n+    ```\n+1. Add `/* tslint:disable:class-name */` to the top of `Schema.ts`\n+1. Execute `npm run lint` to fix all the linting errors\n \n ## JavaScript (for Google Closure Compiler builds)\n \n 1. Generate the flatbuffers JS source from the Arrow project root directory\n     ```sh\n-    flatc --js -o ./js/closure-compiler-scripts ./format/*.fbs\n-    ```\n-1. Delete `Tensor_generated.js` (remove this step once we support Tensors)\n-1. Add `goog.module` declarations to the top of each generated file\n+    cd $ARROW_HOME\n \n-    Each file starts with a header that looks like this:\n-    ```js\n-    // automatically generated by the FlatBuffers compiler, do not modify\n+    flatc --js --no-js-exports -o ./js/src/format ./format/*.fbs\n \n-    /**\n-    * @const\n-    * @namespace\n-    */\n-    var org = org || {};\n-    ```\n+    cd ./js/src/format\n+\n+    # Delete Tensor_generated.js (skip this when we support Tensors)\n+    rm Tensor_generated.js\n \n-    Update the header of each file to explicitly declare its module.\n+    # append an ES6 export to Schema_generated.js\n+    echo \"$(cat Schema_generated.js)\n+    export { org };\n+    \" > Schema_generated.js\n \n-    `Schema_generated.js`:\n+    # import Schema's \"org\" namespace and\n+    # append an ES6 export to File_generated.js\n+    echo \"import { org } from './Schema';\n+    $(cat File_generated.js)\n+    export { org };\n+    \" > File_generated.js\n+\n+    # import Schema's \"org\" namespace and\n+    # append an ES6 export to Message_generated.js\n+    echo \"import { org } from './Schema';\n+    $(cat Message_generated.js)\n+    export { org };\n+    \" > Message_generated.js\n+    ```\n+1. Fixup the generated JS enums with the reverse value-to-key mappings to match TypeScript\n+    `Message_generated.js`\n     ```js\n-    // automatically generated by the FlatBuffers compiler, do not modify\n-    goog.module(\"module$targets$es5$cls$format$Schema_generated\");\n-    goog.module.declareLegacyNamespace();\n+    // Replace this\n+    org.apache.arrow.flatbuf.MessageHeader = {\n+      NONE: 0,\n+      Schema: 1,\n+      DictionaryBatch: 2,\n+      RecordBatch: 3,\n+      Tensor: 4\n+    };\n+    // With this\n+    org.apache.arrow.flatbuf.MessageHeader = {\n+      NONE: 0, 0: 'NONE',\n+      Schema: 1, 1: 'Schema',\n+      DictionaryBatch: 2, 2: 'DictionaryBatch',\n+      RecordBatch: 3, 3: 'RecordBatch',\n+      Tensor: 4, 4: 'Tensor'\n+    };\n+    ```\n+    `Schema_generated.js`\n+    ```js\n+    /**\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.MetadataVersion = {\n+      /**\n+       * 0.1.0\n+       */\n+      V1: 0, 0: 'V1',\n+\n+      /**\n+       * 0.2.0\n+       */\n+      V2: 1, 1: 'V2',\n+\n+      /**\n+       * 0.3.0 -> 0.7.1\n+       */\n+      V3: 2, 2: 'V3',\n+\n+      /**\n+       * >= 0.8.0\n+       */\n+      V4: 3, 3: 'V4'\n+    };\n \n     /**\n-    * @const\n-    * @namespace\n-    */\n-    var org = org || {};\n-    ```\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.UnionMode = {\n+      Sparse: 0, 0: 'Sparse',\n+      Dense: 1, 1: 'Dense',\n+    };\n \n-    `File_generated.js`:\n+    /**\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.Precision = {\n+      HALF: 0, 0: 'HALF',\n+      SINGLE: 1, 1: 'SINGLE',\n+      DOUBLE: 2, 2: 'DOUBLE',\n+    };\n \n-    ```js\n-    // automatically generated by the FlatBuffers compiler, do not modify\n-    goog.module(\"module$targets$es5$cls$format$File_generated\");\n-    goog.module.declareLegacyNamespace();\n-    var Schema_ = goog.require(\"module$targets$es5$cls$format$Schema_generated\");\n     /**\n-    * @const\n-    * @namespace\n-    */\n-    var org = Schema_.org;\n-    ```\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.DateUnit = {\n+      DAY: 0, 0: 'DAY',\n+      MILLISECOND: 1, 1: 'MILLISECOND',\n+    };\n \n-    `Message_generated.js`:\n+    /**\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.TimeUnit = {\n+      SECOND: 0, 0: 'SECOND',\n+      MILLISECOND: 1, 1: 'MILLISECOND',\n+      MICROSECOND: 2, 2: 'MICROSECOND',\n+      NANOSECOND: 3, 3: 'NANOSECOND',\n+    };\n \n-    ```js\n-    // automatically generated by the FlatBuffers compiler, do not modify\n-    goog.module(\"module$targets$es5$cls$format$Message_generated\");\n-    goog.module.declareLegacyNamespace();\n-    var Schema_ = goog.require(\"module$targets$es5$cls$format$Schema_generated\");\n     /**\n-    * @const\n-    * @namespace\n-    */\n-    var org = Schema_.org;\n-    ```\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.IntervalUnit = {\n+      YEAR_MONTH: 0, 0: 'YEAR_MONTH',\n+      DAY_TIME: 1, 1: 'DAY_TIME',\n+    };\n \n-1. Replace the last line's export declaration\n+    /**\n+     * ----------------------------------------------------------------------\n+     * Top-level Type value, enabling extensible type-specific metadata. We can\n+     * add new logical types to Type without breaking backwards compatibility\n+     *\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.Type = {\n+      NONE: 0, 0: 'NONE',\n+      Null: 1, 1: 'Null',\n+      Int: 2, 2: 'Int',\n+      FloatingPoint: 3, 3: 'FloatingPoint',\n+      Binary: 4, 4: 'Binary',\n+      Utf8: 5, 5: 'Utf8',\n+      Bool: 6, 6: 'Bool',\n+      Decimal: 7, 7: 'Decimal',\n+      Date: 8, 8: 'Date',\n+      Time: 9, 9: 'Time',\n+      Timestamp: 10, 10: 'Timestamp',\n+      Interval: 11, 11: 'Interval',\n+      List: 12, 12: 'List',\n+      Struct_: 13, 13: 'Struct_',\n+      Union: 14, 14: 'Union',\n+      FixedSizeBinary: 15, 15: 'FixedSizeBinary',\n+      FixedSizeList: 16, 16: 'FixedSizeList',\n+      Map: 17, 17: 'Map'\n+    };\n \n-    The last line of each file is:\n+    /**\n+     * ----------------------------------------------------------------------\n+     * The possible types of a vector\n+     *\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.VectorType = {\n+      /**\n+       * used in List type, Dense Union and variable length primitive types (String, Binary)\n+       */\n+      OFFSET: 0, 0: 'OFFSET',\n \n-    ```js\n-    // Exports for Node.js and RequireJS\n-    this.org = org;\n-    ```\n+      /**\n+       * actual data, either wixed width primitive types in slots or variable width delimited by an OFFSET vector\n+       */\n+      DATA: 1, 1: 'DATA',\n \n-    This should instead read:\n+      /**\n+       * Bit vector indicating if each value is null\n+       */\n+      VALIDITY: 2, 2: 'VALIDITY',\n \n-    ```js\n-    // Exports for Node.js and RequireJS\n-    exports.org = org;\n-    ```\n\\ No newline at end of file\n+      /**\n+       * Type vector used in Union type\n+       */\n+      TYPE: 3, 3: 'TYPE'\n+    };\n+\n+    /**\n+     * ----------------------------------------------------------------------\n+     * Endianness of the platform producing the data\n+     *\n+     * @enum\n+     */\n+    org.apache.arrow.flatbuf.Endianness = {\n+      Little: 0, 0: 'Little',\n+      Big: 1, 1: 'Big',\n+    };\n+    ```\ndiff --git a/js/LICENSE b/js/LICENSE\ndeleted file mode 100644\nindex 02e794808..000000000\n--- a/js/LICENSE\n+++ /dev/null\n@@ -1,39 +0,0 @@\n-## 3rd-party licenses for code that has been adapted for the Arrow JavaScript\n-   library\n-\n---------------------------------------------------------------------------------\n-\n-This project includes code from the FlatBuffers project\n-\n-Copyright 2014 Google Inc.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-\n---------------------------------------------------------------------------------\n-\n-This project includes code from the tslib project\n-\n-Copyright 2015 Microsoft Corporation. All rights reserved. \n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-\ndiff --git a/js/README.md b/js/README.md\nindex bee3a9c7d..e07be6bc0 100644\n--- a/js/README.md\n+++ b/js/README.md\n@@ -22,7 +22,7 @@\n [![Build Status](https://travis-ci.org/apache/arrow.svg?branch=master)](https://travis-ci.org/apache/arrow)\n [![Coverage Status](https://coveralls.io/repos/github/apache/arrow/badge.svg)](https://coveralls.io/github/apache/arrow)\n \n-Arrow is a set of technologies that enable big-data systems to process and move data fast.\n+Arrow is a set of technologies that enable big-data systems to process and transfer data quickly.\n \n ## install [apache-arrow from npm](https://www.npmjs.com/package/apache-arrow)\n \n@@ -50,7 +50,7 @@ import { readFileSync } from 'fs';\n import { Table } from 'apache-arrow';\n \n const arrow = readFileSync('simple.arrow');\n-const table = Table.from(arrow);\n+const table = Table.from([arrow]);\n \n console.log(table.toString());\n \n@@ -70,7 +70,7 @@ null, null, null\n import { readFileSync } from 'fs';\n import { Table } from 'apache-arrow';\n \n-const table = Table.from(...[\n+const table = Table.from([\n     'latlong/schema.arrow',\n     'latlong/records.arrow'\n ].map((file) => readFileSync(file)));\n@@ -93,12 +93,12 @@ console.log(table.toString());\n import { readFileSync } from 'fs';\n import { Table } from 'apache-arrow';\n \n-const table = Table.from(...[\n+const table = Table.from([\n     'latlong/schema.arrow',\n     'latlong/records.arrow'\n ].map(readFileSync));\n \n-const column = table.getColumn('origin_lat');\n+const column = table.col('origin_lat');\n const typed = column.slice();\n \n assert(typed instanceof Float32Array);\n@@ -135,7 +135,7 @@ MapD.open(host, port)\n     // Create Arrow Table from results\n     Table.from(schema, records))\n   .map((table) =>\n-    // Stringify the table to CSV\n+    // Stringify the table to CSV with row numbers\n     table.toString({ index: true }))\n   .subscribe((csvStr) =>\n     console.log(csvStr));\ndiff --git a/js/closure-compiler-scripts/flatbuffers.js b/js/closure-compiler-scripts/flatbuffers.js\ndeleted file mode 100644\nindex e51a4a039..000000000\n--- a/js/closure-compiler-scripts/flatbuffers.js\n+++ /dev/null\n@@ -1,1204 +0,0 @@\n-/**\n- * closure-compiler-friendly flatbuffers\n- * copied from\u00a0node_modules/flatbuffers/js/flatbuffers.js\n- * update as needed\n- */\n-\n- /// @file\n-/// @addtogroup flatbuffers_javascript_api\n-/// @{\n-/// @cond FLATBUFFERS_INTERNAL\n-\n-goog.module(\"module$flatbuffers\");\n-goog.module.declareLegacyNamespace();\n-/**\n- * @fileoverview\n- *\n- * Need to suppress 'global this' error so the Node.js export line doesn't cause\n- * closure compile to error out.\n- * @suppress {globalThis}\n- */\n-\n-/**\n- * @const\n- * @namespace\n- */\n-var flatbuffers = {};\n-\n-/**\n- * @typedef {number}\n- */\n-flatbuffers.Offset;\n-\n-/**\n- * @typedef {{\n- *   bb: flatbuffers.ByteBuffer,\n- *   bb_pos: number\n- * }}\n- */\n-flatbuffers.Table;\n-\n-/**\n- * @type {number}\n- * @const\n- */\n-flatbuffers.SIZEOF_SHORT = 2;\n-\n-/**\n- * @type {number}\n- * @const\n- */\n-flatbuffers.SIZEOF_INT = 4;\n-\n-/**\n- * @type {number}\n- * @const\n- */\n-flatbuffers.FILE_IDENTIFIER_LENGTH = 4;\n-\n-/**\n- * @enum {number}\n- */\n-flatbuffers.Encoding = {\n-  UTF8_BYTES: 1,\n-  UTF16_STRING: 2\n-};\n-\n-/**\n- * @type {Int32Array}\n- * @const\n- */\n-flatbuffers.int32 = new Int32Array(2);\n-\n-/**\n- * @type {Float32Array}\n- * @const\n- */\n-flatbuffers.float32 = new Float32Array(flatbuffers.int32.buffer);\n-\n-/**\n- * @type {Float64Array}\n- * @const\n- */\n-flatbuffers.float64 = new Float64Array(flatbuffers.int32.buffer);\n-\n-/**\n- * @type {boolean}\n- * @const\n- */\n-flatbuffers.isLittleEndian = new Uint16Array(new Uint8Array([1, 0]).buffer)[0] === 1;\n-\n-////////////////////////////////////////////////////////////////////////////////\n-\n-/**\n- * @constructor\n- * @param {number} low\n- * @param {number} high\n- */\n-flatbuffers.Long = function(low, high) {\n-  /**\n-   * @type {number}\n-   * @const\n-   */\n-  this.low = low | 0;\n-\n-  /**\n-   * @type {number}\n-   * @const\n-   */\n-  this.high = high | 0;\n-};\n-\n-/**\n- * @param {number} low\n- * @param {number} high\n- * @returns {flatbuffers.Long}\n- */\n-flatbuffers.Long.create = function(low, high) {\n-  // Special-case zero to avoid GC overhead for default values\n-  return low == 0 && high == 0 ? flatbuffers.Long.ZERO : new flatbuffers.Long(low, high);\n-};\n-\n-/**\n- * @returns {number}\n- */\n-flatbuffers.Long.prototype.toFloat64 = function() {\n-  return (this.low >>> 0) + this.high * 0x100000000;\n-};\n-\n-/**\n- * @param {flatbuffers.Long} other\n- * @returns {boolean}\n- */\n-flatbuffers.Long.prototype.equals = function(other) {\n-  return this.low == other.low && this.high == other.high;\n-};\n-\n-/**\n- * @type {flatbuffers.Long}\n- * @const\n- */\n-flatbuffers.Long.ZERO = new flatbuffers.Long(0, 0);\n-\n-/// @endcond\n-////////////////////////////////////////////////////////////////////////////////\n-/**\n- * Create a FlatBufferBuilder.\n- *\n- * @constructor\n- * @param {number=} opt_initial_size\n- */\n-flatbuffers.Builder = function(opt_initial_size) {\n-  if (!opt_initial_size) {\n-    var initial_size = 1024;\n-  } else {\n-    var initial_size = opt_initial_size;\n-  }\n-\n-  /**\n-   * @type {flatbuffers.ByteBuffer}\n-   * @private\n-   */\n-  this.bb = flatbuffers.ByteBuffer.allocate(initial_size);\n-\n-  /**\n-   * Remaining space in the ByteBuffer.\n-   *\n-   * @type {number}\n-   * @private\n-   */\n-  this.space = initial_size;\n-\n-  /**\n-   * Minimum alignment encountered so far.\n-   *\n-   * @type {number}\n-   * @private\n-   */\n-  this.minalign = 1;\n-\n-  /**\n-   * The vtable for the current table.\n-   *\n-   * @type {Array.<number>}\n-   * @private\n-   */\n-  this.vtable = null;\n-\n-  /**\n-   * The amount of fields we're actually using.\n-   *\n-   * @type {number}\n-   * @private\n-   */\n-  this.vtable_in_use = 0;\n-\n-  /**\n-   * Whether we are currently serializing a table.\n-   *\n-   * @type {boolean}\n-   * @private\n-   */\n-  this.isNested = false;\n-\n-  /**\n-   * Starting offset of the current struct/table.\n-   *\n-   * @type {number}\n-   * @private\n-   */\n-  this.object_start = 0;\n-\n-  /**\n-   * List of offsets of all vtables.\n-   *\n-   * @type {Array.<number>}\n-   * @private\n-   */\n-  this.vtables = [];\n-\n-  /**\n-   * For the current vector being built.\n-   *\n-   * @type {number}\n-   * @private\n-   */\n-  this.vector_num_elems = 0;\n-\n-  /**\n-   * False omits default values from the serialized data\n-   *\n-   * @type {boolean}\n-   * @private\n-   */\n-  this.force_defaults = false;\n-};\n-\n-/**\n- * In order to save space, fields that are set to their default value\n- * don't get serialized into the buffer. Forcing defaults provides a\n- * way to manually disable this optimization.\n- *\n- * @param {boolean} forceDefaults true always serializes default values\n- */\n-flatbuffers.Builder.prototype.forceDefaults = function(forceDefaults) {\n-  this.force_defaults = forceDefaults;\n-};\n-\n-/**\n- * Get the ByteBuffer representing the FlatBuffer. Only call this after you've\n- * called finish(). The actual data starts at the ByteBuffer's current position,\n- * not necessarily at 0.\n- *\n- * @returns {flatbuffers.ByteBuffer}\n- */\n-flatbuffers.Builder.prototype.dataBuffer = function() {\n-  return this.bb;\n-};\n-\n-/**\n- * Get the bytes representing the FlatBuffer. Only call this after you've\n- * called finish().\n- *\n- * @returns {Uint8Array}\n- */\n-flatbuffers.Builder.prototype.asUint8Array = function() {\n-  return this.bb.bytes().subarray(this.bb.position(), this.bb.position() + this.offset());\n-};\n-\n-/// @cond FLATBUFFERS_INTERNAL\n-/**\n- * Prepare to write an element of `size` after `additional_bytes` have been\n- * written, e.g. if you write a string, you need to align such the int length\n- * field is aligned to 4 bytes, and the string data follows it directly. If all\n- * you need to do is alignment, `additional_bytes` will be 0.\n- *\n- * @param {number} size This is the of the new element to write\n- * @param {number} additional_bytes The padding size\n- */\n-flatbuffers.Builder.prototype.prep = function(size, additional_bytes) {\n-  // Track the biggest thing we've ever aligned to.\n-  if (size > this.minalign) {\n-    this.minalign = size;\n-  }\n-\n-  // Find the amount of alignment needed such that `size` is properly\n-  // aligned after `additional_bytes`\n-  var align_size = ((~(this.bb.capacity() - this.space + additional_bytes)) + 1) & (size - 1);\n-\n-  // Reallocate the buffer if needed.\n-  while (this.space < align_size + size + additional_bytes) {\n-    var old_buf_size = this.bb.capacity();\n-    this.bb = flatbuffers.Builder.growByteBuffer(this.bb);\n-    this.space += this.bb.capacity() - old_buf_size;\n-  }\n-\n-  this.pad(align_size);\n-};\n-\n-/**\n- * @param {number} byte_size\n- */\n-flatbuffers.Builder.prototype.pad = function(byte_size) {\n-  for (var i = 0; i < byte_size; i++) {\n-    this.bb.writeInt8(--this.space, 0);\n-  }\n-};\n-\n-/**\n- * @param {number} value\n- */\n-flatbuffers.Builder.prototype.writeInt8 = function(value) {\n-  this.bb.writeInt8(this.space -= 1, value);\n-};\n-\n-/**\n- * @param {number} value\n- */\n-flatbuffers.Builder.prototype.writeInt16 = function(value) {\n-  this.bb.writeInt16(this.space -= 2, value);\n-};\n-\n-/**\n- * @param {number} value\n- */\n-flatbuffers.Builder.prototype.writeInt32 = function(value) {\n-  this.bb.writeInt32(this.space -= 4, value);\n-};\n-\n-/**\n- * @param {flatbuffers.Long} value\n- */\n-flatbuffers.Builder.prototype.writeInt64 = function(value) {\n-  this.bb.writeInt64(this.space -= 8, value);\n-};\n-\n-/**\n- * @param {number} value\n- */\n-flatbuffers.Builder.prototype.writeFloat32 = function(value) {\n-  this.bb.writeFloat32(this.space -= 4, value);\n-};\n-\n-/**\n- * @param {number} value\n- */\n-flatbuffers.Builder.prototype.writeFloat64 = function(value) {\n-  this.bb.writeFloat64(this.space -= 8, value);\n-};\n-/// @endcond\n-\n-/**\n- * Add an `int8` to the buffer, properly aligned, and grows the buffer (if necessary).\n- * @param {number} value The `int8` to add the the buffer.\n- */\n-flatbuffers.Builder.prototype.addInt8 = function(value) {\n-  this.prep(1, 0);\n-  this.writeInt8(value);\n-};\n-\n-/**\n- * Add an `int16` to the buffer, properly aligned, and grows the buffer (if necessary).\n- * @param {number} value The `int16` to add the the buffer.\n- */\n-flatbuffers.Builder.prototype.addInt16 = function(value) {\n-  this.prep(2, 0);\n-  this.writeInt16(value);\n-};\n-\n-/**\n- * Add an `int32` to the buffer, properly aligned, and grows the buffer (if necessary).\n- * @param {number} value The `int32` to add the the buffer.\n- */\n-flatbuffers.Builder.prototype.addInt32 = function(value) {\n-  this.prep(4, 0);\n-  this.writeInt32(value);\n-};\n-\n-/**\n- * Add an `int64` to the buffer, properly aligned, and grows the buffer (if necessary).\n- * @param {flatbuffers.Long} value The `int64` to add the the buffer.\n- */\n-flatbuffers.Builder.prototype.addInt64 = function(value) {\n-  this.prep(8, 0);\n-  this.writeInt64(value);\n-};\n-\n-/**\n- * Add a `float32` to the buffer, properly aligned, and grows the buffer (if necessary).\n- * @param {number} value The `float32` to add the the buffer.\n- */\n-flatbuffers.Builder.prototype.addFloat32 = function(value) {\n-  this.prep(4, 0);\n-  this.writeFloat32(value);\n-};\n-\n-/**\n- * Add a `float64` to the buffer, properly aligned, and grows the buffer (if necessary).\n- * @param {number} value The `float64` to add the the buffer.\n- */\n-flatbuffers.Builder.prototype.addFloat64 = function(value) {\n-  this.prep(8, 0);\n-  this.writeFloat64(value);\n-};\n-\n-/// @cond FLATBUFFERS_INTERNAL\n-/**\n- * @param {number} voffset\n- * @param {number} value\n- * @param {number} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldInt8 = function(voffset, value, defaultValue) {\n-  if (this.force_defaults || value != defaultValue) {\n-    this.addInt8(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * @param {number} voffset\n- * @param {number} value\n- * @param {number} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldInt16 = function(voffset, value, defaultValue) {\n-  if (this.force_defaults || value != defaultValue) {\n-    this.addInt16(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * @param {number} voffset\n- * @param {number} value\n- * @param {number} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldInt32 = function(voffset, value, defaultValue) {\n-  if (this.force_defaults || value != defaultValue) {\n-    this.addInt32(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * @param {number} voffset\n- * @param {flatbuffers.Long} value\n- * @param {flatbuffers.Long} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldInt64 = function(voffset, value, defaultValue) {\n-  if (this.force_defaults || !value.equals(defaultValue)) {\n-    this.addInt64(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * @param {number} voffset\n- * @param {number} value\n- * @param {number} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldFloat32 = function(voffset, value, defaultValue) {\n-  if (this.force_defaults || value != defaultValue) {\n-    this.addFloat32(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * @param {number} voffset\n- * @param {number} value\n- * @param {number} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldFloat64 = function(voffset, value, defaultValue) {\n-  if (this.force_defaults || value != defaultValue) {\n-    this.addFloat64(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * @param {number} voffset\n- * @param {flatbuffers.Offset} value\n- * @param {flatbuffers.Offset} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldOffset = function(voffset, value, defaultValue) {\n-  if (this.force_defaults || value != defaultValue) {\n-    this.addOffset(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * Structs are stored inline, so nothing additional is being added. `d` is always 0.\n- *\n- * @param {number} voffset\n- * @param {flatbuffers.Offset} value\n- * @param {flatbuffers.Offset} defaultValue\n- */\n-flatbuffers.Builder.prototype.addFieldStruct = function(voffset, value, defaultValue) {\n-  if (value != defaultValue) {\n-    this.nested(value);\n-    this.slot(voffset);\n-  }\n-};\n-\n-/**\n- * Structures are always stored inline, they need to be created right\n- * where they're used.  You'll get this assertion failure if you\n- * created it elsewhere.\n- *\n- * @param {flatbuffers.Offset} obj The offset of the created object\n- */\n-flatbuffers.Builder.prototype.nested = function(obj) {\n-  if (obj != this.offset()) {\n-    throw new Error('FlatBuffers: struct must be serialized inline.');\n-  }\n-};\n-\n-/**\n- * Should not be creating any other object, string or vector\n- * while an object is being constructed\n- */\n-flatbuffers.Builder.prototype.notNested = function() {\n-  if (this.isNested) {\n-    throw new Error('FlatBuffers: object serialization must not be nested.');\n-  }\n-};\n-\n-/**\n- * Set the current vtable at `voffset` to the current location in the buffer.\n- *\n- * @param {number} voffset\n- */\n-flatbuffers.Builder.prototype.slot = function(voffset) {\n-  this.vtable[voffset] = this.offset();\n-};\n-\n-/**\n- * @returns {flatbuffers.Offset} Offset relative to the end of the buffer.\n- */\n-flatbuffers.Builder.prototype.offset = function() {\n-  return this.bb.capacity() - this.space;\n-};\n-\n-/**\n- * Doubles the size of the backing ByteBuffer and copies the old data towards\n- * the end of the new buffer (since we build the buffer backwards).\n- *\n- * @param {flatbuffers.ByteBuffer} bb The current buffer with the existing data\n- * @returns {flatbuffers.ByteBuffer} A new byte buffer with the old data copied\n- * to it. The data is located at the end of the buffer.\n- *\n- * uint8Array.set() formally takes {Array<number>|ArrayBufferView}, so to pass\n- * it a uint8Array we need to suppress the type check:\n- * @suppress {checkTypes}\n- */\n-flatbuffers.Builder.growByteBuffer = function(bb) {\n-  var old_buf_size = bb.capacity();\n-\n-  // Ensure we don't grow beyond what fits in an int.\n-  if (old_buf_size & 0xC0000000) {\n-    throw new Error('FlatBuffers: cannot grow buffer beyond 2 gigabytes.');\n-  }\n-\n-  var new_buf_size = old_buf_size << 1;\n-  var nbb = flatbuffers.ByteBuffer.allocate(new_buf_size);\n-  nbb.setPosition(new_buf_size - old_buf_size);\n-  nbb.bytes().set(bb.bytes(), new_buf_size - old_buf_size);\n-  return nbb;\n-};\n-/// @endcond\n-\n-/**\n- * Adds on offset, relative to where it will be written.\n- *\n- * @param {flatbuffers.Offset} offset The offset to add.\n- */\n-flatbuffers.Builder.prototype.addOffset = function(offset) {\n-  this.prep(flatbuffers.SIZEOF_INT, 0); // Ensure alignment is already done.\n-  this.writeInt32(this.offset() - offset + flatbuffers.SIZEOF_INT);\n-};\n-\n-/// @cond FLATBUFFERS_INTERNAL\n-/**\n- * Start encoding a new object in the buffer.  Users will not usually need to\n- * call this directly. The FlatBuffers compiler will generate helper methods\n- * that call this method internally.\n- *\n- * @param {number} numfields\n- */\n-flatbuffers.Builder.prototype.startObject = function(numfields) {\n-  this.notNested();\n-  if (this.vtable == null) {\n-    this.vtable = [];\n-  }\n-  this.vtable_in_use = numfields;\n-  for (var i = 0; i < numfields; i++) {\n-    this.vtable[i] = 0; // This will push additional elements as needed\n-  }\n-  this.isNested = true;\n-  this.object_start = this.offset();\n-};\n-\n-/**\n- * Finish off writing the object that is under construction.\n- *\n- * @returns {flatbuffers.Offset} The offset to the object inside `dataBuffer`\n- */\n-flatbuffers.Builder.prototype.endObject = function() {\n-  if (this.vtable == null || !this.isNested) {\n-    throw new Error('FlatBuffers: endObject called without startObject');\n-  }\n-\n-  this.addInt32(0);\n-  var vtableloc = this.offset();\n-\n-  // Write out the current vtable.\n-  for (var i = this.vtable_in_use - 1; i >= 0; i--) {\n-    // Offset relative to the start of the table.\n-    this.addInt16(this.vtable[i] != 0 ? vtableloc - this.vtable[i] : 0);\n-  }\n-\n-  var standard_fields = 2; // The fields below:\n-  this.addInt16(vtableloc - this.object_start);\n-  this.addInt16((this.vtable_in_use + standard_fields) * flatbuffers.SIZEOF_SHORT);\n-\n-  // Search for an existing vtable that matches the current one.\n-  var existing_vtable = 0;\n-outer_loop:\n-  for (var i = 0; i < this.vtables.length; i++) {\n-    var vt1 = this.bb.capacity() - this.vtables[i];\n-    var vt2 = this.space;\n-    var len = this.bb.readInt16(vt1);\n-    if (len == this.bb.readInt16(vt2)) {\n-      for (var j = flatbuffers.SIZEOF_SHORT; j < len; j += flatbuffers.SIZEOF_SHORT) {\n-        if (this.bb.readInt16(vt1 + j) != this.bb.readInt16(vt2 + j)) {\n-          continue outer_loop;\n-        }\n-      }\n-      existing_vtable = this.vtables[i];\n-      break;\n-    }\n-  }\n-\n-  if (existing_vtable) {\n-    // Found a match:\n-    // Remove the current vtable.\n-    this.space = this.bb.capacity() - vtableloc;\n-\n-    // Point table to existing vtable.\n-    this.bb.writeInt32(this.space, existing_vtable - vtableloc);\n-  } else {\n-    // No match:\n-    // Add the location of the current vtable to the list of vtables.\n-    this.vtables.push(this.offset());\n-\n-    // Point table to current vtable.\n-    this.bb.writeInt32(this.bb.capacity() - vtableloc, this.offset() - vtableloc);\n-  }\n-\n-  this.isNested = false;\n-  return vtableloc;\n-};\n-/// @endcond\n-\n-/**\n- * Finalize a buffer, poiting to the given `root_table`.\n- *\n- * @param {flatbuffers.Offset} root_table\n- * @param {string=} opt_file_identifier\n- */\n-flatbuffers.Builder.prototype.finish = function(root_table, opt_file_identifier) {\n-  if (opt_file_identifier) {\n-    var file_identifier = opt_file_identifier;\n-    this.prep(this.minalign, flatbuffers.SIZEOF_INT +\n-      flatbuffers.FILE_IDENTIFIER_LENGTH);\n-    if (file_identifier.length != flatbuffers.FILE_IDENTIFIER_LENGTH) {\n-      throw new Error('FlatBuffers: file identifier must be length ' +\n-        flatbuffers.FILE_IDENTIFIER_LENGTH);\n-    }\n-    for (var i = flatbuffers.FILE_IDENTIFIER_LENGTH - 1; i >= 0; i--) {\n-      this.writeInt8(file_identifier.charCodeAt(i));\n-    }\n-  }\n-  this.prep(this.minalign, flatbuffers.SIZEOF_INT);\n-  this.addOffset(root_table);\n-  this.bb.setPosition(this.space);\n-};\n-\n-/// @cond FLATBUFFERS_INTERNAL\n-/**\n- * This checks a required field has been set in a given table that has\n- * just been constructed.\n- *\n- * @param {flatbuffers.Offset} table\n- * @param {number} field\n- */\n-flatbuffers.Builder.prototype.requiredField = function(table, field) {\n-  var table_start = this.bb.capacity() - table;\n-  var vtable_start = table_start - this.bb.readInt32(table_start);\n-  var ok = this.bb.readInt16(vtable_start + field) != 0;\n-\n-  // If this fails, the caller will show what field needs to be set.\n-  if (!ok) {\n-    throw new Error('FlatBuffers: field ' + field + ' must be set');\n-  }\n-};\n-\n-/**\n- * Start a new array/vector of objects.  Users usually will not call\n- * this directly. The FlatBuffers compiler will create a start/end\n- * method for vector types in generated code.\n- *\n- * @param {number} elem_size The size of each element in the array\n- * @param {number} num_elems The number of elements in the array\n- * @param {number} alignment The alignment of the array\n- */\n-flatbuffers.Builder.prototype.startVector = function(elem_size, num_elems, alignment) {\n-  this.notNested();\n-  this.vector_num_elems = num_elems;\n-  this.prep(flatbuffers.SIZEOF_INT, elem_size * num_elems);\n-  this.prep(alignment, elem_size * num_elems); // Just in case alignment > int.\n-};\n-\n-/**\n- * Finish off the creation of an array and all its elements. The array must be\n- * created with `startVector`.\n- *\n- * @returns {flatbuffers.Offset} The offset at which the newly created array\n- * starts.\n- */\n-flatbuffers.Builder.prototype.endVector = function() {\n-  this.writeInt32(this.vector_num_elems);\n-  return this.offset();\n-};\n-/// @endcond\n-\n-/**\n- * Encode the string `s` in the buffer using UTF-8. If a Uint8Array is passed\n- * instead of a string, it is assumed to contain valid UTF-8 encoded data.\n- *\n- * @param {string|Uint8Array} s The string to encode\n- * @return {flatbuffers.Offset} The offset in the buffer where the encoded string starts\n- */\n-flatbuffers.Builder.prototype.createString = function(s) {\n-  if (s instanceof Uint8Array) {\n-    var utf8 = s;\n-  } else {\n-    var utf8 = [];\n-    var i = 0;\n-\n-    while (i < s.length) {\n-      var codePoint;\n-\n-      // Decode UTF-16\n-      var a = s.charCodeAt(i++);\n-      if (a < 0xD800 || a >= 0xDC00) {\n-        codePoint = a;\n-      } else {\n-        var b = s.charCodeAt(i++);\n-        codePoint = (a << 10) + b + (0x10000 - (0xD800 << 10) - 0xDC00);\n-      }\n-\n-      // Encode UTF-8\n-      if (codePoint < 0x80) {\n-        utf8.push(codePoint);\n-      } else {\n-        if (codePoint < 0x800) {\n-          utf8.push(((codePoint >> 6) & 0x1F) | 0xC0);\n-        } else {\n-          if (codePoint < 0x10000) {\n-            utf8.push(((codePoint >> 12) & 0x0F) | 0xE0);\n-          } else {\n-            utf8.push(\n-              ((codePoint >> 18) & 0x07) | 0xF0,\n-              ((codePoint >> 12) & 0x3F) | 0x80);\n-          }\n-          utf8.push(((codePoint >> 6) & 0x3F) | 0x80);\n-        }\n-        utf8.push((codePoint & 0x3F) | 0x80);\n-      }\n-    }\n-  }\n-\n-  this.addInt8(0);\n-  this.startVector(1, utf8.length, 1);\n-  this.bb.setPosition(this.space -= utf8.length);\n-  for (var i = 0, offset = this.space, bytes = this.bb.bytes(); i < utf8.length; i++) {\n-    bytes[offset++] = utf8[i];\n-  }\n-  return this.endVector();\n-};\n-\n-/**\n- * A helper function to avoid generated code depending on this file directly.\n- *\n- * @param {number} low\n- * @param {number} high\n- * @returns {flatbuffers.Long}\n- */\n-flatbuffers.Builder.prototype.createLong = function(low, high) {\n-  return flatbuffers.Long.create(low, high);\n-};\n-////////////////////////////////////////////////////////////////////////////////\n-/// @cond FLATBUFFERS_INTERNAL\n-/**\n- * Create a new ByteBuffer with a given array of bytes (`Uint8Array`).\n- *\n- * @constructor\n- * @param {Uint8Array} bytes\n- */\n-flatbuffers.ByteBuffer = function(bytes) {\n-  /**\n-   * @type {Uint8Array}\n-   * @private\n-   */\n-  this.bytes_ = bytes;\n-\n-  /**\n-   * @type {number}\n-   * @private\n-   */\n-  this.position_ = 0;\n-};\n-\n-/**\n- * Create and allocate a new ByteBuffer with a given size.\n- *\n- * @param {number} byte_size\n- * @returns {flatbuffers.ByteBuffer}\n- */\n-flatbuffers.ByteBuffer.allocate = function(byte_size) {\n-  return new flatbuffers.ByteBuffer(new Uint8Array(byte_size));\n-};\n-\n-/**\n- * Get the underlying `Uint8Array`.\n- *\n- * @returns {Uint8Array}\n- */\n-flatbuffers.ByteBuffer.prototype.bytes = function() {\n-  return this.bytes_;\n-};\n-\n-/**\n- * Get the buffer's position.\n- *\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.position = function() {\n-  return this.position_;\n-};\n-\n-/**\n- * Set the buffer's position.\n- *\n- * @param {number} position\n- */\n-flatbuffers.ByteBuffer.prototype.setPosition = function(position) {\n-  this.position_ = position;\n-};\n-\n-/**\n- * Get the buffer's capacity.\n- *\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.capacity = function() {\n-  return this.bytes_.length;\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readInt8 = function(offset) {\n-  return this.readUint8(offset) << 24 >> 24;\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readUint8 = function(offset) {\n-  return this.bytes_[offset];\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readInt16 = function(offset) {\n-  return this.readUint16(offset) << 16 >> 16;\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readUint16 = function(offset) {\n-  return this.bytes_[offset] | this.bytes_[offset + 1] << 8;\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readInt32 = function(offset) {\n-  return this.bytes_[offset] | this.bytes_[offset + 1] << 8 | this.bytes_[offset + 2] << 16 | this.bytes_[offset + 3] << 24;\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readUint32 = function(offset) {\n-  return this.readInt32(offset) >>> 0;\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {flatbuffers.Long}\n- */\n-flatbuffers.ByteBuffer.prototype.readInt64 = function(offset) {\n-  return new flatbuffers.Long(this.readInt32(offset), this.readInt32(offset + 4));\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {flatbuffers.Long}\n- */\n-flatbuffers.ByteBuffer.prototype.readUint64 = function(offset) {\n-  return new flatbuffers.Long(this.readUint32(offset), this.readUint32(offset + 4));\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readFloat32 = function(offset) {\n-  flatbuffers.int32[0] = this.readInt32(offset);\n-  return flatbuffers.float32[0];\n-};\n-\n-/**\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.readFloat64 = function(offset) {\n-  flatbuffers.int32[flatbuffers.isLittleEndian ? 0 : 1] = this.readInt32(offset);\n-  flatbuffers.int32[flatbuffers.isLittleEndian ? 1 : 0] = this.readInt32(offset + 4);\n-  return flatbuffers.float64[0];\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number|boolean} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeInt8 = function(offset, value) {\n-  this.bytes_[offset] = /** @type {number} */(value);\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeUint8 = function(offset, value) {\n-  this.bytes_[offset] = value;\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeInt16 = function(offset, value) {\n-  this.bytes_[offset] = value;\n-  this.bytes_[offset + 1] = value >> 8;\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeUint16 = function(offset, value) {\n-    this.bytes_[offset] = value;\n-    this.bytes_[offset + 1] = value >> 8;\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeInt32 = function(offset, value) {\n-  this.bytes_[offset] = value;\n-  this.bytes_[offset + 1] = value >> 8;\n-  this.bytes_[offset + 2] = value >> 16;\n-  this.bytes_[offset + 3] = value >> 24;\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeUint32 = function(offset, value) {\n-    this.bytes_[offset] = value;\n-    this.bytes_[offset + 1] = value >> 8;\n-    this.bytes_[offset + 2] = value >> 16;\n-    this.bytes_[offset + 3] = value >> 24;\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {flatbuffers.Long} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeInt64 = function(offset, value) {\n-  this.writeInt32(offset, value.low);\n-  this.writeInt32(offset + 4, value.high);\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {flatbuffers.Long} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeUint64 = function(offset, value) {\n-    this.writeUint32(offset, value.low);\n-    this.writeUint32(offset + 4, value.high);\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeFloat32 = function(offset, value) {\n-  flatbuffers.float32[0] = value;\n-  this.writeInt32(offset, flatbuffers.int32[0]);\n-};\n-\n-/**\n- * @param {number} offset\n- * @param {number} value\n- */\n-flatbuffers.ByteBuffer.prototype.writeFloat64 = function(offset, value) {\n-  flatbuffers.float64[0] = value;\n-  this.writeInt32(offset, flatbuffers.int32[flatbuffers.isLittleEndian ? 0 : 1]);\n-  this.writeInt32(offset + 4, flatbuffers.int32[flatbuffers.isLittleEndian ? 1 : 0]);\n-};\n-\n-/**\n- * Look up a field in the vtable, return an offset into the object, or 0 if the\n- * field is not present.\n- *\n- * @param {number} bb_pos\n- * @param {number} vtable_offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.__offset = function(bb_pos, vtable_offset) {\n-  var vtable = bb_pos - this.readInt32(bb_pos);\n-  return vtable_offset < this.readInt16(vtable) ? this.readInt16(vtable + vtable_offset) : 0;\n-};\n-\n-/**\n- * Initialize any Table-derived type to point to the union at the given offset.\n- *\n- * @param {flatbuffers.Table} t\n- * @param {number} offset\n- * @returns {flatbuffers.Table}\n- */\n-flatbuffers.ByteBuffer.prototype.__union = function(t, offset) {\n-  t.bb_pos = offset + this.readInt32(offset);\n-  t.bb = this;\n-  return t;\n-};\n-\n-/**\n- * Create a JavaScript string from UTF-8 data stored inside the FlatBuffer.\n- * This allocates a new string and converts to wide chars upon each access.\n- *\n- * To avoid the conversion to UTF-16, pass flatbuffers.Encoding.UTF8_BYTES as\n- * the \"optionalEncoding\" argument. This is useful for avoiding conversion to\n- * and from UTF-16 when the data will just be packaged back up in another\n- * FlatBuffer later on.\n- *\n- * @param {number} offset\n- * @param {flatbuffers.Encoding=} opt_encoding Defaults to UTF16_STRING\n- * @returns {string|Uint8Array}\n- */\n-flatbuffers.ByteBuffer.prototype.__string = function(offset, opt_encoding) {\n-  offset += this.readInt32(offset);\n-\n-  var length = this.readInt32(offset);\n-  var result = '';\n-  var i = 0;\n-\n-  offset += flatbuffers.SIZEOF_INT;\n-\n-  if (opt_encoding === flatbuffers.Encoding.UTF8_BYTES) {\n-    return this.bytes_.subarray(offset, offset + length);\n-  }\n-\n-  while (i < length) {\n-    var codePoint;\n-\n-    // Decode UTF-8\n-    var a = this.readUint8(offset + i++);\n-    if (a < 0xC0) {\n-      codePoint = a;\n-    } else {\n-      var b = this.readUint8(offset + i++);\n-      if (a < 0xE0) {\n-        codePoint =\n-          ((a & 0x1F) << 6) |\n-          (b & 0x3F);\n-      } else {\n-        var c = this.readUint8(offset + i++);\n-        if (a < 0xF0) {\n-          codePoint =\n-            ((a & 0x0F) << 12) |\n-            ((b & 0x3F) << 6) |\n-            (c & 0x3F);\n-        } else {\n-          var d = this.readUint8(offset + i++);\n-          codePoint =\n-            ((a & 0x07) << 18) |\n-            ((b & 0x3F) << 12) |\n-            ((c & 0x3F) << 6) |\n-            (d & 0x3F);\n-        }\n-      }\n-    }\n-\n-    // Encode UTF-16\n-    if (codePoint < 0x10000) {\n-      result += String.fromCharCode(codePoint);\n-    } else {\n-      codePoint -= 0x10000;\n-      result += String.fromCharCode(\n-        (codePoint >> 10) + 0xD800,\n-        (codePoint & ((1 << 10) - 1)) + 0xDC00);\n-    }\n-  }\n-\n-  return result;\n-};\n-\n-/**\n- * Retrieve the relative offset stored at \"offset\"\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.__indirect = function(offset) {\n-  return offset + this.readInt32(offset);\n-};\n-\n-/**\n- * Get the start of data of a vector whose offset is stored at \"offset\" in this object.\n- *\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.__vector = function(offset) {\n-  return offset + this.readInt32(offset) + flatbuffers.SIZEOF_INT; // data starts after the length\n-};\n-\n-/**\n- * Get the length of a vector whose offset is stored at \"offset\" in this object.\n- *\n- * @param {number} offset\n- * @returns {number}\n- */\n-flatbuffers.ByteBuffer.prototype.__vector_len = function(offset) {\n-  return this.readInt32(offset + this.readInt32(offset));\n-};\n-\n-/**\n- * @param {string} ident\n- * @returns {boolean}\n- */\n-flatbuffers.ByteBuffer.prototype.__has_identifier = function(ident) {\n-  if (ident.length != flatbuffers.FILE_IDENTIFIER_LENGTH) {\n-    throw new Error('FlatBuffers: file identifier must be length ' +\n-                    flatbuffers.FILE_IDENTIFIER_LENGTH);\n-  }\n-  for (var i = 0; i < flatbuffers.FILE_IDENTIFIER_LENGTH; i++) {\n-    if (ident.charCodeAt(i) != this.readInt8(this.position_ + flatbuffers.SIZEOF_INT + i)) {\n-      return false;\n-    }\n-  }\n-  return true;\n-};\n-\n-/**\n- * A helper function to avoid generated code depending on this file directly.\n- *\n- * @param {number} low\n- * @param {number} high\n- * @returns {flatbuffers.Long}\n- */\n-flatbuffers.ByteBuffer.prototype.createLong = function(low, high) {\n-  return flatbuffers.Long.create(low, high);\n-};\n-\n-// Exports for Node.js and RequireJS\n-exports.flatbuffers = flatbuffers;\n-\n-/// @endcond\n-/// @}\ndiff --git a/js/closure-compiler-scripts/text-encoding.js b/js/closure-compiler-scripts/text-encoding.js\ndeleted file mode 100644\nindex 398883ab9..000000000\n--- a/js/closure-compiler-scripts/text-encoding.js\n+++ /dev/null\n@@ -1,648 +0,0 @@\n-/**\n- * closure-compiler-friendly text-encoding-utf-8\n- * copied from\u00a0node_modules/text-encoding-utf-8/lib/encoding.cjs.js\n- * update as needed\n- */\n-\n- // This is free and unencumbered software released into the public domain.\n-// See LICENSE.md for more information.\n-\n-//\n-// Utilities\n-//\n-\n-goog.module(\"module$text_encoding_utf_8\");\n-goog.module.declareLegacyNamespace();\n-/**\n- * @param {number} a The number to test.\n- * @param {number} min The minimum value in the range, inclusive.\n- * @param {number} max The maximum value in the range, inclusive.\n- * @return {boolean} True if a >= min and a <= max.\n- */\n-function inRange(a, min, max) {\n-  return min <= a && a <= max;\n-}\n-\n-/**\n- * @param {*} o\n- * @return {Object}\n- */\n-function ToDictionary(o) {\n-  if (o === undefined) return {};\n-  if (o === Object(o)) return o;\n-  throw TypeError('Could not convert argument to dictionary');\n-}\n-\n-/**\n- * @param {string} string Input string of UTF-16 code units.\n- * @return {!Array.<number>} Code points.\n- */\n-function stringToCodePoints(string) {\n-  // https://heycam.github.io/webidl/#dfn-obtain-unicode\n-\n-  // 1. Let S be the DOMString value.\n-  var s = String(string);\n-\n-  // 2. Let n be the length of S.\n-  var n = s.length;\n-\n-  // 3. Initialize i to 0.\n-  var i = 0;\n-\n-  // 4. Initialize U to be an empty sequence of Unicode characters.\n-  var u = [];\n-\n-  // 5. While i < n:\n-  while (i < n) {\n-\n-    // 1. Let c be the code unit in S at index i.\n-    var c = s.charCodeAt(i);\n-\n-    // 2. Depending on the value of c:\n-\n-    // c < 0xD800 or c > 0xDFFF\n-    if (c < 0xD800 || c > 0xDFFF) {\n-      // Append to U the Unicode character with code point c.\n-      u.push(c);\n-    }\n-\n-    // 0xDC00 \u2264 c \u2264 0xDFFF\n-    else if (0xDC00 <= c && c <= 0xDFFF) {\n-      // Append to U a U+FFFD REPLACEMENT CHARACTER.\n-      u.push(0xFFFD);\n-    }\n-\n-    // 0xD800 \u2264 c \u2264 0xDBFF\n-    else if (0xD800 <= c && c <= 0xDBFF) {\n-      // 1. If i = n\u22121, then append to U a U+FFFD REPLACEMENT\n-      // CHARACTER.\n-      if (i === n - 1) {\n-        u.push(0xFFFD);\n-      }\n-      // 2. Otherwise, i < n\u22121:\n-      else {\n-        // 1. Let d be the code unit in S at index i+1.\n-        var d = string.charCodeAt(i + 1);\n-\n-        // 2. If 0xDC00 \u2264 d \u2264 0xDFFF, then:\n-        if (0xDC00 <= d && d <= 0xDFFF) {\n-          // 1. Let a be c & 0x3FF.\n-          var a = c & 0x3FF;\n-\n-          // 2. Let b be d & 0x3FF.\n-          var b = d & 0x3FF;\n-\n-          // 3. Append to U the Unicode character with code point\n-          // 2^16+2^10*a+b.\n-          u.push(0x10000 + (a << 10) + b);\n-\n-          // 4. Set i to i+1.\n-          i += 1;\n-        }\n-\n-        // 3. Otherwise, d < 0xDC00 or d > 0xDFFF. Append to U a\n-        // U+FFFD REPLACEMENT CHARACTER.\n-        else  {\n-          u.push(0xFFFD);\n-        }\n-      }\n-    }\n-\n-    // 3. Set i to i+1.\n-    i += 1;\n-  }\n-\n-  // 6. Return U.\n-  return u;\n-}\n-\n-/**\n- * @param {!Array.<number>} code_points Array of code points.\n- * @return {string} string String of UTF-16 code units.\n- */\n-function codePointsToString(code_points) {\n-  var s = '';\n-  for (var i = 0; i < code_points.length; ++i) {\n-    var cp = code_points[i];\n-    if (cp <= 0xFFFF) {\n-      s += String.fromCharCode(cp);\n-    } else {\n-      cp -= 0x10000;\n-      s += String.fromCharCode((cp >> 10) + 0xD800,\n-                               (cp & 0x3FF) + 0xDC00);\n-    }\n-  }\n-  return s;\n-}\n-\n-\n-//\n-// Implementation of Encoding specification\n-// https://encoding.spec.whatwg.org/\n-//\n-\n-//\n-// 3. Terminology\n-//\n-\n-/**\n- * End-of-stream is a special token that signifies no more tokens\n- * are in the stream.\n- * @const\n- */ var end_of_stream = -1;\n-\n-/**\n- * A stream represents an ordered sequence of tokens.\n- *\n- * @constructor\n- * @param {!(Array.<number>|Uint8Array)} tokens Array of tokens that provide the\n- * stream.\n- */\n-function Stream(tokens) {\n-  /** @type {!Array.<number>} */\n-  this.tokens = [].slice.call(tokens);\n-}\n-\n-Stream.prototype = {\n-  /**\n-   * @return {boolean} True if end-of-stream has been hit.\n-   */\n-  endOfStream: function() {\n-    return !this.tokens.length;\n-  },\n-\n-  /**\n-   * When a token is read from a stream, the first token in the\n-   * stream must be returned and subsequently removed, and\n-   * end-of-stream must be returned otherwise.\n-   *\n-   * @return {number} Get the next token from the stream, or\n-   * end_of_stream.\n-   */\n-   read: function() {\n-    if (!this.tokens.length)\n-      return end_of_stream;\n-     return this.tokens.shift();\n-   },\n-\n-  /**\n-   * When one or more tokens are prepended to a stream, those tokens\n-   * must be inserted, in given order, before the first token in the\n-   * stream.\n-   *\n-   * @param {(number|!Array.<number>)} token The token(s) to prepend to the stream.\n-   */\n-  prepend: function(token) {\n-    if (Array.isArray(token)) {\n-      var tokens = /**@type {!Array.<number>}*/(token);\n-      while (tokens.length)\n-        this.tokens.unshift(tokens.pop());\n-    } else {\n-      this.tokens.unshift(token);\n-    }\n-  },\n-\n-  /**\n-   * When one or more tokens are pushed to a stream, those tokens\n-   * must be inserted, in given order, after the last token in the\n-   * stream.\n-   *\n-   * @param {(number|!Array.<number>)} token The tokens(s) to prepend to the stream.\n-   */\n-  push: function(token) {\n-    if (Array.isArray(token)) {\n-      var tokens = /**@type {!Array.<number>}*/(token);\n-      while (tokens.length)\n-        this.tokens.push(tokens.shift());\n-    } else {\n-      this.tokens.push(token);\n-    }\n-  }\n-};\n-\n-//\n-// 4. Encodings\n-//\n-\n-// 4.1 Encoders and decoders\n-\n-/** @const */\n-var finished = -1;\n-\n-/**\n- * @param {boolean} fatal If true, decoding errors raise an exception.\n- * @param {number=} opt_code_point Override the standard fallback code point.\n- * @return {number} The code point to insert on a decoding error.\n- */\n-function decoderError(fatal, opt_code_point) {\n-  if (fatal)\n-    throw TypeError('Decoder error');\n-  return opt_code_point || 0xFFFD;\n-}\n-\n-//\n-// 7. API\n-//\n-\n-/** @const */ var DEFAULT_ENCODING = 'utf-8';\n-\n-// 7.1 Interface TextDecoder\n-\n-/**\n- * @constructor\n- * @param {string=} encoding The label of the encoding;\n- *     defaults to 'utf-8'.\n- * @param {Object=} options\n- */\n-function TextDecoder(encoding, options) {\n-  if (!(this instanceof TextDecoder)) {\n-    return new TextDecoder(encoding, options);\n-  }\n-  encoding = encoding !== undefined ? String(encoding).toLowerCase() : DEFAULT_ENCODING;\n-  if (encoding !== DEFAULT_ENCODING) {\n-    throw new Error('Encoding not supported. Only utf-8 is supported');\n-  }\n-  options = ToDictionary(options);\n-\n-  /** @private @type {boolean} */\n-  this._streaming = false;\n-  /** @private @type {boolean} */\n-  this._BOMseen = false;\n-  /** @private @type {?Decoder} */\n-  this._decoder = null;\n-  /** @private @type {boolean} */\n-  this._fatal = Boolean(options['fatal']);\n-  /** @private @type {boolean} */\n-  this._ignoreBOM = Boolean(options['ignoreBOM']);\n-\n-  Object.defineProperty(this, 'encoding', {value: 'utf-8'});\n-  Object.defineProperty(this, 'fatal', {value: this._fatal});\n-  Object.defineProperty(this, 'ignoreBOM', {value: this._ignoreBOM});\n-}\n-\n-TextDecoder.prototype = {\n-  /**\n-   * @param {ArrayBufferView=} input The buffer of bytes to decode.\n-   * @param {Object=} options\n-   * @return {string} The decoded string.\n-   */\n-  decode: function decode(input, options) {\n-    var bytes;\n-    if (typeof input === 'object' && input instanceof ArrayBuffer) {\n-      bytes = new Uint8Array(input);\n-    } else if (typeof input === 'object' && 'buffer' in input &&\n-               input.buffer instanceof ArrayBuffer) {\n-      bytes = new Uint8Array(input.buffer,\n-                             input.byteOffset,\n-                             input.byteLength);\n-    } else {\n-      bytes = new Uint8Array(0);\n-    }\n-\n-    options = ToDictionary(options);\n-\n-    if (!this._streaming) {\n-      this._decoder = new UTF8Decoder({fatal: this._fatal});\n-      this._BOMseen = false;\n-    }\n-    this._streaming = Boolean(options['stream']);\n-\n-    var input_stream = new Stream(bytes);\n-\n-    var code_points = [];\n-\n-    /** @type {?(number|!Array.<number>)} */\n-    var result;\n-\n-    while (!input_stream.endOfStream()) {\n-      result = this._decoder.handler(input_stream, input_stream.read());\n-      if (result === finished)\n-        break;\n-      if (result === null)\n-        continue;\n-      if (Array.isArray(result))\n-        code_points.push.apply(code_points, /**@type {!Array.<number>}*/(result));\n-      else\n-        code_points.push(result);\n-    }\n-    if (!this._streaming) {\n-      do {\n-        result = this._decoder.handler(input_stream, input_stream.read());\n-        if (result === finished)\n-          break;\n-        if (result === null)\n-          continue;\n-        if (Array.isArray(result))\n-          code_points.push.apply(code_points, /**@type {!Array.<number>}*/(result));\n-        else\n-          code_points.push(result);\n-      } while (!input_stream.endOfStream());\n-      this._decoder = null;\n-    }\n-\n-    if (code_points.length) {\n-      // If encoding is one of utf-8, utf-16be, and utf-16le, and\n-      // ignore BOM flag and BOM seen flag are unset, run these\n-      // subsubsteps:\n-      if (['utf-8'].indexOf(this.encoding) !== -1 &&\n-          !this._ignoreBOM && !this._BOMseen) {\n-        // If token is U+FEFF, set BOM seen flag.\n-        if (code_points[0] === 0xFEFF) {\n-          this._BOMseen = true;\n-          code_points.shift();\n-        } else {\n-          // Otherwise, if token is not end-of-stream, set BOM seen\n-          // flag and append token to output.\n-          this._BOMseen = true;\n-        }\n-      }\n-    }\n-\n-    return codePointsToString(code_points);\n-  }\n-};\n-\n-// 7.2 Interface TextEncoder\n-\n-/**\n- * @constructor\n- * @param {string=} encoding The label of the encoding;\n- *     defaults to 'utf-8'.\n- * @param {Object=} options\n- */\n-function TextEncoder(encoding, options) {\n-  if (!(this instanceof TextEncoder))\n-    return new TextEncoder(encoding, options);\n-  encoding = encoding !== undefined ? String(encoding).toLowerCase() : DEFAULT_ENCODING;\n-  if (encoding !== DEFAULT_ENCODING) {\n-    throw new Error('Encoding not supported. Only utf-8 is supported');\n-  }\n-  options = ToDictionary(options);\n-\n-  /** @private @type {boolean} */\n-  this._streaming = false;\n-  /** @private @type {?Encoder} */\n-  this._encoder = null;\n-  /** @private @type {{fatal: boolean}} */\n-  this._options = {fatal: Boolean(options['fatal'])};\n-\n-  Object.defineProperty(this, 'encoding', {value: 'utf-8'});\n-}\n-\n-TextEncoder.prototype = {\n-  /**\n-   * @param {string=} opt_string The string to encode.\n-   * @param {Object=} options\n-   * @return {Uint8Array} Encoded bytes, as a Uint8Array.\n-   */\n-  encode: function encode(opt_string, options) {\n-    opt_string = opt_string ? String(opt_string) : '';\n-    options = ToDictionary(options);\n-\n-    // NOTE: This option is nonstandard. None of the encodings\n-    // permitted for encoding (i.e. UTF-8, UTF-16) are stateful,\n-    // so streaming is not necessary.\n-    if (!this._streaming)\n-      this._encoder = new UTF8Encoder(this._options);\n-    this._streaming = Boolean(options['stream']);\n-\n-    var bytes = [];\n-    var input_stream = new Stream(stringToCodePoints(opt_string));\n-    /** @type {?(number|!Array.<number>)} */\n-    var result;\n-    while (!input_stream.endOfStream()) {\n-      result = this._encoder.handler(input_stream, input_stream.read());\n-      if (result === finished)\n-        break;\n-      if (Array.isArray(result))\n-        bytes.push.apply(bytes, /**@type {!Array.<number>}*/(result));\n-      else\n-        bytes.push(result);\n-    }\n-    if (!this._streaming) {\n-      while (true) {\n-        result = this._encoder.handler(input_stream, input_stream.read());\n-        if (result === finished)\n-          break;\n-        if (Array.isArray(result))\n-          bytes.push.apply(bytes, /**@type {!Array.<number>}*/(result));\n-        else\n-          bytes.push(result);\n-      }\n-      this._encoder = null;\n-    }\n-    return new Uint8Array(bytes);\n-  }\n-};\n-\n-//\n-// 8. The encoding\n-//\n-\n-// 8.1 utf-8\n-\n-/**\n- * @constructor\n- * @implements {Decoder}\n- * @param {{fatal: boolean}} options\n- */\n-function UTF8Decoder(options) {\n-  var fatal = options.fatal;\n-\n-  // utf-8's decoder's has an associated utf-8 code point, utf-8\n-  // bytes seen, and utf-8 bytes needed (all initially 0), a utf-8\n-  // lower boundary (initially 0x80), and a utf-8 upper boundary\n-  // (initially 0xBF).\n-  var /** @type {number} */ utf8_code_point = 0,\n-      /** @type {number} */ utf8_bytes_seen = 0,\n-      /** @type {number} */ utf8_bytes_needed = 0,\n-      /** @type {number} */ utf8_lower_boundary = 0x80,\n-      /** @type {number} */ utf8_upper_boundary = 0xBF;\n-\n-  /**\n-   * @param {Stream} stream The stream of bytes being decoded.\n-   * @param {number} bite The next byte read from the stream.\n-   * @return {?(number|!Array.<number>)} The next code point(s)\n-   *     decoded, or null if not enough data exists in the input\n-   *     stream to decode a complete code point.\n-   */\n-  this.handler = function(stream, bite) {\n-    // 1. If byte is end-of-stream and utf-8 bytes needed is not 0,\n-    // set utf-8 bytes needed to 0 and return error.\n-    if (bite === end_of_stream && utf8_bytes_needed !== 0) {\n-      utf8_bytes_needed = 0;\n-      return decoderError(fatal);\n-    }\n-\n-    // 2. If byte is end-of-stream, return finished.\n-    if (bite === end_of_stream)\n-      return finished;\n-\n-    // 3. If utf-8 bytes needed is 0, based on byte:\n-    if (utf8_bytes_needed === 0) {\n-\n-      // 0x00 to 0x7F\n-      if (inRange(bite, 0x00, 0x7F)) {\n-        // Return a code point whose value is byte.\n-        return bite;\n-      }\n-\n-      // 0xC2 to 0xDF\n-      if (inRange(bite, 0xC2, 0xDF)) {\n-        // Set utf-8 bytes needed to 1 and utf-8 code point to byte\n-        // \u2212 0xC0.\n-        utf8_bytes_needed = 1;\n-        utf8_code_point = bite - 0xC0;\n-      }\n-\n-      // 0xE0 to 0xEF\n-      else if (inRange(bite, 0xE0, 0xEF)) {\n-        // 1. If byte is 0xE0, set utf-8 lower boundary to 0xA0.\n-        if (bite === 0xE0)\n-          utf8_lower_boundary = 0xA0;\n-        // 2. If byte is 0xED, set utf-8 upper boundary to 0x9F.\n-        if (bite === 0xED)\n-          utf8_upper_boundary = 0x9F;\n-        // 3. Set utf-8 bytes needed to 2 and utf-8 code point to\n-        // byte \u2212 0xE0.\n-        utf8_bytes_needed = 2;\n-        utf8_code_point = bite - 0xE0;\n-      }\n-\n-      // 0xF0 to 0xF4\n-      else if (inRange(bite, 0xF0, 0xF4)) {\n-        // 1. If byte is 0xF0, set utf-8 lower boundary to 0x90.\n-        if (bite === 0xF0)\n-          utf8_lower_boundary = 0x90;\n-        // 2. If byte is 0xF4, set utf-8 upper boundary to 0x8F.\n-        if (bite === 0xF4)\n-          utf8_upper_boundary = 0x8F;\n-        // 3. Set utf-8 bytes needed to 3 and utf-8 code point to\n-        // byte \u2212 0xF0.\n-        utf8_bytes_needed = 3;\n-        utf8_code_point = bite - 0xF0;\n-      }\n-\n-      // Otherwise\n-      else {\n-        // Return error.\n-        return decoderError(fatal);\n-      }\n-\n-      // Then (byte is in the range 0xC2 to 0xF4) set utf-8 code\n-      // point to utf-8 code point << (6 \u00d7 utf-8 bytes needed) and\n-      // return continue.\n-      utf8_code_point = utf8_code_point << (6 * utf8_bytes_needed);\n-      return null;\n-    }\n-\n-    // 4. If byte is not in the range utf-8 lower boundary to utf-8\n-    // upper boundary, run these substeps:\n-    if (!inRange(bite, utf8_lower_boundary, utf8_upper_boundary)) {\n-\n-      // 1. Set utf-8 code point, utf-8 bytes needed, and utf-8\n-      // bytes seen to 0, set utf-8 lower boundary to 0x80, and set\n-      // utf-8 upper boundary to 0xBF.\n-      utf8_code_point = utf8_bytes_needed = utf8_bytes_seen = 0;\n-      utf8_lower_boundary = 0x80;\n-      utf8_upper_boundary = 0xBF;\n-\n-      // 2. Prepend byte to stream.\n-      stream.prepend(bite);\n-\n-      // 3. Return error.\n-      return decoderError(fatal);\n-    }\n-\n-    // 5. Set utf-8 lower boundary to 0x80 and utf-8 upper boundary\n-    // to 0xBF.\n-    utf8_lower_boundary = 0x80;\n-    utf8_upper_boundary = 0xBF;\n-\n-    // 6. Increase utf-8 bytes seen by one and set utf-8 code point\n-    // to utf-8 code point + (byte \u2212 0x80) << (6 \u00d7 (utf-8 bytes\n-    // needed \u2212 utf-8 bytes seen)).\n-    utf8_bytes_seen += 1;\n-    utf8_code_point += (bite - 0x80) << (6 * (utf8_bytes_needed - utf8_bytes_seen));\n-\n-    // 7. If utf-8 bytes seen is not equal to utf-8 bytes needed,\n-    // continue.\n-    if (utf8_bytes_seen !== utf8_bytes_needed)\n-      return null;\n-\n-    // 8. Let code point be utf-8 code point.\n-    var code_point = utf8_code_point;\n-\n-    // 9. Set utf-8 code point, utf-8 bytes needed, and utf-8 bytes\n-    // seen to 0.\n-    utf8_code_point = utf8_bytes_needed = utf8_bytes_seen = 0;\n-\n-    // 10. Return a code point whose value is code point.\n-    return code_point;\n-  };\n-}\n-\n-/**\n- * @constructor\n- * @implements {Encoder}\n- * @param {{fatal: boolean}} options\n- */\n-function UTF8Encoder(options) {\n-  var fatal = options.fatal;\n-  /**\n-   * @param {Stream} stream Input stream.\n-   * @param {number} code_point Next code point read from the stream.\n-   * @return {(number|!Array.<number>)} Byte(s) to emit.\n-   */\n-  this.handler = function(stream, code_point) {\n-    // 1. If code point is end-of-stream, return finished.\n-    if (code_point === end_of_stream)\n-      return finished;\n-\n-    // 2. If code point is in the range U+0000 to U+007F, return a\n-    // byte whose value is code point.\n-    if (inRange(code_point, 0x0000, 0x007f))\n-      return code_point;\n-\n-    // 3. Set count and offset based on the range code point is in:\n-    var count, offset;\n-    // U+0080 to U+07FF:    1 and 0xC0\n-    if (inRange(code_point, 0x0080, 0x07FF)) {\n-      count = 1;\n-      offset = 0xC0;\n-    }\n-    // U+0800 to U+FFFF:    2 and 0xE0\n-    else if (inRange(code_point, 0x0800, 0xFFFF)) {\n-      count = 2;\n-      offset = 0xE0;\n-    }\n-    // U+10000 to U+10FFFF: 3 and 0xF0\n-    else if (inRange(code_point, 0x10000, 0x10FFFF)) {\n-      count = 3;\n-      offset = 0xF0;\n-    }\n-\n-    // 4.Let bytes be a byte sequence whose first byte is (code\n-    // point >> (6 \u00d7 count)) + offset.\n-    var bytes = [(code_point >> (6 * count)) + offset];\n-\n-    // 5. Run these substeps while count is greater than 0:\n-    while (count > 0) {\n-\n-      // 1. Set temp to code point >> (6 \u00d7 (count \u2212 1)).\n-      var temp = code_point >> (6 * (count - 1));\n-\n-      // 2. Append to bytes 0x80 | (temp & 0x3F).\n-      bytes.push(0x80 | (temp & 0x3F));\n-\n-      // 3. Decrease count by one.\n-      count -= 1;\n-    }\n-\n-    // 6. Return bytes bytes, in order.\n-    return bytes;\n-  };\n-}\n-\n-exports.TextEncoder = TextEncoder;\n-exports.TextDecoder = TextDecoder;\ndiff --git a/js/closure-compiler-scripts/tslib.js b/js/closure-compiler-scripts/tslib.js\ndeleted file mode 100644\nindex b5a722a65..000000000\n--- a/js/closure-compiler-scripts/tslib.js\n+++ /dev/null\n@@ -1,151 +0,0 @@\n-/**\n- * closure-compiler-friendly tslib\n- * copied from\u00a0node_modules/tslib/tslib.js\n- * update as needed\n- */\n-\n-var extendStatics = Object.setPrototypeOf ||\n-    ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n-    function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n-\n-function __extends(d, b) {\n-    extendStatics(d, b);\n-    function __() { this.constructor = d; }\n-    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n-};\n-\n-var __assign = Object.assign || function (t) {\n-    for (var s, i = 1, n = arguments.length; i < n; i++) {\n-        s = arguments[i];\n-        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n-    }\n-    return t;\n-};\n-\n-function __rest(s, e) {\n-    var t = {};\n-    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n-        t[p] = s[p];\n-    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n-        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) if (e.indexOf(p[i]) < 0)\n-            t[p[i]] = s[p[i]];\n-    return t;\n-};\n-\n-function __decorate(decorators, target, key, desc) {\n-    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n-    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n-    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n-    return c > 3 && r && Object.defineProperty(target, key, r), r;\n-};\n-\n-function __param(paramIndex, decorator) {\n-    return function (target, key) { decorator(target, key, paramIndex); }\n-};\n-\n-function __metadata(metadataKey, metadataValue) {\n-    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\n-};\n-\n-function __awaiter(thisArg, _arguments, P, generator) {\n-    return new (P || (P = Promise))(function (resolve, reject) {\n-        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n-        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n-        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n-        step((generator = generator.apply(thisArg, _arguments || [])).next());\n-    });\n-};\n-\n-function __generator(thisArg, body) {\n-    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n-    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n-    function verb(n) { return function (v) { return step([n, v]); }; }\n-    function step(op) {\n-        if (f) throw new TypeError(\"Generator is already executing.\");\n-        while (_) try {\n-            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n-            if (y = 0, t) op = [0, t.value];\n-            switch (op[0]) {\n-                case 0: case 1: t = op; break;\n-                case 4: _.label++; return { value: op[1], done: false };\n-                case 5: _.label++; y = op[1]; op = [0]; continue;\n-                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n-                default:\n-                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n-                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n-                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n-                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n-                    if (t[2]) _.ops.pop();\n-                    _.trys.pop(); continue;\n-            }\n-            op = body.call(thisArg, _);\n-        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n-        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n-    }\n-};\n-\n-function __exportStar(m, exports) {\n-    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n-};\n-\n-function __values(o) {\n-    var m = typeof Symbol === \"function\" && o[Symbol.iterator], i = 0;\n-    if (m) return m.call(o);\n-    return {\n-        next: function () {\n-            if (o && i >= o.length) o = void 0;\n-            return { value: o && o[i++], done: !o };\n-        }\n-    };\n-};\n-\n-function __read(o, n) {\n-    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n-    if (!m) return o;\n-    var i = m.call(o), r, ar = [], e;\n-    try {\n-        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\n-    }\n-    catch (error) { e = { error: error }; }\n-    finally {\n-        try {\n-            if (r && !r.done && (m = i[\"return\"])) m.call(i);\n-        }\n-        finally { if (e) throw e.error; }\n-    }\n-    return ar;\n-};\n-\n-function __spread() {\n-    for (var ar = [], i = 0; i < arguments.length; i++)\n-        ar = ar.concat(__read(arguments[i]));\n-    return ar;\n-};\n-\n-function __await(v) {\n-    return this instanceof __await ? (this.v = v, this) : new __await(v);\n-};\n-\n-function __asyncGenerator(thisArg, _arguments, generator) {\n-    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n-    var g = generator.apply(thisArg, _arguments || []), i, q = [];\n-    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\n-    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\n-    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n-    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);  }\n-    function fulfill(value) { resume(\"next\", value); }\n-    function reject(value) { resume(\"throw\", value); }\n-    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n-};\n-\n-function __asyncDelegator(o) {\n-    var i, p;\n-    return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\n-    function verb(n, f) { if (o[n]) i[n] = function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; }; }\n-};\n-\n-function __asyncValues(o) {\n-    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n-    var m = o[Symbol.asyncIterator];\n-    return m ? m.call(o) : typeof __values === \"function\" ? __values(o) : o[Symbol.iterator]();\n-};\ndiff --git a/js/gulp/argv.js b/js/gulp/argv.js\nindex 33553704e..253553c73 100644\n--- a/js/gulp/argv.js\n+++ b/js/gulp/argv.js\n@@ -22,9 +22,12 @@ const argv = require(`command-line-args`)([\n     { name: `target`, type: String, defaultValue: `` },\n     { name: `module`, type: String, defaultValue: `` },\n     { name: `coverage`, type: Boolean, defaultValue: false },\n+    { name: `integration`, alias: `i`, type: Boolean, defaultValue: false },\n     { name: `targets`, alias: `t`, type: String, multiple: true, defaultValue: [] },\n-    { name: `modules`, alias: `m`, type: String, multiple: true, defaultValue: [] }\n-]);\n+    { name: `modules`, alias: `m`, type: String, multiple: true, defaultValue: [] },\n+    { name: `sources`, alias: `s`, type: String, multiple: true, defaultValue: [`cpp`, `java`] },\n+    { name: `formats`, alias: `f`, type: String, multiple: true, defaultValue: [`file`, `stream`] },\n+], { partial: true });\n \n const { targets, modules } = argv;\n \ndiff --git a/js/gulp/arrow-task.js b/js/gulp/arrow-task.js\nindex d160ecb0e..cc33ee144 100644\n--- a/js/gulp/arrow-task.js\n+++ b/js/gulp/arrow-task.js\n@@ -27,7 +27,8 @@ const { memoizeTask } = require('./memoize-task');\n const { Observable, ReplaySubject } = require('rxjs');\n \n const arrowTask = ((cache) => memoizeTask(cache, function copyMain(target, format) {\n-    const out = targetDir(target), srcGlob = `src/**/*`;\n+    const out = targetDir(target);\n+    const srcGlob = `src/**/*.ts`;\n     const es5Glob = `${targetDir(`es5`, `cjs`)}/**/*.js`;\n     const esmGlob = `${targetDir(`es2015`, `esm`)}/**/*.js`;\n     const es5UmdGlob = `${targetDir(`es5`, `umd`)}/**/*.js`;\n@@ -48,7 +49,7 @@ const arrowTask = ((cache) => memoizeTask(cache, function copyMain(target, forma\n }))({});\n \n const arrowTSTask = ((cache) => memoizeTask(cache, function copyTS(target, format) {\n-    return observableFromStreams(gulp.src(`src/**/*`), gulp.dest(targetDir(target, format)));\n+    return observableFromStreams(gulp.src(`src/**/*.ts`), gulp.dest(targetDir(target, format)));\n }))({});\n   \n   \ndiff --git a/js/gulp/closure-task.js b/js/gulp/closure-task.js\nindex 950bf40e2..a1f0a9a69 100644\n--- a/js/gulp/closure-task.js\n+++ b/js/gulp/closure-task.js\n@@ -37,10 +37,14 @@ const closureTask = ((cache) => memoizeTask(cache, function closure(target, form\n     const externs = path.join(src, `${mainExport}.externs`);\n     return observableFromStreams(\n         gulp.src([\n-/*   external libs first --> */ `closure-compiler-scripts/*.js`,\n-/*    then sources glob --> */ `${src}/**/*.js`,\n-/* and exclusions last --> */ `!${src}/format/*.js`,\n-                              `!${src}/Arrow.externs.js`,\n+/*   external libs first --> */ `node_modules/tslib/package.json`,\n+                                `node_modules/tslib/tslib.es6.js`,\n+                                `node_modules/flatbuffers/package.json`,\n+                                `node_modules/flatbuffers/js/flatbuffers.mjs`,\n+                                `node_modules/text-encoding-utf-8/package.json`,\n+                                `node_modules/text-encoding-utf-8/src/encoding.js`,\n+/*    then sources globs --> */ `${src}/**/*.js`,\n+/* and exclusions last -->  */ `!${src}/Arrow.externs.js`,\n         ], { base: `./` }),\n         sourcemaps.init(),\n         closureCompiler(createClosureArgs(entry, externs)),\n@@ -53,12 +57,14 @@ const closureTask = ((cache) => memoizeTask(cache, function closure(target, form\n const createClosureArgs = (entry, externs) => ({\n     third_party: true,\n     warning_level: `QUIET`,\n-    dependency_mode: `LOOSE`,\n+    dependency_mode: `STRICT`,\n     rewrite_polyfills: false,\n     externs: `${externs}.js`,\n     entry_point: `${entry}.js`,\n+    module_resolution: `NODE`,\n     // formatting: `PRETTY_PRINT`,\n     compilation_level: `ADVANCED`,\n+    package_json_entry_names: `module,jsnext:main,main`,\n     assume_function_wrapper: true,\n     js_output_file: `${mainExport}.js`,\n     language_in: gCCLanguageNames[`es2015`],\ndiff --git a/js/gulp/test-task.js b/js/gulp/test-task.js\nindex b46b2bb14..ae6b8071d 100644\n--- a/js/gulp/test-task.js\n+++ b/js/gulp/test-task.js\n@@ -15,10 +15,19 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+const del = require('del');\n const path = require('path');\n-const child_process = require(`child_process`);\n const { argv } = require('./argv');\n+const { promisify } = require('util');\n+const glob = promisify(require('glob'));\n+const stat = promisify(require('fs').stat);\n+const mkdirp = promisify(require('mkdirp'));\n+const rimraf = promisify(require('rimraf'));\n+const child_process = require(`child_process`);\n const { memoizeTask } = require('./memoize-task');\n+const readFile = promisify(require('fs').readFile);\n+const exec = promisify(require('child_process').exec);\n+const parseXML = promisify(require('xml2js').parseString);\n \n const jestArgv = [];\n argv.update && jestArgv.push(`-u`);\n@@ -29,16 +38,129 @@ const debugArgv = [`--runInBand`, `--env`, `jest-environment-node-debug`];\n const jest = require.resolve(path.join(`..`, `node_modules`, `.bin`, `jest`));\n \n const testTask = ((cache, execArgv, testOptions) => memoizeTask(cache, function test(target, format, debug = false) {\n-    const opts = Object.assign({}, testOptions);\n+    const opts = { ...testOptions };\n     const args = !debug ? [...execArgv] : [...debugArgv, ...execArgv];\n-    opts.env = Object.assign({}, opts.env, { TEST_TARGET: target, TEST_MODULE: format });\n+    if (!argv.integration) {\n+        args.push('test/vector-tests.ts');\n+    }\n+    opts.env = { ...opts.env,\n+        TEST_TARGET: target,\n+        TEST_MODULE: format,\n+        TEST_TS_SOURCE: !!argv.coverage,\n+        TEST_SOURCES: JSON.stringify(Array.isArray(argv.sources) ? argv.sources : [argv.sources]),\n+        TEST_FORMATS: JSON.stringify(Array.isArray(argv.formats) ? argv.formats : [argv.formats]),\n+    };\n     return !debug ?\n         child_process.spawn(jest, args, opts) :\n         child_process.exec(`node --inspect-brk ${jest} ${args.join(` `)}`, opts);\n }))({}, jestArgv, {\n-    env: Object.assign({}, process.env),\n+    env: { ...process.env },\n     stdio: [`ignore`, `inherit`, `inherit`],\n });\n \n module.exports = testTask;\n module.exports.testTask = testTask;\n+module.exports.cleanTestData = cleanTestData;\n+module.exports.createTestData = createTestData;\n+\n+// Pull C++ and Java paths from environment vars first, otherwise sane defaults\n+const ARROW_HOME = process.env.ARROW_HOME || path.resolve('../');\n+const ARROW_JAVA_DIR = process.env.ARROW_JAVA_DIR || path.join(ARROW_HOME, 'java');\n+const CPP_EXE_PATH = process.env.ARROW_CPP_EXE_PATH || path.join(ARROW_HOME, 'cpp/build/debug');\n+const ARROW_INTEGRATION_DIR = process.env.ARROW_INTEGRATION_DIR || path.join(ARROW_HOME, 'integration');\n+const CPP_JSON_TO_ARROW = path.join(CPP_EXE_PATH, 'json-integration-test');\n+const CPP_STREAM_TO_FILE = path.join(CPP_EXE_PATH, 'stream-to-file');\n+const CPP_FILE_TO_STREAM = path.join(CPP_EXE_PATH, 'file-to-stream');\n+\n+const testFilesDir = path.join(ARROW_HOME, 'js/test/data');\n+const cppFilesDir = path.join(testFilesDir, 'cpp');\n+const javaFilesDir = path.join(testFilesDir, 'java');\n+const jsonFilesDir = path.join(testFilesDir, 'json');\n+\n+async function cleanTestData() {\n+    return await del(`${testFilesDir}/**`);\n+}\n+\n+async function createTestJSON() {\n+    await mkdirp(jsonFilesDir);\n+    await exec(`shx cp ${ARROW_INTEGRATION_DIR}/data/*.json ${jsonFilesDir}`);\n+    await exec(`python ${ARROW_INTEGRATION_DIR}/integration_test.py --write_generated_json ${jsonFilesDir}`);\n+}\n+\n+async function createTestData() {\n+\n+    let JAVA_TOOLS_JAR = process.env.ARROW_JAVA_INTEGRATION_JAR;\n+    if (!JAVA_TOOLS_JAR) {\n+        const pom_version = await\n+            readFile(path.join(ARROW_JAVA_DIR, 'pom.xml'))\n+                .then((pom) => parseXML(pom.toString()))\n+                .then((pomXML) => pomXML.project.version[0]);\n+        JAVA_TOOLS_JAR = path.join(ARROW_JAVA_DIR, `/tools/target/arrow-tools-${pom_version}-jar-with-dependencies.jar`);\n+    }\n+\n+    await cleanTestData().then(createTestJSON);\n+    await mkdirp(path.join(cppFilesDir, 'file'));\n+    await mkdirp(path.join(javaFilesDir, 'file'));\n+    await mkdirp(path.join(cppFilesDir, 'stream'));\n+    await mkdirp(path.join(javaFilesDir, 'stream'));\n+\n+    const errors = [];\n+    const names = await glob(path.join(jsonFilesDir, '*.json'));\n+\n+    for (let jsonPath of names) {\n+        const name = path.parse(path.basename(jsonPath)).name;\n+        const arrowCppFilePath = path.join(cppFilesDir, 'file', `${name}.arrow`);\n+        const arrowJavaFilePath = path.join(javaFilesDir, 'file', `${name}.arrow`);\n+        const arrowCppStreamPath = path.join(cppFilesDir, 'stream', `${name}.arrow`);\n+        const arrowJavaStreamPath = path.join(javaFilesDir, 'stream', `${name}.arrow`);\n+        try {\n+            await generateCPPFile(path.resolve(jsonPath), arrowCppFilePath);\n+            await generateCPPStream(arrowCppFilePath, arrowCppStreamPath);\n+        } catch (e) { errors.push(`${e.stdout}\\n${e.message}`); }\n+        try {\n+            await generateJavaFile(path.resolve(jsonPath), arrowJavaFilePath);\n+            await generateJavaStream(arrowJavaFilePath, arrowJavaStreamPath);\n+        } catch (e) { errors.push(`${e.stdout}\\n${e.message}`); }\n+    }\n+    if (errors.length) {\n+        console.error(errors.join(`\\n`));\n+        process.exit(1);\n+    }\n+\n+    async function generateCPPFile(jsonPath, filePath) {\n+        await rimraf(filePath);\n+        return await exec(\n+            `${CPP_JSON_TO_ARROW} ${\n+            `--integration --mode=JSON_TO_ARROW`} ${\n+            `--json=${jsonPath} --arrow=${filePath}`}`,\n+            { maxBuffer: Math.pow(2, 53) - 1 }\n+        );\n+    }\n+    \n+    async function generateCPPStream(filePath, streamPath) {\n+        await rimraf(streamPath);\n+        return await exec(\n+            `${CPP_FILE_TO_STREAM} ${filePath} > ${streamPath}`,\n+            { maxBuffer: Math.pow(2, 53) - 1 }\n+        );\n+    }\n+    \n+    async function generateJavaFile(jsonPath, filePath) {\n+        await rimraf(filePath);\n+        return await exec(\n+            `java -cp ${JAVA_TOOLS_JAR} ${\n+            `org.apache.arrow.tools.Integration -c JSON_TO_ARROW`} ${\n+            `-j ${path.resolve(jsonPath)} -a ${filePath}`}`,\n+            { maxBuffer: Math.pow(2, 53) - 1 }\n+        );\n+    }\n+    \n+    async function generateJavaStream(filePath, streamPath) {\n+        await rimraf(streamPath);\n+        return await exec(\n+            `java -cp ${JAVA_TOOLS_JAR} ${\n+            `org.apache.arrow.tools.FileToStream`} ${filePath} ${streamPath}`,\n+            { maxBuffer: Math.pow(2, 53) - 1 }\n+        );\n+    }\n+}\ndiff --git a/js/gulp/typescript-task.js b/js/gulp/typescript-task.js\nindex 2c6684666..2fd9f1350 100644\n--- a/js/gulp/typescript-task.js\n+++ b/js/gulp/typescript-task.js\n@@ -19,9 +19,11 @@ const {\n     targetDir, tsconfigName, observableFromStreams\n } = require('./util');\n \n+const del = require('del');\n const gulp = require('gulp');\n const path = require('path');\n const ts = require(`gulp-typescript`);\n+const gulpRename = require(`gulp-rename`);\n const sourcemaps = require('gulp-sourcemaps');\n const { memoizeTask } = require('./memoize-task');\n const { Observable, ReplaySubject } = require('rxjs');\n@@ -36,8 +38,26 @@ const typescriptTask = ((cache) => memoizeTask(cache, function typescript(target\n     );\n     const writeDTypes = observableFromStreams(dts, gulp.dest(out));\n     const writeJS = observableFromStreams(js, sourcemaps.write(), gulp.dest(out));\n-    return Observable.forkJoin(writeDTypes, writeJS).publish(new ReplaySubject()).refCount();\n+    return Observable\n+        .forkJoin(writeDTypes, writeJS)\n+        .concat(maybeCopyRawJSArrowFormatFiles(target, format))\n+        .publish(new ReplaySubject()).refCount();\n }))({});\n-  \n+\n module.exports = typescriptTask;\n-module.exports.typescriptTask = typescriptTask;\n\\ No newline at end of file\n+module.exports.typescriptTask = typescriptTask;\n+\n+function maybeCopyRawJSArrowFormatFiles(target, format) {\n+    if (target !== `es5` || format !== `cls`) {\n+        return Observable.empty();\n+    }\n+    return Observable.defer(async () => {\n+        const outFormatDir = path.join(targetDir(target, format), `format`);\n+        await del(path.join(outFormatDir, '*.js'));\n+        await observableFromStreams(\n+            gulp.src(path.join(`src`, `format`, `*_generated.js`)),\n+            gulpRename((p) => { p.basename = p.basename.replace(`_generated`, ``); }),\n+            gulp.dest(outFormatDir)\n+        ).toPromise();\n+    });\n+}\n\\ No newline at end of file\ndiff --git a/js/gulp/uglify-task.js b/js/gulp/uglify-task.js\nindex 804d45045..5c605cb78 100644\n--- a/js/gulp/uglify-task.js\n+++ b/js/gulp/uglify-task.js\n@@ -39,7 +39,7 @@ const uglifyTask = ((cache, commonConfig) => memoizeTask(cache, function uglifyJ\n \n     const targetConfig = { ...commonConfig,\n         output: { ...commonConfig.output,\n-             path: path.resolve(`./${out}`) } };\n+            path: path.resolve(`./${out}`) } };\n \n     const webpackConfigs = [\n         [mainExport, PublicNames]\ndiff --git a/js/gulp/util.js b/js/gulp/util.js\nindex 21ffc3127..e23fc3985 100644\n--- a/js/gulp/util.js\n+++ b/js/gulp/util.js\n@@ -27,7 +27,7 @@ const releasesRootDir = `targets`;\n const knownTargets = [`es5`, `es2015`, `esnext`];\n const knownModules = [`cjs`, `esm`, `cls`, `umd`];\n const moduleFormatsToSkipCombosOf = { cls: true };\n-const metadataFiles = [`LICENSE`, `README.md`];\n+const metadataFiles = [`../LICENSE.txt`, `../NOTICE.txt`, `README.md`];\n const packageJSONFields = [\n   `version`, `license`, `description`,\n   `author`, `homepage`, `repository`,\ndiff --git a/js/gulpfile.js b/js/gulpfile.js\nindex 4cf0342c3..cd0ac7002 100644\n--- a/js/gulpfile.js\n+++ b/js/gulpfile.js\n@@ -19,11 +19,11 @@ const del = require('del');\n const gulp = require('gulp');\n const path = require('path');\n const { Observable } = require('rxjs');\n-const testsTask = require('./gulp/test-task');\n const buildTask = require('./gulp/build-task');\n const cleanTask = require('./gulp/clean-task');\n const packageTask = require('./gulp/package-task');\n const { targets, modules } = require('./gulp/argv');\n+const { testTask, createTestData, cleanTestData } = require('./gulp/test-task');\n const {\n     targetDir,\n     taskName, combinations,\n@@ -35,8 +35,8 @@ const {\n for (const [target, format] of combinations([`all`], [`all`])) {\n     const task = taskName(target, format);\n     gulp.task(`clean:${task}`, cleanTask(target, format));\n-    gulp.task( `test:${task}`, testsTask(target, format));\n-    gulp.task(`debug:${task}`, testsTask(target, format, true));\n+    gulp.task( `test:${task}`,  testTask(target, format));\n+    gulp.task(`debug:${task}`,  testTask(target, format, true));\n     gulp.task(`build:${task}`, gulp.series(`clean:${task}`,\n                                             buildTask(target, format),\n                                             packageTask(target, format)));\n@@ -50,7 +50,7 @@ knownTargets.forEach((target) =>\n         gulp.series(\n             gulp.parallel(\n                 cleanTask(target, `umd`),\n-                cleanTask(UMDSourceTargets[target], `cls`),\n+                cleanTask(UMDSourceTargets[target], `cls`)\n             ),\n             buildTask(UMDSourceTargets[target], `cls`),\n             buildTask(target, `umd`), packageTask(target, `umd`)\n@@ -86,6 +86,8 @@ const buildConcurrent = (tasks) => () =>\n             .merge(...knownTargets.map((target) =>\n                 del(`${targetDir(target, `cls`)}/**`)))));\n   \n+gulp.task(`test:cleanTestData`, cleanTestData);\n+gulp.task(`test:createTestData`, createTestData);\n gulp.task( `test`, gulp.series(getTasks(`test`)));\n gulp.task(`debug`, gulp.series(getTasks(`debug`)));\n gulp.task(`clean`, gulp.parallel(getTasks(`clean`)));\ndiff --git a/js/lerna.json b/js/lerna.json\nindex c8fb8c072..0bf16fdfd 100644\n--- a/js/lerna.json\n+++ b/js/lerna.json\n@@ -2,8 +2,10 @@\n   \"lerna\": \"2.0.0\",\n   \"version\": \"0.1.1\",\n   \"packages\": [\n+    \"targets/ts\",\n     \"targets/es5/*\",\n     \"targets/es2015/*\",\n-    \"targets/esnext/*\"\n+    \"targets/esnext/*\",\n+    \"targets/apache-arrow\"\n   ]\n }\ndiff --git a/js/prepublish.sh b/js/npm-release.sh\nsimilarity index 85%\nrename from js/prepublish.sh\nrename to js/npm-release.sh\nindex b40504ae8..0bf70d979 100644\n--- a/js/prepublish.sh\n+++ b/js/npm-release.sh\n@@ -17,10 +17,4 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-npm run clean\n-npm run lint\n-npm run build\n-npm run test\n-npm --no-git-tag-version version patch &>/dev/null\n-npm run bundle\n-npm run lerna:publish\n\\ No newline at end of file\n+lerna publish --yes --skip-git --force-publish=*\n\\ No newline at end of file\ndiff --git a/js/package.json b/js/package.json\nindex ba93a3468..24bc27f5b 100644\n--- a/js/package.json\n+++ b/js/package.json\n@@ -15,17 +15,17 @@\n     \"build\": \"gulp build\",\n     \"clean\": \"gulp clean\",\n     \"debug\": \"gulp debug\",\n-    \"bundle\": \"gulp bundle\",\n-    \"package\": \"gulp package\",\n     \"perf\": \"node ./perf/index.js\",\n-    \"test:coverage\": \"gulp test -t esnext -m esm --coverage\",\n-    \"validate\": \"npm-run-all clean lint build test bundle\",\n-    \"lerna:publish\": \"lerna exec --bail=false npm publish\",\n-    \"prepublishOnly\": \"sh ./prepublish.sh\",\n+    \"release\": \"./npm-release.sh\",\n+    \"validate\": \"run-s --silent lint build clean\",\n+    \"test:coverage\": \"gulp test -t ts --coverage\",\n+    \"test:cleanTestData\": \"gulp test:cleanTestData\",\n+    \"test:createTestData\": \"gulp test:createTestData\",\n     \"doc\": \"shx rm -rf ./doc && esdoc\",\n     \"lint\": \"npm-run-all -p lint:*\",\n     \"lint:src\": \"tslint --fix --project -p tsconfig.json -c tslint.json \\\"src/**/*.ts\\\"\",\n-    \"lint:test\": \"tslint --fix --project -p test/tsconfig.json -c tslint.json \\\"test/**/*.ts\\\"\"\n+    \"lint:test\": \"tslint --fix --project -p test/tsconfig.json -c tslint.json \\\"test/**/*.ts\\\"\",\n+    \"prepublishOnly\": \"echo \\\"Error: do 'npm run release' instead of 'npm publish'\\\" && exit 1\"\n   },\n   \"repository\": {\n     \"type\": \"git\",\n@@ -53,14 +53,15 @@\n     \"command-line-usage\": \"4.0.1\"\n   },\n   \"dependencies\": {\n-    \"flatbuffers\": \"1.7.0\",\n+    \"flatbuffers\": \"trxcllnt/flatbuffers-esm\",\n     \"text-encoding\": \"0.6.4\"\n   },\n   \"devDependencies\": {\n-    \"@std/esm\": \"0.12.5\",\n+    \"@std/esm\": \"0.13.0\",\n     \"@types/flatbuffers\": \"1.6.5\",\n-    \"@types/jest\": \"21.1.5\",\n-    \"@types/node\": \"8.0.47\",\n+    \"@types/glob\": \"5.0.33\",\n+    \"@types/jest\": \"21.1.6\",\n+    \"@types/node\": \"8.0.51\",\n     \"@types/text-encoding\": \"0.0.32\",\n     \"benchmark\": \"2.1.4\",\n     \"command-line-args\": \"4.0.7\",\n@@ -68,20 +69,22 @@\n     \"del\": \"3.0.0\",\n     \"esdoc\": \"1.0.3\",\n     \"esdoc-standard-plugin\": \"1.0.0\",\n-    \"google-closure-compiler\": \"20170910.0.0\",\n+    \"glob\": \"7.1.2\",\n+    \"google-closure-compiler\": \"20171112.0.0\",\n     \"gulp\": \"github:gulpjs/gulp#4.0\",\n     \"gulp-json-transform\": \"0.4.5\",\n     \"gulp-rename\": \"1.2.2\",\n     \"gulp-sourcemaps\": \"2.6.1\",\n     \"gulp-typescript\": \"3.2.3\",\n+    \"ix\": \"2.3.1\",\n     \"jest\": \"21.2.1\",\n     \"jest-environment-node-debug\": \"2.0.0\",\n     \"json\": \"9.0.6\",\n-    \"lerna\": \"2.5.0\",\n-    \"lint-staged\": \"4.3.0\",\n+    \"lerna\": \"2.5.1\",\n+    \"lint-staged\": \"5.0.0\",\n     \"merge2\": \"1.2.0\",\n     \"mkdirp\": \"0.5.1\",\n-    \"npm-run-all\": \"4.1.1\",\n+    \"npm-run-all\": \"4.1.2\",\n     \"pump\": \"1.0.2\",\n     \"rimraf\": \"2.6.2\",\n     \"rxjs\": \"5.5.2\",\n@@ -89,12 +92,13 @@\n     \"source-map-loader\": \"0.2.3\",\n     \"text-encoding-utf-8\": \"1.0.1\",\n     \"trash\": \"4.1.0\",\n-    \"ts-jest\": \"21.1.4\",\n+    \"ts-jest\": \"21.2.1\",\n     \"tslib\": \"1.8.0\",\n     \"tslint\": \"5.8.0\",\n     \"typescript\": \"2.6.1\",\n     \"uglifyjs-webpack-plugin\": \"1.0.1\",\n-    \"webpack\": \"3.8.1\"\n+    \"webpack\": \"3.8.1\",\n+    \"xml2js\": \"0.4.19\"\n   },\n   \"lint-staged\": {\n     \"*.@(ts)\": [\ndiff --git a/js/perf/arrows/file/dictionary.arrow b/js/perf/arrows/file/dictionary.arrow\ndeleted file mode 100644\nindex 34d41db1f..000000000\nBinary files a/js/perf/arrows/file/dictionary.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/file/simple.arrow b/js/perf/arrows/file/simple.arrow\ndeleted file mode 100644\nindex 838db6dc8..000000000\nBinary files a/js/perf/arrows/file/simple.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/file/struct.arrow b/js/perf/arrows/file/struct.arrow\ndeleted file mode 100644\nindex 3d2c018e6..000000000\nBinary files a/js/perf/arrows/file/struct.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/multi/count/records.arrow b/js/perf/arrows/multi/count/records.arrow\ndeleted file mode 100644\nindex 00d883762..000000000\nBinary files a/js/perf/arrows/multi/count/records.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/multi/count/schema.arrow b/js/perf/arrows/multi/count/schema.arrow\ndeleted file mode 100644\nindex dfd24e9e0..000000000\nBinary files a/js/perf/arrows/multi/count/schema.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/multi/latlong/records.arrow b/js/perf/arrows/multi/latlong/records.arrow\ndeleted file mode 100644\nindex 563d12d17..000000000\nBinary files a/js/perf/arrows/multi/latlong/records.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/multi/latlong/schema.arrow b/js/perf/arrows/multi/latlong/schema.arrow\ndeleted file mode 100644\nindex 638b2ab62..000000000\nBinary files a/js/perf/arrows/multi/latlong/schema.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/multi/origins/records.arrow b/js/perf/arrows/multi/origins/records.arrow\ndeleted file mode 100644\nindex 49a8c407e..000000000\nBinary files a/js/perf/arrows/multi/origins/records.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/multi/origins/schema.arrow b/js/perf/arrows/multi/origins/schema.arrow\ndeleted file mode 100644\nindex 0d10fb0e2..000000000\nBinary files a/js/perf/arrows/multi/origins/schema.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/stream/dictionary.arrow b/js/perf/arrows/stream/dictionary.arrow\ndeleted file mode 100644\nindex 17ca48b3a..000000000\nBinary files a/js/perf/arrows/stream/dictionary.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/stream/simple.arrow b/js/perf/arrows/stream/simple.arrow\ndeleted file mode 100644\nindex 2c68c0e44..000000000\nBinary files a/js/perf/arrows/stream/simple.arrow and /dev/null differ\ndiff --git a/js/perf/arrows/stream/struct.arrow b/js/perf/arrows/stream/struct.arrow\ndeleted file mode 100644\nindex 4e97b7084..000000000\nBinary files a/js/perf/arrows/stream/struct.arrow and /dev/null differ\ndiff --git a/js/perf/config.js b/js/perf/config.js\nindex 4fbcda379..cca108015 100644\n--- a/js/perf/config.js\n+++ b/js/perf/config.js\n@@ -17,22 +17,14 @@\n \n const fs = require('fs');\n const path = require('path');\n-const arrowFormats = ['file', 'stream'];\n-const arrowFileNames = ['simple', 'struct', 'dictionary'];\n-const multipartArrows = ['count', 'latlong', 'origins'];\n-let arrowTestConfigurations = [];\n+const glob = require('glob');\n \n-arrowTestConfigurations = multipartArrows.reduce((configs, folder) => {\n-    const schemaPath = path.resolve(__dirname, `./arrows/multi/${folder}/schema.arrow`);\n-    const recordsPath = path.resolve(__dirname, `./arrows/multi/${folder}/records.arrow`);\n-    return [...configs, [`multipart ${folder}`, fs.readFileSync(schemaPath), fs.readFileSync(recordsPath)]];\n-}, arrowTestConfigurations);\n+const config = [];\n+const filenames = glob.sync(path.resolve(__dirname, `../test/data/cpp/stream`, `*.arrow`));\n \n-arrowTestConfigurations = arrowFormats.reduce((configs, format) => {\n-    return arrowFileNames.reduce((configs, name) => {\n-        const arrowPath = path.resolve(__dirname, `./arrows/${format}/${name}.arrow`);\n-        return [...configs, [`${name} ${format}`, fs.readFileSync(arrowPath)]];\n-    }, configs);\n-}, arrowTestConfigurations);\n+for (const filename of filenames) {\n+    const { name } = path.parse(filename);\n+    config.push({ name, buffers: [fs.readFileSync(filename)] });\n+}\n \n-module.exports = arrowTestConfigurations;\n+module.exports = config;\ndiff --git a/js/perf/index.js b/js/perf/index.js\nindex 3a2ed9677..9eac40e64 100644\n--- a/js/perf/index.js\n+++ b/js/perf/index.js\n@@ -16,24 +16,24 @@\n // under the License.\n \n // Use the ES5 UMD target as perf baseline\n-// const { Table, readBuffers } = require('../targets/es5/umd');\n-// const { Table, readBuffers } = require('../targets/es5/cjs');\n-const { Table, readBuffers } = require('../targets/es2015/umd');\n-// const { Table, readBuffers } = require('../targets/es2015/cjs');\n+// const { Table, readVectors } = require('../targets/es5/umd');\n+// const { Table, readVectors } = require('../targets/es5/cjs');\n+const { Table, readVectors } = require('../targets/es2015/umd');\n+// const { Table, readVectors } = require('../targets/es2015/cjs');\n \n+const config = require('./config');\n const Benchmark = require('benchmark');\n-const arrowTestConfigurations = require('./config');\n \n const suites = [];\n \n-for (let [name, ...buffers] of arrowTestConfigurations) {\n+for (let { name, buffers} of config) {\n     const parseSuite = new Benchmark.Suite(`Parse ${name}`, { async: true });\n     const sliceSuite = new Benchmark.Suite(`Slice ${name} vectors`, { async: true });\n     const iterateSuite = new Benchmark.Suite(`Iterate ${name} vectors`, { async: true });\n     const getByIndexSuite = new Benchmark.Suite(`Get ${name} values by index`, { async: true });\n     parseSuite.add(createFromTableTest(name, buffers));\n-    parseSuite.add(createReadBuffersTest(name, buffers));\n-    for (const vector of Table.from(...buffers).columns) {\n+    parseSuite.add(createReadVectorsTest(name, buffers));\n+    for (const vector of Table.from(buffers).columns) {\n         sliceSuite.add(createSliceTest(vector));\n         iterateSuite.add(createIterateTest(vector));\n         getByIndexSuite.add(createGetByIndexTest(vector));\n@@ -66,16 +66,16 @@ function createFromTableTest(name, buffers) {\n     return {\n         async: true,\n         name: `Table.from`,\n-        fn() { table = Table.from(...buffers); }\n+        fn() { table = Table.from(buffers); }\n     };\n }\n \n-function createReadBuffersTest(name, buffers) {\n+function createReadVectorsTest(name, buffers) {\n     let vectors;\n     return {\n         async: true,\n-        name: `readBuffers`,\n-        fn() { for (vectors of readBuffers(...buffers)) {} }\n+        name: `readVectors`,\n+        fn() { for (vectors of readVectors(buffers)) {} }\n     };\n }\n \ndiff --git a/js/src/Arrow.ts b/js/src/Arrow.ts\nindex 319655088..e6527b34e 100644\n--- a/js/src/Arrow.ts\n+++ b/js/src/Arrow.ts\n@@ -15,45 +15,64 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { readBuffers } from './reader/arrow';\n+import { Table } from './vector/table';\n+import { Vector } from './vector/vector';\n+import { Utf8Vector } from './vector/utf8';\n+import { DictionaryVector } from './vector/dictionary';\n+import { StructVector, StructRow } from './vector/struct';\n+import { readVectors, readVectorsAsync } from './reader/arrow';\n+import { ListVector, BinaryVector, FixedSizeListVector } from './vector/list';\n \n-import { Vector } from './types/types';\n-import { ListVector } from './types/list';\n-import { Utf8Vector } from './types/utf8';\n-import { BoolVector } from './types/vector/bool';\n-import { DateVector } from './types/vector/date';\n-import { RowVector } from './types/table/row';\n-import { TableVector } from './types/table/table';\n-import { StructVector } from './types/table/struct';\n-import { DictionaryVector } from './types/dictionary';\n-import { FixedSizeListVector } from './types/fixedsizelist';\n-import { LongVector, Int64Vector, Uint64Vector, } from './types/vector/long';\n import {\n-    TypedVector,\n+    BoolVector,\n     Int8Vector,\n     Int16Vector,\n     Int32Vector,\n+    Int64Vector,\n     Uint8Vector,\n     Uint16Vector,\n     Uint32Vector,\n+    Uint64Vector,\n+    Float16Vector,\n     Float32Vector,\n-    Float64Vector\n-} from './types/vector/typed';\n-\n-import './types/table/from';\n+    Float64Vector,\n+    Date32Vector,\n+    Date64Vector,\n+    Time32Vector,\n+    Time64Vector,\n+    DecimalVector,\n+    TimestampVector,\n+} from './vector/numeric';\n \n+export { Table, Vector, StructRow };\n+export { readVectors, readVectorsAsync };\n+export { NumericVectorConstructor } from './vector/numeric';\n+export { List, TypedArray, TypedArrayConstructor } from './vector/types';\n export {\n-    Vector,\n-    readBuffers,\n+    BoolVector,\n+    ListVector,\n+    Utf8Vector,\n+    Int8Vector,\n+    Int16Vector,\n+    Int32Vector,\n+    Int64Vector,\n+    Uint8Vector,\n+    Uint16Vector,\n+    Uint32Vector,\n+    Uint64Vector,\n+    Date32Vector,\n+    Date64Vector,\n+    Time32Vector,\n+    Time64Vector,\n+    BinaryVector,\n+    StructVector,\n+    Float16Vector,\n+    Float32Vector,\n+    Float64Vector,\n+    DecimalVector,\n+    TimestampVector,\n     DictionaryVector,\n-    RowVector as Row,\n-    TableVector as Table,\n-    StructVector, Utf8Vector,\n-    ListVector, FixedSizeListVector,\n-    BoolVector, TypedVector, LongVector,\n-    DateVector, Float32Vector, Float64Vector,\n-    Int8Vector, Int16Vector, Int32Vector, Int64Vector,\n-    Uint8Vector, Uint16Vector, Uint32Vector, Uint64Vector,\n+    FixedSizeListVector,\n };\n \n /* These exports are needed for the closure umd targets */\n@@ -61,18 +80,14 @@ try {\n     const Arrow = eval('exports');\n     if (typeof Arrow === 'object') {\n         // string indexers tell closure compiler not to rename these properties\n+        Arrow['readVectors'] = readVectors;\n+        Arrow['readVectorsAsync'] = readVectorsAsync;\n+        Arrow['Table'] = Table;\n         Arrow['Vector'] = Vector;\n-        Arrow['Table'] = TableVector;\n-        Arrow['readBuffers'] = readBuffers;\n+        Arrow['StructRow'] = StructRow;\n         Arrow['BoolVector'] = BoolVector;\n-        Arrow['Utf8Vector'] = Utf8Vector;\n         Arrow['ListVector'] = ListVector;\n-        Arrow['StructVector'] = StructVector;\n-        Arrow['DictionaryVector'] = DictionaryVector;\n-        Arrow['FixedSizeListVector'] = FixedSizeListVector;\n-        Arrow['LongVector'] = LongVector;\n-        Arrow['TypedVector'] = TypedVector;\n-        Arrow['DateVector'] = DateVector;\n+        Arrow['Utf8Vector'] = Utf8Vector;\n         Arrow['Int8Vector'] = Int8Vector;\n         Arrow['Int16Vector'] = Int16Vector;\n         Arrow['Int32Vector'] = Int32Vector;\n@@ -81,8 +96,19 @@ try {\n         Arrow['Uint16Vector'] = Uint16Vector;\n         Arrow['Uint32Vector'] = Uint32Vector;\n         Arrow['Uint64Vector'] = Uint64Vector;\n+        Arrow['Date32Vector'] = Date32Vector;\n+        Arrow['Date64Vector'] = Date64Vector;\n+        Arrow['Time32Vector'] = Time32Vector;\n+        Arrow['Time64Vector'] = Time64Vector;\n+        Arrow['BinaryVector'] = BinaryVector;\n+        Arrow['StructVector'] = StructVector;\n+        Arrow['Float16Vector'] = Float16Vector;\n         Arrow['Float32Vector'] = Float32Vector;\n         Arrow['Float64Vector'] = Float64Vector;\n+        Arrow['DecimalVector'] = DecimalVector;\n+        Arrow['TimestampVector'] = TimestampVector;\n+        Arrow['DictionaryVector'] = DictionaryVector;\n+        Arrow['FixedSizeListVector'] = FixedSizeListVector;\n     }\n } catch (e) { /* not the UMD bundle */ }\n /* end closure exports */\ndiff --git a/js/src/format/File_generated.ts b/js/src/format/File.ts\nsimilarity index 99%\nrename from js/src/format/File_generated.ts\nrename to js/src/format/File.ts\nindex d0b774ae3..56f50ed20 100644\n--- a/js/src/format/File_generated.ts\n+++ b/js/src/format/File.ts\n@@ -1,7 +1,7 @@\n // automatically generated by the FlatBuffers compiler, do not modify\n \n import { flatbuffers } from 'flatbuffers';\n-import * as NS16187549871986683199 from './Schema_generated';\n+import * as NS16187549871986683199 from './Schema';\n /**\n  * ----------------------------------------------------------------------\n  * Arrow File metadata\ndiff --git a/js/closure-compiler-scripts/File_generated.js b/js/src/format/File_generated.js\nsimilarity index 95%\nrename from js/closure-compiler-scripts/File_generated.js\nrename to js/src/format/File_generated.js\nindex bb82cc4cc..12aae293e 100644\n--- a/js/closure-compiler-scripts/File_generated.js\n+++ b/js/src/format/File_generated.js\n@@ -1,12 +1,5 @@\n+import { org } from './Schema';\n // automatically generated by the FlatBuffers compiler, do not modify\n-goog.module(\"module$targets$es5$cls$format$File_generated\");\n-goog.module.declareLegacyNamespace();\n-var Schema_ = goog.require(\"module$targets$es5$cls$format$Schema_generated\");\n-/**\n- * @const\n- * @namespace\n- */\n-var org = Schema_.org;\n \n /**\n  * @const\n@@ -259,6 +252,5 @@ org.apache.arrow.flatbuf.Block.createBlock = function(builder, offset, metaDataL\n   builder.writeInt64(offset);\n   return builder.offset();\n };\n+export { org };\n \n-// Exports for Node.js and RequireJS\n-exports.org = org;\ndiff --git a/js/src/format/Message_generated.ts b/js/src/format/Message.ts\nsimilarity index 94%\nrename from js/src/format/Message_generated.ts\nrename to js/src/format/Message.ts\nindex daa781f9b..4610fbef2 100644\n--- a/js/src/format/Message_generated.ts\n+++ b/js/src/format/Message.ts\n@@ -1,7 +1,7 @@\n // automatically generated by the FlatBuffers compiler, do not modify\n \n import { flatbuffers } from 'flatbuffers';\n-import * as NS16187549871986683199 from './Schema_generated';\n+import * as NS16187549871986683199 from './Schema';\n export namespace org.apache.arrow.flatbuf {\n   export import Schema = NS16187549871986683199.org.apache.arrow.flatbuf.Schema;\n }\n@@ -181,7 +181,7 @@ export namespace org.apache.arrow.flatbuf {\n      */\n     buffers(index: number, obj?: NS16187549871986683199.org.apache.arrow.flatbuf.Buffer): NS16187549871986683199.org.apache.arrow.flatbuf.Buffer | null {\n       let offset = this.bb.__offset(this.bb_pos, 8);\n-      return offset ? (obj || new NS16187549871986683199.org.apache.arrow.flatbuf.Buffer).__init(this.bb.__vector(this.bb_pos + offset) + index * 24, this.bb) : null;\n+      return offset ? (obj || new NS16187549871986683199.org.apache.arrow.flatbuf.Buffer).__init(this.bb.__vector(this.bb_pos + offset) + index * 16, this.bb) : null;\n     }\n \n     /**\n@@ -236,7 +236,7 @@ export namespace org.apache.arrow.flatbuf {\n      * @param {number} numElems\n      */\n     static startBuffersVector(builder: flatbuffers.Builder, numElems: number) {\n-      builder.startVector(24, numElems, 8);\n+      builder.startVector(16, numElems, 8);\n     }\n \n     /**\n@@ -251,12 +251,12 @@ export namespace org.apache.arrow.flatbuf {\n   }\n }\n /**\n- * ----------------------------------------------------------------------\n  * For sending dictionary encoding information. Any Field can be\n  * dictionary-encoded, but in this case none of its children may be\n  * dictionary-encoded.\n- * There is one vector / column per dictionary\n- *\n+ * There is one vector / column per dictionary, but that vector / column\n+ * may be spread across multiple dictionary batches by using the isDelta\n+ * flag\n  *\n  * @constructor\n  */\n@@ -308,11 +308,22 @@ export namespace org.apache.arrow.flatbuf {\n       return offset ? (obj || new org.apache.arrow.flatbuf.RecordBatch).__init(this.bb.__indirect(this.bb_pos + offset), this.bb) : null;\n     }\n \n+    /**\n+     * If isDelta is true the values in the dictionary are to be appended to a\n+     * dictionary with the indicated id\n+     *\n+     * @returns {boolean}\n+     */\n+    isDelta(): boolean {\n+      let offset = this.bb.__offset(this.bb_pos, 8);\n+      return offset ? !!this.bb.readInt8(this.bb_pos + offset) : false;\n+    }\n+\n     /**\n      * @param {flatbuffers.Builder} builder\n      */\n     static startDictionaryBatch(builder: flatbuffers.Builder) {\n-      builder.startObject(2);\n+      builder.startObject(3);\n     }\n \n     /**\n@@ -331,6 +342,14 @@ export namespace org.apache.arrow.flatbuf {\n       builder.addFieldOffset(1, dataOffset, 0);\n     }\n \n+    /**\n+     * @param {flatbuffers.Builder} builder\n+     * @param {boolean} isDelta\n+     */\n+    static addIsDelta(builder: flatbuffers.Builder, isDelta: boolean) {\n+      builder.addFieldInt8(2, +isDelta, +false);\n+    }\n+\n     /**\n      * @param {flatbuffers.Builder} builder\n      * @returns {flatbuffers.Offset}\ndiff --git a/js/closure-compiler-scripts/Message_generated.js b/js/src/format/Message_generated.js\nsimilarity index 93%\nrename from js/closure-compiler-scripts/Message_generated.js\nrename to js/src/format/Message_generated.js\nindex 0c1a1a99d..ef46c9805 100644\n--- a/js/closure-compiler-scripts/Message_generated.js\n+++ b/js/src/format/Message_generated.js\n@@ -1,12 +1,5 @@\n+import { org } from './Schema';\n // automatically generated by the FlatBuffers compiler, do not modify\n-goog.module(\"module$targets$es5$cls$format$Message_generated\");\n-goog.module.declareLegacyNamespace();\n-var Schema_ = goog.require(\"module$targets$es5$cls$format$Schema_generated\");\n-/**\n- * @const\n- * @namespace\n- */\n-var org = Schema_.org;\n \n /**\n  * @const\n@@ -200,7 +193,7 @@ org.apache.arrow.flatbuf.RecordBatch.prototype.nodesLength = function() {\n  */\n org.apache.arrow.flatbuf.RecordBatch.prototype.buffers = function(index, obj) {\n   var offset = this.bb.__offset(this.bb_pos, 8);\n-  return offset ? (obj || new org.apache.arrow.flatbuf.Buffer).__init(this.bb.__vector(this.bb_pos + offset) + index * 24, this.bb) : null;\n+  return offset ? (obj || new org.apache.arrow.flatbuf.Buffer).__init(this.bb.__vector(this.bb_pos + offset) + index * 16, this.bb) : null;\n };\n \n /**\n@@ -255,7 +248,7 @@ org.apache.arrow.flatbuf.RecordBatch.addBuffers = function(builder, buffersOffse\n  * @param {number} numElems\n  */\n org.apache.arrow.flatbuf.RecordBatch.startBuffersVector = function(builder, numElems) {\n-  builder.startVector(24, numElems, 8);\n+  builder.startVector(16, numElems, 8);\n };\n \n /**\n@@ -268,12 +261,12 @@ org.apache.arrow.flatbuf.RecordBatch.endRecordBatch = function(builder) {\n };\n \n /**\n- * ----------------------------------------------------------------------\n  * For sending dictionary encoding information. Any Field can be\n  * dictionary-encoded, but in this case none of its children may be\n  * dictionary-encoded.\n- * There is one vector / column per dictionary\n- *\n+ * There is one vector / column per dictionary, but that vector / column\n+ * may be spread across multiple dictionary batches by using the isDelta\n+ * flag\n  *\n  * @constructor\n  */\n@@ -326,11 +319,22 @@ org.apache.arrow.flatbuf.DictionaryBatch.prototype.data = function(obj) {\n   return offset ? (obj || new org.apache.arrow.flatbuf.RecordBatch).__init(this.bb.__indirect(this.bb_pos + offset), this.bb) : null;\n };\n \n+/**\n+ * If isDelta is true the values in the dictionary are to be appended to a\n+ * dictionary with the indicated id\n+ *\n+ * @returns {boolean}\n+ */\n+org.apache.arrow.flatbuf.DictionaryBatch.prototype.isDelta = function() {\n+  var offset = this.bb.__offset(this.bb_pos, 8);\n+  return offset ? !!this.bb.readInt8(this.bb_pos + offset) : false;\n+};\n+\n /**\n  * @param {flatbuffers.Builder} builder\n  */\n org.apache.arrow.flatbuf.DictionaryBatch.startDictionaryBatch = function(builder) {\n-  builder.startObject(2);\n+  builder.startObject(3);\n };\n \n /**\n@@ -349,6 +353,14 @@ org.apache.arrow.flatbuf.DictionaryBatch.addData = function(builder, dataOffset)\n   builder.addFieldOffset(1, dataOffset, 0);\n };\n \n+/**\n+ * @param {flatbuffers.Builder} builder\n+ * @param {boolean} isDelta\n+ */\n+org.apache.arrow.flatbuf.DictionaryBatch.addIsDelta = function(builder, isDelta) {\n+  builder.addFieldInt8(2, +isDelta, +false);\n+};\n+\n /**\n  * @param {flatbuffers.Builder} builder\n  * @returns {flatbuffers.Offset}\n@@ -481,6 +493,5 @@ org.apache.arrow.flatbuf.Message.endMessage = function(builder) {\n org.apache.arrow.flatbuf.Message.finishMessageBuffer = function(builder, offset) {\n   builder.finish(offset);\n };\n+export { org };\n \n-// Exports for Node.js and RequireJS\n-exports.org = org;\ndiff --git a/js/src/format/Schema_generated.ts b/js/src/format/Schema.ts\nsimilarity index 99%\nrename from js/src/format/Schema_generated.ts\nrename to js/src/format/Schema.ts\nindex c5b3e5011..d9b45ed20 100644\n--- a/js/src/format/Schema_generated.ts\n+++ b/js/src/format/Schema.ts\n@@ -7,9 +7,25 @@ import { flatbuffers } from 'flatbuffers';\n  */\n export namespace org.apache.arrow.flatbuf {\n   export enum MetadataVersion {\n+    /**\n+     * 0.1.0\n+     */\n     V1 = 0,\n+\n+    /**\n+     * 0.2.0\n+     */\n     V2 = 1,\n-    V3 = 2\n+\n+    /**\n+     * 0.3.0 -> 0.7.1\n+     */\n+    V3 = 2,\n+\n+    /**\n+     * >= 0.8.0\n+     */\n+    V4 = 3\n   }\n }\n \n@@ -2049,7 +2065,6 @@ export namespace org.apache.arrow.flatbuf {\n \n     /**\n      * @param {flatbuffers.Builder} builder\n-     * @param {number} page\n      * @param {flatbuffers.Long} offset\n      * @param {flatbuffers.Long} length\n      * @returns {flatbuffers.Offset}\ndiff --git a/js/closure-compiler-scripts/Schema_generated.js b/js/src/format/Schema_generated.js\nsimilarity index 98%\nrename from js/closure-compiler-scripts/Schema_generated.js\nrename to js/src/format/Schema_generated.js\nindex 5b7644388..f89cf2fa8 100644\n--- a/js/closure-compiler-scripts/Schema_generated.js\n+++ b/js/src/format/Schema_generated.js\n@@ -1,6 +1,4 @@\n // automatically generated by the FlatBuffers compiler, do not modify\n-goog.module(\"module$targets$es5$cls$format$Schema_generated\");\n-goog.module.declareLegacyNamespace();\n \n /**\n  * @const\n@@ -30,9 +28,25 @@ org.apache.arrow.flatbuf = org.apache.arrow.flatbuf || {};\n  * @enum\n  */\n org.apache.arrow.flatbuf.MetadataVersion = {\n+  /**\n+   * 0.1.0\n+   */\n   V1: 0, 0: 'V1',\n+\n+  /**\n+   * 0.2.0\n+   */\n   V2: 1, 1: 'V2',\n+\n+  /**\n+   * 0.3.0 -> 0.7.1\n+   */\n   V3: 2, 2: 'V3',\n+\n+  /**\n+   * >= 0.8.0\n+   */\n+  V4: 3, 3: 'V4'\n };\n \n /**\n@@ -103,7 +117,7 @@ org.apache.arrow.flatbuf.Type = {\n   Union: 14, 14: 'Union',\n   FixedSizeBinary: 15, 15: 'FixedSizeBinary',\n   FixedSizeList: 16, 16: 'FixedSizeList',\n-  Map: 17, 17: 'Map',\n+  Map: 17, 17: 'Map'\n };\n \n /**\n@@ -131,7 +145,7 @@ org.apache.arrow.flatbuf.VectorType = {\n   /**\n    * Type vector used in Union type\n    */\n-  TYPE: 3, 3: 'TYPE',\n+  TYPE: 3, 3: 'TYPE'\n };\n \n /**\n@@ -2005,16 +2019,6 @@ org.apache.arrow.flatbuf.Buffer.prototype.__init = function(i, bb) {\n   return this;\n };\n \n-/**\n- * The shared memory page id where this buffer is located. Currently this is\n- * not used\n- *\n- * @returns {number}\n- */\n-org.apache.arrow.flatbuf.Buffer.prototype.page = function() {\n-  return this.bb.readInt32(this.bb_pos);\n-};\n-\n /**\n  * The relative offset into the shared memory page where the bytes for this\n  * buffer starts\n@@ -2022,7 +2026,7 @@ org.apache.arrow.flatbuf.Buffer.prototype.page = function() {\n  * @returns {flatbuffers.Long}\n  */\n org.apache.arrow.flatbuf.Buffer.prototype.offset = function() {\n-  return this.bb.readInt64(this.bb_pos + 8);\n+  return this.bb.readInt64(this.bb_pos);\n };\n \n /**\n@@ -2032,22 +2036,19 @@ org.apache.arrow.flatbuf.Buffer.prototype.offset = function() {\n  * @returns {flatbuffers.Long}\n  */\n org.apache.arrow.flatbuf.Buffer.prototype.length = function() {\n-  return this.bb.readInt64(this.bb_pos + 16);\n+  return this.bb.readInt64(this.bb_pos + 8);\n };\n \n /**\n  * @param {flatbuffers.Builder} builder\n- * @param {number} page\n  * @param {flatbuffers.Long} offset\n  * @param {flatbuffers.Long} length\n  * @returns {flatbuffers.Offset}\n  */\n-org.apache.arrow.flatbuf.Buffer.createBuffer = function(builder, page, offset, length) {\n-  builder.prep(8, 24);\n+org.apache.arrow.flatbuf.Buffer.createBuffer = function(builder, offset, length) {\n+  builder.prep(8, 16);\n   builder.writeInt64(length);\n   builder.writeInt64(offset);\n-  builder.pad(4);\n-  builder.writeInt32(page);\n   return builder.offset();\n };\n \n@@ -2226,6 +2227,5 @@ org.apache.arrow.flatbuf.Schema.endSchema = function(builder) {\n org.apache.arrow.flatbuf.Schema.finishSchemaBuffer = function(builder, offset) {\n   builder.finish(offset);\n };\n+export { org };\n \n-// Exports for Node.js and RequireJS\n-exports.org = org;\ndiff --git a/js/src/reader/arrow.ts b/js/src/reader/arrow.ts\nindex 033bfecae..8d3aafc72 100644\n--- a/js/src/reader/arrow.ts\n+++ b/js/src/reader/arrow.ts\n@@ -15,66 +15,143 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+import { Vector } from '../vector/vector';\n import { flatbuffers } from 'flatbuffers';\n-import * as Schema_ from '../format/Schema_generated';\n-import * as Message_ from '../format/Message_generated';\n-export import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n-export import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n+import { readVector, readValueVector } from './vector';\n+import {\n+    readFileFooter, readFileMessages,\n+    readStreamSchema, readStreamMessages\n+} from './format';\n \n-import { readFile } from './file';\n-import { readStream } from './stream';\n-import { readVector } from './vector';\n-import { readDictionary } from './dictionary';\n-import { Vector, Column } from '../types/types';\n+import * as File_ from '../format/File';\n+import * as Schema_ from '../format/Schema';\n+import * as Message_ from '../format/Message';\n \n import ByteBuffer = flatbuffers.ByteBuffer;\n+import Footer = File_.org.apache.arrow.flatbuf.Footer;\n import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-export type Dictionaries = { [k: string]: Vector<any> } | null;\n-export type IteratorState = { nodeIndex: number; bufferIndex: number };\n-\n-export function* readRecords(...bytes: ByteBuffer[]) {\n-    try {\n-        yield* readFile(...bytes);\n-    } catch (e) {\n-        try {\n-            yield* readStream(...bytes);\n-        } catch (e) {\n-            throw new Error('Invalid Arrow buffer');\n-        }\n+import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n+import Message = Message_.org.apache.arrow.flatbuf.Message;\n+import ArrowBuffer = Schema_.org.apache.arrow.flatbuf.Buffer;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n+import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n+import MetadataVersion = Schema_.org.apache.arrow.flatbuf.MetadataVersion;\n+import DictionaryBatch = Message_.org.apache.arrow.flatbuf.DictionaryBatch;\n+import DictionaryEncoding = Schema_.org.apache.arrow.flatbuf.DictionaryEncoding;\n+\n+export type ArrowReaderContext = {\n+    schema?: Schema;\n+    footer?: Footer | null;\n+    dictionaries: Map<string, Vector>;\n+    dictionaryEncodedFields: Map<string, Field>;\n+    readMessages: (bb: ByteBuffer, footer: Footer) => Iterable<Message>;\n+};\n+\n+export interface VectorReaderContext {\n+    offset: number;\n+    bytes: Uint8Array;\n+    batch: RecordBatch;\n+    dictionaries: Map<string, Vector>;\n+    readNextNode(): FieldNode;\n+    readNextBuffer(): ArrowBuffer;\n+}\n+\n+export function* readVectors(buffers: Iterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n     }\n }\n \n-export function* readBuffers(...bytes: Array<Uint8Array | Buffer | string>) {\n-    const dictionaries: Dictionaries = {};\n-    const byteBuffers = bytes.map(toByteBuffer);\n-    for (let { schema, batch } of readRecords(...byteBuffers)) {\n-        let vectors: Column<any>[] = [];\n-        let state = { nodeIndex: 0, bufferIndex: 0 };\n-        let fieldsLength = schema.fieldsLength();\n-        let index = -1, field: Field, vector: Vector<any>;\n-        if (batch.id) {\n-            // A dictionary batch only contain a single vector. Traverse each\n-            // field and its children until we find one that uses this dictionary\n-            while (++index < fieldsLength) {\n-                if (field = schema.fields(index)!) {\n-                    if (vector = readDictionary<any>(field, batch, state, dictionaries)!) {\n-                        dictionaries[batch.id] = dictionaries[batch.id] && dictionaries[batch.id].concat(vector) || vector;\n-                        break;\n-                    }\n+export async function* readVectorsAsync(buffers: AsyncIterable<Uint8Array | Buffer | string>, context?: ArrowReaderContext) {\n+    const context_ = context || {} as ArrowReaderContext;\n+    for await (const buffer of buffers) {\n+        yield* readBuffer(toByteBuffer(buffer), context_);\n+    }\n+}\n+\n+function* readBuffer(bb: ByteBuffer, readerContext: ArrowReaderContext) {\n+\n+    let { schema, footer, readMessages, dictionaryEncodedFields, dictionaries } = readerContext;\n+\n+    if (!schema) {\n+        ({ schema, footer, readMessages, dictionaryEncodedFields } = readSchema(bb));\n+        readerContext.schema = schema;\n+        readerContext.readMessages = readMessages;\n+        readerContext.dictionaryEncodedFields = dictionaryEncodedFields;\n+        readerContext.dictionaries = dictionaries = new Map<string, Vector>();\n+    }\n+\n+    const fieldsLength = schema.fieldsLength();\n+    const context = new BufferReaderContext(bb.bytes(), dictionaries);\n+\n+    for (const message of readMessages(bb, footer!)) {\n+\n+        let id: string;\n+        let field: Field;\n+        let vector: Vector;\n+        let vectors: Array<Vector>;\n+\n+        context.message = message;\n+\n+        if (message.headerType() === MessageHeader.DictionaryBatch) {\n+            let batch: DictionaryBatch;\n+            if (batch = message.header(new DictionaryBatch())!) {\n+                context.batch = batch.data()!;\n+                id = batch.id().toFloat64().toString();\n+                field = dictionaryEncodedFields.get(id)!;\n+                vector = readValueVector(field, context);\n+                if (batch.isDelta() && dictionaries.has(id)) {\n+                    vector = dictionaries.get(id)!.concat(vector);\n                 }\n+                dictionaries.set(id, vector);\n             }\n-        } else {\n-            while (++index < fieldsLength) {\n-                if ((field = schema.fields(index)!) &&\n-                    (vector = readVector<any>(field, batch, state, dictionaries)!)) {\n-                    vectors[index] = vector as Column<any>;\n-                }\n+            continue;\n+        }\n+\n+        vectors = new Array<Vector>(fieldsLength);\n+        context.batch = message.header(new RecordBatch())!;\n+\n+        for (let i = -1; ++i < fieldsLength;) {\n+            if ((field = schema.fields(i)!) || (vectors[i] = null as any)) {\n+                vectors[i] = readVector(field, context);\n             }\n-            yield vectors;\n         }\n+\n+        yield vectors;\n     }\n }\n \n+function readSchema(bb: ByteBuffer) {\n+    let schema: Schema, readMessages, footer = readFileFooter(bb);\n+    if (footer) {\n+        schema = footer.schema()!;\n+        readMessages = readFileMessages;\n+    } else if (schema = readStreamSchema(bb)!) {\n+        readMessages = readStreamMessages;\n+    } else {\n+        throw new Error('Invalid Arrow buffer');\n+    }\n+    return { schema, footer, readMessages, dictionaryEncodedFields: readDictionaryEncodedFields(schema, new Map<string, Field>()) };\n+}\n+\n+function readDictionaryEncodedFields(parent: Schema | Field, fields: Map<string, Field>) {\n+    let field: Field, encoding: DictionaryEncoding, id: string;\n+    let getField = parent instanceof Field ? parent.children : parent.fields;\n+    let getFieldCount = parent instanceof Field ? parent.childrenLength : parent.fieldsLength;\n+    for (let i = -1, n = getFieldCount.call(parent); ++i < n;) {\n+        if (field = getField.call(parent, i)!) {\n+            if ((encoding = field.dictionary()!) &&\n+                (id = encoding.id().toFloat64().toString())) {\n+                !fields.has(id) && fields.set(id, field);\n+            }\n+            readDictionaryEncodedFields(field, fields);\n+        }\n+    }\n+    return fields;\n+}\n+\n function toByteBuffer(bytes?: Uint8Array | Buffer | string) {\n     let arr: Uint8Array = bytes as any || new Uint8Array(0);\n     if (typeof bytes === 'string') {\n@@ -86,3 +163,33 @@ function toByteBuffer(bytes?: Uint8Array | Buffer | string) {\n     }\n     return new ByteBuffer(arr);\n }\n+\n+class BufferReaderContext implements VectorReaderContext {\n+    public offset: number;\n+    public batch: RecordBatch;\n+    private nodeIndex: number;\n+    private bufferIndex: number;\n+    private metadataVersion: MetadataVersion;\n+    constructor(public bytes: Uint8Array,\n+                public dictionaries: Map<string, Vector>) {\n+    }\n+    set message(m: Message) {\n+        this.nodeIndex = 0;\n+        this.bufferIndex = 0;\n+        this.offset = m.bb.position();\n+        this.metadataVersion = m.version();\n+    }\n+    public readNextNode() {\n+        return this.batch.nodes(this.nodeIndex++)!;\n+    }\n+    public readNextBuffer() {\n+        const buffer = this.batch.buffers(this.bufferIndex++)!;\n+        // If this Arrow buffer was written before version 4,\n+        // advance the buffer's bb_pos 8 bytes to skip past\n+        // the now-removed page id field.\n+        if (this.metadataVersion < MetadataVersion[`V4`]) {\n+            buffer.bb_pos += (8 * this.bufferIndex);\n+        }\n+        return buffer;\n+    }\n+}\n\\ No newline at end of file\ndiff --git a/js/src/reader/dictionary.ts b/js/src/reader/dictionary.ts\ndeleted file mode 100644\nindex 0c58ace3b..000000000\n--- a/js/src/reader/dictionary.ts\n+++ /dev/null\n@@ -1,36 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { readVector } from './vector';\n-import { MessageBatch } from './message';\n-import { DictionaryVector } from '../types/dictionary';\n-import * as Schema_ from '../format/Schema_generated';\n-import { IteratorState, Dictionaries } from './arrow';\n-import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-\n-export function readDictionary<T>(field: Field, batch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries): DictionaryVector<T> | null {\n-    let vector: DictionaryVector<T> | null, id, encoding = field.dictionary();\n-    if (encoding && batch.id === (id = encoding.id().toFloat64().toString())) {\n-        return readVector<T>(field, batch, iterator, null) as DictionaryVector<T>;\n-    }\n-    for (let i = -1, n = field.childrenLength() | 0; ++i < n;) {\n-        if (vector = readDictionary<T>(field.children(i)!, batch, iterator, dictionaries)) {\n-            return vector;\n-        }\n-    }\n-    return null;\n-}\ndiff --git a/js/src/reader/file.ts b/js/src/reader/file.ts\ndeleted file mode 100644\nindex bd60b4763..000000000\n--- a/js/src/reader/file.ts\n+++ /dev/null\n@@ -1,82 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { flatbuffers } from 'flatbuffers';\n-import * as File_ from '../format/File_generated';\n-import * as Schema_ from '../format/Schema_generated';\n-import * as Message_ from '../format/Message_generated';\n-import { PADDING, readMessageBatches } from './message';\n-\n-import ByteBuffer = flatbuffers.ByteBuffer;\n-import Footer = File_.org.apache.arrow.flatbuf.Footer;\n-export import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n-export import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n-\n-const MAGIC_STR = 'ARROW1';\n-const MAGIC = new Uint8Array(MAGIC_STR.length);\n-for (let i = 0; i < MAGIC_STR.length; i += 1 | 0) {\n-    MAGIC[i] = MAGIC_STR.charCodeAt(i);\n-}\n-\n-export function _checkMagic(buffer: Uint8Array, index = 0) {\n-    for (let i = -1, n = MAGIC.length; ++i < n;) {\n-        if (MAGIC[i] !== buffer[index + i]) {\n-            return false;\n-        }\n-    }\n-    return true;\n-}\n-\n-const magicLength = MAGIC.length;\n-const magicAndPadding = magicLength + PADDING;\n-const magicX2AndPadding = magicLength * 2 + PADDING;\n-\n-export function* readFile(...bbs: ByteBuffer[]) {\n-    for (let bb of bbs) {\n-        let fileLength = bb.capacity();\n-        let footerLength: number, footerOffset: number;\n-        if ((fileLength < magicX2AndPadding /*                     Arrow buffer too small */) ||\n-            (!_checkMagic(bb.bytes(), 0) /*                        Missing magic start    */) ||\n-            (!_checkMagic(bb.bytes(), fileLength - magicLength) /* Missing magic end      */) ||\n-            (/*                                                    Invalid footer length  */\n-            (footerLength = bb.readInt32(footerOffset = fileLength - magicAndPadding)) < 1 &&\n-            (footerLength + magicX2AndPadding > fileLength))) {\n-            throw new Error('Invalid file');\n-        }\n-        bb.setPosition(footerOffset - footerLength);\n-        let schema, footer = Footer.getRootAsFooter(bb);\n-        if (!(schema = footer.schema()!)) {\n-            return;\n-        }\n-        for (let i = -1, n = footer.dictionariesLength(); ++i < n;) {\n-            let block = footer.dictionaries(i)!;\n-            bb.setPosition(block.offset().low);\n-            for (let batch of readMessageBatches(bb)) {\n-                yield { schema, batch };\n-                break;\n-            }\n-        }\n-        for (let i = -1, n = footer.recordBatchesLength(); ++i < n;) {\n-            const block = footer.recordBatches(i)!;\n-            bb.setPosition(block.offset().low);\n-            for (let batch of readMessageBatches(bb)) {\n-                yield { schema, batch };\n-                break;\n-            }\n-        }\n-    }\n-}\ndiff --git a/js/src/reader/format.ts b/js/src/reader/format.ts\nnew file mode 100644\nindex 000000000..fd8f1b40d\n--- /dev/null\n+++ b/js/src/reader/format.ts\n@@ -0,0 +1,112 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import { flatbuffers } from 'flatbuffers';\n+import * as File_ from '../format/File';\n+import * as Schema_ from '../format/Schema';\n+import * as Message_ from '../format/Message';\n+import ByteBuffer = flatbuffers.ByteBuffer;\n+import Footer = File_.org.apache.arrow.flatbuf.Footer;\n+import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n+import Message = Message_.org.apache.arrow.flatbuf.Message;\n+import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n+\n+const PADDING = 4;\n+const MAGIC_STR = 'ARROW1';\n+const MAGIC = new Uint8Array(MAGIC_STR.length);\n+for (let i = 0; i < MAGIC_STR.length; i += 1 | 0) {\n+    MAGIC[i] = MAGIC_STR.charCodeAt(i);\n+}\n+\n+export function _checkMagic(buffer: Uint8Array, index = 0) {\n+    for (let i = -1, n = MAGIC.length; ++i < n;) {\n+        if (MAGIC[i] !== buffer[index + i]) {\n+            return false;\n+        }\n+    }\n+    return true;\n+}\n+\n+const magicLength = MAGIC.length;\n+const magicAndPadding = magicLength + PADDING;\n+const magicX2AndPadding = magicLength * 2 + PADDING;\n+\n+export function readStreamSchema(bb: ByteBuffer) {\n+    if (!_checkMagic(bb.bytes(), 0)) {\n+        for (const message of readMessages(bb)) {\n+            if (message.headerType() === MessageHeader.Schema) {\n+                return message.header(new Schema());\n+            }\n+        }\n+    }\n+    return null;\n+}\n+\n+export function readFileFooter(bb: ByteBuffer) {\n+    let fileLength = bb.capacity();\n+    let footerLength: number, footerOffset: number;\n+    if ((fileLength < magicX2AndPadding /*                     Arrow buffer too small */) ||\n+        (!_checkMagic(bb.bytes(), 0) /*                        Missing magic start    */) ||\n+        (!_checkMagic(bb.bytes(), fileLength - magicLength) /* Missing magic end      */) ||\n+        (/*                                                    Invalid footer length  */\n+        (footerLength = bb.readInt32(footerOffset = fileLength - magicAndPadding)) < 1 &&\n+        (footerLength + magicX2AndPadding > fileLength))) {\n+        return null;\n+    }\n+    bb.setPosition(footerOffset - footerLength);\n+    return Footer.getRootAsFooter(bb);\n+}\n+\n+export function* readFileMessages(bb: ByteBuffer, footer: Footer) {\n+    for (let i = -1, n = footer.dictionariesLength(); ++i < n;) {\n+        bb.setPosition(footer.dictionaries(i)!.offset().low);\n+        yield readMessage(bb, bb.readInt32(bb.position()));\n+    }\n+    for (let i = -1, n = footer.recordBatchesLength(); ++i < n;) {\n+        bb.setPosition(footer.recordBatches(i)!.offset().low);\n+        yield readMessage(bb, bb.readInt32(bb.position()));\n+    }\n+}\n+\n+export function readMessage(bb: ByteBuffer, length: number) {\n+    bb.setPosition(bb.position() + PADDING);\n+    const message = Message.getRootAsMessage(bb);\n+    bb.setPosition(bb.position() + length);\n+    return message;\n+}\n+\n+export function* readMessages(bb: ByteBuffer) {\n+    let length;\n+    while (bb.position() < bb.capacity() &&\n+          (length = bb.readInt32(bb.position())) > 0) {\n+        yield readMessage(bb, length);\n+    }\n+}\n+\n+export function* readStreamMessages(bb: ByteBuffer) {\n+    for (const message of readMessages(bb)) {\n+        switch (message.headerType()) {\n+            case MessageHeader.RecordBatch:\n+            case MessageHeader.DictionaryBatch:\n+                yield message;\n+                break;\n+            default: continue;\n+        }\n+        // position the buffer after the body to read the next message\n+        bb.setPosition(bb.position() + message.bodyLength().low);\n+    }\n+}\ndiff --git a/js/src/reader/message.ts b/js/src/reader/message.ts\ndeleted file mode 100644\nindex 6c8a96902..000000000\n--- a/js/src/reader/message.ts\n+++ /dev/null\n@@ -1,63 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { flatbuffers } from 'flatbuffers';\n-import * as Message_ from '../format/Message_generated';\n-import ByteBuffer = flatbuffers.ByteBuffer;\n-import Message = Message_.org.apache.arrow.flatbuf.Message;\n-import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n-import RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\n-import DictionaryBatch = Message_.org.apache.arrow.flatbuf.DictionaryBatch;\n-\n-export const PADDING = 4;\n-export type MessageBatch = {\n-    id?: string;\n-    offset: number;\n-    bytes: Uint8Array;\n-    data: RecordBatch;\n-};\n-\n-export function* readMessages(bb: ByteBuffer) {\n-    let message, length;\n-    while (bb.position() < bb.capacity() &&\n-          (length = bb.readInt32(bb.position())) > 0) {\n-        bb.setPosition(bb.position() + PADDING);\n-        message = Message.getRootAsMessage(bb);\n-        bb.setPosition(bb.position() + length);\n-        yield message;\n-    }\n-}\n-\n-export function* readMessageBatches(bb: ByteBuffer) {\n-    let bytes = bb.bytes();\n-    for (let message of readMessages(bb)) {\n-        let type = message.headerType();\n-        let id: string | void, data: RecordBatch;\n-        if (type === MessageHeader.RecordBatch) {\n-            data = message.header(new RecordBatch())!;\n-        } else if (type === MessageHeader.DictionaryBatch) {\n-            let header = message.header(new DictionaryBatch())!;\n-            id = header.id().toFloat64().toString();\n-            data = header.data()!;\n-        } else {\n-            continue;\n-        }\n-        yield <MessageBatch> { id, data, bytes, offset: bytes.byteOffset + bb.position() };\n-        // position the buffer after the body to read the next message\n-        bb.setPosition(bb.position() + message.bodyLength().low);\n-    }\n-}\ndiff --git a/js/src/reader/stream.ts b/js/src/reader/stream.ts\ndeleted file mode 100644\nindex 2062b1a8c..000000000\n--- a/js/src/reader/stream.ts\n+++ /dev/null\n@@ -1,43 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { _checkMagic } from './file';\n-import { flatbuffers } from 'flatbuffers';\n-import * as Schema_ from '../format/Schema_generated';\n-import * as Message_ from '../format/Message_generated';\n-import { readMessages, readMessageBatches } from './message';\n-\n-import ByteBuffer = flatbuffers.ByteBuffer;\n-import Schema = Schema_.org.apache.arrow.flatbuf.Schema;\n-import MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\n-\n-export function* readStream(...bbs: ByteBuffer[]) {\n-    if (!bbs.length || _checkMagic(bbs[0].bytes(), 0)) {\n-        throw new Error('Invalid Arrow Stream');\n-    }\n-    for (const message of readMessages(bbs[0])) {\n-        let schema: Schema;\n-        if (message.headerType() === MessageHeader.Schema && (schema = message.header(new Schema())!)) {\n-            for (const bb of bbs) {\n-                for (const batch of readMessageBatches(bb)) {\n-                    yield { schema, batch };\n-                }\n-            }\n-            break;\n-        }\n-    }\n-}\ndiff --git a/js/src/reader/vector.ts b/js/src/reader/vector.ts\nindex 4d3321833..0f95b769e 100644\n--- a/js/src/reader/vector.ts\n+++ b/js/src/reader/vector.ts\n@@ -15,288 +15,257 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { flatbuffers } from 'flatbuffers';\n-import { MessageBatch } from './message';\n-import * as Schema_ from '../format/Schema_generated';\n-import * as Message_ from '../format/Message_generated';\n-import { IteratorState, Dictionaries } from './arrow';\n+import { VectorReaderContext } from './arrow';\n+import * as Schema_ from '../format/Schema';\n+import * as Message_ from '../format/Message';\n+import { TypedArray, TypedArrayConstructor } from '../vector/types';\n import {\n-    Vector, Column,\n-    IntArray, FloatArray,\n-    TypedArray, TypedArrayConstructor,\n-} from '../types/types';\n-\n-import {\n-    DictionaryVector,\n-    Utf8Vector, StructVector,\n-    ListVector, FixedSizeListVector,\n-    DateVector, Float32Vector, Float64Vector,\n+    Vector, BoolVector, BinaryVector, DictionaryVector,\n     Int8Vector, Int16Vector, Int32Vector, Int64Vector,\n     Uint8Vector, Uint16Vector, Uint32Vector, Uint64Vector,\n-} from '../types/arrow';\n+    Utf8Vector, ListVector, FixedSizeListVector, StructVector,\n+    Float16Vector, Float32Vector, Float64Vector, DecimalVector,\n+    Date32Vector, Date64Vector, Time32Vector, Time64Vector, TimestampVector,\n+} from '../vector/arrow';\n \n import Int = Schema_.org.apache.arrow.flatbuf.Int;\n+import Date = Schema_.org.apache.arrow.flatbuf.Date;\n+import Time = Schema_.org.apache.arrow.flatbuf.Time;\n import Type = Schema_.org.apache.arrow.flatbuf.Type;\n import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+import Buffer = Schema_.org.apache.arrow.flatbuf.Buffer;\n+import Decimal = Schema_.org.apache.arrow.flatbuf.Decimal;\n+import DateUnit = Schema_.org.apache.arrow.flatbuf.DateUnit;\n+import TimeUnit = Schema_.org.apache.arrow.flatbuf.TimeUnit;\n+// import Interval = Schema_.org.apache.arrow.flatbuf.Interval;\n+import Timestamp = Schema_.org.apache.arrow.flatbuf.Timestamp;\n+// import IntervalUnit = Schema_.org.apache.arrow.flatbuf.IntervalUnit;\n import Precision = Schema_.org.apache.arrow.flatbuf.Precision;\n-import VectorType = Schema_.org.apache.arrow.flatbuf.VectorType;\n-import VectorLayout = Schema_.org.apache.arrow.flatbuf.VectorLayout;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n import FixedSizeList = Schema_.org.apache.arrow.flatbuf.FixedSizeList;\n import FloatingPoint = Schema_.org.apache.arrow.flatbuf.FloatingPoint;\n-import DictionaryEncoding = Schema_.org.apache.arrow.flatbuf.DictionaryEncoding;\n+import FixedSizeBinary = Schema_.org.apache.arrow.flatbuf.FixedSizeBinary;\n \n-export function readVector<T>(field: Field, batch: MessageBatch, state: IteratorState, dictionaries: Dictionaries): Column<T> | DictionaryVector<T> | null {\n-    return readDictionaryVector<T>(field, batch, state, dictionaries) ||\n-                readTypedVector<T>(field, batch, state, dictionaries);\n+export function readVector(field: Field, state: VectorReaderContext) {\n+    return readDictionaryVector(field, state) || readValueVector(field, state);\n }\n \n-function readTypedVector<T>(field: Field, batch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries): Column<T> | DictionaryVector<T> | null {\n-    let typeType = field.typeType(), readTyped = typedVectorReaders[typeType];\n-    if (!readTyped) {\n-        throw new Error('Unrecognized vector name \"' + Type[typeType] + '\" type \"' + typeType + '\"');\n-    }\n-    return readTyped(field, batch, iterator, dictionaries) as Column<T>;\n-}\n+/* a dictionary index defaults to signed 32 bit int if unspecified */\n+const defaultDictionaryIndexType = { bitWidth: () => 32, isSigned: () => true } as Int;\n+const intVectors = [\n+    [/* unsigned */ [Uint8Vector,  Uint8Array ],  /* signed */ [Int8Vector , Int8Array ]],\n+    [/* unsigned */ [Uint16Vector, Uint16Array],  /* signed */ [Int16Vector, Int16Array]],\n+    [/* unsigned */ [Uint32Vector, Uint32Array],  /* signed */ [Int32Vector, Int32Array]],,\n+    [/* unsigned */ [Uint64Vector, Uint32Array],  /* signed */ [Int64Vector, Int32Array]]\n+] as [any, TypedArrayConstructor][][];\n \n-function readDictionaryVector<T>(field: Field, batch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries): DictionaryVector<T> | null {\n-    let data: Vector<any>, encoding: DictionaryEncoding;\n-    if (dictionaries &&\n-        (encoding = field.dictionary()!) &&\n-        (data = dictionaries[encoding.id().toFloat64().toString()])) {\n-        let indexType =  encoding.indexType() ||\n-            /* a dictionary index defaults to signed 32 bit int if unspecified */\n-            { bitWidth: () => 32, isSigned: () => true };\n-        // workaround for https://issues.apache.org/jira/browse/ARROW-1363\n-        let indexField = createSyntheticDictionaryIndexField(field, indexType);\n-        let keys = readIntVector(indexField, batch, iterator, null, indexType)!;\n-        return new DictionaryVector<T>({ data, keys: keys! });\n+export function readDictionaryVector(field: Field, state: VectorReaderContext) {\n+    const encoding = field.dictionary()!;\n+    if (encoding) {\n+        const type = encoding.indexType() || defaultDictionaryIndexType;\n+        const data = state.dictionaries.get(encoding.id().toFloat64().toString())!;\n+        const [IntVector, IntArray] = intVectors[type.bitWidth() >>> 4]![+type.isSigned()];\n+        const { fieldNode, validity, data: keys } = readNumericBuffers(field, state, IntArray);\n+        return new DictionaryVector({\n+            validity, data, field, fieldNode,\n+            keys: new IntVector({ field, fieldNode, data: keys })\n+        });\n     }\n     return null;\n }\n \n-const IntViews    = [Int8Array,    Int16Array,   Int32Array,   Int32Array  ];\n-const Int32Views  = [Int32Array,   Int32Array,   Int32Array,   Int32Array  ];\n-const UintViews   = [Uint8Array,   Uint16Array,  Uint32Array,  Uint32Array ];\n-const Uint8Views  = [Uint8Array,   Uint8Array,   Uint8Array,   Uint8Array  ];\n-const Uint32Views = [Uint32Array,  Uint32Array,  Uint32Array,  Uint32Array ];\n-const FloatViews  = [Int8Array,    Int16Array,   Float32Array, Float64Array];\n-\n-const createIntDataViews = createTypedArray.bind(null, IntViews, null);\n-const createUintDataViews = createTypedArray.bind(null, UintViews, null);\n-const createDateDataViews = createTypedArray.bind(null, Uint32Views, null);\n-const createFloatDataViews = createTypedArray.bind(null, FloatViews, null);\n-const createNestedDataViews = createTypedArray.bind(null, Uint32Views, null);\n-const createValidityDataViews = createTypedArray.bind(null, Uint8Views, null);\n-const createUtf8DataViews = createTypedArray.bind(null, Uint8Views, Int32Views);\n-\n-// Define as computed properties for closure-compiler\n-const floatVectors = {\n-    [Precision.HALF]: Float32Vector,\n-    [Precision.SINGLE]: Float32Vector,\n-    [Precision.DOUBLE]: Float64Vector,\n-} as { [k: number]: any };\n+export function readValueVector(field: Field, state: VectorReaderContext): Vector {\n+    switch (field.typeType()) {\n+        case Type.NONE: return readNullVector();\n+        case Type.Null: return readNullVector();\n+        // case Type.Map: return readMapVector(field, state);\n+        case Type.Int: return readIntVector(field, state);\n+        case Type.Bool: return readBoolVector(field, state);\n+        case Type.Date: return readDateVector(field, state);\n+        case Type.List: return readListVector(field, state);\n+        case Type.Utf8: return readUtf8Vector(field, state);\n+        case Type.Time: return readTimeVector(field, state);\n+        // case Type.Union: return readUnionVector(field, state);\n+        case Type.Binary: return readBinaryVector(field, state);\n+        case Type.Decimal: return readDecimalVector(field, state);\n+        case Type.Struct_: return readStructVector(field, state);\n+        case Type.FloatingPoint: return readFloatVector(field, state);\n+        case Type.Timestamp: return readTimestampVector(field, state);\n+        case Type.FixedSizeList: return readFixedSizeListVector(field, state);\n+        case Type.FixedSizeBinary: return readFixedSizeBinaryVector(field, state);\n+    }\n+    throw new Error(`Unrecognized Vector { name: ${Type[field.typeType()]}, type: ${field.typeType()} }`);\n+}\n \n-// and again as string-indexed keys for Uglify...\n-floatVectors[Precision['HALF']] = Float32Vector;\n-floatVectors[Precision['SINGLE']] = Float32Vector;\n-floatVectors[Precision['DOUBLE']] = Float64Vector;\n+export function readNullVector() {\n+    return new Vector();\n+}\n \n-const intVectors = [\n-    [/* unsigned */ Uint8Vector,   /* signed */ Int8Vector ],\n-    [/* unsigned */ Uint16Vector,  /* signed */ Int16Vector],\n-    [/* unsigned */ Uint32Vector,  /* signed */ Int32Vector],\n-    [/* unsigned */ Uint64Vector,  /* signed */ Int64Vector]\n-] as any[][];\n+export function readBoolVector(field: Field, state: VectorReaderContext) {\n+    return new BoolVector(readNumericBuffers(field, state, Uint8Array));\n+}\n \n-function readIntVector(field: Field, batch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries, primitiveType?: PrimitiveType) {\n-    let type = (primitiveType || field.type(new Int())!);\n-    return type.isSigned() ?\n-        read_IntVector(field, batch, iterator, dictionaries, type) :\n-        readUintVector(field, batch, iterator, dictionaries, type);\n+export function readDateVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new Date())!;\n+    switch (type.unit()) {\n+        case DateUnit.DAY: return new Date32Vector({ ...readNumericBuffers(field, state, Int32Array), unit: DateUnit[type.unit()] });\n+        case DateUnit.MILLISECOND: return new Date64Vector({ ...readNumericBuffers(field, state, Int32Array), unit: DateUnit[type.unit()] });\n+    }\n+    throw new Error(`Unrecognized Date { unit: ${type.unit()} }`);\n }\n \n-function read_IntVector(field: Field, batch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries, primitiveType?: PrimitiveType) {\n-    return readVectorLayout(createIntDataViews, createIntVector, field, batch, iterator, dictionaries, primitiveType);\n+export function readTimeVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new Time())!;\n+    switch (type.bitWidth()) {\n+        case 32: return new Time32Vector({ ...readNumericBuffers(field, state, Int32Array), unit: TimeUnit[type.unit()] });\n+        case 64: return new Time64Vector({ ...readNumericBuffers(field, state, Uint32Array), unit: TimeUnit[type.unit()] });\n+    }\n+    throw new Error(`Unrecognized Time { unit: ${type.unit()}, bitWidth: ${type.bitWidth()} }`);\n }\n \n-function readUintVector(field: Field, batch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries, primitiveType?: PrimitiveType) {\n-    return readVectorLayout(createUintDataViews, createIntVector, field, batch, iterator, dictionaries, primitiveType);\n+export function readTimestampVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new Timestamp())!;\n+    const { fieldNode, validity, data } = readNumericBuffers(field, state, Uint32Array);\n+    return new TimestampVector({\n+        field, fieldNode, validity, data,\n+        timezone: type.timezone()!,\n+        unit: TimeUnit[type.unit()],\n+    });\n }\n \n-function createIntVector(argv: VectorFactoryArgv<IntArray>) {\n-    let { field, fieldNode, data, validity, offsets, primitiveType } = argv;\n-    let type = primitiveType || field.type(new Int())!, bitWidth = type.bitWidth();\n-    let IntVector = valueForBitWidth(bitWidth, intVectors)[+type.isSigned()];\n-    return new IntVector({ fieldNode, field, validity, data: data! || offsets! });\n-    // ---------------------------------------------------- \ud83d\udc46:\n-    // Workaround for https://issues.apache.org/jira/browse/ARROW-1363\n-    // This bug causes dictionary encoded vector indicies' IntVector data\n-    // buffers to be tagged as VectorType.OFFSET (0) in the field metadata\n-    // instead of VectorType.DATA. The `readVectorLayout` routine strictly\n-    // obeys the types in the field metadata, so if we're parsing an Arrow\n-    // file written by a version of the library published before ARROW-1363\n-    // was fixed, the IntVector's data buffer will be null, and the offset\n-    // buffer will be the actual data. If data is null, it's safe to assume\n-    // the offset buffer is the data, because IntVectors don't have offsets.\n+export function readListVector(field: Field, state: VectorReaderContext) {\n+    const { fieldNode, validity, offsets } = readListBuffers(field, state);\n+    return new ListVector({\n+        field, fieldNode, validity, offsets,\n+        values: readVector(field.children(0)!, state)\n+    });\n }\n \n-function bindVectorReader<T extends TypedArray, V>(createBufferView: BufferViewFactory<T>, createVector: VectorFactory<T, V>) {\n-    return function readVector(field: Field, batch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries, primitiveType?: PrimitiveType) {\n-        return readVectorLayout(createBufferView, createVector, field, batch, iterator, dictionaries, primitiveType);\n-    };\n+export function readStructVector(field: Field, state: VectorReaderContext) {\n+    const n = field.childrenLength();\n+    const columns = new Array<Vector>(n);\n+    const fieldNode = state.readNextNode();\n+    const validity = readValidityBuffer(field, fieldNode, state);\n+    for (let i = -1, child: Field; ++i < n;) {\n+        if (child = field.children(i)!) {\n+            columns[i] = readVector(child, state);\n+        }\n+    }\n+    return new StructVector({ field, fieldNode, validity, columns });\n }\n \n-const readFloatVector = bindVectorReader(createFloatDataViews, ({ field, fieldNode, data, validity }: VectorFactoryArgv<FloatArray>) => {\n-    const type = field.type(new FloatingPoint())!;\n-    const FloatVector = floatVectors[type.precision()];\n-    return new FloatVector({ field, fieldNode, validity, data: data! });\n-});\n+export function readBinaryVector(field: Field, state: VectorReaderContext) {\n+    return new BinaryVector(readBinaryBuffers(field, state));\n+}\n \n-const readDateVector = bindVectorReader(createDateDataViews, ({ field, fieldNode, data, validity }: VectorFactoryArgv<Uint32Array>) => {\n-    return new DateVector({ field, fieldNode, validity, data: data! });\n-});\n+export function readDecimalVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new Decimal())!;\n+    const { fieldNode, validity, data } = readNumericBuffers(field, state, Uint32Array);\n+    return new DecimalVector({\n+        scale: type.scale(),\n+        precision: type.precision(),\n+        field, fieldNode, validity, data\n+    });\n+}\n \n-const readUtf8Vector = bindVectorReader(createUtf8DataViews, ({ field, fieldNode, data, offsets, validity }: VectorFactoryArgv<Uint8Array>) => {\n+export function readUtf8Vector(field: Field, state: VectorReaderContext) {\n+    const { fieldNode, validity, offsets, data } = readBinaryBuffers(field, state);\n     return new Utf8Vector({\n         field, fieldNode,\n-        values: new ListVector({\n-            validity,\n-            offsets: offsets as Int32Array,\n-            values: new Uint8Vector({ data: data! })\n-        }) as any as Vector<Uint8Array | null>\n+        values: new BinaryVector({\n+            validity, offsets, data\n+        })\n     });\n-});\n+}\n \n-const readListVector = bindVectorReader(createNestedDataViews, ({ field, fieldNode, offsets, validity, iterator, messageBatch, dictionaries }: VectorFactoryArgv<TypedArray>) => {\n-    return new ListVector({\n+export function readFixedSizeListVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new FixedSizeList())!;\n+    const fieldNode = state.readNextNode();\n+    const validity = readValidityBuffer(field, fieldNode, state);\n+    return new FixedSizeListVector({\n         field, fieldNode, validity,\n-        offsets: offsets! as Int32Array,\n-        values: readVector(field.children(0)!, messageBatch, iterator, dictionaries)!\n+        size: type.listSize(),\n+        values: readVector(field.children(0)!, state)\n     });\n-});\n+}\n \n-const readFixedSizeListVector = bindVectorReader(createNestedDataViews, ({ field, fieldNode, validity, iterator, messageBatch, dictionaries }: VectorFactoryArgv<Uint32Array>) => {\n+export function readFixedSizeBinaryVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new FixedSizeBinary())!;\n+    const { fieldNode, validity, data } = readNumericBuffers(field, state, Uint8Array);\n     return new FixedSizeListVector({\n+        size: type.byteWidth(),\n         field, fieldNode, validity,\n-        listSize: field.type(new FixedSizeList())!.listSize(),\n-        values: readVector(field.children(0)!, messageBatch, iterator, dictionaries)!\n+        values: new Uint8Vector({ data })\n     });\n-});\n+}\n \n-const readStructVector = bindVectorReader(createNestedDataViews, ({ field, fieldNode, validity, iterator, messageBatch, dictionaries }: VectorFactoryArgv<ArrayLike<any>>) => {\n-    let columns: Column<any>[] = [];\n-    for (let i = -1, n = field.childrenLength(); ++i < n;) {\n-        columns[i] = readVector<any>(field.children(i)!, messageBatch, iterator, dictionaries) as Column<any>;\n+export function readFloatVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new FloatingPoint())!;\n+    switch (type.precision()) {\n+        case Precision.HALF:   return new Float16Vector(readNumericBuffers(field, state, Uint16Array));\n+        case Precision.SINGLE: return new Float32Vector(readNumericBuffers(field, state, Float32Array));\n+        case Precision.DOUBLE: return new Float64Vector(readNumericBuffers(field, state, Float64Array));\n     }\n-    return new StructVector({ field, fieldNode, validity, columns });\n-});\n+    throw new Error(`Unrecognized FloatingPoint { precision: ${type.precision()} }`);\n+}\n \n-// Define as computed properties for closure-compiler\n-const typedVectorReaders = {\n-    [Type.Int]: readIntVector,\n-    [Type.Date]: readDateVector,\n-    [Type.List]: readListVector,\n-    [Type.Utf8]: readUtf8Vector,\n-    [Type.Struct_]: readStructVector,\n-    [Type.FloatingPoint]: readFloatVector,\n-    [Type.FixedSizeList]: readFixedSizeListVector,\n-} as { [k: number]: (...args: any[]) => Vector | null };\n+export function readIntVector(field: Field, state: VectorReaderContext) {\n+    const type = field.type(new Int())!;\n+    if (type.isSigned()) {\n+        switch (type.bitWidth()) {\n+            case  8: return new  Int8Vector(readNumericBuffers(field, state, Int8Array));\n+            case 16: return new Int16Vector(readNumericBuffers(field, state, Int16Array));\n+            case 32: return new Int32Vector(readNumericBuffers(field, state, Int32Array));\n+            case 64: return new Int64Vector(readNumericBuffers(field, state, Int32Array));\n+        }\n+    }\n+    switch (type.bitWidth()) {\n+        case  8: return new  Uint8Vector(readNumericBuffers(field, state, Uint8Array));\n+        case 16: return new Uint16Vector(readNumericBuffers(field, state, Uint16Array));\n+        case 32: return new Uint32Vector(readNumericBuffers(field, state, Uint32Array));\n+        case 64: return new Uint64Vector(readNumericBuffers(field, state, Uint32Array));\n+    }\n+    throw new Error(`Unrecognized Int { isSigned: ${type.isSigned()}, bitWidth: ${type.bitWidth()} }`);\n+}\n \n-// and again as string-indexed keys for Uglify...\n-typedVectorReaders[Type['Int']] = readIntVector;\n-typedVectorReaders[Type['Date']] = readDateVector;\n-typedVectorReaders[Type['List']] = readListVector;\n-typedVectorReaders[Type['Utf8']] = readUtf8Vector;\n-typedVectorReaders[Type['Struct_']] = readStructVector;\n-typedVectorReaders[Type['FloatingPoint']] = readFloatVector;\n-typedVectorReaders[Type['FixedSizeList']] = readFixedSizeListVector;\n+function readListBuffers(field: Field, state: VectorReaderContext) {\n+    const fieldNode = state.readNextNode();\n+    const validity = readValidityBuffer(field, fieldNode, state);\n+    const offsets = readDataBuffer(Int32Array, state);\n+    return { field, fieldNode, validity, offsets };\n+}\n \n-type VectorFactory<T, V> = (argv: VectorFactoryArgv<T>) => V;\n-type PrimitiveType = { bitWidth(): number; isSigned(): boolean };\n-type BufferViewFactory<T extends TypedArray> = (batch: MessageBatch, type: VectorType, bitWidth: number, offset: number, length: number) => T;\n+function readBinaryBuffers(field: Field, state: VectorReaderContext) {\n+    const fieldNode = state.readNextNode();\n+    const validity = readValidityBuffer(field, fieldNode, state);\n+    const offsets = readDataBuffer(Int32Array, state);\n+    const data = readDataBuffer(Uint8Array, state);\n+    return { field, fieldNode, validity, offsets, data };\n+}\n \n-interface VectorFactoryArgv<T> {\n-    field: Field;\n-    fieldNode: FieldNode;\n-    iterator: IteratorState;\n-    dictionaries: Dictionaries;\n-    messageBatch: MessageBatch;\n-    data?: T;\n-    offsets?: TypedArray;\n-    validity?: Uint8Array;\n-    primitiveType?: PrimitiveType;\n+function readNumericBuffers<T extends TypedArray>(field: Field, state: VectorReaderContext, ArrayConstructor: TypedArrayConstructor<T>) {\n+    const fieldNode = state.readNextNode();\n+    const validity = readValidityBuffer(field, fieldNode, state);\n+    const data = readDataBuffer(ArrayConstructor, state);\n+    return { field, fieldNode, validity, data };\n }\n \n-function readVectorLayout<T extends TypedArray, V>(\n-    createBufferView: BufferViewFactory<T>, createVector: VectorFactory<T, V>,\n-    field: Field, messageBatch: MessageBatch, iterator: IteratorState, dictionaries: Dictionaries, primitiveType?: PrimitiveType\n-) {\n-    let fieldNode: FieldNode, recordBatch = messageBatch.data;\n-    if (!(fieldNode = recordBatch.nodes(iterator.nodeIndex)!)) {\n-        return null;\n-    }\n-    iterator.nodeIndex += 1;\n-    let type, bitWidth, layout, buffer, bufferLength;\n-    let data: T | undefined, offsets: TypedArray | undefined, validity: Uint8Array | undefined;\n-    for (let i = -1, n = field.layoutLength(); ++i < n;) {\n-        if (!(layout = field.layout(i)!) ||\n-            !(buffer = recordBatch.buffers(iterator.bufferIndex)!)) {\n-            continue;\n-        }\n-        iterator.bufferIndex += 1;\n-        if ((type = layout.type()) === VectorType.TYPE ||\n-            (bufferLength = buffer.length().low) <= 0  ||\n-            (bitWidth = layout.bitWidth()) <= 0) {\n-            continue;\n-        } else if (type === VectorType.DATA) {\n-            data = createBufferView(messageBatch, type, bitWidth, buffer.offset().low, bufferLength);\n-        } else if (type === VectorType.OFFSET) {\n-            offsets = createBufferView(messageBatch, type, bitWidth, buffer.offset().low, bufferLength);\n-        } else if (fieldNode.nullCount().low > 0) {\n-            validity = createValidityDataViews(messageBatch, type, bitWidth, buffer.offset().low, fieldNode.length().low);\n-        }\n-    }\n-    return createVector({ data, offsets, validity, field, fieldNode, iterator, messageBatch, dictionaries, primitiveType });\n+function readDataBuffer<T extends TypedArray>(ArrayConstructor: TypedArrayConstructor<T>, state: VectorReaderContext) {\n+    return createTypedArray(ArrayConstructor, state.bytes, state.offset, state.readNextBuffer());\n }\n \n-function createTypedArray(\n-    bufferViews: TypedArrayConstructor[], offsetViews: TypedArrayConstructor[] | null,\n-    batch: MessageBatch, type: VectorType, bitWidth: number, offset: number, length: number\n-) {\n-    const buffer = batch.bytes.buffer;\n-    const byteLength = buffer.byteLength;\n-    const byteOffset = batch.offset + offset;\n-    const DataViewType = valueForBitWidth(bitWidth, type === VectorType.OFFSET && offsetViews || bufferViews);\n-    const dataViewLength = ((byteOffset + length) <= byteLength\n-        ? length\n-        : byteLength - byteOffset\n-    ) / DataViewType['BYTES_PER_ELEMENT'];\n-    return new DataViewType(buffer, byteOffset, dataViewLength);\n+function readValidityBuffer(field: Field, fieldNode: FieldNode, state: VectorReaderContext) {\n+    return createValidityArray(field, fieldNode, state.bytes, state.offset, state.readNextBuffer());\n }\n \n-function valueForBitWidth<T>(bitWidth: number, values: T[]) {\n-    return values[bitWidth >> 4] || values[3];\n+function createValidityArray(field: Field, fieldNode: FieldNode, bytes: Uint8Array, offset: number, buffer: Buffer) {\n+    return field.nullable() && fieldNode.nullCount().low > 0 && createTypedArray(Uint8Array, bytes, offset, buffer) || null;\n }\n \n-function createSyntheticDictionaryIndexField(field: Field, type: PrimitiveType) {\n-    let layouts = [] as VectorLayout[];\n-    let builder = new flatbuffers.Builder();\n-    if (field.nullable()) {\n-        VectorLayout.startVectorLayout(builder);\n-        VectorLayout.addBitWidth(builder, 8);\n-        VectorLayout.addType(builder, VectorType.VALIDITY);\n-        builder.finish(VectorLayout.endVectorLayout(builder));\n-        layouts.push(VectorLayout.getRootAsVectorLayout(builder.dataBuffer()));\n-        builder = new flatbuffers.Builder();\n-    }\n-    VectorLayout.startVectorLayout(builder);\n-    VectorLayout.addBitWidth(builder, type.bitWidth());\n-    VectorLayout.addType(builder, VectorType.DATA);\n-    builder.finish(VectorLayout.endVectorLayout(builder));\n-    layouts.push(VectorLayout.getRootAsVectorLayout(builder.dataBuffer()));\n-    return Object.create(field, {\n-        layout: { value(i: number) { return layouts[i]; } },\n-        layoutLength: { value() { return layouts.length; } }\n-    });\n+function createTypedArray<T extends TypedArray>(ArrayConstructor: TypedArrayConstructor<T>, bytes: Uint8Array, offset: number, buffer: Buffer) {\n+    return new ArrayConstructor(\n+        bytes.buffer,\n+        bytes.byteOffset + offset + buffer.offset().low,\n+        buffer.length().low / ArrayConstructor.BYTES_PER_ELEMENT\n+    );\n }\ndiff --git a/js/src/types/arrow.ts b/js/src/types/arrow.ts\ndeleted file mode 100644\nindex e18f5da4f..000000000\n--- a/js/src/types/arrow.ts\n+++ /dev/null\n@@ -1,88 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import * as Schema_ from '../format/Schema_generated';\n-import * as Message_ from '../format/Message_generated';\n-import Field = Schema_.org.apache.arrow.flatbuf.Field;\n-import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n-\n-import { BoolVector } from './vector/bool';\n-import { DictionaryVector } from './dictionary';\n-import { nullableMixin, fieldMixin } from './vector/traits';\n-import { ListVector as ListVectorBase } from './list';\n-import { Utf8Vector as Utf8VectorBase } from './utf8';\n-import { Vector, Column, TypedArray } from './types';\n-import { DateVector as DateVectorBase } from './vector/date';\n-import { TableVector as TableVectorBase } from './table/table';\n-import { StructVector as StructVectorBase } from './table/struct';\n-import { FixedSizeListVector as FixedSizeListVectorBase } from './fixedsizelist';\n-import {\n-    LongVector as LongVectorBase,\n-    Int64Vector as Int64VectorBase,\n-    Uint64Vector as Uint64VectorBase,\n-} from './vector/long';\n-import {\n-    TypedVector,\n-    Int8Vector as Int8VectorBase,\n-    Int16Vector as Int16VectorBase,\n-    Int32Vector as Int32VectorBase,\n-    Uint8Vector as Uint8VectorBase,\n-    Uint16Vector as Uint16VectorBase,\n-    Uint32Vector as Uint32VectorBase,\n-    Float32Vector as Float32VectorBase,\n-    Float64Vector as Float64VectorBase,\n-} from './vector/typed';\n-\n-export { TypedArray, TypedVector };\n-export { Column, BoolVector, DictionaryVector };\n-export class ListVector extends MixinArrowTraits(ListVectorBase) {}\n-export class Utf8Vector extends MixinArrowTraits(Utf8VectorBase) {}\n-export class TableVector extends MixinArrowTraits(TableVectorBase) {}\n-export class StructVector extends MixinArrowTraits(StructVectorBase) {}\n-export class FixedSizeListVector extends MixinArrowTraits(FixedSizeListVectorBase) {}\n-export class DateVector extends MixinArrowTraits(DateVectorBase) {}\n-export class LongVector extends MixinArrowTraits(LongVectorBase) {}\n-export class Int8Vector extends MixinArrowTraits(Int8VectorBase) {}\n-export class Int16Vector extends MixinArrowTraits(Int16VectorBase) {}\n-export class Int32Vector extends MixinArrowTraits(Int32VectorBase) {}\n-export class Int64Vector extends MixinArrowTraits(Int64VectorBase) {}\n-export class Uint8Vector extends MixinArrowTraits(Uint8VectorBase) {}\n-export class Uint16Vector extends MixinArrowTraits(Uint16VectorBase) {}\n-export class Uint32Vector extends MixinArrowTraits(Uint32VectorBase) {}\n-export class Uint64Vector extends MixinArrowTraits(Uint64VectorBase) {}\n-export class Float32Vector extends MixinArrowTraits(Float32VectorBase) {}\n-export class Float64Vector extends MixinArrowTraits(Float64VectorBase) {}\n-\n-export function MixinArrowTraits<T extends Vector<any>, TArgv>(BaseVector: new (argv: TArgv) => T) {\n-    const FieldVector = fieldMixin(BaseVector);\n-    const NullableVector = nullableMixin(BaseVector);\n-    const NullableFieldVector = nullableMixin(FieldVector);\n-    return function(this: any, argv: TArgv & (object | { validity: Uint8Array } | { field: Field, fieldNode: FieldNode })) {\n-        return new ((!isFieldArgv(argv) ? !isNullableArgv(argv) ?\n-            BaseVector : NullableVector : !isNullableArgv(argv) ?\n-            FieldVector : NullableFieldVector\n-        ) as any)(argv);\n-    } as any as { new (argv: TArgv & (object | { validity: Uint8Array } | { field: Field, fieldNode: FieldNode })): T };\n-}\n-\n-function isFieldArgv(x: any): x is { field: Field, fieldNode: FieldNode } {\n-    return x && x.field instanceof Field && x.fieldNode instanceof FieldNode;\n-}\n-\n-function isNullableArgv(x: any): x is { validity: Uint8Array } {\n-    return x && x.validity && ArrayBuffer.isView(x.validity) && x.validity instanceof Uint8Array;\n-}\ndiff --git a/js/src/types/fixedsizelist.ts b/js/src/types/fixedsizelist.ts\ndeleted file mode 100644\nindex 6311d891d..000000000\n--- a/js/src/types/fixedsizelist.ts\n+++ /dev/null\n@@ -1,35 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { List, Vector } from './types';\n-import { VirtualVector } from './vector/virtual';\n-\n-export class FixedSizeListVector<T, TArray extends List<T>> extends Vector<TArray> {\n-    readonly listSize: number;\n-    readonly values: Vector<T>;\n-    constructor(argv: { listSize: number, values: Vector<T> }) {\n-        super();\n-        this.values = argv.values;\n-        this.listSize = argv.listSize;\n-    }\n-    get(index: number) {\n-        return this.values.slice<TArray>(this.listSize * index, this.listSize * (index + 1));\n-    }\n-    concat(...vectors: Vector<TArray>[]): Vector<TArray> {\n-        return new VirtualVector(Array, this, ...vectors);\n-    }\n-}\ndiff --git a/js/src/types/list.ts b/js/src/types/list.ts\ndeleted file mode 100644\nindex ca9170b59..000000000\n--- a/js/src/types/list.ts\n+++ /dev/null\n@@ -1,35 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { List, Vector } from './types';\n-import { VirtualVector } from './vector/virtual';\n-\n-export class ListVector<T, TArray extends List<T>> extends Vector<TArray> {\n-    readonly offsets: Int32Array;\n-    readonly values: Vector<T>;\n-    constructor(argv: { offsets: Int32Array, values: Vector<T> }) {\n-        super();\n-        this.values = argv.values;\n-        this.offsets = argv.offsets;\n-    }\n-    get(index: number) {\n-        return this.values.slice<TArray>(this.offsets[index], this.offsets[index + 1]);\n-    }\n-    concat(...vectors: Vector<TArray>[]): Vector<TArray> {\n-        return new VirtualVector(Array, this, ...vectors);\n-    }\n-}\n\\ No newline at end of file\ndiff --git a/js/src/types/table/from.ts b/js/src/types/table/from.ts\ndeleted file mode 100644\nindex ae0755961..000000000\n--- a/js/src/types/table/from.ts\n+++ /dev/null\n@@ -1,34 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { Column } from '../types';\n-import { TableVector } from './table';\n-import { readBuffers } from '../../reader/arrow';\n-\n-export function fromBuffers(...bytes: Array<Uint8Array | Buffer | string>) {\n-    let columns: Column<any>[] = null as any;\n-    for (let vectors of readBuffers(...bytes)) {\n-        columns = !columns ? vectors : columns.map((v, i) => v.concat(vectors[i]) as Column<any>);\n-    }\n-    return new TableVector({ columns });\n-}\n-\n-TableVector.from = fromBuffers;\n-\n-declare module './table' {\n-    namespace TableVector { export let from: typeof fromBuffers; }\n-}\n\\ No newline at end of file\ndiff --git a/js/src/types/table/row.ts b/js/src/types/table/row.ts\ndeleted file mode 100644\nindex 432cfd736..000000000\n--- a/js/src/types/table/row.ts\n+++ /dev/null\n@@ -1,61 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { Row, Vector, Struct } from '../types';\n-import { VirtualVector } from '../vector/virtual';\n-\n-export class RowVector<T = any> extends Vector<T> implements Row<T> {\n-    readonly row: number;\n-    readonly length: number;\n-    readonly table: Struct<T>;\n-    [Symbol.toStringTag]() { return 'Row'; }\n-    constructor(table: Struct<T>, row: number) {\n-        super();\n-        this.row = row;\n-        this.table = table;\n-        this.length = table.columns.length;\n-    }\n-    get(index: number) {\n-        const col = this.table.columns[index];\n-        return col ? col.get(this.row) as T : null;\n-    }\n-    col(key: string) {\n-        const col = this.table.col(key);\n-        return col ? col.get(this.row) as T : null;\n-    }\n-    *[Symbol.iterator]() {\n-        const { row } = this;\n-        for (const col of this.table.columns) {\n-            yield col ? col.get(row) : null;\n-        }\n-    }\n-    concat(...rows: Vector<T>[]): Vector<T> {\n-        return new VirtualVector(Array, this, ...rows as any[]);\n-    }\n-    toArray() { return [...this]; }\n-    toJSON() { return this.toArray(); }\n-    toString() { return `Row [${this.length})` }\n-    toObject(): Record<string, any> {\n-        const { row } = this, map = Object.create(null);\n-        for (const col of this.table.columns) {\n-            if (col && col.name) {\n-                map[col.name] = col.get(row);\n-            }\n-        }\n-        return map;\n-    }\n-}\ndiff --git a/js/src/types/table/struct.ts b/js/src/types/table/struct.ts\ndeleted file mode 100644\nindex de6a3a056..000000000\n--- a/js/src/types/table/struct.ts\n+++ /dev/null\n@@ -1,63 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { RowVector } from './row';\n-import { toString } from './toString';\n-import { VirtualVector } from '../vector/virtual';\n-import { Row, Vector, Column, Struct } from '../types';\n-\n-export interface StructVector {\n-    toString(): string;\n-    toString(index: boolean): string;\n-    toString(options: { index: boolean }): string;\n-}\n-\n-export class StructVector<T = any> extends Vector<Row<T>> implements Struct<T> {\n-    readonly length: number;\n-    readonly columns: Column[];\n-    constructor(argv: { columns: Column[] }) {\n-        super();\n-        this.columns = argv.columns || [];\n-        if (!this.length) {\n-            this.length = Math.max(...this.columns.map((col) => col.length)) | 0;\n-        }\n-    }\n-    get(index: number): StructRow<T> {\n-        return new StructRow(this, index);\n-    }\n-    col(name: string) {\n-        return this.columns.find((col) => col.name === name) || null;\n-    }\n-    key(index: number) {\n-        return this.columns[index] ? this.columns[index].name : null;\n-    }\n-    select(...columns: string[]) {\n-        return new StructVector({ columns: columns.map((name) => this.col(name)!) });\n-    }\n-    concat(...structs: Vector<Row<T>>[]): Vector<Row<T>> {\n-        return new VirtualVector(Array, this, ...structs as any[]);\n-    }\n-    toString(x?: any) {\n-        return toString(this, x);\n-    }\n-}\n-\n-export class StructRow<T> extends RowVector<T> {\n-    toString() {\n-        return JSON.stringify(this);\n-    }\n-}\n\\ No newline at end of file\ndiff --git a/js/src/types/table/table.ts b/js/src/types/table/table.ts\ndeleted file mode 100644\nindex d9074dec2..000000000\n--- a/js/src/types/table/table.ts\n+++ /dev/null\n@@ -1,30 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { StructVector, StructRow } from './struct';\n-\n-export class TableVector<T> extends StructVector<T> {\n-    get(index: number): TableRow<T> {\n-        return new TableRow(this, index);\n-    }\n-}\n-\n-export class TableRow<T> extends StructRow<T> {\n-    toString() {\n-        return this.toArray().map((x) => JSON.stringify(x)).join(', ');\n-    }\n-}\n\\ No newline at end of file\ndiff --git a/js/src/types/table/toString.ts b/js/src/types/table/toString.ts\ndeleted file mode 100644\nindex 85b23ca24..000000000\n--- a/js/src/types/table/toString.ts\n+++ /dev/null\n@@ -1,40 +0,0 @@\n-import { Struct } from '../types';\n-\n-export function toString<T>(source: Struct<T>, options?: any) {\n-    const index = typeof options === 'object' ? options && !!options.index\n-                : typeof options === 'boolean' ? !!options\n-                : false;\n-    const { length } = source;\n-    if (length <= 0) { return ''; }\n-    const rows = new Array(length + 1);\n-    const maxColumnWidths = [] as number[];\n-    rows[0] = source.columns.map((_, i) => source.key(i));\n-    index && rows[0].unshift('Index');\n-    for (let i = -1, n = rows.length - 1; ++i < n;) {\n-        rows[i + 1] = [...source.get(i)!];\n-        index && rows[i + 1].unshift(i);\n-    }\n-    // Pass one to convert to strings and count max column widths\n-    for (let i = -1, n = rows.length; ++i < n;) {\n-        const row = rows[i];\n-        for (let j = -1, k = row.length; ++j < k;) {\n-            const val = row[j] = `${row[j]}`;\n-            maxColumnWidths[j] = !maxColumnWidths[j]\n-                ? val.length\n-                : Math.max(maxColumnWidths[j], val.length);\n-        }\n-    }\n-    // Pass two to pad each one to max column width\n-    for (let i = -1, n = rows.length; ++i < n;) {\n-        const row = rows[i];\n-        for (let j = -1, k = row.length; ++j < k;) {\n-            row[j] = leftPad(row[j], ' ', maxColumnWidths[j]);\n-        }\n-        rows[i] = row.join(', ');\n-    }\n-    return rows.join('\\n');\n-}\n-\n-function leftPad(str: string, fill: string, n: number) {\n-    return (new Array(n + 1).join(fill) + str).slice(-1 * n);\n-}\ndiff --git a/js/src/types/vector/bool.ts b/js/src/types/vector/bool.ts\ndeleted file mode 100644\nindex b2eea81f8..000000000\n--- a/js/src/types/vector/bool.ts\n+++ /dev/null\n@@ -1,55 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { TypedVector } from './typed';\n-\n-export interface BoolVector extends TypedVector<boolean, Uint8Array> {\n-    set(index: number, value: boolean): void;\n-}\n-\n-export class BoolVector extends TypedVector<boolean, Uint8Array> {\n-    static pack = pack;\n-    get(index: number) {\n-        return (this.data[index >> 3] & 1 << index % 8) !== 0;\n-    }\n-    set(index: number, value: boolean) {\n-        if (index > -1 === false) {\n-            return;\n-        } else if (value) {\n-            this.data[index >> 3] |=  (1 << (index % 8));\n-        } else {\n-            this.data[index >> 3] &= ~(1 << (index % 8));\n-        }\n-    }\n-}\n-\n-export function pack(values: Iterable<any>) {\n-    let xs = [], n, i = 0;\n-    let bit = 0, byte = 0;\n-    for (const value of values) {\n-        value && (byte |= 1 << bit);\n-        if (++bit === 8) {\n-            xs[i++] = byte;\n-            byte = bit = 0;\n-        }\n-    }\n-    if (i === 0 || bit > 0) { xs[i++] = byte; }\n-    if (i % 8 && (n = i + 8 - i % 8)) {\n-        do { xs[i] = 0; } while (++i < n);\n-    }\n-    return new Uint8Array(xs);\n-}\ndiff --git a/js/src/types/vector/date.ts b/js/src/types/vector/date.ts\ndeleted file mode 100644\nindex 82dc82e64..000000000\n--- a/js/src/types/vector/date.ts\n+++ /dev/null\n@@ -1,29 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { TypedVector } from './typed';\n-\n-export class DateVector extends TypedVector<Date, Uint32Array> {\n-    get(index: number): Date {\n-        return new Date(4294967296   * /* 2^32 */\n-            (super.get(index * 2 + 1) as any) + /* high */\n-            (super.get(index * 2) as any)       /*  low */\n-        );\n-    }\n-}\n-\n-(DateVector.prototype as any).stride = 2;\ndiff --git a/js/src/types/vector/long.ts b/js/src/types/vector/long.ts\ndeleted file mode 100644\nindex de8eb0c13..000000000\n--- a/js/src/types/vector/long.ts\n+++ /dev/null\n@@ -1,35 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { TypedVector } from './typed';\n-import { TypedArray } from '../types';\n-import { flatbuffers } from 'flatbuffers';\n-import Long = flatbuffers.Long;\n-\n-export class LongVector<T extends TypedArray> extends TypedVector<Long, T> {\n-    get(index: number) {\n-        return new Long(\n-            super.get(index * 2) as any,    /*  low */\n-            super.get(index * 2 + 1) as any /* high */\n-        );\n-    }\n-}\n-\n-(LongVector.prototype as any).stride = 2;\n-\n-export class Int64Vector extends LongVector<Int32Array> {}\n-export class Uint64Vector extends LongVector<Uint32Array> {}\n\\ No newline at end of file\ndiff --git a/js/src/types/vector/typed.ts b/js/src/types/vector/typed.ts\ndeleted file mode 100644\nindex fc093f2cb..000000000\n--- a/js/src/types/vector/typed.ts\n+++ /dev/null\n@@ -1,57 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { Vector } from '../types';\n-import { VirtualVector } from './virtual';\n-import { TypedArray, TypedArrayConstructor } from '../types';\n-\n-export interface TypedVector<T, TArray extends TypedArray> {\n-    slice(start?: number, end?: number): TArray;\n-}\n-\n-export class TypedVector<T, TArray extends TypedArray> extends Vector<T> {\n-    readonly data: TArray;\n-    readonly stride: number;\n-    readonly length: number;\n-    constructor(argv: { data: TArray } | TArray) {\n-        super();\n-        const data = ArrayBuffer.isView(argv) ? argv : argv.data;\n-        this.length = ((this.data = data).length / this.stride) | 0;\n-    }\n-    get(index: number): T | null {\n-        return this.data[index] as any;\n-    }\n-    concat(...vectors: Vector<T>[]): Vector<T> {\n-        return new VirtualVector(this.data.constructor as TypedArrayConstructor, this, ...vectors);\n-    }\n-    slice(start?: number, end?: number) {\n-        const { data, stride } = this, from = start! | 0;\n-        const to = end === undefined ? data.length : Math.max(end | 0, from);\n-        return data.subarray(Math.min(from, to) * stride | 0, to * stride | 0);\n-    }\n-}\n-\n-(TypedVector.prototype as any).stride = 1;\n-\n-export class Int8Vector extends TypedVector<number, Int8Array> {}\n-export class Int16Vector extends TypedVector<number, Int16Array> {}\n-export class Int32Vector extends TypedVector<number, Int32Array> {}\n-export class Uint8Vector extends TypedVector<number, Uint8Array> {}\n-export class Uint16Vector extends TypedVector<number, Uint16Array> {}\n-export class Uint32Vector extends TypedVector<number, Uint32Array> {}\n-export class Float32Vector extends TypedVector<number, Float32Array> {}\n-export class Float64Vector extends TypedVector<number, Float64Array> {}\ndiff --git a/js/src/types/vector/virtual.ts b/js/src/types/vector/virtual.ts\ndeleted file mode 100644\nindex 7f56012dc..000000000\n--- a/js/src/types/vector/virtual.ts\n+++ /dev/null\n@@ -1,129 +0,0 @@\n-// Licensed to the Apache Software Foundation (ASF) under one\n-// or more contributor license agreements.  See the NOTICE file\n-// distributed with this work for additional information\n-// regarding copyright ownership.  The ASF licenses this file\n-// to you under the Apache License, Version 2.0 (the\n-// \"License\"); you may not use this file except in compliance\n-// with the License.  You may obtain a copy of the License at\n-//\n-//   http://www.apache.org/licenses/LICENSE-2.0\n-//\n-// Unless required by applicable law or agreed to in writing,\n-// software distributed under the License is distributed on an\n-// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-// KIND, either express or implied.  See the License for the\n-// specific language governing permissions and limitations\n-// under the License.\n-\n-import { TypedVector } from './typed';\n-import { Vector, Column, TypedArray, TypedArrayConstructor } from '../types';\n-\n-export class VirtualVector<T> implements Column<T> {\n-    readonly name: string;\n-    readonly type: string;\n-    readonly length: number;\n-    readonly vectors: Vector<T>[];\n-    readonly offsets: Uint32Array;\n-    readonly ArrayType: ArrayConstructor | TypedArrayConstructor;\n-    constructor(ArrayType: ArrayConstructor | TypedArrayConstructor, ...vectors: Vector<T>[]) {\n-        this.vectors = vectors;\n-        this.ArrayType = ArrayType;\n-        this.name = (vectors[0] as any).name;\n-        this.type = (vectors[0] as any).type;\n-        this.length = vectors.reduce((sum, vec) => sum + vec.length, 0);\n-        this.offsets = Uint32Array.from(vectors.reduce((sums, vector, index) => [...sums, vector.length + sums[index]], [0]));\n-    }\n-    *[Symbol.iterator]() {\n-        for (const vector of this.vectors) {\n-            yield* vector;\n-        }\n-    }\n-    get nullable() {\n-        return (this.vectors as Column<T>[]).some((vec) => vec.nullable);\n-    }\n-    get nullCount() {\n-        return (this.vectors as Column<T>[]).reduce((sum, v) => sum + v.nullCount | 0, 0);\n-    }\n-    get metadata() {\n-        return new Map<string, string>(\n-            (this.vectors as Column<T>[]).reduce((entries, v) => [\n-                ...entries, ...v.metadata.entries()\n-            ], [] as [string, string][])\n-        );\n-    }\n-    get(index: number) {\n-        return findIndex(this.offsets, index) ? this.vectors[_vector].get(_offset) : null;\n-    }\n-    concat(...vectors: Vector<T>[]) {\n-        return new VirtualVector(this.ArrayType, ...this.vectors, ...vectors);\n-    }\n-    slice(begin?: number, end?: number) {\n-        const ArrayType = this.ArrayType as any;\n-        // clamp begin and end values between the virtual length\n-        clampRange(this.length, begin!, end);\n-        const from = _from, total = _total;\n-        // find the start vector index and adjusted value index offset\n-        if (!findIndex(this.offsets, from)) { return new ArrayType(0); }\n-        const set = ArrayType === Array ? arraySet : typedArraySet as any;\n-        let index = _vector, vectors = this.vectors as TypedVector<T, TypedArray>[];\n-        let vector = vectors[index], source = vector.slice(_offset, _offset + total), target = source;\n-        // Perf optimization: if the first slice contains all the values we're looking for,\n-        // we don't have to copy values to a target Array. If we're slicing a TypedArray,\n-        // this is a significant improvement as we avoid the memcpy \ud83c\udf89\n-        if ((source.length / vector.stride | 0) < total) {\n-            let vectorsLength = vectors.length;\n-            let count = 0, length = 0, sources = [];\n-            do {\n-                sources.push(source);\n-                length += source.length;\n-                count += (source.length / vector.stride | 0);\n-            } while (\n-                (count  < total) &&\n-                (vector = vectors[index = (++index % vectorsLength)]) &&\n-                (source = vector.slice(0, Math.min(vector.length, total - count)))\n-            );\n-            target = new ArrayType(length);\n-            for (let i = -1, j = 0, n = sources.length; ++i < n;) {\n-                j = set(sources[i], target, j);\n-            }\n-        }\n-        return target;\n-    }\n-}\n-\n-let _from = -1, _total = -1;\n-function clampRange(length: number, start: number, end?: number) {\n-    let total = length, from = start || 0;\n-    let to = end === end && typeof end == 'number' ? end : total;\n-    if (to < 0) { to = total + to; }\n-    if (from < 0) { from = total - (from * -1) % total; }\n-    if (to < from) { from = to; to = start; }\n-    _from = from;\n-    _total = !isFinite(total = (to - from)) || total < 0 ? 0 : total;\n-}\n-\n-let _offset = -1, _vector = -1;\n-function findIndex(offsets: Uint32Array, index: number) {\n-    let offset = 0, left = 0, middle = 0, right = offsets.length - 1;\n-    while (index < offsets[right] && index >= (offset = offsets[left])) {\n-        if (left + 1 === right) {\n-            _vector = left;\n-            _offset = index - offset;\n-            return true;\n-        }\n-        middle = left + ((right - left) / 2) | 0;\n-        index >= offsets[middle] ? (left = middle) : (right = middle);\n-    }\n-    return false;\n-}\n-\n-function arraySet<T>(source: T[], target: T[], index: number) {\n-    for (let i = 0, n = source.length; i < n;) {\n-        target[index++] = source[i++];\n-    }\n-    return index;\n-}\n-\n-function typedArraySet(source: TypedArray, target: TypedArray, index: number) {\n-    return target.set(source, index) || index + source.length;\n-}\ndiff --git a/js/src/vector/arrow.ts b/js/src/vector/arrow.ts\nnew file mode 100644\nindex 000000000..88fec7e44\n--- /dev/null\n+++ b/js/src/vector/arrow.ts\n@@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import * as Schema_ from '../format/Schema';\n+import * as Message_ from '../format/Message';\n+import Field = Schema_.org.apache.arrow.flatbuf.Field;\n+import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n+\n+import { Vector } from './vector';\n+import { Utf8Vector as Utf8VectorBase } from './utf8';\n+import { StructVector as StructVectorBase } from './struct';\n+import { DictionaryVector as DictionaryVectorBase } from './dictionary';\n+import {\n+    ListVector as ListVectorBase,\n+    BinaryVector as BinaryVectorBase,\n+    FixedSizeListVector as FixedSizeListVectorBase\n+} from './list';\n+\n+import {\n+    BoolVector as BoolVectorBase,\n+    Int8Vector as Int8VectorBase,\n+    Int16Vector as Int16VectorBase,\n+    Int32Vector as Int32VectorBase,\n+    Int64Vector as Int64VectorBase,\n+    Uint8Vector as Uint8VectorBase,\n+    Uint16Vector as Uint16VectorBase,\n+    Uint32Vector as Uint32VectorBase,\n+    Uint64Vector as Uint64VectorBase,\n+    Float16Vector as Float16VectorBase,\n+    Float32Vector as Float32VectorBase,\n+    Float64Vector as Float64VectorBase,\n+    Date32Vector as Date32VectorBase,\n+    Date64Vector as Date64VectorBase,\n+    Time32Vector as Time32VectorBase,\n+    Time64Vector as Time64VectorBase,\n+    DecimalVector as DecimalVectorBase,\n+    TimestampVector as TimestampVectorBase,\n+} from './numeric';\n+\n+import { nullableMixin, fieldMixin } from './traits';\n+\n+function MixinArrowTraits<T extends Vector<any>, TArgv>(\n+    Base: new (argv: TArgv) => T,\n+    Field: new (argv: TArgv & { field: Field, fieldNode: FieldNode }) => T,\n+    Nullable: new (argv: TArgv & { validity: Uint8Array }) => T,\n+    NullableField: new (argv: TArgv & { validity: Uint8Array, field: Field, fieldNode: FieldNode }) => T,\n+) {\n+    return function(argv: TArgv | (TArgv & { validity: Uint8Array }) | (TArgv & { field: Field, fieldNode: FieldNode })) {\n+        return new (!isFieldArgv(argv)\n+            ? !isNullableArgv(argv) ? Base : Nullable\n+            : !isNullableArgv(argv) ? Field : NullableField\n+        )(argv as any);\n+    } as any as { new (argv: TArgv | (TArgv & { validity: Uint8Array }) | (TArgv & { field: Field, fieldNode: FieldNode })): T };\n+}\n+\n+function isFieldArgv(x: any): x is { field: Field, fieldNode: FieldNode } {\n+    return x && x.field instanceof Field && x.fieldNode instanceof FieldNode;\n+}\n+\n+function isNullableArgv(x: any): x is { validity: Uint8Array } {\n+    return x && x.validity && ArrayBuffer.isView(x.validity) && x.validity instanceof Uint8Array;\n+}\n+\n+export { Vector };\n+export class ListVector extends MixinArrowTraits(\n+    ListVectorBase,\n+    class ListVector extends fieldMixin(ListVectorBase) {} as any,\n+    class ListVector extends nullableMixin(ListVectorBase) {} as any,\n+    class ListVector extends nullableMixin(fieldMixin(ListVectorBase)) {} as any\n+) {}\n+\n+export class BinaryVector extends MixinArrowTraits(\n+    BinaryVectorBase,\n+    class BinaryVector extends fieldMixin(BinaryVectorBase) {} as any,\n+    class BinaryVector extends nullableMixin(BinaryVectorBase) {} as any,\n+    class BinaryVector extends nullableMixin(fieldMixin(BinaryVectorBase)) {} as any\n+) {}\n+\n+export class Utf8Vector extends MixinArrowTraits(\n+    Utf8VectorBase,\n+    class Utf8Vector extends fieldMixin(Utf8VectorBase) {} as any,\n+    class Utf8Vector extends nullableMixin(Utf8VectorBase) {} as any,\n+    class Utf8Vector extends nullableMixin(fieldMixin(Utf8VectorBase)) {} as any\n+) {}\n+\n+export class BoolVector extends MixinArrowTraits(\n+    BoolVectorBase,\n+    class BoolVector extends fieldMixin(BoolVectorBase) {} as any,\n+    class BoolVector extends nullableMixin(BoolVectorBase) {} as any,\n+    class BoolVector extends nullableMixin(fieldMixin(BoolVectorBase)) {} as any\n+) {}\n+\n+export class Int8Vector extends MixinArrowTraits(\n+    Int8VectorBase,\n+    class Int8Vector extends fieldMixin(Int8VectorBase) {} as any,\n+    class Int8Vector extends nullableMixin(Int8VectorBase) {} as any,\n+    class Int8Vector extends nullableMixin(fieldMixin(Int8VectorBase)) {} as any\n+) {}\n+\n+export class Int16Vector extends MixinArrowTraits(\n+    Int16VectorBase,\n+    class Int16Vector extends fieldMixin(Int16VectorBase) {} as any,\n+    class Int16Vector extends nullableMixin(Int16VectorBase) {} as any,\n+    class Int16Vector extends nullableMixin(fieldMixin(Int16VectorBase)) {} as any\n+) {}\n+\n+export class Int32Vector extends MixinArrowTraits(\n+    Int32VectorBase,\n+    class Int32Vector extends fieldMixin(Int32VectorBase) {} as any,\n+    class Int32Vector extends nullableMixin(Int32VectorBase) {} as any,\n+    class Int32Vector extends nullableMixin(fieldMixin(Int32VectorBase)) {} as any\n+) {}\n+\n+export class Int64Vector extends MixinArrowTraits(\n+    Int64VectorBase,\n+    class Int64Vector extends fieldMixin(Int64VectorBase) {} as any,\n+    class Int64Vector extends nullableMixin(Int64VectorBase) {} as any,\n+    class Int64Vector extends nullableMixin(fieldMixin(Int64VectorBase)) {} as any\n+) {}\n+\n+export class Uint8Vector extends MixinArrowTraits(\n+    Uint8VectorBase,\n+    class Uint8Vector extends fieldMixin(Uint8VectorBase) {} as any,\n+    class Uint8Vector extends nullableMixin(Uint8VectorBase) {} as any,\n+    class Uint8Vector extends nullableMixin(fieldMixin(Uint8VectorBase)) {} as any\n+) {}\n+\n+export class Uint16Vector extends MixinArrowTraits(\n+    Uint16VectorBase,\n+    class Uint16Vector extends fieldMixin(Uint16VectorBase) {} as any,\n+    class Uint16Vector extends nullableMixin(Uint16VectorBase) {} as any,\n+    class Uint16Vector extends nullableMixin(fieldMixin(Uint16VectorBase)) {} as any\n+) {}\n+\n+export class Uint32Vector extends MixinArrowTraits(\n+    Uint32VectorBase,\n+    class Uint32Vector extends fieldMixin(Uint32VectorBase) {} as any,\n+    class Uint32Vector extends nullableMixin(Uint32VectorBase) {} as any,\n+    class Uint32Vector extends nullableMixin(fieldMixin(Uint32VectorBase)) {} as any\n+) {}\n+\n+export class Uint64Vector extends MixinArrowTraits(\n+    Uint64VectorBase,\n+    class Uint64Vector extends fieldMixin(Uint64VectorBase) {} as any,\n+    class Uint64Vector extends nullableMixin(Uint64VectorBase) {} as any,\n+    class Uint64Vector extends nullableMixin(fieldMixin(Uint64VectorBase)) {} as any\n+) {}\n+\n+export class Date32Vector extends MixinArrowTraits(\n+    Date32VectorBase,\n+    class Date32Vector extends fieldMixin(Date32VectorBase) {} as any,\n+    class Date32Vector extends nullableMixin(Date32VectorBase) {} as any,\n+    class Date32Vector extends nullableMixin(fieldMixin(Date32VectorBase)) {} as any\n+) {}\n+\n+export class Date64Vector extends MixinArrowTraits(\n+    Date64VectorBase,\n+    class Date64Vector extends fieldMixin(Date64VectorBase) {} as any,\n+    class Date64Vector extends nullableMixin(Date64VectorBase) {} as any,\n+    class Date64Vector extends nullableMixin(fieldMixin(Date64VectorBase)) {} as any\n+) {}\n+\n+export class Time32Vector extends MixinArrowTraits(\n+    Time32VectorBase,\n+    class Time32Vector extends fieldMixin(Time32VectorBase) {} as any,\n+    class Time32Vector extends nullableMixin(Time32VectorBase) {} as any,\n+    class Time32Vector extends nullableMixin(fieldMixin(Time32VectorBase)) {} as any\n+) {}\n+\n+export class Time64Vector extends MixinArrowTraits(\n+    Time64VectorBase,\n+    class Time64Vector extends fieldMixin(Time64VectorBase) {} as any,\n+    class Time64Vector extends nullableMixin(Time64VectorBase) {} as any,\n+    class Time64Vector extends nullableMixin(fieldMixin(Time64VectorBase)) {} as any\n+) {}\n+\n+export class Float16Vector extends MixinArrowTraits(\n+    Float16VectorBase,\n+    class Float16Vector extends fieldMixin(Float16VectorBase) {} as any,\n+    class Float16Vector extends nullableMixin(Float16VectorBase) {} as any,\n+    class Float16Vector extends nullableMixin(fieldMixin(Float16VectorBase)) {} as any\n+) {}\n+\n+export class Float32Vector extends MixinArrowTraits(\n+    Float32VectorBase,\n+    class Float32Vector extends fieldMixin(Float32VectorBase) {} as any,\n+    class Float32Vector extends nullableMixin(Float32VectorBase) {} as any,\n+    class Float32Vector extends nullableMixin(fieldMixin(Float32VectorBase)) {} as any\n+) {}\n+\n+export class Float64Vector extends MixinArrowTraits(\n+    Float64VectorBase,\n+    class Float64Vector extends fieldMixin(Float64VectorBase) {} as any,\n+    class Float64Vector extends nullableMixin(Float64VectorBase) {} as any,\n+    class Float64Vector extends nullableMixin(fieldMixin(Float64VectorBase)) {} as any\n+) {}\n+\n+export class StructVector extends MixinArrowTraits(\n+    StructVectorBase,\n+    class StructVector extends fieldMixin(StructVectorBase) {} as any,\n+    class StructVector extends nullableMixin(StructVectorBase) {} as any,\n+    class StructVector extends nullableMixin(fieldMixin(StructVectorBase)) {} as any\n+) {}\n+\n+export class DecimalVector extends MixinArrowTraits(\n+    DecimalVectorBase,\n+    class DecimalVector extends fieldMixin(DecimalVectorBase) {} as any,\n+    class DecimalVector extends nullableMixin(DecimalVectorBase) {} as any,\n+    class DecimalVector extends nullableMixin(fieldMixin(DecimalVectorBase)) {} as any\n+) {}\n+\n+export class TimestampVector extends MixinArrowTraits(\n+    TimestampVectorBase,\n+    class TimestampVector extends fieldMixin(TimestampVectorBase) {} as any,\n+    class TimestampVector extends nullableMixin(TimestampVectorBase) {} as any,\n+    class TimestampVector extends nullableMixin(fieldMixin(TimestampVectorBase)) {} as any\n+) {}\n+\n+export class DictionaryVector extends MixinArrowTraits(\n+    DictionaryVectorBase,\n+    class DictionaryVector extends fieldMixin(DictionaryVectorBase) {} as any,\n+    class DictionaryVector extends nullableMixin(DictionaryVectorBase) {} as any,\n+    class DictionaryVector extends nullableMixin(fieldMixin(DictionaryVectorBase)) {} as any\n+) {}\n+\n+export class FixedSizeListVector extends MixinArrowTraits(\n+    FixedSizeListVectorBase,\n+    class FixedSizeListVector extends fieldMixin(FixedSizeListVectorBase) {} as any,\n+    class FixedSizeListVector extends nullableMixin(FixedSizeListVectorBase) {} as any,\n+    class FixedSizeListVector extends nullableMixin(fieldMixin(FixedSizeListVectorBase)) {} as any\n+) {}\ndiff --git a/js/src/types/dictionary.ts b/js/src/vector/dictionary.ts\nsimilarity index 62%\nrename from js/src/types/dictionary.ts\nrename to js/src/vector/dictionary.ts\nindex cafa75331..b7375c090 100644\n--- a/js/src/types/dictionary.ts\n+++ b/js/src/vector/dictionary.ts\n@@ -15,28 +15,19 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { Vector, Column } from './types';\n-import { VirtualVector } from './vector/virtual';\n+import { Vector } from './vector';\n+import { VirtualVector } from './virtual';\n \n-export interface DictionaryVector<T> extends Vector<T> {\n-    getValue(key: number): T;\n-    getKey(index: number): number;\n-}\n-\n-export class DictionaryVector<T> extends Vector<T> implements Column<T>, DictionaryVector<T> {\n+export class DictionaryVector<T> extends Vector<T> {\n+    readonly length: number;\n     readonly data: Vector<T>;\n-    readonly keys: Column<number>;\n+    readonly keys: Vector<number>;\n     constructor(argv: { data: Vector<T>, keys: Vector<number> }) {\n         super();\n         this.data = argv.data;\n-        this.keys = argv.keys as Column<number>;\n+        this.keys = argv.keys;\n+        this.length = this.keys.length;\n     }\n-    get name () { return this.keys.name; }\n-    get type () { return this.keys.type; }\n-    get length () { return this.keys.length; }\n-    get metadata () { return this.keys.metadata; }\n-    get nullable () { return this.keys.nullable; }\n-    get nullCount () { return this.keys.nullCount; }\n     get(index: number) {\n         return this.getValue(this.getKey(index)!);\n     }\n@@ -50,9 +41,8 @@ export class DictionaryVector<T> extends Vector<T> implements Column<T>, Diction\n         return new VirtualVector(Array, this, ...vectors);\n     }\n     *[Symbol.iterator]() {\n-        const { data, keys } = this;\n-        for (let i = -1, n = keys.length; ++i < n;) {\n-            yield data.get(keys.get(i)!);\n+        for (let i = -1, n = this.length; ++i < n;) {\n+            yield this.get(i);\n         }\n     }\n }\ndiff --git a/js/src/vector/list.ts b/js/src/vector/list.ts\nnew file mode 100644\nindex 000000000..97913f8d8\n--- /dev/null\n+++ b/js/src/vector/list.ts\n@@ -0,0 +1,74 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import { List } from './types';\n+import { Vector } from './vector';\n+import { VirtualVector } from './virtual';\n+\n+export class BinaryVector extends Vector<Uint8Array> {\n+    readonly data: Uint8Array;\n+    readonly offsets: Int32Array;\n+    constructor(argv: { offsets: Int32Array, data: Uint8Array }) {\n+        super();\n+        this.data = argv.data;\n+        this.offsets = argv.offsets;\n+    }\n+    get(index: number) {\n+        return this.data.subarray(this.offsets[index], this.offsets[index + 1]);\n+    }\n+    concat(...vectors: Vector<Uint8Array>[]): Vector<Uint8Array> {\n+        return new VirtualVector(Array, this, ...vectors);\n+    }\n+}\n+\n+export class ListVector<T> extends Vector<T[]> {\n+    readonly offsets: Int32Array;\n+    readonly values: Vector<T>;\n+    constructor(argv: { offsets: Int32Array, values: Vector<T> }) {\n+        super();\n+        this.values = argv.values;\n+        this.offsets = argv.offsets;\n+    }\n+    get(index: number) {\n+        const { offsets, values } = this;\n+        const from = offsets[index];\n+        const xs = new Array(offsets[index + 1] - from);\n+        for (let i = -1, n = xs.length; ++i < n;) {\n+            xs[i] = values.get(i + from);\n+        }\n+        return xs;\n+    }\n+    concat(...vectors: Vector<T[]>[]): Vector<T[]> {\n+        return new VirtualVector(Array, this, ...vectors);\n+    }\n+}\n+\n+export class FixedSizeListVector<T, TArray extends List<T>> extends Vector<TArray> {\n+    readonly size: number;\n+    readonly values: Vector<T>;\n+    constructor(argv: { size: number, values: Vector<T> }) {\n+        super();\n+        this.size = argv.size;\n+        this.values = argv.values;\n+    }\n+    get(index: number) {\n+        return this.values.slice<TArray>(this.size * index, this.size * (index + 1));\n+    }\n+    concat(...vectors: Vector<TArray>[]): Vector<TArray> {\n+        return new VirtualVector(Array, this, ...vectors);\n+    }\n+}\ndiff --git a/js/src/vector/numeric.ts b/js/src/vector/numeric.ts\nnew file mode 100644\nindex 000000000..fe4767809\n--- /dev/null\n+++ b/js/src/vector/numeric.ts\n@@ -0,0 +1,168 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import { Vector } from './vector';\n+import { VirtualVector } from './virtual';\n+import { TypedArray, TypedArrayConstructor } from './types';\n+\n+export class NumericVector<T, TArray extends TypedArray> extends Vector<T> {\n+    readonly data: TArray;\n+    readonly length: number;\n+    readonly stride: number;\n+    constructor(argv: { data: TArray }) {\n+        super();\n+        const data = (ArrayBuffer.isView(argv) ? argv : argv.data) as TArray;\n+        this.length = ((this.data = data).length / this.stride) | 0;\n+    }\n+    get(index: number) {\n+        return this.data[index] as any;\n+    }\n+    concat(...vectors: Vector<T>[]): Vector<T> {\n+        return new VirtualVector(this.data.constructor as TypedArrayConstructor, this, ...vectors);\n+    }\n+    slice(start?: number, end?: number) {\n+        const { data, stride } = this, from = start! | 0;\n+        const to = end === undefined ? data.length : Math.max(end | 0, from);\n+        return data.subarray(Math.min(from, to) * stride | 0, to * stride | 0);\n+    }\n+}\n+\n+export class FixedWidthNumericVector<T, TArray extends TypedArray> extends NumericVector<T, TArray> {\n+    get(index: number) {\n+        return this.data.slice(this.stride * index, this.stride * (index + 1)) as TArray;\n+    }\n+}\n+\n+export class BoolVector extends NumericVector<boolean, Uint8Array> {\n+    static pack(values: Iterable<any>) {\n+        let xs = [], n, i = 0;\n+        let bit = 0, byte = 0;\n+        for (const value of values) {\n+            value && (byte |= 1 << bit);\n+            if (++bit === 8) {\n+                xs[i++] = byte;\n+                byte = bit = 0;\n+            }\n+        }\n+        if (i === 0 || bit > 0) { xs[i++] = byte; }\n+        if (i % 8 && (n = i + 8 - i % 8)) {\n+            do { xs[i] = 0; } while (++i < n);\n+        }\n+        return new Uint8Array(xs);\n+    }\n+    get(index: number) {\n+        return (this.data[index >> 3] & 1 << index % 8) !== 0;\n+    }\n+    set(index: number, value: boolean) {\n+        if (index > -1 === false) {\n+            return;\n+        } else if (value) {\n+            this.data[index >> 3] |=  (1 << (index % 8));\n+        } else {\n+            this.data[index >> 3] &= ~(1 << (index % 8));\n+        }\n+    }\n+}\n+\n+export class Int8Vector extends NumericVector<number, Int8Array> {}\n+export class Int16Vector extends NumericVector<number, Int16Array> {}\n+export class Int32Vector extends NumericVector<number, Int32Array> {}\n+export class Int64Vector extends FixedWidthNumericVector<number, Int32Array> {}\n+\n+export class Uint8Vector extends NumericVector<number, Uint8Array> {}\n+export class Uint16Vector extends NumericVector<number, Uint16Array> {}\n+export class Uint32Vector extends NumericVector<number, Uint32Array> {}\n+export class Uint64Vector extends FixedWidthNumericVector<number, Uint32Array> {}\n+\n+export class Float16Vector extends NumericVector<number, Uint16Array> {\n+    get(index: number) {\n+        return Math.min((super.get(index)! -  32767) / 32767, 1);\n+    }\n+}\n+\n+export class Float32Vector extends NumericVector<number, Float32Array> {}\n+export class Float64Vector extends NumericVector<number, Float64Array> {}\n+\n+export class Date32Vector extends NumericVector<Date, Int32Array> {\n+    public readonly unit: string;\n+    constructor(argv: { data: Int32Array, unit: string }) {\n+        super(argv);\n+        this.unit = argv.unit;\n+    }\n+    get(index: number): Date {\n+        return new Date(86400000 * (super.get(index) as any));\n+    }\n+}\n+\n+export class Date64Vector extends NumericVector<Date, Int32Array> {\n+    public readonly unit: string;\n+    constructor(argv: { unit: string, data: Int32Array }) {\n+        super(argv);\n+        this.unit = argv.unit;\n+    }\n+    get(index: number): Date {\n+        return new Date(4294967296   * /* 2^32 */\n+            (super.get(index * 2 + 1) as any) + /* high */\n+            (super.get(index * 2) as any)       /*  low */\n+        );\n+    }\n+}\n+\n+export class Time32Vector extends NumericVector<number, Int32Array> {\n+    public readonly unit: string;\n+    constructor(argv: { data: Int32Array, unit: string }) {\n+        super(argv);\n+        this.unit = argv.unit;\n+    }\n+}\n+\n+export class Time64Vector extends FixedWidthNumericVector<number, Uint32Array> {\n+    public readonly unit: string;\n+    constructor(argv: { unit: string, data: Uint32Array }) {\n+        super(argv);\n+        this.unit = argv.unit;\n+    }\n+}\n+\n+export class DecimalVector extends FixedWidthNumericVector<number, Uint32Array> {\n+    readonly scale: number;\n+    readonly precision: number;\n+    constructor(argv: { precision: number, scale: number, data: Uint32Array }) {\n+        super(argv);\n+        this.scale = argv.scale;\n+        this.precision = argv.precision;\n+    }\n+}\n+\n+export class TimestampVector extends FixedWidthNumericVector<number, Uint32Array> {\n+    readonly unit: string;\n+    readonly timezone: string;\n+    constructor(argv: { unit: string, timezone: string, data: Uint32Array }) {\n+        super(argv);\n+        this.unit = argv.unit;\n+        this.timezone = argv.timezone;\n+    }\n+}\n+\n+export interface NumericVectorConstructor<T, TArray extends TypedArray> {\n+    readonly prototype: NumericVector<T, TArray>;\n+    new (argv: { data: TArray }): NumericVector<T, TArray>;\n+}\n+\n+(DecimalVector.prototype as any).stride = 4;\n+(NumericVector.prototype as any).stride = 1;\n+(FixedWidthNumericVector.prototype as any).stride = 2;\ndiff --git a/js/src/vector/struct.ts b/js/src/vector/struct.ts\nnew file mode 100644\nindex 000000000..c43f6efc4\n--- /dev/null\n+++ b/js/src/vector/struct.ts\n@@ -0,0 +1,127 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import { Vector } from './vector';\n+import { VirtualVector } from './virtual';\n+\n+export class StructVector<T = any> extends Vector<StructRow<T>> {\n+    readonly length: number;\n+    readonly columns: Vector[];\n+    constructor(argv: { columns: Vector[] }) {\n+        super();\n+        this.columns = argv.columns || [];\n+    }\n+    get(index: number): StructRow<T> {\n+        return new StructRow(this, index);\n+    }\n+    col(name: string) {\n+        return this.columns.find((col) => col.name === name) || null;\n+    }\n+    key(index: number) {\n+        return this.columns[index] ? this.columns[index].name : null;\n+    }\n+    select(...columns: string[]) {\n+        return new StructVector({ columns: columns.map((name) => this.col(name)!) });\n+    }\n+    concat(...structs: Vector<StructRow<T>>[]): Vector<StructRow<T>> {\n+        return new VirtualVector(Array, this, ...structs as any[]);\n+    }\n+    toString(options?: any) {\n+        const index = typeof options === 'object' ? options && !!options.index\n+                    : typeof options === 'boolean' ? !!options\n+                    : false;\n+        const { length } = this;\n+        if (length <= 0) { return ''; }\n+        const rows = new Array(length + 1);\n+        const maxColumnWidths = [] as number[];\n+        rows[0] = this.columns.map((_, i) => this.key(i));\n+        index && rows[0].unshift('Index');\n+        for (let i = -1, n = rows.length - 1; ++i < n;) {\n+            rows[i + 1] = [...this.get(i)!];\n+            index && rows[i + 1].unshift(i);\n+        }\n+        // Pass one to convert to strings and count max column widths\n+        for (let i = -1, n = rows.length; ++i < n;) {\n+            const row = rows[i];\n+            for (let j = -1, k = row.length; ++j < k;) {\n+                const val = row[j] = stringify(row[j]);\n+                maxColumnWidths[j] = !maxColumnWidths[j]\n+                    ? val.length\n+                    : Math.max(maxColumnWidths[j], val.length);\n+            }\n+        }\n+        // Pass two to pad each one to max column width\n+        for (let i = -1, n = rows.length; ++i < n;) {\n+            const row = rows[i];\n+            for (let j = -1, k = row.length; ++j < k;) {\n+                row[j] = leftPad(row[j], ' ', maxColumnWidths[j]);\n+            }\n+            rows[i] = row.join(', ');\n+        }\n+        return rows.join('\\n');\n+    }\n+}\n+\n+export class StructRow<T = any> extends Vector<T> {\n+    readonly row: number;\n+    readonly length: number;\n+    readonly table: StructVector<T>;\n+    [Symbol.toStringTag]() { return 'Row'; }\n+    constructor(table: StructVector<T>, row: number) {\n+        super();\n+        this.row = row;\n+        this.table = table;\n+        this.length = table.columns.length;\n+    }\n+    get(index: number) {\n+        const col = this.table.columns[index];\n+        return col ? col.get(this.row) as T : null;\n+    }\n+    col(key: string) {\n+        const col = this.table.col(key);\n+        return col ? col.get(this.row) as T : null;\n+    }\n+    *[Symbol.iterator]() {\n+        const { row } = this;\n+        for (const col of this.table.columns) {\n+            yield col ? col.get(row) : null;\n+        }\n+    }\n+    concat(...rows: Vector<T>[]): Vector<T> {\n+        return new VirtualVector(Array, this, ...rows as any[]);\n+    }\n+    toArray() { return [...this]; }\n+    toJSON() { return this.toArray(); }\n+    toString() { return JSON.stringify(this); }\n+    toObject(): Record<string, T> {\n+        const { row } = this, map = Object.create(null);\n+        for (const col of this.table.columns) {\n+            if (col && col.name) {\n+                map[col.name] = col.get(row);\n+            }\n+        }\n+        return map;\n+    }\n+}\n+\n+function leftPad(str: string, fill: string, n: number) {\n+    return (new Array(n + 1).join(fill) + str).slice(-1 * n);\n+}\n+\n+function stringify(x: any) {\n+    return Array.isArray(x) ? JSON.stringify(x) : ArrayBuffer.isView(x) ? `[${x}]` : `${x}`;\n+}\ndiff --git a/js/src/vector/table.ts b/js/src/vector/table.ts\nnew file mode 100644\nindex 000000000..b15092a72\n--- /dev/null\n+++ b/js/src/vector/table.ts\n@@ -0,0 +1,59 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import { Vector } from './vector';\n+import { StructVector, StructRow } from './struct';\n+import { readVectors, readVectorsAsync } from '../reader/arrow';\n+\n+export class Table<T> extends StructVector<T> {\n+    static from(buffers?: Iterable<Uint8Array | Buffer | string>) {\n+        let columns: Vector<any>[] = [];\n+        if (buffers) {\n+            for (let vectors of readVectors(buffers)) {\n+                columns = columns.length === 0 ? vectors : vectors.map((vec, i, _vs, col = columns[i]) =>\n+                    vec && col && col.concat(vec) || col || vec\n+                ) as Vector<any>[];\n+            }\n+        }\n+        return new Table({ columns });\n+    }\n+    static async fromAsync(buffers?: AsyncIterable<Uint8Array | Buffer | string>) {\n+        let columns: Vector<any>[] = [];\n+        if (buffers) {\n+            for await (let vectors of readVectorsAsync(buffers)) {\n+                columns = columns.length === 0 ? vectors : vectors.map((vec, i, _vs, col = columns[i]) =>\n+                    vec && col && col.concat(vec) || col || vec\n+                ) as Vector<any>[];\n+            }\n+        }\n+        return new Table({ columns });\n+    }\n+    readonly length: number;\n+    constructor(argv: { columns: Vector<any>[] }) {\n+        super(argv);\n+        this.length = Math.max(...this.columns.map((col) => col.length)) | 0;\n+    }\n+    get(index: number): TableRow<T> {\n+        return new TableRow(this, index);\n+    }\n+}\n+\n+export class TableRow<T> extends StructRow<T> {\n+    toString() {\n+        return this.toArray().map((x) => JSON.stringify(x)).join(', ');\n+    }\n+}\ndiff --git a/js/src/types/vector/traits.ts b/js/src/vector/traits.ts\nsimilarity index 88%\nrename from js/src/types/vector/traits.ts\nrename to js/src/vector/traits.ts\nindex 872c40b64..ca933f160 100644\n--- a/js/src/types/vector/traits.ts\n+++ b/js/src/vector/traits.ts\n@@ -15,10 +15,10 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { BoolVector } from './bool';\n-import { Vector, Column } from '../types';\n-import * as Schema_ from '../../format/Schema_generated';\n-import * as Message_ from '../../format/Message_generated';\n+import { Vector } from './vector';\n+import { BoolVector } from './numeric';\n+import * as Schema_ from '../format/Schema';\n+import * as Message_ from '../format/Message';\n import Type = Schema_.org.apache.arrow.flatbuf.Type;\n import Field = Schema_.org.apache.arrow.flatbuf.Field;\n import FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\n@@ -38,7 +38,7 @@ export const nullableMixin = <T extends Vector, TArgv>(superclass: new (argv: TA\n     };\n \n export const fieldMixin = <T extends Vector, TArgv>(superclass: new (argv: TArgv) => T) =>\n-    class extends (superclass as Ctor<TArgv>) implements Column {\n+    class extends (superclass as Ctor<TArgv>) implements Vector {\n         readonly field: Field;\n         readonly type: string;\n         readonly length: number;\n@@ -53,8 +53,8 @@ export const fieldMixin = <T extends Vector, TArgv>(superclass: new (argv: TArgv\n             this.fieldNode = fieldNode;\n             this.nullable = field.nullable();\n             this.type = Type[field.typeType()];\n+            this.length = fieldNode.length().low | 0;\n             this.nullCount = fieldNode.nullCount().low;\n-            this.length = (fieldNode.length().low / this.stride) | 0;\n         }\n         get name() { return this.field.name()!; }\n         get metadata()  {\ndiff --git a/js/src/vector/types.ts b/js/src/vector/types.ts\nnew file mode 100644\nindex 000000000..363fcf226\n--- /dev/null\n+++ b/js/src/vector/types.ts\n@@ -0,0 +1,43 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+export interface TypedArrayConstructor<T extends TypedArray = TypedArray> {\n+    readonly prototype: T;\n+    readonly BYTES_PER_ELEMENT: number;\n+    new (length: number): T;\n+    new (elements: Iterable<number>): T;\n+    new (arrayOrArrayBuffer: ArrayLike<number> | ArrayBufferLike): T;\n+    new (buffer: ArrayBufferLike, byteOffset: number, length?: number): T;\n+}\n+\n+export interface TypedArray extends Iterable<number> {\n+    [index: number]: number;\n+    readonly length: number;\n+    readonly byteLength: number;\n+    readonly byteOffset: number;\n+    readonly buffer: ArrayBufferLike;\n+    readonly BYTES_PER_ELEMENT: number;\n+    [Symbol.iterator](): IterableIterator<number>;\n+    slice(start?: number, end?: number): TypedArray;\n+    subarray(begin: number, end?: number): TypedArray;\n+    set(array: ArrayLike<number>, offset?: number): void;\n+}\n+\n+export type List<T> = T[] | TypedArray;\n+export type FloatArray = Float32Array | Float64Array;\n+export type IntArray = Int8Array | Int16Array | Int32Array;\n+export type UintArray = Uint8ClampedArray | Uint8Array | Uint16Array | Uint32Array;\ndiff --git a/js/src/types/utf8.ts b/js/src/vector/utf8.ts\nsimilarity index 94%\nrename from js/src/types/utf8.ts\nrename to js/src/vector/utf8.ts\nindex 178704f61..ba875cf33 100644\n--- a/js/src/types/utf8.ts\n+++ b/js/src/vector/utf8.ts\n@@ -15,9 +15,9 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { Vector } from './types';\n+import { Vector } from './vector';\n+import { VirtualVector } from './virtual';\n import { TextDecoder } from 'text-encoding-utf-8';\n-import { VirtualVector } from './vector/virtual';\n \n const decoder = new TextDecoder('utf-8');\n \ndiff --git a/js/src/types/types.ts b/js/src/vector/vector.ts\nsimilarity index 56%\nrename from js/src/types/types.ts\nrename to js/src/vector/vector.ts\nindex f732bc097..8047c8992 100644\n--- a/js/src/types/types.ts\n+++ b/js/src/vector/vector.ts\n@@ -15,64 +15,20 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import * as Schema_ from '../format/Schema_generated';\n+import * as Schema_ from '../format/Schema';\n import Type = Schema_.org.apache.arrow.flatbuf.Type;\n \n-export interface TypedArrayConstructor<T extends TypedArray = TypedArray> {\n-    readonly prototype: T;\n-    readonly BYTES_PER_ELEMENT: number;\n-    new (length: number): T;\n-    new (elements: Iterable<number>): T;\n-    new (arrayOrArrayBuffer: ArrayLike<number> | ArrayBufferLike): T;\n-    new (buffer: ArrayBufferLike, byteOffset: number, length?: number): T;\n-}\n-\n-export interface TypedArray extends Iterable<number> {\n-    [index: number]: number;\n-    readonly length: number;\n-    readonly byteLength: number;\n-    readonly byteOffset: number;\n-    readonly buffer: ArrayBufferLike;\n-    readonly BYTES_PER_ELEMENT: number;\n-    [Symbol.iterator](): IterableIterator<number>;\n-    slice(start?: number, end?: number): TypedArray;\n-    subarray(begin: number, end?: number): TypedArray;\n-    set(array: ArrayLike<number>, offset?: number): void;\n-}\n-\n-export type FloatArray = Float32Array | Float64Array;\n-export type IntArray = Int8Array | Int16Array | Int32Array;\n-export type UintArray = Uint8ClampedArray | Uint8Array | Uint16Array | Uint32Array;\n-\n-export type List<T> = T[] | TypedArray;\n-\n export interface Vector<T = any> extends Iterable<T | null> {\n-    readonly length: number;\n-    get(index: number): T | null;\n-    concat(...vectors: Vector<T>[]): Vector<T>;\n-    slice<R = T[]>(start?: number, end?: number): R;\n-}\n-\n-export interface Row<T = any> extends Vector<T> {\n-    col(key: string): T | null;\n-}\n-\n-export interface Column<T = any> extends Vector<T> {\n     readonly name: string;\n     readonly type: string;\n+    readonly length: number;\n     readonly nullable: boolean;\n     readonly nullCount: number;\n     readonly metadata: Map<string, string>;\n+    get(index: number): T | null;\n+    concat(...vectors: Vector<T>[]): Vector<T>;\n+    slice<R = T[]>(start?: number, end?: number): R;\n }\n-\n-export interface Struct<T = any> extends Vector<Row<T>> {\n-    readonly columns: Column[];\n-    key(key: number): string | null;\n-    col(key: string): Column | null;\n-    select(...columns: string[]): Struct<T>;\n-    concat(...structs: Vector<Row<T>>[]): Vector<Row<T>>;\n-}\n-\n export class Vector<T = any> implements Vector<T> {\n     slice<R = T[]>(start?: number, end?: number): R {\n         let { length } = this, from = start! | 0;\n@@ -91,8 +47,8 @@ export class Vector<T = any> implements Vector<T> {\n }\n \n (Vector.prototype as any).name = '';\n-(Vector.prototype as any).type = Type[0];\n (Vector.prototype as any).stride = 1;\n (Vector.prototype as any).nullable = !1;\n (Vector.prototype as any).nullCount = 0;\n (Vector.prototype as any).metadata = new Map();\n+(Vector.prototype as any).type = Type[Type.NONE];\ndiff --git a/js/src/vector/virtual.ts b/js/src/vector/virtual.ts\nnew file mode 100644\nindex 000000000..6ec3a8eef\n--- /dev/null\n+++ b/js/src/vector/virtual.ts\n@@ -0,0 +1,129 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import { Vector } from './vector';\n+import { NumericVector } from './numeric';\n+import { TypedArray, TypedArrayConstructor } from './types';\n+\n+export class VirtualVector<T> implements Vector<T> {\n+    readonly name: string;\n+    readonly type: string;\n+    readonly length: number;\n+    readonly vectors: Vector<T>[];\n+    readonly offsets: Uint32Array;\n+    readonly ArrayType: ArrayConstructor | TypedArrayConstructor;\n+    constructor(ArrayType: ArrayConstructor | TypedArrayConstructor, ...vectors: Vector<T>[]) {\n+        this.vectors = vectors;\n+        this.ArrayType = ArrayType;\n+        this.name = (vectors[0] as any).name;\n+        this.type = (vectors[0] as any).type;\n+        this.length = vectors.reduce((sum, vec) => sum + vec.length, 0);\n+        this.offsets = Uint32Array.from(vectors.reduce((sums, vector, index) => [...sums, vector.length + sums[index]], [0]));\n+    }\n+    *[Symbol.iterator]() {\n+        for (const vector of this.vectors) {\n+            yield* vector;\n+        }\n+    }\n+    get nullable() {\n+        return (this.vectors as Vector<T>[]).some((vec) => vec.nullable);\n+    }\n+    get nullCount() {\n+        return (this.vectors as Vector<T>[]).reduce((sum, v) => sum + v.nullCount | 0, 0);\n+    }\n+    get metadata() {\n+        return new Map<string, string>(\n+            (this.vectors as Vector<T>[]).reduce((entries, v) => [\n+                ...entries, ...v.metadata.entries()\n+            ], [] as [string, string][])\n+        );\n+    }\n+    get(index: number) {\n+        // find the vector index and adjusted value offset (inlined)\n+        let offsets = this.offsets, offset = 0;\n+        let left = 0, middle = 0, right = offsets.length - 1;\n+        while (index < offsets[right] && index >= (offset = offsets[left])) {\n+            if (left + 1 === right) {\n+                return this.vectors[left].get(index - offset);\n+            }\n+            middle = left + ((right - left) / 2) | 0;\n+            index >= offsets[middle] ? (left = middle) : (right = middle);\n+        }\n+        return null;\n+    }\n+    concat(...vectors: Vector<T>[]) {\n+        return new VirtualVector(this.ArrayType, ...this.vectors, ...vectors);\n+    }\n+    slice(begin?: number, end?: number) {\n+\n+        // clamp begin and end values between the virtual length (inlined)\n+        // let [from, total] = clampRange(this.length, begin!, end);\n+        let total = this.length, from = begin! | 0;\n+        let to = end === end && typeof end == 'number' ? end : total;\n+        if (to < 0) { to = total + to; }\n+        if (from < 0) { from = total - (from * -1) % total; }\n+        if (to < from) { from = to; to = begin! | 0; }\n+        total = !isFinite(total = (to - from)) || total < 0 ? 0 : total;\n+\n+        // find the vector index and adjusted value offset (inlined)\n+        let offsets = this.offsets, ArrayType = this.ArrayType as any;\n+        let offset = 0, index = 0, middle = 0, right = offsets.length - 1;\n+        while (from < offsets[right] && from >= (offset = offsets[index])) {\n+            if (index + 1 === right) {\n+                from -= offset;\n+                let set = ArrayType === Array ? arraySet : typedArraySet as any;\n+                let vectors = this.vectors as any as NumericVector<T, TypedArray>[];\n+                let vector = vectors[index], source = vector.slice(from, from + total), target = source;\n+                // Perf optimization: if the first slice contains all the values we're looking for,\n+                // we don't have to copy values to a target Array. If we're slicing a TypedArray,\n+                // this is a significant improvement as we avoid the memcpy \ud83c\udf89\n+                if ((source.length / vector.stride | 0) < total) {\n+                    let vectorsLength = vectors.length;\n+                    let count = 0, length = 0, sources = [];\n+                    do {\n+                        sources.push(source);\n+                        length += source.length;\n+                        count += (source.length / vector.stride | 0);\n+                    } while (\n+                        (count  < total) &&\n+                        (vector = vectors[index = (++index % vectorsLength)]) &&\n+                        (source = vector.slice(0, Math.min(vector.length, total - count)))\n+                    );\n+                    target = new ArrayType(length);\n+                    for (let i = -1, j = 0, n = sources.length; ++i < n;) {\n+                        j = set(sources[i], target, j);\n+                    }\n+                }\n+                return target;\n+            }\n+            middle = index + ((right - index) / 2) | 0;\n+            from >= offsets[middle] ? (index = middle) : (right = middle);\n+        }\n+        return new ArrayType(0);\n+    }\n+}\n+\n+function arraySet<T>(source: T[], target: T[], index: number) {\n+    for (let i = 0, n = source.length; i < n;) {\n+        target[index++] = source[i++];\n+    }\n+    return index;\n+}\n+\n+function typedArraySet(source: TypedArray, target: TypedArray, index: number) {\n+    return target.set(source, index) || index + source.length;\n+}\ndiff --git a/js/test/Arrow.ts b/js/test/Arrow.ts\nindex 722781db6..66a5c21ac 100644\n--- a/js/test/Arrow.ts\n+++ b/js/test/Arrow.ts\n@@ -21,6 +21,7 @@\n const path = require('path');\n const target = process.env.TEST_TARGET!;\n const format = process.env.TEST_MODULE!;\n+const useSrc = process.env.TEST_TS_SOURCE === `true`;\n \n // these are duplicated in the gulpfile :<\n const targets = [`es5`, `es2015`, `esnext`];\n@@ -32,55 +33,17 @@ function throwInvalidImportError(name: string, value: string, values: string[])\n \n let modulePath = ``;\n \n-if (target === `ts` || target === `apache-arrow`) modulePath = target;\n+if (useSrc) modulePath = '../src';\n+else if (target === `ts` || target === `apache-arrow`) modulePath = target;\n else if (!~targets.indexOf(target)) throwInvalidImportError('target', target, targets);\n else if (!~formats.indexOf(format)) throwInvalidImportError('module', format, formats);\n else modulePath = path.join(target, format);\n \n-let Arrow: any = require(path.resolve(`./targets`, modulePath, `Arrow`));\n+export { List } from '../src/Arrow';\n+export { TypedArray } from '../src/Arrow';\n+export { TypedArrayConstructor } from '../src/Arrow';\n+export { NumericVectorConstructor } from '../src/Arrow';\n \n-import {\n-    Table as Table_,\n-    Vector as Vector_,\n-    readBuffers as readBuffers_,\n-    BoolVector as BoolVector_,\n-    TypedVector as TypedVector_,\n-    ListVector as ListVector_,\n-    Utf8Vector as Utf8Vector_,\n-    DateVector as DateVector_,\n-    Int8Vector as Int8Vector_,\n-    Int16Vector as Int16Vector_,\n-    Int32Vector as Int32Vector_,\n-    Int64Vector as Int64Vector_,\n-    Uint8Vector as Uint8Vector_,\n-    Uint16Vector as Uint16Vector_,\n-    Uint32Vector as Uint32Vector_,\n-    Uint64Vector as Uint64Vector_,\n-    Float32Vector as Float32Vector_,\n-    Float64Vector as Float64Vector_,\n-    StructVector as StructVector_,\n-    DictionaryVector as DictionaryVector_,\n-    FixedSizeListVector as FixedSizeListVector_,\n-} from '../src/Arrow';\n-\n-export let Table = Arrow.Table as typeof Table_;\n-export let Vector = Arrow.Vector as typeof Vector_;\n-export let readBuffers = Arrow.readBuffers as typeof readBuffers_;\n-export let BoolVector = Arrow.BoolVector as typeof BoolVector_;\n-export let TypedVector = Arrow.TypedVector as typeof TypedVector_;\n-export let ListVector = Arrow.ListVector as typeof ListVector_;\n-export let Utf8Vector = Arrow.Utf8Vector as typeof Utf8Vector_;\n-export let DateVector = Arrow.DateVector as typeof DateVector_;\n-export let Int8Vector = Arrow.Int8Vector as typeof Int8Vector_;\n-export let Int16Vector = Arrow.Int16Vector as typeof Int16Vector_;\n-export let Int32Vector = Arrow.Int32Vector as typeof Int32Vector_;\n-export let Int64Vector = Arrow.Int64Vector as typeof Int64Vector_;\n-export let Uint8Vector = Arrow.Uint8Vector as typeof Uint8Vector_;\n-export let Uint16Vector = Arrow.Uint16Vector as typeof Uint16Vector_;\n-export let Uint32Vector = Arrow.Uint32Vector as typeof Uint32Vector_;\n-export let Uint64Vector = Arrow.Uint64Vector as typeof Uint64Vector_;\n-export let Float32Vector = Arrow.Float32Vector as typeof Float32Vector_;\n-export let Float64Vector = Arrow.Float64Vector as typeof Float64Vector_;\n-export let StructVector = Arrow.StructVector as typeof StructVector_;\n-export let DictionaryVector = Arrow.DictionaryVector as typeof DictionaryVector_;\n-export let FixedSizeListVector = Arrow.FixedSizeListVector as typeof FixedSizeListVector_;\n+import * as Arrow_ from '../src/Arrow';\n+export let Arrow: typeof Arrow_ = require(path.resolve(`./targets`, modulePath, `Arrow`));\n+export default Arrow;\n\\ No newline at end of file\ndiff --git a/js/test/__snapshots__/reader-tests.ts.snap b/js/test/__snapshots__/reader-tests.ts.snap\ndeleted file mode 100644\nindex 961ce8786..000000000\n--- a/js/test/__snapshots__/reader-tests.ts.snap\n+++ /dev/null\n@@ -1,497 +0,0 @@\n-// Jest Snapshot v1, https://goo.gl/fbAQLP\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"example-csv\"`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Struct_\"`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `2`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `\n-Array [\n-  \"Hermione\",\n-  25,\n-  Float32Array [\n-    -53.235599517822266,\n-    40.231998443603516,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `\n-Array [\n-  \"Severus\",\n-  30,\n-  Float32Array [\n-    -62.22999954223633,\n-    3,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `\"example-csv\"`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `\"Struct_\"`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `1`;\n-\n-exports[`dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 9`] = `\n-Array [\n-  \"Harry\",\n-  20,\n-  Float32Array [\n-    23,\n-    -100.23652648925781,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"example-csv\"`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Struct_\"`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `2`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `\n-Array [\n-  \"Hermione\",\n-  25,\n-  Float32Array [\n-    -53.235599517822266,\n-    40.231998443603516,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `\n-Array [\n-  \"Severus\",\n-  30,\n-  Float32Array [\n-    -62.22999954223633,\n-    3,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `\"example-csv\"`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `\"Struct_\"`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `1`;\n-\n-exports[`dictionary stream Arrow readBuffers enumerates each batch as an Array of Vectors 9`] = `\n-Array [\n-  \"Harry\",\n-  20,\n-  Float32Array [\n-    23,\n-    -100.23652648925781,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary2 file Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"struct\"`;\n-\n-exports[`dictionary2 file Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Struct_\"`;\n-\n-exports[`dictionary2 file Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `2`;\n-\n-exports[`dictionary2 file Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `\n-Array [\n-  \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-  \"Airbus\",\n-  1502880750,\n-  Float32Array [\n-    32.45663833618164,\n-    1.8712350130081177,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary2 file Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `\n-Array [\n-  \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-  \"Boeing\",\n-  1502880750,\n-  Float32Array [\n-    38.766666412353516,\n-    -4.181231498718262,\n-  ],\n-]\n-`;\n-\n-exports[`multi_dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"struct\"`;\n-\n-exports[`multi_dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Struct_\"`;\n-\n-exports[`multi_dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `2`;\n-\n-exports[`multi_dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `\n-Array [\n-  \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-  \"12345\",\n-  \"Airbus\",\n-  1502880750,\n-  Float32Array [\n-    32.45663833618164,\n-    1.8712350130081177,\n-  ],\n-]\n-`;\n-\n-exports[`multi_dictionary file Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `\n-Array [\n-  \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-  \"67890\",\n-  \"Boeing\",\n-  1502880750,\n-  Float32Array [\n-    38.766666412353516,\n-    -4.181231498718262,\n-  ],\n-]\n-`;\n-\n-exports[`multipart count Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"row_count\"`;\n-\n-exports[`multipart count Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Int\"`;\n-\n-exports[`multipart count Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `1`;\n-\n-exports[`multipart count Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `10000`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"origin_lat\"`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"FloatingPoint\"`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `5`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `35.393089294433594`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `35.393089294433594`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `35.393089294433594`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `29.533695220947266`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `29.533695220947266`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 9`] = `\"origin_lon\"`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 10`] = `\"FloatingPoint\"`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 11`] = `5`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 12`] = `-97.6007308959961`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 13`] = `-97.6007308959961`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 14`] = `-97.6007308959961`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 15`] = `-98.46977996826172`;\n-\n-exports[`multipart latlong Arrow readBuffers enumerates each batch as an Array of Vectors 16`] = `-98.46977996826172`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"origin_city\"`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Utf8\"`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `5`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `\"Oklahoma City\"`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `\"Oklahoma City\"`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `\"Oklahoma City\"`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `\"San Antonio\"`;\n-\n-exports[`multipart origins Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `\"San Antonio\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"foo\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Int\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `5`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `1`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `null`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `3`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `4`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `5`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 9`] = `\"bar\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 10`] = `\"FloatingPoint\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 11`] = `5`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 12`] = `1`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 13`] = `null`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 14`] = `null`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 15`] = `4`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 16`] = `5`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 17`] = `\"baz\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 18`] = `\"Utf8\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 19`] = `5`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 20`] = `\"aa\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 21`] = `null`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 22`] = `null`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 23`] = `\"bbb\"`;\n-\n-exports[`simple file Arrow readBuffers enumerates each batch as an Array of Vectors 24`] = `\"cccc\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"foo\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Int\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `5`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `1`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `null`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `3`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `4`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `5`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 9`] = `\"bar\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 10`] = `\"FloatingPoint\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 11`] = `5`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 12`] = `1`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 13`] = `null`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 14`] = `null`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 15`] = `4`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 16`] = `5`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 17`] = `\"baz\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 18`] = `\"Utf8\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 19`] = `5`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 20`] = `\"aa\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 21`] = `null`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 22`] = `null`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 23`] = `\"bbb\"`;\n-\n-exports[`simple stream Arrow readBuffers enumerates each batch as an Array of Vectors 24`] = `\"cccc\"`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"struct_nullable\"`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Struct_\"`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `7`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `null`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `\n-Array [\n-  null,\n-  \"MhRNxD4\",\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `\n-Array [\n-  137773603,\n-  \"3F9HBxK\",\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `\n-Array [\n-  410361374,\n-  \"aVd88fp\",\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `null`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 9`] = `\n-Array [\n-  null,\n-  \"3loZrRf\",\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 10`] = `null`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 11`] = `\"struct_nullable\"`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 12`] = `\"Struct_\"`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 13`] = `10`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 14`] = `null`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 15`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 16`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 17`] = `null`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 18`] = `\n-Array [\n-  null,\n-  \"78SLiRw\",\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 19`] = `null`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 20`] = `null`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 21`] = `\n-Array [\n-  null,\n-  \"0ilsf82\",\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 22`] = `\n-Array [\n-  null,\n-  \"LjS9MbU\",\n-]\n-`;\n-\n-exports[`struct file Arrow readBuffers enumerates each batch as an Array of Vectors 23`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 1`] = `\"struct_nullable\"`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 2`] = `\"Struct_\"`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 3`] = `7`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 4`] = `null`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 5`] = `\n-Array [\n-  null,\n-  \"MhRNxD4\",\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 6`] = `\n-Array [\n-  137773603,\n-  \"3F9HBxK\",\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 7`] = `\n-Array [\n-  410361374,\n-  \"aVd88fp\",\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 8`] = `null`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 9`] = `\n-Array [\n-  null,\n-  \"3loZrRf\",\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 10`] = `null`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 11`] = `\"struct_nullable\"`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 12`] = `\"Struct_\"`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 13`] = `10`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 14`] = `null`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 15`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 16`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 17`] = `null`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 18`] = `\n-Array [\n-  null,\n-  \"78SLiRw\",\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 19`] = `null`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 20`] = `null`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 21`] = `\n-Array [\n-  null,\n-  \"0ilsf82\",\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 22`] = `\n-Array [\n-  null,\n-  \"LjS9MbU\",\n-]\n-`;\n-\n-exports[`struct stream Arrow readBuffers enumerates each batch as an Array of Vectors 23`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\ndiff --git a/js/test/__snapshots__/table-tests.ts.snap b/js/test/__snapshots__/table-tests.ts.snap\ndeleted file mode 100644\nindex 401b992d9..000000000\n--- a/js/test/__snapshots__/table-tests.ts.snap\n+++ /dev/null\n@@ -1,1815 +0,0 @@\n-// Jest Snapshot v1, https://goo.gl/fbAQLP\n-\n-exports[`dictionary file Arrow Table creates a Table from Arrow buffers 1`] = `\"example-csv\"`;\n-\n-exports[`dictionary file Arrow Table creates a Table from Arrow buffers 2`] = `\"Struct_\"`;\n-\n-exports[`dictionary file Arrow Table creates a Table from Arrow buffers 3`] = `3`;\n-\n-exports[`dictionary file Arrow Table creates a Table from Arrow buffers 4`] = `\n-Array [\n-  \"Hermione\",\n-  25,\n-  Float32Array [\n-    -53.235599517822266,\n-    40.231998443603516,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow Table creates a Table from Arrow buffers 5`] = `\n-Array [\n-  \"Severus\",\n-  30,\n-  Float32Array [\n-    -62.22999954223633,\n-    3,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow Table creates a Table from Arrow buffers 6`] = `\n-Array [\n-  \"Harry\",\n-  20,\n-  Float32Array [\n-    23,\n-    -100.23652648925781,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"example-csv\": Array [\n-    \"Hermione\",\n-    25,\n-    Float32Array [\n-      -53.235599517822266,\n-      40.231998443603516,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary file Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"example-csv\": Array [\n-    \"Severus\",\n-    30,\n-    Float32Array [\n-      -62.22999954223633,\n-      3,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary file Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"example-csv\": Array [\n-    \"Harry\",\n-    20,\n-    Float32Array [\n-      23,\n-      -100.23652648925781,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary file Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  Array [\n-    \"Hermione\",\n-    25,\n-    Float32Array [\n-      -53.235599517822266,\n-      40.231998443603516,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  Array [\n-    \"Severus\",\n-    30,\n-    Float32Array [\n-      -62.22999954223633,\n-      3,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  Array [\n-    \"Harry\",\n-    20,\n-    Float32Array [\n-      23,\n-      -100.23652648925781,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary file Arrow Table toString() prints a pretty Table 1`] = `\n-\"                                                     example-csv\n-[\\\\\"Hermione\\\\\",25,{\\\\\"0\\\\\":-53.235599517822266,\\\\\"1\\\\\":40.231998443603516}]\n-                   [\\\\\"Severus\\\\\",30,{\\\\\"0\\\\\":-62.22999954223633,\\\\\"1\\\\\":3}]\n-                   [\\\\\"Harry\\\\\",20,{\\\\\"0\\\\\":23,\\\\\"1\\\\\":-100.23652648925781}]\"\n-`;\n-\n-exports[`dictionary file Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`dictionary file Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,                                                      example-csv\n-    0, [\\\\\"Hermione\\\\\",25,{\\\\\"0\\\\\":-53.235599517822266,\\\\\"1\\\\\":40.231998443603516}]\n-    1,                    [\\\\\"Severus\\\\\",30,{\\\\\"0\\\\\":-62.22999954223633,\\\\\"1\\\\\":3}]\n-    2,                    [\\\\\"Harry\\\\\",20,{\\\\\"0\\\\\":23,\\\\\"1\\\\\":-100.23652648925781}]\"\n-`;\n-\n-exports[`dictionary stream Arrow Table creates a Table from Arrow buffers 1`] = `\"example-csv\"`;\n-\n-exports[`dictionary stream Arrow Table creates a Table from Arrow buffers 2`] = `\"Struct_\"`;\n-\n-exports[`dictionary stream Arrow Table creates a Table from Arrow buffers 3`] = `3`;\n-\n-exports[`dictionary stream Arrow Table creates a Table from Arrow buffers 4`] = `\n-Array [\n-  \"Hermione\",\n-  25,\n-  Float32Array [\n-    -53.235599517822266,\n-    40.231998443603516,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow Table creates a Table from Arrow buffers 5`] = `\n-Array [\n-  \"Severus\",\n-  30,\n-  Float32Array [\n-    -62.22999954223633,\n-    3,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow Table creates a Table from Arrow buffers 6`] = `\n-Array [\n-  \"Harry\",\n-  20,\n-  Float32Array [\n-    23,\n-    -100.23652648925781,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"example-csv\": Array [\n-    \"Hermione\",\n-    25,\n-    Float32Array [\n-      -53.235599517822266,\n-      40.231998443603516,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary stream Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"example-csv\": Array [\n-    \"Severus\",\n-    30,\n-    Float32Array [\n-      -62.22999954223633,\n-      3,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary stream Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"example-csv\": Array [\n-    \"Harry\",\n-    20,\n-    Float32Array [\n-      23,\n-      -100.23652648925781,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary stream Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  Array [\n-    \"Hermione\",\n-    25,\n-    Float32Array [\n-      -53.235599517822266,\n-      40.231998443603516,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  Array [\n-    \"Severus\",\n-    30,\n-    Float32Array [\n-      -62.22999954223633,\n-      3,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  Array [\n-    \"Harry\",\n-    20,\n-    Float32Array [\n-      23,\n-      -100.23652648925781,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary stream Arrow Table toString() prints a pretty Table 1`] = `\n-\"                                                     example-csv\n-[\\\\\"Hermione\\\\\",25,{\\\\\"0\\\\\":-53.235599517822266,\\\\\"1\\\\\":40.231998443603516}]\n-                   [\\\\\"Severus\\\\\",30,{\\\\\"0\\\\\":-62.22999954223633,\\\\\"1\\\\\":3}]\n-                   [\\\\\"Harry\\\\\",20,{\\\\\"0\\\\\":23,\\\\\"1\\\\\":-100.23652648925781}]\"\n-`;\n-\n-exports[`dictionary stream Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`dictionary stream Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,                                                      example-csv\n-    0, [\\\\\"Hermione\\\\\",25,{\\\\\"0\\\\\":-53.235599517822266,\\\\\"1\\\\\":40.231998443603516}]\n-    1,                    [\\\\\"Severus\\\\\",30,{\\\\\"0\\\\\":-62.22999954223633,\\\\\"1\\\\\":3}]\n-    2,                    [\\\\\"Harry\\\\\",20,{\\\\\"0\\\\\":23,\\\\\"1\\\\\":-100.23652648925781}]\"\n-`;\n-\n-exports[`dictionary2 file Arrow Table creates a Table from Arrow buffers 1`] = `\"struct\"`;\n-\n-exports[`dictionary2 file Arrow Table creates a Table from Arrow buffers 2`] = `\"Struct_\"`;\n-\n-exports[`dictionary2 file Arrow Table creates a Table from Arrow buffers 3`] = `2`;\n-\n-exports[`dictionary2 file Arrow Table creates a Table from Arrow buffers 4`] = `\n-Array [\n-  \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-  \"Airbus\",\n-  1502880750,\n-  Float32Array [\n-    32.45663833618164,\n-    1.8712350130081177,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary2 file Arrow Table creates a Table from Arrow buffers 5`] = `\n-Array [\n-  \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-  \"Boeing\",\n-  1502880750,\n-  Float32Array [\n-    38.766666412353516,\n-    -4.181231498718262,\n-  ],\n-]\n-`;\n-\n-exports[`dictionary2 file Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"struct\": Array [\n-    \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-    \"Airbus\",\n-    1502880750,\n-    Float32Array [\n-      32.45663833618164,\n-      1.8712350130081177,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary2 file Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"struct\": Array [\n-    \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-    \"Boeing\",\n-    1502880750,\n-    Float32Array [\n-      38.766666412353516,\n-      -4.181231498718262,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`dictionary2 file Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  Array [\n-    \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-    \"Airbus\",\n-    1502880750,\n-    Float32Array [\n-      32.45663833618164,\n-      1.8712350130081177,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary2 file Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  Array [\n-    \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-    \"Boeing\",\n-    1502880750,\n-    Float32Array [\n-      38.766666412353516,\n-      -4.181231498718262,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`dictionary2 file Arrow Table toString() prints a pretty Table 1`] = `\n-\"                                                                                                      struct\n- [\\\\\"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\\\\\",\\\\\"Airbus\\\\\",1502880750,{\\\\\"0\\\\\":32.45663833618164,\\\\\"1\\\\\":1.8712350130081177}]\n-[\\\\\"50fb46f4-fefa-42c1-919c-0121974cdd00\\\\\",\\\\\"Boeing\\\\\",1502880750,{\\\\\"0\\\\\":38.766666412353516,\\\\\"1\\\\\":-4.181231498718262}]\"\n-`;\n-\n-exports[`dictionary2 file Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`dictionary2 file Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,                                                                                                       struct\n-    0,  [\\\\\"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\\\\\",\\\\\"Airbus\\\\\",1502880750,{\\\\\"0\\\\\":32.45663833618164,\\\\\"1\\\\\":1.8712350130081177}]\n-    1, [\\\\\"50fb46f4-fefa-42c1-919c-0121974cdd00\\\\\",\\\\\"Boeing\\\\\",1502880750,{\\\\\"0\\\\\":38.766666412353516,\\\\\"1\\\\\":-4.181231498718262}]\"\n-`;\n-\n-exports[`multi_dictionary file Arrow Table creates a Table from Arrow buffers 1`] = `\"struct\"`;\n-\n-exports[`multi_dictionary file Arrow Table creates a Table from Arrow buffers 2`] = `\"Struct_\"`;\n-\n-exports[`multi_dictionary file Arrow Table creates a Table from Arrow buffers 3`] = `2`;\n-\n-exports[`multi_dictionary file Arrow Table creates a Table from Arrow buffers 4`] = `\n-Array [\n-  \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-  \"12345\",\n-  \"Airbus\",\n-  1502880750,\n-  Float32Array [\n-    32.45663833618164,\n-    1.8712350130081177,\n-  ],\n-]\n-`;\n-\n-exports[`multi_dictionary file Arrow Table creates a Table from Arrow buffers 5`] = `\n-Array [\n-  \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-  \"67890\",\n-  \"Boeing\",\n-  1502880750,\n-  Float32Array [\n-    38.766666412353516,\n-    -4.181231498718262,\n-  ],\n-]\n-`;\n-\n-exports[`multi_dictionary file Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"struct\": Array [\n-    \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-    \"12345\",\n-    \"Airbus\",\n-    1502880750,\n-    Float32Array [\n-      32.45663833618164,\n-      1.8712350130081177,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`multi_dictionary file Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"struct\": Array [\n-    \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-    \"67890\",\n-    \"Boeing\",\n-    1502880750,\n-    Float32Array [\n-      38.766666412353516,\n-      -4.181231498718262,\n-    ],\n-  ],\n-}\n-`;\n-\n-exports[`multi_dictionary file Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  Array [\n-    \"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\",\n-    \"12345\",\n-    \"Airbus\",\n-    1502880750,\n-    Float32Array [\n-      32.45663833618164,\n-      1.8712350130081177,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`multi_dictionary file Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  Array [\n-    \"50fb46f4-fefa-42c1-919c-0121974cdd00\",\n-    \"67890\",\n-    \"Boeing\",\n-    1502880750,\n-    Float32Array [\n-      38.766666412353516,\n-      -4.181231498718262,\n-    ],\n-  ],\n-]\n-`;\n-\n-exports[`multi_dictionary file Arrow Table toString() prints a pretty Table 1`] = `\n-\"                                                                                                              struct\n- [\\\\\"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\\\\\",\\\\\"12345\\\\\",\\\\\"Airbus\\\\\",1502880750,{\\\\\"0\\\\\":32.45663833618164,\\\\\"1\\\\\":1.8712350130081177}]\n-[\\\\\"50fb46f4-fefa-42c1-919c-0121974cdd00\\\\\",\\\\\"67890\\\\\",\\\\\"Boeing\\\\\",1502880750,{\\\\\"0\\\\\":38.766666412353516,\\\\\"1\\\\\":-4.181231498718262}]\"\n-`;\n-\n-exports[`multi_dictionary file Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`multi_dictionary file Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,                                                                                                               struct\n-    0,  [\\\\\"a0fb47f9-f8fb-4403-a64a-786d7611f8ef\\\\\",\\\\\"12345\\\\\",\\\\\"Airbus\\\\\",1502880750,{\\\\\"0\\\\\":32.45663833618164,\\\\\"1\\\\\":1.8712350130081177}]\n-    1, [\\\\\"50fb46f4-fefa-42c1-919c-0121974cdd00\\\\\",\\\\\"67890\\\\\",\\\\\"Boeing\\\\\",1502880750,{\\\\\"0\\\\\":38.766666412353516,\\\\\"1\\\\\":-4.181231498718262}]\"\n-`;\n-\n-exports[`multipart count Arrow Table creates a Table from Arrow buffers 1`] = `\"row_count\"`;\n-\n-exports[`multipart count Arrow Table creates a Table from Arrow buffers 2`] = `\"Int\"`;\n-\n-exports[`multipart count Arrow Table creates a Table from Arrow buffers 3`] = `1`;\n-\n-exports[`multipart count Arrow Table creates a Table from Arrow buffers 4`] = `10000`;\n-\n-exports[`multipart count Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"row_count\": 10000,\n-}\n-`;\n-\n-exports[`multipart count Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  10000,\n-]\n-`;\n-\n-exports[`multipart count Arrow Table toString() prints a pretty Table 1`] = `\n-\"row_count\n-    10000\"\n-`;\n-\n-exports[`multipart count Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`multipart count Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index, row_count\n-    0,     10000\"\n-`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 1`] = `\"origin_lat\"`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 2`] = `\"FloatingPoint\"`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 3`] = `5`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 4`] = `35.393089294433594`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 5`] = `35.393089294433594`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 6`] = `35.393089294433594`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 7`] = `29.533695220947266`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 8`] = `29.533695220947266`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 9`] = `\"origin_lon\"`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 10`] = `\"FloatingPoint\"`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 11`] = `5`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 12`] = `-97.6007308959961`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 13`] = `-97.6007308959961`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 14`] = `-97.6007308959961`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 15`] = `-98.46977996826172`;\n-\n-exports[`multipart latlong Arrow Table creates a Table from Arrow buffers 16`] = `-98.46977996826172`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"origin_lat\": 35.393089294433594,\n-  \"origin_lon\": -97.6007308959961,\n-}\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"origin_lat\": 35.393089294433594,\n-  \"origin_lon\": -97.6007308959961,\n-}\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"origin_lat\": 35.393089294433594,\n-  \"origin_lon\": -97.6007308959961,\n-}\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows 4`] = `\n-Object {\n-  \"origin_lat\": 29.533695220947266,\n-  \"origin_lon\": -98.46977996826172,\n-}\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows 5`] = `\n-Object {\n-  \"origin_lat\": 29.533695220947266,\n-  \"origin_lon\": -98.46977996826172,\n-}\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  35.393089294433594,\n-  -97.6007308959961,\n-]\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  35.393089294433594,\n-  -97.6007308959961,\n-]\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  35.393089294433594,\n-  -97.6007308959961,\n-]\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows compact 4`] = `\n-Array [\n-  29.533695220947266,\n-  -98.46977996826172,\n-]\n-`;\n-\n-exports[`multipart latlong Arrow Table enumerates Table rows compact 5`] = `\n-Array [\n-  29.533695220947266,\n-  -98.46977996826172,\n-]\n-`;\n-\n-exports[`multipart latlong Arrow Table toString() prints a pretty Table 1`] = `\n-\"        origin_lat,         origin_lon\n-35.393089294433594,  -97.6007308959961\n-35.393089294433594,  -97.6007308959961\n-35.393089294433594,  -97.6007308959961\n-29.533695220947266, -98.46977996826172\n-29.533695220947266, -98.46977996826172\"\n-`;\n-\n-exports[`multipart latlong Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`multipart latlong Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,         origin_lat,         origin_lon\n-    0, 35.393089294433594,  -97.6007308959961\n-    1, 35.393089294433594,  -97.6007308959961\n-    2, 35.393089294433594,  -97.6007308959961\n-    3, 29.533695220947266, -98.46977996826172\n-    4, 29.533695220947266, -98.46977996826172\"\n-`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 1`] = `\"origin_city\"`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 2`] = `\"Utf8\"`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 3`] = `5`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 4`] = `\"Oklahoma City\"`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 5`] = `\"Oklahoma City\"`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 6`] = `\"Oklahoma City\"`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 7`] = `\"San Antonio\"`;\n-\n-exports[`multipart origins Arrow Table creates a Table from Arrow buffers 8`] = `\"San Antonio\"`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"origin_city\": \"Oklahoma City\",\n-}\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"origin_city\": \"Oklahoma City\",\n-}\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"origin_city\": \"Oklahoma City\",\n-}\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows 4`] = `\n-Object {\n-  \"origin_city\": \"San Antonio\",\n-}\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows 5`] = `\n-Object {\n-  \"origin_city\": \"San Antonio\",\n-}\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  \"Oklahoma City\",\n-]\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  \"Oklahoma City\",\n-]\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  \"Oklahoma City\",\n-]\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows compact 4`] = `\n-Array [\n-  \"San Antonio\",\n-]\n-`;\n-\n-exports[`multipart origins Arrow Table enumerates Table rows compact 5`] = `\n-Array [\n-  \"San Antonio\",\n-]\n-`;\n-\n-exports[`multipart origins Arrow Table toString() prints a pretty Table 1`] = `\n-\"  origin_city\n-Oklahoma City\n-Oklahoma City\n-Oklahoma City\n-  San Antonio\n-  San Antonio\"\n-`;\n-\n-exports[`multipart origins Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`multipart origins Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,   origin_city\n-    0, Oklahoma City\n-    1, Oklahoma City\n-    2, Oklahoma City\n-    3,   San Antonio\n-    4,   San Antonio\"\n-`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 1`] = `\"foo\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 2`] = `\"Int\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 3`] = `5`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 4`] = `1`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 5`] = `null`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 6`] = `3`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 7`] = `4`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 8`] = `5`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 9`] = `\"bar\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 10`] = `\"FloatingPoint\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 11`] = `5`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 12`] = `1`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 13`] = `null`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 14`] = `null`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 15`] = `4`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 16`] = `5`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 17`] = `\"baz\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 18`] = `\"Utf8\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 19`] = `5`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 20`] = `\"aa\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 21`] = `null`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 22`] = `null`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 23`] = `\"bbb\"`;\n-\n-exports[`simple file Arrow Table creates a Table from Arrow buffers 24`] = `\"cccc\"`;\n-\n-exports[`simple file Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"bar\": 1,\n-  \"baz\": \"aa\",\n-  \"foo\": 1,\n-}\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"bar\": null,\n-  \"baz\": null,\n-  \"foo\": null,\n-}\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"bar\": null,\n-  \"baz\": null,\n-  \"foo\": 3,\n-}\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows 4`] = `\n-Object {\n-  \"bar\": 4,\n-  \"baz\": \"bbb\",\n-  \"foo\": 4,\n-}\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows 5`] = `\n-Object {\n-  \"bar\": 5,\n-  \"baz\": \"cccc\",\n-  \"foo\": 5,\n-}\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  1,\n-  1,\n-  \"aa\",\n-]\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  null,\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  3,\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows compact 4`] = `\n-Array [\n-  4,\n-  4,\n-  \"bbb\",\n-]\n-`;\n-\n-exports[`simple file Arrow Table enumerates Table rows compact 5`] = `\n-Array [\n-  5,\n-  5,\n-  \"cccc\",\n-]\n-`;\n-\n-exports[`simple file Arrow Table toString() prints a pretty Table 1`] = `\n-\" foo,  bar,  baz\n-   1,    1,   aa\n-null, null, null\n-   3, null, null\n-   4,    4,  bbb\n-   5,    5, cccc\"\n-`;\n-\n-exports[`simple file Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`simple file Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,  foo,  bar,  baz\n-    0,    1,    1,   aa\n-    1, null, null, null\n-    2,    3, null, null\n-    3,    4,    4,  bbb\n-    4,    5,    5, cccc\"\n-`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 1`] = `\"foo\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 2`] = `\"Int\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 3`] = `5`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 4`] = `1`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 5`] = `null`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 6`] = `3`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 7`] = `4`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 8`] = `5`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 9`] = `\"bar\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 10`] = `\"FloatingPoint\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 11`] = `5`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 12`] = `1`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 13`] = `null`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 14`] = `null`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 15`] = `4`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 16`] = `5`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 17`] = `\"baz\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 18`] = `\"Utf8\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 19`] = `5`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 20`] = `\"aa\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 21`] = `null`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 22`] = `null`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 23`] = `\"bbb\"`;\n-\n-exports[`simple stream Arrow Table creates a Table from Arrow buffers 24`] = `\"cccc\"`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"bar\": 1,\n-  \"baz\": \"aa\",\n-  \"foo\": 1,\n-}\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"bar\": null,\n-  \"baz\": null,\n-  \"foo\": null,\n-}\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"bar\": null,\n-  \"baz\": null,\n-  \"foo\": 3,\n-}\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows 4`] = `\n-Object {\n-  \"bar\": 4,\n-  \"baz\": \"bbb\",\n-  \"foo\": 4,\n-}\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows 5`] = `\n-Object {\n-  \"bar\": 5,\n-  \"baz\": \"cccc\",\n-  \"foo\": 5,\n-}\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  1,\n-  1,\n-  \"aa\",\n-]\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  null,\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  3,\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows compact 4`] = `\n-Array [\n-  4,\n-  4,\n-  \"bbb\",\n-]\n-`;\n-\n-exports[`simple stream Arrow Table enumerates Table rows compact 5`] = `\n-Array [\n-  5,\n-  5,\n-  \"cccc\",\n-]\n-`;\n-\n-exports[`simple stream Arrow Table toString() prints a pretty Table 1`] = `\n-\" foo,  bar,  baz\n-   1,    1,   aa\n-null, null, null\n-   3, null, null\n-   4,    4,  bbb\n-   5,    5, cccc\"\n-`;\n-\n-exports[`simple stream Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`simple stream Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,  foo,  bar,  baz\n-    0,    1,    1,   aa\n-    1, null, null, null\n-    2,    3, null, null\n-    3,    4,    4,  bbb\n-    4,    5,    5, cccc\"\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 1`] = `\"struct_nullable\"`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 2`] = `\"Struct_\"`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 3`] = `17`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 4`] = `null`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 5`] = `\n-Array [\n-  null,\n-  \"MhRNxD4\",\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 6`] = `\n-Array [\n-  137773603,\n-  \"3F9HBxK\",\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 7`] = `\n-Array [\n-  410361374,\n-  \"aVd88fp\",\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 8`] = `null`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 9`] = `\n-Array [\n-  null,\n-  \"3loZrRf\",\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 10`] = `null`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 11`] = `null`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 12`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 13`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 14`] = `null`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 15`] = `\n-Array [\n-  null,\n-  \"78SLiRw\",\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 16`] = `null`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 17`] = `null`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 18`] = `\n-Array [\n-  null,\n-  \"0ilsf82\",\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 19`] = `\n-Array [\n-  null,\n-  \"LjS9MbU\",\n-]\n-`;\n-\n-exports[`struct file Arrow Table creates a Table from Arrow buffers 20`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"MhRNxD4\",\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    137773603,\n-    \"3F9HBxK\",\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 4`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    410361374,\n-    \"aVd88fp\",\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 5`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 6`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"3loZrRf\",\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 7`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 8`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 9`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    null,\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 10`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    null,\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 11`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 12`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"78SLiRw\",\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 13`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 14`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 15`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"0ilsf82\",\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 16`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"LjS9MbU\",\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows 17`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    null,\n-  ],\n-}\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  Array [\n-    null,\n-    \"MhRNxD4\",\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  Array [\n-    137773603,\n-    \"3F9HBxK\",\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 4`] = `\n-Array [\n-  Array [\n-    410361374,\n-    \"aVd88fp\",\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 5`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 6`] = `\n-Array [\n-  Array [\n-    null,\n-    \"3loZrRf\",\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 7`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 8`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 9`] = `\n-Array [\n-  Array [\n-    null,\n-    null,\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 10`] = `\n-Array [\n-  Array [\n-    null,\n-    null,\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 11`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 12`] = `\n-Array [\n-  Array [\n-    null,\n-    \"78SLiRw\",\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 13`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 14`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 15`] = `\n-Array [\n-  Array [\n-    null,\n-    \"0ilsf82\",\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 16`] = `\n-Array [\n-  Array [\n-    null,\n-    \"LjS9MbU\",\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table enumerates Table rows compact 17`] = `\n-Array [\n-  Array [\n-    null,\n-    null,\n-  ],\n-]\n-`;\n-\n-exports[`struct file Arrow Table toString() prints a pretty Table 1`] = `\n-\"      struct_nullable\n-                 null\n-     [null,\\\\\"MhRNxD4\\\\\"]\n-[137773603,\\\\\"3F9HBxK\\\\\"]\n-[410361374,\\\\\"aVd88fp\\\\\"]\n-                 null\n-     [null,\\\\\"3loZrRf\\\\\"]\n-                 null\n-                 null\n-          [null,null]\n-          [null,null]\n-                 null\n-     [null,\\\\\"78SLiRw\\\\\"]\n-                 null\n-                 null\n-     [null,\\\\\"0ilsf82\\\\\"]\n-     [null,\\\\\"LjS9MbU\\\\\"]\n-          [null,null]\"\n-`;\n-\n-exports[`struct file Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`struct file Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,       struct_nullable\n-    0,                  null\n-    1,      [null,\\\\\"MhRNxD4\\\\\"]\n-    2, [137773603,\\\\\"3F9HBxK\\\\\"]\n-    3, [410361374,\\\\\"aVd88fp\\\\\"]\n-    4,                  null\n-    5,      [null,\\\\\"3loZrRf\\\\\"]\n-    6,                  null\n-    7,                  null\n-    8,           [null,null]\n-    9,           [null,null]\n-   10,                  null\n-   11,      [null,\\\\\"78SLiRw\\\\\"]\n-   12,                  null\n-   13,                  null\n-   14,      [null,\\\\\"0ilsf82\\\\\"]\n-   15,      [null,\\\\\"LjS9MbU\\\\\"]\n-   16,           [null,null]\"\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 1`] = `\"struct_nullable\"`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 2`] = `\"Struct_\"`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 3`] = `17`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 4`] = `null`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 5`] = `\n-Array [\n-  null,\n-  \"MhRNxD4\",\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 6`] = `\n-Array [\n-  137773603,\n-  \"3F9HBxK\",\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 7`] = `\n-Array [\n-  410361374,\n-  \"aVd88fp\",\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 8`] = `null`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 9`] = `\n-Array [\n-  null,\n-  \"3loZrRf\",\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 10`] = `null`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 11`] = `null`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 12`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 13`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 14`] = `null`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 15`] = `\n-Array [\n-  null,\n-  \"78SLiRw\",\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 16`] = `null`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 17`] = `null`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 18`] = `\n-Array [\n-  null,\n-  \"0ilsf82\",\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 19`] = `\n-Array [\n-  null,\n-  \"LjS9MbU\",\n-]\n-`;\n-\n-exports[`struct stream Arrow Table creates a Table from Arrow buffers 20`] = `\n-Array [\n-  null,\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 1`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 2`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"MhRNxD4\",\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 3`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    137773603,\n-    \"3F9HBxK\",\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 4`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    410361374,\n-    \"aVd88fp\",\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 5`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 6`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"3loZrRf\",\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 7`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 8`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 9`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    null,\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 10`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    null,\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 11`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 12`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"78SLiRw\",\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 13`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 14`] = `\n-Object {\n-  \"struct_nullable\": null,\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 15`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"0ilsf82\",\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 16`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    \"LjS9MbU\",\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows 17`] = `\n-Object {\n-  \"struct_nullable\": Array [\n-    null,\n-    null,\n-  ],\n-}\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 1`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 2`] = `\n-Array [\n-  Array [\n-    null,\n-    \"MhRNxD4\",\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 3`] = `\n-Array [\n-  Array [\n-    137773603,\n-    \"3F9HBxK\",\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 4`] = `\n-Array [\n-  Array [\n-    410361374,\n-    \"aVd88fp\",\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 5`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 6`] = `\n-Array [\n-  Array [\n-    null,\n-    \"3loZrRf\",\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 7`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 8`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 9`] = `\n-Array [\n-  Array [\n-    null,\n-    null,\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 10`] = `\n-Array [\n-  Array [\n-    null,\n-    null,\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 11`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 12`] = `\n-Array [\n-  Array [\n-    null,\n-    \"78SLiRw\",\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 13`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 14`] = `\n-Array [\n-  null,\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 15`] = `\n-Array [\n-  Array [\n-    null,\n-    \"0ilsf82\",\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 16`] = `\n-Array [\n-  Array [\n-    null,\n-    \"LjS9MbU\",\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table enumerates Table rows compact 17`] = `\n-Array [\n-  Array [\n-    null,\n-    null,\n-  ],\n-]\n-`;\n-\n-exports[`struct stream Arrow Table toString() prints a pretty Table 1`] = `\n-\"      struct_nullable\n-                 null\n-     [null,\\\\\"MhRNxD4\\\\\"]\n-[137773603,\\\\\"3F9HBxK\\\\\"]\n-[410361374,\\\\\"aVd88fp\\\\\"]\n-                 null\n-     [null,\\\\\"3loZrRf\\\\\"]\n-                 null\n-                 null\n-          [null,null]\n-          [null,null]\n-                 null\n-     [null,\\\\\"78SLiRw\\\\\"]\n-                 null\n-                 null\n-     [null,\\\\\"0ilsf82\\\\\"]\n-     [null,\\\\\"LjS9MbU\\\\\"]\n-          [null,null]\"\n-`;\n-\n-exports[`struct stream Arrow Table toString() prints an empty Table 1`] = `\"\"`;\n-\n-exports[`struct stream Arrow Table toString({ index: true }) prints a pretty Table with an Index column 1`] = `\n-\"Index,       struct_nullable\n-    0,                  null\n-    1,      [null,\\\\\"MhRNxD4\\\\\"]\n-    2, [137773603,\\\\\"3F9HBxK\\\\\"]\n-    3, [410361374,\\\\\"aVd88fp\\\\\"]\n-    4,                  null\n-    5,      [null,\\\\\"3loZrRf\\\\\"]\n-    6,                  null\n-    7,                  null\n-    8,           [null,null]\n-    9,           [null,null]\n-   10,                  null\n-   11,      [null,\\\\\"78SLiRw\\\\\"]\n-   12,                  null\n-   13,                  null\n-   14,      [null,\\\\\"0ilsf82\\\\\"]\n-   15,      [null,\\\\\"LjS9MbU\\\\\"]\n-   16,           [null,null]\"\n-`;\ndiff --git a/js/test/arrows/file/dictionary.arrow b/js/test/arrows/file/dictionary.arrow\ndeleted file mode 100644\nindex 34d41db1f..000000000\nBinary files a/js/test/arrows/file/dictionary.arrow and /dev/null differ\ndiff --git a/js/test/arrows/file/dictionary2.arrow b/js/test/arrows/file/dictionary2.arrow\ndeleted file mode 100644\nindex 1537f54db..000000000\nBinary files a/js/test/arrows/file/dictionary2.arrow and /dev/null differ\ndiff --git a/js/test/arrows/file/multi_dictionary.arrow b/js/test/arrows/file/multi_dictionary.arrow\ndeleted file mode 100644\nindex 113d30da7..000000000\nBinary files a/js/test/arrows/file/multi_dictionary.arrow and /dev/null differ\ndiff --git a/js/test/arrows/file/simple.arrow b/js/test/arrows/file/simple.arrow\ndeleted file mode 100644\nindex 838db6dc8..000000000\nBinary files a/js/test/arrows/file/simple.arrow and /dev/null differ\ndiff --git a/js/test/arrows/file/struct.arrow b/js/test/arrows/file/struct.arrow\ndeleted file mode 100644\nindex 3d2c018e6..000000000\nBinary files a/js/test/arrows/file/struct.arrow and /dev/null differ\ndiff --git a/js/test/arrows/multi/count/records.arrow b/js/test/arrows/multi/count/records.arrow\ndeleted file mode 100644\nindex 00d883762..000000000\nBinary files a/js/test/arrows/multi/count/records.arrow and /dev/null differ\ndiff --git a/js/test/arrows/multi/count/schema.arrow b/js/test/arrows/multi/count/schema.arrow\ndeleted file mode 100644\nindex dfd24e9e0..000000000\nBinary files a/js/test/arrows/multi/count/schema.arrow and /dev/null differ\ndiff --git a/js/test/arrows/multi/latlong/records.arrow b/js/test/arrows/multi/latlong/records.arrow\ndeleted file mode 100644\nindex 563d12d17..000000000\nBinary files a/js/test/arrows/multi/latlong/records.arrow and /dev/null differ\ndiff --git a/js/test/arrows/multi/latlong/schema.arrow b/js/test/arrows/multi/latlong/schema.arrow\ndeleted file mode 100644\nindex 638b2ab62..000000000\nBinary files a/js/test/arrows/multi/latlong/schema.arrow and /dev/null differ\ndiff --git a/js/test/arrows/multi/origins/records.arrow b/js/test/arrows/multi/origins/records.arrow\ndeleted file mode 100644\nindex 49a8c407e..000000000\nBinary files a/js/test/arrows/multi/origins/records.arrow and /dev/null differ\ndiff --git a/js/test/arrows/multi/origins/schema.arrow b/js/test/arrows/multi/origins/schema.arrow\ndeleted file mode 100644\nindex 0d10fb0e2..000000000\nBinary files a/js/test/arrows/multi/origins/schema.arrow and /dev/null differ\ndiff --git a/js/test/arrows/stream/dictionary.arrow b/js/test/arrows/stream/dictionary.arrow\ndeleted file mode 100644\nindex 17ca48b3a..000000000\nBinary files a/js/test/arrows/stream/dictionary.arrow and /dev/null differ\ndiff --git a/js/test/arrows/stream/simple.arrow b/js/test/arrows/stream/simple.arrow\ndeleted file mode 100644\nindex 2c68c0e44..000000000\nBinary files a/js/test/arrows/stream/simple.arrow and /dev/null differ\ndiff --git a/js/test/arrows/stream/struct.arrow b/js/test/arrows/stream/struct.arrow\ndeleted file mode 100644\nindex 4e97b7084..000000000\nBinary files a/js/test/arrows/stream/struct.arrow and /dev/null differ\ndiff --git a/js/test/integration-tests.ts b/js/test/integration-tests.ts\nnew file mode 100644\nindex 000000000..4147e862b\n--- /dev/null\n+++ b/js/test/integration-tests.ts\n@@ -0,0 +1,114 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+import Arrow from './Arrow';\n+import { zip } from 'ix/iterable/zip';\n+import { config, formats } from './test-config';\n+\n+const { Table, readVectors } = Arrow;\n+\n+expect.extend({\n+    toEqualVector(v1: any, v2: any) {\n+\n+        const format = (x: any, y: any, msg= ' ') => `${\n+            this.utils.printExpected(x)}${\n+                msg}${\n+            this.utils.printReceived(y)\n+        }`;\n+\n+        let getFailures = new Array<string>();\n+        let propsFailures = new Array<string>();\n+        let iteratorFailures = new Array<string>();\n+        let allFailures = [\n+            { title: 'get', failures: getFailures },\n+            { title: 'props', failures: propsFailures },\n+            { title: 'iterator', failures: iteratorFailures }\n+        ];\n+\n+        let props = ['name', 'type', 'length', 'nullable', 'nullCount', 'metadata'];\n+        for (let i = -1, n = props.length; ++i < n;) {\n+            const prop = props[i];\n+            if (this.utils.stringify(v1[prop]) !== this.utils.stringify(v2[prop])) {\n+                propsFailures.push(`${prop}: ${format(v1[prop], v2[prop], ' !== ')}`);\n+            }\n+        }\n+\n+        for (let i = -1, n = v1.length; ++i < n;) {\n+            let x1 = v1.get(i), x2 = v2.get(i);\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                getFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        let i = -1;\n+        for (let [x1, x2] of zip(v1, v2)) {\n+            ++i;\n+            if (this.utils.stringify(x1) !== this.utils.stringify(x2)) {\n+                iteratorFailures.push(`${i}: ${format(x1, x2, ' !== ')}`);\n+            }\n+        }\n+\n+        return {\n+            pass: allFailures.every(({ failures }) => failures.length === 0),\n+            message: () => [\n+                `${v1.name}: (${format('cpp', 'java', ' !== ')})\\n`,\n+                ...allFailures.map(({ failures, title }) =>\n+                    !failures.length ? `` : [`${title}:`, ...failures].join(`\\n`))\n+            ].join('\\n')\n+        };\n+    }\n+});\n+\n+describe(`Integration`, () => {\n+    for (const format of formats) {\n+        describe(format, () => {\n+            for (const [cppArrow, javaArrow] of zip(config.cpp[format], config.java[format])) {\n+                describe(`${cppArrow.name}`, () => {\n+                    testReaderIntegration(cppArrow.buffers, javaArrow.buffers);\n+                    testTableFromBuffersIntegration(cppArrow.buffers, javaArrow.buffers);\n+                });\n+            }\n+        });\n+    }\n+});\n+\n+function testReaderIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java vectors report the same values`, () => {\n+        expect.hasAssertions();\n+        for (const [cppVectors, javaVectors] of zip(readVectors(cppBuffers), readVectors(javaBuffers))) {\n+            expect(cppVectors.length).toEqual(javaVectors.length);\n+            for (let i = -1, n = cppVectors.length; ++i < n;) {\n+                (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+            }\n+        }\n+    });\n+}\n+\n+function testTableFromBuffersIntegration(cppBuffers: Uint8Array[], javaBuffers: Uint8Array[]) {\n+    test(`cpp and java tables report the same values`, () => {\n+        expect.hasAssertions();\n+        const cppTable = Table.from(cppBuffers);\n+        const javaTable = Table.from(javaBuffers);\n+        const cppVectors = cppTable.columns;\n+        const javaVectors = javaTable.columns;\n+        expect(cppTable.length).toEqual(javaTable.length);\n+        expect(cppVectors.length).toEqual(javaVectors.length);\n+        for (let i = -1, n = cppVectors.length; ++i < n;) {\n+            (expect(cppVectors[i]) as any).toEqualVector(javaVectors[i]);\n+        }\n+    });\n+}\ndiff --git a/js/test/reader-tests.ts b/js/test/reader-tests.ts\nindex a7f9f4110..309cec9e2 100644\n--- a/js/test/reader-tests.ts\n+++ b/js/test/reader-tests.ts\n@@ -15,36 +15,55 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { readBuffers } from './Arrow';\n-import arrowTestConfigurations from './test-config';\n+import Arrow from './Arrow';\n+const { readVectors } = Arrow;\n+import { config, sources, formats } from './test-config';\n \n-for (let [name, ...buffers] of arrowTestConfigurations) {\n-    describe(`${name} readBuffers`, () => {\n-        test(`enumerates each batch as an Array of Vectors`, () => {\n-            expect.hasAssertions();\n-            for (let vectors of readBuffers(...buffers)) {\n-                for (let vector of vectors) {\n-                    expect(vector.name).toMatchSnapshot();\n-                    expect(vector.type).toMatchSnapshot();\n-                    expect(vector.length).toMatchSnapshot();\n-                        for (let i = -1, n = vector.length; ++i < n;) {\n-                        expect(vector.get(i)).toMatchSnapshot();\n+describe(`readBuffers`, () => {\n+    for (const source of sources) {\n+        describe(source, () => {\n+            for (const format of formats) {\n+                describe(format, () => {\n+                    for (const { name, buffers } of config[source][format]) {\n+                        describe(name, () => {\n+                            testReaderIterator(buffers);\n+                            testVectorIterator(buffers);\n+                        });\n                     }\n-                }\n+                });\n             }\n         });\n-        test(`vector iterators report the same values as get`, () => {\n-            expect.hasAssertions();\n-            for (let vectors of readBuffers(...buffers)) {\n-                for (let vector of vectors) {\n-                    let i = -1, n = vector.length;\n-                    for (let v of vector) {\n-                        expect(++i).toBeLessThan(n);\n-                        expect(v).toEqual(vector.get(i));\n-                    }\n-                    expect(++i).toEqual(n);\n+    }\n+});\n+\n+function testReaderIterator(buffers: Uint8Array[]) {\n+    test(`reads each batch as an Array of Vectors`, () => {\n+        expect.hasAssertions();\n+        for (const vectors of readVectors(buffers)) {\n+            for (const vector of vectors) {\n+                expect(vector.name).toMatchSnapshot();\n+                expect(vector.type).toMatchSnapshot();\n+                expect(vector.length).toMatchSnapshot();\n+                for (let i = -1, n = vector.length; ++i < n;) {\n+                    expect(vector.get(i)).toMatchSnapshot();\n                 }\n             }\n-        });\n+        }\n+    });\n+}\n+\n+function testVectorIterator(buffers: Uint8Array[]) {\n+    test(`vector iterators report the same values as get`, () => {\n+        expect.hasAssertions();\n+        for (const vectors of readVectors(buffers)) {\n+            for (const vector of vectors) {\n+                let i = -1, n = vector.length;\n+                for (let v of vector) {\n+                    expect(++i).toBeLessThan(n);\n+                    expect(v).toEqual(vector.get(i));\n+                }\n+                expect(++i).toEqual(n);\n+            }\n+        }\n     });\n }\ndiff --git a/js/test/table-tests.ts b/js/test/table-tests.ts\nindex d0d70059e..5ec04a72f 100644\n--- a/js/test/table-tests.ts\n+++ b/js/test/table-tests.ts\n@@ -15,75 +15,122 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { Table, readBuffers } from './Arrow';\n-import arrowTestConfigurations from './test-config';\n+import Arrow from './Arrow';\n+const { Table, readVectors } = Arrow;\n+import { config, sources, formats } from './test-config';\n \n-for (let [name, ...buffers] of arrowTestConfigurations) {\n-    describe(`${name} Table`, () => {\n-        test(`creates a Table from Arrow buffers`, () => {\n-            expect.hasAssertions();\n-            const table = Table.from(...buffers);\n-            for (const vector of table.columns) {\n-                expect(vector.name).toMatchSnapshot();\n-                expect(vector.type).toMatchSnapshot();\n-                expect(vector.length).toMatchSnapshot();\n-                for (let i = -1, n = vector.length; ++i < n;) {\n-                    expect(vector.get(i)).toMatchSnapshot();\n-                }\n-            }\n-        });\n-        test(`vector iterators report the same values as get`, () => {\n-            expect.hasAssertions();\n-            const table = Table.from(...buffers);\n-            for (const vector of table.columns) {\n-                let i = -1, n = vector.length;\n-                for (let v of vector) {\n-                    expect(++i).toBeLessThan(n);\n-                    expect(v).toEqual(vector.get(i));\n-                }\n-                expect(++i).toEqual(n);\n-            }\n-        });\n-        test(`batch and Table Vectors report the same values`, () => {\n-            expect.hasAssertions();\n-            let rowsTotal = 0;\n-            let table = Table.from(...buffers);\n-            for (let vectors of readBuffers(...buffers)) {\n-                let rowsNow = Math.max(...vectors.map((v) => v.length));\n-                for (let vi = -1, vn = vectors.length; ++vi < vn;) {\n-                    let v1 = vectors[vi];\n-                    let v2 = table.columns[vi];\n-                    expect(v1.name).toEqual(v2.name);\n-                    expect(v1.type).toEqual(v2.type);\n-                    for (let i = -1, n = v1.length; ++i < n;) {\n-                        expect(v1.get(i)).toEqual(v2.get(i + rowsTotal));\n+describe(`Table`, () => {\n+    for (const source of sources) {\n+        describe(source, () => {\n+            for (const format of formats) {\n+                describe(format, () => {\n+                    for (const { name, buffers } of config[source][format]) {\n+                        describe(name, () => {\n+                            testTableFromBuffers(buffers);\n+                            testColumnIterators(buffers);\n+                            testReaderVectorsAndTableColumns(buffers);\n+                            testTableRowIterator(buffers);\n+                            testTableRowIteratorCompact(buffers);\n+                            testEmptyTableToString();\n+                            testTableToStringPretty(buffers);\n+                            testTableToStringPrettyWithIndex(buffers);\n+                        });\n                     }\n-                }\n-                rowsTotal += rowsNow;\n+                });\n             }\n         });\n-        test(`enumerates Table rows`, () => {\n-            expect.hasAssertions();\n-            const table = Table.from(...buffers);\n-            for (const row of table) {\n-                expect(row!.toObject()).toMatchSnapshot();\n+    }\n+});\n+\n+function testTableFromBuffers(buffers: Uint8Array[]) {\n+    test(`creates a Table from Arrow buffers`, () => {\n+        expect.hasAssertions();\n+        const table = Table.from(buffers);\n+        for (const vector of table.columns) {\n+            expect(vector.name).toMatchSnapshot();\n+            expect(vector.type).toMatchSnapshot();\n+            expect(vector.length).toMatchSnapshot();\n+            for (let i = -1, n = vector.length; ++i < n;) {\n+                expect(vector.get(i)).toMatchSnapshot();\n             }\n-        });\n-        test(`enumerates Table rows compact`, () => {\n-            expect.hasAssertions();\n-            const table = Table.from(...buffers);\n-            for (const row of table) {\n-                expect(row!.toArray()).toMatchSnapshot();\n+        }\n+    });\n+}\n+\n+function testColumnIterators(buffers: Uint8Array[]) {\n+    test(`vector iterators report the same values as get`, () => {\n+        expect.hasAssertions();\n+        const table = Table.from(buffers);\n+        for (const vector of table.columns) {\n+            let i = -1, n = vector.length;\n+            for (let v of vector) {\n+                expect(++i).toBeLessThan(n);\n+                expect(v).toEqual(vector.get(i));\n             }\n-        });\n-        test(`toString() prints an empty Table`, () => {\n-            expect(Table.from().toString()).toMatchSnapshot();\n-        });\n-        test(`toString() prints a pretty Table`, () => {\n-            expect(Table.from(...buffers).toString()).toMatchSnapshot();\n-        });\n-        test(`toString({ index: true }) prints a pretty Table with an Index column`, () => {\n-            expect(Table.from(...buffers).toString({ index: true })).toMatchSnapshot();\n-        });\n+            expect(++i).toEqual(n);\n+        }\n     });\n }\n+\n+function testReaderVectorsAndTableColumns(buffers: Uint8Array[]) {\n+    test(`batch and Table Vectors report the same values`, () => {\n+        expect.hasAssertions();\n+        let rowsTotal = 0;\n+        let table = Table.from(buffers);\n+        for (let vectors of readVectors(buffers)) {\n+            let rowsNow = Math.max(...vectors.map((v) => v.length));\n+            for (let vi = -1, vn = vectors.length; ++vi < vn;) {\n+                let v1 = vectors[vi];\n+                let v2 = table.columns[vi];\n+                expect(v1.name).toEqual(v2.name);\n+                expect(v1.type).toEqual(v2.type);\n+                for (let i = -1, n = v1.length; ++i < n;) {\n+                    expect(v1.get(i)).toEqual(v2.get(i + rowsTotal));\n+                }\n+            }\n+            rowsTotal += rowsNow;\n+        }\n+    });\n+}\n+\n+function testTableRowIterator(buffers: Uint8Array[]) {\n+    test(`enumerates Table rows`, () => {\n+        expect.hasAssertions();\n+        const table = Table.from(buffers);\n+        expect(table.length).toMatchSnapshot();\n+        expect(table.columns.length).toMatchSnapshot();\n+        for (const row of table) {\n+            expect(row!.toObject()).toMatchSnapshot();\n+        }\n+    });\n+}\n+\n+function testTableRowIteratorCompact(buffers: Uint8Array[]) {\n+    test(`enumerates Table rows compact`, () => {\n+        expect.hasAssertions();\n+        const table = Table.from(buffers);\n+        expect(table.length).toMatchSnapshot();\n+        expect(table.columns.length).toMatchSnapshot();\n+        for (const row of table) {\n+            expect(row!.toArray()).toMatchSnapshot();\n+        }\n+    });\n+}\n+\n+function testEmptyTableToString() {\n+    test(`toString() prints an empty Table`, () => {\n+        expect(Table.from().toString()).toMatchSnapshot();\n+    });\n+}\n+\n+function testTableToStringPretty(buffers: Uint8Array[]) {\n+    test(`toString() prints a pretty Table`, () => {\n+        expect(Table.from(buffers).toString()).toMatchSnapshot();\n+    });\n+}\n+\n+function testTableToStringPrettyWithIndex(buffers: Uint8Array[]) {\n+    test(`toString({ index: true }) prints a pretty Table with an Index column`, () => {\n+        expect(Table.from(buffers).toString({ index: true })).toMatchSnapshot();\n+    });\n+}\n\\ No newline at end of file\ndiff --git a/js/test/test-config.ts b/js/test/test-config.ts\nindex 89de1cc6c..d185ecc92 100644\n--- a/js/test/test-config.ts\n+++ b/js/test/test-config.ts\n@@ -17,26 +17,36 @@\n \n import * as fs from 'fs';\n import * as path from 'path';\n-const arrowFormats = ['file', 'stream'];\n-const arrowFileNames = ['simple', 'struct', 'dictionary', 'dictionary2', 'multi_dictionary'];\n-const multipartArrows = ['count', 'latlong', 'origins'];\n-export let arrowTestConfigurations = [] as (string | Buffer)[][];\n+import * as glob from 'glob';\n \n-arrowTestConfigurations = arrowFormats.reduce((configs, format) => {\n-    return arrowFileNames.reduce((configs, name) => {\n-        const arrowPath = path.resolve(__dirname, `./arrows/${format}/${name}.arrow`);\n-        try {\n-            const arrowFile = fs.readFileSync(arrowPath);\n-            return [...configs, [`${name} ${format} Arrow`, arrowFile]];\n-        } catch (e) {}\n-        return configs;\n-    }, configs);\n-}, arrowTestConfigurations);\n+export const sources = (process.env.TEST_SOURCES\n+    ? JSON.parse(process.env.TEST_SOURCES + '')\n+    : [`cpp`, `java`]) as ['cpp' | 'java'];\n \n-arrowTestConfigurations = multipartArrows.reduce((configs, folder) => {\n-    const schemaPath = path.resolve(__dirname, `./arrows/multi/${folder}/schema.arrow`);\n-    const recordsPath = path.resolve(__dirname, `./arrows/multi/${folder}/records.arrow`);\n-    return [...configs, [`multipart ${folder} Arrow`, fs.readFileSync(schemaPath), fs.readFileSync(recordsPath)]];\n-}, arrowTestConfigurations);\n+export const formats = (process.env.TEST_FORMATS\n+    ? JSON.parse(process.env.TEST_FORMATS + '')\n+    : [`file`, `stream`]) as ['file' | 'stream'];\n \n-export default arrowTestConfigurations;\n+export const config = sources.reduce((sources, source) => ({\n+    ...sources,\n+    [source]: formats.reduce((formats, format) => ({\n+        ...formats,\n+        [format]: loadArrows(source, format)\n+    }), {})\n+}), {}) as {\n+    [k in 'cpp' | 'java']: {\n+        [k in 'file' | 'stream']: Arrows\n+    }\n+};\n+\n+export type Arrows = { name: string, buffers: Uint8Array[] }[];\n+\n+function loadArrows(source: string, format: string) {\n+    const arrows = [];\n+    const filenames = glob.sync(path.resolve(__dirname, `data/${source}/${format}`, `*.arrow`));\n+    for (const filename of filenames) {\n+        const { name } = path.parse(filename);\n+        arrows.push({ name, buffers: [fs.readFileSync(filename)] });\n+    }\n+    return arrows as Arrows;\n+}\ndiff --git a/js/test/tsconfig.json b/js/test/tsconfig.json\nindex c1ae20421..838bb1d70 100644\n--- a/js/test/tsconfig.json\n+++ b/js/test/tsconfig.json\n@@ -2,7 +2,7 @@\n   \"extends\": \"../tsconfig.json\",\n   \"include\": [\"./**/*.ts\"],\n   \"compilerOptions\": {\n-    \"target\": \"ESNEXT\",\n+    \"target\": \"es2015\",\n     \"module\": \"commonjs\",\n     \"allowJs\": true,\n     \"importHelpers\": false,\ndiff --git a/js/test/vector-tests.ts b/js/test/vector-tests.ts\nindex 0eca2327b..0aaba19ee 100644\n--- a/js/test/vector-tests.ts\n+++ b/js/test/vector-tests.ts\n@@ -15,11 +15,15 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-import { flatbuffers } from 'flatbuffers';\n-import Long = flatbuffers.Long;\n+import Arrow from './Arrow';\n import {\n+    TypedArray,\n+    TypedArrayConstructor,\n+    NumericVectorConstructor,\n+} from './Arrow';\n+\n+const {\n     BoolVector,\n-    TypedVector,\n     Int64Vector,\n     Uint64Vector,\n     Int8Vector,\n@@ -28,28 +32,29 @@ import {\n     Uint8Vector,\n     Uint16Vector,\n     Uint32Vector,\n+    Float16Vector,\n     Float32Vector,\n     Float64Vector,\n-} from './Arrow';\n+} = Arrow;\n \n-const LongVectors = {\n-    Int64Vector: [Int64Vector, Int32Array],\n-    Uint64Vector: [Uint64Vector, Uint32Array]\n+const FixedSizeVectors = {\n+    Int64Vector: [Int64Vector, Int32Array] as [NumericVectorConstructor<number, any>, any],\n+    Uint64Vector: [Uint64Vector, Uint32Array] as [NumericVectorConstructor<number, any>, any]\n };\n \n-const TypedVectors = {\n-    Int8Vector: [Int8Vector, Int8Array],\n-    Int16Vector: [Int16Vector, Int16Array],\n-    Int32Vector: [Int32Vector, Int32Array],\n-    Uint8Vector: [Uint8Vector, Uint8Array],\n-    Uint16Vector: [Uint16Vector, Uint16Array],\n-    Uint32Vector: [Uint32Vector, Uint32Array],\n-    Float32Vector: [Float32Vector, Float32Array],\n-    Float64Vector: [Float64Vector, Float64Array]\n+const FixedWidthVectors = {\n+    Int8Vector: [Int8Vector, Int8Array] as [NumericVectorConstructor<number, any>, any],\n+    Int16Vector: [Int16Vector, Int16Array] as [NumericVectorConstructor<number, any>, any],\n+    Int32Vector: [Int32Vector, Int32Array] as [NumericVectorConstructor<number, any>, any],\n+    Uint8Vector: [Uint8Vector, Uint8Array] as [NumericVectorConstructor<number, any>, any],\n+    Uint16Vector: [Uint16Vector, Uint16Array] as [NumericVectorConstructor<number, any>, any],\n+    Uint32Vector: [Uint32Vector, Uint32Array] as [NumericVectorConstructor<number, any>, any],\n+    Float32Vector: [Float32Vector, Float32Array] as [NumericVectorConstructor<number, any>, any],\n+    Float64Vector: [Float64Vector, Float64Array] as [NumericVectorConstructor<number, any>, any]\n };\n \n-const longVectors = toMap<[typeof TypedVector, any]>(LongVectors, Object.keys(LongVectors));\n-const byteVectors = toMap<[typeof TypedVector, any]>(TypedVectors, Object.keys(TypedVectors));\n+const fixedSizeVectors = toMap(FixedSizeVectors, Object.keys(FixedSizeVectors));\n+const fixedWidthVectors = toMap(FixedWidthVectors, Object.keys(FixedWidthVectors));\n const bytes = Array.from(\n     { length: 5 },\n     () => Uint8Array.from(\n@@ -127,30 +132,66 @@ describe(`BoolVector`, () => {\n     });\n });\n \n-for (const [VectorName, [VectorType, ArrayType]] of longVectors) {\n+describe('Float16Vector', () => {\n+    const values = concatTyped(Uint16Array, ...bytes);\n+    const vector = bytes\n+        .map((b) => new Float16Vector({ data: new Uint16Array(b.buffer) }))\n+        .reduce((v: any, v2) => v.concat(v2));\n+    const n = values.length;\n+    const clamp = (x: number) => Math.min((x -  32767) / 32767, 1);\n+    test(`gets expected values`, () => {\n+        let i = -1;\n+        while (++i < n) {\n+            expect(vector.get(i)).toEqual(clamp(values[i]));\n+        }\n+    });\n+    test(`iterates expected values`, () => {\n+        expect.hasAssertions();\n+        let i = -1;\n+        for (let v of vector) {\n+            expect(++i).toBeLessThan(n);\n+            expect(v).toEqual(clamp(values[i]));\n+        }\n+    });\n+    test(`slices the entire array`, () => {\n+        expect(vector.slice()).toEqual(values);\n+    });\n+    test(`slice returns a TypedArray`, () => {\n+        expect(vector.slice()).toBeInstanceOf(Uint16Array);\n+    });\n+    test(`slices from -20 to length`, () => {\n+        expect(vector.slice(-20)).toEqual(values.slice(-20));\n+    });\n+    test(`slices from 0 to -20`, () => {\n+        expect(vector.slice(0, -20)).toEqual(values.slice(0, -20));\n+    });\n+    test(`slices the array from 0 to length - 20`, () => {\n+        expect(vector.slice(0, n - 20)).toEqual(values.slice(0, n - 20));\n+    });\n+    test(`slices the array from 0 to length + 20`, () => {\n+        expect(vector.slice(0, n + 20)).toEqual(\n+            concatTyped(Uint16Array, values, values.slice(0, 20)));\n+    });\n+});\n+\n+for (const [VectorName, [VectorType, ArrayType]] of fixedSizeVectors) {\n     describe(`${VectorName}`, () => {\n         const values = concatTyped(ArrayType, ...bytes);\n         const vector = bytes\n-            .map((b) => new VectorType<Long, any>({\n-                data: new ArrayType(b.buffer)\n-            }))\n+            .map((b) => new VectorType({ data: new ArrayType(b.buffer) }))\n             .reduce((v: any, v2) => v.concat(v2));\n         const n = values.length * 0.5;\n         test(`gets expected values`, () => {\n             let i = -1;\n             while (++i < n) {\n-                expect(vector.get(i)).toEqual(new Long(\n-                    values[i * 2], values[i * 2 + 1]\n-                ));\n+                expect(vector.get(i)).toEqual(values.slice(2 * i, 2 * (i + 1)));\n             }\n         });\n         test(`iterates expected values`, () => {\n             let i = -1;\n             for (let v of vector) {\n                 expect(++i).toBeLessThan(n);\n-                expect(v).toEqual(new Long(\n-                    values[i * 2], values[i * 2 + 1]\n-                ));\n+                expect(v).toEqual(values.slice(2 * i, 2 * (i + 1)));\n             }\n         });\n         test(`slices the entire array`, () => {\n@@ -175,13 +216,11 @@ for (const [VectorName, [VectorType, ArrayType]] of longVectors) {\n     });\n }\n \n-for (const [VectorName, [VectorType, ArrayType]] of byteVectors) {\n+for (const [VectorName, [VectorType, ArrayType]] of fixedWidthVectors) {\n     describe(`${VectorName}`, () => {\n         const values = concatTyped(ArrayType, ...bytes);\n         const vector = bytes\n-            .map((b) => new VectorType<number, any>({\n-                data: new ArrayType(b.buffer)\n-            }))\n+            .map((b) => new VectorType({ data: new ArrayType(b.buffer) }))\n             .reduce((v: any, v2) => v.concat(v2));\n \n         const n = values.length;\n@@ -221,14 +260,14 @@ for (const [VectorName, [VectorType, ArrayType]] of byteVectors) {\n     });\n }\n \n-function toMap<T>(entries: any, keys: string[]) {\n+function toMap<T>(entries: Record<string, T>, keys: string[]) {\n     return keys.reduce((map, key) => {\n         map.set(key, entries[key] as T);\n         return map;\n     }, new Map<string, T>());\n }\n \n-function concatTyped(ArrayType: any, ...bytes: any[]) {\n+function concatTyped<T extends TypedArray>(ArrayType: TypedArrayConstructor<T>, ...bytes: any[]) {\n     const BPE = ArrayType.BYTES_PER_ELEMENT;\n     return bytes.reduce((v, bytes) => {\n         const l = bytes.byteLength / BPE;\n@@ -237,5 +276,5 @@ function concatTyped(ArrayType: any, ...bytes: any[]) {\n         a.set(v);\n         a.set(b, v.length);\n         return a;\n-    }, new ArrayType(0)) as Array<number>;\n+    }, new ArrayType(0)) as T;\n }\n\\ No newline at end of file\ndiff --git a/js/tsconfig/tsconfig.es5.cls.json b/js/tsconfig/tsconfig.es5.cls.json\nindex 6e6f213b4..502432da0 100644\n--- a/js/tsconfig/tsconfig.es5.cls.json\n+++ b/js/tsconfig/tsconfig.es5.cls.json\n@@ -4,8 +4,6 @@\n   \"compilerOptions\": {\n     \"target\": \"ES5\",\n     \"module\": \"es2015\",\n-    \"declaration\": false,\n-    \"noEmitHelpers\": true,\n-    \"importHelpers\": false\n+    \"declaration\": false\n   }\n }\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T14:23:04.874+0000",
                    "updated": "2017-11-20T14:23:04.874+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16259282",
                    "id": "16259282",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 1294\n[https://github.com/apache/arrow/pull/1294]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-11-20T14:23:05.991+0000",
                    "updated": "2017-11-20T14:23:05.991+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16259600",
                    "id": "16259600",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "trxcllnt commented on issue #1294: ARROW-1693: [JS] Expand JavaScript implementation, build system, fix integration tests\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345783422\n \n \n   @wesm I added https://github.com/apache/arrow/commit/48111290c2c8169ccefcf04c92afa684f0e8d56d to support reading <= 0.7.1 buffers. I tested on the previous arrow files in the tests, plus a few I generated in pyarrow locally. Is there anything else we need to do on that?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T18:22:17.185+0000",
                    "updated": "2017-11-20T18:22:17.185+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13110997/comment/16259723",
                    "id": "16259723",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1294: ARROW-1693: [JS] Expand JavaScript implementation, build system, fix integration tests\nURL: https://github.com/apache/arrow/pull/1294#issuecomment-345803902\n \n \n   Ah cool I missed that. I think we are good then, so I suggest we cut a JS release ASAP to make sure we've got the process down and then we can release again after 0.8.0 final goes out. I'm available this week to help out with this\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-20T19:32:29.736+0000",
                    "updated": "2017-11-20T19:32:29.736+0000"
                }
            ],
            "maxResults": 89,
            "total": 89,
            "startAt": 0
        },
        "customfield_12311820": "0|i3liqv:",
        "customfield_12314139": null
    }
}