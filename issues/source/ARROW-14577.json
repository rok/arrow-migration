{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13409890",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890",
    "key": "ARROW-14577",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350591",
                "id": "12350591",
                "description": "",
                "name": "7.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-02-03"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350323",
                "id": "12350323",
                "description": "",
                "name": "6.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-10-26"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12631374",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12631374",
                "type": {
                    "id": "12310000",
                    "name": "Duplicate",
                    "inward": "is duplicated by",
                    "outward": "duplicates",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                },
                "inwardIssue": {
                    "id": "13407848",
                    "key": "ARROW-14429",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13407848",
                    "fields": {
                        "summary": "[C++] RecordBatchFileReader performance really bad in S3",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12625768",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12625768",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13377241",
                    "key": "ARROW-12683",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13377241",
                    "fields": {
                        "summary": "[C++] Enable fine-grained I/O (coalescing) in IPC reader",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
            "name": "westonpace",
            "key": "westonpace",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Weston Pace",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=niyue",
            "name": "niyue",
            "key": "niyue",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=niyue&avatarId=48220",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=niyue&avatarId=48220",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=niyue&avatarId=48220",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=niyue&avatarId=48220"
            },
            "displayName": "Yue Ni",
            "active": true,
            "timeZone": "Asia/Shanghai"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=niyue",
            "name": "niyue",
            "key": "niyue",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=niyue&avatarId=48220",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=niyue&avatarId=48220",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=niyue&avatarId=48220",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=niyue&avatarId=48220"
            },
            "displayName": "Yue Ni",
            "active": true,
            "timeZone": "Asia/Shanghai"
        },
        "aggregateprogress": {
            "progress": 29400,
            "total": 29400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 29400,
            "total": 29400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-14577/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 49,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/676862",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace opened a new pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616\n\n\n   **This is still very much a WIP**\r\n   \r\n   This PR attempts to address several issues:\r\n   \r\n    * Memory mapped IPC reads always call WillNeed on the data and the user has no way to avoid this\r\n    * Projection pushdown is only available in the synchronous API\r\n    * Coalescing / readahead is only available via the generators API\r\n    * There is a lot of duplicate code in the generators path\r\n    \r\n    It adds two new methods to RecordBatchFileReader:\r\n    \r\n    ```\r\n      /// \\brief Begin loading metadata for the desired batches into memory.\r\n     ///\r\n     /// This method will also begin loading all dictionaries messages into memory.\r\n     ///\r\n     /// For a regular file this will immediately begin disk I/O in the background on a\r\n     /// thread on the IOContext's thread pool.  If the file is memory mapped this will\r\n     /// ensure the memory needed for the metadata is paged from disk into memory\r\n     ///\r\n     /// \\param indices Indices of the batches to prefetch\r\n     ///                If empty then all batches will be prefetched.\r\n     virtual Status WillNeedMetadata(const std::vector<int>& indices) = 0;\r\n   \r\n     /// \\brief Begin loading metadata for the desired batches into memory and indicate\r\n     ///        that the data itself should be prefetched when it is requested\r\n     ///\r\n     /// This method should not be called in combination with WillNeedMetadata.  If you want\r\n     /// to prefetch the data then use this method.  If you do not want to prefetch the data\r\n     /// (because you are only accessing a small # of items in the batch's arrays) then you\r\n     /// should use WillNeedMetadata\r\n     ///\r\n     /// This method will immediately start the I/O for the metadata and dictionaries.\r\n     ///\r\n     /// This method will not immediately start the I/O for the data.  The data I/O will be\r\n     /// started when you call ReadRecordBatch.\r\n     ///\r\n     /// If you want to read multiple batches in parallel then you can make concurrent calls\r\n     /// to ReadRecordBatch or ReadRecordBatchAsync\r\n     /// \\param indices\r\n     /// \\return\r\n     virtual Status WillNeedBatches(const std::vector<int>& indices) = 0;\r\n   ```\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-05T03:15:12.820+0000",
                    "updated": "2021-11-05T03:15:12.820+0000",
                    "started": "2021-11-05T03:15:12.820+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "676862",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/676863",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-961596136\n\n\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-05T03:15:50.566+0000",
                    "updated": "2021-11-05T03:15:50.566+0000",
                    "started": "2021-11-05T03:15:50.565+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "676863",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/677294",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace opened a new pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616\n\n\n   **This is still very much a WIP**\r\n   \r\n   This PR attempts to address several issues:\r\n   \r\n    * Memory mapped IPC reads always call WillNeed on the data and the user has no way to avoid this\r\n    * Projection pushdown is only available in the synchronous API\r\n    * Coalescing / readahead is only available via the generators API\r\n    * There is a lot of duplicate code in the generators path\r\n    \r\n    It adds two new methods to RecordBatchFileReader:\r\n    \r\n    ```\r\n      /// \\brief Begin loading metadata for the desired batches into memory.\r\n     ///\r\n     /// This method will also begin loading all dictionaries messages into memory.\r\n     ///\r\n     /// For a regular file this will immediately begin disk I/O in the background on a\r\n     /// thread on the IOContext's thread pool.  If the file is memory mapped this will\r\n     /// ensure the memory needed for the metadata is paged from disk into memory\r\n     ///\r\n     /// \\param indices Indices of the batches to prefetch\r\n     ///                If empty then all batches will be prefetched.\r\n     virtual Status WillNeedMetadata(const std::vector<int>& indices) = 0;\r\n   \r\n     /// \\brief Begin loading metadata for the desired batches into memory and indicate\r\n     ///        that the data itself should be prefetched when it is requested\r\n     ///\r\n     /// This method should not be called in combination with WillNeedMetadata.  If you want\r\n     /// to prefetch the data then use this method.  If you do not want to prefetch the data\r\n     /// (because you are only accessing a small # of items in the batch's arrays) then you\r\n     /// should use WillNeedMetadata\r\n     ///\r\n     /// This method will immediately start the I/O for the metadata and dictionaries.\r\n     ///\r\n     /// This method will not immediately start the I/O for the data.  The data I/O will be\r\n     /// started when you call ReadRecordBatch.\r\n     ///\r\n     /// If you want to read multiple batches in parallel then you can make concurrent calls\r\n     /// to ReadRecordBatch or ReadRecordBatchAsync\r\n     /// \\param indices\r\n     /// \\return\r\n     virtual Status WillNeedBatches(const std::vector<int>& indices) = 0;\r\n   ```\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-05T19:34:18.250+0000",
                    "updated": "2021-11-05T19:34:18.250+0000",
                    "started": "2021-11-05T19:34:18.249+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "677294",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/677337",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-961596136\n\n\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-05T19:38:58.773+0000",
                    "updated": "2021-11-05T19:38:58.773+0000",
                    "started": "2021-11-05T19:38:58.772+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "677337",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/677685",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace opened a new pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616\n\n\n   **This is still very much a WIP**\r\n   \r\n   This PR attempts to address several issues:\r\n   \r\n    * Memory mapped IPC reads always call WillNeed on the data and the user has no way to avoid this\r\n    * Projection pushdown is only available in the synchronous API\r\n    * Coalescing / readahead is only available via the generators API\r\n    * There is a lot of duplicate code in the generators path\r\n    \r\n    It adds two new methods to RecordBatchFileReader:\r\n    \r\n    ```\r\n      /// \\brief Begin loading metadata for the desired batches into memory.\r\n     ///\r\n     /// This method will also begin loading all dictionaries messages into memory.\r\n     ///\r\n     /// For a regular file this will immediately begin disk I/O in the background on a\r\n     /// thread on the IOContext's thread pool.  If the file is memory mapped this will\r\n     /// ensure the memory needed for the metadata is paged from disk into memory\r\n     ///\r\n     /// \\param indices Indices of the batches to prefetch\r\n     ///                If empty then all batches will be prefetched.\r\n     virtual Status WillNeedMetadata(const std::vector<int>& indices) = 0;\r\n   \r\n     /// \\brief Begin loading metadata for the desired batches into memory and indicate\r\n     ///        that the data itself should be prefetched when it is requested\r\n     ///\r\n     /// This method should not be called in combination with WillNeedMetadata.  If you want\r\n     /// to prefetch the data then use this method.  If you do not want to prefetch the data\r\n     /// (because you are only accessing a small # of items in the batch's arrays) then you\r\n     /// should use WillNeedMetadata\r\n     ///\r\n     /// This method will immediately start the I/O for the metadata and dictionaries.\r\n     ///\r\n     /// This method will not immediately start the I/O for the data.  The data I/O will be\r\n     /// started when you call ReadRecordBatch.\r\n     ///\r\n     /// If you want to read multiple batches in parallel then you can make concurrent calls\r\n     /// to ReadRecordBatch or ReadRecordBatchAsync\r\n     /// \\param indices\r\n     /// \\return\r\n     virtual Status WillNeedBatches(const std::vector<int>& indices) = 0;\r\n   ```\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-05T20:25:42.528+0000",
                    "updated": "2021-11-05T20:25:42.528+0000",
                    "started": "2021-11-05T20:25:42.528+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "677685",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/677723",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-961596136\n\n\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-05T20:30:10.654+0000",
                    "updated": "2021-11-05T20:30:10.654+0000",
                    "started": "2021-11-05T20:30:10.654+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "677723",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/690439",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-985970975\n\n\n   This is ready for review but at the moment the performance is worse in the micro-benchmark.  The micro-benchmark is dealing with a 1MB in-memory file so my guess is the fact that we have to make more read calls for partial reads is hurting.  I will try it again with larger files with memory contention and with disk I/O to see if that changes anything.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-04T05:19:19.513+0000",
                    "updated": "2021-12-04T05:19:19.513+0000",
                    "started": "2021-12-04T05:19:19.513+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "690439",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/692190",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-988441083\n\n\n   I fixed up the benchmarks somewhat and added a benchmark for cold I/O.  Initial results are a bit noisy:\r\n   \r\n   ```\r\n   ReadRealFile/1/0/real_time_mean                          +0.1096         +0.0203     882364277     979101124     141562817     144432381\r\n   ReadRealFile/4/0/real_time_mean                          +0.1379         -0.0096    1014012277    1153867283     141160362     139811386\r\n   ReadRealFile/16/0/real_time_mean                         -0.0303         +0.0033     900165884     872914568     143141575     143615607\r\n   ReadRealFile/64/0/real_time_mean                         -0.1049         +0.0007    1154140298    1033116675     140212506     140312232\r\n   ReadRealFile/256/0/real_time_mean                        +0.0990         +0.0239    1036406449    1138971720     149655837     153234293\r\n   ReadRealFile/1024/0/real_time_mean                       +0.0572         +0.0509     841348002     889506548     160709304     168895957\r\n   ReadRealFile/4096/0/real_time_mean                       -0.0244         +0.0147    1040310983    1014902847     269116155     273081737\r\n   ReadRealFile/8192/0/real_time_mean                       +0.1152         +0.0127    1073965563    1197736789     388846023     393793665\r\n   ReadRealFile/1/1/real_time_mean                          -0.0211         -0.0686     852270837     834276010     146015520     136002655\r\n   ReadRealFile/4/1/real_time_mean                          -0.0477         -0.0025     444691103     423473671      53215988      53082698\r\n   ReadRealFile/16/1/real_time_mean                         +1.5411         -0.1796     172459194     438231423      29137200      23905451\r\n   ReadRealFile/64/1/real_time_mean                         -0.1627         -0.0478    1004655612     841218794      35870849      34156124\r\n   ReadRealFile/256/1/real_time_mean                        +0.0982         -0.0181     897612093     985737042      63828576      62673771\r\n   ReadRealFile/1024/1/real_time_mean                       +0.2167         +0.5705    1020315892    1241371726      84622012     132899024\r\n   ReadRealFile/4096/1/real_time_mean                       -0.2797         -0.1929    1209181656     871000618      71425702      57648840\r\n   ReadRealFile/8192/1/real_time_mean                       +0.2138         +0.3822     938647868    1139351095     159262940     220134001\r\n   ReadRealFileAsync/1/0/real_time_mean                     +0.3462         +0.3408     906170613    1219925626       2299242       3082930\r\n   ReadRealFileAsync/4/0/real_time_mean                     -0.1024         +0.3570    1124871244    1009668198       2312991       3138757\r\n   ReadRealFileAsync/16/0/real_time_mean                    +0.2950         +0.5326     846347457    1096059130       2476560       3795647\r\n   ReadRealFileAsync/64/0/real_time_mean                    +0.0606         +0.8470    1225185369    1299444655       2964952       5476138\r\n   ReadRealFileAsync/256/0/real_time_mean                   -0.0583         +1.6426    1091256184    1027624433       4635198      12249101\r\n   ReadRealFileAsync/1024/0/real_time_mean                  +0.2313         +2.2223     925963093    1140141694      11659770      37571048\r\n   ReadRealFileAsync/4096/0/real_time_mean                  +0.2538         +1.0950     981474329    1230572649      46248110      96890904\r\n   ReadRealFileAsync/8192/0/real_time_mean                  -0.2438         +1.0463    1352917947    1023135386      86818642     177659883\r\n   ReadRealFileAsync/1/1/real_time_mean                     +0.2791         +0.7906     856795160    1095885713       2013025       3604501\r\n   ReadRealFileAsync/4/1/real_time_mean                     -0.6628         +7.4180    1022300282     344763011       2321308      19540718\r\n   ReadRealFileAsync/16/1/real_time_mean                    -0.8603         +5.4649    1240246020     173301490       2479652      16030715\r\n   ReadRealFileAsync/64/1/real_time_mean                    -0.1437         +6.2582     852187403     729739446       2156059      15649018\r\n   ReadRealFileAsync/256/1/real_time_mean                   +0.1711         +6.8878    1059134316    1240323095       2993556      23612644\r\n   ReadRealFileAsync/1024/1/real_time_mean                  +0.1014         +8.6551    1091676930    1202395405       4424422      42718098\r\n   ReadRealFileAsync/4096/1/real_time_mean                  +0.5519         +6.7698    1042589081    1618010814       8712906      67697324\r\n   ReadRealFileAsync/8192/1/real_time_mean                  -0.2005         +4.6431    1307820760    1045555603      17304062      97648656\r\n   ```\r\n   \r\n   There is a substantial improvement in the partial-column read async case (ReadRealFileAsync/num_cols/1) at 4/16 columns.  I'm not sure why that falls away as the number of columns increases so I need to investigate that still.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-08T02:32:03.656+0000",
                    "updated": "2021-12-08T02:32:03.656+0000",
                    "started": "2021-12-08T02:32:03.655+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "692190",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/692214",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-988474850\n\n\n   At a macro level at least it seems there is some benefit, but definitely some strange behaviors going on:\r\n   \r\n   ![async](https://user-images.githubusercontent.com/1696093/145145405-3e1b6ebf-35e5-456d-b299-4625e82ed775.png)\r\n   ![old](https://user-images.githubusercontent.com/1696093/145145409-859f8a57-36d7-4f21-9765-8cd50e4bf67d.png)\r\n   ![sync](https://user-images.githubusercontent.com/1696093/145145411-297350d5-d11a-4a1c-8b54-c7d1751912a8.png)\r\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-08T03:54:09.919+0000",
                    "updated": "2021-12-08T03:54:09.919+0000",
                    "started": "2021-12-08T03:54:09.918+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "692214",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/692215",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace removed a comment on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-988474850\n\n\n   At a macro level at least it seems there is some benefit, but definitely some strange behaviors going on:\r\n   \r\n   ![async](https://user-images.githubusercontent.com/1696093/145145405-3e1b6ebf-35e5-456d-b299-4625e82ed775.png)\r\n   ![old](https://user-images.githubusercontent.com/1696093/145145409-859f8a57-36d7-4f21-9765-8cd50e4bf67d.png)\r\n   ![sync](https://user-images.githubusercontent.com/1696093/145145411-297350d5-d11a-4a1c-8b54-c7d1751912a8.png)\r\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-08T03:55:22.789+0000",
                    "updated": "2021-12-08T03:55:22.789+0000",
                    "started": "2021-12-08T03:55:22.788+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "692215",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/692216",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-988475534\n\n\n   (fixed charts).  There is some benefit at the macro-level.  These are hot I/O reads which explains why we are able to see some parallelism:\r\n   \r\n   ![async](https://user-images.githubusercontent.com/1696093/145145590-1167fc33-6d81-4545-b70f-03d5a539db0a.png)\r\n   ![old](https://user-images.githubusercontent.com/1696093/145145591-7da6c6be-33f6-4583-901d-a056b4cd181e.png)\r\n   ![sync](https://user-images.githubusercontent.com/1696093/145145593-11be46a0-060a-4918-b9da-724fee6ffd14.png)\r\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-08T03:55:55.996+0000",
                    "updated": "2021-12-08T03:55:55.996+0000",
                    "started": "2021-12-08T03:55:55.996+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "692216",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/692217",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-988477261\n\n\n   Similar results with cold I/O\r\n   ![async-cold](https://user-images.githubusercontent.com/1696093/145146046-2dd47ccb-60d0-4bad-aa6b-60a260d7f324.png)\r\n   ![old-cold](https://user-images.githubusercontent.com/1696093/145146049-dad8da50-2256-4847-a963-3709bb8f5e76.png)\r\n   ![sync-cold](https://user-images.githubusercontent.com/1696093/145146052-5af140ae-b919-4a24-92e0-ad0105d270ec.png)\r\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-08T04:00:45.834+0000",
                    "updated": "2021-12-08T04:00:45.834+0000",
                    "started": "2021-12-08T04:00:45.833+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "692217",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/692808",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-989103386\n\n\n   Out of curiosity, how does this affect S3 performance? (Or simulated S3 via Minio/toxiproxy which would probably be less variable.)\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-08T18:57:15.378+0000",
                    "updated": "2021-12-08T18:57:15.378+0000",
                    "started": "2021-12-08T18:57:15.378+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "692808",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/694177",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#discussion_r766761232\n\n\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       Hmm, the reads are not consolidated because they're too large or too far apart?\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_benchmark.cc\n##########\n@@ -49,9 +51,29 @@ std::shared_ptr<RecordBatch> MakeRecordBatch(int64_t total_size, int64_t num_fie\n   return RecordBatch::Make(schema, length, arrays);\n }\n \n+std::vector<int> GetIncludedFields(int64_t num_fields, int64_t is_partial_read) {\n+  if (is_partial_read) {\n+    std::vector<int> field_indices;\n+    for (int i = 0; i < num_fields; i += 8) {\n+      field_indices.push_back(i);\n+    }\n+    return field_indices;\n+  } else {\n+    return std::vector<int>();\n+  }\n+}\n+\n+int64_t BytesPerIteration(int64_t num_fields, int64_t is_partial_read, int64_t batch_size, int64_t num_batches) {\n+  std::size_t num_actual_fields = GetIncludedFields(num_fields, is_partial_read).size();\n+  double selectivity = num_actual_fields / static_cast<double>(num_fields);\n+  if (num_actual_fields == 0) selectivity = 1;\n+  auto bytes = batch_size * num_batches * selectivity;\n+  return static_cast<int64_t>(bytes);\n+}\n+\n static void WriteRecordBatch(benchmark::State& state) {  // NOLINT non-const reference\n   // 1MB\n-  constexpr int64_t kTotalSize = 1 << 20;\n+  constexpr int64_t kTotalSize = 1 << 23;\n\nReview comment:\n       Changing the size will effectively invalidate previous benchmark numbers right?\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       Ah, I see now - metadata and data are always read separately to support column selection. I wonder if it'd be worth also optimizing for when no column selection is done.\n\n##########\nFile path: cpp/src/arrow/ipc/reader.cc\n##########\n@@ -147,6 +172,16 @@ class ArrayLoader {\n       : metadata_(metadata),\n         metadata_version_(metadata_version),\n         file_(file),\n+        offset_(0),\n\nReview comment:\n       Maybe `file_offset_`? My first instinct would be array offset\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n\nReview comment:\n       This could be filed for a later JIRA, but we could perhaps skip one read by speculatively reading (say) 1 MB of the footer instead of reading the footer size and footer separately.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-10T19:14:32.984+0000",
                    "updated": "2021-12-10T19:14:32.984+0000",
                    "started": "2021-12-10T19:14:32.984+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694177",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/694185",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#discussion_r766935036\n\n\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       It probably is a good idea since the metadata reads are so small, I figure we can defer that for a future PR.  If we really want to maximize performance It might be interesting to evaluate a file-only (non-streaming) variant where all the metadata is at the end of the file.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-10T19:41:09.870+0000",
                    "updated": "2021-12-10T19:41:09.870+0000",
                    "started": "2021-12-10T19:41:09.869+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694185",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/694186",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#discussion_r766935359\n\n\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       Although in the few-columns case it might not make that much of a difference\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-10T19:41:42.621+0000",
                    "updated": "2021-12-10T19:41:42.621+0000",
                    "started": "2021-12-10T19:41:42.621+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694186",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/694187",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#discussion_r766936170\n\n\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_benchmark.cc\n##########\n@@ -49,9 +51,29 @@ std::shared_ptr<RecordBatch> MakeRecordBatch(int64_t total_size, int64_t num_fie\n   return RecordBatch::Make(schema, length, arrays);\n }\n \n+std::vector<int> GetIncludedFields(int64_t num_fields, int64_t is_partial_read) {\n+  if (is_partial_read) {\n+    std::vector<int> field_indices;\n+    for (int i = 0; i < num_fields; i += 8) {\n+      field_indices.push_back(i);\n+    }\n+    return field_indices;\n+  } else {\n+    return std::vector<int>();\n+  }\n+}\n+\n+int64_t BytesPerIteration(int64_t num_fields, int64_t is_partial_read, int64_t batch_size, int64_t num_batches) {\n+  std::size_t num_actual_fields = GetIncludedFields(num_fields, is_partial_read).size();\n+  double selectivity = num_actual_fields / static_cast<double>(num_fields);\n+  if (num_actual_fields == 0) selectivity = 1;\n+  auto bytes = batch_size * num_batches * selectivity;\n+  return static_cast<int64_t>(bytes);\n+}\n+\n static void WriteRecordBatch(benchmark::State& state) {  // NOLINT non-const reference\n   // 1MB\n-  constexpr int64_t kTotalSize = 1 << 20;\n+  constexpr int64_t kTotalSize = 1 << 23;\n\nReview comment:\n       Yes, fair point.  Maybe the benchmark changes can be peeled off onto their own PR first so we have some time for the newer numbers to stabilize before we actually change any code.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-10T19:43:06.162+0000",
                    "updated": "2021-12-10T19:43:06.162+0000",
                    "started": "2021-12-10T19:43:06.161+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694187",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/694541",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#discussion_r766935036\n\n\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       It probably is a good idea since the metadata reads are so small, I figure we can defer that for a future PR.  If we really want to maximize performance It might be interesting to evaluate a file-only (non-streaming) variant where all the metadata is at the end of the file.\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       Although in the few-columns case it might not make that much of a difference\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_benchmark.cc\n##########\n@@ -49,9 +51,29 @@ std::shared_ptr<RecordBatch> MakeRecordBatch(int64_t total_size, int64_t num_fie\n   return RecordBatch::Make(schema, length, arrays);\n }\n \n+std::vector<int> GetIncludedFields(int64_t num_fields, int64_t is_partial_read) {\n+  if (is_partial_read) {\n+    std::vector<int> field_indices;\n+    for (int i = 0; i < num_fields; i += 8) {\n+      field_indices.push_back(i);\n+    }\n+    return field_indices;\n+  } else {\n+    return std::vector<int>();\n+  }\n+}\n+\n+int64_t BytesPerIteration(int64_t num_fields, int64_t is_partial_read, int64_t batch_size, int64_t num_batches) {\n+  std::size_t num_actual_fields = GetIncludedFields(num_fields, is_partial_read).size();\n+  double selectivity = num_actual_fields / static_cast<double>(num_fields);\n+  if (num_actual_fields == 0) selectivity = 1;\n+  auto bytes = batch_size * num_batches * selectivity;\n+  return static_cast<int64_t>(bytes);\n+}\n+\n static void WriteRecordBatch(benchmark::State& state) {  // NOLINT non-const reference\n   // 1MB\n-  constexpr int64_t kTotalSize = 1 << 20;\n+  constexpr int64_t kTotalSize = 1 << 23;\n\nReview comment:\n       Yes, fair point.  Maybe the benchmark changes can be peeled off onto their own PR first so we have some time for the newer numbers to stabilize before we actually change any code.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T05:56:55.234+0000",
                    "updated": "2021-12-12T05:56:55.234+0000",
                    "started": "2021-12-12T05:56:55.234+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694541",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/694571",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#discussion_r766761232\n\n\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       Hmm, the reads are not consolidated because they're too large or too far apart?\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_benchmark.cc\n##########\n@@ -49,9 +51,29 @@ std::shared_ptr<RecordBatch> MakeRecordBatch(int64_t total_size, int64_t num_fie\n   return RecordBatch::Make(schema, length, arrays);\n }\n \n+std::vector<int> GetIncludedFields(int64_t num_fields, int64_t is_partial_read) {\n+  if (is_partial_read) {\n+    std::vector<int> field_indices;\n+    for (int i = 0; i < num_fields; i += 8) {\n+      field_indices.push_back(i);\n+    }\n+    return field_indices;\n+  } else {\n+    return std::vector<int>();\n+  }\n+}\n+\n+int64_t BytesPerIteration(int64_t num_fields, int64_t is_partial_read, int64_t batch_size, int64_t num_batches) {\n+  std::size_t num_actual_fields = GetIncludedFields(num_fields, is_partial_read).size();\n+  double selectivity = num_actual_fields / static_cast<double>(num_fields);\n+  if (num_actual_fields == 0) selectivity = 1;\n+  auto bytes = batch_size * num_batches * selectivity;\n+  return static_cast<int64_t>(bytes);\n+}\n+\n static void WriteRecordBatch(benchmark::State& state) {  // NOLINT non-const reference\n   // 1MB\n-  constexpr int64_t kTotalSize = 1 << 20;\n+  constexpr int64_t kTotalSize = 1 << 23;\n\nReview comment:\n       Changing the size will effectively invalidate previous benchmark numbers right?\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n+\n+class PreBufferingTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    file_buffer_ = MakeBooleanInt32Int64File(kRowsPerBatch, kNumBatches);\n+  }\n+\n+  void OpenReader() {\n+    buffer_reader_ = make_unique<io::BufferReader>(file_buffer_);\n+    tracked_ = std::make_shared<TrackedRandomAccessFile>(buffer_reader_.get());\n+    auto read_options = IpcReadOptions::Defaults();\n+    if (ReadsArePlugged()) {\n+      // This will ensure that all reads get globbed together into one large read\n+      read_options.pre_buffer_cache_options.hole_size_limit =\n+          std::numeric_limits<int64_t>::max() - 1;\n+      read_options.pre_buffer_cache_options.range_size_limit =\n+          std::numeric_limits<int64_t>::max();\n+    }\n+    ASSERT_OK_AND_ASSIGN(reader_, RecordBatchFileReader::Open(tracked_, read_options));\n+  }\n+\n+  bool ReadsArePlugged() { return GetParam(); }\n+\n+  std::vector<int> AllBatchIndices() {\n+    std::vector<int> all_batch_indices(kNumBatches);\n+    std::iota(all_batch_indices.begin(), all_batch_indices.end(), 0);\n+    return all_batch_indices;\n+  }\n+\n+  void AssertMetadataLoaded(std::vector<int> batch_indices) {\n+    if (batch_indices.size() == 0) {\n+      batch_indices = AllBatchIndices();\n+    }\n+    const auto& read_ranges = tracked_->get_read_ranges();\n+    if (ReadsArePlugged()) {\n+      // The read should have arrived as one large read\n+      ASSERT_EQ(kNumReadsOnOpen + 1, read_ranges.size());\n+      if (batch_indices.size() > 1) {\n+        ASSERT_GT(read_ranges[kNumReadsOnOpen].length, kMaxMetadataSizeBytes);\n+      }\n+    } else {\n+      // We should get many small reads of metadata only\n+      ASSERT_EQ(batch_indices.size() + kNumReadsOnOpen, read_ranges.size());\n+      for (const auto& read_range : read_ranges) {\n+        ASSERT_LT(read_range.length, kMaxMetadataSizeBytes);\n+      }\n+    }\n+  }\n+\n+  std::vector<std::shared_ptr<RecordBatch>> LoadExpected() {\n+    auto buffer_reader = make_unique<io::BufferReader>(file_buffer_);\n+    auto read_options = IpcReadOptions::Defaults();\n+    EXPECT_OK_AND_ASSIGN(auto reader,\n+                         RecordBatchFileReader::Open(buffer_reader.get(), read_options));\n+    std::vector<std::shared_ptr<RecordBatch>> expected_batches;\n+    for (int i = 0; i < reader->num_record_batches(); i++) {\n+      EXPECT_OK_AND_ASSIGN(auto expected_batch, reader->ReadRecordBatch(i));\n+      expected_batches.push_back(expected_batch);\n+    }\n+    return expected_batches;\n+  }\n+\n+  void CheckFileRead(int num_indices_pre_buffered) {\n+    auto expected_batches = LoadExpected();\n+    const std::vector<io::ReadRange>& read_ranges = tracked_->get_read_ranges();\n+    std::size_t starting_reads = read_ranges.size();\n+    for (int i = 0; i < reader_->num_record_batches(); i++) {\n+      ASSERT_OK_AND_ASSIGN(auto next_batch, reader_->ReadRecordBatch(i));\n+      AssertBatchesEqual(*expected_batches[i], *next_batch);\n+    }\n+    int metadata_reads = 0;\n+    int data_reads = 0;\n+    for (std::size_t i = starting_reads; i < read_ranges.size(); i++) {\n+      if (read_ranges[i].length > kMaxMetadataSizeBytes) {\n\nReview comment:\n       Ah, I see now - metadata and data are always read separately to support column selection. I wonder if it'd be worth also optimizing for when no column selection is done.\n\n##########\nFile path: cpp/src/arrow/ipc/reader.cc\n##########\n@@ -147,6 +172,16 @@ class ArrayLoader {\n       : metadata_(metadata),\n         metadata_version_(metadata_version),\n         file_(file),\n+        offset_(0),\n\nReview comment:\n       Maybe `file_offset_`? My first instinct would be array offset\n\n##########\nFile path: cpp/src/arrow/ipc/read_write_test.cc\n##########\n@@ -2715,6 +2727,133 @@ TEST(TestRecordBatchFileReaderIo, ReadTwoContinousFieldsWithIoMerged) {\n   GetReadRecordBatchReadRanges(64, {0, 1}, {8 + 64 * 4});\n }\n \n+constexpr static int kNumBatches = 10;\n+// It can be difficult to know the exact size of the schema.  Instead we just make the\n+// row data big enough that we can easily identify if a read is for a schema or for\n+// row data.\n+//\n+// This needs to be large enough to space record batches kDefaultHoleSizeLimit bytes apart\n+// and also large enough that record batch data is more than kMaxMetadataSizeBytes bytes\n+constexpr static int kRowsPerBatch = 1000;\n+constexpr static int64_t kMaxMetadataSizeBytes = 1 << 13;\n+// There are always 2 reads when the file is opened\n+constexpr static int kNumReadsOnOpen = 2;\n\nReview comment:\n       This could be filed for a later JIRA, but we could perhaps skip one read by speculatively reading (say) 1 MB of the footer instead of reading the footer size and footer separately.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T05:59:54.711+0000",
                    "updated": "2021-12-12T05:59:54.711+0000",
                    "started": "2021-12-12T05:59:54.711+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694571",
                    "issueId": "13409890"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/worklog/696995",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #11616:\nURL: https://github.com/apache/arrow/pull/11616#issuecomment-995349558\n\n\n   I dug into the performance a bit more for the small files case (I'll do S3 soon but I think I want to do real S3 and not minio since the former supports parallelism and the latter, attached to my HDD, does not).\r\n   \r\n   Note: Asynchronous readers in these tests are not being consumed in parallel.  So we wait until batch is returned before reading the next batch.  However, asynchronous readers still issue parallel reads and use threads.  Reading a single batch that needs 8 columns will trigger 8 parallel reads.\r\n   \r\n   Note: Even the synchronous reader will use parallel reads if only a subset of the columns are targeted.  It will use the IoRecordedRandomAccessFile which then uses the read range cache which performs reads in parallel. \r\n   \r\n   ### Hot In-Memory Memory Mapped (also, arrow::io::BufferReader)\r\n   \r\n   Asynchronous reads should never be used in this case.  A \"read\" is just pointer arithmetic.  There are no copies.  I didn't benchmark this case.\r\n   \r\n   ### Cold On-Disk Memory Mapped\r\n   \r\n   I did not test this.  I'm not sure if it is an interesting case or not.\r\n   \r\n   ### Hot In-Memory Regular File\r\n   \r\n   Cherry picking some interesting cases (note the rate here is based on the total buffer size of the selected columns.  So selecting fewer columns shouldn't yield a higher rate).\r\n   \r\n   | Sync/Async | # of columns | # of columns selected | Rate (Bps) | Note |\r\n   | - | - | - | - | - |\r\n   | Sync | 16 | 16 | 9.79967G/s | Seems a limit on my machine for 1-thread DRAM bandwidth |\r\n   | Sync | 16 | 2 | 12.8979G/s | Parallel reads increase DRAM bandwidth |\r\n   | Sync | 256 | 256 | 8.73684G/s | Starting to hit CPU bottleneck from excess metadata |\r\n   | Sync | 256 | 32 | 7.28792G/s | Since we are throttled on metadata / CPU, perf gets worse |\r\n   | Async | 16 | 16 | 2.58248G/s | Async is quite a bit worse than baseline for full reads |\r\n   | Async | 16 | 2 | 13.9343G/s | Async perf is similar on partial reads |\r\n   | Async | 256 | 256 | 2.4068G/s | |\r\n   | Async | 256 | 32 | 6.8774G/s | |\r\n   | Old-Async | 16 | 16 | 2.84301G/s | Old implementation has slightly lower overhead I think |\r\n   | Old-Async | 16 | 2 | 556.501M/s | Old implementation does not handle partial reads well |\r\n   | Old-Async | 256 | 256 | 2.78802G/s | |\r\n   | Old-Async | 256 | 32 | 459.484M/s | |\r\n   \r\n   Conclusions: This change significnatly improves performance of partial async reads to the point where partial async reads on \"well-formed\" files (data >> metadata) is comparable to sync partial read.\r\n   \r\n   Async full read is still considerably worse than async full read which is surprising but possibly due to threading overhead.  This is worth investigating in a future PR.\r\n   \r\n   ### Cold In-Memory Regular File\r\n   \r\n   | Sync/Async | # of columns | # of columns selected | Rate (bps) | Note |\r\n   | - | - | - | - | - |\r\n   | Sync | 16 | 16 | 111.044M/s | Baseline, HDD throughput |\r\n   | Sync | 16 | 2 | 25.205M/s | Surprising, more below |\r\n   | Sync | 256 | 256 | 99.8336M/s | |\r\n   | Sync | 256 | 32 | 15.2597M/s | Surprising |\r\n   | Async | 16 | 16 | 98.5425M/s | Similar to sync, within noise but did consistently seem a bit lower |\r\n   | Async | 16 | 2 | 54.1136M/s | |\r\n   | Async | 256 | 256 | 96.5957M/s |\r\n   | Async | 256 | 32 | 11.911M/s | Within noise of sync result actually, seems to bottom out around a noisy 10-16 |\r\n   | Old-Async | 16 | 16 | 138.266M/s | Not just noise, old async real-file is consistently better than sync |\r\n   | Old-Async | 16 | 2 | 17.4384M/s | |\r\n   | Old-Async | 256 | 256 | 123.721M/s | |\r\n   | Old-Async | 256 | 32 | 16.4605M/s | |\r\n   \r\n   Conclusions: This change does improve performance of partial async reads.  However, it seems to come at a cost of full async reads.  David's suggest to falling back to a full file read should alleviate this.\r\n   \r\n   In all cases the performance of partial reads deteriorates quickly.  This is because we are essentially falling back to either \"reading too much\" (Old-Async) or random reads.  The random read rate lines up with using `fio` to benchmark my disk.  At 16 batches the data blocks are 520KB and with `fio` random reads@520KB ~ 45MBps.  At 256 batches the data blocks are 32k and with `fio` I get ~4MBps (either `fio` is too pessimistic or we are able to take advantage of the pseudo-sequential nature of the reads).\r\n   \r\n   ### Remaining tasks\r\n   \r\n   - [ ] Add fallback to full-file read for async\r\n   - [ ] Investigate S3\r\n   - [ ] Investigate multi-threaded local reads (both multiple files and consuming in parallel)\r\n   - [ ] Recommend that users should structure record batches so that each column contains at least 4MB of data if they plan to be reading from disk.\r\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-16T01:12:04.988+0000",
                    "updated": "2021-12-16T01:12:04.988+0000",
                    "started": "2021-12-16T01:12:04.988+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "696995",
                    "issueId": "13409890"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 29400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@1808557[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1a498114[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4555fa3f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@13c292a0[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2c070fc1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@3f44ff3e[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@552a7eeb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@52faa17c[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4617d5e5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@5eb27f16[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@58e99f0d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@5f9f242d[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 29400,
        "customfield_12312520": null,
        "customfield_12312521": "Sat Jan 15 00:13:08 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-01-15T00:13:08.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-14577/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2021-11-03T14:50:49.000+0000",
        "updated": "2022-04-20T14:09:02.000+0000",
        "timeoriginalestimate": null,
        "description": "The IPC reader operates at the granularity of an entire record batch; even if you're loading only a few columns, the entire record batch is read. ARROW-12683 partially addressed this issue by enabling this capability for sync read API, however, async read API still lacks of this capability.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "8h 10m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 29400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Enable fine grained IO for async IPC reader ",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/comment/17438115",
                    "id": "17438115",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "We should also combine it with the I/O coalescer.\r\n\r\nCC [~westonpace] who I believe is looking into this already.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-11-03T14:51:33.934+0000",
                    "updated": "2021-11-03T14:51:33.934+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/comment/17438116",
                    "id": "17438116",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Thanks for filing the follow up ticket!",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-11-03T14:51:45.785+0000",
                    "updated": "2021-11-03T14:51:45.785+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13409890/comment/17476486",
                    "id": "17476486",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 11616\n[https://github.com/apache/arrow/pull/11616]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-01-15T00:13:08.154+0000",
                    "updated": "2022-01-15T00:13:08.154+0000"
                }
            ],
            "maxResults": 3,
            "total": 3,
            "startAt": 0
        },
        "customfield_12311820": "0|z0wezc:",
        "customfield_12314139": null
    }
}