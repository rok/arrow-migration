{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13401027",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027",
    "key": "ARROW-13993",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351051",
                "id": "12351051",
                "description": "",
                "name": "8.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-05-06"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "good-second-issue",
            "kernel",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12623305",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12623305",
                "type": {
                    "id": "10032",
                    "name": "Blocker",
                    "inward": "is blocked by",
                    "outward": "blocks",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"
                },
                "outwardIssue": {
                    "id": "13402304",
                    "key": "ARROW-14045",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13402304",
                    "fields": {
                        "summary": "[R] Support for .keep_all = TRUE with distinct() ",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/3",
                            "description": "This issue is being actively worked on at the moment by the assignee.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/inprogress.png",
                            "name": "In Progress",
                            "id": "3",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/4",
                                "id": 4,
                                "key": "indeterminate",
                                "colorName": "yellow",
                                "name": "In Progress"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12633860",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12633860",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13429135",
                    "key": "ARROW-15717",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13429135",
                    "fields": {
                        "summary": "[Docs] Add hash_one to the documentation",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=dhruv9vats",
            "name": "dhruv9vats",
            "key": "dhruv9vats",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
            },
            "displayName": "Dhruv Vats",
            "active": true,
            "timeZone": "Asia/Kolkata"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
            "name": "icook",
            "key": "icook",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
            },
            "displayName": "Ian Cook",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
            "name": "icook",
            "key": "icook",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
            },
            "displayName": "Ian Cook",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 21000,
            "total": 21000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 21000,
            "total": 21000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13993/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 35,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/722863",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats opened a new pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368\n\n\n   Add a hash aggregate function that returns one value from each group.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-08T14:13:21.684+0000",
                    "updated": "2022-02-08T14:13:21.684+0000",
                    "started": "2022-02-08T14:13:21.683+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "722863",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/722864",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#issuecomment-1032653864\n\n\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-08T14:13:56.002+0000",
                    "updated": "2022-02-08T14:13:56.002+0000",
                    "started": "2022-02-08T14:13:56.002+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "722864",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/722866",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r801678902\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,92 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+struct GroupedOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    pool_ = ctx->memory_pool();\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    ARROW_ASSIGN_OR_RAISE(std::ignore, grouper_->Consume(batch));\n+    return Status::OK();\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    // Get (value, group_id) pairs, then translate the group IDs and consume them\n+    // ourselves\n+    ARROW_ASSIGN_OR_RAISE(auto uniques, other->grouper_->GetUniques());\n+    ARROW_ASSIGN_OR_RAISE(auto remapped_g,\n+                          AllocateBuffer(uniques.length * sizeof(uint32_t), pool_));\n+\n+    const auto* g_mapping = group_id_mapping.GetValues<uint32_t>(1);\n+    const auto* other_g = uniques[1].array()->GetValues<uint32_t>(1);\n+    auto* g = reinterpret_cast<uint32_t*>(remapped_g->mutable_data());\n+\n+    for (int64_t i = 0; i < uniques.length; i++) {\n+      g[i] = g_mapping[other_g[i]];\n+    }\n+    uniques.values[1] =\n+        ArrayData::Make(uint32(), uniques.length, {nullptr, std::move(remapped_g)});\n+\n+    return Consume(std::move(uniques));\n+  }\n+\n+  Result<Datum> Finalize() override {\n\nReview comment:\n       Most of the stuff is carryover from `DistinctCount`/`Distinct` as I don't fully understand their function (such as merge). Have added a basic test to confirm this is what we what. Also, have taken a naive `ArrayBuilder` approach to get this basics working. What would some better approaches be?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-08T14:18:30.730+0000",
                    "updated": "2022-02-08T14:18:30.730+0000",
                    "started": "2022-02-08T14:18:30.730+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "722866",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/722867",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r801678902\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,92 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+struct GroupedOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    pool_ = ctx->memory_pool();\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    ARROW_ASSIGN_OR_RAISE(std::ignore, grouper_->Consume(batch));\n+    return Status::OK();\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    // Get (value, group_id) pairs, then translate the group IDs and consume them\n+    // ourselves\n+    ARROW_ASSIGN_OR_RAISE(auto uniques, other->grouper_->GetUniques());\n+    ARROW_ASSIGN_OR_RAISE(auto remapped_g,\n+                          AllocateBuffer(uniques.length * sizeof(uint32_t), pool_));\n+\n+    const auto* g_mapping = group_id_mapping.GetValues<uint32_t>(1);\n+    const auto* other_g = uniques[1].array()->GetValues<uint32_t>(1);\n+    auto* g = reinterpret_cast<uint32_t*>(remapped_g->mutable_data());\n+\n+    for (int64_t i = 0; i < uniques.length; i++) {\n+      g[i] = g_mapping[other_g[i]];\n+    }\n+    uniques.values[1] =\n+        ArrayData::Make(uint32(), uniques.length, {nullptr, std::move(remapped_g)});\n+\n+    return Consume(std::move(uniques));\n+  }\n+\n+  Result<Datum> Finalize() override {\n\nReview comment:\n       Most of the stuff is carryover from `DistinctCount`/`Distinct` as I don't fully understand their function (such as `Merge`). Have added a basic test to confirm this is what we what. Also, have taken a naive `ArrayBuilder` approach to get this basics working. What would some better approaches be?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-08T14:18:53.165+0000",
                    "updated": "2022-02-08T14:18:53.165+0000",
                    "started": "2022-02-08T14:18:53.165+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "722867",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/722871",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r801678902\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,92 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+struct GroupedOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    pool_ = ctx->memory_pool();\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    ARROW_ASSIGN_OR_RAISE(std::ignore, grouper_->Consume(batch));\n+    return Status::OK();\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    // Get (value, group_id) pairs, then translate the group IDs and consume them\n+    // ourselves\n+    ARROW_ASSIGN_OR_RAISE(auto uniques, other->grouper_->GetUniques());\n+    ARROW_ASSIGN_OR_RAISE(auto remapped_g,\n+                          AllocateBuffer(uniques.length * sizeof(uint32_t), pool_));\n+\n+    const auto* g_mapping = group_id_mapping.GetValues<uint32_t>(1);\n+    const auto* other_g = uniques[1].array()->GetValues<uint32_t>(1);\n+    auto* g = reinterpret_cast<uint32_t*>(remapped_g->mutable_data());\n+\n+    for (int64_t i = 0; i < uniques.length; i++) {\n+      g[i] = g_mapping[other_g[i]];\n+    }\n+    uniques.values[1] =\n+        ArrayData::Make(uint32(), uniques.length, {nullptr, std::move(remapped_g)});\n+\n+    return Consume(std::move(uniques));\n+  }\n+\n+  Result<Datum> Finalize() override {\n\nReview comment:\n       Most of the stuff is carryover from `DistinctCount`/`Distinct` as I don't fully understand their function (such as `Merge`). Have added a basic test to confirm this is what we what. Also, have taken a naive `ArrayBuilder` approach to get the basics working. What would some better approaches be?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-08T14:27:33.903+0000",
                    "updated": "2022-02-08T14:27:33.903+0000",
                    "started": "2022-02-08T14:27:33.903+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "722871",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/723467",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "Crystrix commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r802311399\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,92 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+struct GroupedOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    pool_ = ctx->memory_pool();\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    ARROW_ASSIGN_OR_RAISE(std::ignore, grouper_->Consume(batch));\n+    return Status::OK();\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    // Get (value, group_id) pairs, then translate the group IDs and consume them\n+    // ourselves\n+    ARROW_ASSIGN_OR_RAISE(auto uniques, other->grouper_->GetUniques());\n+    ARROW_ASSIGN_OR_RAISE(auto remapped_g,\n+                          AllocateBuffer(uniques.length * sizeof(uint32_t), pool_));\n+\n+    const auto* g_mapping = group_id_mapping.GetValues<uint32_t>(1);\n+    const auto* other_g = uniques[1].array()->GetValues<uint32_t>(1);\n+    auto* g = reinterpret_cast<uint32_t*>(remapped_g->mutable_data());\n+\n+    for (int64_t i = 0; i < uniques.length; i++) {\n+      g[i] = g_mapping[other_g[i]];\n+    }\n+    uniques.values[1] =\n+        ArrayData::Make(uint32(), uniques.length, {nullptr, std::move(remapped_g)});\n+\n+    return Consume(std::move(uniques));\n+  }\n+\n+  Result<Datum> Finalize() override {\n\nReview comment:\n       I think the extra `grouper_` variable from `GroupedDistinctImpl` is not necessary as `hash_one` doesn't need to calculate distinct values. The struct of the `hash_one` can also learn from `GroupedMinMaxImpl`. In a way, `min/max` is a special case of `hash_one`.\r\n   \r\n   Like the `mins_` variable in `GroupedMinMaxImpl` which stores the min value of a group, we can have a similar variable to restore the values. Then the remaining operation should be similar to `GroupedMinMaxImpl` without value comparison. \r\n   \r\n   - `Consume` function, store the value for each group if the value doesn't exist.\r\n   - `Merge` function, add the values of new groups. \r\n   - `Finalize` function, output the values and groups, which is the same as `GroupedMinMaxImpl`.\r\n   \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-09T06:46:41.683+0000",
                    "updated": "2022-02-09T06:46:41.683+0000",
                    "started": "2022-02-09T06:46:41.683+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "723467",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/724486",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#issuecomment-1034907613\n\n\n   We don't need to support ScalarAggregateOptions here.\r\n   \r\n   If it's more manageable, you can split the support for variable-width types into a separate JIRA.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-10T13:13:09.574+0000",
                    "updated": "2022-02-10T13:13:09.574+0000",
                    "started": "2022-02-10T13:13:09.574+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "724486",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/725089",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r804579744\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2460,476 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+TEST(GroupBy, One) {\n\nReview comment:\n       This test can probably be deleted as tests below capture this.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2460,476 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                          field(\"hash_one\", float64()),\n+                                          field(\"hash_one\", null()),\n+                                          field(\"hash_one\", boolean()),\n+                                          field(\"key_0\", int64()),\n+                                      }),\n+                                      R\"([\n+    [1.0,  null, true,  1],\n+    [0.0,  null, false, 2],\n+    [null, null, false, 3],\n+    [4.0,  null, null,  null]\n+  ])\"),\n+                        aggregated_and_grouped,\n+                        /*verbose=*/true);\n+    }\n+  }\n+}\n+\n+TEST(GroupBy, OneTypes) {\n+  std::vector<std::shared_ptr<DataType>> types;\n+  types.insert(types.end(), NumericTypes().begin(), NumericTypes().end());\n+  types.insert(types.end(), TemporalTypes().begin(), TemporalTypes().end());\n+  types.push_back(month_interval());\n+\n+  const std::vector<std::string> default_table = {R\"([\n+    [1,    1],\n+    [null, 1]\n+])\",\n+                                                  R\"([\n+    [0,    2],\n+    [null, 3],\n+    [3,    4],\n+    [5,    4],\n+    [4,    null],\n+    [3,    1],\n+    [0,    2]\n+])\",\n+                                                  R\"([\n+    [0,    2],\n+    [1,    null],\n+    [null, 3]\n+])\"};\n+\n+  const std::vector<std::string> date64_table = {R\"([\n+    [86400000,  1],\n+    [null,      1]\n+])\",\n+                                                 R\"([\n+    [0,         2],\n+    [null,      3],\n+    [259200000, 4],\n+    [432000000, 4],\n+    [345600000, null],\n+    [259200000, 1],\n+    [0,         2]\n+])\",\n+                                                 R\"([\n+    [0,         2],\n+    [86400000,  null],\n+    [null,      3]\n+])\"};\n+\n+  const std::string default_expected =\n+      R\"([\n+    [1,    1],\n+    [0,    2],\n+    [null, 3],\n+    [3,    4],\n+    [4,    null]\n+    ])\";\n+\n+  const std::string date64_expected =\n+      R\"([\n+    [86400000,  1],\n+    [0,         2],\n+    [null,      3],\n+    [259200000, 4],\n+    [345600000, null]\n+    ])\";\n+\n+  for (const auto& ty : types) {\n+    SCOPED_TRACE(ty->ToString());\n+    auto in_schema = schema({field(\"argument0\", ty), field(\"key\", int64())});\n+    auto table =\n+        TableFromJSON(in_schema, (ty->name() == \"date64\") ? date64_table : default_table);\n+\n+    ASSERT_OK_AND_ASSIGN(\n+        Datum aggregated_and_grouped,\n+        GroupByTest({table->GetColumnByName(\"argument0\")},\n+                    {table->GetColumnByName(\"key\")}, {{\"hash_one\", nullptr}},\n+                    /*use_threads=*/false, /*use_exec_plan=*/true));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(\n+        ArrayFromJSON(struct_({\n+                          field(\"hash_one\", ty),\n+                          field(\"key_0\", int64()),\n+                      }),\n+                      (ty->name() == \"date64\") ? date64_expected : default_expected),\n+        aggregated_and_grouped,\n+        /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneDecimal) {\n+  auto in_schema = schema({\n+      field(\"argument0\", decimal128(3, 2)),\n+      field(\"argument1\", decimal256(3, 2)),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {/*true, */ false}) {\n\nReview comment:\n       The `true` option for `use_threads` is greyed out in all these test because, well, they run parallelly, and the way `hash_one` is currently implemented, when it encounters a value (null or otherwise) for a group for the first time, it stores that value and never updates it.\r\n   For example, in the table below, \r\n   - If we go serially, `[\"4.01\", \"4.01\",   null]` is the first row encountered which has `null` as its key. But,\r\n   - If we go parallelly, `[\"0.75\",  \"0.75\",  null]` is the first row encountered which has `null` as its key.\r\n   \r\n   And while this is totally expected, this is a bit tricky to test for in a single go. So should we test explicitly for both `use_threads` = `true` and `false`?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2460,476 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                          field(\"hash_one\", float64()),\n+                                          field(\"hash_one\", null()),\n+                                          field(\"hash_one\", boolean()),\n+                                          field(\"key_0\", int64()),\n+                                      }),\n+                                      R\"([\n+    [1.0,  null, true,  1],\n+    [0.0,  null, false, 2],\n+    [null, null, false, 3],\n+    [4.0,  null, null,  null]\n+  ])\"),\n+                        aggregated_and_grouped,\n+                        /*verbose=*/true);\n+    }\n+  }\n+}\n+\n+TEST(GroupBy, OneTypes) {\n\nReview comment:\n       Most of these tests are carried over from MinMax tests with appropriate modifications. Is that okay? Should some more tests also be added?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n\nReview comment:\n       These overloaded `MakeOffsetsValues` methods are identical between `GroupedOneImp` and `GroupedMinMaxImp`, should we consider making them helper functions?  \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-11T12:13:25.916+0000",
                    "updated": "2022-02-11T12:13:25.916+0000",
                    "started": "2022-02-11T12:13:25.915+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "725089",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/725150",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r804677914\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2460,476 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                          field(\"hash_one\", float64()),\n+                                          field(\"hash_one\", null()),\n+                                          field(\"hash_one\", boolean()),\n+                                          field(\"key_0\", int64()),\n+                                      }),\n+                                      R\"([\n+    [1.0,  null, true,  1],\n+    [0.0,  null, false, 2],\n+    [null, null, false, 3],\n+    [4.0,  null, null,  null]\n+  ])\"),\n+                        aggregated_and_grouped,\n+                        /*verbose=*/true);\n+    }\n+  }\n+}\n+\n+TEST(GroupBy, OneTypes) {\n+  std::vector<std::shared_ptr<DataType>> types;\n+  types.insert(types.end(), NumericTypes().begin(), NumericTypes().end());\n+  types.insert(types.end(), TemporalTypes().begin(), TemporalTypes().end());\n+  types.push_back(month_interval());\n+\n+  const std::vector<std::string> default_table = {R\"([\n+    [1,    1],\n+    [null, 1]\n+])\",\n+                                                  R\"([\n+    [0,    2],\n+    [null, 3],\n+    [3,    4],\n+    [5,    4],\n+    [4,    null],\n+    [3,    1],\n+    [0,    2]\n+])\",\n+                                                  R\"([\n+    [0,    2],\n+    [1,    null],\n+    [null, 3]\n+])\"};\n+\n+  const std::vector<std::string> date64_table = {R\"([\n+    [86400000,  1],\n+    [null,      1]\n+])\",\n+                                                 R\"([\n+    [0,         2],\n+    [null,      3],\n+    [259200000, 4],\n+    [432000000, 4],\n+    [345600000, null],\n+    [259200000, 1],\n+    [0,         2]\n+])\",\n+                                                 R\"([\n+    [0,         2],\n+    [86400000,  null],\n+    [null,      3]\n+])\"};\n+\n+  const std::string default_expected =\n+      R\"([\n+    [1,    1],\n+    [0,    2],\n+    [null, 3],\n+    [3,    4],\n+    [4,    null]\n+    ])\";\n+\n+  const std::string date64_expected =\n+      R\"([\n+    [86400000,  1],\n+    [0,         2],\n+    [null,      3],\n+    [259200000, 4],\n+    [345600000, null]\n+    ])\";\n+\n+  for (const auto& ty : types) {\n+    SCOPED_TRACE(ty->ToString());\n+    auto in_schema = schema({field(\"argument0\", ty), field(\"key\", int64())});\n+    auto table =\n+        TableFromJSON(in_schema, (ty->name() == \"date64\") ? date64_table : default_table);\n+\n+    ASSERT_OK_AND_ASSIGN(\n+        Datum aggregated_and_grouped,\n+        GroupByTest({table->GetColumnByName(\"argument0\")},\n+                    {table->GetColumnByName(\"key\")}, {{\"hash_one\", nullptr}},\n+                    /*use_threads=*/false, /*use_exec_plan=*/true));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(\n+        ArrayFromJSON(struct_({\n+                          field(\"hash_one\", ty),\n+                          field(\"key_0\", int64()),\n+                      }),\n+                      (ty->name() == \"date64\") ? date64_expected : default_expected),\n+        aggregated_and_grouped,\n+        /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneDecimal) {\n+  auto in_schema = schema({\n+      field(\"argument0\", decimal128(3, 2)),\n+      field(\"argument1\", decimal256(3, 2)),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {/*true, */ false}) {\n\nReview comment:\n       Hmm, we can't assume any particular value and we shouldn't assume anything about the order that the kernel gets batches whether it's serial or parallel. That makes the test hard to write, though.\r\n   \r\n   We could do something like this:\r\n   ```cpp\r\n   const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\r\n   // Check the key column\r\n   AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, 4, null]\"), struct_arr->field(2)));\r\n   // Check values individually\r\n   const auto& col0 = struct_arr->field(0);\r\n   ASSERT_OK_AND_ASSIGN(const auto col0_0, col0->GetScalar(0));\r\n   EXPECT_THAT(col0_0->Equals(*ScalarFromJSON(...)) || col0_0->Equals(*ScalarFromJSON()) ...);\r\n   ```\r\n   \r\n   this would get tedious fast though so I would honestly reduce the number of groups in the first place\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-11T14:03:13.083+0000",
                    "updated": "2022-02-11T14:03:13.083+0000",
                    "started": "2022-02-11T14:03:13.083+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "725150",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/725151",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r804679025\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2460,476 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                          field(\"hash_one\", float64()),\n+                                          field(\"hash_one\", null()),\n+                                          field(\"hash_one\", boolean()),\n+                                          field(\"key_0\", int64()),\n+                                      }),\n+                                      R\"([\n+    [1.0,  null, true,  1],\n+    [0.0,  null, false, 2],\n+    [null, null, false, 3],\n+    [4.0,  null, null,  null]\n+  ])\"),\n+                        aggregated_and_grouped,\n+                        /*verbose=*/true);\n+    }\n+  }\n+}\n+\n+TEST(GroupBy, OneTypes) {\n+  std::vector<std::shared_ptr<DataType>> types;\n+  types.insert(types.end(), NumericTypes().begin(), NumericTypes().end());\n+  types.insert(types.end(), TemporalTypes().begin(), TemporalTypes().end());\n+  types.push_back(month_interval());\n+\n+  const std::vector<std::string> default_table = {R\"([\n+    [1,    1],\n+    [null, 1]\n+])\",\n+                                                  R\"([\n+    [0,    2],\n+    [null, 3],\n+    [3,    4],\n+    [5,    4],\n+    [4,    null],\n+    [3,    1],\n+    [0,    2]\n+])\",\n+                                                  R\"([\n+    [0,    2],\n+    [1,    null],\n+    [null, 3]\n+])\"};\n+\n+  const std::vector<std::string> date64_table = {R\"([\n+    [86400000,  1],\n+    [null,      1]\n+])\",\n+                                                 R\"([\n+    [0,         2],\n+    [null,      3],\n+    [259200000, 4],\n+    [432000000, 4],\n+    [345600000, null],\n+    [259200000, 1],\n+    [0,         2]\n+])\",\n+                                                 R\"([\n+    [0,         2],\n+    [86400000,  null],\n+    [null,      3]\n+])\"};\n+\n+  const std::string default_expected =\n+      R\"([\n+    [1,    1],\n+    [0,    2],\n+    [null, 3],\n+    [3,    4],\n+    [4,    null]\n+    ])\";\n+\n+  const std::string date64_expected =\n+      R\"([\n+    [86400000,  1],\n+    [0,         2],\n+    [null,      3],\n+    [259200000, 4],\n+    [345600000, null]\n+    ])\";\n+\n+  for (const auto& ty : types) {\n+    SCOPED_TRACE(ty->ToString());\n+    auto in_schema = schema({field(\"argument0\", ty), field(\"key\", int64())});\n+    auto table =\n+        TableFromJSON(in_schema, (ty->name() == \"date64\") ? date64_table : default_table);\n+\n+    ASSERT_OK_AND_ASSIGN(\n+        Datum aggregated_and_grouped,\n+        GroupByTest({table->GetColumnByName(\"argument0\")},\n+                    {table->GetColumnByName(\"key\")}, {{\"hash_one\", nullptr}},\n+                    /*use_threads=*/false, /*use_exec_plan=*/true));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(\n+        ArrayFromJSON(struct_({\n+                          field(\"hash_one\", ty),\n+                          field(\"key_0\", int64()),\n+                      }),\n+                      (ty->name() == \"date64\") ? date64_expected : default_expected),\n+        aggregated_and_grouped,\n+        /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneDecimal) {\n+  auto in_schema = schema({\n+      field(\"argument0\", decimal128(3, 2)),\n+      field(\"argument1\", decimal256(3, 2)),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {/*true, */ false}) {\n\nReview comment:\n       Or you can try to make AnyOf work with EXPECT_THAT: https://github.com/google/googletest/blob/main/docs/reference/matchers.md#composite-matchers\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-11T14:04:35.906+0000",
                    "updated": "2022-02-11T14:04:35.906+0000",
                    "started": "2022-02-11T14:04:35.906+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "725151",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/726363",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r805961512\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n\nReview comment:\n       This is what the `EXPECT_THAT` and `AnyOf` approach might look like, for testing _just one_ column.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n+        const auto matcher = AnyOfScalarFromUniques(\n+            checked_pointer_cast<ListArray>(struct_arr_distinct->field(col)));\n+        EXPECT_THAT(struct_arr->field(col), matcher);\n+      }\n\nReview comment:\n       While this tests _all_ the columns (the key column is not a `ListArray` so will have to be tested manually, but that's non-trivial). So if using other kernels is not strictly discouraged to write test, this is a rather clean way of doing this. @lidavidm \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-14T15:34:34.414+0000",
                    "updated": "2022-02-14T15:34:34.414+0000",
                    "started": "2022-02-14T15:34:34.414+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "726363",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/726401",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r805965402\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n+        const auto matcher = AnyOfScalarFromUniques(\n+            checked_pointer_cast<ListArray>(struct_arr_distinct->field(col)));\n+        EXPECT_THAT(struct_arr->field(col), matcher);\n+      }\n\nReview comment:\n       While this tests _all_ the columns (the key column is not a `ListArray` so will have to be tested manually, but that's trivial). So if using other kernels is not strictly discouraged to write test, this is a rather clean way of doing this. @lidavidm \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-14T16:39:30.543+0000",
                    "updated": "2022-02-14T16:39:30.543+0000",
                    "started": "2022-02-14T16:39:30.543+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "726401",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/726840",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r806444672\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n\nReview comment:\n       ```suggestion\r\n         for (int64_t col = 0; col < struct_arr_distinct->num_fields() - 1; ++col) {\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-15T04:51:23.290+0000",
                    "updated": "2022-02-15T04:51:23.290+0000",
                    "started": "2022-02-15T04:51:23.289+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "726840",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/727021",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r806838598\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n\nReview comment:\n       IIRC, I think these convenience macros aren't always available in the CI environments we use. See https://github.com/apache/arrow/commit/cd30dea861d6dfd670032c655f329cb16bb99a7a\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n+      ArrayData* array, const std::vector<util::optional<StringType>>& values) {\n+    using offset_type = typename T::offset_type;\n+    ARROW_ASSIGN_OR_RAISE(\n+        auto raw_offsets,\n+        AllocateBuffer((1 + values.size()) * sizeof(offset_type), ctx_->memory_pool()));\n+    auto* offsets = reinterpret_cast<offset_type*>(raw_offsets->mutable_data());\n+    offsets[0] = 0;\n+    offsets++;\n+    const uint8_t* null_bitmap = array->buffers[0]->data();\n+    offset_type total_length = 0;\n+    for (size_t i = 0; i < values.size(); i++) {\n+      if (bit_util::GetBit(null_bitmap, i)) {\n+        const util::optional<StringType>& value = values[i];\n+        DCHECK(value.has_value());\n+        if (value->size() >\n+                static_cast<size_t>(std::numeric_limits<offset_type>::max()) ||\n+            arrow::internal::AddWithOverflow(\n+                total_length, static_cast<offset_type>(value->size()), &total_length)) {\n+          return Status::Invalid(\"Result is too large to fit in \", *array->type,\n+                                 \" cast to large_ variant of type\");\n+        }\n+      }\n+      offsets[i] = total_length;\n+    }\n+    ARROW_ASSIGN_OR_RAISE(auto data, AllocateBuffer(total_length, ctx_->memory_pool()));\n+    int64_t offset = 0;\n+    for (size_t i = 0; i < values.size(); i++) {\n+      if (bit_util::GetBit(null_bitmap, i)) {\n+        const util::optional<StringType>& value = values[i];\n+        DCHECK(value.has_value());\n+        std::memcpy(data->mutable_data() + offset, value->data(), value->size());\n+        offset += value->size();\n+      }\n+    }\n+    array->buffers[1] = std::move(raw_offsets);\n+    array->buffers.push_back(std::move(data));\n+    return Status::OK();\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_same<T, FixedSizeBinaryType, Status> MakeOffsetsValues(\n+      ArrayData* array, const std::vector<util::optional<StringType>>& values) {\n+    const uint8_t* null_bitmap = array->buffers[0]->data();\n+    const int32_t slot_width =\n+        checked_cast<const FixedSizeBinaryType&>(*array->type).byte_width();\n+    int64_t total_length = values.size() * slot_width;\n+    ARROW_ASSIGN_OR_RAISE(auto data, AllocateBuffer(total_length, ctx_->memory_pool()));\n+    int64_t offset = 0;\n+    for (size_t i = 0; i < values.size(); i++) {\n+      if (bit_util::GetBit(null_bitmap, i)) {\n+        const util::optional<StringType>& value = values[i];\n+        DCHECK(value.has_value());\n+        std::memcpy(data->mutable_data() + offset, value->data(), slot_width);\n+      } else {\n+        std::memset(data->mutable_data() + offset, 0x00, slot_width);\n+      }\n+      offset += slot_width;\n+    }\n+    array->buffers[1] = std::move(data);\n+    return Status::OK();\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  ExecContext* ctx_;\n+  Allocator allocator_;\n+  int64_t num_groups_;\n+  std::vector<util::optional<StringType>> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+template <typename T>\n+Result<std::unique_ptr<KernelState>> GroupedOneInit(KernelContext* ctx,\n+                                                    const KernelInitArgs& args) {\n+  ARROW_ASSIGN_OR_RAISE(auto impl, HashAggregateInit<GroupedOneImpl<T>>(ctx, args));\n+  auto instance = static_cast<GroupedOneImpl<T>*>(impl.get());\n+  instance->out_type_ = args.inputs[0].type;\n+  return std::move(impl);\n+}\n+\n+struct GroupedOneFactory {\n+  template <typename T>\n+  enable_if_physical_integer<T, Status> Visit(const T&) {\n+    using PhysicalType = typename T::PhysicalType;\n+    kernel = MakeKernel(std::move(argument_type), GroupedOneInit<PhysicalType>);\n+    return Status::OK();\n+  }\n+\n+  // MSVC2015 apparently doesn't compile this properly if we use\n\nReview comment:\n       we got rid of MSVC2015 so we can replace these two overloads with enable_if_floating_point.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n\nReview comment:\n       We could handle the error instead and report an assertion failure if GetScalar fails.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n\nReview comment:\n       We could factor those out, yeah\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n\nReview comment:\n       ResultWith is in matchers.h: https://github.com/apache/arrow/blob/26d6e6217ff79451a3fe366bcc88293c7ae67417/cpp/src/arrow/testing/matchers.h#L250-L254\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,92 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+struct GroupedOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    pool_ = ctx->memory_pool();\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    ARROW_ASSIGN_OR_RAISE(std::ignore, grouper_->Consume(batch));\n+    return Status::OK();\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    // Get (value, group_id) pairs, then translate the group IDs and consume them\n+    // ourselves\n+    ARROW_ASSIGN_OR_RAISE(auto uniques, other->grouper_->GetUniques());\n+    ARROW_ASSIGN_OR_RAISE(auto remapped_g,\n+                          AllocateBuffer(uniques.length * sizeof(uint32_t), pool_));\n+\n+    const auto* g_mapping = group_id_mapping.GetValues<uint32_t>(1);\n+    const auto* other_g = uniques[1].array()->GetValues<uint32_t>(1);\n+    auto* g = reinterpret_cast<uint32_t*>(remapped_g->mutable_data());\n+\n+    for (int64_t i = 0; i < uniques.length; i++) {\n+      g[i] = g_mapping[other_g[i]];\n+    }\n+    uniques.values[1] =\n+        ArrayData::Make(uint32(), uniques.length, {nullptr, std::move(remapped_g)});\n+\n+    return Consume(std::move(uniques));\n+  }\n+\n+  Result<Datum> Finalize() override {\n\nReview comment:\n       Hash aggregates can be executed in parallel\r\n   \r\n   Consume takes an input batch and updates local state\r\n   Merge takes two local states and combines them\r\n   Finalize takes a local state and produces the ouput array\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2460,476 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+TEST(GroupBy, One) {\n\nReview comment:\n       I think we can remove this, and we can consolidate test cases to be more compact.\r\n   \r\n   We can have one test for all the numeric types (\"OneTypes\", though maybe let's rename it \"OneNumericTypes\" or something?), then one test for all the \"misc\" types (write out one large input for null, boolean, decimal128, decimal256, fixed size binary), and one test for all the binary types (iterate through binary/large binary/string/large string).\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n\nReview comment:\n       Hmm, maybe we don't want this? That is, we could remove this and \"bias\" the kernel towards not returning null.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n\nReview comment:\n       I think something like `EXPECT_THAT(col0->GetScalar(0), ResultWith(AnyOfScalar(...))` could shorten this. Also, we could make a helper function `AnyOfJSON(type, str)` which calls `AnyOfScalar(ArrayFromJSON())` for you.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n+        const auto matcher = AnyOfScalarFromUniques(\n+            checked_pointer_cast<ListArray>(struct_arr_distinct->field(col)));\n+        EXPECT_THAT(struct_arr->field(col), matcher);\n+      }\n\nReview comment:\n       We can use other kernels, but I'm not sure this is any cleaner. The other approach is repetitive, but clear about what's going on. This requires a lot of thought to see what's happening.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-15T13:51:45.359+0000",
                    "updated": "2022-02-15T13:51:45.359+0000",
                    "started": "2022-02-15T13:51:45.358+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "727021",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/727336",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r805961512\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n\nReview comment:\n       This is what the `EXPECT_THAT` and `AnyOf` approach might look like, for testing _just one_ column.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n+        const auto matcher = AnyOfScalarFromUniques(\n+            checked_pointer_cast<ListArray>(struct_arr_distinct->field(col)));\n+        EXPECT_THAT(struct_arr->field(col), matcher);\n+      }\n\nReview comment:\n       While this tests _all_ the columns (the key column is not a `ListArray` so will have to be tested manually, but that's non-trivial). So if using other kernels is not strictly discouraged to write test, this is a rather clean way of doing this. @lidavidm \n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n+        const auto matcher = AnyOfScalarFromUniques(\n+            checked_pointer_cast<ListArray>(struct_arr_distinct->field(col)));\n+        EXPECT_THAT(struct_arr->field(col), matcher);\n+      }\n\nReview comment:\n       While this tests _all_ the columns (the key column is not a `ListArray` so will have to be tested manually, but that's trivial). So if using other kernels is not strictly discouraged to write test, this is a rather clean way of doing this. @lidavidm \n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n\nReview comment:\n       ```suggestion\r\n         for (int64_t col = 0; col < struct_arr_distinct->num_fields() - 1; ++col) {\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-15T18:41:39.216+0000",
                    "updated": "2022-02-15T18:41:39.216+0000",
                    "started": "2022-02-15T18:41:39.215+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "727336",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/727685",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r806838598\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n\nReview comment:\n       IIRC, I think these convenience macros aren't always available in the CI environments we use. See https://github.com/apache/arrow/commit/cd30dea861d6dfd670032c655f329cb16bb99a7a\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n+      ArrayData* array, const std::vector<util::optional<StringType>>& values) {\n+    using offset_type = typename T::offset_type;\n+    ARROW_ASSIGN_OR_RAISE(\n+        auto raw_offsets,\n+        AllocateBuffer((1 + values.size()) * sizeof(offset_type), ctx_->memory_pool()));\n+    auto* offsets = reinterpret_cast<offset_type*>(raw_offsets->mutable_data());\n+    offsets[0] = 0;\n+    offsets++;\n+    const uint8_t* null_bitmap = array->buffers[0]->data();\n+    offset_type total_length = 0;\n+    for (size_t i = 0; i < values.size(); i++) {\n+      if (bit_util::GetBit(null_bitmap, i)) {\n+        const util::optional<StringType>& value = values[i];\n+        DCHECK(value.has_value());\n+        if (value->size() >\n+                static_cast<size_t>(std::numeric_limits<offset_type>::max()) ||\n+            arrow::internal::AddWithOverflow(\n+                total_length, static_cast<offset_type>(value->size()), &total_length)) {\n+          return Status::Invalid(\"Result is too large to fit in \", *array->type,\n+                                 \" cast to large_ variant of type\");\n+        }\n+      }\n+      offsets[i] = total_length;\n+    }\n+    ARROW_ASSIGN_OR_RAISE(auto data, AllocateBuffer(total_length, ctx_->memory_pool()));\n+    int64_t offset = 0;\n+    for (size_t i = 0; i < values.size(); i++) {\n+      if (bit_util::GetBit(null_bitmap, i)) {\n+        const util::optional<StringType>& value = values[i];\n+        DCHECK(value.has_value());\n+        std::memcpy(data->mutable_data() + offset, value->data(), value->size());\n+        offset += value->size();\n+      }\n+    }\n+    array->buffers[1] = std::move(raw_offsets);\n+    array->buffers.push_back(std::move(data));\n+    return Status::OK();\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_same<T, FixedSizeBinaryType, Status> MakeOffsetsValues(\n+      ArrayData* array, const std::vector<util::optional<StringType>>& values) {\n+    const uint8_t* null_bitmap = array->buffers[0]->data();\n+    const int32_t slot_width =\n+        checked_cast<const FixedSizeBinaryType&>(*array->type).byte_width();\n+    int64_t total_length = values.size() * slot_width;\n+    ARROW_ASSIGN_OR_RAISE(auto data, AllocateBuffer(total_length, ctx_->memory_pool()));\n+    int64_t offset = 0;\n+    for (size_t i = 0; i < values.size(); i++) {\n+      if (bit_util::GetBit(null_bitmap, i)) {\n+        const util::optional<StringType>& value = values[i];\n+        DCHECK(value.has_value());\n+        std::memcpy(data->mutable_data() + offset, value->data(), slot_width);\n+      } else {\n+        std::memset(data->mutable_data() + offset, 0x00, slot_width);\n+      }\n+      offset += slot_width;\n+    }\n+    array->buffers[1] = std::move(data);\n+    return Status::OK();\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  ExecContext* ctx_;\n+  Allocator allocator_;\n+  int64_t num_groups_;\n+  std::vector<util::optional<StringType>> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+template <typename T>\n+Result<std::unique_ptr<KernelState>> GroupedOneInit(KernelContext* ctx,\n+                                                    const KernelInitArgs& args) {\n+  ARROW_ASSIGN_OR_RAISE(auto impl, HashAggregateInit<GroupedOneImpl<T>>(ctx, args));\n+  auto instance = static_cast<GroupedOneImpl<T>*>(impl.get());\n+  instance->out_type_ = args.inputs[0].type;\n+  return std::move(impl);\n+}\n+\n+struct GroupedOneFactory {\n+  template <typename T>\n+  enable_if_physical_integer<T, Status> Visit(const T&) {\n+    using PhysicalType = typename T::PhysicalType;\n+    kernel = MakeKernel(std::move(argument_type), GroupedOneInit<PhysicalType>);\n+    return Status::OK();\n+  }\n+\n+  // MSVC2015 apparently doesn't compile this properly if we use\n\nReview comment:\n       we got rid of MSVC2015 so we can replace these two overloads with enable_if_floating_point.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n\nReview comment:\n       We could handle the error instead and report an assertion failure if GetScalar fails.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n\nReview comment:\n       We could factor those out, yeah\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n\nReview comment:\n       ResultWith is in matchers.h: https://github.com/apache/arrow/blob/26d6e6217ff79451a3fe366bcc88293c7ae67417/cpp/src/arrow/testing/matchers.h#L250-L254\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,92 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+struct GroupedOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    pool_ = ctx->memory_pool();\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    ARROW_ASSIGN_OR_RAISE(std::ignore, grouper_->Consume(batch));\n+    return Status::OK();\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    // Get (value, group_id) pairs, then translate the group IDs and consume them\n+    // ourselves\n+    ARROW_ASSIGN_OR_RAISE(auto uniques, other->grouper_->GetUniques());\n+    ARROW_ASSIGN_OR_RAISE(auto remapped_g,\n+                          AllocateBuffer(uniques.length * sizeof(uint32_t), pool_));\n+\n+    const auto* g_mapping = group_id_mapping.GetValues<uint32_t>(1);\n+    const auto* other_g = uniques[1].array()->GetValues<uint32_t>(1);\n+    auto* g = reinterpret_cast<uint32_t*>(remapped_g->mutable_data());\n+\n+    for (int64_t i = 0; i < uniques.length; i++) {\n+      g[i] = g_mapping[other_g[i]];\n+    }\n+    uniques.values[1] =\n+        ArrayData::Make(uint32(), uniques.length, {nullptr, std::move(remapped_g)});\n+\n+    return Consume(std::move(uniques));\n+  }\n+\n+  Result<Datum> Finalize() override {\n\nReview comment:\n       Hash aggregates can be executed in parallel\r\n   \r\n   Consume takes an input batch and updates local state\r\n   Merge takes two local states and combines them\r\n   Finalize takes a local state and produces the ouput array\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2460,476 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+TEST(GroupBy, One) {\n\nReview comment:\n       I think we can remove this, and we can consolidate test cases to be more compact.\r\n   \r\n   We can have one test for all the numeric types (\"OneTypes\", though maybe let's rename it \"OneNumericTypes\" or something?), then one test for all the \"misc\" types (write out one large input for null, boolean, decimal128, decimal256, fixed size binary), and one test for all the binary types (iterate through binary/large binary/string/large string).\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n\nReview comment:\n       Hmm, maybe we don't want this? That is, we could remove this and \"bias\" the kernel towards not returning null.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n\nReview comment:\n       I think something like `EXPECT_THAT(col0->GetScalar(0), ResultWith(AnyOfScalar(...))` could shorten this. Also, we could make a helper function `AnyOfJSON(type, str)` which calls `AnyOfScalar(ArrayFromJSON())` for you.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,558 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P(AnyOfScalar, arrow_array, \"\") {\n+  for (int64_t i = 0; i < arrow_array->length(); ++i) {\n+    auto scalar = arrow_array->GetScalar(i).ValueOrDie();\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n+  return false;\n+}\n+\n+MATCHER_P(AnyOfScalarFromUniques, unique_list, \"\") {\n+  const auto& flatten = unique_list->Flatten().ValueOrDie();\n+  const auto& offsets = std::dynamic_pointer_cast<Int32Array>(unique_list->offsets());\n+\n+  for (int64_t i = 0; i < arg->length(); ++i) {\n+    bool match_found = false;\n+    const auto group_hash_one = arg->GetScalar(i).ValueOrDie();\n+    int64_t start = offsets->Value(i);\n+    int64_t end = offsets->Value(i + 1);\n+    for (int64_t j = start; j < end; ++j) {\n+      auto s = flatten->GetScalar(j).ValueOrDie();\n+      if (s->Equals(group_hash_one)) {\n+        match_found = true;\n+        break;\n+      }\n+    }\n+    if (!match_found) {\n+      *result_listener << \"Argument scalar: '\" << group_hash_one->ToString()\n+                       << \"' matches no input scalar.\";\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+TEST(GroupBy, One) {\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", int64()), field(\"key\", int64())}), {R\"([\n+    [99,  1],\n+    [99,  1]\n+])\",\n+                                                                                    R\"([\n+    [77,  2],\n+    [null,   3],\n+    [null,   3]\n+])\",\n+                                                                                    R\"([\n+    [null,   4],\n+    [null,   4]\n+])\",\n+                                                                                  R\"([\n+    [88,  null],\n+    [99,  3]\n+])\",\n+                                                                                  R\"([\n+    [77,  2],\n+    [76, 2]\n+])\",\n+                                                                                  R\"([\n+    [75, null],\n+    [74,  3]\n+  ])\",\n+                                                                                  R\"([\n+    [73,    null],\n+    [72,    null]\n+  ])\"});\n+\n+  ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                       internal::GroupBy(\n+                           {\n+                               table->GetColumnByName(\"argument\"),\n+                           },\n+                           {\n+                               table->GetColumnByName(\"key\"),\n+                           },\n+                           {\n+                               {\"hash_one\", nullptr},\n+                           },\n+                           false));\n+  ValidateOutput(aggregated_and_grouped);\n+  SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+  AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                      field(\"hash_one\", int64()),\n+                                      field(\"key_0\", int64()),\n+                                  }),\n+                                  R\"([\n+      [99, 1],\n+      [77, 2],\n+      [null,  3],\n+      [null,  4],\n+      [88, null]\n+    ])\"),\n+                    aggregated_and_grouped,\n+                    /*verbose=*/true);\n+  }\n+  {\n+    auto table =\n+        TableFromJSON(schema({field(\"argument\", utf8()), field(\"key\", int64())}), {R\"([\n+     [\"foo\",  1],\n+     [\"foo\",  1]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [null,   3],\n+     [null,   3]\n+ ])\",\n+                                                                                   R\"([\n+     [null,   4],\n+     [null,   4]\n+ ])\",\n+                                                                                   R\"([\n+     [\"baz\",  null],\n+     [\"foo\",  3]\n+ ])\",\n+                                                                                   R\"([\n+     [\"bar\",  2],\n+     [\"spam\", 2]\n+ ])\",\n+                                                                                   R\"([\n+     [\"eggs\", null],\n+     [\"ham\",  3]\n+   ])\",\n+                                                                                   R\"([\n+     [\"a\",    null],\n+     [\"b\",    null]\n+   ])\"});\n+\n+    ASSERT_OK_AND_ASSIGN(auto aggregated_and_grouped,\n+                         internal::GroupBy(\n+                             {\n+                                 table->GetColumnByName(\"argument\"),\n+                             },\n+                             {\n+                                 table->GetColumnByName(\"key\"),\n+                             },\n+                             {\n+                                 {\"hash_one\", nullptr},\n+                             },\n+                             false));\n+    ValidateOutput(aggregated_and_grouped);\n+    SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+    AssertDatumsEqual(ArrayFromJSON(struct_({\n+                                        field(\"hash_one\", utf8()),\n+                                        field(\"key_0\", int64()),\n+                                    }),\n+                                    R\"([\n+       [\"foo\", 1],\n+       [\"bar\", 2],\n+       [null,  3],\n+       [null,  4],\n+       [\"baz\", null]\n+     ])\"),\n+                      aggregated_and_grouped,\n+                      /*verbose=*/true);\n+  }\n+}\n+\n+TEST(GroupBy, OneOnly) {\n+  auto in_schema = schema({\n+      field(\"argument0\", float64()),\n+      field(\"argument1\", null()),\n+      field(\"argument2\", boolean()),\n+      field(\"key\", int64()),\n+  });\n+  for (bool use_exec_plan : {false, true}) {\n+    for (bool use_threads : {false, true}) {\n+      SCOPED_TRACE(use_threads ? \"parallel/merged\" : \"serial\");\n+\n+      auto table = TableFromJSON(in_schema, {R\"([\n+    [1.0,   null, true, 1],\n+    [null,  null, true, 1]\n+])\",\n+                                             R\"([\n+    [0.0,   null, false, 2],\n+    [null,  null, false, 3],\n+    [4.0,   null, null,  null],\n+    [3.25,  null, true,  1],\n+    [0.125, null, false, 2]\n+])\",\n+                                             R\"([\n+    [-0.25, null, false, 2],\n+    [0.75,  null, true,  null],\n+    [null,  null, true,  3]\n+])\"});\n+\n+      ASSERT_OK_AND_ASSIGN(Datum aggregated_and_grouped,\n+                           GroupByTest(\n+                               {\n+                                   table->GetColumnByName(\"argument0\"),\n+                                   table->GetColumnByName(\"argument1\"),\n+                                   table->GetColumnByName(\"argument2\"),\n+                               },\n+                               {table->GetColumnByName(\"key\")},\n+                               {\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                                   {\"hash_one\", nullptr},\n+                               },\n+                               use_threads, use_exec_plan));\n+      ValidateOutput(aggregated_and_grouped);\n+      SortBy({\"key_0\"}, &aggregated_and_grouped);\n+\n+      //      AssertDatumsEqual(ArrayFromJSON(struct_({\n+      //                                          field(\"hash_one\", float64()),\n+      //                                          field(\"hash_one\", null()),\n+      //                                          field(\"hash_one\", boolean()),\n+      //                                          field(\"key_0\", int64()),\n+      //                                      }),\n+      //                                      R\"([\n+      //          [1.0,  null, true,  1],\n+      //          [0.0,  null, false, 2],\n+      //          [null, null, false, 3],\n+      //          [4.0,  null, null,  null]\n+      //        ])\"),\n+      //                        aggregated_and_grouped,\n+      //                        /*verbose=*/true);\n+\n+      const auto& struct_arr = aggregated_and_grouped.array_as<StructArray>();\n+      //  Check the key column\n+      AssertDatumsEqual(ArrayFromJSON(int64(), \"[1, 2, 3, null]\"), struct_arr->field(3));\n+\n+      auto type_col_0 = float64();\n+      auto group_one_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([1.0, null, 3.25])\"));\n+      auto group_two_col_0 =\n+          AnyOfScalar(ArrayFromJSON(type_col_0, R\"([0.0, 0.125, -0.25])\"));\n+      auto group_three_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([null])\"));\n+      auto group_null_col_0 = AnyOfScalar(ArrayFromJSON(type_col_0, R\"([4.0, 0.75])\"));\n+\n+      //  Check values individually\n+      const auto& col0 = struct_arr->field(0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_one, col0->GetScalar(0));\n+      EXPECT_THAT(g_one, group_one_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_two, col0->GetScalar(1));\n+      EXPECT_THAT(g_two, group_two_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_three, col0->GetScalar(2));\n+      EXPECT_THAT(g_three, group_three_col_0);\n+      ASSERT_OK_AND_ASSIGN(const auto g_null, col0->GetScalar(3));\n+      EXPECT_THAT(g_null, group_null_col_0);\n+\n+      CountOptions all(CountOptions::ALL);\n+      ASSERT_OK_AND_ASSIGN(\n+          auto distinct_out,\n+          internal::GroupBy(\n+              {\n+                  table->GetColumnByName(\"argument0\"),\n+                  table->GetColumnByName(\"argument1\"),\n+                  table->GetColumnByName(\"argument2\"),\n+              },\n+              {\n+                  table->GetColumnByName(\"key\"),\n+              },\n+              {{\"hash_distinct\", &all}, {\"hash_distinct\", &all}, {\"hash_distinct\", &all}},\n+              use_threads));\n+      ValidateOutput(distinct_out);\n+      SortBy({\"key_0\"}, &distinct_out);\n+\n+      const auto& struct_arr_distinct = distinct_out.array_as<StructArray>();\n+      for (int64_t col = 0; col < struct_arr_distinct->length() - 1; ++col) {\n+        const auto matcher = AnyOfScalarFromUniques(\n+            checked_pointer_cast<ListArray>(struct_arr_distinct->field(col)));\n+        EXPECT_THAT(struct_arr->field(col), matcher);\n+      }\n\nReview comment:\n       We can use other kernels, but I'm not sure this is any cleaner. The other approach is repetitive, but clear about what's going on. This requires a lot of thought to see what's happening.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-15T19:09:37.624+0000",
                    "updated": "2022-02-15T19:09:37.624+0000",
                    "started": "2022-02-15T19:09:37.624+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "727685",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/728160",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r807884279\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n\nReview comment:\n       What would this look like?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-16T12:18:57.099+0000",
                    "updated": "2022-02-16T12:18:57.099+0000",
                    "started": "2022-02-16T12:18:57.098+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "728160",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/728161",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "dhruv9vats commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r807884279\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n\nReview comment:\n       What would this look like? Like would it go in some sort of helper file?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-16T12:20:14.973+0000",
                    "updated": "2022-02-16T12:20:14.973+0000",
                    "started": "2022-02-16T12:20:14.973+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "728161",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/728192",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r807957098\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate.cc\n##########\n@@ -2451,6 +2451,333 @@ Result<std::unique_ptr<KernelState>> GroupedDistinctInit(KernelContext* ctx,\n   return std::move(impl);\n }\n \n+// ----------------------------------------------------------------------\n+// One implementation\n+\n+template <typename Type, typename Enable = void>\n+struct GroupedOneImpl final : public GroupedAggregator {\n+  using CType = typename TypeTraits<Type>::CType;\n+  using GetSet = GroupedValueTraits<Type>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    // out_type_ initialized by GroupedOneInit\n+    ones_ = TypedBufferBuilder<CType>(ctx->memory_pool());\n+    has_one_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    num_groups_ = new_num_groups;\n+    RETURN_NOT_OK(ones_.Append(added_groups, static_cast<CType>(0)));\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    auto raw_ones_ = ones_.mutable_data();\n+\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, CType val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            GetSet::Set(raw_ones_, g, val);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+\n+    auto raw_ones = ones_.mutable_data();\n+    auto other_raw_ones = other->ones_.mutable_data();\n+\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          GetSet::Set(raw_ones, *g, GetSet::Get(other_raw_ones, other_g));\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    ARROW_ASSIGN_OR_RAISE(auto data, ones_.Finish());\n+    return ArrayData::Make(out_type_, num_groups_,\n+                           {std::move(null_bitmap), std::move(data)});\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return out_type_; }\n+\n+  int64_t num_groups_;\n+  TypedBufferBuilder<CType> ones_;\n+  TypedBufferBuilder<bool> has_one_, has_value_;\n+  std::shared_ptr<DataType> out_type_;\n+};\n+\n+struct GroupedNullOneImpl : public GroupedAggregator {\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    num_groups_ = new_num_groups;\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override { return Status::OK(); }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    return ArrayData::Make(null(), num_groups_, {nullptr}, num_groups_);\n+  }\n+\n+  std::shared_ptr<DataType> out_type() const override { return null(); }\n+\n+  int64_t num_groups_;\n+};\n+\n+template <typename Type>\n+struct GroupedOneImpl<Type, enable_if_t<is_base_binary_type<Type>::value ||\n+                                        std::is_same<Type, FixedSizeBinaryType>::value>>\n+    final : public GroupedAggregator {\n+  using Allocator = arrow::stl::allocator<char>;\n+  using StringType = std::basic_string<char, std::char_traits<char>, Allocator>;\n+\n+  Status Init(ExecContext* ctx, const std::vector<ValueDescr>&,\n+              const FunctionOptions* options) override {\n+    ctx_ = ctx;\n+    allocator_ = Allocator(ctx->memory_pool());\n+    // out_type_ initialized by GroupedOneInit\n+    has_value_ = TypedBufferBuilder<bool>(ctx->memory_pool());\n+    return Status::OK();\n+  }\n+\n+  Status Resize(int64_t new_num_groups) override {\n+    auto added_groups = new_num_groups - num_groups_;\n+    DCHECK_GE(added_groups, 0);\n+    num_groups_ = new_num_groups;\n+    ones_.resize(new_num_groups);\n+    RETURN_NOT_OK(has_one_.Append(added_groups, false));\n+    RETURN_NOT_OK(has_value_.Append(added_groups, false));\n+    return Status::OK();\n+  }\n+\n+  Status Consume(const ExecBatch& batch) override {\n+    return VisitGroupedValues<Type>(\n+        batch,\n+        [&](uint32_t g, util::string_view val) -> Status {\n+          if (!bit_util::GetBit(has_one_.data(), g)) {\n+            ones_[g].emplace(val.data(), val.size(), allocator_);\n+            bit_util::SetBit(has_one_.mutable_data(), g);\n+            bit_util::SetBit(has_value_.mutable_data(), g);\n+          }\n+          return Status::OK();\n+        },\n+        [&](uint32_t g) -> Status {\n+          // as has_one_ is set, has_value_ will never be set, resulting in null\n+          bit_util::SetBit(has_one_.mutable_data(), g);\n+          return Status::OK();\n+        });\n+  }\n+\n+  Status Merge(GroupedAggregator&& raw_other,\n+               const ArrayData& group_id_mapping) override {\n+    auto other = checked_cast<GroupedOneImpl*>(&raw_other);\n+    auto g = group_id_mapping.GetValues<uint32_t>(1);\n+    for (uint32_t other_g = 0; static_cast<int64_t>(other_g) < group_id_mapping.length;\n+         ++other_g, ++g) {\n+      if (!bit_util::GetBit(has_one_.data(), *g)) {\n+        if (bit_util::GetBit(other->has_value_.data(), other_g)) {\n+          ones_[*g] = std::move(other->ones_[other_g]);\n+          bit_util::SetBit(has_value_.mutable_data(), *g);\n+        }\n+        bit_util::SetBit(has_one_.mutable_data(), *g);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Result<Datum> Finalize() override {\n+    ARROW_ASSIGN_OR_RAISE(auto null_bitmap, has_value_.Finish());\n+    auto ones =\n+        ArrayData::Make(out_type(), num_groups_, {std::move(null_bitmap), nullptr});\n+    RETURN_NOT_OK(MakeOffsetsValues(ones.get(), ones_));\n+    return ones;\n+  }\n+\n+  template <typename T = Type>\n+  enable_if_base_binary<T, Status> MakeOffsetsValues(\n\nReview comment:\n       I think it can stay in this file. If there's not a clear way to factor it out, then let's not.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-16T13:21:07.146+0000",
                    "updated": "2022-02-16T13:21:07.146+0000",
                    "started": "2022-02-16T13:21:07.146+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "728192",
                    "issueId": "13401027"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/worklog/728210",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #12368:\nURL: https://github.com/apache/arrow/pull/12368#discussion_r807991560\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,315 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P2(AnyOfJSON, type, array_json, \"\") {\n+  auto array = ArrayFromJSON(type, array_json);\n+  for (int64_t i = 0; i < array->length(); ++i) {\n+    std::shared_ptr<Scalar> scalar;\n+    auto maybe_scalar = array->GetScalar(i);\n+    if (maybe_scalar.ok()) {\n+      scalar = maybe_scalar.ValueOrDie();\n+    } else {\n+      *result_listener << \"Unable to retrieve scalar via GetScalar() \"\n+                       << \"at index \" << i << \" from the input JSON Array\";\n+      return false;\n+    }\n+\n+    if (scalar->Equals(arg)) return true;\n+  }\n+  *result_listener << \"Argument scalar: '\" << arg->ToString()\n+                   << \"' matches no input scalar.\";\n\nReview comment:\n       also include `array_json`?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,315 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P2(AnyOfJSON, type, array_json, \"\") {\n+  auto array = ArrayFromJSON(type, array_json);\n+  for (int64_t i = 0; i < array->length(); ++i) {\n+    std::shared_ptr<Scalar> scalar;\n+    auto maybe_scalar = array->GetScalar(i);\n+    if (maybe_scalar.ok()) {\n+      scalar = maybe_scalar.ValueOrDie();\n+    } else {\n+      *result_listener << \"Unable to retrieve scalar via GetScalar() \"\n+                       << \"at index \" << i << \" from the input JSON Array\";\n\nReview comment:\n       also include `maybe_scalar.status().ToString()`?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -2460,6 +2461,315 @@ TEST(GroupBy, Distinct) {\n   }\n }\n \n+MATCHER_P2(AnyOfJSON, type, array_json, \"\") {\n\nReview comment:\n       Just reiterating my earlier comment - but we've found before that these convenience macros don't work in all environments.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-16T13:52:39.882+0000",
                    "updated": "2022-02-16T13:52:39.882+0000",
                    "started": "2022-02-16T13:52:39.881+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "728210",
                    "issueId": "13401027"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 21000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@c83c96b[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@583ce44a[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@787444c3[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@47d5e133[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@35de295e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@2f69e279[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@75e1f90b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@1d5552fd[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@59051cd0[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@399f57a3[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@43ccd83a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@74b9a804[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 21000,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Jun 30 13:46:47 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-02-17T13:13:31.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13993/watchers",
            "watchCount": 5,
            "isWatching": false
        },
        "created": "2021-09-14T13:53:10.000+0000",
        "updated": "2022-06-30T13:46:47.000+0000",
        "timeoriginalestimate": null,
        "description": "It would be nice to have a hash aggregate function that returns the first value of a column within each hash group.\r\n\r\nIf row order within groups is\u00a0non-deterministic, then effectively this would return one arbitrary value. This is a very computationally cheap operation.\r\n\r\nThis can be quite useful when querying a non-normalized table. For example if you have a table with a {{country}} column and also a\u00a0{{country_abbr}}\u00a0column and you want to group by either/both of those columns but return the values from both columns, you could do\r\n{code:java}\r\nSELECT country, country_abbr FROM table GROUP BY country, country_abbr{code}\r\nbut it would be more efficient to do\r\n{code:java}\r\nSELECT country, first(country_abbr) FROM table GROUP BY country{code}\r\nbecause then the engine does not need to scan all the values of the {{country_abbr}} column.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "5h 50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 21000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Hash aggregate function that returns value from first row in group",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17414961",
                    "id": "17414961",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "A more general solution would be to implement a {{hash_take}}\u00a0hash aggregate function that takes a scalar integer\u00a0argument {{n}}\u00a0and returns the {{nth}}\u00a0row from each hash group.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-09-14T14:10:53.318+0000",
                    "updated": "2021-09-14T14:11:48.101+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17460929",
                    "id": "17460929",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Since the result would be non-deterministic, I'm not sure I understand the point of  a {{hash_take}} function compared to the {{hash_first}} proposal.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2021-12-16T17:51:33.341+0000",
                    "updated": "2021-12-16T17:51:33.341+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17462643",
                    "id": "17462643",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "[~apitrou]\u00a0I agree, there is probably no point; just a {{hash_first}} kernel would suffice for all the uses I can imagine",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-12-20T14:28:49.954+0000",
                    "updated": "2021-12-20T14:28:49.954+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17487249",
                    "id": "17487249",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "So it sounds like we can implement this JIRA as \"pick one column value from the group\" and not \"pick the first column value from the group\".  The latter we can create a new JIRA for (there is some desire for this: see ARROW-15474) and tackle later once we have an idea of how we deal with ordering mid-plan.\r\n\r\nDo we want to consider a name other than {{hash_first}}?  Maybe {{hash_one}} or {{hash_single}}?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-02-04T19:05:48.358+0000",
                    "updated": "2022-02-04T19:05:48.358+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17488089",
                    "id": "17488089",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=dhruv9vats",
                        "name": "dhruv9vats",
                        "key": "dhruv9vats",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
                        },
                        "displayName": "Dhruv Vats",
                        "active": true,
                        "timeZone": "Asia/Kolkata"
                    },
                    "body": "Just so I understand this correctly (as I don't have a very formal CS background), when we do:\r\n{code:sql}\r\nSELECT country, SUM(customerID) FROM db_table GROUP BY country{code}\r\nfrom a supposed sales table {{db_table}} that has fields {{country}} and {{{}customerID{}}}, we get number of customers _per_ country/group.\r\n\r\nSo here instead sum of all tuples in a group, we just want to return a single tuple from the different groups/country? And, it seems _which_ tuple (like either the first or a specific one) to return is yet to be finalised, right?\r\n\r\nAlso is there a PR or an existing kernel that has a similar boilerplate code to what this will have? (That'll save a disproportionate time going through all the abstractions).",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=dhruv9vats",
                        "name": "dhruv9vats",
                        "key": "dhruv9vats",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
                        },
                        "displayName": "Dhruv Vats",
                        "active": true,
                        "timeZone": "Asia/Kolkata"
                    },
                    "created": "2022-02-07T13:12:04.761+0000",
                    "updated": "2022-02-07T13:12:04.761+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17488095",
                    "id": "17488095",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Yes, we just want a single row per group. Any row will do; the point above is that we can't implement anything else (because the query engine currently lacks support for ordering, beyond sorting outputs at the very end).\r\n\r\nAll hash_ kernels (\"hash aggregate kernels\") are in [{{hash_aggregate.cc}}|https://github.com/apache/arrow/blob/master/cpp/src/arrow/compute/kernels/hash_aggregate.cc] and it will be very similar to the CountDistinct/Distinct implementation there. ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-02-07T13:16:24.471+0000",
                    "updated": "2022-02-07T13:17:00.378+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17493931",
                    "id": "17493931",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 12368\n[https://github.com/apache/arrow/pull/12368]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-02-17T13:13:31.037+0000",
                    "updated": "2022-02-17T13:13:31.037+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17494021",
                    "id": "17494021",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "[~dhruv9vats]\u00a0Thanks for doing this! I think we need a follow-up to add {{hash_one}} to the table of hash aggregate functions in [compute.rst|https://github.com/apache/arrow/blob/master/docs/source/cpp/compute.rst]. Could you create an issue for that please?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-02-17T15:36:41.859+0000",
                    "updated": "2022-02-17T15:36:41.859+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17494023",
                    "id": "17494023",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "D'oh. Sorry [~dhruv9vats] I forgot to note this in the review. Thanks [~icook] for catching this.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-02-17T15:38:30.605+0000",
                    "updated": "2022-02-17T15:38:30.605+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17494025",
                    "id": "17494025",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "See ARROW-15717.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-02-17T15:39:01.734+0000",
                    "updated": "2022-02-17T15:39:01.734+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17494030",
                    "id": "17494030",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Thanks!",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-02-17T15:48:20.601+0000",
                    "updated": "2022-02-17T15:48:20.601+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13401027/comment/17561056",
                    "id": "17561056",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I recently learned that this function is called {{any_value}} in some SQL dialects (for example in Snowflake: https://docs.snowflake.com/en/sql-reference/functions/any_value.html)",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=icook",
                        "name": "icook",
                        "key": "icook",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=icook&avatarId=29388",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=icook&avatarId=29388",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=icook&avatarId=29388",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=icook&avatarId=29388"
                        },
                        "displayName": "Ian Cook",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-06-30T13:46:47.447+0000",
                    "updated": "2022-06-30T13:46:47.447+0000"
                }
            ],
            "maxResults": 12,
            "total": 12,
            "startAt": 0
        },
        "customfield_12311820": "0|z0uwc0:",
        "customfield_12314139": null
    }
}