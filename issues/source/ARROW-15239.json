{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13420467",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467",
    "key": "ARROW-15239",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351051",
                "id": "12351051",
                "description": "",
                "name": "8.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-05-06"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available",
            "query-engine"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350323",
                "id": "12350323",
                "description": "",
                "name": "6.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-10-26"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12632388",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12632388",
                "type": {
                    "id": "10032",
                    "name": "Blocker",
                    "inward": "is blocked by",
                    "outward": "blocks",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"
                },
                "outwardIssue": {
                    "id": "13425500",
                    "key": "ARROW-15498",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13425500",
                    "fields": {
                        "summary": "[C++][Compute] Implement Bloom filter pushdown between hash joins ",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12629671",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12629671",
                "type": {
                    "id": "12310460",
                    "name": "Child-Issue",
                    "inward": "is a child of",
                    "outward": "is a parent of",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310460"
                },
                "inwardIssue": {
                    "id": "13376404",
                    "key": "ARROW-12633",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13376404",
                    "fields": {
                        "summary": "[C++] Query engine umbrella issue",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
            "name": "michalno",
            "key": "michalno",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Michal Nowakiewicz",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
            "name": "michalno",
            "key": "michalno",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Michal Nowakiewicz",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
            "name": "michalno",
            "key": "michalno",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Michal Nowakiewicz",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 37800,
            "total": 37800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 37800,
            "total": 37800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15239/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 63,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/703194",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa opened a new pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067\n\n\n   Implementing register blocked Bloom filter to be used in hash join exec node.\r\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-04T05:30:29.453+0000",
                    "updated": "2022-01-04T05:30:29.453+0000",
                    "started": "2022-01-04T05:30:29.452+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "703194",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/703195",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#issuecomment-1004539393\n\n\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-04T05:30:52.556+0000",
                    "updated": "2022-01-04T05:30:52.556+0000",
                    "started": "2022-01-04T05:30:52.556+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "703195",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/704885",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r779963566\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n\nReview comment:\n       Can these two lines be removed?  I don't see these classes anywhere.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n\nReview comment:\n       Can you link to a paper or description describing the filter you based your implementation on and then briefly describe what's variant about this one (or at least what the goals were)?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes);\n+\n+  // Uses SIMD if available for smaller Bloom filters.\n+  // Uses memory prefetching for larger Bloom filters.\n+  //\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+\n+  // Folding of a block Bloom filter after the initial version\n+  // has been built.\n+  //\n+  // One of the parameters for creation of Bloom filter is the number\n+  // of bits allocated for it. The more bits allocated, the lower the\n+  // probability of false positives. A good heuristic is to aim for\n+  // half of the bits set in the constructed Bloom filter. This should\n+  // result in a good trade off between size (and following cost of\n+  // memory accesses) and false positives rate.\n+  //\n+  // There might have been many duplicate keys in the input provided\n+  // to Bloom filter builder. In that case the resulting bit vector\n+  // would be more sparse then originally intended. It is possible to\n+  // easily correct that and cut in half the size of Bloom filter\n+  // after it has already been constructed. The process to do that is\n+  // approximately equal to OR-ing bits from upper and lower half (the\n+  // way we address these bits when inserting or querying a hash makes\n+  // such folding in half possible).\n+  //\n+  // We will keep folding as long as the fraction of bits set is less\n+  // than 1/4. The resulting bit vector density should be in the [1/4,\n+  // 1/2) range.\n+  //\n+  void Fold();\n+\n+  int log_num_blocks() const { return log_num_blocks_; }\n+\n+  int NumHashBitsUsed() const;\n+\n+  bool IsSameAs(const BlockedBloomFilter* other) const;\n+\n+  int64_t NumBitsSet() const;\n+\n+ private:\n+  inline uint64_t mask(uint64_t hash) const {\n+    // The lowest bits of hash are used to pick mask index.\n+    //\n+    int mask_id = static_cast<int>(hash & (BloomFilterMasks::kNumMasks - 1));\n+    uint64_t result = masks_.mask(mask_id);\n+\n+    // The next set of hash bits is used to pick the amount of bit\n+    // rotation of the mask.\n+    //\n+    int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\n+    result = ROTL64(result, rotation);\n+\n+    return result;\n+  }\n+\n+  inline int64_t block_id(uint64_t hash) const {\n+    // The next set of hash bits following the bits used to select a\n+    // mask is used to pick block id (index of 64-bit word in a bit\n+    // vector).\n+    //\n+    return (hash >> (BloomFilterMasks::kLogNumMasks + 6)) & (num_blocks_ - 1);\n+  }\n+\n+  template <typename T>\n+  inline void InsertImp(int64_t num_rows, const T* hashes);\n+\n+  template <typename T>\n+  inline void FindImp(int64_t num_rows, const T* hashes, uint8_t* result_bit_vector,\n+                      bool enable_prefetch) const;\n+\n+  void SingleFold(int num_folds);\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  inline __m256i mask_avx2(__m256i hash) const;\n+  inline __m256i block_id_avx2(__m256i hash) const;\n+  int64_t Insert_avx2(int64_t num_rows, const uint32_t* hashes);\n+  int64_t Insert_avx2(int64_t num_rows, const uint64_t* hashes);\n+  template <typename T>\n+  int64_t InsertImp_avx2(int64_t num_rows, const T* hashes);\n+  int64_t Find_avx2(int64_t num_rows, const uint32_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  int64_t Find_avx2(int64_t num_rows, const uint64_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  template <typename T>\n+  int64_t FindImp_avx2(int64_t num_rows, const T* hashes,\n+                       uint8_t* result_bit_vector) const;\n+#endif\n+\n+  bool UsePrefetch() const {\n+    return num_blocks_ * sizeof(uint64_t) > kPrefetchLimitBytes;\n+  }\n+\n+  static constexpr int64_t kPrefetchLimitBytes = 256 * 1024;\n+\n+  static BloomFilterMasks masks_;\n+\n+  // Total number of bits used by block Bloom filter must be a power\n+  // of 2.\n+  //\n+  int log_num_blocks_;\n+  int64_t num_blocks_;\n+\n+  // Buffer allocated to store an array of power of 2 64-bit blocks.\n+  //\n+  std::shared_ptr<Buffer> buf_;\n+  // Pointer to mutable data owned by Buffer\n+  //\n+  uint64_t* blocks_;\n+};\n+\n+enum class BloomFilterBuildStrategy {\n+  SINGLE_THREADED = 0,\n+  PARALLEL = 1,\n+};\n+\n+class BloomFilterBuilder {\n\nReview comment:\n       This API shape (begin/finish/cleanup) is a little unorthodox (elsewhere for builders we use constructor or static factory that initializes the target, finish returns the built target, and cleanup happens in the destructor).  However, I'm thinking this is for interaction with the scheduler API used elsewhere in the hash-join implementation?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n\nReview comment:\n       Nit: This feels like it could be a private method but then I suppose you will need to friend the builders.  Why not make this a constructor?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.cc\n##########\n@@ -0,0 +1,434 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include <random>\n+#include \"arrow/compute/exec/util.h\"  // PREFETCH\n+#include \"arrow/util/bit_util.h\"      // Log2\n+#include \"arrow/util/bitmap_ops.h\"    // CountSetBits\n+\n+namespace arrow {\n+namespace compute {\n+\n+BloomFilterMasks::BloomFilterMasks() {\n+  std::seed_seq seed{0, 0, 0, 0, 0, 0, 0, 0};\n+  std::mt19937 re(seed);\n+  std::uniform_int_distribution<uint64_t> rd;\n+  auto random = [&re, &rd](int min_value, int max_value) {\n+    return min_value + rd(re) % (max_value - min_value + 1);\n+  };\n+\n+  memset(masks_, 0, kTotalBytes);\n+\n+  // Prepare the first mask\n+  //\n+  int num_bits_set = static_cast<int>(random(kMinBitsSet, kMaxBitsSet));\n+  for (int i = 0; i < num_bits_set; ++i) {\n+    for (;;) {\n+      int bit_pos = static_cast<int>(random(0, kBitsPerMask - 1));\n+      if (!bit_util::GetBit(masks_, bit_pos)) {\n+        bit_util::SetBit(masks_, bit_pos);\n+        break;\n+      }\n+    }\n+  }\n+\n+  int64_t num_bits_total = kNumMasks + kBitsPerMask - 1;\n+\n+  // The value num_bits_set will be updated in each iteration of the loop to\n+  // represent the number of bits set in the entire mask directly preceding the\n+  // currently processed bit.\n+  //\n+  for (int64_t i = kBitsPerMask; i < num_bits_total; ++i) {\n+    // The value of the lowest bit of the previous mask that will be removed\n+    // from the current mask as we move to the next position in the bit vector\n+    // of masks.\n+    //\n+    int bit_leaving = bit_util::GetBit(masks_, i - kBitsPerMask) ? 1 : 0;\n+\n+    // Next bit has to be 1 because of minimum bits in a mask requirement\n+    //\n+    if (bit_leaving == 1 && num_bits_set == kMinBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      continue;\n+    }\n+\n+    // Next bit has to be 0 because of maximum bits in a mask requirement\n+    //\n+    if (bit_leaving == 0 && num_bits_set == kMaxBitsSet) {\n+      continue;\n+    }\n+\n+    // Next bit can be random. Use the expected number of bits set in a mask\n+    // as a probability of 1.\n+    //\n+    if (random(0, kBitsPerMask * 2 - 1) < kMinBitsSet + kMaxBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      if (bit_leaving == 0) {\n+        ++num_bits_set;\n+      }\n+    } else {\n+      if (bit_leaving == 1) {\n+        --num_bits_set;\n+      }\n+    }\n+  }\n+}\n+\n+BloomFilterMasks BlockedBloomFilter::masks_;\n+\n+Status BlockedBloomFilter::CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool) {\n+  // Compute the size\n+  //\n+  constexpr int64_t min_num_bits_per_key = 8;\n+  constexpr int64_t min_num_bits = 512;\n+  int64_t desired_num_bits =\n+      std::max(min_num_bits, num_rows_to_insert * min_num_bits_per_key);\n+  int log_num_bits = bit_util::Log2(desired_num_bits);\n+\n+  log_num_blocks_ = log_num_bits - 6;\n+  num_blocks_ = 1ULL << log_num_blocks_;\n+\n+  // Allocate and zero out bit vector\n+  //\n+  int64_t buffer_size = num_blocks_ * sizeof(uint64_t);\n+  ARROW_ASSIGN_OR_RAISE(buf_, AllocateBuffer(buffer_size, pool));\n+  blocks_ = reinterpret_cast<uint64_t*>(buf_->mutable_data());\n+  memset(blocks_, 0, buffer_size);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BlockedBloomFilter::InsertImp(int64_t num_rows, const T* hashes) {\n+  for (int64_t i = 0; i < num_rows; ++i) {\n+    Insert(hashes[i]);\n+  }\n+}\n+\n+void BlockedBloomFilter::Insert(int64_t hardware_flags, int64_t num_rows,\n+                                const uint32_t* hashes) {\n+  int64_t num_processed = 0;\n+#if defined(ARROW_HAVE_AVX2)\n+  if (hardware_flags & arrow::internal::CpuInfo::AVX2) {\n+    num_processed = Insert_avx2(num_rows, hashes);\n+  }\n+#endif\n+  InsertImp(num_rows - num_processed, hashes + num_processed);\n\nReview comment:\n       Would leftovers here be whatever hashes didn't fit nicely into the AVX block?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n\nReview comment:\n       Why is hardware_flags an int64 instead of a bool?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-07T03:34:17.764+0000",
                    "updated": "2022-01-07T03:34:17.764+0000",
                    "started": "2022-01-07T03:34:17.764+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "704885",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/714161",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r791242565\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n\nReview comment:\n       ```suggestion\r\n       ARROW_SCOPED_TRACE(\"bit rotation=\", with_rotation ? \"ON\" : \"OFF\");\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n\nReview comment:\n       ```suggestion\r\n         ASSERT_TRUE(reference.IsSameAs(&bloom));\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.cc\n##########\n@@ -0,0 +1,434 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include <random>\n+#include \"arrow/compute/exec/util.h\"  // PREFETCH\n+#include \"arrow/util/bit_util.h\"      // Log2\n+#include \"arrow/util/bitmap_ops.h\"    // CountSetBits\n+\n+namespace arrow {\n+namespace compute {\n+\n+BloomFilterMasks::BloomFilterMasks() {\n+  std::seed_seq seed{0, 0, 0, 0, 0, 0, 0, 0};\n+  std::mt19937 re(seed);\n+  std::uniform_int_distribution<uint64_t> rd;\n+  auto random = [&re, &rd](int min_value, int max_value) {\n+    return min_value + rd(re) % (max_value - min_value + 1);\n+  };\n+\n+  memset(masks_, 0, kTotalBytes);\n+\n+  // Prepare the first mask\n+  //\n+  int num_bits_set = static_cast<int>(random(kMinBitsSet, kMaxBitsSet));\n+  for (int i = 0; i < num_bits_set; ++i) {\n+    for (;;) {\n+      int bit_pos = static_cast<int>(random(0, kBitsPerMask - 1));\n+      if (!bit_util::GetBit(masks_, bit_pos)) {\n+        bit_util::SetBit(masks_, bit_pos);\n+        break;\n+      }\n+    }\n+  }\n+\n+  int64_t num_bits_total = kNumMasks + kBitsPerMask - 1;\n+\n+  // The value num_bits_set will be updated in each iteration of the loop to\n+  // represent the number of bits set in the entire mask directly preceding the\n+  // currently processed bit.\n+  //\n+  for (int64_t i = kBitsPerMask; i < num_bits_total; ++i) {\n+    // The value of the lowest bit of the previous mask that will be removed\n+    // from the current mask as we move to the next position in the bit vector\n+    // of masks.\n+    //\n+    int bit_leaving = bit_util::GetBit(masks_, i - kBitsPerMask) ? 1 : 0;\n+\n+    // Next bit has to be 1 because of minimum bits in a mask requirement\n+    //\n+    if (bit_leaving == 1 && num_bits_set == kMinBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      continue;\n+    }\n+\n+    // Next bit has to be 0 because of maximum bits in a mask requirement\n+    //\n+    if (bit_leaving == 0 && num_bits_set == kMaxBitsSet) {\n+      continue;\n+    }\n+\n+    // Next bit can be random. Use the expected number of bits set in a mask\n+    // as a probability of 1.\n+    //\n+    if (random(0, kBitsPerMask * 2 - 1) < kMinBitsSet + kMaxBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      if (bit_leaving == 0) {\n+        ++num_bits_set;\n+      }\n+    } else {\n+      if (bit_leaving == 1) {\n+        --num_bits_set;\n+      }\n+    }\n+  }\n+}\n+\n+BloomFilterMasks BlockedBloomFilter::masks_;\n+\n+Status BlockedBloomFilter::CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool) {\n+  // Compute the size\n+  //\n+  constexpr int64_t min_num_bits_per_key = 8;\n+  constexpr int64_t min_num_bits = 512;\n+  int64_t desired_num_bits =\n+      std::max(min_num_bits, num_rows_to_insert * min_num_bits_per_key);\n+  int log_num_bits = bit_util::Log2(desired_num_bits);\n+\n+  log_num_blocks_ = log_num_bits - 6;\n+  num_blocks_ = 1ULL << log_num_blocks_;\n+\n+  // Allocate and zero out bit vector\n+  //\n+  int64_t buffer_size = num_blocks_ * sizeof(uint64_t);\n+  ARROW_ASSIGN_OR_RAISE(buf_, AllocateBuffer(buffer_size, pool));\n+  blocks_ = reinterpret_cast<uint64_t*>(buf_->mutable_data());\n+  memset(blocks_, 0, buffer_size);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BlockedBloomFilter::InsertImp(int64_t num_rows, const T* hashes) {\n+  for (int64_t i = 0; i < num_rows; ++i) {\n+    Insert(hashes[i]);\n+  }\n+}\n+\n+void BlockedBloomFilter::Insert(int64_t hardware_flags, int64_t num_rows,\n+                                const uint32_t* hashes) {\n+  int64_t num_processed = 0;\n+#if defined(ARROW_HAVE_AVX2)\n+  if (hardware_flags & arrow::internal::CpuInfo::AVX2) {\n+    num_processed = Insert_avx2(num_rows, hashes);\n+  }\n+#endif\n+  InsertImp(num_rows - num_processed, hashes + num_processed);\n+}\n+\n+void BlockedBloomFilter::Insert(int64_t hardware_flags, int64_t num_rows,\n+                                const uint64_t* hashes) {\n+  int64_t num_processed = 0;\n+#if defined(ARROW_HAVE_AVX2)\n+  if (hardware_flags & arrow::internal::CpuInfo::AVX2) {\n+    num_processed = Insert_avx2(num_rows, hashes);\n+  }\n+#endif\n+  InsertImp(num_rows - num_processed, hashes + num_processed);\n+}\n+\n+template <typename T>\n+void BlockedBloomFilter::FindImp(int64_t num_rows, const T* hashes,\n+                                 uint8_t* result_bit_vector, bool enable_prefetch) const {\n+  int64_t num_processed = 0;\n+  uint64_t bits = 0ULL;\n+\n+  if (enable_prefetch && UsePrefetch()) {\n+    constexpr int kPrefetchIterations = 16;\n+    for (int64_t i = 0; i < num_rows - kPrefetchIterations; ++i) {\n+      PREFETCH(blocks_ + block_id(hashes[i + kPrefetchIterations]));\n+      uint64_t result = Find(hashes[i]) ? 1ULL : 0ULL;\n+      bits |= result << (i & 63);\n+      if ((i & 63) == 63) {\n+        reinterpret_cast<uint64_t*>(result_bit_vector)[i / 64] = bits;\n+        bits = 0ULL;\n+      }\n+    }\n+    num_processed = num_rows - kPrefetchIterations;\n+  }\n+\n+  for (int64_t i = num_processed; i < num_rows; ++i) {\n+    uint64_t result = Find(hashes[i]) ? 1ULL : 0ULL;\n+    bits |= result << (i & 63);\n+    if ((i & 63) == 63) {\n+      reinterpret_cast<uint64_t*>(result_bit_vector)[i / 64] = bits;\n+      bits = 0ULL;\n+    }\n+  }\n+\n+  for (int i = 0; i < bit_util::CeilDiv(num_rows % 64, 8); ++i) {\n+    result_bit_vector[num_rows / 64 * 8 + i] = static_cast<uint8_t>(bits >> (i * 8));\n+  }\n+}\n+\n+void BlockedBloomFilter::Find(int64_t hardware_flags, int64_t num_rows,\n+                              const uint32_t* hashes, uint8_t* result_bit_vector,\n+                              bool enable_prefetch) const {\n+  int64_t num_processed = 0;\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  if (!(enable_prefetch && UsePrefetch()) &&\n+      (hardware_flags & arrow::internal::CpuInfo::AVX2)) {\n+    num_processed = Find_avx2(num_rows, hashes, result_bit_vector);\n+    // Make sure that the results in bit vector for the remaining rows start at\n+    // a byte boundary.\n+    //\n+    num_processed -= (num_processed % 8);\n+  }\n+#endif\n+\n+  ARROW_DCHECK(num_processed % 8 == 0);\n+  FindImp(num_rows - num_processed, hashes + num_processed,\n+          result_bit_vector + num_processed / 8, enable_prefetch);\n+}\n+\n+void BlockedBloomFilter::Find(int64_t hardware_flags, int64_t num_rows,\n+                              const uint64_t* hashes, uint8_t* result_bit_vector,\n+                              bool enable_prefetch) const {\n+  int64_t num_processed = 0;\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  if (!(enable_prefetch && UsePrefetch()) &&\n+      (hardware_flags & arrow::internal::CpuInfo::AVX2)) {\n+    num_processed = Find_avx2(num_rows, hashes, result_bit_vector);\n+    num_processed -= (num_processed % 8);\n+  }\n+#endif\n+\n+  ARROW_DCHECK(num_processed % 8 == 0);\n+  FindImp(num_rows - num_processed, hashes + num_processed,\n+          result_bit_vector + num_processed / 8, enable_prefetch);\n+}\n+\n+void BlockedBloomFilter::Fold() {\n+  // Keep repeating until one of the stop conditions checked inside the loop\n+  // is met\n+  for (;;) {\n+    // If we reached the minimum size of blocked Bloom filter then stop\n+    constexpr int log_num_blocks_min = 4;\n+    if (log_num_blocks_ <= log_num_blocks_min) {\n+      break;\n+    }\n+\n+    int64_t num_bits = num_blocks_ * 64;\n+\n+    // Calculate the number of bits set in this blocked Bloom filter\n+    int64_t num_bits_set = 0;\n+    int batch_size_max = 65536;\n+    for (int64_t i = 0; i < num_bits; i += batch_size_max) {\n+      int batch_size =\n+          static_cast<int>(std::min(num_bits - i, static_cast<int64_t>(batch_size_max)));\n+      num_bits_set +=\n+          arrow::internal::CountSetBits(reinterpret_cast<const uint8_t*>(blocks_) + i / 8,\n+                                        /*offset=*/0, batch_size);\n+    }\n+\n+    // If at least 1/4 of bits is set then stop\n+    if (4 * num_bits_set >= num_bits) {\n+      break;\n+    }\n+\n+    // Decide how many times to fold at once.\n+    // The resulting size should not be less than log_num_bits_min.\n+    int num_folds = 1;\n+\n+    while ((log_num_blocks_ - num_folds) > log_num_blocks_min &&\n+           (4 * num_bits_set) < (num_bits >> num_folds)) {\n+      ++num_folds;\n+    }\n+\n+    // Actual update to block Bloom filter bits\n+    SingleFold(num_folds);\n+  }\n+}\n+\n+void BlockedBloomFilter::SingleFold(int num_folds) {\n+  // Calculate number of slices and size of a slice\n+  //\n+  int64_t num_slices = 1LL << num_folds;\n+  int64_t num_slice_blocks = (num_blocks_ >> num_folds);\n+  uint64_t* target_slice = blocks_;\n+\n+  // OR bits of all the slices and store result in the first slice\n+  //\n+  for (int64_t slice = 1; slice < num_slices; ++slice) {\n+    const uint64_t* source_slice = blocks_ + slice * num_slice_blocks;\n+    for (int i = 0; i < num_slice_blocks; ++i) {\n+      target_slice[i] |= source_slice[i];\n+    }\n+  }\n+\n+  log_num_blocks_ -= num_folds;\n+  num_blocks_ = 1ULL << log_num_blocks_;\n+}\n+\n+int BlockedBloomFilter::NumHashBitsUsed() const {\n+  constexpr int num_bits_for_mask = (BloomFilterMasks::kLogNumMasks + 6);\n+  int num_bits_for_block = log_num_blocks();\n+  return num_bits_for_mask + num_bits_for_block;\n+}\n+\n+bool BlockedBloomFilter::IsSameAs(const BlockedBloomFilter* other) const {\n+  if (log_num_blocks_ != other->log_num_blocks_ || num_blocks_ != other->num_blocks_) {\n+    return false;\n+  }\n+  if (memcmp(blocks_, other->blocks_, num_blocks_ * sizeof(uint64_t)) != 0) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+int64_t BlockedBloomFilter::NumBitsSet() const {\n+  return arrow::internal::CountSetBits(reinterpret_cast<const uint8_t*>(blocks_),\n+                                       /*offset=*/0, (1LL << log_num_blocks()) * 64);\n+}\n+\n+Status BloomFilterBuilder_SingleThreaded::Begin(size_t /*num_threads*/,\n+                                                int64_t hardware_flags, MemoryPool* pool,\n+                                                int64_t num_rows, int64_t /*num_batches*/,\n+                                                BlockedBloomFilter* build_target) {\n+  hardware_flags_ = hardware_flags;\n+  build_target_ = build_target;\n+\n+  RETURN_NOT_OK(build_target->CreateEmpty(num_rows, pool));\n+\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_SingleThreaded::PushNextBatch(size_t /*thread_index*/,\n+                                                        int num_rows,\n+                                                        const uint32_t* hashes) {\n+  PushNextBatchImp(num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_SingleThreaded::PushNextBatch(size_t /*thread_index*/,\n+                                                        int num_rows,\n+                                                        const uint64_t* hashes) {\n+  PushNextBatchImp(num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BloomFilterBuilder_SingleThreaded::PushNextBatchImp(int num_rows, const T* hashes) {\n+  build_target_->Insert(hardware_flags_, num_rows, hashes);\n+}\n+\n+Status BloomFilterBuilder_Parallel::Begin(size_t num_threads, int64_t hardware_flags,\n+                                          MemoryPool* pool, int64_t num_rows,\n+                                          int64_t /*num_batches*/,\n+                                          BlockedBloomFilter* build_target) {\n+  hardware_flags_ = hardware_flags;\n+  build_target_ = build_target;\n+\n+  constexpr int kMaxLogNumPrtns = 8;\n+  log_num_prtns_ = std::min(kMaxLogNumPrtns, bit_util::Log2(num_threads));\n+\n+  thread_local_states_.resize(num_threads);\n+  prtn_locks_.Init(1 << log_num_prtns_);\n+\n+  RETURN_NOT_OK(build_target->CreateEmpty(num_rows, pool));\n+\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_Parallel::PushNextBatch(size_t thread_id, int num_rows,\n+                                                  const uint32_t* hashes) {\n+  PushNextBatchImp(thread_id, num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_Parallel::PushNextBatch(size_t thread_id, int num_rows,\n+                                                  const uint64_t* hashes) {\n+  PushNextBatchImp(thread_id, num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BloomFilterBuilder_Parallel::PushNextBatchImp(size_t thread_id, int num_rows,\n+                                                   const T* hashes) {\n+  int num_prtns = 1 << log_num_prtns_;\n+  ThreadLocalState& local_state = thread_local_states_[thread_id];\n+  local_state.partition_ranges.resize(num_prtns + 1);\n+  local_state.partitioned_hashes_64.resize(num_rows);\n+  local_state.unprocessed_partition_ids.resize(num_prtns);\n+  uint16_t* partition_ranges = local_state.partition_ranges.data();\n+  uint64_t* partitioned_hashes = local_state.partitioned_hashes_64.data();\n+  int* unprocessed_partition_ids = local_state.unprocessed_partition_ids.data();\n+\n+  PartitionSort::Eval(\n+      num_rows, num_prtns, partition_ranges,\n+      [hashes, num_prtns](int row_id) {\n+        constexpr int kLogBlocksKeptTogether = 7;\n+        constexpr int kPrtnIdBitOffset =\n+            BloomFilterMasks::kLogNumMasks + 6 + kLogBlocksKeptTogether;\n+        return (hashes[row_id] >> (kPrtnIdBitOffset)) & (num_prtns - 1);\n+      },\n+      [hashes, partitioned_hashes](int row_id, int output_pos) {\n+        partitioned_hashes[output_pos] = hashes[row_id];\n+      });\n+\n+  int num_unprocessed_partitions = 0;\n+  for (int i = 0; i < num_prtns; ++i) {\n+    bool is_prtn_empty = (partition_ranges[i + 1] == partition_ranges[i]);\n+    if (!is_prtn_empty) {\n+      unprocessed_partition_ids[num_unprocessed_partitions++] = i;\n+    }\n+  }\n+  while (num_unprocessed_partitions > 0) {\n+    int locked_prtn_id;\n+    int locked_prtn_id_pos;\n+    prtn_locks_.AcquirePartitionLock(num_unprocessed_partitions,\n+                                     unprocessed_partition_ids,\n+                                     /*limit_retries=*/false, /*max_retries=*/-1,\n+                                     &locked_prtn_id, &locked_prtn_id_pos);\n+    build_target_->Insert(\n+        hardware_flags_,\n+        partition_ranges[locked_prtn_id + 1] - partition_ranges[locked_prtn_id],\n+        partitioned_hashes + partition_ranges[locked_prtn_id]);\n+    prtn_locks_.ReleasePartitionLock(locked_prtn_id);\n+    if (locked_prtn_id_pos < num_unprocessed_partitions - 1) {\n+      unprocessed_partition_ids[locked_prtn_id_pos] =\n+          unprocessed_partition_ids[num_unprocessed_partitions - 1];\n+    }\n+    --num_unprocessed_partitions;\n+  }\n+}\n\nReview comment:\n       So each thread will keep picking partitions at random until all partitions are gone?  It's a sort of dynamic scheduling approach that handles load balancing automatically?\r\n   \r\n   I think that is clever (as we won't really know in general at any point in time how many threads are available to do work) and I'm curious to see how it would be used in practice.\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes);\n+\n+  // Uses SIMD if available for smaller Bloom filters.\n+  // Uses memory prefetching for larger Bloom filters.\n+  //\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+\n+  // Folding of a block Bloom filter after the initial version\n+  // has been built.\n+  //\n+  // One of the parameters for creation of Bloom filter is the number\n+  // of bits allocated for it. The more bits allocated, the lower the\n+  // probability of false positives. A good heuristic is to aim for\n+  // half of the bits set in the constructed Bloom filter. This should\n+  // result in a good trade off between size (and following cost of\n+  // memory accesses) and false positives rate.\n+  //\n+  // There might have been many duplicate keys in the input provided\n+  // to Bloom filter builder. In that case the resulting bit vector\n+  // would be more sparse then originally intended. It is possible to\n+  // easily correct that and cut in half the size of Bloom filter\n+  // after it has already been constructed. The process to do that is\n+  // approximately equal to OR-ing bits from upper and lower half (the\n+  // way we address these bits when inserting or querying a hash makes\n+  // such folding in half possible).\n+  //\n+  // We will keep folding as long as the fraction of bits set is less\n+  // than 1/4. The resulting bit vector density should be in the [1/4,\n+  // 1/2) range.\n+  //\n+  void Fold();\n+\n+  int log_num_blocks() const { return log_num_blocks_; }\n+\n+  int NumHashBitsUsed() const;\n+\n+  bool IsSameAs(const BlockedBloomFilter* other) const;\n+\n+  int64_t NumBitsSet() const;\n+\n+ private:\n+  inline uint64_t mask(uint64_t hash) const {\n+    // The lowest bits of hash are used to pick mask index.\n+    //\n+    int mask_id = static_cast<int>(hash & (BloomFilterMasks::kNumMasks - 1));\n+    uint64_t result = masks_.mask(mask_id);\n+\n+    // The next set of hash bits is used to pick the amount of bit\n+    // rotation of the mask.\n+    //\n+    int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\n+    result = ROTL64(result, rotation);\n+\n\nReview comment:\n       ```suggestion\r\n       int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\r\n       if (rotation != 0) {\r\n         result = ROTL64(result, rotation);\r\n       }\r\n   ```\r\n   `ROTL64(x, 0)` is technically undefined because your polyfill becomes `(x << 0) | (x >> 64)` and `x >> 64` is undefined.\n\n##########\nFile path: cpp/src/arrow/compute/exec/key_hash_avx2.cc\n##########\n@@ -18,248 +18,302 @@\n #include <immintrin.h>\n \n #include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/util/bit_util.h\"\n \n namespace arrow {\n namespace compute {\n \n #if defined(ARROW_HAVE_AVX2)\n \n-void Hashing::avalanche_avx2(uint32_t num_keys, uint32_t* hashes) {\n+inline __m256i Hashing32::avalanche_avx2(__m256i hash) {\n+  hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 15));\n+  hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_2));\n+  hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 13));\n+  hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_3));\n+  hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 16));\n+  return hash;\n+}\n+\n+inline __m256i Hashing32::combine_hashes_avx2(__m256i previous_hash, __m256i hash) {\n+  // previous_hash ^= acc + kCombineConst + (previous_hash << 6) +\n+  // (previous_hash >> 2);\n+  //\n+  __m256i x = _mm256_add_epi32(_mm256_slli_epi32(previous_hash, 6),\n+                               _mm256_srli_epi32(previous_hash, 2));\n+  __m256i y = _mm256_add_epi32(hash, _mm256_set1_epi32(kCombineConst));\n+  __m256i new_hash = _mm256_xor_si256(previous_hash, _mm256_add_epi32(x, y));\n+  return new_hash;\n+}\n+\n+template <bool T_COMBINE_HASHES>\n+void Hashing32::avalanche_all_avx2(uint32_t num_rows_to_process, uint32_t* hashes,\n+                                   const uint32_t* hashes_temp_for_combine) {\n   constexpr int unroll = 8;\n-  ARROW_DCHECK(num_keys % unroll == 0);\n-  for (uint32_t i = 0; i < num_keys / unroll; ++i) {\n-    __m256i hash = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + i);\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 15));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_2));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 13));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_3));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 16));\n-    _mm256_storeu_si256((reinterpret_cast<__m256i*>(hashes)) + i, hash);\n+  for (uint32_t i = 0; i < num_rows_to_process / unroll; ++i) {\n+    __m256i acc;\n+    if (T_COMBINE_HASHES) {\n+      acc = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes_temp_for_combine) +\n+                               i);\n+    } else {\n+      acc = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + i);\n+    }\n+    acc = avalanche_avx2(acc);\n+    if (T_COMBINE_HASHES) {\n+      __m256i previous_hash =\n+          _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + i);\n+      acc = combine_hashes_avx2(previous_hash, acc);\n+    }\n+    _mm256_storeu_si256(reinterpret_cast<__m256i*>(hashes) + i, acc);\n   }\n+  for (uint32_t i = num_rows_to_process - (num_rows_to_process % unroll);\n+       i < num_rows_to_process; ++i) {\n+    if (T_COMBINE_HASHES) {\n+      hashes[i] = combine_hashes(hashes[i], avalanche(hashes_temp_for_combine[i]));\n+    } else {\n+      hashes[i] = avalanche(hashes[i]);\n+    }\n+  }\n+}\n+\n+inline __m256i Hashing32::round_avx2(__m256i acc, __m256i input) {\n+  acc = _mm256_add_epi32(acc, _mm256_mullo_epi32(input, _mm256_set1_epi32(PRIME32_2)));\n+  acc = _mm256_or_si256(_mm256_slli_epi32(acc, 13), _mm256_srli_epi32(acc, 32 - 13));\n+  acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_1));\n+  return acc;\n }\n \n-inline uint64_t Hashing::combine_accumulators_avx2(__m256i acc) {\n-  acc = _mm256_or_si256(\n-      _mm256_sllv_epi32(acc, _mm256_setr_epi32(1, 7, 12, 18, 1, 7, 12, 18)),\n-      _mm256_srlv_epi32(acc, _mm256_setr_epi32(32 - 1, 32 - 7, 32 - 12, 32 - 18, 32 - 1,\n-                                               32 - 7, 32 - 12, 32 - 18)));\n+inline uint64_t Hashing32::combine_accumulators_avx2(__m256i acc) {\n+  // Each 128-bit lane of input represents a set of 4 accumulators related to\n+  // a single hash (we process here two hashes together).\n+  //\n+  __m256i rotate_const_left = _mm256_setr_epi32(1, 7, 12, 18, 1, 7, 12, 18);\n+  __m256i rotate_const_right = _mm256_setr_epi32(32 - 1, 32 - 7, 32 - 12, 32 - 18, 32 - 1,\n+                                                 32 - 7, 32 - 12, 32 - 18);\n+\n+  acc = _mm256_or_si256(_mm256_sllv_epi32(acc, rotate_const_left),\n+                        _mm256_srlv_epi32(acc, rotate_const_right));\n   acc = _mm256_add_epi32(acc, _mm256_shuffle_epi32(acc, 0xee));  // 0b11101110\n   acc = _mm256_add_epi32(acc, _mm256_srli_epi64(acc, 32));\n   acc = _mm256_permutevar8x32_epi32(acc, _mm256_setr_epi32(0, 4, 0, 0, 0, 0, 0, 0));\n   uint64_t result = _mm256_extract_epi64(acc, 0);\n   return result;\n }\n \n-void Hashing::helper_stripes_avx2(uint32_t num_keys, uint32_t key_length,\n-                                  const uint8_t* keys, uint32_t* hash) {\n+inline __m256i Hashing32::stripe_mask_avx2(int i, int j) {\n+  // Return two 16 byte masks, where the first i/j bytes are 0xff and the\n+  // remaining ones are 0x00\n+  //\n+  ARROW_DCHECK(i >= 0 && i <= kStripeSize && j >= 0 && j <= kStripeSize);\n+  return _mm256_cmpgt_epi8(\n+      _mm256_blend_epi32(_mm256_set1_epi8(i), _mm256_set1_epi8(j), 0xf0),\n+      _mm256_setr_epi64x(0x0706050403020100ULL, 0x0f0e0d0c0b0a0908ULL,\n+                         0x0706050403020100ULL, 0x0f0e0d0c0b0a0908ULL));\n+}\n+\n+template <bool two_equal_lengths>\n+inline __m256i Hashing32::process_stripes_avx2(int64_t num_stripes_A,\n+                                               int64_t num_stripes_B,\n+                                               __m256i mask_last_stripe,\n+                                               const uint8_t* keys, int64_t offset_A,\n+                                               int64_t offset_B) {\n+  ARROW_DCHECK(num_stripes_A > 0 && num_stripes_B > 0);\n+\n+  __m256i acc = _mm256_setr_epi32(\n+      static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) & 0xffffffff),\n+      PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)),\n+      static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) & 0xffffffff),\n+      PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)));\n+\n+  // Constant for permutexvar8x32 instruction that conditionally swaps two\n+  // 128-bit lanes if and only if num_stripes_B > num_stripes_A.\n+  //\n+  __m256i swap_permute = _mm256_setzero_si256();\n+  int64_t offset_shorter, offset_longer;\n+  int64_t num_stripes_shorter, num_stripes_longer;\n+\n+  if (!two_equal_lengths) {\n+    int64_t swap_mask = num_stripes_B > num_stripes_A ? ~0LL : 0LL;\n+    swap_permute = _mm256_xor_si256(_mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7),\n+                                    _mm256_set1_epi32(swap_mask & 4));\n+    offset_shorter = (offset_A & swap_mask) | (offset_B & ~swap_mask);\n+    offset_longer = (offset_A & ~swap_mask) | (offset_B & swap_mask);\n+    num_stripes_shorter = (num_stripes_A & swap_mask) | (num_stripes_B & ~swap_mask);\n+    num_stripes_longer = (num_stripes_A & ~swap_mask) | (num_stripes_B & swap_mask);\n+  } else {\n+    ARROW_DCHECK(num_stripes_A == num_stripes_B);\n+    offset_longer = offset_A;\n+    offset_shorter = offset_B;\n+    num_stripes_longer = num_stripes_A;\n+    num_stripes_shorter = num_stripes_A;\n+  }\n+\n+  int64_t istripe = 0;\n+  for (; istripe + 1 < num_stripes_shorter; ++istripe) {\n+    __m256i stripe = _mm256_inserti128_si256(\n+        _mm256_castsi128_si256(_mm_loadu_si128(\n+            reinterpret_cast<const __m128i*>(keys + offset_longer) + istripe)),\n+        _mm_loadu_si128(reinterpret_cast<const __m128i*>(keys + offset_shorter) +\n+                        istripe),\n+        1);\n+    acc = round_avx2(acc, stripe);\n+  }\n+  __m256i stripe = _mm256_inserti128_si256(\n+      _mm256_castsi128_si256(_mm_loadu_si128(\n+          reinterpret_cast<const __m128i*>(keys + offset_longer) + istripe)),\n+      _mm_loadu_si128(reinterpret_cast<const __m128i*>(keys + offset_shorter) + istripe),\n+      1);\n+  if (!two_equal_lengths) {\n+    __m256i acc_copy = acc;\n+    for (; istripe + 1 < num_stripes_longer; ++istripe) {\n+      acc = round_avx2(acc, stripe);\n+      stripe = _mm256_inserti128_si256(\n+          stripe,\n+          _mm_loadu_si128(reinterpret_cast<const __m128i*>(keys + offset_longer) +\n+                          istripe + 1),\n+          0);\n+    }\n+    acc = _mm256_blend_epi32(acc, acc_copy, 0xf0);\n+    mask_last_stripe = _mm256_permutevar8x32_epi32(mask_last_stripe, swap_permute);\n+  }\n+  stripe = _mm256_and_si256(stripe, mask_last_stripe);\n+  acc = round_avx2(acc, stripe);\n+  if (!two_equal_lengths) {\n+    acc = _mm256_permutevar8x32_epi32(acc, swap_permute);\n+  }\n+  return acc;\n+}\n+\n+template <bool combine_hashes>\n+uint32_t Hashing32::hash_fixedlen_imp_avx2(uint32_t num_rows, uint64_t length,\n+                                           const uint8_t* keys, uint32_t* hashes,\n+                                           uint32_t* hashes_temp_for_combine) {\n   constexpr int unroll = 2;\n-  ARROW_DCHECK(num_keys % unroll == 0);\n-\n-  constexpr uint64_t kByteSequence0To7 = 0x0706050403020100ULL;\n-  constexpr uint64_t kByteSequence8To15 = 0x0f0e0d0c0b0a0908ULL;\n-\n-  const __m256i mask_last_stripe =\n-      (key_length % 16) <= 8\n-          ? _mm256_set1_epi8(static_cast<char>(0xffU))\n-          : _mm256_cmpgt_epi8(_mm256_set1_epi8(key_length % 16),\n-                              _mm256_setr_epi64x(kByteSequence0To7, kByteSequence8To15,\n-                                                 kByteSequence0To7, kByteSequence8To15));\n-\n-  // If length modulo stripe length is less than or equal 8, round down to the nearest 16B\n-  // boundary (8B ending will be processed in a separate function), otherwise round up.\n-  const uint32_t num_stripes = (key_length + 7) / 16;\n-  for (uint32_t i = 0; i < num_keys / unroll; ++i) {\n-    __m256i acc = _mm256_setr_epi32(\n-        static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) &\n-                              0xffffffff),\n-        PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)),\n-        static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) &\n-                              0xffffffff),\n-        PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)));\n-    auto key0 = reinterpret_cast<const __m128i*>(keys + key_length * 2 * i);\n-    auto key1 = reinterpret_cast<const __m128i*>(keys + key_length * 2 * i + key_length);\n-    for (uint32_t stripe = 0; stripe < num_stripes - 1; ++stripe) {\n-      auto key_stripe =\n-          _mm256_inserti128_si256(_mm256_castsi128_si256(_mm_loadu_si128(key0 + stripe)),\n-                                  _mm_loadu_si128(key1 + stripe), 1);\n-      acc = _mm256_add_epi32(\n-          acc, _mm256_mullo_epi32(key_stripe, _mm256_set1_epi32(PRIME32_2)));\n-      acc = _mm256_or_si256(_mm256_slli_epi32(acc, 13), _mm256_srli_epi32(acc, 32 - 13));\n-      acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_1));\n+\n+  // Do not process rows that could read past the end of the buffer using 16\n+  // byte loads. Round down number of rows to process to multiple of 2.\n+  //\n+  uint64_t num_rows_to_skip = bit_util::CeilDiv(length, kStripeSize);\n+  uint32_t num_rows_to_process =\n+      (num_rows_to_skip > num_rows)\n+          ? 0\n+          : (num_rows - static_cast<uint32_t>(num_rows_to_skip));\n+  num_rows_to_process -= (num_rows_to_process % unroll);\n+\n+  uint64_t num_stripes = bit_util::CeilDiv(length, kStripeSize);\n+  int num_tail_bytes = ((length - 1) & (kStripeSize - 1)) + 1;\n+  __m256i mask_last_stripe = stripe_mask_avx2(num_tail_bytes, num_tail_bytes);\n+\n+  for (uint32_t i = 0; i < num_rows_to_process / unroll; ++i) {\n+    __m256i acc = process_stripes_avx2</*two_equal_lengths=*/true>(\n+        num_stripes, num_stripes, mask_last_stripe, keys,\n+        static_cast<int64_t>(i) * unroll * length,\n+        static_cast<int64_t>(i) * unroll * length + length);\n+\n+    if (combine_hashes) {\n+      reinterpret_cast<uint64_t*>(hashes_temp_for_combine)[i] =\n+          combine_accumulators_avx2(acc);\n+    } else {\n+      reinterpret_cast<uint64_t*>(hashes)[i] = combine_accumulators_avx2(acc);\n     }\n-    auto key_stripe = _mm256_inserti128_si256(\n-        _mm256_castsi128_si256(_mm_loadu_si128(key0 + num_stripes - 1)),\n-        _mm_loadu_si128(key1 + num_stripes - 1), 1);\n-    key_stripe = _mm256_and_si256(key_stripe, mask_last_stripe);\n-    acc = _mm256_add_epi32(acc,\n-                           _mm256_mullo_epi32(key_stripe, _mm256_set1_epi32(PRIME32_2)));\n-    acc = _mm256_or_si256(_mm256_slli_epi32(acc, 13), _mm256_srli_epi32(acc, 32 - 13));\n-    acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_1));\n-    uint64_t result = combine_accumulators_avx2(acc);\n-    reinterpret_cast<uint64_t*>(hash)[i] = result;\n   }\n+\n+  avalanche_all_avx2<combine_hashes>(num_rows_to_process, hashes,\n+                                     hashes_temp_for_combine);\n+\n+  return num_rows_to_process;\n }\n \n-void Hashing::helper_tails_avx2(uint32_t num_keys, uint32_t key_length,\n-                                const uint8_t* keys, uint32_t* hash) {\n-  constexpr int unroll = 8;\n-  ARROW_DCHECK(num_keys % unroll == 0);\n-  auto keys_i64 = reinterpret_cast<arrow::util::int64_for_gather_t*>(keys);\n-\n-  // Process between 1 and 8 last bytes of each key, starting from 16B boundary.\n-  // The caller needs to make sure that there are no more than 8 bytes to process after\n-  // that 16B boundary.\n-  uint32_t first_offset = key_length - (key_length % 16);\n-  __m256i mask = _mm256_set1_epi64x((~0ULL) >> (8 * (8 - (key_length % 16))));\n-  __m256i offset =\n-      _mm256_setr_epi32(0, key_length, key_length * 2, key_length * 3, key_length * 4,\n-                        key_length * 5, key_length * 6, key_length * 7);\n-  offset = _mm256_add_epi32(offset, _mm256_set1_epi32(first_offset));\n-  __m256i offset_incr = _mm256_set1_epi32(key_length * 8);\n-\n-  for (uint32_t i = 0; i < num_keys / unroll; ++i) {\n-    auto v1 = _mm256_i32gather_epi64(keys_i64, _mm256_castsi256_si128(offset), 1);\n-    auto v2 = _mm256_i32gather_epi64(keys_i64, _mm256_extracti128_si256(offset, 1), 1);\n-    v1 = _mm256_and_si256(v1, mask);\n-    v2 = _mm256_and_si256(v2, mask);\n-    v1 = _mm256_permutevar8x32_epi32(v1, _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7));\n-    v2 = _mm256_permutevar8x32_epi32(v2, _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7));\n-    auto x1 = _mm256_permute2x128_si256(v1, v2, 0x20);\n-    auto x2 = _mm256_permute2x128_si256(v1, v2, 0x31);\n-    __m256i acc = _mm256_loadu_si256((reinterpret_cast<const __m256i*>(hash)) + i);\n-\n-    acc = _mm256_add_epi32(acc, _mm256_mullo_epi32(x1, _mm256_set1_epi32(PRIME32_3)));\n-    acc = _mm256_or_si256(_mm256_slli_epi32(acc, 17), _mm256_srli_epi32(acc, 32 - 17));\n-    acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_4));\n-\n-    acc = _mm256_add_epi32(acc, _mm256_mullo_epi32(x2, _mm256_set1_epi32(PRIME32_3)));\n-    acc = _mm256_or_si256(_mm256_slli_epi32(acc, 17), _mm256_srli_epi32(acc, 32 - 17));\n-    acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_4));\n-\n-    _mm256_storeu_si256((reinterpret_cast<__m256i*>(hash)) + i, acc);\n-\n-    offset = _mm256_add_epi32(offset, offset_incr);\n+uint32_t Hashing32::hash_fixedlen_avx2(bool combine_hashes, uint32_t num_rows,\n+                                       uint64_t length, const uint8_t* keys,\n+                                       uint32_t* hashes,\n+                                       uint32_t* hashes_temp_for_combine) {\n+  if (combine_hashes) {\n+    return hash_fixedlen_imp_avx2<true>(num_rows, length, keys, hashes,\n+                                        hashes_temp_for_combine);\n+  } else {\n+    return hash_fixedlen_imp_avx2<false>(num_rows, length, keys, hashes,\n+                                         hashes_temp_for_combine);\n   }\n }\n \n-void Hashing::hash_varlen_avx2(uint32_t num_rows, const uint32_t* offsets,\n-                               const uint8_t* concatenated_keys,\n-                               uint32_t* temp_buffer,  // Needs to hold 4 x 32-bit per row\n-                               uint32_t* hashes) {\n-  constexpr uint64_t kByteSequence0To7 = 0x0706050403020100ULL;\n-  constexpr uint64_t kByteSequence8To15 = 0x0f0e0d0c0b0a0908ULL;\n+template <typename T, bool combine_hashes>\n+uint32_t Hashing32::hash_varlen_imp_avx2(uint32_t num_rows, const T* offsets,\n+                                         const uint8_t* concatenated_keys,\n+                                         uint32_t* hashes,\n+                                         uint32_t* hashes_temp_for_combine) {\n+  constexpr int unroll = 2;\n \n-  const __m128i sequence = _mm_set_epi64x(kByteSequence8To15, kByteSequence0To7);\n-  const __m128i acc_init = _mm_setr_epi32(\n-      static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) & 0xffffffff),\n-      PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)));\n+  // Do not process rows that could read past the end of the buffer using 16\n+  // byte loads. Round down number of rows to process to multiple of 2.\n+  //\n+  uint32_t num_rows_to_process = num_rows;\n+  while (num_rows_to_process > 0 &&\n+         offsets[num_rows_to_process] + kStripeSize > offsets[num_rows]) {\n+    --num_rows_to_process;\n+  }\n+  num_rows_to_process -= (num_rows_to_process % unroll);\n \n-  // Variable length keys are always processed as a sequence of 16B stripes,\n-  // with the last stripe, if extending past the end of the key, having extra bytes set to\n-  // 0 on the fly.\n-  for (uint32_t ikey = 0; ikey < num_rows; ++ikey) {\n-    uint32_t begin = offsets[ikey];\n-    uint32_t end = offsets[ikey + 1];\n-    uint32_t length = end - begin;\n-    const uint8_t* base = concatenated_keys + begin;\n-\n-    __m128i acc = acc_init;\n-\n-    if (length) {\n-      uint32_t i;\n-      for (i = 0; i < (length - 1) / 16; ++i) {\n-        __m128i key_stripe = _mm_loadu_si128(reinterpret_cast<const __m128i*>(base) + i);\n-        acc = _mm_add_epi32(acc, _mm_mullo_epi32(key_stripe, _mm_set1_epi32(PRIME32_2)));\n-        acc = _mm_or_si128(_mm_slli_epi32(acc, 13), _mm_srli_epi32(acc, 32 - 13));\n-        acc = _mm_mullo_epi32(acc, _mm_set1_epi32(PRIME32_1));\n-      }\n-      __m128i key_stripe = _mm_loadu_si128(reinterpret_cast<const __m128i*>(base) + i);\n-      __m128i mask = _mm_cmpgt_epi8(_mm_set1_epi8(((length - 1) % 16) + 1), sequence);\n-      key_stripe = _mm_and_si128(key_stripe, mask);\n-      acc = _mm_add_epi32(acc, _mm_mullo_epi32(key_stripe, _mm_set1_epi32(PRIME32_2)));\n-      acc = _mm_or_si128(_mm_slli_epi32(acc, 13), _mm_srli_epi32(acc, 32 - 13));\n-      acc = _mm_mullo_epi32(acc, _mm_set1_epi32(PRIME32_1));\n-    }\n+  for (uint32_t i = 0; i < num_rows_to_process / unroll; ++i) {\n+    T offset_A = offsets[unroll * i + 0];\n+    T offset_B = offsets[unroll * i + 1];\n+    T offset_end = offsets[unroll * i + 2];\n \n-    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_buffer) + ikey, acc);\n-  }\n+    T length = offset_B - offset_A;\n+    int is_non_empty = length == 0 ? 0 : 1;\n+    int64_t num_stripes_A =\n+        static_cast<int64_t>(bit_util::CeilDiv(length, kStripeSize)) + (1 - is_non_empty);\n+    int num_tail_bytes_A = ((length - is_non_empty) & (kStripeSize - 1)) + is_non_empty;\n \n-  // Combine accumulators and perform avalanche\n-  constexpr int unroll = 8;\n-  for (uint32_t i = 0; i < num_rows / unroll; ++i) {\n-    __m256i accA =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 0);\n-    __m256i accB =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 1);\n-    __m256i accC =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 2);\n-    __m256i accD =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 3);\n-    // Transpose 2x 4x4 32-bit matrices\n-    __m256i r0 = _mm256_unpacklo_epi32(accA, accB);\n-    __m256i r1 = _mm256_unpackhi_epi32(accA, accB);\n-    __m256i r2 = _mm256_unpacklo_epi32(accC, accD);\n-    __m256i r3 = _mm256_unpackhi_epi32(accC, accD);\n-    accA = _mm256_unpacklo_epi64(r0, r2);\n-    accB = _mm256_unpackhi_epi64(r0, r2);\n-    accC = _mm256_unpacklo_epi64(r1, r3);\n-    accD = _mm256_unpackhi_epi64(r1, r3);\n-    // _rotl(accA, 1)\n-    // _rotl(accB, 7)\n-    // _rotl(accC, 12)\n-    // _rotl(accD, 18)\n-    accA = _mm256_or_si256(_mm256_slli_epi32(accA, 1), _mm256_srli_epi32(accA, 32 - 1));\n-    accB = _mm256_or_si256(_mm256_slli_epi32(accB, 7), _mm256_srli_epi32(accB, 32 - 7));\n-    accC = _mm256_or_si256(_mm256_slli_epi32(accC, 12), _mm256_srli_epi32(accC, 32 - 12));\n-    accD = _mm256_or_si256(_mm256_slli_epi32(accD, 18), _mm256_srli_epi32(accD, 32 - 18));\n-    accA = _mm256_add_epi32(_mm256_add_epi32(accA, accB), _mm256_add_epi32(accC, accD));\n-    // avalanche\n-    __m256i hash = accA;\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 15));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_2));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 13));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_3));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 16));\n-    // Store.\n-    // At this point, because of way 2x 4x4 transposition was done, output hashes are in\n-    // order: 0, 2, 4, 6, 1, 3, 5, 7. Bring back the original order.\n-    _mm256_storeu_si256(\n-        reinterpret_cast<__m256i*>(hashes) + i,\n-        _mm256_permutevar8x32_epi32(hash, _mm256_setr_epi32(0, 4, 1, 5, 2, 6, 3, 7)));\n+    length = offset_end - offset_B;\n+    is_non_empty = length == 0 ? 0 : 1;\n+    int64_t num_stripes_B =\n+        static_cast<int64_t>(bit_util::CeilDiv(length, kStripeSize)) + (1 - is_non_empty);\n+    int num_tail_bytes_B = ((length - is_non_empty) & (kStripeSize - 1)) + is_non_empty;\n+\n+    __m256i mask_last_stripe = stripe_mask_avx2(num_tail_bytes_A, num_tail_bytes_B);\n+\n+    __m256i acc = process_stripes_avx2</*two_equal_lengths=*/false>(\n+        num_stripes_A, num_stripes_B, mask_last_stripe, concatenated_keys,\n+        static_cast<int64_t>(offset_A), static_cast<int64_t>(offset_B));\n+\n+    if (combine_hashes) {\n\nReview comment:\n       I'm not sure why it doesn't happen on CI (maybe just because you need to rebase) but on my machine this is matching the static function `combine_hashes` before it matches the template argument and I end up with a compile error:\r\n   \r\n   ```\r\n   /home/pace/dev/arrow/cpp/src/arrow/compute/exec/key_hash_avx2.cc:279:9: warning: address of function 'combine_hashes' will always evaluate to 'true' [-Wpointer-bool-conversion]\r\n       if (combine_hashes) {\r\n       ~~  ^~~~~~~~~~~~~~\r\n   /home/pace/dev/arrow/cpp/src/arrow/compute/exec/key_hash_avx2.cc:279:9: note: prefix with the address-of operator to silence this warning\r\n       if (combine_hashes) {\r\n           ^\r\n           &\r\n   ```\r\n   Renaming the template argument (e.g. `COMBINE_HASHES_T`) solved the issue for me.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n\nReview comment:\n       This is more informational than assertion based.  I'm not sure where the right place to put such information belongs but perhaps as a comment or in a document somewhere.  If we wanted to keep it in the unit test (e.g. to ensure that future changes didn't accidentally introduce collisiony masks) then maybe we could change it to an assertion?  For example, it seems we can assert that this ratio must be less than `0.01` when `i >2`?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n\nReview comment:\n       Is this for performance reasons?  Does this make tests too slow in debug mode?  Can you add a comment to clarify?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n\nReview comment:\n       We shouldn't print to stdout in unit tests.  You can use `SCOPED_TRACE` to add context to potential failures instead.\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n+\n+    if (!use_simd && cpu_nanos_scalar) {\n+      *cpu_nanos_scalar = nanos_per_hash;\n+    }\n+    if (use_simd && cpu_nanos_simd) {\n+      *cpu_nanos_simd = nanos_per_hash;\n+    }\n+  }\n+  if (use_32bit_hash) {\n+    for (int i = 0; i < num_rows; ++i) {\n+      hashes_scalar64[i] = hashes_scalar32[i];\n+      hashes_simd64[i] = hashes_simd32[i];\n+    }\n+  }\n+\n+  // Verify that both scalar and AVX2 implementations give the same hashes\n+  //\n+  bool ok = true;\n+  for (int i = 0; i < num_rows; ++i) {\n+    if (hashes_scalar64[i] != hashes_simd64[i]) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+    }\n+  }\n+  printf(\"%s \", ok ? \"correct\" : \"wrong\");\n\nReview comment:\n       Should this be an assert?\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n+\n+    if (!use_simd && cpu_nanos_scalar) {\n+      *cpu_nanos_scalar = nanos_per_hash;\n+    }\n+    if (use_simd && cpu_nanos_simd) {\n+      *cpu_nanos_simd = nanos_per_hash;\n+    }\n+  }\n+  if (use_32bit_hash) {\n+    for (int i = 0; i < num_rows; ++i) {\n+      hashes_scalar64[i] = hashes_scalar32[i];\n+      hashes_simd64[i] = hashes_simd32[i];\n+    }\n+  }\n+\n+  // Verify that both scalar and AVX2 implementations give the same hashes\n+  //\n+  bool ok = true;\n+  for (int i = 0; i < num_rows; ++i) {\n+    if (hashes_scalar64[i] != hashes_simd64[i]) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+    }\n+  }\n+  printf(\"%s \", ok ? \"correct\" : \"wrong\");\n+\n+  // Verify that the same key appearing multiple times generates the same hash\n+  // each time. Measure the number of unique hashes and compare to the number\n+  // of unique keys.\n+  //\n+  std::map<int, uint64_t> unique_key_to_hash;\n+  std::set<uint64_t> unique_hashes;\n+  for (int i = 0; i < num_rows; ++i) {\n+    std::map<int, uint64_t>::iterator iter = unique_key_to_hash.find(row_ids[i]);\n+    if (iter == unique_key_to_hash.end()) {\n+      unique_key_to_hash.insert(std::make_pair(row_ids[i], hashes_scalar64[i]));\n+    } else {\n+      ARROW_DCHECK(iter->second == hashes_scalar64[i]);\n+    }\n+    if (unique_hashes.find(hashes_scalar64[i]) == unique_hashes.end()) {\n+      unique_hashes.insert(hashes_scalar64[i]);\n+    }\n+  }\n+  float percent_hash_collisions = 100.0f *\n+                                  static_cast<float>(num_unique - unique_hashes.size()) /\n+                                  static_cast<float>(num_unique);\n+  printf(\"percent_hash_collisions %.2f \", percent_hash_collisions);\n+  ARROW_DCHECK(percent_hash_collisions < 5.0f);\n+\n+  printf(\"\\n\");\n+}\n+\n+TEST(VectorHash, Basic) {\n+  Random64Bit random(/*seed=*/0);\n+\n+  int numtest = 100;\n+\n+  constexpr int min_length = 1;\n+  constexpr int max_length = 50;\n+\n+  for (bool use_32bit_hash : {true, false}) {\n+    for (bool use_varlen_input : {false, true}) {\n+      for (int itest = 0; itest < numtest; ++itest) {\n+        int length = static_cast<int>(std::max(\n+            static_cast<uint64_t>(use_varlen_input ? 2 : 1),\n+            static_cast<uint64_t>(min_length +\n+                                  random.next() % (max_length - min_length + 1))));\n+\n+        TestVectorHashImp(random, use_32bit_hash, use_varlen_input,\n+                          use_varlen_input ? 0 : length, length);\n+      }\n+    }\n+  }\n+}\n+\n+TEST(VectorHash, Benchmark) {\n+  Random64Bit random(/*seed=*/0);\n+\n+  for (bool use_32bit_hash : {true, false}) {\n+    for (bool use_varlen_input : {false, true}) {\n+      std::vector<float> nanos_scalar;\n+      std::vector<float> nanos_simd;\n+      std::vector<int> lengths;\n+      for (int length = 2; length <= 64; ++length) {\n+        lengths.push_back(length);\n+      }\n+      nanos_scalar.resize(lengths.size());\n+      nanos_simd.resize(lengths.size());\n+      for (size_t i = 0; i < lengths.size(); ++i) {\n+        TestVectorHashImp(random, use_32bit_hash, use_varlen_input,\n+                          use_varlen_input ? 0 : lengths[i],\n+                          use_varlen_input ? 2 * lengths[i] : lengths[i],\n+                          &nanos_scalar[i], &nanos_simd[i]);\n+      }\n+      printf(\"%s %s (avg_length; nanos_scalar; nanos_avx2):\\n\",\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n+\n+    if (!use_simd && cpu_nanos_scalar) {\n+      *cpu_nanos_scalar = nanos_per_hash;\n+    }\n+    if (use_simd && cpu_nanos_simd) {\n+      *cpu_nanos_simd = nanos_per_hash;\n+    }\n+  }\n+  if (use_32bit_hash) {\n+    for (int i = 0; i < num_rows; ++i) {\n+      hashes_scalar64[i] = hashes_scalar32[i];\n+      hashes_simd64[i] = hashes_simd32[i];\n+    }\n+  }\n+\n+  // Verify that both scalar and AVX2 implementations give the same hashes\n+  //\n+  bool ok = true;\n+  for (int i = 0; i < num_rows; ++i) {\n+    if (hashes_scalar64[i] != hashes_simd64[i]) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+    }\n+  }\n+  printf(\"%s \", ok ? \"correct\" : \"wrong\");\n+\n+  // Verify that the same key appearing multiple times generates the same hash\n+  // each time. Measure the number of unique hashes and compare to the number\n+  // of unique keys.\n+  //\n+  std::map<int, uint64_t> unique_key_to_hash;\n+  std::set<uint64_t> unique_hashes;\n+  for (int i = 0; i < num_rows; ++i) {\n+    std::map<int, uint64_t>::iterator iter = unique_key_to_hash.find(row_ids[i]);\n+    if (iter == unique_key_to_hash.end()) {\n+      unique_key_to_hash.insert(std::make_pair(row_ids[i], hashes_scalar64[i]));\n+    } else {\n+      ARROW_DCHECK(iter->second == hashes_scalar64[i]);\n+    }\n+    if (unique_hashes.find(hashes_scalar64[i]) == unique_hashes.end()) {\n+      unique_hashes.insert(hashes_scalar64[i]);\n+    }\n+  }\n+  float percent_hash_collisions = 100.0f *\n+                                  static_cast<float>(num_unique - unique_hashes.size()) /\n+                                  static_cast<float>(num_unique);\n+  printf(\"percent_hash_collisions %.2f \", percent_hash_collisions);\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n\nReview comment:\n       ```suggestion\r\n         size_t thread_index = 0;\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n\nReview comment:\n       ```suggestion\r\n       constexpr int key_length = sizeof(uint64_t);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n\nReview comment:\n       This part belongs in a benchmark\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n\nReview comment:\n       ```suggestion\r\n       ASSERT_TRUE(found);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n\nReview comment:\n       Is there a reason `locks_` can't be a vector?  Perhaps for alignment purposes?  Could you leave a comment to the reasoning here?\n\n##########\nFile path: cpp/src/arrow/compute/exec/key_hash.h\n##########\n@@ -32,76 +32,161 @@ namespace compute {\n // Implementations are based on xxh3 32-bit algorithm description from:\n // https://github.com/Cyan4973/xxHash/blob/dev/doc/xxhash_spec.md\n //\n-class Hashing {\n+class Hashing32 {\n\nReview comment:\n       We already have a vendored version of xxhash in Arrow (src/arrow/vendored/xxhash.h).  Why do we need (for example) `Hashing32::round` and `XXH32_round`?  If this implementation is different in some way can you add some comments explaining that?\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n+  for (int i = 0; i < num_prtns; ++i) {\n+    locks_[i].lock.store(false);\n+  }\n+}\n+\n+void PartitionLocks::CleanUp() {\n+  if (locks_) {\n+    delete[] locks_;\n+    locks_ = nullptr;\n+  }\n+  num_prtns_ = 0;\n+}\n\nReview comment:\n       Can you move this logic into a constructor / destructor to stick with the style of the rest of the code base?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n\nReview comment:\n       ```suggestion\r\n         ASSERT_GE(ARROW_POPCOUNT64(mask), BloomFilterMasks::kMinBitsSet);\r\n         ASSERT_LE(ARROW_POPCOUNT64(mask), BloomFilterMasks::kMaxBitsSet);\r\n   ```\r\n   \r\n   Although this opens something of a can of worms when it comes to `static constexpr`.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n+    if (sizeof(T) == sizeof(uint32_t)) {\n+      Hashing32::hash_fixed(hardware_flags, false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint32_t*>(output_hashes) + ibase, nullptr);\n+    } else {\n+      Hashing64::hash_fixed(false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint64_t*>(output_hashes) + ibase);\n+    }\n+\n+    ibase += next_batch_size;\n+  }\n+}\n+\n+// Test with larger size Bloom filters (use large prime with arithmetic\n+// sequence modulo 2^64).\n+//\n+Status TestBloomLarge(BloomFilterBuildStrategy strategy, int64_t num_build, int dop,\n+                      bool use_simd, bool enable_prefetch, float* fpr, float* build_cost,\n+                      float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  const int64_t block = 1024;\n+  std::vector<uint64_t> first_in_block;\n+  first_in_block.resize(bit_util::CeilDiv(num_build + num_probe, block));\n+  uint64_t current = prime;\n+  for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+    if (i % block == 0) {\n+      first_in_block[i / block] = current;\n+    }\n+    current += prime;\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  for (int ibuild = 0; ibuild < 2; ++ibuild) {\n+    if (ibuild == 0 && strategy == BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      continue;\n\nReview comment:\n       So when `ibuild == 0` then you are creating the reference?  Which isn't needed when building single threaded because reference basically means \"build single threaded and see if you get the same result\"?\r\n   \r\n   I think this would be more readable as just two back-to-back calls like you have in TestBloomSmall\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n+    if (sizeof(T) == sizeof(uint32_t)) {\n+      Hashing32::hash_fixed(hardware_flags, false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint32_t*>(output_hashes) + ibase, nullptr);\n+    } else {\n+      Hashing64::hash_fixed(false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint64_t*>(output_hashes) + ibase);\n+    }\n+\n+    ibase += next_batch_size;\n+  }\n+}\n+\n+// Test with larger size Bloom filters (use large prime with arithmetic\n+// sequence modulo 2^64).\n+//\n+Status TestBloomLarge(BloomFilterBuildStrategy strategy, int64_t num_build, int dop,\n+                      bool use_simd, bool enable_prefetch, float* fpr, float* build_cost,\n+                      float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  const int64_t block = 1024;\n+  std::vector<uint64_t> first_in_block;\n+  first_in_block.resize(bit_util::CeilDiv(num_build + num_probe, block));\n+  uint64_t current = prime;\n+  for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+    if (i % block == 0) {\n+      first_in_block[i / block] = current;\n+    }\n+    current += prime;\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  for (int ibuild = 0; ibuild < 2; ++ibuild) {\n+    if (ibuild == 0 && strategy == BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      continue;\n+    }\n+    RETURN_NOT_OK(BuildBloomFilter(\n+        ibuild == 0 ? BloomFilterBuildStrategy::SINGLE_THREADED : strategy,\n+        ibuild == 0 ? 1 : dop, hardware_flags, pool, num_build,\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint32_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint64_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        ibuild == 0 ? &reference : &bloom,\n+        ibuild == 0 ? &build_cost_single_threaded : build_cost));\n+  }\n+\n+  if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+    bool is_same = reference.IsSameAs(&bloom);\n+    printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+    ARROW_DCHECK(is_same);\n+  }\n+\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  std::vector<uint8_t> result_bit_vector;\n+  hashes32.resize(block);\n+  hashes64.resize(block);\n+  result_bit_vector.resize(bit_util::BytesForBits(block));\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  // Verify no false negatives and measure false positives.\n+  // Measure FPR and performance.\n+  //\n+  int64_t num_negatives_build = 0LL;\n+  int64_t num_negatives_probe = 0LL;\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t i = 0; i < num_build + num_probe * num_repeats;) {\n+    int64_t first_row = i < num_build ? i : num_build + ((i - num_build) % num_probe);\n+    int64_t last_row = i < num_build ? num_build : num_build + num_probe;\n+    int64_t next_batch_size = std::min(last_row - first_row, block);\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes64.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes64.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    } else {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes32.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes32.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    }\n+    uint64_t num_negatives = 0ULL;\n+    for (int iword = 0; iword < next_batch_size / 64; ++iword) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(result_bit_vector.data())[iword];\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (next_batch_size % 64 > 0) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(\n+          result_bit_vector.data())[next_batch_size / 64];\n+      uint64_t mask = (1ULL << (next_batch_size % 64)) - 1;\n+      word |= ~mask;\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (i < num_build) {\n+      num_negatives_build += num_negatives;\n+    } else {\n+      num_negatives_probe += num_negatives;\n+    }\n+    i += next_batch_size;\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+  ARROW_DCHECK(num_negatives_build == 0);\n+  printf(\"%s false_negatives %d\\n\", num_negatives_build == 0 ? \"success\" : \"failure\",\n+         static_cast<int>(num_negatives_build));\n+\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_probe * num_repeats - num_negatives_probe) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+TEST(BloomFilter, Basic) {\n+  std::vector<int64_t> num_build;\n+  constexpr int log_min = 8;\n+  constexpr int log_max = 16;\n+  constexpr int log_large = 22;\n+  for (int log_num_build = log_min; log_num_build < log_max; ++log_num_build) {\n+    constexpr int num_intermediate_points = 2;\n+    for (int i = 0; i < num_intermediate_points; ++i) {\n+      int64_t num_left = 1LL << log_num_build;\n+      int64_t num_right = 1LL << (log_num_build + 1);\n+      num_build.push_back((num_left * (num_intermediate_points - i) + num_right * i) /\n+                          num_intermediate_points);\n+    }\n+  }\n+  num_build.push_back(1LL << log_max);\n+  num_build.push_back(1LL << log_large);\n+\n+  constexpr int num_param_sets = 3;\n+  struct {\n+    bool use_avx2;\n+    bool enable_prefetch;\n+    bool insert_multiple_copies;\n+  } params[num_param_sets];\n+  for (int i = 0; i < num_param_sets; ++i) {\n+    params[i].use_avx2 = (i == 1);\n+    params[i].enable_prefetch = (i == 2);\n+    params[i].insert_multiple_copies = (i == 3);\n+  }\n\nReview comment:\n       This would probably be easier to interpret as a parameterized test.\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.h\n##########\n@@ -0,0 +1,95 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <atomic>\n+#include <cassert>\n+#include <cstdint>\n+#include <functional>\n+#include <random>\n+#include \"arrow/buffer.h\"\n+#include \"arrow/compute/exec/util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+class PartitionSort {\n+ public:\n+  // Bucket sort rows on partition ids.\n+  // Include in the output exclusive cummulative sum of bucket sizes.\n+  // This corresponds to ranges in the sorted array containing all row ids for\n+  // each of the partitions.\n+  //\n+  template <class INPUT_PRTN_ID_FN, class OUTPUT_POS_FN>\n\nReview comment:\n       Just looking at this file I think it is very difficult to tell what is supposed to be happening here.  What are the assumptions and assertions on `prtn_id_impl` and `output_pos_impl`?  Can they just return any random id or does there need to be some structure to it?  Some more comments here would help I think.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n\nReview comment:\n       It seems a lot of these test are mixing benchmarks and unit tests.  For example, you are gathering and returning `build_cost` but you aren't doing anything other than printing it.  Can you clean these tests up so that they are purely testing and then create a separate benchmark?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n+    if (sizeof(T) == sizeof(uint32_t)) {\n+      Hashing32::hash_fixed(hardware_flags, false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint32_t*>(output_hashes) + ibase, nullptr);\n+    } else {\n+      Hashing64::hash_fixed(false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint64_t*>(output_hashes) + ibase);\n+    }\n+\n+    ibase += next_batch_size;\n+  }\n+}\n+\n+// Test with larger size Bloom filters (use large prime with arithmetic\n+// sequence modulo 2^64).\n+//\n+Status TestBloomLarge(BloomFilterBuildStrategy strategy, int64_t num_build, int dop,\n+                      bool use_simd, bool enable_prefetch, float* fpr, float* build_cost,\n+                      float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  const int64_t block = 1024;\n+  std::vector<uint64_t> first_in_block;\n+  first_in_block.resize(bit_util::CeilDiv(num_build + num_probe, block));\n+  uint64_t current = prime;\n+  for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+    if (i % block == 0) {\n+      first_in_block[i / block] = current;\n+    }\n+    current += prime;\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  for (int ibuild = 0; ibuild < 2; ++ibuild) {\n+    if (ibuild == 0 && strategy == BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      continue;\n+    }\n+    RETURN_NOT_OK(BuildBloomFilter(\n+        ibuild == 0 ? BloomFilterBuildStrategy::SINGLE_THREADED : strategy,\n+        ibuild == 0 ? 1 : dop, hardware_flags, pool, num_build,\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint32_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint64_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        ibuild == 0 ? &reference : &bloom,\n+        ibuild == 0 ? &build_cost_single_threaded : build_cost));\n+  }\n+\n+  if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+    bool is_same = reference.IsSameAs(&bloom);\n+    printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+    ARROW_DCHECK(is_same);\n+  }\n+\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  std::vector<uint8_t> result_bit_vector;\n+  hashes32.resize(block);\n+  hashes64.resize(block);\n+  result_bit_vector.resize(bit_util::BytesForBits(block));\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  // Verify no false negatives and measure false positives.\n+  // Measure FPR and performance.\n+  //\n+  int64_t num_negatives_build = 0LL;\n+  int64_t num_negatives_probe = 0LL;\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t i = 0; i < num_build + num_probe * num_repeats;) {\n+    int64_t first_row = i < num_build ? i : num_build + ((i - num_build) % num_probe);\n+    int64_t last_row = i < num_build ? num_build : num_build + num_probe;\n+    int64_t next_batch_size = std::min(last_row - first_row, block);\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes64.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes64.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    } else {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes32.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes32.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    }\n+    uint64_t num_negatives = 0ULL;\n+    for (int iword = 0; iword < next_batch_size / 64; ++iword) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(result_bit_vector.data())[iword];\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (next_batch_size % 64 > 0) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(\n+          result_bit_vector.data())[next_batch_size / 64];\n+      uint64_t mask = (1ULL << (next_batch_size % 64)) - 1;\n+      word |= ~mask;\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (i < num_build) {\n+      num_negatives_build += num_negatives;\n+    } else {\n+      num_negatives_probe += num_negatives;\n+    }\n+    i += next_batch_size;\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+  ARROW_DCHECK(num_negatives_build == 0);\n+  printf(\"%s false_negatives %d\\n\", num_negatives_build == 0 ? \"success\" : \"failure\",\n+         static_cast<int>(num_negatives_build));\n+\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_probe * num_repeats - num_negatives_probe) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+TEST(BloomFilter, Basic) {\n+  std::vector<int64_t> num_build;\n+  constexpr int log_min = 8;\n+  constexpr int log_max = 16;\n+  constexpr int log_large = 22;\n+  for (int log_num_build = log_min; log_num_build < log_max; ++log_num_build) {\n+    constexpr int num_intermediate_points = 2;\n+    for (int i = 0; i < num_intermediate_points; ++i) {\n+      int64_t num_left = 1LL << log_num_build;\n+      int64_t num_right = 1LL << (log_num_build + 1);\n+      num_build.push_back((num_left * (num_intermediate_points - i) + num_right * i) /\n+                          num_intermediate_points);\n+    }\n+  }\n+  num_build.push_back(1LL << log_max);\n+  num_build.push_back(1LL << log_large);\n+\n+  constexpr int num_param_sets = 3;\n+  struct {\n+    bool use_avx2;\n+    bool enable_prefetch;\n+    bool insert_multiple_copies;\n+  } params[num_param_sets];\n+  for (int i = 0; i < num_param_sets; ++i) {\n+    params[i].use_avx2 = (i == 1);\n+    params[i].enable_prefetch = (i == 2);\n+    params[i].insert_multiple_copies = (i == 3);\n+  }\n+\n+  std::vector<BloomFilterBuildStrategy> strategy;\n+  strategy.push_back(BloomFilterBuildStrategy::SINGLE_THREADED);\n+  strategy.push_back(BloomFilterBuildStrategy::PARALLEL);\n+\n+  static constexpr int64_t min_rows_for_large = 2 * 1024 * 1024;\n+\n+  int dop = 1;  // omp_get_max_threads();\n+  // printf(\"omp_get_thread_limit() = %d\\n\", dop);\n+\n+  for (size_t istrategy = 0; istrategy < strategy.size(); ++istrategy) {\n+    for (int iparam_set = 0; iparam_set < num_param_sets; ++iparam_set) {\n+      printf(\"%s \", params[iparam_set].use_avx2                 ? \"AVX2\"\n+                    : params[iparam_set].enable_prefetch        ? \"PREFETCH\"\n+                    : params[iparam_set].insert_multiple_copies ? \"FOLDING\"\n+                                                                : \"REGULAR\");\n+      std::vector<float> fpr_vector(num_build.size());\n+      std::vector<float> probe_vector(num_build.size());\n+      for (size_t inum_build = 0; inum_build < num_build.size(); ++inum_build) {\n+        printf(\"num_build %d \", static_cast<int>(num_build[inum_build]));\n+        float fpr, build_cost, probe_cost;\n+        if (num_build[inum_build] >= min_rows_for_large) {\n+          ASSERT_OK(TestBloomLarge(strategy[istrategy], num_build[inum_build], dop,\n+                                   params[iparam_set].use_avx2,\n+                                   params[iparam_set].enable_prefetch, &fpr, &build_cost,\n+                                   &probe_cost));\n+\n+        } else {\n+          ASSERT_OK(TestBloomSmall(strategy[istrategy], num_build[inum_build],\n+                                   params[iparam_set].insert_multiple_copies ? 8 : 1, dop,\n+                                   params[iparam_set].use_avx2,\n+                                   params[iparam_set].enable_prefetch, &fpr, &build_cost,\n+                                   &probe_cost));\n+        }\n+        if (iparam_set == 0) {\n+          fpr_vector[inum_build] = fpr;\n+        }\n+        probe_vector[inum_build] = probe_cost;\n+      }\n+      if (iparam_set == 0) {\n+        printf(\"(build size; FPR percent):\\n\");\n+        for (size_t i = 0; i < num_build.size(); ++i) {\n+          printf(\"%d; %.2f;\\n\", static_cast<int>(num_build[i]), fpr_vector[i]);\n+        }\n+      }\n+      printf(\"(build size; CPU cycles per probe):\\n\");\n+      for (size_t i = 0; i < num_build.size(); ++i) {\n+        printf(\"%d; %.2f;\\n\", static_cast<int>(num_build[i]), probe_vector[i]);\n+      }\n+    }\n+  }\n+}\n+\n+TEST(BloomFilter, Scaling) {\n\nReview comment:\n       Again, this seems more like a benchmark than a test.\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n+  for (int i = 0; i < num_prtns; ++i) {\n+    locks_[i].lock.store(false);\n+  }\n+}\n+\n+void PartitionLocks::CleanUp() {\n+  if (locks_) {\n+    delete[] locks_;\n+    locks_ = nullptr;\n+  }\n+  num_prtns_ = 0;\n+}\n+\n+std::atomic<bool>* PartitionLocks::lock_ptr(int prtn_id) {\n\nReview comment:\n       Minor nit: Style-wise I think this might be simpler returning a `const std::atomic<bool>&`\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_avx2.cc\n##########\n@@ -0,0 +1,136 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n\nReview comment:\n       I'll have to see if I can find someone to review this file.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes);\n+\n+  // Uses SIMD if available for smaller Bloom filters.\n+  // Uses memory prefetching for larger Bloom filters.\n+  //\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+\n+  // Folding of a block Bloom filter after the initial version\n+  // has been built.\n+  //\n+  // One of the parameters for creation of Bloom filter is the number\n+  // of bits allocated for it. The more bits allocated, the lower the\n+  // probability of false positives. A good heuristic is to aim for\n+  // half of the bits set in the constructed Bloom filter. This should\n+  // result in a good trade off between size (and following cost of\n+  // memory accesses) and false positives rate.\n+  //\n+  // There might have been many duplicate keys in the input provided\n+  // to Bloom filter builder. In that case the resulting bit vector\n+  // would be more sparse then originally intended. It is possible to\n+  // easily correct that and cut in half the size of Bloom filter\n+  // after it has already been constructed. The process to do that is\n+  // approximately equal to OR-ing bits from upper and lower half (the\n+  // way we address these bits when inserting or querying a hash makes\n+  // such folding in half possible).\n+  //\n+  // We will keep folding as long as the fraction of bits set is less\n+  // than 1/4. The resulting bit vector density should be in the [1/4,\n+  // 1/2) range.\n+  //\n+  void Fold();\n+\n+  int log_num_blocks() const { return log_num_blocks_; }\n+\n+  int NumHashBitsUsed() const;\n+\n+  bool IsSameAs(const BlockedBloomFilter* other) const;\n+\n+  int64_t NumBitsSet() const;\n+\n+ private:\n+  inline uint64_t mask(uint64_t hash) const {\n+    // The lowest bits of hash are used to pick mask index.\n+    //\n+    int mask_id = static_cast<int>(hash & (BloomFilterMasks::kNumMasks - 1));\n+    uint64_t result = masks_.mask(mask_id);\n+\n+    // The next set of hash bits is used to pick the amount of bit\n+    // rotation of the mask.\n+    //\n+    int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\n+    result = ROTL64(result, rotation);\n+\n+    return result;\n+  }\n+\n+  inline int64_t block_id(uint64_t hash) const {\n+    // The next set of hash bits following the bits used to select a\n+    // mask is used to pick block id (index of 64-bit word in a bit\n+    // vector).\n+    //\n+    return (hash >> (BloomFilterMasks::kLogNumMasks + 6)) & (num_blocks_ - 1);\n+  }\n+\n+  template <typename T>\n+  inline void InsertImp(int64_t num_rows, const T* hashes);\n+\n+  template <typename T>\n+  inline void FindImp(int64_t num_rows, const T* hashes, uint8_t* result_bit_vector,\n+                      bool enable_prefetch) const;\n+\n+  void SingleFold(int num_folds);\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  inline __m256i mask_avx2(__m256i hash) const;\n+  inline __m256i block_id_avx2(__m256i hash) const;\n+  int64_t Insert_avx2(int64_t num_rows, const uint32_t* hashes);\n+  int64_t Insert_avx2(int64_t num_rows, const uint64_t* hashes);\n+  template <typename T>\n+  int64_t InsertImp_avx2(int64_t num_rows, const T* hashes);\n+  int64_t Find_avx2(int64_t num_rows, const uint32_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  int64_t Find_avx2(int64_t num_rows, const uint64_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  template <typename T>\n+  int64_t FindImp_avx2(int64_t num_rows, const T* hashes,\n+                       uint8_t* result_bit_vector) const;\n+#endif\n+\n+  bool UsePrefetch() const {\n+    return num_blocks_ * sizeof(uint64_t) > kPrefetchLimitBytes;\n+  }\n+\n+  static constexpr int64_t kPrefetchLimitBytes = 256 * 1024;\n+\n+  static BloomFilterMasks masks_;\n+\n+  // Total number of bits used by block Bloom filter must be a power\n+  // of 2.\n+  //\n+  int log_num_blocks_;\n+  int64_t num_blocks_;\n+\n+  // Buffer allocated to store an array of power of 2 64-bit blocks.\n+  //\n+  std::shared_ptr<Buffer> buf_;\n+  // Pointer to mutable data owned by Buffer\n+  //\n+  uint64_t* blocks_;\n+};\n+\n+enum class BloomFilterBuildStrategy {\n+  SINGLE_THREADED = 0,\n+  PARALLEL = 1,\n+};\n+\n+class BloomFilterBuilder {\n+ public:\n+  virtual ~BloomFilterBuilder() = default;\n+  virtual Status Begin(size_t num_threads, int64_t hardware_flags, MemoryPool* pool,\n+                       int64_t num_rows, int64_t num_batches,\n+                       BlockedBloomFilter* build_target) = 0;\n+  virtual int64_t num_tasks() const { return 0; }\n+  virtual void RunInitTask(int64_t task_id) {}\n+  virtual Status PushNextBatch(size_t thread_index, int num_rows,\n+                               const uint32_t* hashes) = 0;\n+  virtual Status PushNextBatch(size_t thread_index, int num_rows,\n+                               const uint64_t* hashes) = 0;\n+  virtual void RunFinishTask(int64_t task_id) {}\n+  virtual void CleanUp() {}\n+  static std::unique_ptr<BloomFilterBuilder> Make(BloomFilterBuildStrategy strategy);\n+};\n+\n+class BloomFilterBuilder_SingleThreaded : public BloomFilterBuilder {\n+ public:\n+  Status Begin(size_t num_threads, int64_t hardware_flags, MemoryPool* pool,\n+               int64_t num_rows, int64_t num_batches,\n+               BlockedBloomFilter* build_target) override;\n+\n+  Status PushNextBatch(size_t /*thread_index*/, int num_rows,\n+                       const uint32_t* hashes) override;\n+\n+  Status PushNextBatch(size_t /*thread_index*/, int num_rows,\n+                       const uint64_t* hashes) override;\n+\n+ private:\n+  template <typename T>\n+  void PushNextBatchImp(int num_rows, const T* hashes);\n+\n+  int64_t hardware_flags_;\n+  BlockedBloomFilter* build_target_;\n+};\n+\n+class BloomFilterBuilder_Parallel : public BloomFilterBuilder {\n+ public:\n+  Status Begin(size_t num_threads, int64_t hardware_flags, MemoryPool* pool,\n+               int64_t num_rows, int64_t num_batches,\n+               BlockedBloomFilter* build_target) override;\n+\n+  Status PushNextBatch(size_t thread_id, int num_rows, const uint32_t* hashes) override;\n\nReview comment:\n       Some comments around how this is meant to be used in parallel might be helpful (or a pointer to somewhere else in the code base where this is documented).  If I am making sense of the code right I think the idea is that this function can be called multiple times concurrently (each time with a different `thread_id`) but it doesn't actually do any \"scheduling\" itself.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-25T02:27:30.499+0000",
                    "updated": "2022-01-25T02:27:30.499+0000",
                    "started": "2022-01-25T02:27:30.499+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "714161",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/715041",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r791242565\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n\nReview comment:\n       ```suggestion\r\n       ARROW_SCOPED_TRACE(\"bit rotation=\", with_rotation ? \"ON\" : \"OFF\");\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n\nReview comment:\n       ```suggestion\r\n         ASSERT_TRUE(reference.IsSameAs(&bloom));\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.cc\n##########\n@@ -0,0 +1,434 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include <random>\n+#include \"arrow/compute/exec/util.h\"  // PREFETCH\n+#include \"arrow/util/bit_util.h\"      // Log2\n+#include \"arrow/util/bitmap_ops.h\"    // CountSetBits\n+\n+namespace arrow {\n+namespace compute {\n+\n+BloomFilterMasks::BloomFilterMasks() {\n+  std::seed_seq seed{0, 0, 0, 0, 0, 0, 0, 0};\n+  std::mt19937 re(seed);\n+  std::uniform_int_distribution<uint64_t> rd;\n+  auto random = [&re, &rd](int min_value, int max_value) {\n+    return min_value + rd(re) % (max_value - min_value + 1);\n+  };\n+\n+  memset(masks_, 0, kTotalBytes);\n+\n+  // Prepare the first mask\n+  //\n+  int num_bits_set = static_cast<int>(random(kMinBitsSet, kMaxBitsSet));\n+  for (int i = 0; i < num_bits_set; ++i) {\n+    for (;;) {\n+      int bit_pos = static_cast<int>(random(0, kBitsPerMask - 1));\n+      if (!bit_util::GetBit(masks_, bit_pos)) {\n+        bit_util::SetBit(masks_, bit_pos);\n+        break;\n+      }\n+    }\n+  }\n+\n+  int64_t num_bits_total = kNumMasks + kBitsPerMask - 1;\n+\n+  // The value num_bits_set will be updated in each iteration of the loop to\n+  // represent the number of bits set in the entire mask directly preceding the\n+  // currently processed bit.\n+  //\n+  for (int64_t i = kBitsPerMask; i < num_bits_total; ++i) {\n+    // The value of the lowest bit of the previous mask that will be removed\n+    // from the current mask as we move to the next position in the bit vector\n+    // of masks.\n+    //\n+    int bit_leaving = bit_util::GetBit(masks_, i - kBitsPerMask) ? 1 : 0;\n+\n+    // Next bit has to be 1 because of minimum bits in a mask requirement\n+    //\n+    if (bit_leaving == 1 && num_bits_set == kMinBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      continue;\n+    }\n+\n+    // Next bit has to be 0 because of maximum bits in a mask requirement\n+    //\n+    if (bit_leaving == 0 && num_bits_set == kMaxBitsSet) {\n+      continue;\n+    }\n+\n+    // Next bit can be random. Use the expected number of bits set in a mask\n+    // as a probability of 1.\n+    //\n+    if (random(0, kBitsPerMask * 2 - 1) < kMinBitsSet + kMaxBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      if (bit_leaving == 0) {\n+        ++num_bits_set;\n+      }\n+    } else {\n+      if (bit_leaving == 1) {\n+        --num_bits_set;\n+      }\n+    }\n+  }\n+}\n+\n+BloomFilterMasks BlockedBloomFilter::masks_;\n+\n+Status BlockedBloomFilter::CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool) {\n+  // Compute the size\n+  //\n+  constexpr int64_t min_num_bits_per_key = 8;\n+  constexpr int64_t min_num_bits = 512;\n+  int64_t desired_num_bits =\n+      std::max(min_num_bits, num_rows_to_insert * min_num_bits_per_key);\n+  int log_num_bits = bit_util::Log2(desired_num_bits);\n+\n+  log_num_blocks_ = log_num_bits - 6;\n+  num_blocks_ = 1ULL << log_num_blocks_;\n+\n+  // Allocate and zero out bit vector\n+  //\n+  int64_t buffer_size = num_blocks_ * sizeof(uint64_t);\n+  ARROW_ASSIGN_OR_RAISE(buf_, AllocateBuffer(buffer_size, pool));\n+  blocks_ = reinterpret_cast<uint64_t*>(buf_->mutable_data());\n+  memset(blocks_, 0, buffer_size);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BlockedBloomFilter::InsertImp(int64_t num_rows, const T* hashes) {\n+  for (int64_t i = 0; i < num_rows; ++i) {\n+    Insert(hashes[i]);\n+  }\n+}\n+\n+void BlockedBloomFilter::Insert(int64_t hardware_flags, int64_t num_rows,\n+                                const uint32_t* hashes) {\n+  int64_t num_processed = 0;\n+#if defined(ARROW_HAVE_AVX2)\n+  if (hardware_flags & arrow::internal::CpuInfo::AVX2) {\n+    num_processed = Insert_avx2(num_rows, hashes);\n+  }\n+#endif\n+  InsertImp(num_rows - num_processed, hashes + num_processed);\n+}\n+\n+void BlockedBloomFilter::Insert(int64_t hardware_flags, int64_t num_rows,\n+                                const uint64_t* hashes) {\n+  int64_t num_processed = 0;\n+#if defined(ARROW_HAVE_AVX2)\n+  if (hardware_flags & arrow::internal::CpuInfo::AVX2) {\n+    num_processed = Insert_avx2(num_rows, hashes);\n+  }\n+#endif\n+  InsertImp(num_rows - num_processed, hashes + num_processed);\n+}\n+\n+template <typename T>\n+void BlockedBloomFilter::FindImp(int64_t num_rows, const T* hashes,\n+                                 uint8_t* result_bit_vector, bool enable_prefetch) const {\n+  int64_t num_processed = 0;\n+  uint64_t bits = 0ULL;\n+\n+  if (enable_prefetch && UsePrefetch()) {\n+    constexpr int kPrefetchIterations = 16;\n+    for (int64_t i = 0; i < num_rows - kPrefetchIterations; ++i) {\n+      PREFETCH(blocks_ + block_id(hashes[i + kPrefetchIterations]));\n+      uint64_t result = Find(hashes[i]) ? 1ULL : 0ULL;\n+      bits |= result << (i & 63);\n+      if ((i & 63) == 63) {\n+        reinterpret_cast<uint64_t*>(result_bit_vector)[i / 64] = bits;\n+        bits = 0ULL;\n+      }\n+    }\n+    num_processed = num_rows - kPrefetchIterations;\n+  }\n+\n+  for (int64_t i = num_processed; i < num_rows; ++i) {\n+    uint64_t result = Find(hashes[i]) ? 1ULL : 0ULL;\n+    bits |= result << (i & 63);\n+    if ((i & 63) == 63) {\n+      reinterpret_cast<uint64_t*>(result_bit_vector)[i / 64] = bits;\n+      bits = 0ULL;\n+    }\n+  }\n+\n+  for (int i = 0; i < bit_util::CeilDiv(num_rows % 64, 8); ++i) {\n+    result_bit_vector[num_rows / 64 * 8 + i] = static_cast<uint8_t>(bits >> (i * 8));\n+  }\n+}\n+\n+void BlockedBloomFilter::Find(int64_t hardware_flags, int64_t num_rows,\n+                              const uint32_t* hashes, uint8_t* result_bit_vector,\n+                              bool enable_prefetch) const {\n+  int64_t num_processed = 0;\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  if (!(enable_prefetch && UsePrefetch()) &&\n+      (hardware_flags & arrow::internal::CpuInfo::AVX2)) {\n+    num_processed = Find_avx2(num_rows, hashes, result_bit_vector);\n+    // Make sure that the results in bit vector for the remaining rows start at\n+    // a byte boundary.\n+    //\n+    num_processed -= (num_processed % 8);\n+  }\n+#endif\n+\n+  ARROW_DCHECK(num_processed % 8 == 0);\n+  FindImp(num_rows - num_processed, hashes + num_processed,\n+          result_bit_vector + num_processed / 8, enable_prefetch);\n+}\n+\n+void BlockedBloomFilter::Find(int64_t hardware_flags, int64_t num_rows,\n+                              const uint64_t* hashes, uint8_t* result_bit_vector,\n+                              bool enable_prefetch) const {\n+  int64_t num_processed = 0;\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  if (!(enable_prefetch && UsePrefetch()) &&\n+      (hardware_flags & arrow::internal::CpuInfo::AVX2)) {\n+    num_processed = Find_avx2(num_rows, hashes, result_bit_vector);\n+    num_processed -= (num_processed % 8);\n+  }\n+#endif\n+\n+  ARROW_DCHECK(num_processed % 8 == 0);\n+  FindImp(num_rows - num_processed, hashes + num_processed,\n+          result_bit_vector + num_processed / 8, enable_prefetch);\n+}\n+\n+void BlockedBloomFilter::Fold() {\n+  // Keep repeating until one of the stop conditions checked inside the loop\n+  // is met\n+  for (;;) {\n+    // If we reached the minimum size of blocked Bloom filter then stop\n+    constexpr int log_num_blocks_min = 4;\n+    if (log_num_blocks_ <= log_num_blocks_min) {\n+      break;\n+    }\n+\n+    int64_t num_bits = num_blocks_ * 64;\n+\n+    // Calculate the number of bits set in this blocked Bloom filter\n+    int64_t num_bits_set = 0;\n+    int batch_size_max = 65536;\n+    for (int64_t i = 0; i < num_bits; i += batch_size_max) {\n+      int batch_size =\n+          static_cast<int>(std::min(num_bits - i, static_cast<int64_t>(batch_size_max)));\n+      num_bits_set +=\n+          arrow::internal::CountSetBits(reinterpret_cast<const uint8_t*>(blocks_) + i / 8,\n+                                        /*offset=*/0, batch_size);\n+    }\n+\n+    // If at least 1/4 of bits is set then stop\n+    if (4 * num_bits_set >= num_bits) {\n+      break;\n+    }\n+\n+    // Decide how many times to fold at once.\n+    // The resulting size should not be less than log_num_bits_min.\n+    int num_folds = 1;\n+\n+    while ((log_num_blocks_ - num_folds) > log_num_blocks_min &&\n+           (4 * num_bits_set) < (num_bits >> num_folds)) {\n+      ++num_folds;\n+    }\n+\n+    // Actual update to block Bloom filter bits\n+    SingleFold(num_folds);\n+  }\n+}\n+\n+void BlockedBloomFilter::SingleFold(int num_folds) {\n+  // Calculate number of slices and size of a slice\n+  //\n+  int64_t num_slices = 1LL << num_folds;\n+  int64_t num_slice_blocks = (num_blocks_ >> num_folds);\n+  uint64_t* target_slice = blocks_;\n+\n+  // OR bits of all the slices and store result in the first slice\n+  //\n+  for (int64_t slice = 1; slice < num_slices; ++slice) {\n+    const uint64_t* source_slice = blocks_ + slice * num_slice_blocks;\n+    for (int i = 0; i < num_slice_blocks; ++i) {\n+      target_slice[i] |= source_slice[i];\n+    }\n+  }\n+\n+  log_num_blocks_ -= num_folds;\n+  num_blocks_ = 1ULL << log_num_blocks_;\n+}\n+\n+int BlockedBloomFilter::NumHashBitsUsed() const {\n+  constexpr int num_bits_for_mask = (BloomFilterMasks::kLogNumMasks + 6);\n+  int num_bits_for_block = log_num_blocks();\n+  return num_bits_for_mask + num_bits_for_block;\n+}\n+\n+bool BlockedBloomFilter::IsSameAs(const BlockedBloomFilter* other) const {\n+  if (log_num_blocks_ != other->log_num_blocks_ || num_blocks_ != other->num_blocks_) {\n+    return false;\n+  }\n+  if (memcmp(blocks_, other->blocks_, num_blocks_ * sizeof(uint64_t)) != 0) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+int64_t BlockedBloomFilter::NumBitsSet() const {\n+  return arrow::internal::CountSetBits(reinterpret_cast<const uint8_t*>(blocks_),\n+                                       /*offset=*/0, (1LL << log_num_blocks()) * 64);\n+}\n+\n+Status BloomFilterBuilder_SingleThreaded::Begin(size_t /*num_threads*/,\n+                                                int64_t hardware_flags, MemoryPool* pool,\n+                                                int64_t num_rows, int64_t /*num_batches*/,\n+                                                BlockedBloomFilter* build_target) {\n+  hardware_flags_ = hardware_flags;\n+  build_target_ = build_target;\n+\n+  RETURN_NOT_OK(build_target->CreateEmpty(num_rows, pool));\n+\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_SingleThreaded::PushNextBatch(size_t /*thread_index*/,\n+                                                        int num_rows,\n+                                                        const uint32_t* hashes) {\n+  PushNextBatchImp(num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_SingleThreaded::PushNextBatch(size_t /*thread_index*/,\n+                                                        int num_rows,\n+                                                        const uint64_t* hashes) {\n+  PushNextBatchImp(num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BloomFilterBuilder_SingleThreaded::PushNextBatchImp(int num_rows, const T* hashes) {\n+  build_target_->Insert(hardware_flags_, num_rows, hashes);\n+}\n+\n+Status BloomFilterBuilder_Parallel::Begin(size_t num_threads, int64_t hardware_flags,\n+                                          MemoryPool* pool, int64_t num_rows,\n+                                          int64_t /*num_batches*/,\n+                                          BlockedBloomFilter* build_target) {\n+  hardware_flags_ = hardware_flags;\n+  build_target_ = build_target;\n+\n+  constexpr int kMaxLogNumPrtns = 8;\n+  log_num_prtns_ = std::min(kMaxLogNumPrtns, bit_util::Log2(num_threads));\n+\n+  thread_local_states_.resize(num_threads);\n+  prtn_locks_.Init(1 << log_num_prtns_);\n+\n+  RETURN_NOT_OK(build_target->CreateEmpty(num_rows, pool));\n+\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_Parallel::PushNextBatch(size_t thread_id, int num_rows,\n+                                                  const uint32_t* hashes) {\n+  PushNextBatchImp(thread_id, num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+Status BloomFilterBuilder_Parallel::PushNextBatch(size_t thread_id, int num_rows,\n+                                                  const uint64_t* hashes) {\n+  PushNextBatchImp(thread_id, num_rows, hashes);\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BloomFilterBuilder_Parallel::PushNextBatchImp(size_t thread_id, int num_rows,\n+                                                   const T* hashes) {\n+  int num_prtns = 1 << log_num_prtns_;\n+  ThreadLocalState& local_state = thread_local_states_[thread_id];\n+  local_state.partition_ranges.resize(num_prtns + 1);\n+  local_state.partitioned_hashes_64.resize(num_rows);\n+  local_state.unprocessed_partition_ids.resize(num_prtns);\n+  uint16_t* partition_ranges = local_state.partition_ranges.data();\n+  uint64_t* partitioned_hashes = local_state.partitioned_hashes_64.data();\n+  int* unprocessed_partition_ids = local_state.unprocessed_partition_ids.data();\n+\n+  PartitionSort::Eval(\n+      num_rows, num_prtns, partition_ranges,\n+      [hashes, num_prtns](int row_id) {\n+        constexpr int kLogBlocksKeptTogether = 7;\n+        constexpr int kPrtnIdBitOffset =\n+            BloomFilterMasks::kLogNumMasks + 6 + kLogBlocksKeptTogether;\n+        return (hashes[row_id] >> (kPrtnIdBitOffset)) & (num_prtns - 1);\n+      },\n+      [hashes, partitioned_hashes](int row_id, int output_pos) {\n+        partitioned_hashes[output_pos] = hashes[row_id];\n+      });\n+\n+  int num_unprocessed_partitions = 0;\n+  for (int i = 0; i < num_prtns; ++i) {\n+    bool is_prtn_empty = (partition_ranges[i + 1] == partition_ranges[i]);\n+    if (!is_prtn_empty) {\n+      unprocessed_partition_ids[num_unprocessed_partitions++] = i;\n+    }\n+  }\n+  while (num_unprocessed_partitions > 0) {\n+    int locked_prtn_id;\n+    int locked_prtn_id_pos;\n+    prtn_locks_.AcquirePartitionLock(num_unprocessed_partitions,\n+                                     unprocessed_partition_ids,\n+                                     /*limit_retries=*/false, /*max_retries=*/-1,\n+                                     &locked_prtn_id, &locked_prtn_id_pos);\n+    build_target_->Insert(\n+        hardware_flags_,\n+        partition_ranges[locked_prtn_id + 1] - partition_ranges[locked_prtn_id],\n+        partitioned_hashes + partition_ranges[locked_prtn_id]);\n+    prtn_locks_.ReleasePartitionLock(locked_prtn_id);\n+    if (locked_prtn_id_pos < num_unprocessed_partitions - 1) {\n+      unprocessed_partition_ids[locked_prtn_id_pos] =\n+          unprocessed_partition_ids[num_unprocessed_partitions - 1];\n+    }\n+    --num_unprocessed_partitions;\n+  }\n+}\n\nReview comment:\n       So each thread will keep picking partitions at random until all partitions are gone?  It's a sort of dynamic scheduling approach that handles load balancing automatically?\r\n   \r\n   I think that is clever (as we won't really know in general at any point in time how many threads are available to do work) and I'm curious to see how it would be used in practice.\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes);\n+\n+  // Uses SIMD if available for smaller Bloom filters.\n+  // Uses memory prefetching for larger Bloom filters.\n+  //\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+\n+  // Folding of a block Bloom filter after the initial version\n+  // has been built.\n+  //\n+  // One of the parameters for creation of Bloom filter is the number\n+  // of bits allocated for it. The more bits allocated, the lower the\n+  // probability of false positives. A good heuristic is to aim for\n+  // half of the bits set in the constructed Bloom filter. This should\n+  // result in a good trade off between size (and following cost of\n+  // memory accesses) and false positives rate.\n+  //\n+  // There might have been many duplicate keys in the input provided\n+  // to Bloom filter builder. In that case the resulting bit vector\n+  // would be more sparse then originally intended. It is possible to\n+  // easily correct that and cut in half the size of Bloom filter\n+  // after it has already been constructed. The process to do that is\n+  // approximately equal to OR-ing bits from upper and lower half (the\n+  // way we address these bits when inserting or querying a hash makes\n+  // such folding in half possible).\n+  //\n+  // We will keep folding as long as the fraction of bits set is less\n+  // than 1/4. The resulting bit vector density should be in the [1/4,\n+  // 1/2) range.\n+  //\n+  void Fold();\n+\n+  int log_num_blocks() const { return log_num_blocks_; }\n+\n+  int NumHashBitsUsed() const;\n+\n+  bool IsSameAs(const BlockedBloomFilter* other) const;\n+\n+  int64_t NumBitsSet() const;\n+\n+ private:\n+  inline uint64_t mask(uint64_t hash) const {\n+    // The lowest bits of hash are used to pick mask index.\n+    //\n+    int mask_id = static_cast<int>(hash & (BloomFilterMasks::kNumMasks - 1));\n+    uint64_t result = masks_.mask(mask_id);\n+\n+    // The next set of hash bits is used to pick the amount of bit\n+    // rotation of the mask.\n+    //\n+    int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\n+    result = ROTL64(result, rotation);\n+\n\nReview comment:\n       ```suggestion\r\n       int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\r\n       if (rotation != 0) {\r\n         result = ROTL64(result, rotation);\r\n       }\r\n   ```\r\n   `ROTL64(x, 0)` is technically undefined because your polyfill becomes `(x << 0) | (x >> 64)` and `x >> 64` is undefined.\n\n##########\nFile path: cpp/src/arrow/compute/exec/key_hash_avx2.cc\n##########\n@@ -18,248 +18,302 @@\n #include <immintrin.h>\n \n #include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/util/bit_util.h\"\n \n namespace arrow {\n namespace compute {\n \n #if defined(ARROW_HAVE_AVX2)\n \n-void Hashing::avalanche_avx2(uint32_t num_keys, uint32_t* hashes) {\n+inline __m256i Hashing32::avalanche_avx2(__m256i hash) {\n+  hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 15));\n+  hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_2));\n+  hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 13));\n+  hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_3));\n+  hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 16));\n+  return hash;\n+}\n+\n+inline __m256i Hashing32::combine_hashes_avx2(__m256i previous_hash, __m256i hash) {\n+  // previous_hash ^= acc + kCombineConst + (previous_hash << 6) +\n+  // (previous_hash >> 2);\n+  //\n+  __m256i x = _mm256_add_epi32(_mm256_slli_epi32(previous_hash, 6),\n+                               _mm256_srli_epi32(previous_hash, 2));\n+  __m256i y = _mm256_add_epi32(hash, _mm256_set1_epi32(kCombineConst));\n+  __m256i new_hash = _mm256_xor_si256(previous_hash, _mm256_add_epi32(x, y));\n+  return new_hash;\n+}\n+\n+template <bool T_COMBINE_HASHES>\n+void Hashing32::avalanche_all_avx2(uint32_t num_rows_to_process, uint32_t* hashes,\n+                                   const uint32_t* hashes_temp_for_combine) {\n   constexpr int unroll = 8;\n-  ARROW_DCHECK(num_keys % unroll == 0);\n-  for (uint32_t i = 0; i < num_keys / unroll; ++i) {\n-    __m256i hash = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + i);\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 15));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_2));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 13));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_3));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 16));\n-    _mm256_storeu_si256((reinterpret_cast<__m256i*>(hashes)) + i, hash);\n+  for (uint32_t i = 0; i < num_rows_to_process / unroll; ++i) {\n+    __m256i acc;\n+    if (T_COMBINE_HASHES) {\n+      acc = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes_temp_for_combine) +\n+                               i);\n+    } else {\n+      acc = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + i);\n+    }\n+    acc = avalanche_avx2(acc);\n+    if (T_COMBINE_HASHES) {\n+      __m256i previous_hash =\n+          _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + i);\n+      acc = combine_hashes_avx2(previous_hash, acc);\n+    }\n+    _mm256_storeu_si256(reinterpret_cast<__m256i*>(hashes) + i, acc);\n   }\n+  for (uint32_t i = num_rows_to_process - (num_rows_to_process % unroll);\n+       i < num_rows_to_process; ++i) {\n+    if (T_COMBINE_HASHES) {\n+      hashes[i] = combine_hashes(hashes[i], avalanche(hashes_temp_for_combine[i]));\n+    } else {\n+      hashes[i] = avalanche(hashes[i]);\n+    }\n+  }\n+}\n+\n+inline __m256i Hashing32::round_avx2(__m256i acc, __m256i input) {\n+  acc = _mm256_add_epi32(acc, _mm256_mullo_epi32(input, _mm256_set1_epi32(PRIME32_2)));\n+  acc = _mm256_or_si256(_mm256_slli_epi32(acc, 13), _mm256_srli_epi32(acc, 32 - 13));\n+  acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_1));\n+  return acc;\n }\n \n-inline uint64_t Hashing::combine_accumulators_avx2(__m256i acc) {\n-  acc = _mm256_or_si256(\n-      _mm256_sllv_epi32(acc, _mm256_setr_epi32(1, 7, 12, 18, 1, 7, 12, 18)),\n-      _mm256_srlv_epi32(acc, _mm256_setr_epi32(32 - 1, 32 - 7, 32 - 12, 32 - 18, 32 - 1,\n-                                               32 - 7, 32 - 12, 32 - 18)));\n+inline uint64_t Hashing32::combine_accumulators_avx2(__m256i acc) {\n+  // Each 128-bit lane of input represents a set of 4 accumulators related to\n+  // a single hash (we process here two hashes together).\n+  //\n+  __m256i rotate_const_left = _mm256_setr_epi32(1, 7, 12, 18, 1, 7, 12, 18);\n+  __m256i rotate_const_right = _mm256_setr_epi32(32 - 1, 32 - 7, 32 - 12, 32 - 18, 32 - 1,\n+                                                 32 - 7, 32 - 12, 32 - 18);\n+\n+  acc = _mm256_or_si256(_mm256_sllv_epi32(acc, rotate_const_left),\n+                        _mm256_srlv_epi32(acc, rotate_const_right));\n   acc = _mm256_add_epi32(acc, _mm256_shuffle_epi32(acc, 0xee));  // 0b11101110\n   acc = _mm256_add_epi32(acc, _mm256_srli_epi64(acc, 32));\n   acc = _mm256_permutevar8x32_epi32(acc, _mm256_setr_epi32(0, 4, 0, 0, 0, 0, 0, 0));\n   uint64_t result = _mm256_extract_epi64(acc, 0);\n   return result;\n }\n \n-void Hashing::helper_stripes_avx2(uint32_t num_keys, uint32_t key_length,\n-                                  const uint8_t* keys, uint32_t* hash) {\n+inline __m256i Hashing32::stripe_mask_avx2(int i, int j) {\n+  // Return two 16 byte masks, where the first i/j bytes are 0xff and the\n+  // remaining ones are 0x00\n+  //\n+  ARROW_DCHECK(i >= 0 && i <= kStripeSize && j >= 0 && j <= kStripeSize);\n+  return _mm256_cmpgt_epi8(\n+      _mm256_blend_epi32(_mm256_set1_epi8(i), _mm256_set1_epi8(j), 0xf0),\n+      _mm256_setr_epi64x(0x0706050403020100ULL, 0x0f0e0d0c0b0a0908ULL,\n+                         0x0706050403020100ULL, 0x0f0e0d0c0b0a0908ULL));\n+}\n+\n+template <bool two_equal_lengths>\n+inline __m256i Hashing32::process_stripes_avx2(int64_t num_stripes_A,\n+                                               int64_t num_stripes_B,\n+                                               __m256i mask_last_stripe,\n+                                               const uint8_t* keys, int64_t offset_A,\n+                                               int64_t offset_B) {\n+  ARROW_DCHECK(num_stripes_A > 0 && num_stripes_B > 0);\n+\n+  __m256i acc = _mm256_setr_epi32(\n+      static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) & 0xffffffff),\n+      PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)),\n+      static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) & 0xffffffff),\n+      PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)));\n+\n+  // Constant for permutexvar8x32 instruction that conditionally swaps two\n+  // 128-bit lanes if and only if num_stripes_B > num_stripes_A.\n+  //\n+  __m256i swap_permute = _mm256_setzero_si256();\n+  int64_t offset_shorter, offset_longer;\n+  int64_t num_stripes_shorter, num_stripes_longer;\n+\n+  if (!two_equal_lengths) {\n+    int64_t swap_mask = num_stripes_B > num_stripes_A ? ~0LL : 0LL;\n+    swap_permute = _mm256_xor_si256(_mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7),\n+                                    _mm256_set1_epi32(swap_mask & 4));\n+    offset_shorter = (offset_A & swap_mask) | (offset_B & ~swap_mask);\n+    offset_longer = (offset_A & ~swap_mask) | (offset_B & swap_mask);\n+    num_stripes_shorter = (num_stripes_A & swap_mask) | (num_stripes_B & ~swap_mask);\n+    num_stripes_longer = (num_stripes_A & ~swap_mask) | (num_stripes_B & swap_mask);\n+  } else {\n+    ARROW_DCHECK(num_stripes_A == num_stripes_B);\n+    offset_longer = offset_A;\n+    offset_shorter = offset_B;\n+    num_stripes_longer = num_stripes_A;\n+    num_stripes_shorter = num_stripes_A;\n+  }\n+\n+  int64_t istripe = 0;\n+  for (; istripe + 1 < num_stripes_shorter; ++istripe) {\n+    __m256i stripe = _mm256_inserti128_si256(\n+        _mm256_castsi128_si256(_mm_loadu_si128(\n+            reinterpret_cast<const __m128i*>(keys + offset_longer) + istripe)),\n+        _mm_loadu_si128(reinterpret_cast<const __m128i*>(keys + offset_shorter) +\n+                        istripe),\n+        1);\n+    acc = round_avx2(acc, stripe);\n+  }\n+  __m256i stripe = _mm256_inserti128_si256(\n+      _mm256_castsi128_si256(_mm_loadu_si128(\n+          reinterpret_cast<const __m128i*>(keys + offset_longer) + istripe)),\n+      _mm_loadu_si128(reinterpret_cast<const __m128i*>(keys + offset_shorter) + istripe),\n+      1);\n+  if (!two_equal_lengths) {\n+    __m256i acc_copy = acc;\n+    for (; istripe + 1 < num_stripes_longer; ++istripe) {\n+      acc = round_avx2(acc, stripe);\n+      stripe = _mm256_inserti128_si256(\n+          stripe,\n+          _mm_loadu_si128(reinterpret_cast<const __m128i*>(keys + offset_longer) +\n+                          istripe + 1),\n+          0);\n+    }\n+    acc = _mm256_blend_epi32(acc, acc_copy, 0xf0);\n+    mask_last_stripe = _mm256_permutevar8x32_epi32(mask_last_stripe, swap_permute);\n+  }\n+  stripe = _mm256_and_si256(stripe, mask_last_stripe);\n+  acc = round_avx2(acc, stripe);\n+  if (!two_equal_lengths) {\n+    acc = _mm256_permutevar8x32_epi32(acc, swap_permute);\n+  }\n+  return acc;\n+}\n+\n+template <bool combine_hashes>\n+uint32_t Hashing32::hash_fixedlen_imp_avx2(uint32_t num_rows, uint64_t length,\n+                                           const uint8_t* keys, uint32_t* hashes,\n+                                           uint32_t* hashes_temp_for_combine) {\n   constexpr int unroll = 2;\n-  ARROW_DCHECK(num_keys % unroll == 0);\n-\n-  constexpr uint64_t kByteSequence0To7 = 0x0706050403020100ULL;\n-  constexpr uint64_t kByteSequence8To15 = 0x0f0e0d0c0b0a0908ULL;\n-\n-  const __m256i mask_last_stripe =\n-      (key_length % 16) <= 8\n-          ? _mm256_set1_epi8(static_cast<char>(0xffU))\n-          : _mm256_cmpgt_epi8(_mm256_set1_epi8(key_length % 16),\n-                              _mm256_setr_epi64x(kByteSequence0To7, kByteSequence8To15,\n-                                                 kByteSequence0To7, kByteSequence8To15));\n-\n-  // If length modulo stripe length is less than or equal 8, round down to the nearest 16B\n-  // boundary (8B ending will be processed in a separate function), otherwise round up.\n-  const uint32_t num_stripes = (key_length + 7) / 16;\n-  for (uint32_t i = 0; i < num_keys / unroll; ++i) {\n-    __m256i acc = _mm256_setr_epi32(\n-        static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) &\n-                              0xffffffff),\n-        PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)),\n-        static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) &\n-                              0xffffffff),\n-        PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)));\n-    auto key0 = reinterpret_cast<const __m128i*>(keys + key_length * 2 * i);\n-    auto key1 = reinterpret_cast<const __m128i*>(keys + key_length * 2 * i + key_length);\n-    for (uint32_t stripe = 0; stripe < num_stripes - 1; ++stripe) {\n-      auto key_stripe =\n-          _mm256_inserti128_si256(_mm256_castsi128_si256(_mm_loadu_si128(key0 + stripe)),\n-                                  _mm_loadu_si128(key1 + stripe), 1);\n-      acc = _mm256_add_epi32(\n-          acc, _mm256_mullo_epi32(key_stripe, _mm256_set1_epi32(PRIME32_2)));\n-      acc = _mm256_or_si256(_mm256_slli_epi32(acc, 13), _mm256_srli_epi32(acc, 32 - 13));\n-      acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_1));\n+\n+  // Do not process rows that could read past the end of the buffer using 16\n+  // byte loads. Round down number of rows to process to multiple of 2.\n+  //\n+  uint64_t num_rows_to_skip = bit_util::CeilDiv(length, kStripeSize);\n+  uint32_t num_rows_to_process =\n+      (num_rows_to_skip > num_rows)\n+          ? 0\n+          : (num_rows - static_cast<uint32_t>(num_rows_to_skip));\n+  num_rows_to_process -= (num_rows_to_process % unroll);\n+\n+  uint64_t num_stripes = bit_util::CeilDiv(length, kStripeSize);\n+  int num_tail_bytes = ((length - 1) & (kStripeSize - 1)) + 1;\n+  __m256i mask_last_stripe = stripe_mask_avx2(num_tail_bytes, num_tail_bytes);\n+\n+  for (uint32_t i = 0; i < num_rows_to_process / unroll; ++i) {\n+    __m256i acc = process_stripes_avx2</*two_equal_lengths=*/true>(\n+        num_stripes, num_stripes, mask_last_stripe, keys,\n+        static_cast<int64_t>(i) * unroll * length,\n+        static_cast<int64_t>(i) * unroll * length + length);\n+\n+    if (combine_hashes) {\n+      reinterpret_cast<uint64_t*>(hashes_temp_for_combine)[i] =\n+          combine_accumulators_avx2(acc);\n+    } else {\n+      reinterpret_cast<uint64_t*>(hashes)[i] = combine_accumulators_avx2(acc);\n     }\n-    auto key_stripe = _mm256_inserti128_si256(\n-        _mm256_castsi128_si256(_mm_loadu_si128(key0 + num_stripes - 1)),\n-        _mm_loadu_si128(key1 + num_stripes - 1), 1);\n-    key_stripe = _mm256_and_si256(key_stripe, mask_last_stripe);\n-    acc = _mm256_add_epi32(acc,\n-                           _mm256_mullo_epi32(key_stripe, _mm256_set1_epi32(PRIME32_2)));\n-    acc = _mm256_or_si256(_mm256_slli_epi32(acc, 13), _mm256_srli_epi32(acc, 32 - 13));\n-    acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_1));\n-    uint64_t result = combine_accumulators_avx2(acc);\n-    reinterpret_cast<uint64_t*>(hash)[i] = result;\n   }\n+\n+  avalanche_all_avx2<combine_hashes>(num_rows_to_process, hashes,\n+                                     hashes_temp_for_combine);\n+\n+  return num_rows_to_process;\n }\n \n-void Hashing::helper_tails_avx2(uint32_t num_keys, uint32_t key_length,\n-                                const uint8_t* keys, uint32_t* hash) {\n-  constexpr int unroll = 8;\n-  ARROW_DCHECK(num_keys % unroll == 0);\n-  auto keys_i64 = reinterpret_cast<arrow::util::int64_for_gather_t*>(keys);\n-\n-  // Process between 1 and 8 last bytes of each key, starting from 16B boundary.\n-  // The caller needs to make sure that there are no more than 8 bytes to process after\n-  // that 16B boundary.\n-  uint32_t first_offset = key_length - (key_length % 16);\n-  __m256i mask = _mm256_set1_epi64x((~0ULL) >> (8 * (8 - (key_length % 16))));\n-  __m256i offset =\n-      _mm256_setr_epi32(0, key_length, key_length * 2, key_length * 3, key_length * 4,\n-                        key_length * 5, key_length * 6, key_length * 7);\n-  offset = _mm256_add_epi32(offset, _mm256_set1_epi32(first_offset));\n-  __m256i offset_incr = _mm256_set1_epi32(key_length * 8);\n-\n-  for (uint32_t i = 0; i < num_keys / unroll; ++i) {\n-    auto v1 = _mm256_i32gather_epi64(keys_i64, _mm256_castsi256_si128(offset), 1);\n-    auto v2 = _mm256_i32gather_epi64(keys_i64, _mm256_extracti128_si256(offset, 1), 1);\n-    v1 = _mm256_and_si256(v1, mask);\n-    v2 = _mm256_and_si256(v2, mask);\n-    v1 = _mm256_permutevar8x32_epi32(v1, _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7));\n-    v2 = _mm256_permutevar8x32_epi32(v2, _mm256_setr_epi32(0, 2, 4, 6, 1, 3, 5, 7));\n-    auto x1 = _mm256_permute2x128_si256(v1, v2, 0x20);\n-    auto x2 = _mm256_permute2x128_si256(v1, v2, 0x31);\n-    __m256i acc = _mm256_loadu_si256((reinterpret_cast<const __m256i*>(hash)) + i);\n-\n-    acc = _mm256_add_epi32(acc, _mm256_mullo_epi32(x1, _mm256_set1_epi32(PRIME32_3)));\n-    acc = _mm256_or_si256(_mm256_slli_epi32(acc, 17), _mm256_srli_epi32(acc, 32 - 17));\n-    acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_4));\n-\n-    acc = _mm256_add_epi32(acc, _mm256_mullo_epi32(x2, _mm256_set1_epi32(PRIME32_3)));\n-    acc = _mm256_or_si256(_mm256_slli_epi32(acc, 17), _mm256_srli_epi32(acc, 32 - 17));\n-    acc = _mm256_mullo_epi32(acc, _mm256_set1_epi32(PRIME32_4));\n-\n-    _mm256_storeu_si256((reinterpret_cast<__m256i*>(hash)) + i, acc);\n-\n-    offset = _mm256_add_epi32(offset, offset_incr);\n+uint32_t Hashing32::hash_fixedlen_avx2(bool combine_hashes, uint32_t num_rows,\n+                                       uint64_t length, const uint8_t* keys,\n+                                       uint32_t* hashes,\n+                                       uint32_t* hashes_temp_for_combine) {\n+  if (combine_hashes) {\n+    return hash_fixedlen_imp_avx2<true>(num_rows, length, keys, hashes,\n+                                        hashes_temp_for_combine);\n+  } else {\n+    return hash_fixedlen_imp_avx2<false>(num_rows, length, keys, hashes,\n+                                         hashes_temp_for_combine);\n   }\n }\n \n-void Hashing::hash_varlen_avx2(uint32_t num_rows, const uint32_t* offsets,\n-                               const uint8_t* concatenated_keys,\n-                               uint32_t* temp_buffer,  // Needs to hold 4 x 32-bit per row\n-                               uint32_t* hashes) {\n-  constexpr uint64_t kByteSequence0To7 = 0x0706050403020100ULL;\n-  constexpr uint64_t kByteSequence8To15 = 0x0f0e0d0c0b0a0908ULL;\n+template <typename T, bool combine_hashes>\n+uint32_t Hashing32::hash_varlen_imp_avx2(uint32_t num_rows, const T* offsets,\n+                                         const uint8_t* concatenated_keys,\n+                                         uint32_t* hashes,\n+                                         uint32_t* hashes_temp_for_combine) {\n+  constexpr int unroll = 2;\n \n-  const __m128i sequence = _mm_set_epi64x(kByteSequence8To15, kByteSequence0To7);\n-  const __m128i acc_init = _mm_setr_epi32(\n-      static_cast<uint32_t>((static_cast<uint64_t>(PRIME32_1) + PRIME32_2) & 0xffffffff),\n-      PRIME32_2, 0, static_cast<uint32_t>(-static_cast<int32_t>(PRIME32_1)));\n+  // Do not process rows that could read past the end of the buffer using 16\n+  // byte loads. Round down number of rows to process to multiple of 2.\n+  //\n+  uint32_t num_rows_to_process = num_rows;\n+  while (num_rows_to_process > 0 &&\n+         offsets[num_rows_to_process] + kStripeSize > offsets[num_rows]) {\n+    --num_rows_to_process;\n+  }\n+  num_rows_to_process -= (num_rows_to_process % unroll);\n \n-  // Variable length keys are always processed as a sequence of 16B stripes,\n-  // with the last stripe, if extending past the end of the key, having extra bytes set to\n-  // 0 on the fly.\n-  for (uint32_t ikey = 0; ikey < num_rows; ++ikey) {\n-    uint32_t begin = offsets[ikey];\n-    uint32_t end = offsets[ikey + 1];\n-    uint32_t length = end - begin;\n-    const uint8_t* base = concatenated_keys + begin;\n-\n-    __m128i acc = acc_init;\n-\n-    if (length) {\n-      uint32_t i;\n-      for (i = 0; i < (length - 1) / 16; ++i) {\n-        __m128i key_stripe = _mm_loadu_si128(reinterpret_cast<const __m128i*>(base) + i);\n-        acc = _mm_add_epi32(acc, _mm_mullo_epi32(key_stripe, _mm_set1_epi32(PRIME32_2)));\n-        acc = _mm_or_si128(_mm_slli_epi32(acc, 13), _mm_srli_epi32(acc, 32 - 13));\n-        acc = _mm_mullo_epi32(acc, _mm_set1_epi32(PRIME32_1));\n-      }\n-      __m128i key_stripe = _mm_loadu_si128(reinterpret_cast<const __m128i*>(base) + i);\n-      __m128i mask = _mm_cmpgt_epi8(_mm_set1_epi8(((length - 1) % 16) + 1), sequence);\n-      key_stripe = _mm_and_si128(key_stripe, mask);\n-      acc = _mm_add_epi32(acc, _mm_mullo_epi32(key_stripe, _mm_set1_epi32(PRIME32_2)));\n-      acc = _mm_or_si128(_mm_slli_epi32(acc, 13), _mm_srli_epi32(acc, 32 - 13));\n-      acc = _mm_mullo_epi32(acc, _mm_set1_epi32(PRIME32_1));\n-    }\n+  for (uint32_t i = 0; i < num_rows_to_process / unroll; ++i) {\n+    T offset_A = offsets[unroll * i + 0];\n+    T offset_B = offsets[unroll * i + 1];\n+    T offset_end = offsets[unroll * i + 2];\n \n-    _mm_storeu_si128(reinterpret_cast<__m128i*>(temp_buffer) + ikey, acc);\n-  }\n+    T length = offset_B - offset_A;\n+    int is_non_empty = length == 0 ? 0 : 1;\n+    int64_t num_stripes_A =\n+        static_cast<int64_t>(bit_util::CeilDiv(length, kStripeSize)) + (1 - is_non_empty);\n+    int num_tail_bytes_A = ((length - is_non_empty) & (kStripeSize - 1)) + is_non_empty;\n \n-  // Combine accumulators and perform avalanche\n-  constexpr int unroll = 8;\n-  for (uint32_t i = 0; i < num_rows / unroll; ++i) {\n-    __m256i accA =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 0);\n-    __m256i accB =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 1);\n-    __m256i accC =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 2);\n-    __m256i accD =\n-        _mm256_loadu_si256(reinterpret_cast<const __m256i*>(temp_buffer) + 4 * i + 3);\n-    // Transpose 2x 4x4 32-bit matrices\n-    __m256i r0 = _mm256_unpacklo_epi32(accA, accB);\n-    __m256i r1 = _mm256_unpackhi_epi32(accA, accB);\n-    __m256i r2 = _mm256_unpacklo_epi32(accC, accD);\n-    __m256i r3 = _mm256_unpackhi_epi32(accC, accD);\n-    accA = _mm256_unpacklo_epi64(r0, r2);\n-    accB = _mm256_unpackhi_epi64(r0, r2);\n-    accC = _mm256_unpacklo_epi64(r1, r3);\n-    accD = _mm256_unpackhi_epi64(r1, r3);\n-    // _rotl(accA, 1)\n-    // _rotl(accB, 7)\n-    // _rotl(accC, 12)\n-    // _rotl(accD, 18)\n-    accA = _mm256_or_si256(_mm256_slli_epi32(accA, 1), _mm256_srli_epi32(accA, 32 - 1));\n-    accB = _mm256_or_si256(_mm256_slli_epi32(accB, 7), _mm256_srli_epi32(accB, 32 - 7));\n-    accC = _mm256_or_si256(_mm256_slli_epi32(accC, 12), _mm256_srli_epi32(accC, 32 - 12));\n-    accD = _mm256_or_si256(_mm256_slli_epi32(accD, 18), _mm256_srli_epi32(accD, 32 - 18));\n-    accA = _mm256_add_epi32(_mm256_add_epi32(accA, accB), _mm256_add_epi32(accC, accD));\n-    // avalanche\n-    __m256i hash = accA;\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 15));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_2));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 13));\n-    hash = _mm256_mullo_epi32(hash, _mm256_set1_epi32(PRIME32_3));\n-    hash = _mm256_xor_si256(hash, _mm256_srli_epi32(hash, 16));\n-    // Store.\n-    // At this point, because of way 2x 4x4 transposition was done, output hashes are in\n-    // order: 0, 2, 4, 6, 1, 3, 5, 7. Bring back the original order.\n-    _mm256_storeu_si256(\n-        reinterpret_cast<__m256i*>(hashes) + i,\n-        _mm256_permutevar8x32_epi32(hash, _mm256_setr_epi32(0, 4, 1, 5, 2, 6, 3, 7)));\n+    length = offset_end - offset_B;\n+    is_non_empty = length == 0 ? 0 : 1;\n+    int64_t num_stripes_B =\n+        static_cast<int64_t>(bit_util::CeilDiv(length, kStripeSize)) + (1 - is_non_empty);\n+    int num_tail_bytes_B = ((length - is_non_empty) & (kStripeSize - 1)) + is_non_empty;\n+\n+    __m256i mask_last_stripe = stripe_mask_avx2(num_tail_bytes_A, num_tail_bytes_B);\n+\n+    __m256i acc = process_stripes_avx2</*two_equal_lengths=*/false>(\n+        num_stripes_A, num_stripes_B, mask_last_stripe, concatenated_keys,\n+        static_cast<int64_t>(offset_A), static_cast<int64_t>(offset_B));\n+\n+    if (combine_hashes) {\n\nReview comment:\n       I'm not sure why it doesn't happen on CI (maybe just because you need to rebase) but on my machine this is matching the static function `combine_hashes` before it matches the template argument and I end up with a compile error:\r\n   \r\n   ```\r\n   /home/pace/dev/arrow/cpp/src/arrow/compute/exec/key_hash_avx2.cc:279:9: warning: address of function 'combine_hashes' will always evaluate to 'true' [-Wpointer-bool-conversion]\r\n       if (combine_hashes) {\r\n       ~~  ^~~~~~~~~~~~~~\r\n   /home/pace/dev/arrow/cpp/src/arrow/compute/exec/key_hash_avx2.cc:279:9: note: prefix with the address-of operator to silence this warning\r\n       if (combine_hashes) {\r\n           ^\r\n           &\r\n   ```\r\n   Renaming the template argument (e.g. `COMBINE_HASHES_T`) solved the issue for me.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n\nReview comment:\n       This is more informational than assertion based.  I'm not sure where the right place to put such information belongs but perhaps as a comment or in a document somewhere.  If we wanted to keep it in the unit test (e.g. to ensure that future changes didn't accidentally introduce collisiony masks) then maybe we could change it to an assertion?  For example, it seems we can assert that this ratio must be less than `0.01` when `i >2`?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n\nReview comment:\n       Is this for performance reasons?  Does this make tests too slow in debug mode?  Can you add a comment to clarify?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n\nReview comment:\n       We shouldn't print to stdout in unit tests.  You can use `SCOPED_TRACE` to add context to potential failures instead.\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n+\n+    if (!use_simd && cpu_nanos_scalar) {\n+      *cpu_nanos_scalar = nanos_per_hash;\n+    }\n+    if (use_simd && cpu_nanos_simd) {\n+      *cpu_nanos_simd = nanos_per_hash;\n+    }\n+  }\n+  if (use_32bit_hash) {\n+    for (int i = 0; i < num_rows; ++i) {\n+      hashes_scalar64[i] = hashes_scalar32[i];\n+      hashes_simd64[i] = hashes_simd32[i];\n+    }\n+  }\n+\n+  // Verify that both scalar and AVX2 implementations give the same hashes\n+  //\n+  bool ok = true;\n+  for (int i = 0; i < num_rows; ++i) {\n+    if (hashes_scalar64[i] != hashes_simd64[i]) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+    }\n+  }\n+  printf(\"%s \", ok ? \"correct\" : \"wrong\");\n\nReview comment:\n       Should this be an assert?\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n+\n+    if (!use_simd && cpu_nanos_scalar) {\n+      *cpu_nanos_scalar = nanos_per_hash;\n+    }\n+    if (use_simd && cpu_nanos_simd) {\n+      *cpu_nanos_simd = nanos_per_hash;\n+    }\n+  }\n+  if (use_32bit_hash) {\n+    for (int i = 0; i < num_rows; ++i) {\n+      hashes_scalar64[i] = hashes_scalar32[i];\n+      hashes_simd64[i] = hashes_simd32[i];\n+    }\n+  }\n+\n+  // Verify that both scalar and AVX2 implementations give the same hashes\n+  //\n+  bool ok = true;\n+  for (int i = 0; i < num_rows; ++i) {\n+    if (hashes_scalar64[i] != hashes_simd64[i]) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+    }\n+  }\n+  printf(\"%s \", ok ? \"correct\" : \"wrong\");\n+\n+  // Verify that the same key appearing multiple times generates the same hash\n+  // each time. Measure the number of unique hashes and compare to the number\n+  // of unique keys.\n+  //\n+  std::map<int, uint64_t> unique_key_to_hash;\n+  std::set<uint64_t> unique_hashes;\n+  for (int i = 0; i < num_rows; ++i) {\n+    std::map<int, uint64_t>::iterator iter = unique_key_to_hash.find(row_ids[i]);\n+    if (iter == unique_key_to_hash.end()) {\n+      unique_key_to_hash.insert(std::make_pair(row_ids[i], hashes_scalar64[i]));\n+    } else {\n+      ARROW_DCHECK(iter->second == hashes_scalar64[i]);\n+    }\n+    if (unique_hashes.find(hashes_scalar64[i]) == unique_hashes.end()) {\n+      unique_hashes.insert(hashes_scalar64[i]);\n+    }\n+  }\n+  float percent_hash_collisions = 100.0f *\n+                                  static_cast<float>(num_unique - unique_hashes.size()) /\n+                                  static_cast<float>(num_unique);\n+  printf(\"percent_hash_collisions %.2f \", percent_hash_collisions);\n+  ARROW_DCHECK(percent_hash_collisions < 5.0f);\n+\n+  printf(\"\\n\");\n+}\n+\n+TEST(VectorHash, Basic) {\n+  Random64Bit random(/*seed=*/0);\n+\n+  int numtest = 100;\n+\n+  constexpr int min_length = 1;\n+  constexpr int max_length = 50;\n+\n+  for (bool use_32bit_hash : {true, false}) {\n+    for (bool use_varlen_input : {false, true}) {\n+      for (int itest = 0; itest < numtest; ++itest) {\n+        int length = static_cast<int>(std::max(\n+            static_cast<uint64_t>(use_varlen_input ? 2 : 1),\n+            static_cast<uint64_t>(min_length +\n+                                  random.next() % (max_length - min_length + 1))));\n+\n+        TestVectorHashImp(random, use_32bit_hash, use_varlen_input,\n+                          use_varlen_input ? 0 : length, length);\n+      }\n+    }\n+  }\n+}\n+\n+TEST(VectorHash, Benchmark) {\n+  Random64Bit random(/*seed=*/0);\n+\n+  for (bool use_32bit_hash : {true, false}) {\n+    for (bool use_varlen_input : {false, true}) {\n+      std::vector<float> nanos_scalar;\n+      std::vector<float> nanos_simd;\n+      std::vector<int> lengths;\n+      for (int length = 2; length <= 64; ++length) {\n+        lengths.push_back(length);\n+      }\n+      nanos_scalar.resize(lengths.size());\n+      nanos_simd.resize(lengths.size());\n+      for (size_t i = 0; i < lengths.size(); ++i) {\n+        TestVectorHashImp(random, use_32bit_hash, use_varlen_input,\n+                          use_varlen_input ? 0 : lengths[i],\n+                          use_varlen_input ? 2 * lengths[i] : lengths[i],\n+                          &nanos_scalar[i], &nanos_simd[i]);\n+      }\n+      printf(\"%s %s (avg_length; nanos_scalar; nanos_avx2):\\n\",\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n+\n+    if (!use_simd && cpu_nanos_scalar) {\n+      *cpu_nanos_scalar = nanos_per_hash;\n+    }\n+    if (use_simd && cpu_nanos_simd) {\n+      *cpu_nanos_simd = nanos_per_hash;\n+    }\n+  }\n+  if (use_32bit_hash) {\n+    for (int i = 0; i < num_rows; ++i) {\n+      hashes_scalar64[i] = hashes_scalar32[i];\n+      hashes_simd64[i] = hashes_simd32[i];\n+    }\n+  }\n+\n+  // Verify that both scalar and AVX2 implementations give the same hashes\n+  //\n+  bool ok = true;\n+  for (int i = 0; i < num_rows; ++i) {\n+    if (hashes_scalar64[i] != hashes_simd64[i]) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+    }\n+  }\n+  printf(\"%s \", ok ? \"correct\" : \"wrong\");\n+\n+  // Verify that the same key appearing multiple times generates the same hash\n+  // each time. Measure the number of unique hashes and compare to the number\n+  // of unique keys.\n+  //\n+  std::map<int, uint64_t> unique_key_to_hash;\n+  std::set<uint64_t> unique_hashes;\n+  for (int i = 0; i < num_rows; ++i) {\n+    std::map<int, uint64_t>::iterator iter = unique_key_to_hash.find(row_ids[i]);\n+    if (iter == unique_key_to_hash.end()) {\n+      unique_key_to_hash.insert(std::make_pair(row_ids[i], hashes_scalar64[i]));\n+    } else {\n+      ARROW_DCHECK(iter->second == hashes_scalar64[i]);\n+    }\n+    if (unique_hashes.find(hashes_scalar64[i]) == unique_hashes.end()) {\n+      unique_hashes.insert(hashes_scalar64[i]);\n+    }\n+  }\n+  float percent_hash_collisions = 100.0f *\n+                                  static_cast<float>(num_unique - unique_hashes.size()) /\n+                                  static_cast<float>(num_unique);\n+  printf(\"percent_hash_collisions %.2f \", percent_hash_collisions);\n\nReview comment:\n       No printf in unit tests (see earlier comment on `SCOPED_TRACE`)\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n\nReview comment:\n       ```suggestion\r\n         size_t thread_index = 0;\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n\nReview comment:\n       ```suggestion\r\n       constexpr int key_length = sizeof(uint64_t);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n\nReview comment:\n       This part belongs in a benchmark\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n\nReview comment:\n       ```suggestion\r\n       ASSERT_TRUE(found);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n\nReview comment:\n       Is there a reason `locks_` can't be a vector?  Perhaps for alignment purposes?  Could you leave a comment to the reasoning here?\n\n##########\nFile path: cpp/src/arrow/compute/exec/key_hash.h\n##########\n@@ -32,76 +32,161 @@ namespace compute {\n // Implementations are based on xxh3 32-bit algorithm description from:\n // https://github.com/Cyan4973/xxHash/blob/dev/doc/xxhash_spec.md\n //\n-class Hashing {\n+class Hashing32 {\n\nReview comment:\n       We already have a vendored version of xxhash in Arrow (src/arrow/vendored/xxhash.h).  Why do we need (for example) `Hashing32::round` and `XXH32_round`?  If this implementation is different in some way can you add some comments explaining that?\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n+  for (int i = 0; i < num_prtns; ++i) {\n+    locks_[i].lock.store(false);\n+  }\n+}\n+\n+void PartitionLocks::CleanUp() {\n+  if (locks_) {\n+    delete[] locks_;\n+    locks_ = nullptr;\n+  }\n+  num_prtns_ = 0;\n+}\n\nReview comment:\n       Can you move this logic into a constructor / destructor to stick with the style of the rest of the code base?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n\nReview comment:\n       ```suggestion\r\n         ASSERT_GE(ARROW_POPCOUNT64(mask), BloomFilterMasks::kMinBitsSet);\r\n         ASSERT_LE(ARROW_POPCOUNT64(mask), BloomFilterMasks::kMaxBitsSet);\r\n   ```\r\n   \r\n   Although this opens something of a can of worms when it comes to `static constexpr`.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n+    if (sizeof(T) == sizeof(uint32_t)) {\n+      Hashing32::hash_fixed(hardware_flags, false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint32_t*>(output_hashes) + ibase, nullptr);\n+    } else {\n+      Hashing64::hash_fixed(false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint64_t*>(output_hashes) + ibase);\n+    }\n+\n+    ibase += next_batch_size;\n+  }\n+}\n+\n+// Test with larger size Bloom filters (use large prime with arithmetic\n+// sequence modulo 2^64).\n+//\n+Status TestBloomLarge(BloomFilterBuildStrategy strategy, int64_t num_build, int dop,\n+                      bool use_simd, bool enable_prefetch, float* fpr, float* build_cost,\n+                      float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  const int64_t block = 1024;\n+  std::vector<uint64_t> first_in_block;\n+  first_in_block.resize(bit_util::CeilDiv(num_build + num_probe, block));\n+  uint64_t current = prime;\n+  for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+    if (i % block == 0) {\n+      first_in_block[i / block] = current;\n+    }\n+    current += prime;\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  for (int ibuild = 0; ibuild < 2; ++ibuild) {\n+    if (ibuild == 0 && strategy == BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      continue;\n\nReview comment:\n       So when `ibuild == 0` then you are creating the reference?  Which isn't needed when building single threaded because reference basically means \"build single threaded and see if you get the same result\"?\r\n   \r\n   I think this would be more readable as just two back-to-back calls like you have in TestBloomSmall\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n+    if (sizeof(T) == sizeof(uint32_t)) {\n+      Hashing32::hash_fixed(hardware_flags, false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint32_t*>(output_hashes) + ibase, nullptr);\n+    } else {\n+      Hashing64::hash_fixed(false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint64_t*>(output_hashes) + ibase);\n+    }\n+\n+    ibase += next_batch_size;\n+  }\n+}\n+\n+// Test with larger size Bloom filters (use large prime with arithmetic\n+// sequence modulo 2^64).\n+//\n+Status TestBloomLarge(BloomFilterBuildStrategy strategy, int64_t num_build, int dop,\n+                      bool use_simd, bool enable_prefetch, float* fpr, float* build_cost,\n+                      float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  const int64_t block = 1024;\n+  std::vector<uint64_t> first_in_block;\n+  first_in_block.resize(bit_util::CeilDiv(num_build + num_probe, block));\n+  uint64_t current = prime;\n+  for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+    if (i % block == 0) {\n+      first_in_block[i / block] = current;\n+    }\n+    current += prime;\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  for (int ibuild = 0; ibuild < 2; ++ibuild) {\n+    if (ibuild == 0 && strategy == BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      continue;\n+    }\n+    RETURN_NOT_OK(BuildBloomFilter(\n+        ibuild == 0 ? BloomFilterBuildStrategy::SINGLE_THREADED : strategy,\n+        ibuild == 0 ? 1 : dop, hardware_flags, pool, num_build,\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint32_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint64_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        ibuild == 0 ? &reference : &bloom,\n+        ibuild == 0 ? &build_cost_single_threaded : build_cost));\n+  }\n+\n+  if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+    bool is_same = reference.IsSameAs(&bloom);\n+    printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+    ARROW_DCHECK(is_same);\n+  }\n+\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  std::vector<uint8_t> result_bit_vector;\n+  hashes32.resize(block);\n+  hashes64.resize(block);\n+  result_bit_vector.resize(bit_util::BytesForBits(block));\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  // Verify no false negatives and measure false positives.\n+  // Measure FPR and performance.\n+  //\n+  int64_t num_negatives_build = 0LL;\n+  int64_t num_negatives_probe = 0LL;\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t i = 0; i < num_build + num_probe * num_repeats;) {\n+    int64_t first_row = i < num_build ? i : num_build + ((i - num_build) % num_probe);\n+    int64_t last_row = i < num_build ? num_build : num_build + num_probe;\n+    int64_t next_batch_size = std::min(last_row - first_row, block);\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes64.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes64.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    } else {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes32.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes32.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    }\n+    uint64_t num_negatives = 0ULL;\n+    for (int iword = 0; iword < next_batch_size / 64; ++iword) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(result_bit_vector.data())[iword];\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (next_batch_size % 64 > 0) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(\n+          result_bit_vector.data())[next_batch_size / 64];\n+      uint64_t mask = (1ULL << (next_batch_size % 64)) - 1;\n+      word |= ~mask;\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (i < num_build) {\n+      num_negatives_build += num_negatives;\n+    } else {\n+      num_negatives_probe += num_negatives;\n+    }\n+    i += next_batch_size;\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+  ARROW_DCHECK(num_negatives_build == 0);\n+  printf(\"%s false_negatives %d\\n\", num_negatives_build == 0 ? \"success\" : \"failure\",\n+         static_cast<int>(num_negatives_build));\n+\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_probe * num_repeats - num_negatives_probe) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+TEST(BloomFilter, Basic) {\n+  std::vector<int64_t> num_build;\n+  constexpr int log_min = 8;\n+  constexpr int log_max = 16;\n+  constexpr int log_large = 22;\n+  for (int log_num_build = log_min; log_num_build < log_max; ++log_num_build) {\n+    constexpr int num_intermediate_points = 2;\n+    for (int i = 0; i < num_intermediate_points; ++i) {\n+      int64_t num_left = 1LL << log_num_build;\n+      int64_t num_right = 1LL << (log_num_build + 1);\n+      num_build.push_back((num_left * (num_intermediate_points - i) + num_right * i) /\n+                          num_intermediate_points);\n+    }\n+  }\n+  num_build.push_back(1LL << log_max);\n+  num_build.push_back(1LL << log_large);\n+\n+  constexpr int num_param_sets = 3;\n+  struct {\n+    bool use_avx2;\n+    bool enable_prefetch;\n+    bool insert_multiple_copies;\n+  } params[num_param_sets];\n+  for (int i = 0; i < num_param_sets; ++i) {\n+    params[i].use_avx2 = (i == 1);\n+    params[i].enable_prefetch = (i == 2);\n+    params[i].insert_multiple_copies = (i == 3);\n+  }\n\nReview comment:\n       This would probably be easier to interpret as a parameterized test.\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.h\n##########\n@@ -0,0 +1,95 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <atomic>\n+#include <cassert>\n+#include <cstdint>\n+#include <functional>\n+#include <random>\n+#include \"arrow/buffer.h\"\n+#include \"arrow/compute/exec/util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+class PartitionSort {\n+ public:\n+  // Bucket sort rows on partition ids.\n+  // Include in the output exclusive cummulative sum of bucket sizes.\n+  // This corresponds to ranges in the sorted array containing all row ids for\n+  // each of the partitions.\n+  //\n+  template <class INPUT_PRTN_ID_FN, class OUTPUT_POS_FN>\n\nReview comment:\n       Just looking at this file I think it is very difficult to tell what is supposed to be happening here.  What are the assumptions and assertions on `prtn_id_impl` and `output_pos_impl`?  Can they just return any random id or does there need to be some structure to it?  Some more comments here would help I think.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n\nReview comment:\n       It seems a lot of these test are mixing benchmarks and unit tests.  For example, you are gathering and returning `build_cost` but you aren't doing anything other than printing it.  Can you clean these tests up so that they are purely testing and then create a separate benchmark?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void test_Bloom_large_hash(int64_t hardware_flags, int64_t block,\n+                           const std::vector<uint64_t>& first_in_block, int64_t first_row,\n+                           int num_rows, T* output_hashes) {\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  constexpr int mini_batch_size = 1024;\n+  uint64_t keys[mini_batch_size];\n+  int64_t ikey = first_row / block * block;\n+  uint64_t key = first_in_block[first_row / block];\n+  while (ikey < first_row) {\n+    key += prime;\n+    ++ikey;\n+  }\n+  for (int ibase = 0; ibase < num_rows;) {\n+    int next_batch_size = std::min(num_rows - ibase, mini_batch_size);\n+    for (int i = 0; i < next_batch_size; ++i) {\n+      keys[i] = key;\n+      key += prime;\n+    }\n+\n+    int key_length = sizeof(uint64_t);\n+    if (sizeof(T) == sizeof(uint32_t)) {\n+      Hashing32::hash_fixed(hardware_flags, false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint32_t*>(output_hashes) + ibase, nullptr);\n+    } else {\n+      Hashing64::hash_fixed(false, next_batch_size, key_length,\n+                            reinterpret_cast<const uint8_t*>(keys),\n+                            reinterpret_cast<uint64_t*>(output_hashes) + ibase);\n+    }\n+\n+    ibase += next_batch_size;\n+  }\n+}\n+\n+// Test with larger size Bloom filters (use large prime with arithmetic\n+// sequence modulo 2^64).\n+//\n+Status TestBloomLarge(BloomFilterBuildStrategy strategy, int64_t num_build, int dop,\n+                      bool use_simd, bool enable_prefetch, float* fpr, float* build_cost,\n+                      float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Largest 63-bit prime\n+  constexpr uint64_t prime = 0x7FFFFFFFFFFFFFE7ULL;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  const int64_t block = 1024;\n+  std::vector<uint64_t> first_in_block;\n+  first_in_block.resize(bit_util::CeilDiv(num_build + num_probe, block));\n+  uint64_t current = prime;\n+  for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+    if (i % block == 0) {\n+      first_in_block[i / block] = current;\n+    }\n+    current += prime;\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  for (int ibuild = 0; ibuild < 2; ++ibuild) {\n+    if (ibuild == 0 && strategy == BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      continue;\n+    }\n+    RETURN_NOT_OK(BuildBloomFilter(\n+        ibuild == 0 ? BloomFilterBuildStrategy::SINGLE_THREADED : strategy,\n+        ibuild == 0 ? 1 : dop, hardware_flags, pool, num_build,\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint32_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        [hardware_flags, &first_in_block](int64_t first_row, int num_rows,\n+                                          uint64_t* output_hashes) {\n+          const int64_t block = 1024;\n+          test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                                num_rows, output_hashes);\n+        },\n+        ibuild == 0 ? &reference : &bloom,\n+        ibuild == 0 ? &build_cost_single_threaded : build_cost));\n+  }\n+\n+  if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+    bool is_same = reference.IsSameAs(&bloom);\n+    printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+    ARROW_DCHECK(is_same);\n+  }\n+\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  std::vector<uint8_t> result_bit_vector;\n+  hashes32.resize(block);\n+  hashes64.resize(block);\n+  result_bit_vector.resize(bit_util::BytesForBits(block));\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  // Verify no false negatives and measure false positives.\n+  // Measure FPR and performance.\n+  //\n+  int64_t num_negatives_build = 0LL;\n+  int64_t num_negatives_probe = 0LL;\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t i = 0; i < num_build + num_probe * num_repeats;) {\n+    int64_t first_row = i < num_build ? i : num_build + ((i - num_build) % num_probe);\n+    int64_t last_row = i < num_build ? num_build : num_build + num_probe;\n+    int64_t next_batch_size = std::min(last_row - first_row, block);\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes64.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes64.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    } else {\n+      test_Bloom_large_hash(hardware_flags, block, first_in_block, first_row,\n+                            static_cast<int>(next_batch_size), hashes32.data());\n+      bloom.Find(hardware_flags, next_batch_size, hashes32.data(),\n+                 result_bit_vector.data(), enable_prefetch);\n+    }\n+    uint64_t num_negatives = 0ULL;\n+    for (int iword = 0; iword < next_batch_size / 64; ++iword) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(result_bit_vector.data())[iword];\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (next_batch_size % 64 > 0) {\n+      uint64_t word = reinterpret_cast<const uint64_t*>(\n+          result_bit_vector.data())[next_batch_size / 64];\n+      uint64_t mask = (1ULL << (next_batch_size % 64)) - 1;\n+      word |= ~mask;\n+      num_negatives += ARROW_POPCOUNT64(~word);\n+    }\n+    if (i < num_build) {\n+      num_negatives_build += num_negatives;\n+    } else {\n+      num_negatives_probe += num_negatives;\n+    }\n+    i += next_batch_size;\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+  ARROW_DCHECK(num_negatives_build == 0);\n+  printf(\"%s false_negatives %d\\n\", num_negatives_build == 0 ? \"success\" : \"failure\",\n+         static_cast<int>(num_negatives_build));\n+\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_probe * num_repeats - num_negatives_probe) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n+}\n+\n+TEST(BloomFilter, Basic) {\n+  std::vector<int64_t> num_build;\n+  constexpr int log_min = 8;\n+  constexpr int log_max = 16;\n+  constexpr int log_large = 22;\n+  for (int log_num_build = log_min; log_num_build < log_max; ++log_num_build) {\n+    constexpr int num_intermediate_points = 2;\n+    for (int i = 0; i < num_intermediate_points; ++i) {\n+      int64_t num_left = 1LL << log_num_build;\n+      int64_t num_right = 1LL << (log_num_build + 1);\n+      num_build.push_back((num_left * (num_intermediate_points - i) + num_right * i) /\n+                          num_intermediate_points);\n+    }\n+  }\n+  num_build.push_back(1LL << log_max);\n+  num_build.push_back(1LL << log_large);\n+\n+  constexpr int num_param_sets = 3;\n+  struct {\n+    bool use_avx2;\n+    bool enable_prefetch;\n+    bool insert_multiple_copies;\n+  } params[num_param_sets];\n+  for (int i = 0; i < num_param_sets; ++i) {\n+    params[i].use_avx2 = (i == 1);\n+    params[i].enable_prefetch = (i == 2);\n+    params[i].insert_multiple_copies = (i == 3);\n+  }\n+\n+  std::vector<BloomFilterBuildStrategy> strategy;\n+  strategy.push_back(BloomFilterBuildStrategy::SINGLE_THREADED);\n+  strategy.push_back(BloomFilterBuildStrategy::PARALLEL);\n+\n+  static constexpr int64_t min_rows_for_large = 2 * 1024 * 1024;\n+\n+  int dop = 1;  // omp_get_max_threads();\n+  // printf(\"omp_get_thread_limit() = %d\\n\", dop);\n+\n+  for (size_t istrategy = 0; istrategy < strategy.size(); ++istrategy) {\n+    for (int iparam_set = 0; iparam_set < num_param_sets; ++iparam_set) {\n+      printf(\"%s \", params[iparam_set].use_avx2                 ? \"AVX2\"\n+                    : params[iparam_set].enable_prefetch        ? \"PREFETCH\"\n+                    : params[iparam_set].insert_multiple_copies ? \"FOLDING\"\n+                                                                : \"REGULAR\");\n+      std::vector<float> fpr_vector(num_build.size());\n+      std::vector<float> probe_vector(num_build.size());\n+      for (size_t inum_build = 0; inum_build < num_build.size(); ++inum_build) {\n+        printf(\"num_build %d \", static_cast<int>(num_build[inum_build]));\n+        float fpr, build_cost, probe_cost;\n+        if (num_build[inum_build] >= min_rows_for_large) {\n+          ASSERT_OK(TestBloomLarge(strategy[istrategy], num_build[inum_build], dop,\n+                                   params[iparam_set].use_avx2,\n+                                   params[iparam_set].enable_prefetch, &fpr, &build_cost,\n+                                   &probe_cost));\n+\n+        } else {\n+          ASSERT_OK(TestBloomSmall(strategy[istrategy], num_build[inum_build],\n+                                   params[iparam_set].insert_multiple_copies ? 8 : 1, dop,\n+                                   params[iparam_set].use_avx2,\n+                                   params[iparam_set].enable_prefetch, &fpr, &build_cost,\n+                                   &probe_cost));\n+        }\n+        if (iparam_set == 0) {\n+          fpr_vector[inum_build] = fpr;\n+        }\n+        probe_vector[inum_build] = probe_cost;\n+      }\n+      if (iparam_set == 0) {\n+        printf(\"(build size; FPR percent):\\n\");\n+        for (size_t i = 0; i < num_build.size(); ++i) {\n+          printf(\"%d; %.2f;\\n\", static_cast<int>(num_build[i]), fpr_vector[i]);\n+        }\n+      }\n+      printf(\"(build size; CPU cycles per probe):\\n\");\n+      for (size_t i = 0; i < num_build.size(); ++i) {\n+        printf(\"%d; %.2f;\\n\", static_cast<int>(num_build[i]), probe_vector[i]);\n+      }\n+    }\n+  }\n+}\n+\n+TEST(BloomFilter, Scaling) {\n\nReview comment:\n       Again, this seems more like a benchmark than a test.\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n+  for (int i = 0; i < num_prtns; ++i) {\n+    locks_[i].lock.store(false);\n+  }\n+}\n+\n+void PartitionLocks::CleanUp() {\n+  if (locks_) {\n+    delete[] locks_;\n+    locks_ = nullptr;\n+  }\n+  num_prtns_ = 0;\n+}\n+\n+std::atomic<bool>* PartitionLocks::lock_ptr(int prtn_id) {\n\nReview comment:\n       Minor nit: Style-wise I think this might be simpler returning a `const std::atomic<bool>&`\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_avx2.cc\n##########\n@@ -0,0 +1,136 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n\nReview comment:\n       I'll have to see if I can find someone to review this file.\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes);\n+\n+  // Uses SIMD if available for smaller Bloom filters.\n+  // Uses memory prefetching for larger Bloom filters.\n+  //\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+\n+  // Folding of a block Bloom filter after the initial version\n+  // has been built.\n+  //\n+  // One of the parameters for creation of Bloom filter is the number\n+  // of bits allocated for it. The more bits allocated, the lower the\n+  // probability of false positives. A good heuristic is to aim for\n+  // half of the bits set in the constructed Bloom filter. This should\n+  // result in a good trade off between size (and following cost of\n+  // memory accesses) and false positives rate.\n+  //\n+  // There might have been many duplicate keys in the input provided\n+  // to Bloom filter builder. In that case the resulting bit vector\n+  // would be more sparse then originally intended. It is possible to\n+  // easily correct that and cut in half the size of Bloom filter\n+  // after it has already been constructed. The process to do that is\n+  // approximately equal to OR-ing bits from upper and lower half (the\n+  // way we address these bits when inserting or querying a hash makes\n+  // such folding in half possible).\n+  //\n+  // We will keep folding as long as the fraction of bits set is less\n+  // than 1/4. The resulting bit vector density should be in the [1/4,\n+  // 1/2) range.\n+  //\n+  void Fold();\n+\n+  int log_num_blocks() const { return log_num_blocks_; }\n+\n+  int NumHashBitsUsed() const;\n+\n+  bool IsSameAs(const BlockedBloomFilter* other) const;\n+\n+  int64_t NumBitsSet() const;\n+\n+ private:\n+  inline uint64_t mask(uint64_t hash) const {\n+    // The lowest bits of hash are used to pick mask index.\n+    //\n+    int mask_id = static_cast<int>(hash & (BloomFilterMasks::kNumMasks - 1));\n+    uint64_t result = masks_.mask(mask_id);\n+\n+    // The next set of hash bits is used to pick the amount of bit\n+    // rotation of the mask.\n+    //\n+    int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\n+    result = ROTL64(result, rotation);\n+\n+    return result;\n+  }\n+\n+  inline int64_t block_id(uint64_t hash) const {\n+    // The next set of hash bits following the bits used to select a\n+    // mask is used to pick block id (index of 64-bit word in a bit\n+    // vector).\n+    //\n+    return (hash >> (BloomFilterMasks::kLogNumMasks + 6)) & (num_blocks_ - 1);\n+  }\n+\n+  template <typename T>\n+  inline void InsertImp(int64_t num_rows, const T* hashes);\n+\n+  template <typename T>\n+  inline void FindImp(int64_t num_rows, const T* hashes, uint8_t* result_bit_vector,\n+                      bool enable_prefetch) const;\n+\n+  void SingleFold(int num_folds);\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  inline __m256i mask_avx2(__m256i hash) const;\n+  inline __m256i block_id_avx2(__m256i hash) const;\n+  int64_t Insert_avx2(int64_t num_rows, const uint32_t* hashes);\n+  int64_t Insert_avx2(int64_t num_rows, const uint64_t* hashes);\n+  template <typename T>\n+  int64_t InsertImp_avx2(int64_t num_rows, const T* hashes);\n+  int64_t Find_avx2(int64_t num_rows, const uint32_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  int64_t Find_avx2(int64_t num_rows, const uint64_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  template <typename T>\n+  int64_t FindImp_avx2(int64_t num_rows, const T* hashes,\n+                       uint8_t* result_bit_vector) const;\n+#endif\n+\n+  bool UsePrefetch() const {\n+    return num_blocks_ * sizeof(uint64_t) > kPrefetchLimitBytes;\n+  }\n+\n+  static constexpr int64_t kPrefetchLimitBytes = 256 * 1024;\n+\n+  static BloomFilterMasks masks_;\n+\n+  // Total number of bits used by block Bloom filter must be a power\n+  // of 2.\n+  //\n+  int log_num_blocks_;\n+  int64_t num_blocks_;\n+\n+  // Buffer allocated to store an array of power of 2 64-bit blocks.\n+  //\n+  std::shared_ptr<Buffer> buf_;\n+  // Pointer to mutable data owned by Buffer\n+  //\n+  uint64_t* blocks_;\n+};\n+\n+enum class BloomFilterBuildStrategy {\n+  SINGLE_THREADED = 0,\n+  PARALLEL = 1,\n+};\n+\n+class BloomFilterBuilder {\n+ public:\n+  virtual ~BloomFilterBuilder() = default;\n+  virtual Status Begin(size_t num_threads, int64_t hardware_flags, MemoryPool* pool,\n+                       int64_t num_rows, int64_t num_batches,\n+                       BlockedBloomFilter* build_target) = 0;\n+  virtual int64_t num_tasks() const { return 0; }\n+  virtual void RunInitTask(int64_t task_id) {}\n+  virtual Status PushNextBatch(size_t thread_index, int num_rows,\n+                               const uint32_t* hashes) = 0;\n+  virtual Status PushNextBatch(size_t thread_index, int num_rows,\n+                               const uint64_t* hashes) = 0;\n+  virtual void RunFinishTask(int64_t task_id) {}\n+  virtual void CleanUp() {}\n+  static std::unique_ptr<BloomFilterBuilder> Make(BloomFilterBuildStrategy strategy);\n+};\n+\n+class BloomFilterBuilder_SingleThreaded : public BloomFilterBuilder {\n+ public:\n+  Status Begin(size_t num_threads, int64_t hardware_flags, MemoryPool* pool,\n+               int64_t num_rows, int64_t num_batches,\n+               BlockedBloomFilter* build_target) override;\n+\n+  Status PushNextBatch(size_t /*thread_index*/, int num_rows,\n+                       const uint32_t* hashes) override;\n+\n+  Status PushNextBatch(size_t /*thread_index*/, int num_rows,\n+                       const uint64_t* hashes) override;\n+\n+ private:\n+  template <typename T>\n+  void PushNextBatchImp(int num_rows, const T* hashes);\n+\n+  int64_t hardware_flags_;\n+  BlockedBloomFilter* build_target_;\n+};\n+\n+class BloomFilterBuilder_Parallel : public BloomFilterBuilder {\n+ public:\n+  Status Begin(size_t num_threads, int64_t hardware_flags, MemoryPool* pool,\n+               int64_t num_rows, int64_t num_batches,\n+               BlockedBloomFilter* build_target) override;\n+\n+  Status PushNextBatch(size_t thread_id, int num_rows, const uint32_t* hashes) override;\n\nReview comment:\n       Some comments around how this is meant to be used in parallel might be helpful (or a pointer to somewhere else in the code base where this is documented).  If I am making sense of the code right I think the idea is that this function can be called multiple times concurrently (each time with a different `thread_id`) but it doesn't actually do any \"scheduling\" itself.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-25T17:08:19.989+0000",
                    "updated": "2022-01-25T17:08:19.989+0000",
                    "started": "2022-01-25T17:08:19.988+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "715041",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/716046",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r793048162\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n\nReview comment:\n       Is it ok to do benchmarking inside of the unit test? Maybe we should separate this out into its own benchmark?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_avx2.cc\n##########\n@@ -0,0 +1,136 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <immintrin.h>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+#if defined(ARROW_HAVE_AVX2)\n+\n+inline __m256i BlockedBloomFilter::mask_avx2(__m256i hash) const {\n+  // AVX2 translation of mask() method\n+  //\n+  __m256i mask_id =\n+      _mm256_and_si256(hash, _mm256_set1_epi64x(BloomFilterMasks::kNumMasks - 1));\n+\n+  auto masks = reinterpret_cast<const arrow::util::int64_for_gather_t*>(masks_.masks_);\n+  __m256i result = _mm256_i64gather_epi64(masks, _mm256_srli_epi64(mask_id, 3), 1);\n+  result = _mm256_srlv_epi64(result, _mm256_and_si256(mask_id, _mm256_set1_epi64x(7)));\n+  result = _mm256_and_si256(result, _mm256_set1_epi64x(BloomFilterMasks::kFullMask));\n+\n+  __m256i rotation = _mm256_and_si256(\n+      _mm256_srli_epi64(hash, BloomFilterMasks::kLogNumMasks), _mm256_set1_epi64x(63));\n+\n+  result = _mm256_or_si256(\n+      _mm256_sllv_epi64(result, rotation),\n+      _mm256_srlv_epi64(result, _mm256_sub_epi64(_mm256_set1_epi64x(64), rotation)));\n+\n+  return result;\n+}\n+\n+inline __m256i BlockedBloomFilter::block_id_avx2(__m256i hash) const {\n\nReview comment:\n       Is it worth to add `__attribute__((always_inline))` here? \n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n+  for (int i = 0; i < num_prtns; ++i) {\n+    locks_[i].lock.store(false);\n+  }\n+}\n+\n+void PartitionLocks::CleanUp() {\n+  if (locks_) {\n+    delete[] locks_;\n+    locks_ = nullptr;\n+  }\n+  num_prtns_ = 0;\n+}\n+\n+std::atomic<bool>* PartitionLocks::lock_ptr(int prtn_id) {\n\nReview comment:\n       I actually like pointer here more because you never want to make a copy, and I don't think there's ever a way to enforce someone in the future to _only_ take a reference, and never copy by value. \n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_avx2.cc\n##########\n@@ -0,0 +1,136 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <immintrin.h>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+#if defined(ARROW_HAVE_AVX2)\n+\n+inline __m256i BlockedBloomFilter::mask_avx2(__m256i hash) const {\n+  // AVX2 translation of mask() method\n+  //\n+  __m256i mask_id =\n+      _mm256_and_si256(hash, _mm256_set1_epi64x(BloomFilterMasks::kNumMasks - 1));\n+\n+  auto masks = reinterpret_cast<const arrow::util::int64_for_gather_t*>(masks_.masks_);\n+  __m256i result = _mm256_i64gather_epi64(masks, _mm256_srli_epi64(mask_id, 3), 1);\n+  result = _mm256_srlv_epi64(result, _mm256_and_si256(mask_id, _mm256_set1_epi64x(7)));\n\nReview comment:\n       Same here, separating the `and` out into `mask_bit_index` would be clearer\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.cc\n##########\n@@ -0,0 +1,434 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include <random>\n+#include \"arrow/compute/exec/util.h\"  // PREFETCH\n+#include \"arrow/util/bit_util.h\"      // Log2\n+#include \"arrow/util/bitmap_ops.h\"    // CountSetBits\n+\n+namespace arrow {\n+namespace compute {\n+\n+BloomFilterMasks::BloomFilterMasks() {\n+  std::seed_seq seed{0, 0, 0, 0, 0, 0, 0, 0};\n+  std::mt19937 re(seed);\n+  std::uniform_int_distribution<uint64_t> rd;\n+  auto random = [&re, &rd](int min_value, int max_value) {\n+    return min_value + rd(re) % (max_value - min_value + 1);\n+  };\n+\n+  memset(masks_, 0, kTotalBytes);\n+\n+  // Prepare the first mask\n+  //\n+  int num_bits_set = static_cast<int>(random(kMinBitsSet, kMaxBitsSet));\n+  for (int i = 0; i < num_bits_set; ++i) {\n+    for (;;) {\n+      int bit_pos = static_cast<int>(random(0, kBitsPerMask - 1));\n+      if (!bit_util::GetBit(masks_, bit_pos)) {\n+        bit_util::SetBit(masks_, bit_pos);\n+        break;\n+      }\n+    }\n+  }\n+\n+  int64_t num_bits_total = kNumMasks + kBitsPerMask - 1;\n+\n+  // The value num_bits_set will be updated in each iteration of the loop to\n+  // represent the number of bits set in the entire mask directly preceding the\n+  // currently processed bit.\n+  //\n+  for (int64_t i = kBitsPerMask; i < num_bits_total; ++i) {\n+    // The value of the lowest bit of the previous mask that will be removed\n+    // from the current mask as we move to the next position in the bit vector\n+    // of masks.\n+    //\n+    int bit_leaving = bit_util::GetBit(masks_, i - kBitsPerMask) ? 1 : 0;\n+\n+    // Next bit has to be 1 because of minimum bits in a mask requirement\n+    //\n+    if (bit_leaving == 1 && num_bits_set == kMinBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      continue;\n+    }\n+\n+    // Next bit has to be 0 because of maximum bits in a mask requirement\n+    //\n+    if (bit_leaving == 0 && num_bits_set == kMaxBitsSet) {\n+      continue;\n+    }\n+\n+    // Next bit can be random. Use the expected number of bits set in a mask\n+    // as a probability of 1.\n+    //\n+    if (random(0, kBitsPerMask * 2 - 1) < kMinBitsSet + kMaxBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      if (bit_leaving == 0) {\n+        ++num_bits_set;\n+      }\n+    } else {\n+      if (bit_leaving == 1) {\n+        --num_bits_set;\n+      }\n+    }\n+  }\n+}\n+\n+BloomFilterMasks BlockedBloomFilter::masks_;\n+\n+Status BlockedBloomFilter::CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool) {\n+  // Compute the size\n+  //\n+  constexpr int64_t min_num_bits_per_key = 8;\n+  constexpr int64_t min_num_bits = 512;\n+  int64_t desired_num_bits =\n+      std::max(min_num_bits, num_rows_to_insert * min_num_bits_per_key);\n+  int log_num_bits = bit_util::Log2(desired_num_bits);\n+\n+  log_num_blocks_ = log_num_bits - 6;\n+  num_blocks_ = 1ULL << log_num_blocks_;\n+\n+  // Allocate and zero out bit vector\n+  //\n+  int64_t buffer_size = num_blocks_ * sizeof(uint64_t);\n+  ARROW_ASSIGN_OR_RAISE(buf_, AllocateBuffer(buffer_size, pool));\n+  blocks_ = reinterpret_cast<uint64_t*>(buf_->mutable_data());\n+  memset(blocks_, 0, buffer_size);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BlockedBloomFilter::InsertImp(int64_t num_rows, const T* hashes) {\n+  for (int64_t i = 0; i < num_rows; ++i) {\n+    Insert(hashes[i]);\n+  }\n+}\n+\n+void BlockedBloomFilter::Insert(int64_t hardware_flags, int64_t num_rows,\n+                                const uint32_t* hashes) {\n+  int64_t num_processed = 0;\n+#if defined(ARROW_HAVE_AVX2)\n+  if (hardware_flags & arrow::internal::CpuInfo::AVX2) {\n+    num_processed = Insert_avx2(num_rows, hashes);\n+  }\n+#endif\n+  InsertImp(num_rows - num_processed, hashes + num_processed);\n\nReview comment:\n       Yep\n\n##########\nFile path: cpp/src/arrow/compute/exec/key_hash.h\n##########\n@@ -32,76 +32,161 @@ namespace compute {\n // Implementations are based on xxh3 32-bit algorithm description from:\n // https://github.com/Cyan4973/xxHash/blob/dev/doc/xxhash_spec.md\n //\n-class Hashing {\n+class Hashing32 {\n  public:\n-  static void hash_fixed(int64_t hardware_flags, uint32_t num_keys, uint32_t length_key,\n-                         const uint8_t* keys, uint32_t* hashes);\n+  static void hash_fixed(int64_t hardware_flags, bool combine_hashes, uint32_t num_keys,\n+                         uint64_t length_key, const uint8_t* keys, uint32_t* hashes,\n+                         uint32_t* temp_hashes_for_combine);\n \n-  static void hash_varlen(int64_t hardware_flags, uint32_t num_rows,\n+  static void hash_varlen(int64_t hardware_flags, bool combine_hashes, uint32_t num_rows,\n                           const uint32_t* offsets, const uint8_t* concatenated_keys,\n-                          uint32_t* temp_buffer,  // Needs to hold 4 x 32-bit per row\n-                          uint32_t* hashes);\n+                          uint32_t* hashes, uint32_t* temp_hashes_for_combine);\n+\n+  static void hash_varlen(int64_t hardware_flags, bool combine_hashes, uint32_t num_rows,\n+                          const uint64_t* offsets, const uint8_t* concatenated_keys,\n+                          uint32_t* hashes, uint32_t* temp_hashes_for_combine);\n \n   static void HashMultiColumn(const std::vector<KeyEncoder::KeyColumnArray>& cols,\n                               KeyEncoder::KeyEncoderContext* ctx, uint32_t* out_hash);\n \n  private:\n-  static const uint32_t PRIME32_1 = 0x9E3779B1;  // 0b10011110001101110111100110110001\n-  static const uint32_t PRIME32_2 = 0x85EBCA77;  // 0b10000101111010111100101001110111\n-  static const uint32_t PRIME32_3 = 0xC2B2AE3D;  // 0b11000010101100101010111000111101\n-  static const uint32_t PRIME32_4 = 0x27D4EB2F;  // 0b00100111110101001110101100101111\n-  static const uint32_t PRIME32_5 = 0x165667B1;  // 0b00010110010101100110011110110001\n-\n-  static void HashCombine(KeyEncoder::KeyEncoderContext* ctx, uint32_t num_rows,\n-                          uint32_t* accumulated_hash, const uint32_t* next_column_hash);\n+  static const uint32_t PRIME32_1 = 0x9E3779B1;\n+  static const uint32_t PRIME32_2 = 0x85EBCA77;\n+  static const uint32_t PRIME32_3 = 0xC2B2AE3D;\n+  static const uint32_t PRIME32_4 = 0x27D4EB2F;\n+  static const uint32_t PRIME32_5 = 0x165667B1;\n+  static const uint32_t kCombineConst = 0x9e3779b9UL;\n+  static const int64_t kStripeSize = 4 * sizeof(uint32_t);\n+\n+  static inline uint32_t avalanche(uint32_t acc) {\n\nReview comment:\n       Why are these functions in snake case? Is this a rule for static methods?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n\nReview comment:\n       The hardware_flags provided by `CpuInfo` is an `int64_t`, so probably just copying that. \n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes);\n+\n+  // Uses SIMD if available for smaller Bloom filters.\n+  // Uses memory prefetching for larger Bloom filters.\n+  //\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+\n+  // Folding of a block Bloom filter after the initial version\n+  // has been built.\n+  //\n+  // One of the parameters for creation of Bloom filter is the number\n+  // of bits allocated for it. The more bits allocated, the lower the\n+  // probability of false positives. A good heuristic is to aim for\n+  // half of the bits set in the constructed Bloom filter. This should\n+  // result in a good trade off between size (and following cost of\n+  // memory accesses) and false positives rate.\n+  //\n+  // There might have been many duplicate keys in the input provided\n+  // to Bloom filter builder. In that case the resulting bit vector\n+  // would be more sparse then originally intended. It is possible to\n+  // easily correct that and cut in half the size of Bloom filter\n+  // after it has already been constructed. The process to do that is\n+  // approximately equal to OR-ing bits from upper and lower half (the\n+  // way we address these bits when inserting or querying a hash makes\n+  // such folding in half possible).\n+  //\n+  // We will keep folding as long as the fraction of bits set is less\n+  // than 1/4. The resulting bit vector density should be in the [1/4,\n+  // 1/2) range.\n+  //\n+  void Fold();\n+\n+  int log_num_blocks() const { return log_num_blocks_; }\n+\n+  int NumHashBitsUsed() const;\n+\n+  bool IsSameAs(const BlockedBloomFilter* other) const;\n+\n+  int64_t NumBitsSet() const;\n+\n+ private:\n+  inline uint64_t mask(uint64_t hash) const {\n+    // The lowest bits of hash are used to pick mask index.\n+    //\n+    int mask_id = static_cast<int>(hash & (BloomFilterMasks::kNumMasks - 1));\n+    uint64_t result = masks_.mask(mask_id);\n+\n+    // The next set of hash bits is used to pick the amount of bit\n+    // rotation of the mask.\n+    //\n+    int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\n+    result = ROTL64(result, rotation);\n+\n+    return result;\n+  }\n+\n+  inline int64_t block_id(uint64_t hash) const {\n+    // The next set of hash bits following the bits used to select a\n+    // mask is used to pick block id (index of 64-bit word in a bit\n+    // vector).\n+    //\n+    return (hash >> (BloomFilterMasks::kLogNumMasks + 6)) & (num_blocks_ - 1);\n+  }\n+\n+  template <typename T>\n+  inline void InsertImp(int64_t num_rows, const T* hashes);\n+\n+  template <typename T>\n+  inline void FindImp(int64_t num_rows, const T* hashes, uint8_t* result_bit_vector,\n+                      bool enable_prefetch) const;\n+\n+  void SingleFold(int num_folds);\n+\n+#if defined(ARROW_HAVE_AVX2)\n+  inline __m256i mask_avx2(__m256i hash) const;\n+  inline __m256i block_id_avx2(__m256i hash) const;\n+  int64_t Insert_avx2(int64_t num_rows, const uint32_t* hashes);\n+  int64_t Insert_avx2(int64_t num_rows, const uint64_t* hashes);\n+  template <typename T>\n+  int64_t InsertImp_avx2(int64_t num_rows, const T* hashes);\n+  int64_t Find_avx2(int64_t num_rows, const uint32_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  int64_t Find_avx2(int64_t num_rows, const uint64_t* hashes,\n+                    uint8_t* result_bit_vector) const;\n+  template <typename T>\n+  int64_t FindImp_avx2(int64_t num_rows, const T* hashes,\n+                       uint8_t* result_bit_vector) const;\n+#endif\n+\n+  bool UsePrefetch() const {\n+    return num_blocks_ * sizeof(uint64_t) > kPrefetchLimitBytes;\n+  }\n+\n+  static constexpr int64_t kPrefetchLimitBytes = 256 * 1024;\n+\n+  static BloomFilterMasks masks_;\n+\n+  // Total number of bits used by block Bloom filter must be a power\n+  // of 2.\n+  //\n+  int log_num_blocks_;\n+  int64_t num_blocks_;\n+\n+  // Buffer allocated to store an array of power of 2 64-bit blocks.\n+  //\n+  std::shared_ptr<Buffer> buf_;\n+  // Pointer to mutable data owned by Buffer\n+  //\n+  uint64_t* blocks_;\n+};\n+\n+enum class BloomFilterBuildStrategy {\n+  SINGLE_THREADED = 0,\n+  PARALLEL = 1,\n+};\n+\n+class BloomFilterBuilder {\n+ public:\n+  virtual ~BloomFilterBuilder() = default;\n+  virtual Status Begin(size_t num_threads, int64_t hardware_flags, MemoryPool* pool,\n+                       int64_t num_rows, int64_t num_batches,\n+                       BlockedBloomFilter* build_target) = 0;\n+  virtual int64_t num_tasks() const { return 0; }\n+  virtual void RunInitTask(int64_t task_id) {}\n\nReview comment:\n       Can we get rid of `RunInitTask`, `RunFinishTask`, and `Cleanup` since they're nops?\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_avx2.cc\n##########\n@@ -0,0 +1,136 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <immintrin.h>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+#if defined(ARROW_HAVE_AVX2)\n+\n+inline __m256i BlockedBloomFilter::mask_avx2(__m256i hash) const {\n+  // AVX2 translation of mask() method\n+  //\n+  __m256i mask_id =\n+      _mm256_and_si256(hash, _mm256_set1_epi64x(BloomFilterMasks::kNumMasks - 1));\n+\n+  auto masks = reinterpret_cast<const arrow::util::int64_for_gather_t*>(masks_.masks_);\n+  __m256i result = _mm256_i64gather_epi64(masks, _mm256_srli_epi64(mask_id, 3), 1);\n\nReview comment:\n       Might be clearer to separate the `srli` into a separate variable called `mask_byte_index` or similar\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_avx2.cc\n##########\n@@ -0,0 +1,136 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <immintrin.h>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+#if defined(ARROW_HAVE_AVX2)\n+\n+inline __m256i BlockedBloomFilter::mask_avx2(__m256i hash) const {\n+  // AVX2 translation of mask() method\n+  //\n+  __m256i mask_id =\n+      _mm256_and_si256(hash, _mm256_set1_epi64x(BloomFilterMasks::kNumMasks - 1));\n+\n+  auto masks = reinterpret_cast<const arrow::util::int64_for_gather_t*>(masks_.masks_);\n+  __m256i result = _mm256_i64gather_epi64(masks, _mm256_srli_epi64(mask_id, 3), 1);\n+  result = _mm256_srlv_epi64(result, _mm256_and_si256(mask_id, _mm256_set1_epi64x(7)));\n+  result = _mm256_and_si256(result, _mm256_set1_epi64x(BloomFilterMasks::kFullMask));\n+\n+  __m256i rotation = _mm256_and_si256(\n+      _mm256_srli_epi64(hash, BloomFilterMasks::kLogNumMasks), _mm256_set1_epi64x(63));\n+\n+  result = _mm256_or_si256(\n+      _mm256_sllv_epi64(result, rotation),\n+      _mm256_srlv_epi64(result, _mm256_sub_epi64(_mm256_set1_epi64x(64), rotation)));\n+\n+  return result;\n+}\n+\n+inline __m256i BlockedBloomFilter::block_id_avx2(__m256i hash) const {\n+  // AVX2 translation of block_id() method\n+  //\n+  __m256i result = _mm256_srli_epi64(hash, BloomFilterMasks::kLogNumMasks + 6);\n+  result = _mm256_and_si256(result, _mm256_set1_epi64x(num_blocks_ - 1));\n+  return result;\n+}\n+\n+template <typename T>\n+int64_t BlockedBloomFilter::FindImp_avx2(int64_t num_rows, const T* hashes,\n+                                         uint8_t* result_bit_vector) const {\n+  constexpr int unroll = 8;\n+\n+  auto blocks = reinterpret_cast<const arrow::util::int64_for_gather_t*>(blocks_);\n+\n+  for (int64_t i = 0; i < num_rows / unroll; ++i) {\n+    __m256i hash_A, hash_B;\n+    if (sizeof(T) == sizeof(uint32_t)) {\n+      hash_A = _mm256_cvtepu32_epi64(\n+          _mm_loadu_si128(reinterpret_cast<const __m128i*>(hashes) + 2 * i + 0));\n+      hash_B = _mm256_cvtepu32_epi64(\n+          _mm_loadu_si128(reinterpret_cast<const __m128i*>(hashes) + 2 * i + 1));\n+    } else {\n+      hash_A = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + 2 * i + 0);\n+      hash_B = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(hashes) + 2 * i + 1);\n+    }\n+    __m256i mask_A = mask_avx2(hash_A);\n+    __m256i mask_B = mask_avx2(hash_B);\n+    __m256i block_id_A = block_id_avx2(hash_A);\n+    __m256i block_id_B = block_id_avx2(hash_B);\n+    __m256i block_A = _mm256_i64gather_epi64(blocks, block_id_A, sizeof(uint64_t));\n+    __m256i block_B = _mm256_i64gather_epi64(blocks, block_id_B, sizeof(uint64_t));\n+    uint64_t result_bytes = _mm256_movemask_epi8(\n+        _mm256_cmpeq_epi64(_mm256_and_si256(block_A, mask_A), mask_A));\n+    result_bytes |= static_cast<uint64_t>(_mm256_movemask_epi8(\n+                        _mm256_cmpeq_epi64(_mm256_and_si256(block_B, mask_B), mask_B)))\n+                    << 32;\n+    result_bit_vector[i] =\n+        static_cast<uint8_t>(_mm256_movemask_epi8(_mm256_set1_epi64x(result_bytes)));\n\nReview comment:\n       This can be switched to a `pext` I think? \n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n\nReview comment:\n       To add on to this, you can keep using OpenMP in benchmarks, just not tests. You can use the hash join benchmarks as an example.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-26T21:53:47.337+0000",
                    "updated": "2022-01-26T21:53:47.337+0000",
                    "started": "2022-01-26T21:53:47.337+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "716046",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737976",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821380560\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.cc\n##########\n@@ -0,0 +1,434 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include <random>\n+#include \"arrow/compute/exec/util.h\"  // PREFETCH\n+#include \"arrow/util/bit_util.h\"      // Log2\n+#include \"arrow/util/bitmap_ops.h\"    // CountSetBits\n+\n+namespace arrow {\n+namespace compute {\n+\n+BloomFilterMasks::BloomFilterMasks() {\n+  std::seed_seq seed{0, 0, 0, 0, 0, 0, 0, 0};\n+  std::mt19937 re(seed);\n+  std::uniform_int_distribution<uint64_t> rd;\n+  auto random = [&re, &rd](int min_value, int max_value) {\n+    return min_value + rd(re) % (max_value - min_value + 1);\n+  };\n+\n+  memset(masks_, 0, kTotalBytes);\n+\n+  // Prepare the first mask\n+  //\n+  int num_bits_set = static_cast<int>(random(kMinBitsSet, kMaxBitsSet));\n+  for (int i = 0; i < num_bits_set; ++i) {\n+    for (;;) {\n+      int bit_pos = static_cast<int>(random(0, kBitsPerMask - 1));\n+      if (!bit_util::GetBit(masks_, bit_pos)) {\n+        bit_util::SetBit(masks_, bit_pos);\n+        break;\n+      }\n+    }\n+  }\n+\n+  int64_t num_bits_total = kNumMasks + kBitsPerMask - 1;\n+\n+  // The value num_bits_set will be updated in each iteration of the loop to\n+  // represent the number of bits set in the entire mask directly preceding the\n+  // currently processed bit.\n+  //\n+  for (int64_t i = kBitsPerMask; i < num_bits_total; ++i) {\n+    // The value of the lowest bit of the previous mask that will be removed\n+    // from the current mask as we move to the next position in the bit vector\n+    // of masks.\n+    //\n+    int bit_leaving = bit_util::GetBit(masks_, i - kBitsPerMask) ? 1 : 0;\n+\n+    // Next bit has to be 1 because of minimum bits in a mask requirement\n+    //\n+    if (bit_leaving == 1 && num_bits_set == kMinBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      continue;\n+    }\n+\n+    // Next bit has to be 0 because of maximum bits in a mask requirement\n+    //\n+    if (bit_leaving == 0 && num_bits_set == kMaxBitsSet) {\n+      continue;\n+    }\n+\n+    // Next bit can be random. Use the expected number of bits set in a mask\n+    // as a probability of 1.\n+    //\n+    if (random(0, kBitsPerMask * 2 - 1) < kMinBitsSet + kMaxBitsSet) {\n+      bit_util::SetBit(masks_, i);\n+      if (bit_leaving == 0) {\n+        ++num_bits_set;\n+      }\n+    } else {\n+      if (bit_leaving == 1) {\n+        --num_bits_set;\n+      }\n+    }\n+  }\n+}\n+\n+BloomFilterMasks BlockedBloomFilter::masks_;\n+\n+Status BlockedBloomFilter::CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool) {\n+  // Compute the size\n+  //\n+  constexpr int64_t min_num_bits_per_key = 8;\n+  constexpr int64_t min_num_bits = 512;\n+  int64_t desired_num_bits =\n+      std::max(min_num_bits, num_rows_to_insert * min_num_bits_per_key);\n+  int log_num_bits = bit_util::Log2(desired_num_bits);\n+\n+  log_num_blocks_ = log_num_bits - 6;\n+  num_blocks_ = 1ULL << log_num_blocks_;\n+\n+  // Allocate and zero out bit vector\n+  //\n+  int64_t buffer_size = num_blocks_ * sizeof(uint64_t);\n+  ARROW_ASSIGN_OR_RAISE(buf_, AllocateBuffer(buffer_size, pool));\n+  blocks_ = reinterpret_cast<uint64_t*>(buf_->mutable_data());\n+  memset(blocks_, 0, buffer_size);\n+\n+  return Status::OK();\n+}\n+\n+template <typename T>\n+void BlockedBloomFilter::InsertImp(int64_t num_rows, const T* hashes) {\n+  for (int64_t i = 0; i < num_rows; ++i) {\n+    Insert(hashes[i]);\n+  }\n+}\n+\n+void BlockedBloomFilter::Insert(int64_t hardware_flags, int64_t num_rows,\n+                                const uint32_t* hashes) {\n+  int64_t num_processed = 0;\n+#if defined(ARROW_HAVE_AVX2)\n+  if (hardware_flags & arrow::internal::CpuInfo::AVX2) {\n+    num_processed = Insert_avx2(num_rows, hashes);\n+  }\n+#endif\n+  InsertImp(num_rows - num_processed, hashes + num_processed);\n\nReview comment:\n       Yes. This is the pattern I have used everywhere with AVX2 code. All AVX2 functions process only a multiple of AVX2 blocks. They return the number of rows processed and the tail is processed using regular scalar code-path.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:14:16.501+0000",
                    "updated": "2022-03-08T07:14:16.501+0000",
                    "started": "2022-03-08T07:14:16.501+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737976",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737978",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821381174\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n\nReview comment:\n       Yes, hardware_flags are taken from CpuInfo. In the future we may have AVX-512 added (very easy to do), and bool would not be enough.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:15:21.623+0000",
                    "updated": "2022-03-08T07:15:21.623+0000",
                    "started": "2022-03-08T07:15:21.623+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737978",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737985",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821390021\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter.h\n##########\n@@ -0,0 +1,313 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#if defined(ARROW_HAVE_AVX2)\n+#include <immintrin.h>\n+#endif\n+\n+#include <atomic>\n+#include <cstdint>\n+#include <memory>\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// A set of pre-generated bit masks from a 64-bit word.\n+//\n+// It is used to map selected bits of hash to a bit mask that will be used in\n+// a Bloom filter.\n+//\n+// These bit masks need to look random and need to have a similar fractions of\n+// bits set in order for a Bloom filter to have a low false positives rate.\n+//\n+struct BloomFilterMasks {\n+  // Generate all masks as a single bit vector. Each bit offset in this bit\n+  // vector corresponds to a single mask.\n+  // In each consecutive kBitsPerMask bits, there must be between\n+  // kMinBitsSet and kMaxBitsSet bits set.\n+  //\n+  BloomFilterMasks();\n+\n+  inline uint64_t mask(int bit_offset) {\n+#if ARROW_LITTLE_ENDIAN\n+    return (util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8) >> (bit_offset % 8)) &\n+           kFullMask;\n+#else\n+    return (BYTESWAP(util::SafeLoadAs<uint64_t>(masks_ + bit_offset / 8)) >>\n+            (bit_offset % 8)) &\n+           kFullMask;\n+#endif\n+  }\n+\n+  // Masks are 57 bits long because then they can be accessed at an\n+  // arbitrary bit offset using a single unaligned 64-bit load instruction.\n+  //\n+  static constexpr int kBitsPerMask = 57;\n+  static constexpr uint64_t kFullMask = (1ULL << kBitsPerMask) - 1;\n+\n+  // Minimum and maximum number of bits set in each mask.\n+  // This constraint is enforced when generating the bit masks.\n+  // Values should be close to each other and chosen as to minimize a Bloom\n+  // filter false positives rate.\n+  //\n+  static constexpr int kMinBitsSet = 4;\n+  static constexpr int kMaxBitsSet = 5;\n+\n+  // Number of generated masks.\n+  // Having more masks to choose will improve false positives rate of Bloom\n+  // filter but will also use more memory, which may lead to more CPU cache\n+  // misses.\n+  // The chosen value results in using only a few cache-lines for mask lookups,\n+  // while providing a good variety of available bit masks.\n+  //\n+  static constexpr int kLogNumMasks = 10;\n+  static constexpr int kNumMasks = 1 << kLogNumMasks;\n+\n+  // Data of masks. Masks are stored in a single bit vector. Nth mask is\n+  // kBitsPerMask bits starting at bit offset N.\n+  //\n+  static constexpr int kTotalBytes = (kNumMasks + 64) / 8;\n+  uint8_t masks_[kTotalBytes];\n+};\n+\n+// A variant of a blocked Bloom filter implementation.\n+// A Bloom filter is a data structure that provides approximate membership test\n+// functionality based only on the hash of the key. Membership test may return\n+// false positives but not false negatives. Approximation of the result allows\n+// in general case (for arbitrary data types of keys) to save on both memory and\n+// lookup cost compared to the accurate membership test.\n+// The accurate test may sometimes still be cheaper for a specific data types\n+// and inputs, e.g. integers from a small range.\n+//\n+// This blocked Bloom filter is optimized for use in hash joins, to achieve a\n+// good balance between the size of the filter, the cost of its building and\n+// querying and the rate of false positives.\n+//\n+class BlockedBloomFilter {\n+  friend class BloomFilterBuilder_Partitioned;\n+  friend class BloomFilterBuilder_Atomic;\n+\n+ public:\n+  Status CreateEmpty(int64_t num_rows_to_insert, MemoryPool* pool);\n+\n+  inline void Insert(uint64_t hash) {\n+    uint64_t m = mask(hash);\n+    uint64_t& b = blocks_[block_id(hash)];\n+    b |= m;\n+  }\n+\n+  inline bool Find(uint64_t hash) const {\n+    uint64_t m = mask(hash);\n+    uint64_t b = blocks_[block_id(hash)];\n+    return (b & m) == m;\n+  }\n+\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes);\n+  void Insert(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes);\n+\n+  // Uses SIMD if available for smaller Bloom filters.\n+  // Uses memory prefetching for larger Bloom filters.\n+  //\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint32_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+  void Find(int64_t hardware_flags, int64_t num_rows, const uint64_t* hashes,\n+            uint8_t* result_bit_vector, bool enable_prefetch = true) const;\n+\n+  // Folding of a block Bloom filter after the initial version\n+  // has been built.\n+  //\n+  // One of the parameters for creation of Bloom filter is the number\n+  // of bits allocated for it. The more bits allocated, the lower the\n+  // probability of false positives. A good heuristic is to aim for\n+  // half of the bits set in the constructed Bloom filter. This should\n+  // result in a good trade off between size (and following cost of\n+  // memory accesses) and false positives rate.\n+  //\n+  // There might have been many duplicate keys in the input provided\n+  // to Bloom filter builder. In that case the resulting bit vector\n+  // would be more sparse then originally intended. It is possible to\n+  // easily correct that and cut in half the size of Bloom filter\n+  // after it has already been constructed. The process to do that is\n+  // approximately equal to OR-ing bits from upper and lower half (the\n+  // way we address these bits when inserting or querying a hash makes\n+  // such folding in half possible).\n+  //\n+  // We will keep folding as long as the fraction of bits set is less\n+  // than 1/4. The resulting bit vector density should be in the [1/4,\n+  // 1/2) range.\n+  //\n+  void Fold();\n+\n+  int log_num_blocks() const { return log_num_blocks_; }\n+\n+  int NumHashBitsUsed() const;\n+\n+  bool IsSameAs(const BlockedBloomFilter* other) const;\n+\n+  int64_t NumBitsSet() const;\n+\n+ private:\n+  inline uint64_t mask(uint64_t hash) const {\n+    // The lowest bits of hash are used to pick mask index.\n+    //\n+    int mask_id = static_cast<int>(hash & (BloomFilterMasks::kNumMasks - 1));\n+    uint64_t result = masks_.mask(mask_id);\n+\n+    // The next set of hash bits is used to pick the amount of bit\n+    // rotation of the mask.\n+    //\n+    int rotation = (hash >> BloomFilterMasks::kLogNumMasks) & 63;\n+    result = ROTL64(result, rotation);\n+\n\nReview comment:\n       Good catch. I changed the definition of ROTL and ROTL64.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:31:29.942+0000",
                    "updated": "2022-03-08T07:31:29.942+0000",
                    "started": "2022-03-08T07:31:29.941+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737985",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737989",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821396829\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/vector_hash_test.cc\n##########\n@@ -0,0 +1,287 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <chrono>\n+#include <map>\n+#include <set>\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+// TODO: test 64-bit offsets\n+// TODO: test bit inputs\n+// TODO: test multicolumn hash\n+\n+void TestVectorHashImp(Random64Bit& random, bool use_32bit_hash, bool use_varlen_input,\n+                       int min_length, int max_length, float* cpu_nanos_scalar = nullptr,\n+                       float* cpu_nanos_simd = nullptr) {\n+  ARROW_DCHECK(use_varlen_input || min_length == max_length);\n+\n+  constexpr int min_num_unique = 100;\n+  constexpr int max_num_unique = 1000;\n+  constexpr int min_num_rows = 4000;\n+  constexpr int max_num_rows = 64000;\n+  int num_unique =\n+      min_num_unique + (random.next() % (max_num_unique - min_num_unique + 1));\n+  int num_rows = min_num_rows + (random.next() % (max_num_rows - min_num_rows + 1));\n+\n+  printf(\n+      \"num_bits = %d varlen = %s num_unique %d num_rows %d min_length \"\n+      \"%d max_length %d \",\n+      use_32bit_hash ? 32 : 64, use_varlen_input ? \"yes\" : \"no\", num_unique, num_rows,\n+      min_length, max_length);\n+\n+  if (max_length == 1) {\n+    num_unique &= 0x7f;\n+  }\n+\n+  std::vector<uint32_t> unique_keys_offsets;\n+  unique_keys_offsets.resize(num_unique + 1);\n+  unique_keys_offsets[0] = 0;\n+\n+  const int num_bytes = unique_keys_offsets[num_unique];\n+  std::vector<uint8_t> unique_keys;\n+  unique_keys.resize(num_bytes);\n+  std::set<std::string> unique_key_strings;\n+  for (int i = 0; i < num_unique; ++i) {\n+    for (;;) {\n+      int next_length;\n+      if (use_varlen_input) {\n+        next_length = min_length + random.next() % (max_length - min_length + 1);\n+      } else {\n+        next_length = max_length;\n+      }\n+      unique_keys_offsets[i + 1] = unique_keys_offsets[i] + next_length;\n+      unique_keys.resize(unique_keys_offsets[i + 1]);\n+      uint8_t* next_key = unique_keys.data() + unique_keys_offsets[i];\n+\n+      for (int iword = 0; iword < next_length / static_cast<int>(sizeof(uint64_t));\n+           ++iword) {\n+        reinterpret_cast<uint64_t*>(next_key)[iword] = random.next();\n+      }\n+      if (next_length % sizeof(uint64_t) > 0) {\n+        uint8_t* tail = next_key + next_length - (next_length % sizeof(uint64_t));\n+        for (int ibyte = 0; ibyte < (next_length % static_cast<int>(sizeof(uint64_t)));\n+             ++ibyte) {\n+          tail[ibyte] = static_cast<uint8_t>(random.next() & 0xff);\n+        }\n+      }\n+      std::string next_key_string =\n+          std::string(reinterpret_cast<const char*>(next_key), next_length);\n+      if (unique_key_strings.find(next_key_string) == unique_key_strings.end()) {\n+        unique_key_strings.insert(next_key_string);\n+        break;\n+      }\n+    }\n+  }\n+\n+  std::vector<int> row_ids;\n+  row_ids.resize(num_rows);\n+  std::vector<uint8_t> keys;\n+  std::vector<uint32_t> keys_offsets;\n+  keys_offsets.resize(num_rows + 1);\n+  keys_offsets[0] = 0;\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = random.next() % num_unique;\n+    row_ids[i] = row_id;\n+    int next_length = unique_keys_offsets[row_id + 1] - unique_keys_offsets[row_id];\n+    keys_offsets[i + 1] = keys_offsets[i] + next_length;\n+  }\n+  keys.resize(keys_offsets[num_rows]);\n+  for (int i = 0; i < num_rows; ++i) {\n+    int row_id = row_ids[i];\n+    int next_length = keys_offsets[i + 1] - keys_offsets[i];\n+    memcpy(keys.data() + keys_offsets[i],\n+           unique_keys.data() + unique_keys_offsets[row_id], next_length);\n+  }\n+\n+  constexpr int min_rows_for_timing = 1 << 23;\n+  int num_repeats = static_cast<int>(bit_util::CeilDiv(min_rows_for_timing, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1;\n+#endif\n+\n+  std::vector<uint32_t> hashes_scalar32;\n+  std::vector<uint64_t> hashes_scalar64;\n+  hashes_scalar32.resize(num_rows);\n+  hashes_scalar64.resize(num_rows);\n+  std::vector<uint32_t> hashes_simd32;\n+  std::vector<uint64_t> hashes_simd64;\n+  hashes_simd32.resize(num_rows);\n+  hashes_simd64.resize(num_rows);\n+\n+  int64_t hardware_flags_scalar = 0LL;\n+  int64_t hardware_flags_simd = ::arrow::internal::CpuInfo::AVX2;\n+\n+  constexpr int mini_batch_size = 1024;\n+  std::vector<uint32_t> temp_buffer;\n+  temp_buffer.resize(mini_batch_size * 4);\n+\n+  printf(\"cycles per hash \");\n+  for (bool use_simd : {false, true}) {\n+    auto start = std::chrono::high_resolution_clock::now();\n+    for (int i = 0; i < num_repeats; ++i) {\n+      if (use_32bit_hash) {\n+        if (!use_varlen_input) {\n+          Hashing32::hash_fixed(use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                                /*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd32.data() : hashes_scalar32.data(),\n+                                temp_buffer.data());\n+        } else {\n+          for (int first_row = 0; first_row < num_rows;) {\n+            int batch_size_next = std::min(num_rows - first_row, mini_batch_size);\n+\n+            Hashing32::hash_varlen(\n+                use_simd ? hardware_flags_simd : hardware_flags_scalar,\n+                /*combine_hashes=*/false, batch_size_next,\n+                keys_offsets.data() + first_row, keys.data(),\n+                (use_simd ? hashes_simd32.data() : hashes_scalar32.data()) + first_row,\n+                temp_buffer.data());\n+\n+            first_row += batch_size_next;\n+          }\n+        }\n+      } else {\n+        if (!use_varlen_input) {\n+          Hashing64::hash_fixed(/*combine_hashes=*/false, num_rows, max_length,\n+                                keys.data(),\n+                                use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        } else {\n+          Hashing64::hash_varlen(\n+              /*combine_hashes=*/false, num_rows, keys_offsets.data(), keys.data(),\n+              use_simd ? hashes_simd64.data() : hashes_scalar64.data());\n+        }\n+      }\n+    }\n+    auto end = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n+    float nanos_per_hash =\n+        static_cast<float>(ns) / static_cast<float>(num_rows * num_repeats);\n+    printf(\"%s %.2f \", use_simd ? \"avx2\" : \"scalar\", nanos_per_hash);\n+\n+    if (!use_simd && cpu_nanos_scalar) {\n+      *cpu_nanos_scalar = nanos_per_hash;\n+    }\n+    if (use_simd && cpu_nanos_simd) {\n+      *cpu_nanos_simd = nanos_per_hash;\n+    }\n+  }\n+  if (use_32bit_hash) {\n+    for (int i = 0; i < num_rows; ++i) {\n+      hashes_scalar64[i] = hashes_scalar32[i];\n+      hashes_simd64[i] = hashes_simd32[i];\n+    }\n+  }\n+\n+  // Verify that both scalar and AVX2 implementations give the same hashes\n+  //\n+  bool ok = true;\n+  for (int i = 0; i < num_rows; ++i) {\n+    if (hashes_scalar64[i] != hashes_simd64[i]) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+    }\n+  }\n+  printf(\"%s \", ok ? \"correct\" : \"wrong\");\n\nReview comment:\n       there is an assert above\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:42:50.812+0000",
                    "updated": "2022-03-08T07:42:50.812+0000",
                    "started": "2022-03-08T07:42:50.811+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737989",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737990",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821397487\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n\nReview comment:\n       Why is the second form better than the first one?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:43:56.214+0000",
                    "updated": "2022-03-08T07:43:56.214+0000",
                    "started": "2022-03-08T07:43:56.214+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737990",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737993",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821400575\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n\nReview comment:\n       Assertion would be too strong. This is to verify the quality of the generated set of masks, but it was meant as a help in manual verification. I will remove that. If somebody tries to change set of masks its on them to prove that their set is better and the benchmarks should show if they actually are (its unlikely anybody would want to do that without changing the entire Bloom filter design).\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:48:54.192+0000",
                    "updated": "2022-03-08T07:48:54.192+0000",
                    "started": "2022-03-08T07:48:54.192+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737993",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737994",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821403770\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n\nReview comment:\n       I'll remove that test.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:53:49.450+0000",
                    "updated": "2022-03-08T07:53:49.450+0000",
                    "started": "2022-03-08T07:53:49.450+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737994",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737996",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821406119\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n\nReview comment:\n       Repeating in a loop are needed to get meaningful time measurements. Time measurements in debug do not make sense and also yes, the repeats would make test take unreasonably long time with no benefit in debug.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:57:15.372+0000",
                    "updated": "2022-03-08T07:57:15.372+0000",
                    "started": "2022-03-08T07:57:15.372+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737996",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737997",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821406247\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n\nReview comment:\n       I am removing time measurements from the test.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T07:57:28.040+0000",
                    "updated": "2022-03-08T07:57:28.040+0000",
                    "started": "2022-03-08T07:57:28.040+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737997",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/737999",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821408279\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n\nReview comment:\n       I added a comment\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T08:00:34.469+0000",
                    "updated": "2022-03-08T08:00:34.469+0000",
                    "started": "2022-03-08T08:00:34.469+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "737999",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/738000",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821409515\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n\nReview comment:\n       locks_ cannot be a vector because there they contain atomic members and these cannot be used in vectors.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T08:02:20.751+0000",
                    "updated": "2022-03-08T08:02:20.751+0000",
                    "started": "2022-03-08T08:02:20.751+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "738000",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/738002",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821409515\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/partition_util.cc\n##########\n@@ -0,0 +1,91 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/partition_util.h\"\n+#include <mutex>\n+\n+namespace arrow {\n+namespace compute {\n+\n+PartitionLocks::PartitionLocks()\n+    : num_prtns_(0),\n+      locks_(nullptr),\n+      rand_seed_{0, 0, 0, 0, 0, 0, 0, 0},\n+      rand_engine_(rand_seed_) {}\n+\n+PartitionLocks::~PartitionLocks() { CleanUp(); }\n+\n+void PartitionLocks::Init(int num_prtns) {\n+  num_prtns_ = num_prtns;\n+  locks_ = new PartitionLock[num_prtns];\n\nReview comment:\n       locks_ cannot be a vector because they contain atomic members and these cannot be used in vectors.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T08:04:13.639+0000",
                    "updated": "2022-03-08T08:04:13.639+0000",
                    "started": "2022-03-08T08:04:13.638+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "738002",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/738005",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821413912\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n\nReview comment:\n       I removed benchmarking parts in both unit tests in this file.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T08:08:50.710+0000",
                    "updated": "2022-03-08T08:08:50.710+0000",
                    "started": "2022-03-08T08:08:50.710+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "738005",
                    "issueId": "13420467"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/worklog/738006",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on a change in pull request #12067:\nURL: https://github.com/apache/arrow/pull/12067#discussion_r821419293\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/bloom_filter_test.cc\n##########\n@@ -0,0 +1,633 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+\n+#include <algorithm>\n+#include <chrono>\n+#include <condition_variable>\n+#include <set>\n+#include <thread>\n+#include \"arrow/compute/exec/bloom_filter.h\"\n+#include \"arrow/compute/exec/key_hash.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/cpu_info.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+TEST(BloomFilter, Masks) {\n+  BloomFilterMasks masks;\n+  std::vector<int> sum_num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+  std::vector<int> num_masks_with_same_n_bits(BloomFilterMasks::kMaxBitsSet + 1);\n+\n+  for (bool with_rotation : {false, true}) {\n+    printf(\"With bit rotation: %s\\n\", with_rotation ? \"ON\" : \"OFF\");\n+\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      sum_num_masks_with_same_n_bits[i] = 0;\n+    }\n+\n+    for (int imask = 0; imask < BloomFilterMasks::kNumMasks; ++imask) {\n+      uint64_t mask = masks.mask(imask);\n+      // Verify that the number of bits set is in the required range\n+      //\n+      ARROW_DCHECK(ARROW_POPCOUNT64(mask) >= BloomFilterMasks::kMinBitsSet &&\n+                   ARROW_POPCOUNT64(mask) <= BloomFilterMasks::kMaxBitsSet);\n+\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        num_masks_with_same_n_bits[i] = 0;\n+      }\n+      for (int imask2nd = 0; imask2nd < BloomFilterMasks::kNumMasks; ++imask2nd) {\n+        if (imask == imask2nd) {\n+          continue;\n+        }\n+        uint64_t mask_to_compare_to = masks.mask(imask2nd);\n+        for (int bits_to_rotate = 0; bits_to_rotate < (with_rotation ? 64 : 1);\n+             ++bits_to_rotate) {\n+          uint64_t mask_rotated = bits_to_rotate == 0\n+                                      ? mask_to_compare_to\n+                                      : ROTL64(mask_to_compare_to, bits_to_rotate);\n+          ++num_masks_with_same_n_bits[ARROW_POPCOUNT64(mask & mask_rotated)];\n+        }\n+      }\n+      for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+        sum_num_masks_with_same_n_bits[i] += num_masks_with_same_n_bits[i];\n+      }\n+    }\n+\n+    printf(\n+        \"Expected fraction of masks with the same N bits as any random \"\n+        \"mask:\\n\");\n+    for (int i = 0; i <= BloomFilterMasks::kMaxBitsSet; ++i) {\n+      printf(\"%d. %.2f \\n\", i,\n+             static_cast<float>(sum_num_masks_with_same_n_bits[i]) /\n+                 (static_cast<float>(BloomFilterMasks::kNumMasks *\n+                                     BloomFilterMasks::kNumMasks) *\n+                  (with_rotation ? 64 : 1)));\n+    }\n+    printf(\"\\n\");\n+  }\n+}\n+\n+Status BuildBloomFilter(BloomFilterBuildStrategy strategy, size_t num_threads,\n+                        int64_t hardware_flags, MemoryPool* pool, int64_t num_rows,\n+                        std::function<void(int64_t, int, uint32_t*)> get_hash32_impl,\n+                        std::function<void(int64_t, int, uint64_t*)> get_hash64_impl,\n+                        BlockedBloomFilter* target, float* build_cost) {\n+  constexpr int batch_size_max = 32 * 1024;\n+  int64_t num_batches = bit_util::CeilDiv(num_rows, batch_size_max);\n+\n+  // omp_set_num_threads(static_cast<int>(num_threads));\n+\n+  auto builder = BloomFilterBuilder::Make(strategy);\n+\n+  std::vector<std::vector<uint32_t>> thread_local_hashes32;\n+  std::vector<std::vector<uint64_t>> thread_local_hashes64;\n+  thread_local_hashes32.resize(num_threads);\n+  thread_local_hashes64.resize(num_threads);\n+  for (size_t i = 0; i < num_threads; ++i) {\n+    thread_local_hashes32[i].resize(batch_size_max);\n+    thread_local_hashes64[i].resize(batch_size_max);\n+  }\n+\n+  std::vector<float> build_cost_vector;\n+  int64_t num_repeats =\n+      std::max(static_cast<int64_t>(1), bit_util::CeilDiv(1LL << 27, num_rows));\n+#ifndef NDEBUG\n+  num_repeats = 1LL;\n+#endif\n+  build_cost_vector.resize(num_repeats);\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    auto time0 = std::chrono::high_resolution_clock::now();\n+\n+    RETURN_NOT_OK(builder->Begin(num_threads, hardware_flags, pool, num_rows,\n+                                 bit_util::CeilDiv(num_rows, batch_size_max), target));\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunInitTask(i);\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < num_batches; ++i) {\n+      size_t thread_index = 0;  // omp_get_thread_num();\n+      int batch_size = static_cast<int>(\n+          std::min(num_rows - i * batch_size_max, static_cast<int64_t>(batch_size_max)));\n+      if (target->NumHashBitsUsed() > 32) {\n+        uint64_t* hashes = thread_local_hashes64[thread_index].data();\n+        get_hash64_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      } else {\n+        uint32_t* hashes = thread_local_hashes32[thread_index].data();\n+        get_hash32_impl(i * batch_size_max, batch_size, hashes);\n+        Status status = builder->PushNextBatch(thread_index, batch_size, hashes);\n+        ARROW_DCHECK(status.ok());\n+      }\n+    }\n+\n+    // #pragma omp parallel for\n+    for (int64_t i = 0; i < builder->num_tasks(); ++i) {\n+      builder->RunFinishTask(i);\n+    }\n+\n+    auto time1 = std::chrono::high_resolution_clock::now();\n+    auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+\n+    builder->CleanUp();\n+\n+    build_cost_vector[irepeat] = static_cast<float>(ns) / static_cast<float>(num_rows);\n+  }\n+\n+  std::sort(build_cost_vector.begin(), build_cost_vector.end());\n+  *build_cost = build_cost_vector[build_cost_vector.size() / 2];\n+\n+  return Status::OK();\n+}\n+\n+// FPR (false positives rate) - fraction of false positives relative to the sum\n+// of false positives and true negatives.\n+//\n+// Output FPR and build and probe cost.\n+//\n+Status TestBloomSmall(BloomFilterBuildStrategy strategy, int64_t num_build,\n+                      int num_build_copies, int dop, bool use_simd, bool enable_prefetch,\n+                      float* fpr, float* build_cost, float* probe_cost) {\n+  int64_t hardware_flags = use_simd ? ::arrow::internal::CpuInfo::AVX2 : 0;\n+\n+  // Generate input keys\n+  //\n+  int64_t num_probe = 4 * num_build;\n+  Random64Bit rnd(/*seed=*/0);\n+  std::vector<uint64_t> unique_keys;\n+  {\n+    std::set<uint64_t> unique_keys_set;\n+    for (int64_t i = 0; i < num_build + num_probe; ++i) {\n+      uint64_t value;\n+      for (;;) {\n+        value = rnd.next();\n+        if (unique_keys_set.find(value) == unique_keys_set.end()) {\n+          break;\n+        }\n+      }\n+      unique_keys.push_back(value);\n+      unique_keys_set.insert(value);\n+    }\n+  }\n+\n+  // Generate input hashes\n+  //\n+  std::vector<uint32_t> hashes32;\n+  std::vector<uint64_t> hashes64;\n+  hashes32.resize(unique_keys.size());\n+  hashes64.resize(unique_keys.size());\n+  int batch_size_max = 1024;\n+  for (size_t i = 0; i < unique_keys.size(); i += batch_size_max) {\n+    int batch_size = static_cast<int>(\n+        std::min(unique_keys.size() - i, static_cast<size_t>(batch_size_max)));\n+    int key_length = sizeof(uint64_t);\n+    Hashing32::hash_fixed(hardware_flags, /*combine_hashes=*/false, batch_size,\n+                          key_length,\n+                          reinterpret_cast<const uint8_t*>(unique_keys.data() + i),\n+                          hashes32.data() + i, nullptr);\n+    Hashing64::hash_fixed(\n+        /*combine_hashes=*/false, batch_size, key_length,\n+        reinterpret_cast<const uint8_t*>(unique_keys.data() + i), hashes64.data() + i);\n+  }\n+\n+  MemoryPool* pool = default_memory_pool();\n+\n+  // Build the filter\n+  //\n+  BlockedBloomFilter reference;\n+  BlockedBloomFilter bloom;\n+  float build_cost_single_threaded;\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      BloomFilterBuildStrategy::SINGLE_THREADED, dop, hardware_flags, pool, num_build,\n+      [hashes32](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        memcpy(output_hashes, hashes32.data() + first_row, num_rows * sizeof(uint32_t));\n+      },\n+      [hashes64](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        memcpy(output_hashes, hashes64.data() + first_row, num_rows * sizeof(uint64_t));\n+      },\n+      &reference, &build_cost_single_threaded));\n+\n+  RETURN_NOT_OK(BuildBloomFilter(\n+      strategy, dop, hardware_flags, pool, num_build * num_build_copies,\n+      [hashes32, num_build](int64_t first_row, int num_rows, uint32_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes32.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint32_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      [hashes64, num_build](int64_t first_row, int num_rows, uint64_t* output_hashes) {\n+        int64_t first_row_clamped = first_row % num_build;\n+        int64_t num_rows_processed = 0;\n+        while (num_rows_processed < num_rows) {\n+          int64_t num_rows_next =\n+              std::min(static_cast<int64_t>(num_rows) - num_rows_processed,\n+                       num_build - first_row_clamped);\n+          memcpy(output_hashes + num_rows_processed, hashes64.data() + first_row_clamped,\n+                 num_rows_next * sizeof(uint64_t));\n+          first_row_clamped = 0;\n+          num_rows_processed += num_rows_next;\n+        }\n+      },\n+      &bloom, build_cost));\n+\n+  int log_before = bloom.log_num_blocks();\n+\n+  if (num_build_copies > 1) {\n+    reference.Fold();\n+    bloom.Fold();\n+  } else {\n+    if (strategy != BloomFilterBuildStrategy::SINGLE_THREADED) {\n+      bool is_same = reference.IsSameAs(&bloom);\n+      printf(\"%s \", is_same ? \"BUILD_CORRECT\" : \"BUILD_WRONG\");\n+      ARROW_DCHECK(is_same);\n+    }\n+  }\n+\n+  int log_after = bloom.log_num_blocks();\n+\n+  float fraction_of_bits_set = static_cast<float>(bloom.NumBitsSet()) /\n+                               static_cast<float>(64LL << bloom.log_num_blocks());\n+\n+  printf(\"log_before = %d log_after = %d percent_bits_set = %.1f \", log_before, log_after,\n+         100.0f * fraction_of_bits_set);\n+\n+  // Verify no false negatives\n+  //\n+  bool ok = true;\n+  for (int64_t i = 0; i < num_build; ++i) {\n+    bool found;\n+    if (bloom.NumHashBitsUsed() > 32) {\n+      found = bloom.Find(hashes64[i]);\n+    } else {\n+      found = bloom.Find(hashes32[i]);\n+    }\n+    if (!found) {\n+      ok = false;\n+      ARROW_DCHECK(false);\n+      break;\n+    }\n+  }\n+  printf(\"%s\\n\", ok ? \"success\" : \"failure\");\n+\n+  // Measure FPR and performance\n+  //\n+  std::vector<uint8_t> result_bit_vector;\n+  result_bit_vector.resize(bit_util::BytesForBits(batch_size_max));\n+  std::atomic<int64_t> num_positives;\n+  num_positives.store(0);\n+\n+  int64_t num_repeats = 1LL;\n+#ifdef NDEBUG\n+  num_repeats = std::max(1LL, bit_util::CeilDiv(1000000ULL, num_probe));\n+#endif\n+\n+  auto time0 = std::chrono::high_resolution_clock::now();\n+\n+  for (int64_t irepeat = 0; irepeat < num_repeats; ++irepeat) {\n+    for (int64_t i = num_build; i < num_build + num_probe;) {\n+      int batch_size =\n+          static_cast<int>(std::min(static_cast<size_t>(unique_keys.size() - i),\n+                                    static_cast<size_t>(batch_size_max)));\n+      if (bloom.NumHashBitsUsed() > 32) {\n+        bloom.Find(hardware_flags, batch_size, hashes64.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      } else {\n+        bloom.Find(hardware_flags, batch_size, hashes32.data() + i,\n+                   result_bit_vector.data(), enable_prefetch);\n+      }\n+      num_positives += arrow::internal::CountSetBits(result_bit_vector.data(),\n+                                                     /*offset=*/0, batch_size);\n+      i += batch_size;\n+    }\n+  }\n+  auto time1 = std::chrono::high_resolution_clock::now();\n+  auto ns = std::chrono::duration_cast<std::chrono::nanoseconds>(time1 - time0).count();\n+  *probe_cost = static_cast<float>(ns) / static_cast<float>(num_probe * num_repeats);\n+\n+  *fpr = 100.0f * static_cast<float>(num_positives.load()) /\n+         static_cast<float>(num_probe * num_repeats);\n+\n+  return Status::OK();\n\nReview comment:\n       removed\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-08T08:16:25.147+0000",
                    "updated": "2022-03-08T08:16:25.147+0000",
                    "started": "2022-03-08T08:16:25.147+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "738006",
                    "issueId": "13420467"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 37800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2a14c715[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@71b34010[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3774e7ed[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@5c2c92d3[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5776328e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@4923a856[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@59f86510[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@61facef6[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7fe6205[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@53cb0bb4[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@49012438[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@7e3bce90[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 37800,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Mar 24 08:19:58 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-03-24T08:19:58.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15239/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2022-01-03T20:37:35.000+0000",
        "updated": "2022-03-25T16:12:12.000+0000",
        "timeoriginalestimate": null,
        "description": "Bloom filters are a common way to improve performance of hash joins where many rows on the probe side of the hash join do not have matches on the build side. Bloom filters are often able to reduce the cost of eliminating such rows early in the processing pipeline, since they are cheaper to probe than the hash join hash table, but they can return false positives for a reasonably small percentage of inputs.\r\n\r\nThis task is about introducing a data structure of register blocked Bloom filter implementation (a practical modification of Bloom filter concept that is specifically tuned for use in query processing related to hash joins and both more space efficient and less costly than using hash table for filtering). The data structure should provide functionality for parallel construction from a vector of exec batches accumulated in memory and vectorized lookup and filtering for a single exec batch. It should not have a limit on the size of the Bloom filter (the number of inserted hashes), which requires using 64-bit hashes for larger inputs. It should be verified that build and probe costs are reasonable low and false positives rate is at most few percent (which should be acceptable in use for query processing).",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "10.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 37800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Compute] Introduce Bloom filters to hash join",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/comment/17476100",
                    "id": "17476100",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kszucs",
                        "name": "kszucs",
                        "key": "kszucs",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Krisztian Szucs",
                        "active": true,
                        "timeZone": "Europe/Budapest"
                    },
                    "body": "Since the PR is in draft I'm postponing it to 8.0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kszucs",
                        "name": "kszucs",
                        "key": "kszucs",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Krisztian Szucs",
                        "active": true,
                        "timeZone": "Europe/Budapest"
                    },
                    "created": "2022-01-14T12:20:24.838+0000",
                    "updated": "2022-01-14T12:20:24.838+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13420467/comment/17511678",
                    "id": "17511678",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 12067\n[https://github.com/apache/arrow/pull/12067]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-03-24T08:19:58.633+0000",
                    "updated": "2022-03-24T08:19:58.633+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z0y7js:",
        "customfield_12314139": null
    }
}