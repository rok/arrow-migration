{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13117841",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841",
    "key": "ARROW-1802",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341352",
                "id": "12341352",
                "name": "0.8.0",
                "archived": false,
                "released": true,
                "releaseDate": "2017-12-18"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=kou",
            "name": "kou",
            "key": "kou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=kou&avatarId=30762",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kou&avatarId=30762",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kou&avatarId=30762",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kou&avatarId=30762"
            },
            "displayName": "Kouhei Sutou",
            "active": true,
            "timeZone": "Asia/Tokyo"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12332430",
                "id": "12332430",
                "name": "GLib"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333104",
                "id": "12333104",
                "name": "GPU"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=kou",
            "name": "kou",
            "key": "kou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=kou&avatarId=30762",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kou&avatarId=30762",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kou&avatarId=30762",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kou&avatarId=30762"
            },
            "displayName": "Kouhei Sutou",
            "active": true,
            "timeZone": "Asia/Tokyo"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=kou",
            "name": "kou",
            "key": "kou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=kou&avatarId=30762",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kou&avatarId=30762",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kou&avatarId=30762",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kou&avatarId=30762"
            },
            "displayName": "Kouhei Sutou",
            "active": true,
            "timeZone": "Asia/Tokyo"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1802/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@25abae7d[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@18ab7db5[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7529f5ca[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@362c680f[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@34a179cf[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@723cde71[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4881e259[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@1db88756[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2268fa2f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@36b36745[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@71e7d8e0[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@283c73bd[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Nov 14 14:15:10 UTC 2017",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2017-11-14T03:54:24.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1802/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2017-11-13T04:42:11.000+0000",
        "updated": "2017-11-14T14:15:10.000+0000",
        "timeoriginalestimate": null,
        "description": null,
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[GLib] Add Arrow GPU support",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16249099",
                    "id": "16249099",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "kou opened a new pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313\n \n \n   arrow-gpu isn't required. If `arrow-gpu.pc` isn't installed, GPU support is just ignored.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-13T04:44:35.624+0000",
                    "updated": "2017-11-13T04:44:35.624+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16250787",
                    "id": "16250787",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313#discussion_r150731509\n \n \n\n ##########\n File path: c_glib/test/test-gpu-cuda.rb\n ##########\n @@ -0,0 +1,144 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+class TestGPUCUDA < Test::Unit::TestCase\n+  include Helper::Buildable\n+\n+  def setup\n+    omit(\"Arrow GPU is required\") unless defined?(::ArrowGPU)\n+    @manager = ArrowGPU::CUDADeviceManager.new\n+    omit(\"At least one GPU is required\") if @manager.n_devices.zero?\n+    @context = @manager.get_context(0)\n+  end\n+\n+  sub_test_case(\"Context\") do\n+    def test_allocated_size\n+      allocated_size_before = @context.allocated_size\n+      size = 128\n+      buffer = ArrowGPU::CUDABuffer.new(@context, size)\n+      assert_equal(size,\n+                   @context.allocated_size - allocated_size_before)\n+    end\n+  end\n+\n+  sub_test_case(\"Buffer\") do\n+    def setup\n+      super\n+      @buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+    end\n+\n+    def test_copy\n+      @buffer.copy_from_host(\"Hello World\")\n+      assert_equal(\"llo W\", @buffer.copy_to_host(2, 5).to_s)\n+    end\n+\n+    def test_export\n+      @buffer.copy_from_host(\"Hello World\")\n+      handle = @buffer.export\n+      serialized_handle = handle.serialize.data\n+      Tempfile.open(\"arrow-gpu-cuda-export\") do |output|\n+        pid = spawn(RbConfig.ruby, \"-e\", <<-SCRIPT)\n+require \"gi\"\n+\n+Gio = GI.load(\"Gio\")\n+Arrow = GI.load(\"Arrow\")\n+ArrowGPU = GI.load(\"ArrowGPU\")\n+\n+manager = ArrowGPU::CUDADeviceManager.new\n+context = manager.get_context(0)\n+serialized_handle = #{serialized_handle.to_s.dump}\n+handle = ArrowGPU::CUDAIPCMemoryHandle.new(serialized_handle)\n+buffer = ArrowGPU::CUDABuffer.new(context, handle)\n+File.open(#{output.path.dump}, \"w\") do |output|\n+  output.print(buffer.copy_to_host(0, 6).to_s)\n+end\n \n Review comment:\n   ah I see you did test the IPC! We should try to get a C++ test working, it looked a bit tricky with googletest so didn't get it working yet\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T03:53:24.509+0000",
                    "updated": "2017-11-14T03:53:24.509+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16250788",
                    "id": "16250788",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313#discussion_r150725161\n \n \n\n ##########\n File path: c_glib/arrow-gpu-glib/cuda.cpp\n ##########\n @@ -0,0 +1,941 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#ifdef HAVE_CONFIG_H\n+#  include <config.h>\n+#endif\n+\n+#include <arrow-glib/buffer.hpp>\n+#include <arrow-glib/error.hpp>\n+#include <arrow-glib/input-stream.hpp>\n+#include <arrow-glib/output-stream.hpp>\n+#include <arrow-glib/readable.hpp>\n+#include <arrow-glib/record-batch.hpp>\n+#include <arrow-glib/schema.hpp>\n+\n+#include <arrow-gpu-glib/cuda.hpp>\n+\n+G_BEGIN_DECLS\n+\n+/**\n+ * SECTION: cuda\n+ * @section_id: cuda-classes\n+ * @title: CUDA related classes\n+ * @include: arrow-gpu-glib/arrow-gpu-glib.h\n+ *\n+ * The following classes provide CUDA support for Apache Arrow data.\n+ *\n+ * #GArrowGPUCUDADeviceManager is the starting point. You need at\n+ * least one #GArrowGPUCUDAContext to process Apache Arrow data on\n+ * NVIDIA GPU.\n+ *\n+ * #GArrowGPUCUDAContext is a class to keep context for one GPU. You\n+ * need to create #GArrowGPUCUDAContext for each GPU that you want to\n+ * use. You can create #GArrowGPUCUDAContext by\n+ * garrow_gpu_cuda_device_manager_get_context().\n+ *\n+ * #GArrowGPUCUDABuffer is a class for data on GPU. You can copy data\n+ * on GPU to/from CPU by garrow_gpu_cuda_buffer_copy_to_host() and\n+ * garrow_gpu_cuda_buffer_copy_from_host(). You can share data on GPU\n+ * with other processes by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDAHostBuffer is a class for data on CPU that is\n+ * directly accessible from GPU.\n+ *\n+ * #GArrowGPUCUDAIPCMemoryHandle is a class to share data on GPU with\n+ * other processes. You can export your data on GPU to other processes\n+ * by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_ipc_memory_handle_new(). You can import other\n+ * process data on GPU by garrow_gpu_cuda_ipc_memory_handle_new() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDABufferInputStream is a class to read data in\n+ * #GArrowGPUCUDABuffer.\n+ *\n+ * #GArrowGPUCUDABufferOutputStream is a class to write data into\n+ * #GArrowGPUCUDABuffer.\n+ */\n+\n+G_DEFINE_TYPE(GArrowGPUCUDADeviceManager,\n+              garrow_gpu_cuda_device_manager,\n+              G_TYPE_OBJECT)\n+\n+static void\n+garrow_gpu_cuda_device_manager_init(GArrowGPUCUDADeviceManager *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_device_manager_class_init(GArrowGPUCUDADeviceManagerClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_new:\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDADeviceManager on success,\n+ *   %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDADeviceManager *\n+garrow_gpu_cuda_device_manager_new(GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][device-manager][new]\")) {\n+    auto manager = g_object_new(GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER,\n+                                NULL);\n+    return GARROW_GPU_CUDA_DEVICE_MANAGER(manager);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_context:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ * @gpu_number: A GPU device number for the target context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext on\n+ *   success, %NULL on error. Contexts for the same GPU device number\n+ *   share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n+                                           gint gpu_number,\n+                                           GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+  auto status = arrow_manager->GetContext(gpu_number, &context);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][device-manager][get-context]]\")) {\n+    return garrow_gpu_cuda_context_new_raw(&context);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_n_devices:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ *\n+ * Returns: The number of GPU devices.\n+ *\n+ * Since: 0.8.0\n+ */\n+gsize\n+garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  return arrow_manager->num_devices();\n+}\n+\n+\n+typedef struct GArrowGPUCUDAContextPrivate_ {\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+} GArrowGPUCUDAContextPrivate;\n+\n+enum {\n+  PROP_CONTEXT = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAContext,\n+                           garrow_gpu_cuda_context,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object)     \\\n+  static_cast<GArrowGPUCUDAContextPrivate *>(           \\\n+    garrow_gpu_cuda_context_get_instance_private(       \\\n+      GARROW_GPU_CUDA_CONTEXT(object)))\n+\n+static void\n+garrow_gpu_cuda_context_finalize(GObject *object)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  priv->context = nullptr;\n+\n+  G_OBJECT_CLASS(garrow_gpu_cuda_context_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_gpu_cuda_context_set_property(GObject *object,\n+                                     guint prop_id,\n+                                     const GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_CONTEXT:\n+    priv->context =\n+      *static_cast<std::shared_ptr<arrow::gpu::CudaContext> *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_get_property(GObject *object,\n+                                     guint prop_id,\n+                                     GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_init(GArrowGPUCUDAContext *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_context_class_init(GArrowGPUCUDAContextClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_gpu_cuda_context_finalize;\n+  gobject_class->set_property = garrow_gpu_cuda_context_set_property;\n+  gobject_class->get_property = garrow_gpu_cuda_context_get_property;\n+\n+  /**\n+   * GArrowGPUCUDAContext:context:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"context\",\n+                              \"Context\",\n+                              \"The raw std::shared_ptr<arrow::gpu::CudaContext> *\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_CONTEXT, spec);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_context_get_allocated_size:\n+ * @context: A #GArrowGPUCUDAContext.\n+ *\n+ * Returns: The allocated memory by this context in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  return arrow_context->bytes_allocated();\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDABuffer,\n+              garrow_gpu_cuda_buffer,\n+              GARROW_TYPE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_buffer_init(GArrowGPUCUDABuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_class_init(GArrowGPUCUDABufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @size: The number of bytes to be allocated on GPU device for this context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n+                           gint64 size,\n+                           GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->Allocate(size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][new]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_ipc:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @handle: A #GArrowGPUCUDAIPCMemoryHandle to be communicated.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has data from the IPC target.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n+                               GArrowGPUCUDAIPCMemoryHandle *handle,\n+                               GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->OpenIpcBuffer(*arrow_handle, &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-ipc]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_record_batch:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @record_batch: A #GArrowRecordBatch to be serialized.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has serialized record batch\n+ *   data.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n+                                        GArrowRecordBatch *record_batch,\n+                                        GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_record_batch = garrow_record_batch_get_raw(record_batch);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow::gpu::SerializeRecordBatch(*arrow_record_batch,\n+                                                 arrow_context.get(),\n+                                                 &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-record-batch]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_to_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @position: The offset of memory on GPU device to be copied.\n+ * @size: The size of memory on GPU device to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A #GBytes that have copied memory on CPU\n+ *   host on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GBytes *\n+garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n+                                    gint64 position,\n+                                    gint64 size,\n+                                    GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto data = static_cast<uint8_t *>(g_malloc(size));\n+  auto status = arrow_buffer->CopyToHost(position, size, data);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][copy-to-host]\")) {\n+    return g_bytes_new_take(data, size);\n+  } else {\n+    g_free(data);\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_from_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @data: (array length=size): Data on CPU host to be copied.\n+ * @size: The size of data on CPU host to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n+                                      const guint8 *data,\n+                                      gint64 size,\n+                                      GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto status = arrow_buffer->CopyFromHost(0, data, size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[gpu][cuda][buffer][copy-from-host]\");\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_export:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowGPUCUDAIPCMemoryHandle to handle the exported buffer on\n+ *   success, %NULL on error\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_buffer_export(GArrowGPUCUDABuffer *buffer, GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  std::unique_ptr<arrow::gpu::CudaIpcMemHandle> arrow_handle;\n+  auto status = arrow_buffer->ExportForIpc(&arrow_handle);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][export-for-ipc]\")) {\n+    return garrow_gpu_cuda_ipc_memory_handle_new_raw(arrow_handle.release());\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_get_context:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext for the\n+ *   buffer. Contexts for the same buffer share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_buffer_get_context(GArrowGPUCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_context = arrow_buffer->context();\n+  return garrow_gpu_cuda_context_new_raw(&arrow_context);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_read_record_batch:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @schema: A #GArrowSchema for record batch.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowRecordBatch on\n+ *   success, %NULL on error. The record batch data is located on GPU.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowRecordBatch *\n+garrow_gpu_cuda_buffer_read_record_batch(GArrowGPUCUDABuffer *buffer,\n+                                         GArrowSchema *schema,\n+                                         GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_schema = garrow_schema_get_raw(schema);\n+  auto pool = arrow::default_memory_pool();\n+  std::shared_ptr<arrow::RecordBatch> arrow_record_batch;\n+  auto status = arrow::gpu::ReadRecordBatch(arrow_schema,\n+                                            arrow_buffer,\n+                                            pool,\n+                                            &arrow_record_batch);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][read-record-batch]\")) {\n+    return garrow_record_batch_new_raw(&arrow_record_batch);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDAHostBuffer,\n+              garrow_gpu_cuda_host_buffer,\n+              GARROW_TYPE_MUTABLE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_host_buffer_init(GArrowGPUCUDAHostBuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_host_buffer_class_init(GArrowGPUCUDAHostBufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_host_buffer_new:\n+ * @size: The number of bytes to be allocated on CPU host.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDAHostBuffer on success,\n+ *   %NULL on error. The allocated memory is accessible from GPU\n+ *   device for the @context.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAHostBuffer *\n+garrow_gpu_cuda_host_buffer_new(gint64 size, GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  std::shared_ptr<arrow::gpu::CudaHostBuffer> arrow_buffer;\n+  status = manager->AllocateHost(size, &arrow_buffer);\n \n Review comment:\n   How do you anticipate to provide for multiple contexts? See ARROW-1423. I don't yet understand the precise semantics around multiple contexts and multiple GPUs, and dealing with `CUcontext` objects created by other libraries (e.g. I would like to get this stuff working in MapD, and they create and manage their own contexts https://github.com/mapd/mapd-core)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T03:53:24.512+0000",
                    "updated": "2017-11-14T03:53:24.512+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16250789",
                    "id": "16250789",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313#discussion_r150724095\n \n \n\n ##########\n File path: c_glib/arrow-gpu-glib/cuda.cpp\n ##########\n @@ -0,0 +1,941 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#ifdef HAVE_CONFIG_H\n+#  include <config.h>\n+#endif\n+\n+#include <arrow-glib/buffer.hpp>\n+#include <arrow-glib/error.hpp>\n+#include <arrow-glib/input-stream.hpp>\n+#include <arrow-glib/output-stream.hpp>\n+#include <arrow-glib/readable.hpp>\n+#include <arrow-glib/record-batch.hpp>\n+#include <arrow-glib/schema.hpp>\n+\n+#include <arrow-gpu-glib/cuda.hpp>\n+\n+G_BEGIN_DECLS\n+\n+/**\n+ * SECTION: cuda\n+ * @section_id: cuda-classes\n+ * @title: CUDA related classes\n+ * @include: arrow-gpu-glib/arrow-gpu-glib.h\n+ *\n+ * The following classes provide CUDA support for Apache Arrow data.\n+ *\n+ * #GArrowGPUCUDADeviceManager is the starting point. You need at\n+ * least one #GArrowGPUCUDAContext to process Apache Arrow data on\n+ * NVIDIA GPU.\n+ *\n+ * #GArrowGPUCUDAContext is a class to keep context for one GPU. You\n+ * need to create #GArrowGPUCUDAContext for each GPU that you want to\n+ * use. You can create #GArrowGPUCUDAContext by\n+ * garrow_gpu_cuda_device_manager_get_context().\n+ *\n+ * #GArrowGPUCUDABuffer is a class for data on GPU. You can copy data\n+ * on GPU to/from CPU by garrow_gpu_cuda_buffer_copy_to_host() and\n+ * garrow_gpu_cuda_buffer_copy_from_host(). You can share data on GPU\n+ * with other processes by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDAHostBuffer is a class for data on CPU that is\n+ * directly accessible from GPU.\n+ *\n+ * #GArrowGPUCUDAIPCMemoryHandle is a class to share data on GPU with\n+ * other processes. You can export your data on GPU to other processes\n+ * by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_ipc_memory_handle_new(). You can import other\n+ * process data on GPU by garrow_gpu_cuda_ipc_memory_handle_new() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDABufferInputStream is a class to read data in\n+ * #GArrowGPUCUDABuffer.\n+ *\n+ * #GArrowGPUCUDABufferOutputStream is a class to write data into\n+ * #GArrowGPUCUDABuffer.\n+ */\n+\n+G_DEFINE_TYPE(GArrowGPUCUDADeviceManager,\n+              garrow_gpu_cuda_device_manager,\n+              G_TYPE_OBJECT)\n+\n+static void\n+garrow_gpu_cuda_device_manager_init(GArrowGPUCUDADeviceManager *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_device_manager_class_init(GArrowGPUCUDADeviceManagerClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_new:\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDADeviceManager on success,\n+ *   %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDADeviceManager *\n+garrow_gpu_cuda_device_manager_new(GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][device-manager][new]\")) {\n+    auto manager = g_object_new(GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER,\n+                                NULL);\n+    return GARROW_GPU_CUDA_DEVICE_MANAGER(manager);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_context:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ * @gpu_number: A GPU device number for the target context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext on\n+ *   success, %NULL on error. Contexts for the same GPU device number\n+ *   share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n+                                           gint gpu_number,\n+                                           GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+  auto status = arrow_manager->GetContext(gpu_number, &context);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][device-manager][get-context]]\")) {\n+    return garrow_gpu_cuda_context_new_raw(&context);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_n_devices:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ *\n+ * Returns: The number of GPU devices.\n+ *\n+ * Since: 0.8.0\n+ */\n+gsize\n+garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  return arrow_manager->num_devices();\n+}\n+\n+\n+typedef struct GArrowGPUCUDAContextPrivate_ {\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+} GArrowGPUCUDAContextPrivate;\n+\n+enum {\n+  PROP_CONTEXT = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAContext,\n+                           garrow_gpu_cuda_context,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object)     \\\n+  static_cast<GArrowGPUCUDAContextPrivate *>(           \\\n+    garrow_gpu_cuda_context_get_instance_private(       \\\n+      GARROW_GPU_CUDA_CONTEXT(object)))\n+\n+static void\n+garrow_gpu_cuda_context_finalize(GObject *object)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  priv->context = nullptr;\n+\n+  G_OBJECT_CLASS(garrow_gpu_cuda_context_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_gpu_cuda_context_set_property(GObject *object,\n+                                     guint prop_id,\n+                                     const GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_CONTEXT:\n+    priv->context =\n+      *static_cast<std::shared_ptr<arrow::gpu::CudaContext> *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_get_property(GObject *object,\n+                                     guint prop_id,\n+                                     GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_init(GArrowGPUCUDAContext *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_context_class_init(GArrowGPUCUDAContextClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_gpu_cuda_context_finalize;\n+  gobject_class->set_property = garrow_gpu_cuda_context_set_property;\n+  gobject_class->get_property = garrow_gpu_cuda_context_get_property;\n+\n+  /**\n+   * GArrowGPUCUDAContext:context:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"context\",\n+                              \"Context\",\n+                              \"The raw std::shared_ptr<arrow::gpu::CudaContext> *\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_CONTEXT, spec);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_context_get_allocated_size:\n+ * @context: A #GArrowGPUCUDAContext.\n+ *\n+ * Returns: The allocated memory by this context in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  return arrow_context->bytes_allocated();\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDABuffer,\n+              garrow_gpu_cuda_buffer,\n+              GARROW_TYPE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_buffer_init(GArrowGPUCUDABuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_class_init(GArrowGPUCUDABufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @size: The number of bytes to be allocated on GPU device for this context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n+                           gint64 size,\n+                           GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->Allocate(size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][new]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_ipc:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @handle: A #GArrowGPUCUDAIPCMemoryHandle to be communicated.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has data from the IPC target.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n+                               GArrowGPUCUDAIPCMemoryHandle *handle,\n+                               GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->OpenIpcBuffer(*arrow_handle, &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-ipc]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_record_batch:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @record_batch: A #GArrowRecordBatch to be serialized.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has serialized record batch\n+ *   data.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n+                                        GArrowRecordBatch *record_batch,\n+                                        GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_record_batch = garrow_record_batch_get_raw(record_batch);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow::gpu::SerializeRecordBatch(*arrow_record_batch,\n+                                                 arrow_context.get(),\n+                                                 &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-record-batch]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_to_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @position: The offset of memory on GPU device to be copied.\n+ * @size: The size of memory on GPU device to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A #GBytes that have copied memory on CPU\n+ *   host on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GBytes *\n+garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n+                                    gint64 position,\n+                                    gint64 size,\n+                                    GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto data = static_cast<uint8_t *>(g_malloc(size));\n+  auto status = arrow_buffer->CopyToHost(position, size, data);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][copy-to-host]\")) {\n+    return g_bytes_new_take(data, size);\n+  } else {\n+    g_free(data);\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_from_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @data: (array length=size): Data on CPU host to be copied.\n+ * @size: The size of data on CPU host to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n+                                      const guint8 *data,\n+                                      gint64 size,\n+                                      GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto status = arrow_buffer->CopyFromHost(0, data, size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[gpu][cuda][buffer][copy-from-host]\");\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_export:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowGPUCUDAIPCMemoryHandle to handle the exported buffer on\n+ *   success, %NULL on error\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAIPCMemoryHandle *\n \n Review comment:\n   This isn't tested yet, we should try to set up some tests to make sure the IPC handle works\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T03:53:24.518+0000",
                    "updated": "2017-11-14T03:53:24.518+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16250791",
                    "id": "16250791",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313#discussion_r150731909\n \n \n\n ##########\n File path: c_glib/arrow-gpu-glib/cuda.cpp\n ##########\n @@ -0,0 +1,941 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#ifdef HAVE_CONFIG_H\n+#  include <config.h>\n+#endif\n+\n+#include <arrow-glib/buffer.hpp>\n+#include <arrow-glib/error.hpp>\n+#include <arrow-glib/input-stream.hpp>\n+#include <arrow-glib/output-stream.hpp>\n+#include <arrow-glib/readable.hpp>\n+#include <arrow-glib/record-batch.hpp>\n+#include <arrow-glib/schema.hpp>\n+\n+#include <arrow-gpu-glib/cuda.hpp>\n+\n+G_BEGIN_DECLS\n+\n+/**\n+ * SECTION: cuda\n+ * @section_id: cuda-classes\n+ * @title: CUDA related classes\n+ * @include: arrow-gpu-glib/arrow-gpu-glib.h\n+ *\n+ * The following classes provide CUDA support for Apache Arrow data.\n+ *\n+ * #GArrowGPUCUDADeviceManager is the starting point. You need at\n+ * least one #GArrowGPUCUDAContext to process Apache Arrow data on\n+ * NVIDIA GPU.\n+ *\n+ * #GArrowGPUCUDAContext is a class to keep context for one GPU. You\n+ * need to create #GArrowGPUCUDAContext for each GPU that you want to\n+ * use. You can create #GArrowGPUCUDAContext by\n+ * garrow_gpu_cuda_device_manager_get_context().\n+ *\n+ * #GArrowGPUCUDABuffer is a class for data on GPU. You can copy data\n+ * on GPU to/from CPU by garrow_gpu_cuda_buffer_copy_to_host() and\n+ * garrow_gpu_cuda_buffer_copy_from_host(). You can share data on GPU\n+ * with other processes by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDAHostBuffer is a class for data on CPU that is\n+ * directly accessible from GPU.\n+ *\n+ * #GArrowGPUCUDAIPCMemoryHandle is a class to share data on GPU with\n+ * other processes. You can export your data on GPU to other processes\n+ * by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_ipc_memory_handle_new(). You can import other\n+ * process data on GPU by garrow_gpu_cuda_ipc_memory_handle_new() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDABufferInputStream is a class to read data in\n+ * #GArrowGPUCUDABuffer.\n+ *\n+ * #GArrowGPUCUDABufferOutputStream is a class to write data into\n+ * #GArrowGPUCUDABuffer.\n+ */\n+\n+G_DEFINE_TYPE(GArrowGPUCUDADeviceManager,\n+              garrow_gpu_cuda_device_manager,\n+              G_TYPE_OBJECT)\n+\n+static void\n+garrow_gpu_cuda_device_manager_init(GArrowGPUCUDADeviceManager *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_device_manager_class_init(GArrowGPUCUDADeviceManagerClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_new:\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDADeviceManager on success,\n+ *   %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDADeviceManager *\n+garrow_gpu_cuda_device_manager_new(GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][device-manager][new]\")) {\n+    auto manager = g_object_new(GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER,\n+                                NULL);\n+    return GARROW_GPU_CUDA_DEVICE_MANAGER(manager);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_context:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ * @gpu_number: A GPU device number for the target context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext on\n+ *   success, %NULL on error. Contexts for the same GPU device number\n+ *   share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n+                                           gint gpu_number,\n+                                           GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+  auto status = arrow_manager->GetContext(gpu_number, &context);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][device-manager][get-context]]\")) {\n+    return garrow_gpu_cuda_context_new_raw(&context);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_n_devices:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ *\n+ * Returns: The number of GPU devices.\n+ *\n+ * Since: 0.8.0\n+ */\n+gsize\n+garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  return arrow_manager->num_devices();\n+}\n+\n+\n+typedef struct GArrowGPUCUDAContextPrivate_ {\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+} GArrowGPUCUDAContextPrivate;\n+\n+enum {\n+  PROP_CONTEXT = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAContext,\n+                           garrow_gpu_cuda_context,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object)     \\\n+  static_cast<GArrowGPUCUDAContextPrivate *>(           \\\n+    garrow_gpu_cuda_context_get_instance_private(       \\\n+      GARROW_GPU_CUDA_CONTEXT(object)))\n+\n+static void\n+garrow_gpu_cuda_context_finalize(GObject *object)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  priv->context = nullptr;\n+\n+  G_OBJECT_CLASS(garrow_gpu_cuda_context_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_gpu_cuda_context_set_property(GObject *object,\n+                                     guint prop_id,\n+                                     const GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_CONTEXT:\n+    priv->context =\n+      *static_cast<std::shared_ptr<arrow::gpu::CudaContext> *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_get_property(GObject *object,\n+                                     guint prop_id,\n+                                     GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_init(GArrowGPUCUDAContext *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_context_class_init(GArrowGPUCUDAContextClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_gpu_cuda_context_finalize;\n+  gobject_class->set_property = garrow_gpu_cuda_context_set_property;\n+  gobject_class->get_property = garrow_gpu_cuda_context_get_property;\n+\n+  /**\n+   * GArrowGPUCUDAContext:context:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"context\",\n+                              \"Context\",\n+                              \"The raw std::shared_ptr<arrow::gpu::CudaContext> *\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_CONTEXT, spec);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_context_get_allocated_size:\n+ * @context: A #GArrowGPUCUDAContext.\n+ *\n+ * Returns: The allocated memory by this context in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  return arrow_context->bytes_allocated();\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDABuffer,\n+              garrow_gpu_cuda_buffer,\n+              GARROW_TYPE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_buffer_init(GArrowGPUCUDABuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_class_init(GArrowGPUCUDABufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @size: The number of bytes to be allocated on GPU device for this context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n+                           gint64 size,\n+                           GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->Allocate(size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][new]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_ipc:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @handle: A #GArrowGPUCUDAIPCMemoryHandle to be communicated.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has data from the IPC target.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n+                               GArrowGPUCUDAIPCMemoryHandle *handle,\n+                               GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->OpenIpcBuffer(*arrow_handle, &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-ipc]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_record_batch:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @record_batch: A #GArrowRecordBatch to be serialized.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has serialized record batch\n+ *   data.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n+                                        GArrowRecordBatch *record_batch,\n+                                        GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_record_batch = garrow_record_batch_get_raw(record_batch);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow::gpu::SerializeRecordBatch(*arrow_record_batch,\n+                                                 arrow_context.get(),\n+                                                 &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-record-batch]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_to_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @position: The offset of memory on GPU device to be copied.\n+ * @size: The size of memory on GPU device to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A #GBytes that have copied memory on CPU\n+ *   host on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GBytes *\n+garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n+                                    gint64 position,\n+                                    gint64 size,\n+                                    GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto data = static_cast<uint8_t *>(g_malloc(size));\n+  auto status = arrow_buffer->CopyToHost(position, size, data);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][copy-to-host]\")) {\n+    return g_bytes_new_take(data, size);\n+  } else {\n+    g_free(data);\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_from_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @data: (array length=size): Data on CPU host to be copied.\n+ * @size: The size of data on CPU host to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n+                                      const guint8 *data,\n+                                      gint64 size,\n+                                      GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto status = arrow_buffer->CopyFromHost(0, data, size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[gpu][cuda][buffer][copy-from-host]\");\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_export:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowGPUCUDAIPCMemoryHandle to handle the exported buffer on\n+ *   success, %NULL on error\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_buffer_export(GArrowGPUCUDABuffer *buffer, GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  std::unique_ptr<arrow::gpu::CudaIpcMemHandle> arrow_handle;\n+  auto status = arrow_buffer->ExportForIpc(&arrow_handle);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][export-for-ipc]\")) {\n+    return garrow_gpu_cuda_ipc_memory_handle_new_raw(arrow_handle.release());\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_get_context:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext for the\n+ *   buffer. Contexts for the same buffer share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_buffer_get_context(GArrowGPUCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_context = arrow_buffer->context();\n+  return garrow_gpu_cuda_context_new_raw(&arrow_context);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_read_record_batch:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @schema: A #GArrowSchema for record batch.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowRecordBatch on\n+ *   success, %NULL on error. The record batch data is located on GPU.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowRecordBatch *\n+garrow_gpu_cuda_buffer_read_record_batch(GArrowGPUCUDABuffer *buffer,\n+                                         GArrowSchema *schema,\n+                                         GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_schema = garrow_schema_get_raw(schema);\n+  auto pool = arrow::default_memory_pool();\n+  std::shared_ptr<arrow::RecordBatch> arrow_record_batch;\n+  auto status = arrow::gpu::ReadRecordBatch(arrow_schema,\n+                                            arrow_buffer,\n+                                            pool,\n+                                            &arrow_record_batch);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][read-record-batch]\")) {\n+    return garrow_record_batch_new_raw(&arrow_record_batch);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDAHostBuffer,\n+              garrow_gpu_cuda_host_buffer,\n+              GARROW_TYPE_MUTABLE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_host_buffer_init(GArrowGPUCUDAHostBuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_host_buffer_class_init(GArrowGPUCUDAHostBufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_host_buffer_new:\n+ * @size: The number of bytes to be allocated on CPU host.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDAHostBuffer on success,\n+ *   %NULL on error. The allocated memory is accessible from GPU\n+ *   device for the @context.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAHostBuffer *\n+garrow_gpu_cuda_host_buffer_new(gint64 size, GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  std::shared_ptr<arrow::gpu::CudaHostBuffer> arrow_buffer;\n+  status = manager->AllocateHost(size, &arrow_buffer);\n \n Review comment:\n   We can leave this aspect as TBD. Merging this PR in the meantime\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T03:53:45.396+0000",
                    "updated": "2017-11-14T03:53:45.396+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16250793",
                    "id": "16250793",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm closed pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/c_glib/.gitignore b/c_glib/.gitignore\nindex 03bb0fe61..271914740 100644\n--- a/c_glib/.gitignore\n+++ b/c_glib/.gitignore\n@@ -41,6 +41,7 @@ Makefile.in\n /arrow-glib/enums.h\n /arrow-glib/stamp-*\n /arrow-glib/*.pc\n+/arrow-gpu-glib/*.pc\n /example/build\n /example/read-batch\n /example/read-stream\ndiff --git a/c_glib/Makefile.am b/c_glib/Makefile.am\nindex 577b749fb..4cc70e5a0 100644\n--- a/c_glib/Makefile.am\n+++ b/c_glib/Makefile.am\n@@ -19,6 +19,7 @@ ACLOCAL_AMFLAGS = -I m4 ${ACLOCAL_FLAGS}\n \n SUBDIRS =\t\t\t\t\t\\\n \tarrow-glib\t\t\t\t\\\n+\tarrow-gpu-glib\t\t\t\t\\\n \tdoc\t\t\t\t\t\\\n \texample\t\t\t\t\t\\\n \ttool\ndiff --git a/c_glib/arrow-glib/Makefile.am b/c_glib/arrow-glib/Makefile.am\nindex bf68ec491..5ecb1a661 100644\n--- a/c_glib/arrow-glib/Makefile.am\n+++ b/c_glib/arrow-glib/Makefile.am\n@@ -203,20 +203,18 @@ pkgconfigdir = $(libdir)/pkgconfig\n pkgconfig_DATA =\t\t\t\t\\\n \tarrow-glib.pc\n \n-# GObject Introspection\n+if HAVE_INTROSPECTION\n -include $(INTROSPECTION_MAKEFILE)\n INTROSPECTION_GIRS =\n INTROSPECTION_SCANNER_ARGS =\n INTROSPECTION_COMPILER_ARGS =\n \n-if HAVE_INTROSPECTION\n Arrow-1.0.gir: libarrow-glib.la\n Arrow_1_0_gir_PACKAGES =\t\t\t\\\n-\tgobject-2.0\t\t\t\t\\\n \tgio-2.0\n-Arrow_1_0_gir_EXPORT_PACKAGES = arrow\n+Arrow_1_0_gir_EXPORT_PACKAGES =\t\t\t\\\n+\tarrow-glib\n Arrow_1_0_gir_INCLUDES =\t\t\t\\\n-\tGObject-2.0\t\t\t\t\\\n \tGio-2.0\n Arrow_1_0_gir_CFLAGS =\t\t\t\t\\\n \t$(AM_CPPFLAGS)\ndiff --git a/c_glib/arrow-glib/buffer.h b/c_glib/arrow-glib/buffer.h\nindex b3f3a2cdc..300bb4f4e 100644\n--- a/c_glib/arrow-glib/buffer.h\n+++ b/c_glib/arrow-glib/buffer.h\n@@ -19,44 +19,21 @@\n \n #pragma once\n \n-#include <glib-object.h>\n+#include <arrow-glib/gobject-type.h>\n \n G_BEGIN_DECLS\n \n-#define GARROW_TYPE_BUFFER \\\n-  (garrow_buffer_get_type())\n-#define GARROW_BUFFER(obj) \\\n-  (G_TYPE_CHECK_INSTANCE_CAST((obj), GARROW_TYPE_BUFFER, GArrowBuffer))\n-#define GARROW_BUFFER_CLASS(klass) \\\n-  (G_TYPE_CHECK_CLASS_CAST((klass), GARROW_TYPE_BUFFER, GArrowBufferClass))\n-#define GARROW_IS_BUFFER(obj) \\\n-  (G_TYPE_CHECK_INSTANCE_TYPE((obj), GARROW_TYPE_BUFFER))\n-#define GARROW_IS_BUFFER_CLASS(klass) \\\n-  (G_TYPE_CHECK_CLASS_TYPE((klass), GARROW_TYPE_BUFFER))\n-#define GARROW_BUFFER_GET_CLASS(obj) \\\n-  (G_TYPE_INSTANCE_GET_CLASS((obj), GARROW_TYPE_BUFFER, GArrowBufferClass))\n-\n-typedef struct _GArrowBuffer         GArrowBuffer;\n-typedef struct _GArrowBufferClass    GArrowBufferClass;\n-\n-/**\n- * GArrowBuffer:\n- *\n- * It wraps `arrow::Buffer`.\n- */\n-struct _GArrowBuffer\n-{\n-  /*< private >*/\n-  GObject parent_instance;\n-};\n-\n+#define GARROW_TYPE_BUFFER (garrow_buffer_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowBuffer,\n+                         garrow_buffer,\n+                         GARROW,\n+                         BUFFER,\n+                         GObject)\n struct _GArrowBufferClass\n {\n   GObjectClass parent_class;\n };\n \n-GType          garrow_buffer_get_type     (void) G_GNUC_CONST;\n-\n GArrowBuffer  *garrow_buffer_new          (const guint8 *data,\n                                            gint64 size);\n gboolean       garrow_buffer_equal        (GArrowBuffer *buffer,\n@@ -80,49 +57,16 @@ GArrowBuffer  *garrow_buffer_slice        (GArrowBuffer *buffer,\n                                            gint64 size);\n \n \n-#define GARROW_TYPE_MUTABLE_BUFFER              \\\n-  (garrow_mutable_buffer_get_type())\n-#define GARROW_MUTABLE_BUFFER(obj)                              \\\n-  (G_TYPE_CHECK_INSTANCE_CAST((obj),                            \\\n-                              GARROW_TYPE_MUTABLE_BUFFER,       \\\n-                              GArrowMutableBuffer))\n-#define GARROW_MUTABLE_BUFFER_CLASS(klass)              \\\n-  (G_TYPE_CHECK_CLASS_CAST((klass),                     \\\n-                           GARROW_TYPE_MUTABLE_BUFFER,  \\\n-                           GArrowMutableBufferClass))\n-#define GARROW_IS_MUTABLE_BUFFER(obj)                                   \\\n-  (G_TYPE_CHECK_INSTANCE_TYPE((obj), GARROW_TYPE_MUTABLE_BUFFER))\n-#define GARROW_IS_MUTABLE_BUFFER_CLASS(klass)                           \\\n-  (G_TYPE_CHECK_CLASS_TYPE((klass), GARROW_TYPE_MUTABLE_BUFFER))\n-#define GARROW_MUTABLE_BUFFER_GET_CLASS(obj)                    \\\n-  (G_TYPE_INSTANCE_GET_CLASS((obj),                             \\\n-                             GARROW_TYPE_MUTABLE_BUFFER,        \\\n-                             GArrowMutableBufferClass))\n-\n-typedef struct _GArrowMutableBuffer         GArrowMutableBuffer;\n-#ifndef __GTK_DOC_IGNORE__\n-typedef struct _GArrowMutableBufferClass    GArrowMutableBufferClass;\n-#endif\n-\n-/**\n- * GArrowMutableBuffer:\n- *\n- * It wraps `arrow::MutableBuffer`.\n- */\n-struct _GArrowMutableBuffer\n-{\n-  /*< private >*/\n-  GArrowBuffer parent_instance;\n-};\n-\n-#ifndef __GTK_DOC_IGNORE__\n+#define GARROW_TYPE_MUTABLE_BUFFER (garrow_mutable_buffer_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowMutableBuffer,\n+                         garrow_mutable_buffer,\n+                         GARROW,\n+                         MUTABLE_BUFFER,\n+                         GArrowBuffer)\n struct _GArrowMutableBufferClass\n {\n   GArrowBufferClass parent_class;\n };\n-#endif\n-\n-GType garrow_mutable_buffer_get_type(void) G_GNUC_CONST;\n \n GArrowMutableBuffer *garrow_mutable_buffer_new  (guint8 *data,\n                                                  gint64 size);\ndiff --git a/c_glib/arrow-glib/input-stream.h b/c_glib/arrow-glib/input-stream.h\nindex 12c7ae700..c2068d6ac 100644\n--- a/c_glib/arrow-glib/input-stream.h\n+++ b/c_glib/arrow-glib/input-stream.h\n@@ -26,98 +26,28 @@\n \n G_BEGIN_DECLS\n \n-#define GARROW_TYPE_INPUT_STREAM                \\\n-  (garrow_input_stream_get_type())\n-#define GARROW_INPUT_STREAM(obj)                        \\\n-  (G_TYPE_CHECK_INSTANCE_CAST((obj),                    \\\n-                              GARROW_TYPE_INPUT_STREAM, \\\n-                              GArrowInputStream))\n-#define GARROW_INPUT_STREAM_CLASS(klass)                \\\n-  (G_TYPE_CHECK_CLASS_CAST((klass),                     \\\n-                           GARROW_TYPE_INPUT_STREAM,    \\\n-                           GArrowInputStreamClass))\n-#define GARROW_IS_INPUT_STREAM(obj)                             \\\n-  (G_TYPE_CHECK_INSTANCE_TYPE((obj),                            \\\n-                              GARROW_TYPE_INPUT_STREAM))\n-#define GARROW_IS_INPUT_STREAM_CLASS(klass)             \\\n-  (G_TYPE_CHECK_CLASS_TYPE((klass),                     \\\n-                           GARROW_TYPE_INPUT_STREAM))\n-#define GARROW_INPUT_STREAM_GET_CLASS(obj)              \\\n-  (G_TYPE_INSTANCE_GET_CLASS((obj),                     \\\n-                             GARROW_TYPE_INPUT_STREAM,  \\\n-                             GArrowInputStreamClass))\n-\n-typedef struct _GArrowInputStream         GArrowInputStream;\n-#ifndef __GTK_DOC_IGNORE__\n-typedef struct _GArrowInputStreamClass    GArrowInputStreamClass;\n-#endif\n-\n-/**\n- * GArrowInputStream:\n- *\n- * It wraps `arrow::io::InputStream`.\n- */\n-struct _GArrowInputStream\n-{\n-  /*< private >*/\n-  GObject parent_instance;\n-};\n-\n-#ifndef __GTK_DOC_IGNORE__\n+#define GARROW_TYPE_INPUT_STREAM (garrow_input_stream_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowInputStream,\n+                         garrow_input_stream,\n+                         GARROW,\n+                         INPUT_STREAM,\n+                         GObject)\n struct _GArrowInputStreamClass\n {\n   GObjectClass parent_class;\n };\n-#endif\n-\n-GType garrow_input_stream_get_type(void) G_GNUC_CONST;\n-\n \n #define GARROW_TYPE_SEEKABLE_INPUT_STREAM       \\\n   (garrow_seekable_input_stream_get_type())\n-#define GARROW_SEEKABLE_INPUT_STREAM(obj)                               \\\n-  (G_TYPE_CHECK_INSTANCE_CAST((obj),                                    \\\n-                              GARROW_TYPE_SEEKABLE_INPUT_STREAM,        \\\n-                              GArrowSeekableInputStream))\n-#define GARROW_SEEKABLE_INPUT_STREAM_CLASS(klass)               \\\n-  (G_TYPE_CHECK_CLASS_CAST((klass),                             \\\n-                           GARROW_TYPE_SEEKABLE_INPUT_STREAM,   \\\n-                           GArrowSeekableInputStreamClass))\n-#define GARROW_IS_SEEKABLE_INPUT_STREAM(obj)                            \\\n-  (G_TYPE_CHECK_INSTANCE_TYPE((obj),                                    \\\n-                              GARROW_TYPE_SEEKABLE_INPUT_STREAM))\n-#define GARROW_IS_SEEKABLE_INPUT_STREAM_CLASS(klass)            \\\n-  (G_TYPE_CHECK_CLASS_TYPE((klass),                             \\\n-                           GARROW_TYPE_SEEKABLE_INPUT_STREAM))\n-#define GARROW_SEEKABLE_INPUT_STREAM_GET_CLASS(obj)             \\\n-  (G_TYPE_INSTANCE_GET_CLASS((obj),                             \\\n-                             GARROW_TYPE_SEEKABLE_INPUT_STREAM, \\\n-                             GArrowSeekableInputStreamClass))\n-\n-typedef struct _GArrowSeekableInputStream         GArrowSeekableInputStream;\n-#ifndef __GTK_DOC_IGNORE__\n-typedef struct _GArrowSeekableInputStreamClass    GArrowSeekableInputStreamClass;\n-#endif\n-\n-/**\n- * GArrowSeekableInputStream:\n- *\n- * It wraps `arrow::io::RandomAccessFile`.\n- */\n-struct _GArrowSeekableInputStream\n-{\n-  /*< private >*/\n-  GArrowInputStream parent_instance;\n-};\n-\n-#ifndef __GTK_DOC_IGNORE__\n+G_DECLARE_DERIVABLE_TYPE(GArrowSeekableInputStream,\n+                         garrow_seekable_input_stream,\n+                         GARROW,\n+                         SEEKABLE_INPUT_STREAM,\n+                         GArrowInputStream)\n struct _GArrowSeekableInputStreamClass\n {\n   GArrowInputStreamClass parent_class;\n };\n-#endif\n-\n-GType garrow_seekable_input_stream_get_type(void) G_GNUC_CONST;\n \n guint64 garrow_seekable_input_stream_get_size(GArrowSeekableInputStream *input_stream,\n                                               GError **error);\n@@ -133,49 +63,15 @@ GArrowTensor *garrow_seekable_input_stream_read_tensor(GArrowSeekableInputStream\n \n #define GARROW_TYPE_BUFFER_INPUT_STREAM         \\\n   (garrow_buffer_input_stream_get_type())\n-#define GARROW_BUFFER_INPUT_STREAM(obj)                         \\\n-  (G_TYPE_CHECK_INSTANCE_CAST((obj),                            \\\n-                              GARROW_TYPE_BUFFER_INPUT_STREAM,  \\\n-                              GArrowBufferInputStream))\n-#define GARROW_BUFFER_INPUT_STREAM_CLASS(klass)                 \\\n-  (G_TYPE_CHECK_CLASS_CAST((klass),                             \\\n-                           GARROW_TYPE_BUFFER_INPUT_STREAM,     \\\n-                           GArrowBufferInputStreamClass))\n-#define GARROW_IS_BUFFER_INPUT_STREAM(obj)                      \\\n-  (G_TYPE_CHECK_INSTANCE_TYPE((obj),                            \\\n-                              GARROW_TYPE_BUFFER_INPUT_STREAM))\n-#define GARROW_IS_BUFFER_INPUT_STREAM_CLASS(klass)              \\\n-  (G_TYPE_CHECK_CLASS_TYPE((klass),                             \\\n-                           GARROW_TYPE_BUFFER_INPUT_STREAM))\n-#define GARROW_BUFFER_INPUT_STREAM_GET_CLASS(obj)               \\\n-  (G_TYPE_INSTANCE_GET_CLASS((obj),                             \\\n-                             GARROW_TYPE_BUFFER_INPUT_STREAM,   \\\n-                             GArrowBufferInputStreamClass))\n-\n-typedef struct _GArrowBufferInputStream         GArrowBufferInputStream;\n-#ifndef __GTK_DOC_IGNORE__\n-typedef struct _GArrowBufferInputStreamClass    GArrowBufferInputStreamClass;\n-#endif\n-\n-/**\n- * GArrowBufferInputStream:\n- *\n- * It wraps `arrow::io::BufferReader`.\n- */\n-struct _GArrowBufferInputStream\n-{\n-  /*< private >*/\n-  GArrowSeekableInputStream parent_instance;\n-};\n-\n-#ifndef __GTK_DOC_IGNORE__\n+G_DECLARE_DERIVABLE_TYPE(GArrowBufferInputStream,\n+                         garrow_buffer_input_stream,\n+                         GARROW,\n+                         BUFFER_INPUT_STREAM,\n+                         GArrowSeekableInputStream)\n struct _GArrowBufferInputStreamClass\n {\n   GArrowSeekableInputStreamClass parent_class;\n };\n-#endif\n-\n-GType garrow_buffer_input_stream_get_type(void) G_GNUC_CONST;\n \n GArrowBufferInputStream *garrow_buffer_input_stream_new(GArrowBuffer *buffer);\n \ndiff --git a/c_glib/arrow-glib/meson.build b/c_glib/arrow-glib/meson.build\nindex 464a002e7..aeec4172d 100644\n--- a/c_glib/arrow-glib/meson.build\n+++ b/c_glib/arrow-glib/meson.build\n@@ -179,22 +179,23 @@ pkgconfig.generate(filebase: meson.project_name(),\n                    name: 'Apache Arrow GLib',\n                    description: 'C API for Apache Arrow based on GLib',\n                    version: version,\n-                   requires: ['gobject-2.0', 'arrow'],\n+                   requires: ['gio-2.0', 'arrow'],\n                    libraries: [libarrow_glib],\n                    subdirs: ['arrow-glib'])\n \n-gnome.generate_gir(libarrow_glib,\n-                   sources: sources + c_headers + enums,\n-                   namespace: 'Arrow',\n-                   nsversion: api_version,\n-                   identifier_prefix: 'GArrow',\n-                   symbol_prefix: 'garrow',\n-                   export_packages: 'arrow-glib',\n-                   includes: [\n-                     'GObject-2.0',\n-                     'Gio-2.0',\n-                   ],\n-                   install: true,\n-                   extra_args: [\n-                     '--warn-all',\n-                   ])\n+arrow_glib_gir = gnome.generate_gir(libarrow_glib,\n+                                    sources: sources + c_headers + enums,\n+                                    namespace: 'Arrow',\n+                                    nsversion: api_version,\n+                                    identifier_prefix: 'GArrow',\n+                                    symbol_prefix: 'garrow',\n+                                    export_packages: 'arrow-glib',\n+                                    includes: [\n+                                      'GObject-2.0',\n+                                      'Gio-2.0',\n+                                    ],\n+                                    install: true,\n+                                    extra_args: [\n+                                      '--warn-all',\n+                                    ])\n+arrow_glib_gir_dependency = declare_dependency(sources: arrow_glib_gir)\ndiff --git a/c_glib/arrow-glib/output-stream.h b/c_glib/arrow-glib/output-stream.h\nindex e42ebcde4..195a97ac9 100644\n--- a/c_glib/arrow-glib/output-stream.h\n+++ b/c_glib/arrow-glib/output-stream.h\n@@ -26,51 +26,16 @@\n \n G_BEGIN_DECLS\n \n-#define GARROW_TYPE_OUTPUT_STREAM               \\\n-  (garrow_output_stream_get_type())\n-#define GARROW_OUTPUT_STREAM(obj)                               \\\n-  (G_TYPE_CHECK_INSTANCE_CAST((obj),                            \\\n-                              GARROW_TYPE_OUTPUT_STREAM,        \\\n-                              GArrowOutputStream))\n-#define GARROW_OUTPUT_STREAM_CLASS(klass)               \\\n-  (G_TYPE_CHECK_CLASS_CAST((klass),                     \\\n-                           GARROW_TYPE_OUTPUT_STREAM,   \\\n-                           GArrowOutputStreamClass))\n-#define GARROW_IS_OUTPUT_STREAM(obj)                            \\\n-  (G_TYPE_CHECK_INSTANCE_TYPE((obj),                            \\\n-                              GARROW_TYPE_OUTPUT_STREAM))\n-#define GARROW_IS_OUTPUT_STREAM_CLASS(klass)            \\\n-  (G_TYPE_CHECK_CLASS_TYPE((klass),                     \\\n-                           GARROW_TYPE_OUTPUT_STREAM))\n-#define GARROW_OUTPUT_STREAM_GET_CLASS(obj)             \\\n-  (G_TYPE_INSTANCE_GET_CLASS((obj),                     \\\n-                             GARROW_TYPE_OUTPUT_STREAM, \\\n-                             GArrowOutputStreamClass))\n-\n-typedef struct _GArrowOutputStream          GArrowOutputStream;\n-#ifndef __GTK_DOC_IGNORE__\n-typedef struct _GArrowOutputStreamClass     GArrowOutputStreamClass;\n-#endif\n-\n-/**\n- * GArrowOutputStream:\n- *\n- * It wraps `arrow::io::OutputStream`.\n- */\n-struct _GArrowOutputStream\n-{\n-  /*< private >*/\n-  GObject parent_instance;\n-};\n-\n-#ifndef __GTK_DOC_IGNORE__\n+#define GARROW_TYPE_OUTPUT_STREAM (garrow_output_stream_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowOutputStream,\n+                         garrow_output_stream,\n+                         GARROW,\n+                         OUTPUT_STREAM,\n+                         GObject)\n struct _GArrowOutputStreamClass\n {\n   GObjectClass parent_class;\n };\n-#endif\n-\n-GType garrow_output_stream_get_type(void) G_GNUC_CONST;\n \n gint64 garrow_output_stream_write_tensor(GArrowOutputStream *stream,\n                                          GArrowTensor *tensor,\ndiff --git a/c_glib/arrow-glib/readable.cpp b/c_glib/arrow-glib/readable.cpp\nindex 6a9023e6c..33f98d98c 100644\n--- a/c_glib/arrow-glib/readable.cpp\n+++ b/c_glib/arrow-glib/readable.cpp\n@@ -45,6 +45,7 @@ G_DEFINE_INTERFACE(GArrowReadable,\n static void\n garrow_readable_default_init (GArrowReadableInterface *iface)\n {\n+  iface->new_raw = garrow_buffer_new_raw;\n }\n \n /**\n@@ -66,7 +67,8 @@ garrow_readable_read(GArrowReadable *readable,\n   std::shared_ptr<arrow::Buffer> arrow_buffer;\n   auto status = arrow_readable->Read(n_bytes, &arrow_buffer);\n   if (garrow_error_check(error, status, \"[io][readable][read]\")) {\n-    return garrow_buffer_new_raw(&arrow_buffer);\n+    auto *iface = GARROW_READABLE_GET_IFACE(readable);\n+    return iface->new_raw(&arrow_buffer);\n   } else {\n     return NULL;\n   }\ndiff --git a/c_glib/arrow-glib/readable.hpp b/c_glib/arrow-glib/readable.hpp\nindex c241c77aa..ce7770103 100644\n--- a/c_glib/arrow-glib/readable.hpp\n+++ b/c_glib/arrow-glib/readable.hpp\n@@ -32,6 +32,7 @@ struct _GArrowReadableInterface\n {\n   GTypeInterface parent_iface;\n \n+  GArrowBuffer *(*new_raw)(std::shared_ptr<arrow::Buffer> *arrow_buffer);\n   std::shared_ptr<arrow::io::Readable> (*get_raw)(GArrowReadable *file);\n };\n \ndiff --git a/c_glib/arrow-gpu-glib/Makefile.am b/c_glib/arrow-gpu-glib/Makefile.am\nnew file mode 100644\nindex 000000000..ec9615987\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/Makefile.am\n@@ -0,0 +1,109 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+CLEANFILES =\n+\n+EXTRA_DIST =\t\t\t\t\t\\\n+\tmeson.build\n+\n+AM_CPPFLAGS =\t\t\t\t\t\\\n+\t-I$(top_builddir)\t\t\t\\\n+\t-I$(top_srcdir)\n+\n+if HAVE_ARROW_GPU\n+lib_LTLIBRARIES =\t\t\t\t\\\n+\tlibarrow-gpu-glib.la\n+\n+libarrow_gpu_glib_la_CXXFLAGS =\t\t\t\\\n+\t$(GLIB_CFLAGS)\t\t\t\t\\\n+\t$(ARROW_CFLAGS)\t\t\t\t\\\n+\t$(ARROW_GPU_CFLAGS)\t\t\t\\\n+\t$(GARROW_CXXFLAGS)\n+\n+libarrow_gpu_glib_la_LIBADD =\t\t\t\\\n+\t$(GLIB_LIBS)\t\t\t\t\\\n+\t$(ARROW_LIBS)\t\t\t\t\\\n+\t$(ARROW_GPU_LIBS)\t\t\t\\\n+\t../arrow-glib/libarrow-glib.la\n+\n+libarrow_gpu_glib_la_headers =\t\t\t\\\n+\tarrow-gpu-glib.h\t\t\t\\\n+\tcuda.h\n+\n+libarrow_gpu_glib_la_sources =\t\t\t\\\n+\tcuda.cpp\t\t\t\t\\\n+\t$(libarrow_gpu_glib_la_headers)\n+\n+libarrow_gpu_glib_la_cpp_headers =\t\t\\\n+\tarrow-gpu-glib.hpp\t\t\t\\\n+\tcuda.hpp\n+\n+libarrow_gpu_glib_la_SOURCES =\t\t\t\\\n+\t$(libarrow_gpu_glib_la_sources)\t\t\\\n+\t$(libarrow_gpu_glib_la_cpp_headers)\n+\n+arrow_gpu_glib_includedir =\t\t\t\\\n+\t$(includedir)/arrow-gpu-glib\n+arrow_gpu_glib_include_HEADERS =\t\t\\\n+\t$(libarrow_gpu_glib_la_headers)\t\t\\\n+\t$(libarrow_gpu_glib_la_cpp_headers)\n+\n+pkgconfigdir = $(libdir)/pkgconfig\n+pkgconfig_DATA =\t\t\t\t\\\n+\tarrow-gpu-glib.pc\n+\n+if HAVE_INTROSPECTION\n+-include $(INTROSPECTION_MAKEFILE)\n+INTROSPECTION_GIRS =\n+INTROSPECTION_SCANNER_ARGS =\n+INTROSPECTION_SCANNER_ENV =\t\t\t\\\n+\tPKG_CONFIG_PATH=${abs_builddir}/../arrow-glib:$${PKG_CONFIG_PATH}\n+INTROSPECTION_COMPILER_ARGS =\t\t\t\\\n+\t--includedir=$(abs_builddir)/../arrow-glib\n+\n+ArrowGPU-1.0.gir: libarrow-gpu-glib.la\n+ArrowGPU_1_0_gir_PACKAGES =\t\t\t\\\n+\tarrow-glib\n+ArrowGPU_1_0_gir_EXPORT_PACKAGES =\t\t\\\n+\tarrow-gpu-glib\n+ArrowGPU_1_0_gir_INCLUDES =\t\t\t\\\n+\tArrow-1.0\n+ArrowGPU_1_0_gir_CFLAGS =\t\t\t\\\n+\t$(AM_CPPFLAGS)\n+ArrowGPU_1_0_gir_LIBS =\t\t\t\t\t\\\n+\t$(abs_builddir)/../arrow-glib/libarrow-glib.la\t\\\n+\tlibarrow-gpu-glib.la\n+ArrowGPU_1_0_gir_FILES =\t\t\t\\\n+\t$(libarrow_gpu_glib_la_sources)\n+ArrowGPU_1_0_gir_SCANNERFLAGS =\t\t\t\t\t\\\n+\t--warn-all\t\t\t\t\t\t\\\n+\t--add-include-path=$(abs_builddir)/../arrow-glib\t\\\n+\t--identifier-prefix=GArrowGPU\t\t\t\t\\\n+\t--symbol-prefix=garrow_gpu\n+INTROSPECTION_GIRS += ArrowGPU-1.0.gir\n+\n+girdir = $(datadir)/gir-1.0\n+gir_DATA = $(INTROSPECTION_GIRS)\n+\n+typelibdir = $(libdir)/girepository-1.0\n+typelib_DATA = $(INTROSPECTION_GIRS:.gir=.typelib)\n+\n+CLEANFILES +=\t\t\t\t\t\\\n+\t$(gir_DATA)\t\t\t\t\\\n+\t$(typelib_DATA)\n+endif\n+endif\ndiff --git a/c_glib/arrow-gpu-glib/arrow-gpu-glib.h b/c_glib/arrow-gpu-glib/arrow-gpu-glib.h\nnew file mode 100644\nindex 000000000..1538c9a18\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/arrow-gpu-glib.h\n@@ -0,0 +1,24 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#pragma once\n+\n+#include <arrow-glib/arrow-glib.h>\n+\n+#include <arrow-gpu-glib/cuda.h>\ndiff --git a/c_glib/arrow-gpu-glib/arrow-gpu-glib.hpp b/c_glib/arrow-gpu-glib/arrow-gpu-glib.hpp\nnew file mode 100644\nindex 000000000..92017d8b6\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/arrow-gpu-glib.hpp\n@@ -0,0 +1,24 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#pragma once\n+\n+#include <arrow-glib/arrow-glib.hpp>\n+\n+#include <arrow-gpu-glib/cuda.hpp>\ndiff --git a/c_glib/arrow-gpu-glib/arrow-gpu-glib.pc.in b/c_glib/arrow-gpu-glib/arrow-gpu-glib.pc.in\nnew file mode 100644\nindex 000000000..38a6bae1a\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/arrow-gpu-glib.pc.in\n@@ -0,0 +1,28 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+prefix=@prefix@\n+exec_prefix=@exec_prefix@\n+libdir=@libdir@\n+includedir=@includedir@\n+\n+Name: Apache Arrow GPU GLib\n+Description: C API for Apache Arrow GPU based on GLib\n+Version: @VERSION@\n+Libs: -L${libdir} -larrow-gpu-glib\n+Cflags: -I${includedir}\n+Requires: arrow-glib\ndiff --git a/c_glib/arrow-gpu-glib/cuda.cpp b/c_glib/arrow-gpu-glib/cuda.cpp\nnew file mode 100644\nindex 000000000..c2a9af54d\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/cuda.cpp\n@@ -0,0 +1,941 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#ifdef HAVE_CONFIG_H\n+#  include <config.h>\n+#endif\n+\n+#include <arrow-glib/buffer.hpp>\n+#include <arrow-glib/error.hpp>\n+#include <arrow-glib/input-stream.hpp>\n+#include <arrow-glib/output-stream.hpp>\n+#include <arrow-glib/readable.hpp>\n+#include <arrow-glib/record-batch.hpp>\n+#include <arrow-glib/schema.hpp>\n+\n+#include <arrow-gpu-glib/cuda.hpp>\n+\n+G_BEGIN_DECLS\n+\n+/**\n+ * SECTION: cuda\n+ * @section_id: cuda-classes\n+ * @title: CUDA related classes\n+ * @include: arrow-gpu-glib/arrow-gpu-glib.h\n+ *\n+ * The following classes provide CUDA support for Apache Arrow data.\n+ *\n+ * #GArrowGPUCUDADeviceManager is the starting point. You need at\n+ * least one #GArrowGPUCUDAContext to process Apache Arrow data on\n+ * NVIDIA GPU.\n+ *\n+ * #GArrowGPUCUDAContext is a class to keep context for one GPU. You\n+ * need to create #GArrowGPUCUDAContext for each GPU that you want to\n+ * use. You can create #GArrowGPUCUDAContext by\n+ * garrow_gpu_cuda_device_manager_get_context().\n+ *\n+ * #GArrowGPUCUDABuffer is a class for data on GPU. You can copy data\n+ * on GPU to/from CPU by garrow_gpu_cuda_buffer_copy_to_host() and\n+ * garrow_gpu_cuda_buffer_copy_from_host(). You can share data on GPU\n+ * with other processes by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDAHostBuffer is a class for data on CPU that is\n+ * directly accessible from GPU.\n+ *\n+ * #GArrowGPUCUDAIPCMemoryHandle is a class to share data on GPU with\n+ * other processes. You can export your data on GPU to other processes\n+ * by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_ipc_memory_handle_new(). You can import other\n+ * process data on GPU by garrow_gpu_cuda_ipc_memory_handle_new() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDABufferInputStream is a class to read data in\n+ * #GArrowGPUCUDABuffer.\n+ *\n+ * #GArrowGPUCUDABufferOutputStream is a class to write data into\n+ * #GArrowGPUCUDABuffer.\n+ */\n+\n+G_DEFINE_TYPE(GArrowGPUCUDADeviceManager,\n+              garrow_gpu_cuda_device_manager,\n+              G_TYPE_OBJECT)\n+\n+static void\n+garrow_gpu_cuda_device_manager_init(GArrowGPUCUDADeviceManager *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_device_manager_class_init(GArrowGPUCUDADeviceManagerClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_new:\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDADeviceManager on success,\n+ *   %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDADeviceManager *\n+garrow_gpu_cuda_device_manager_new(GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][device-manager][new]\")) {\n+    auto manager = g_object_new(GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER,\n+                                NULL);\n+    return GARROW_GPU_CUDA_DEVICE_MANAGER(manager);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_context:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ * @gpu_number: A GPU device number for the target context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext on\n+ *   success, %NULL on error. Contexts for the same GPU device number\n+ *   share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n+                                           gint gpu_number,\n+                                           GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+  auto status = arrow_manager->GetContext(gpu_number, &context);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][device-manager][get-context]]\")) {\n+    return garrow_gpu_cuda_context_new_raw(&context);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_n_devices:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ *\n+ * Returns: The number of GPU devices.\n+ *\n+ * Since: 0.8.0\n+ */\n+gsize\n+garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  return arrow_manager->num_devices();\n+}\n+\n+\n+typedef struct GArrowGPUCUDAContextPrivate_ {\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+} GArrowGPUCUDAContextPrivate;\n+\n+enum {\n+  PROP_CONTEXT = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAContext,\n+                           garrow_gpu_cuda_context,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object)     \\\n+  static_cast<GArrowGPUCUDAContextPrivate *>(           \\\n+    garrow_gpu_cuda_context_get_instance_private(       \\\n+      GARROW_GPU_CUDA_CONTEXT(object)))\n+\n+static void\n+garrow_gpu_cuda_context_finalize(GObject *object)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  priv->context = nullptr;\n+\n+  G_OBJECT_CLASS(garrow_gpu_cuda_context_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_gpu_cuda_context_set_property(GObject *object,\n+                                     guint prop_id,\n+                                     const GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_CONTEXT:\n+    priv->context =\n+      *static_cast<std::shared_ptr<arrow::gpu::CudaContext> *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_get_property(GObject *object,\n+                                     guint prop_id,\n+                                     GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_init(GArrowGPUCUDAContext *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_context_class_init(GArrowGPUCUDAContextClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_gpu_cuda_context_finalize;\n+  gobject_class->set_property = garrow_gpu_cuda_context_set_property;\n+  gobject_class->get_property = garrow_gpu_cuda_context_get_property;\n+\n+  /**\n+   * GArrowGPUCUDAContext:context:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"context\",\n+                              \"Context\",\n+                              \"The raw std::shared_ptr<arrow::gpu::CudaContext> *\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_CONTEXT, spec);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_context_get_allocated_size:\n+ * @context: A #GArrowGPUCUDAContext.\n+ *\n+ * Returns: The allocated memory by this context in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  return arrow_context->bytes_allocated();\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDABuffer,\n+              garrow_gpu_cuda_buffer,\n+              GARROW_TYPE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_buffer_init(GArrowGPUCUDABuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_class_init(GArrowGPUCUDABufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @size: The number of bytes to be allocated on GPU device for this context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n+                           gint64 size,\n+                           GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->Allocate(size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][new]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_ipc:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @handle: A #GArrowGPUCUDAIPCMemoryHandle to be communicated.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has data from the IPC target.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n+                               GArrowGPUCUDAIPCMemoryHandle *handle,\n+                               GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->OpenIpcBuffer(*arrow_handle, &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-ipc]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_record_batch:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @record_batch: A #GArrowRecordBatch to be serialized.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has serialized record batch\n+ *   data.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n+                                        GArrowRecordBatch *record_batch,\n+                                        GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_record_batch = garrow_record_batch_get_raw(record_batch);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow::gpu::SerializeRecordBatch(*arrow_record_batch,\n+                                                 arrow_context.get(),\n+                                                 &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-record-batch]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_to_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @position: The offset of memory on GPU device to be copied.\n+ * @size: The size of memory on GPU device to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A #GBytes that have copied memory on CPU\n+ *   host on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GBytes *\n+garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n+                                    gint64 position,\n+                                    gint64 size,\n+                                    GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto data = static_cast<uint8_t *>(g_malloc(size));\n+  auto status = arrow_buffer->CopyToHost(position, size, data);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][copy-to-host]\")) {\n+    return g_bytes_new_take(data, size);\n+  } else {\n+    g_free(data);\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_from_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @data: (array length=size): Data on CPU host to be copied.\n+ * @size: The size of data on CPU host to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n+                                      const guint8 *data,\n+                                      gint64 size,\n+                                      GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto status = arrow_buffer->CopyFromHost(0, data, size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[gpu][cuda][buffer][copy-from-host]\");\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_export:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowGPUCUDAIPCMemoryHandle to handle the exported buffer on\n+ *   success, %NULL on error\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_buffer_export(GArrowGPUCUDABuffer *buffer, GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  std::unique_ptr<arrow::gpu::CudaIpcMemHandle> arrow_handle;\n+  auto status = arrow_buffer->ExportForIpc(&arrow_handle);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][export-for-ipc]\")) {\n+    return garrow_gpu_cuda_ipc_memory_handle_new_raw(arrow_handle.release());\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_get_context:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext for the\n+ *   buffer. Contexts for the same buffer share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_buffer_get_context(GArrowGPUCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_context = arrow_buffer->context();\n+  return garrow_gpu_cuda_context_new_raw(&arrow_context);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_read_record_batch:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @schema: A #GArrowSchema for record batch.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowRecordBatch on\n+ *   success, %NULL on error. The record batch data is located on GPU.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowRecordBatch *\n+garrow_gpu_cuda_buffer_read_record_batch(GArrowGPUCUDABuffer *buffer,\n+                                         GArrowSchema *schema,\n+                                         GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_schema = garrow_schema_get_raw(schema);\n+  auto pool = arrow::default_memory_pool();\n+  std::shared_ptr<arrow::RecordBatch> arrow_record_batch;\n+  auto status = arrow::gpu::ReadRecordBatch(arrow_schema,\n+                                            arrow_buffer,\n+                                            pool,\n+                                            &arrow_record_batch);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][read-record-batch]\")) {\n+    return garrow_record_batch_new_raw(&arrow_record_batch);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDAHostBuffer,\n+              garrow_gpu_cuda_host_buffer,\n+              GARROW_TYPE_MUTABLE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_host_buffer_init(GArrowGPUCUDAHostBuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_host_buffer_class_init(GArrowGPUCUDAHostBufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_host_buffer_new:\n+ * @size: The number of bytes to be allocated on CPU host.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDAHostBuffer on success,\n+ *   %NULL on error. The allocated memory is accessible from GPU\n+ *   device for the @context.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAHostBuffer *\n+garrow_gpu_cuda_host_buffer_new(gint64 size, GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  std::shared_ptr<arrow::gpu::CudaHostBuffer> arrow_buffer;\n+  status = manager->AllocateHost(size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][host-buffer][new]\")) {\n+    return garrow_gpu_cuda_host_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+\n+typedef struct GArrowGPUCUDAIPCMemoryHandlePrivate_ {\n+  arrow::gpu::CudaIpcMemHandle *ipc_memory_handle;\n+} GArrowGPUCUDAIPCMemoryHandlePrivate;\n+\n+enum {\n+  PROP_IPC_MEMORY_HANDLE = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAIPCMemoryHandle,\n+                           garrow_gpu_cuda_ipc_memory_handle,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object)   \\\n+  static_cast<GArrowGPUCUDAIPCMemoryHandlePrivate *>(           \\\n+    garrow_gpu_cuda_ipc_memory_handle_get_instance_private(     \\\n+      GARROW_GPU_CUDA_IPC_MEMORY_HANDLE(object)))\n+\n+static void\n+garrow_gpu_cuda_ipc_memory_handle_finalize(GObject *object)\n+{\n+  auto priv = GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object);\n+\n+  delete priv->ipc_memory_handle;\n+\n+  G_OBJECT_CLASS(garrow_gpu_cuda_ipc_memory_handle_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_gpu_cuda_ipc_memory_handle_set_property(GObject *object,\n+                                               guint prop_id,\n+                                               const GValue *value,\n+                                               GParamSpec *pspec)\n+{\n+  auto priv = GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_IPC_MEMORY_HANDLE:\n+    priv->ipc_memory_handle =\n+      static_cast<arrow::gpu::CudaIpcMemHandle *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_ipc_memory_handle_get_property(GObject *object,\n+                                               guint prop_id,\n+                                               GValue *value,\n+                                               GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_ipc_memory_handle_init(GArrowGPUCUDAIPCMemoryHandle *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_ipc_memory_handle_class_init(GArrowGPUCUDAIPCMemoryHandleClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_gpu_cuda_ipc_memory_handle_finalize;\n+  gobject_class->set_property = garrow_gpu_cuda_ipc_memory_handle_set_property;\n+  gobject_class->get_property = garrow_gpu_cuda_ipc_memory_handle_get_property;\n+\n+  /**\n+   * GArrowGPUCUDAIPCMemoryHandle:ipc-memory-handle:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"ipc-memory-handle\",\n+                              \"IPC Memory Handle\",\n+                              \"The raw arrow::gpu::CudaIpcMemHandle *\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_IPC_MEMORY_HANDLE, spec);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_ipc_memory_handle_new:\n+ * @data: (array length=size): A serialized #GArrowGPUCUDAIPCMemoryHandle.\n+ * @size: The size of data.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAIPCMemoryHandle\n+ *   on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_ipc_memory_handle_new(const guint8 *data,\n+                                      gsize size,\n+                                      GError **error)\n+{\n+  std::unique_ptr<arrow::gpu::CudaIpcMemHandle> arrow_handle;\n+  auto status = arrow::gpu::CudaIpcMemHandle::FromBuffer(data, &arrow_handle);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][ipc-memory-handle][new]\")) {\n+    return garrow_gpu_cuda_ipc_memory_handle_new_raw(arrow_handle.release());\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_ipc_memory_handle_serialize:\n+ * @handle: A #GArrowGPUCUDAIPCMemoryHandle.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowBuffer on success,\n+ *   %NULL on error. The buffer has serialized @handle. The serialized\n+ *   @handle can be deserialized by garrow_gpu_cuda_ipc_memory_handle_new()\n+ *   in other process.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowBuffer *\n+garrow_gpu_cuda_ipc_memory_handle_serialize(GArrowGPUCUDAIPCMemoryHandle *handle,\n+                                            GError **error)\n+{\n+  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::Buffer> arrow_buffer;\n+  auto status = arrow_handle->Serialize(arrow::default_memory_pool(),\n+                                        &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][ipc-memory-handle][serialize]\")) {\n+    return garrow_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+GArrowBuffer *\n+garrow_gpu_cuda_buffer_input_stream_new_raw_readable_interface(std::shared_ptr<arrow::Buffer> *arrow_buffer)\n+{\n+  auto buffer = GARROW_BUFFER(g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER,\n+                                           \"buffer\", arrow_buffer,\n+                                           NULL));\n+  return buffer;\n+}\n+\n+static std::shared_ptr<arrow::io::Readable>\n+garrow_gpu_cuda_buffer_input_stream_get_raw_readable_interface(GArrowReadable *readable)\n+{\n+  auto input_stream = GARROW_INPUT_STREAM(readable);\n+  auto arrow_input_stream = garrow_input_stream_get_raw(input_stream);\n+  return arrow_input_stream;\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_input_stream_readable_interface_init(GArrowReadableInterface *iface)\n+{\n+  iface->new_raw =\n+    garrow_gpu_cuda_buffer_input_stream_new_raw_readable_interface;\n+  iface->get_raw =\n+    garrow_gpu_cuda_buffer_input_stream_get_raw_readable_interface;\n+}\n+\n+G_DEFINE_TYPE_WITH_CODE(\n+  GArrowGPUCUDABufferInputStream,\n+  garrow_gpu_cuda_buffer_input_stream,\n+  GARROW_TYPE_BUFFER_INPUT_STREAM,\n+  G_IMPLEMENT_INTERFACE(\n+    GARROW_TYPE_READABLE,\n+    garrow_gpu_cuda_buffer_input_stream_readable_interface_init))\n+\n+static void\n+garrow_gpu_cuda_buffer_input_stream_init(GArrowGPUCUDABufferInputStream *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_input_stream_class_init(GArrowGPUCUDABufferInputStreamClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_input_stream_new:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowGPUCUDABufferInputStream.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABufferInputStream *\n+garrow_gpu_cuda_buffer_input_stream_new(GArrowGPUCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_reader =\n+    std::make_shared<arrow::gpu::CudaBufferReader>(arrow_buffer);\n+  return garrow_gpu_cuda_buffer_input_stream_new_raw(&arrow_reader);\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDABufferOutputStream,\n+              garrow_gpu_cuda_buffer_output_stream,\n+              GARROW_TYPE_OUTPUT_STREAM)\n+\n+static void\n+garrow_gpu_cuda_buffer_output_stream_init(GArrowGPUCUDABufferOutputStream *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_output_stream_class_init(GArrowGPUCUDABufferOutputStreamClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_output_stream_new:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowGPUCUDABufferOutputStream.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABufferOutputStream *\n+garrow_gpu_cuda_buffer_output_stream_new(GArrowGPUCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_writer =\n+    std::make_shared<arrow::gpu::CudaBufferWriter>(arrow_buffer);\n+  return garrow_gpu_cuda_buffer_output_stream_new_raw(&arrow_writer);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_output_stream_set_buffer_size:\n+ * @stream: A #GArrowGPUCUDABufferOutputStream.\n+ * @size: A size of CPU buffer in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Sets CPU buffer size. to limit `cudaMemcpy()` calls. If CPU buffer\n+ * size is `0`, buffering is disabled.\n+ *\n+ * The default is `0`.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_gpu_cuda_buffer_output_stream_set_buffer_size(GArrowGPUCUDABufferOutputStream *stream,\n+                                                     gint64 size,\n+                                                     GError **error)\n+{\n+  auto arrow_stream = garrow_gpu_cuda_buffer_output_stream_get_raw(stream);\n+  auto status = arrow_stream->SetBufferSize(size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[gpu][cuda][buffer-output-stream][set-buffer-size]\");\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_output_stream_get_buffer_size:\n+ * @stream: A #GArrowGPUCUDABufferOutputStream.\n+ *\n+ * Returns: The CPU buffer size in bytes.\n+ *\n+ * See garrow_gpu_cuda_buffer_output_stream_set_buffer_size() for CPU\n+ * buffer size details.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_gpu_cuda_buffer_output_stream_get_buffer_size(GArrowGPUCUDABufferOutputStream *stream)\n+{\n+  auto arrow_stream = garrow_gpu_cuda_buffer_output_stream_get_raw(stream);\n+  return arrow_stream->buffer_size();\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_output_stream_get_buffered_size:\n+ * @stream: A #GArrowGPUCUDABufferOutputStream.\n+ *\n+ * Returns: The size of buffered data in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_gpu_cuda_buffer_output_stream_get_buffered_size(GArrowGPUCUDABufferOutputStream *stream)\n+{\n+  auto arrow_stream = garrow_gpu_cuda_buffer_output_stream_get_raw(stream);\n+  return arrow_stream->num_bytes_buffered();\n+}\n+\n+\n+G_END_DECLS\n+\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_context_new_raw(std::shared_ptr<arrow::gpu::CudaContext> *arrow_context)\n+{\n+  return GARROW_GPU_CUDA_CONTEXT(g_object_new(GARROW_GPU_TYPE_CUDA_CONTEXT,\n+                                              \"context\", arrow_context,\n+                                              NULL));\n+}\n+\n+std::shared_ptr<arrow::gpu::CudaContext>\n+garrow_gpu_cuda_context_get_raw(GArrowGPUCUDAContext *context)\n+{\n+  if (!context)\n+    return nullptr;\n+\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(context);\n+  return priv->context;\n+}\n+\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_ipc_memory_handle_new_raw(arrow::gpu::CudaIpcMemHandle *arrow_handle)\n+{\n+  auto handle = g_object_new(GARROW_GPU_TYPE_CUDA_IPC_MEMORY_HANDLE,\n+                             \"ipc-memory-handle\", arrow_handle,\n+                             NULL);\n+  return GARROW_GPU_CUDA_IPC_MEMORY_HANDLE(handle);\n+}\n+\n+arrow::gpu::CudaIpcMemHandle *\n+garrow_gpu_cuda_ipc_memory_handle_get_raw(GArrowGPUCUDAIPCMemoryHandle *handle)\n+{\n+  if (!handle)\n+    return nullptr;\n+\n+  auto priv = GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(handle);\n+  return priv->ipc_memory_handle;\n+}\n+\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaBuffer> *arrow_buffer)\n+{\n+  return GARROW_GPU_CUDA_BUFFER(g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER,\n+                                             \"buffer\", arrow_buffer,\n+                                             NULL));\n+}\n+\n+std::shared_ptr<arrow::gpu::CudaBuffer>\n+garrow_gpu_cuda_buffer_get_raw(GArrowGPUCUDABuffer *buffer)\n+{\n+  if (!buffer)\n+    return nullptr;\n+\n+  auto arrow_buffer = garrow_buffer_get_raw(GARROW_BUFFER(buffer));\n+  return std::static_pointer_cast<arrow::gpu::CudaBuffer>(arrow_buffer);\n+}\n+\n+GArrowGPUCUDAHostBuffer *\n+garrow_gpu_cuda_host_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaHostBuffer> *arrow_buffer)\n+{\n+  auto buffer = g_object_new(GARROW_GPU_TYPE_CUDA_HOST_BUFFER,\n+                             \"buffer\", arrow_buffer,\n+                             NULL);\n+  return GARROW_GPU_CUDA_HOST_BUFFER(buffer);\n+}\n+\n+std::shared_ptr<arrow::gpu::CudaHostBuffer>\n+garrow_gpu_cuda_host_buffer_get_raw(GArrowGPUCUDAHostBuffer *buffer)\n+{\n+  if (!buffer)\n+    return nullptr;\n+\n+  auto arrow_buffer = garrow_buffer_get_raw(GARROW_BUFFER(buffer));\n+  return std::static_pointer_cast<arrow::gpu::CudaHostBuffer>(arrow_buffer);\n+}\n+\n+GArrowGPUCUDABufferInputStream *\n+garrow_gpu_cuda_buffer_input_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferReader> *arrow_reader)\n+{\n+  auto input_stream = g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER_INPUT_STREAM,\n+                                   \"input-stream\", arrow_reader,\n+                                   NULL);\n+  return GARROW_GPU_CUDA_BUFFER_INPUT_STREAM(input_stream);\n+}\n+\n+std::shared_ptr<arrow::gpu::CudaBufferReader>\n+garrow_gpu_cuda_buffer_input_stream_get_raw(GArrowGPUCUDABufferInputStream *input_stream)\n+{\n+  if (!input_stream)\n+    return nullptr;\n+\n+  auto arrow_reader =\n+    garrow_input_stream_get_raw(GARROW_INPUT_STREAM(input_stream));\n+  return std::static_pointer_cast<arrow::gpu::CudaBufferReader>(arrow_reader);\n+}\n+\n+GArrowGPUCUDABufferOutputStream *\n+garrow_gpu_cuda_buffer_output_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferWriter> *arrow_writer)\n+{\n+  auto output_stream = g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER_OUTPUT_STREAM,\n+                                    \"output-stream\", arrow_writer,\n+                                    NULL);\n+  return GARROW_GPU_CUDA_BUFFER_OUTPUT_STREAM(output_stream);\n+}\n+\n+std::shared_ptr<arrow::gpu::CudaBufferWriter>\n+garrow_gpu_cuda_buffer_output_stream_get_raw(GArrowGPUCUDABufferOutputStream *output_stream)\n+{\n+  if (!output_stream)\n+    return nullptr;\n+\n+  auto arrow_writer =\n+    garrow_output_stream_get_raw(GARROW_OUTPUT_STREAM(output_stream));\n+  return std::static_pointer_cast<arrow::gpu::CudaBufferWriter>(arrow_writer);\n+}\ndiff --git a/c_glib/arrow-gpu-glib/cuda.h b/c_glib/arrow-gpu-glib/cuda.h\nnew file mode 100644\nindex 000000000..7c615a144\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/cuda.h\n@@ -0,0 +1,181 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#pragma once\n+\n+#include <arrow-glib/arrow-glib.h>\n+\n+G_BEGIN_DECLS\n+\n+#define GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER     \\\n+  (garrow_gpu_cuda_device_manager_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDADeviceManager,\n+                         garrow_gpu_cuda_device_manager,\n+                         GARROW_GPU,\n+                         CUDA_DEVICE_MANAGER,\n+                         GObject)\n+struct _GArrowGPUCUDADeviceManagerClass\n+{\n+  GObjectClass parent_class;\n+};\n+\n+#define GARROW_GPU_TYPE_CUDA_CONTEXT (garrow_gpu_cuda_context_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDAContext,\n+                         garrow_gpu_cuda_context,\n+                         GARROW_GPU,\n+                         CUDA_CONTEXT,\n+                         GObject)\n+struct _GArrowGPUCUDAContextClass\n+{\n+  GObjectClass parent_class;\n+};\n+\n+#define GARROW_GPU_TYPE_CUDA_BUFFER (garrow_gpu_cuda_buffer_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDABuffer,\n+                         garrow_gpu_cuda_buffer,\n+                         GARROW_GPU,\n+                         CUDA_BUFFER,\n+                         GArrowBuffer)\n+struct _GArrowGPUCUDABufferClass\n+{\n+  GArrowBufferClass parent_class;\n+};\n+\n+#define GARROW_GPU_TYPE_CUDA_HOST_BUFFER (garrow_gpu_cuda_host_buffer_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDAHostBuffer,\n+                         garrow_gpu_cuda_host_buffer,\n+                         GARROW_GPU,\n+                         CUDA_HOST_BUFFER,\n+                         GArrowMutableBuffer)\n+struct _GArrowGPUCUDAHostBufferClass\n+{\n+  GArrowMutableBufferClass parent_class;\n+};\n+\n+#define GARROW_GPU_TYPE_CUDA_IPC_MEMORY_HANDLE          \\\n+  (garrow_gpu_cuda_ipc_memory_handle_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDAIPCMemoryHandle,\n+                         garrow_gpu_cuda_ipc_memory_handle,\n+                         GARROW_GPU,\n+                         CUDA_IPC_MEMORY_HANDLE,\n+                         GObject)\n+struct _GArrowGPUCUDAIPCMemoryHandleClass\n+{\n+  GObjectClass parent_class;\n+};\n+\n+#define GARROW_GPU_TYPE_CUDA_BUFFER_INPUT_STREAM        \\\n+  (garrow_gpu_cuda_buffer_input_stream_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDABufferInputStream,\n+                         garrow_gpu_cuda_buffer_input_stream,\n+                         GARROW_GPU,\n+                         CUDA_BUFFER_INPUT_STREAM,\n+                         GArrowBufferInputStream)\n+struct _GArrowGPUCUDABufferInputStreamClass\n+{\n+  GArrowBufferInputStreamClass parent_class;\n+};\n+\n+#define GARROW_GPU_TYPE_CUDA_BUFFER_OUTPUT_STREAM               \\\n+  (garrow_gpu_cuda_buffer_output_stream_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDABufferOutputStream,\n+                         garrow_gpu_cuda_buffer_output_stream,\n+                         GARROW_GPU,\n+                         CUDA_BUFFER_OUTPUT_STREAM,\n+                         GArrowOutputStream)\n+struct _GArrowGPUCUDABufferOutputStreamClass\n+{\n+  GArrowOutputStreamClass parent_class;\n+};\n+\n+GArrowGPUCUDADeviceManager *\n+garrow_gpu_cuda_device_manager_new(GError **error);\n+\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n+                                           gint gpu_number,\n+                                           GError **error);\n+gsize\n+garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager);\n+\n+gint64\n+garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context);\n+\n+\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n+                           gint64 size,\n+                           GError **error);\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n+                               GArrowGPUCUDAIPCMemoryHandle *handle,\n+                               GError **error);\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n+                                        GArrowRecordBatch *record_batch,\n+                                        GError **error);\n+GBytes *\n+garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n+                                    gint64 position,\n+                                    gint64 size,\n+                                    GError **error);\n+gboolean\n+garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n+                                      const guint8 *data,\n+                                      gint64 size,\n+                                      GError **error);\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_buffer_export(GArrowGPUCUDABuffer *buffer,\n+                              GError **error);\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_buffer_get_context(GArrowGPUCUDABuffer *buffer);\n+GArrowRecordBatch *\n+garrow_gpu_cuda_buffer_read_record_batch(GArrowGPUCUDABuffer *buffer,\n+                                         GArrowSchema *schema,\n+                                         GError **error);\n+\n+\n+GArrowGPUCUDAHostBuffer *\n+garrow_gpu_cuda_host_buffer_new(gint64 size, GError **error);\n+\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_ipc_memory_handle_new(const guint8 *data,\n+                                      gsize size,\n+                                      GError **error);\n+\n+GArrowBuffer *\n+garrow_gpu_cuda_ipc_memory_handle_serialize(GArrowGPUCUDAIPCMemoryHandle *handle,\n+                                            GError **error);\n+\n+GArrowGPUCUDABufferInputStream *\n+garrow_gpu_cuda_buffer_input_stream_new(GArrowGPUCUDABuffer *buffer);\n+\n+GArrowGPUCUDABufferOutputStream *\n+garrow_gpu_cuda_buffer_output_stream_new(GArrowGPUCUDABuffer *buffer);\n+\n+gboolean\n+garrow_gpu_cuda_buffer_output_stream_set_buffer_size(GArrowGPUCUDABufferOutputStream *stream,\n+                                                     gint64 size,\n+                                                     GError **error);\n+gint64\n+garrow_gpu_cuda_buffer_output_stream_get_buffer_size(GArrowGPUCUDABufferOutputStream *stream);\n+gint64\n+garrow_gpu_cuda_buffer_output_stream_get_buffered_size(GArrowGPUCUDABufferOutputStream *stream);\n+\n+G_END_DECLS\ndiff --git a/c_glib/arrow-gpu-glib/cuda.hpp b/c_glib/arrow-gpu-glib/cuda.hpp\nnew file mode 100644\nindex 000000000..3eeff8b6f\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/cuda.hpp\n@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#pragma once\n+\n+#include <arrow/gpu/cuda_api.h>\n+\n+#include <arrow-gpu-glib/cuda.h>\n+\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_context_new_raw(std::shared_ptr<arrow::gpu::CudaContext> *arrow_context);\n+std::shared_ptr<arrow::gpu::CudaContext>\n+garrow_gpu_cuda_context_get_raw(GArrowGPUCUDAContext *context);\n+\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_ipc_memory_handle_new_raw(arrow::gpu::CudaIpcMemHandle *arrow_handle);\n+arrow::gpu::CudaIpcMemHandle *\n+garrow_gpu_cuda_ipc_memory_handle_get_raw(GArrowGPUCUDAIPCMemoryHandle *handle);\n+\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaBuffer> *arrow_buffer);\n+std::shared_ptr<arrow::gpu::CudaBuffer>\n+garrow_gpu_cuda_buffer_get_raw(GArrowGPUCUDABuffer *buffer);\n+\n+GArrowGPUCUDAHostBuffer *\n+garrow_gpu_cuda_host_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaHostBuffer> *arrow_buffer);\n+std::shared_ptr<arrow::gpu::CudaHostBuffer>\n+garrow_gpu_cuda_host_buffer_get_raw(GArrowGPUCUDAHostBuffer *buffer);\n+\n+GArrowGPUCUDABufferInputStream *\n+garrow_gpu_cuda_buffer_input_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferReader> *arrow_reader);\n+std::shared_ptr<arrow::gpu::CudaBufferReader>\n+garrow_gpu_cuda_buffer_input_stream_get_raw(GArrowGPUCUDABufferInputStream *input_stream);\n+\n+GArrowGPUCUDABufferOutputStream *\n+garrow_gpu_cuda_buffer_output_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferWriter> *arrow_writer);\n+std::shared_ptr<arrow::gpu::CudaBufferWriter>\n+garrow_gpu_cuda_buffer_output_stream_get_raw(GArrowGPUCUDABufferOutputStream *output_stream);\ndiff --git a/c_glib/arrow-gpu-glib/meson.build b/c_glib/arrow-gpu-glib/meson.build\nnew file mode 100644\nindex 000000000..00c7f079d\n--- /dev/null\n+++ b/c_glib/arrow-gpu-glib/meson.build\n@@ -0,0 +1,80 @@\n+# -*- indent-tabs-mode: nil -*-\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+sources = files(\n+  'cuda.cpp',\n+)\n+\n+c_headers = files(\n+  'arrow-gpu-glib.h',\n+  'cuda.h',\n+)\n+\n+cpp_headers = files(\n+  'arrow-gpu-glib.hpp',\n+  'cuda.hpp',\n+)\n+\n+headers = c_headers + cpp_headers\n+install_headers(headers, subdir: 'arrow-gpu-glib')\n+\n+\n+dependencies = [\n+  arrow_gpu_dependency,\n+  libarrow_glib_dependency,\n+]\n+libarrow_gpu_glib = library('arrow-gpu-glib',\n+                            sources: sources,\n+                            install: true,\n+                            dependencies: dependencies,\n+                            include_directories: [\n+                              root_inc,\n+                            ],\n+                            soversion: so_version,\n+                            version: library_version)\n+libarrow_gpu_glib_dependency = declare_dependency(link_with: libarrow_gpu_glib,\n+                                                  include_directories: [\n+                                                    root_inc,\n+                                                  ],\n+                                                  dependencies: dependencies)\n+\n+pkgconfig.generate(filebase: 'arrow-gpu-glib',\n+                   name: 'Apache Arrow GPU GLib',\n+                   description: 'C API for Apache Arrow GPU based on GLib',\n+                   version: version,\n+                   requires: ['arrow-glib', 'arrow-gpu'],\n+                   libraries: [libarrow_gpu_glib],\n+                   subdirs: ['arrow-gpu-glib'])\n+\n+gnome.generate_gir(libarrow_gpu_glib,\n+                   dependencies: arrow_glib_gir_dependency,\n+                   sources: sources + c_headers,\n+                   namespace: 'ArrowGPU',\n+                   nsversion: api_version,\n+                   identifier_prefix: 'GArrowGPU',\n+                   symbol_prefix: 'garrow_gpu',\n+                   export_packages: 'arrow-gpu-glib',\n+                   includes: [\n+                     'Arrow-1.0',\n+                   ],\n+                   install: true,\n+                   extra_args: [\n+                     '--warn-all',\n+                     '--include-uninstalled=./arrow-glib/Arrow-1.0.gir',\n+                   ])\ndiff --git a/c_glib/configure.ac b/c_glib/configure.ac\nindex 5db435275..c6fa0192c 100644\n--- a/c_glib/configure.ac\n+++ b/c_glib/configure.ac\n@@ -77,18 +77,34 @@ AC_ARG_WITH(arrow-cpp-build-dir,\n   [GARROW_ARROW_CPP_BUILD_DIR=\"\"])\n if test \"x$GARROW_ARROW_CPP_BUILD_DIR\" = \"x\"; then\n   PKG_CHECK_MODULES([ARROW], [arrow arrow-compute])\n+  PKG_CHECK_MODULES([ARROW_GPU],\n+                    [arrow-gpu],\n+                    [HAVE_ARROW_GPU=yes],\n+                    [HAVE_ARROW_GPU=no])\n else\n   ARROW_INCLUDE_DIR=\"\\$(abs_top_srcdir)/../cpp/src\"\n   ARROW_LIB_DIR=\"${GARROW_ARROW_CPP_BUILD_DIR}/${GARROW_ARROW_CPP_BUILD_TYPE}\"\n \n   ARROW_CFLAGS=\"-I${ARROW_INCLUDE_DIR}\"\n-\n   ARROW_LIBS=\"-L${ARROW_LIB_DIR} -larrow\"\n-\n-  AC_SUBST(ARROW_LIB_DIR)\n-\n   AC_SUBST(ARROW_CFLAGS)\n   AC_SUBST(ARROW_LIBS)\n+\n+  ARROW_GPU_CFLAGS=\"\"\n+  if test -f \"${GARROW_ARROW_CPP_BUILD_DIR}/src/arrow/gpu/arrow-gpu.pc\"; then\n+    HAVE_ARROW_GPU=yes\n+    ARROW_GPU_LIBS=\"-larrow_gpu\"\n+  else\n+    HAVE_ARROW_GPU=no\n+    ARROW_GPU_LIBS=\"\"\n+  fi\n+  AC_SUBST(ARROW_GPU_CFLAGS)\n+  AC_SUBST(ARROW_GPU_LIBS)\n+fi\n+\n+AM_CONDITIONAL([HAVE_ARROW_GPU], [test \"$HAVE_ARROW_GPU\" = \"yes\"])\n+if test \"$HAVE_ARROW_GPU\" = \"yes\"; then\n+  AC_DEFINE(HAVE_ARROW_GPU, [1], [Define to 1 if Apache Arrow supports GPU.])\n fi\n \n exampledir=\"\\$(datadir)/arrow-glib/example\"\n@@ -98,6 +114,8 @@ AC_CONFIG_FILES([\n   Makefile\n   arrow-glib/Makefile\n   arrow-glib/arrow-glib.pc\n+  arrow-gpu-glib/Makefile\n+  arrow-gpu-glib/arrow-gpu-glib.pc\n   doc/Makefile\n   doc/reference/Makefile\n   doc/reference/xml/Makefile\ndiff --git a/c_glib/doc/Makefile.am b/c_glib/doc/Makefile.am\nindex 85c1d5126..1d491ab09 100644\n--- a/c_glib/doc/Makefile.am\n+++ b/c_glib/doc/Makefile.am\n@@ -16,4 +16,4 @@\n # under the License.\n \n SUBDIRS =                                       \\\n-        reference\n+\treference\ndiff --git a/c_glib/doc/reference/Makefile.am b/c_glib/doc/reference/Makefile.am\nindex 45b11f035..896aff544 100644\n--- a/c_glib/doc/reference/Makefile.am\n+++ b/c_glib/doc/reference/Makefile.am\n@@ -51,6 +51,17 @@ AM_CFLAGS =\t\t\t\t\t\\\n GTKDOC_LIBS =\t\t\t\t\t\t\\\n \t$(top_builddir)/arrow-glib/libarrow-glib.la\n \n+if HAVE_ARROW_GPU\n+DOC_SOURCE_DIR +=\t\t\t\t\\\n+\t$(top_srcdir)/arrow-gpu-glib\n+HFILE_GLOB +=\t\t\t\t\t\\\n+\t$(top_srcdir)/arrow-gpu-glib/*.h\n+CFILE_GLOB +=\t\t\t\t\t\\\n+\t$(top_srcdir)/arrow-gpu-glib/*.cpp\n+GTKDOC_LIBS +=\t\t\t\t\t\t\t\\\n+\t$(top_builddir)/arrow-gpu-glib/libarrow-gpu-glib.la\n+endif\n+\n include $(srcdir)/gtk-doc.make\n \n CLEANFILES +=\t\t\t\t\t\\\ndiff --git a/c_glib/doc/reference/arrow-glib-docs.sgml b/c_glib/doc/reference/arrow-glib-docs.sgml\nindex a504ef114..e267ea2f9 100644\n--- a/c_glib/doc/reference/arrow-glib-docs.sgml\n+++ b/c_glib/doc/reference/arrow-glib-docs.sgml\n@@ -125,6 +125,16 @@\n     </chapter>\n   </part>\n \n+  <!-- TODO\n+  <part id=\"gpu\">\n+    <title>GPU</title>\n+    <chapter id=\"cuda\">\n+      <title>CUDA</title>\n+      <xi:include href=\"xml/cuda.xml\"/>\n+    </chapter>\n+  </part>\n+  -->\n+\n   <chapter id=\"object-tree\">\n     <title>Object Hierarchy</title>\n     <xi:include href=\"xml/tree_index.sgml\"/>\ndiff --git a/c_glib/doc/reference/meson.build b/c_glib/doc/reference/meson.build\nindex 08936daf8..4c9552e83 100644\n--- a/c_glib/doc/reference/meson.build\n+++ b/c_glib/doc/reference/meson.build\n@@ -32,13 +32,26 @@ glib_prefix = dependency('glib-2.0').get_pkgconfig_variable('prefix')\n glib_doc_path = join_paths(glib_prefix, 'share', 'gtk-doc', 'html')\n doc_path = join_paths(data_dir, meson.project_name(), 'gtk-doc', 'html')\n \n+source_directories = [\n+  join_paths(meson.source_root(), 'arrow-glib'),\n+  join_paths(meson.build_root(), 'arrow-glib'),\n+]\n+dependencies = [\n+  libarrow_glib_dependency,\n+]\n+if arrow_gpu_dependency.found()\n+  source_directories += [\n+    join_paths(meson.source_root(), 'arrow-gpu-glib'),\n+    join_paths(meson.build_root(), 'arrow-gpu-glib'),\n+  ]\n+  dependencies += [\n+    libarrow_gpu_glib_dependency,\n+  ]\n+endif\n gnome.gtkdoc(meson.project_name(),\n              main_xml: meson.project_name() + '-docs.sgml',\n-             src_dir: [\n-               join_paths(meson.source_root(), 'arrow-glib'),\n-               join_paths(meson.build_root(), 'arrow-glib'),\n-             ],\n-             dependencies: libarrow_glib_dependency,\n+             src_dir: source_directories,\n+             dependencies: dependencies,\n              gobject_typesfile: meson.project_name() + '.types',\n              scan_args: [\n                '--rebuild-types',\ndiff --git a/c_glib/meson.build b/c_glib/meson.build\nindex 1fa64ba19..9fe1b8cbd 100644\n--- a/c_glib/meson.build\n+++ b/c_glib/meson.build\n@@ -49,6 +49,10 @@ pkgconfig = import('pkgconfig')\n root_inc = include_directories('.')\n \n subdir('arrow-glib')\n+arrow_gpu_dependency = dependency('arrow-gpu', required: false)\n+if arrow_gpu_dependency.found()\n+  subdir('arrow-gpu-glib')\n+endif\n subdir('example')\n \n if get_option('enable_gtk_doc')\n@@ -58,4 +62,7 @@ endif\n run_test = find_program('test/run-test.sh')\n test('unit test',\n      run_test,\n-     env: ['ARROW_GLIB_TYPELIB_DIR=@0@/arrow-glib'.format(meson.build_root())])\n+     env: [\n+       'ARROW_GLIB_TYPELIB_DIR=@0@/arrow-glib'.format(meson.build_root()),\n+       'ARROW_GPU_GLIB_TYPELIB_DIR=@0@/arrow-gpu-glib'.format(meson.build_root()),\n+     ])\ndiff --git a/c_glib/test/run-test.rb b/c_glib/test/run-test.rb\nindex 3451bd29f..392c56f33 100755\n--- a/c_glib/test/run-test.rb\n+++ b/c_glib/test/run-test.rb\n@@ -37,6 +37,12 @@ def initialize(data)\n   end\n end\n \n+begin\n+  ArrowGPU = GI.load(\"ArrowGPU\")\n+rescue GObjectIntrospection::RepositoryError::TypelibNotFound\n+end\n+\n+require \"rbconfig\"\n require \"tempfile\"\n require_relative \"helper/buildable\"\n require_relative \"helper/omittable\"\ndiff --git a/c_glib/test/run-test.sh b/c_glib/test/run-test.sh\nindex 19ccf0778..d563e8586 100755\n--- a/c_glib/test/run-test.sh\n+++ b/c_glib/test/run-test.sh\n@@ -20,27 +20,34 @@\n test_dir=\"$(cd $(dirname $0); pwd)\"\n build_dir=\"$(cd .; pwd)\"\n \n-arrow_glib_build_dir=\"${build_dir}/arrow-glib/\"\n-libtool_dir=\"${arrow_glib_build_dir}/.libs\"\n-if [ -d \"${libtool_dir}\" ]; then\n-  LD_LIBRARY_PATH=\"${libtool_dir}:${LD_LIBRARY_PATH}\"\n-else\n-  if [ -d \"${arrow_glib_build_dir}\" ]; then\n-    LD_LIBRARY_PATH=\"${arrow_glib_build_dir}:${LD_LIBRARY_PATH}\"\n+modules=\"arrow-glib arrow-gpu-glib\"\n+\n+for module in ${modules}; do\n+  module_build_dir=\"${build_dir}/${module}\"\n+  libtool_dir=\"${module_build_dir}/.libs\"\n+  if [ -d \"${libtool_dir}\" ]; then\n+    LD_LIBRARY_PATH=\"${libtool_dir}:${LD_LIBRARY_PATH}\"\n+  else\n+    if [ -d \"${module_build_dir}\" ]; then\n+      LD_LIBRARY_PATH=\"${module_build_dir}:${LD_LIBRARY_PATH}\"\n+    fi\n   fi\n-fi\n+done\n \n if [ -f \"Makefile\" -a \"${NO_MAKE}\" != \"yes\" ]; then\n   make -j8 > /dev/null || exit $?\n fi\n \n-arrow_glib_typelib_dir=\"${ARROW_GLIB_TYPELIB_DIR}\"\n-if [ -z \"${arrow_glib_typelib_dir}\" ]; then\n-  arrow_glib_typelib_dir=\"${build_dir}/arrow-glib\"\n-fi\n+for module in ${modules}; do\n+  MODULE_TYPELIB_DIR_VAR_NAME=\"$(echo ${module} | tr a-z- A-Z_)_TYPELIB_DIR\"\n+  module_typelib_dir=$(eval \"echo \\${${MODULE_TYPELIB_DIR_VAR_NAME}}\")\n+  if [ -z \"${module_typelib_dir}\" ]; then\n+    module_typelib_dir=\"${build_dir}/${module}\"\n+  fi\n \n-if [ -d \"${arrow_glib_typelib_dir}\" ]; then\n-  GI_TYPELIB_PATH=\"${arrow_glib_typelib_dir}:${GI_TYPELIB_PATH}\"\n-fi\n+  if [ -d \"${module_typelib_dir}\" ]; then\n+    GI_TYPELIB_PATH=\"${module_typelib_dir}:${GI_TYPELIB_PATH}\"\n+  fi\n+done\n \n ${GDB} ruby ${test_dir}/run-test.rb \"$@\"\ndiff --git a/c_glib/test/test-gpu-cuda.rb b/c_glib/test/test-gpu-cuda.rb\nnew file mode 100644\nindex 000000000..c710ef226\n--- /dev/null\n+++ b/c_glib/test/test-gpu-cuda.rb\n@@ -0,0 +1,144 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+class TestGPUCUDA < Test::Unit::TestCase\n+  include Helper::Buildable\n+\n+  def setup\n+    omit(\"Arrow GPU is required\") unless defined?(::ArrowGPU)\n+    @manager = ArrowGPU::CUDADeviceManager.new\n+    omit(\"At least one GPU is required\") if @manager.n_devices.zero?\n+    @context = @manager.get_context(0)\n+  end\n+\n+  sub_test_case(\"Context\") do\n+    def test_allocated_size\n+      allocated_size_before = @context.allocated_size\n+      size = 128\n+      buffer = ArrowGPU::CUDABuffer.new(@context, size)\n+      assert_equal(size,\n+                   @context.allocated_size - allocated_size_before)\n+    end\n+  end\n+\n+  sub_test_case(\"Buffer\") do\n+    def setup\n+      super\n+      @buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+    end\n+\n+    def test_copy\n+      @buffer.copy_from_host(\"Hello World\")\n+      assert_equal(\"llo W\", @buffer.copy_to_host(2, 5).to_s)\n+    end\n+\n+    def test_export\n+      @buffer.copy_from_host(\"Hello World\")\n+      handle = @buffer.export\n+      serialized_handle = handle.serialize.data\n+      Tempfile.open(\"arrow-gpu-cuda-export\") do |output|\n+        pid = spawn(RbConfig.ruby, \"-e\", <<-SCRIPT)\n+require \"gi\"\n+\n+Gio = GI.load(\"Gio\")\n+Arrow = GI.load(\"Arrow\")\n+ArrowGPU = GI.load(\"ArrowGPU\")\n+\n+manager = ArrowGPU::CUDADeviceManager.new\n+context = manager.get_context(0)\n+serialized_handle = #{serialized_handle.to_s.dump}\n+handle = ArrowGPU::CUDAIPCMemoryHandle.new(serialized_handle)\n+buffer = ArrowGPU::CUDABuffer.new(context, handle)\n+File.open(#{output.path.dump}, \"w\") do |output|\n+  output.print(buffer.copy_to_host(0, 6).to_s)\n+end\n+        SCRIPT\n+        Process.waitpid(pid)\n+        assert_equal(\"Hello \", output.read)\n+      end\n+    end\n+\n+    def test_context\n+      assert_equal(@context.allocated_size,\n+                   @buffer.context.allocated_size)\n+    end\n+\n+    def test_record_batch\n+      field = Arrow::Field.new(\"enabled\", Arrow::BooleanDataType.new)\n+      schema = Arrow::Schema.new([field])\n+      columns = [\n+        build_boolean_array([true]),\n+      ]\n+      cpu_record_batch = Arrow::RecordBatch.new(schema, 1, columns)\n+\n+      buffer = ArrowGPU::CUDABuffer.new(@context, cpu_record_batch)\n+      gpu_record_batch = buffer.read_record_batch(schema)\n+      assert_equal(cpu_record_batch.n_rows,\n+                   gpu_record_batch.n_rows)\n+    end\n+  end\n+\n+  sub_test_case(\"HostBuffer\") do\n+    def test_new\n+      buffer = ArrowGPU::CUDAHostBuffer.new(128)\n+      assert_equal(128, buffer.size)\n+    end\n+  end\n+\n+  sub_test_case(\"BufferInputStream\") do\n+    def test_new\n+      buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+      buffer.copy_from_host(\"Hello World\")\n+      stream = ArrowGPU::CUDABufferInputStream.new(buffer)\n+      begin\n+        assert_equal(\"Hello Worl\", stream.read(5).copy_to_host(0, 10).to_s)\n+      ensure\n+        stream.close\n+      end\n+    end\n+  end\n+\n+  sub_test_case(\"BufferOutputStream\") do\n+    def setup\n+      super\n+      @buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+      @buffer.copy_from_host(\"\\x00\" * @buffer.size)\n+      @stream = ArrowGPU::CUDABufferOutputStream.new(@buffer)\n+    end\n+\n+    def cleanup\n+      super\n+      @stream.close\n+    end\n+\n+    def test_new\n+      @stream.write(\"Hello World\")\n+      assert_equal(\"Hello World\", @buffer.copy_to_host(0, 11).to_s)\n+    end\n+\n+    def test_buffer\n+      assert_equal(0, @stream.buffer_size)\n+      @stream.buffer_size = 5\n+      assert_equal(5, @stream.buffer_size)\n+      @stream.write(\"Hell\")\n+      assert_equal(4, @stream.buffered_size)\n+      assert_equal(\"\\x00\" * 5, @buffer.copy_to_host(0, 5).to_s)\n+      @stream.write(\"o\")\n+      assert_equal(\"Hello\", @buffer.copy_to_host(0, 5).to_s)\n+    end\n+  end\n+end\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T03:54:10.755+0000",
                    "updated": "2017-11-14T03:54:10.755+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16250794",
                    "id": "16250794",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 1313\n[https://github.com/apache/arrow/pull/1313]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-11-14T03:54:24.497+0000",
                    "updated": "2017-11-14T03:54:24.497+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16251425",
                    "id": "16251425",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "kou commented on a change in pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313#discussion_r150843446\n \n \n\n ##########\n File path: c_glib/arrow-gpu-glib/cuda.cpp\n ##########\n @@ -0,0 +1,941 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#ifdef HAVE_CONFIG_H\n+#  include <config.h>\n+#endif\n+\n+#include <arrow-glib/buffer.hpp>\n+#include <arrow-glib/error.hpp>\n+#include <arrow-glib/input-stream.hpp>\n+#include <arrow-glib/output-stream.hpp>\n+#include <arrow-glib/readable.hpp>\n+#include <arrow-glib/record-batch.hpp>\n+#include <arrow-glib/schema.hpp>\n+\n+#include <arrow-gpu-glib/cuda.hpp>\n+\n+G_BEGIN_DECLS\n+\n+/**\n+ * SECTION: cuda\n+ * @section_id: cuda-classes\n+ * @title: CUDA related classes\n+ * @include: arrow-gpu-glib/arrow-gpu-glib.h\n+ *\n+ * The following classes provide CUDA support for Apache Arrow data.\n+ *\n+ * #GArrowGPUCUDADeviceManager is the starting point. You need at\n+ * least one #GArrowGPUCUDAContext to process Apache Arrow data on\n+ * NVIDIA GPU.\n+ *\n+ * #GArrowGPUCUDAContext is a class to keep context for one GPU. You\n+ * need to create #GArrowGPUCUDAContext for each GPU that you want to\n+ * use. You can create #GArrowGPUCUDAContext by\n+ * garrow_gpu_cuda_device_manager_get_context().\n+ *\n+ * #GArrowGPUCUDABuffer is a class for data on GPU. You can copy data\n+ * on GPU to/from CPU by garrow_gpu_cuda_buffer_copy_to_host() and\n+ * garrow_gpu_cuda_buffer_copy_from_host(). You can share data on GPU\n+ * with other processes by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDAHostBuffer is a class for data on CPU that is\n+ * directly accessible from GPU.\n+ *\n+ * #GArrowGPUCUDAIPCMemoryHandle is a class to share data on GPU with\n+ * other processes. You can export your data on GPU to other processes\n+ * by garrow_gpu_cuda_buffer_export() and\n+ * garrow_gpu_cuda_ipc_memory_handle_new(). You can import other\n+ * process data on GPU by garrow_gpu_cuda_ipc_memory_handle_new() and\n+ * garrow_gpu_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowGPUCUDABufferInputStream is a class to read data in\n+ * #GArrowGPUCUDABuffer.\n+ *\n+ * #GArrowGPUCUDABufferOutputStream is a class to write data into\n+ * #GArrowGPUCUDABuffer.\n+ */\n+\n+G_DEFINE_TYPE(GArrowGPUCUDADeviceManager,\n+              garrow_gpu_cuda_device_manager,\n+              G_TYPE_OBJECT)\n+\n+static void\n+garrow_gpu_cuda_device_manager_init(GArrowGPUCUDADeviceManager *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_device_manager_class_init(GArrowGPUCUDADeviceManagerClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_new:\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDADeviceManager on success,\n+ *   %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDADeviceManager *\n+garrow_gpu_cuda_device_manager_new(GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][device-manager][new]\")) {\n+    auto manager = g_object_new(GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER,\n+                                NULL);\n+    return GARROW_GPU_CUDA_DEVICE_MANAGER(manager);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_context:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ * @gpu_number: A GPU device number for the target context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext on\n+ *   success, %NULL on error. Contexts for the same GPU device number\n+ *   share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n+                                           gint gpu_number,\n+                                           GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+  auto status = arrow_manager->GetContext(gpu_number, &context);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][device-manager][get-context]]\")) {\n+    return garrow_gpu_cuda_context_new_raw(&context);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_device_manager_get_n_devices:\n+ * @manager: A #GArrowGPUCUDADeviceManager.\n+ *\n+ * Returns: The number of GPU devices.\n+ *\n+ * Since: 0.8.0\n+ */\n+gsize\n+garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager)\n+{\n+  arrow::gpu::CudaDeviceManager *arrow_manager;\n+  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n+  return arrow_manager->num_devices();\n+}\n+\n+\n+typedef struct GArrowGPUCUDAContextPrivate_ {\n+  std::shared_ptr<arrow::gpu::CudaContext> context;\n+} GArrowGPUCUDAContextPrivate;\n+\n+enum {\n+  PROP_CONTEXT = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAContext,\n+                           garrow_gpu_cuda_context,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object)     \\\n+  static_cast<GArrowGPUCUDAContextPrivate *>(           \\\n+    garrow_gpu_cuda_context_get_instance_private(       \\\n+      GARROW_GPU_CUDA_CONTEXT(object)))\n+\n+static void\n+garrow_gpu_cuda_context_finalize(GObject *object)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  priv->context = nullptr;\n+\n+  G_OBJECT_CLASS(garrow_gpu_cuda_context_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_gpu_cuda_context_set_property(GObject *object,\n+                                     guint prop_id,\n+                                     const GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_CONTEXT:\n+    priv->context =\n+      *static_cast<std::shared_ptr<arrow::gpu::CudaContext> *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_get_property(GObject *object,\n+                                     guint prop_id,\n+                                     GValue *value,\n+                                     GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_gpu_cuda_context_init(GArrowGPUCUDAContext *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_context_class_init(GArrowGPUCUDAContextClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_gpu_cuda_context_finalize;\n+  gobject_class->set_property = garrow_gpu_cuda_context_set_property;\n+  gobject_class->get_property = garrow_gpu_cuda_context_get_property;\n+\n+  /**\n+   * GArrowGPUCUDAContext:context:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"context\",\n+                              \"Context\",\n+                              \"The raw std::shared_ptr<arrow::gpu::CudaContext> *\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_CONTEXT, spec);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_context_get_allocated_size:\n+ * @context: A #GArrowGPUCUDAContext.\n+ *\n+ * Returns: The allocated memory by this context in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  return arrow_context->bytes_allocated();\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDABuffer,\n+              garrow_gpu_cuda_buffer,\n+              GARROW_TYPE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_buffer_init(GArrowGPUCUDABuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_buffer_class_init(GArrowGPUCUDABufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @size: The number of bytes to be allocated on GPU device for this context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n+                           gint64 size,\n+                           GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->Allocate(size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][new]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_ipc:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @handle: A #GArrowGPUCUDAIPCMemoryHandle to be communicated.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has data from the IPC target.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n+                               GArrowGPUCUDAIPCMemoryHandle *handle,\n+                               GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->OpenIpcBuffer(*arrow_handle, &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-ipc]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_new_record_batch:\n+ * @context: A #GArrowGPUCUDAContext.\n+ * @record_batch: A #GArrowRecordBatch to be serialized.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n+ *   success, %NULL on error. The buffer has serialized record batch\n+ *   data.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDABuffer *\n+garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n+                                        GArrowRecordBatch *record_batch,\n+                                        GError **error)\n+{\n+  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n+  auto arrow_record_batch = garrow_record_batch_get_raw(record_batch);\n+  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n+  auto status = arrow::gpu::SerializeRecordBatch(*arrow_record_batch,\n+                                                 arrow_context.get(),\n+                                                 &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][new-record-batch]\")) {\n+    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_to_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @position: The offset of memory on GPU device to be copied.\n+ * @size: The size of memory on GPU device to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A #GBytes that have copied memory on CPU\n+ *   host on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GBytes *\n+garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n+                                    gint64 position,\n+                                    gint64 size,\n+                                    GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto data = static_cast<uint8_t *>(g_malloc(size));\n+  auto status = arrow_buffer->CopyToHost(position, size, data);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][copy-to-host]\")) {\n+    return g_bytes_new_take(data, size);\n+  } else {\n+    g_free(data);\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_copy_from_host:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @data: (array length=size): Data on CPU host to be copied.\n+ * @size: The size of data on CPU host to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n+                                      const guint8 *data,\n+                                      gint64 size,\n+                                      GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto status = arrow_buffer->CopyFromHost(0, data, size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[gpu][cuda][buffer][copy-from-host]\");\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_export:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowGPUCUDAIPCMemoryHandle to handle the exported buffer on\n+ *   success, %NULL on error\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAIPCMemoryHandle *\n+garrow_gpu_cuda_buffer_export(GArrowGPUCUDABuffer *buffer, GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  std::unique_ptr<arrow::gpu::CudaIpcMemHandle> arrow_handle;\n+  auto status = arrow_buffer->ExportForIpc(&arrow_handle);\n+  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][export-for-ipc]\")) {\n+    return garrow_gpu_cuda_ipc_memory_handle_new_raw(arrow_handle.release());\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_get_context:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowGPUCUDAContext for the\n+ *   buffer. Contexts for the same buffer share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAContext *\n+garrow_gpu_cuda_buffer_get_context(GArrowGPUCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_context = arrow_buffer->context();\n+  return garrow_gpu_cuda_context_new_raw(&arrow_context);\n+}\n+\n+/**\n+ * garrow_gpu_cuda_buffer_read_record_batch:\n+ * @buffer: A #GArrowGPUCUDABuffer.\n+ * @schema: A #GArrowSchema for record batch.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowRecordBatch on\n+ *   success, %NULL on error. The record batch data is located on GPU.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowRecordBatch *\n+garrow_gpu_cuda_buffer_read_record_batch(GArrowGPUCUDABuffer *buffer,\n+                                         GArrowSchema *schema,\n+                                         GError **error)\n+{\n+  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n+  auto arrow_schema = garrow_schema_get_raw(schema);\n+  auto pool = arrow::default_memory_pool();\n+  std::shared_ptr<arrow::RecordBatch> arrow_record_batch;\n+  auto status = arrow::gpu::ReadRecordBatch(arrow_schema,\n+                                            arrow_buffer,\n+                                            pool,\n+                                            &arrow_record_batch);\n+  if (garrow_error_check(error, status,\n+                         \"[gpu][cuda][buffer][read-record-batch]\")) {\n+    return garrow_record_batch_new_raw(&arrow_record_batch);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowGPUCUDAHostBuffer,\n+              garrow_gpu_cuda_host_buffer,\n+              GARROW_TYPE_MUTABLE_BUFFER)\n+\n+static void\n+garrow_gpu_cuda_host_buffer_init(GArrowGPUCUDAHostBuffer *object)\n+{\n+}\n+\n+static void\n+garrow_gpu_cuda_host_buffer_class_init(GArrowGPUCUDAHostBufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_gpu_cuda_host_buffer_new:\n+ * @size: The number of bytes to be allocated on CPU host.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowGPUCUDAHostBuffer on success,\n+ *   %NULL on error. The allocated memory is accessible from GPU\n+ *   device for the @context.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowGPUCUDAHostBuffer *\n+garrow_gpu_cuda_host_buffer_new(gint64 size, GError **error)\n+{\n+  arrow::gpu::CudaDeviceManager *manager;\n+  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n+  std::shared_ptr<arrow::gpu::CudaHostBuffer> arrow_buffer;\n+  status = manager->AllocateHost(size, &arrow_buffer);\n \n Review comment:\n   I don't write any program with this API yet but it seems that the current API (`arrow::gpu::CudaContext` is received as an argument explicitly) isn't bad.\r\n   I think that we can handle multiple contexts with the current API.\r\n   \r\n   I hope that Arrow API doesn't export any CUDA API such as `CUcontext` (don't include `cuda.h`) for integrating with other libraries. It will complicate building programs a bit. I hope that we use `void *` for CUDA objects like we did for `CudaIpcMemHandle`.\r\n   \r\n   `arrow::cpu::CudaContext::FromBuffer(const void *opaque_context, std::shared_ptr<CudaContext>* context)` API may be good to use a context created by other library. It's similar to `CudaIpcMemHandle::FromBuffer()`.\r\n   \r\n   It's better that we discuss this in another issue later. This is a closed place.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T14:15:05.294+0000",
                    "updated": "2017-11-14T14:15:05.294+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117841/comment/16251426",
                    "id": "16251426",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "kou commented on a change in pull request #1313: ARROW-1802: [GLib] Support arrow-gpu\nURL: https://github.com/apache/arrow/pull/1313#discussion_r150843467\n \n \n\n ##########\n File path: c_glib/test/test-gpu-cuda.rb\n ##########\n @@ -0,0 +1,144 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+class TestGPUCUDA < Test::Unit::TestCase\n+  include Helper::Buildable\n+\n+  def setup\n+    omit(\"Arrow GPU is required\") unless defined?(::ArrowGPU)\n+    @manager = ArrowGPU::CUDADeviceManager.new\n+    omit(\"At least one GPU is required\") if @manager.n_devices.zero?\n+    @context = @manager.get_context(0)\n+  end\n+\n+  sub_test_case(\"Context\") do\n+    def test_allocated_size\n+      allocated_size_before = @context.allocated_size\n+      size = 128\n+      buffer = ArrowGPU::CUDABuffer.new(@context, size)\n+      assert_equal(size,\n+                   @context.allocated_size - allocated_size_before)\n+    end\n+  end\n+\n+  sub_test_case(\"Buffer\") do\n+    def setup\n+      super\n+      @buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+    end\n+\n+    def test_copy\n+      @buffer.copy_from_host(\"Hello World\")\n+      assert_equal(\"llo W\", @buffer.copy_to_host(2, 5).to_s)\n+    end\n+\n+    def test_export\n+      @buffer.copy_from_host(\"Hello World\")\n+      handle = @buffer.export\n+      serialized_handle = handle.serialize.data\n+      Tempfile.open(\"arrow-gpu-cuda-export\") do |output|\n+        pid = spawn(RbConfig.ruby, \"-e\", <<-SCRIPT)\n+require \"gi\"\n+\n+Gio = GI.load(\"Gio\")\n+Arrow = GI.load(\"Arrow\")\n+ArrowGPU = GI.load(\"ArrowGPU\")\n+\n+manager = ArrowGPU::CUDADeviceManager.new\n+context = manager.get_context(0)\n+serialized_handle = #{serialized_handle.to_s.dump}\n+handle = ArrowGPU::CUDAIPCMemoryHandle.new(serialized_handle)\n+buffer = ArrowGPU::CUDABuffer.new(context, handle)\n+File.open(#{output.path.dump}, \"w\") do |output|\n+  output.print(buffer.copy_to_host(0, 6).to_s)\n+end\n \n Review comment:\n   Yes! Sure!\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-14T14:15:10.052+0000",
                    "updated": "2017-11-14T14:15:10.052+0000"
                }
            ],
            "maxResults": 9,
            "total": 9,
            "startAt": 0
        },
        "customfield_12311820": "0|i3movb:",
        "customfield_12314139": null
    }
}