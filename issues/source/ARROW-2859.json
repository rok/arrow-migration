{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13172517",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517",
    "key": "ARROW-2859",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12342562",
                "id": "12342562",
                "description": "",
                "name": "0.10.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-08-06"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available",
            "usability"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 5400,
            "total": 5400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 5400,
            "total": 5400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2859/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 9,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126401",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm opened a new pull request #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314\n \n \n   The behavior had been to treat a string-like object like a file name; we didn't have any APIs that made use of this fact, and I think that being able to read a stream from an object importing the buffer protocol is much more convenient and natural as `pa.open_stream(buf)` than `pa.open_stream(pa.BufferReader(buf))`. \r\n   \r\n   I may look at quickly adding support for pathlib.Path objects here.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T02:35:47.509+0000",
                    "updated": "2018-07-24T02:35:47.509+0000",
                    "started": "2018-07-24T02:35:47.509+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126401",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126413",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314#issuecomment-407267259\n \n \n   Added pathlib test. I got annoyed by the use of unittest and so did the pytest refactor, sorry to make a large diff =/\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T03:17:04.873+0000",
                    "updated": "2018-07-24T03:17:04.873+0000",
                    "started": "2018-07-24T03:17:04.873+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126413",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126444",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io commented on issue #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314#issuecomment-407287310\n \n \n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/2314?src=pr&el=h1) Report\n   > Merging [#2314](https://codecov.io/gh/apache/arrow/pull/2314?src=pr&el=desc) into [master](https://codecov.io/gh/apache/arrow/commit/566e398650b40292b1f6293eb80c8f09d2451f98?src=pr&el=desc) will **increase** coverage by `2.38%`.\n   > The diff coverage is `96.23%`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/2314/graphs/tree.svg?width=650&height=150&src=pr&token=LpTCFbqVT1)](https://codecov.io/gh/apache/arrow/pull/2314?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #2314      +/-   ##\n   ==========================================\n   + Coverage   84.38%   86.77%   +2.38%     \n   ==========================================\n     Files         293      237      -56     \n     Lines       44784    42095    -2689     \n   ==========================================\n   - Hits        37789    36526    -1263     \n   + Misses       6964     5569    -1395     \n   + Partials       31        0      -31\n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/2314?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [python/pyarrow/ipc.py](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvaXBjLnB5) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [python/pyarrow/lib.pxd](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvbGliLnB4ZA==) | `0% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [python/pyarrow/ipc.pxi](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvaXBjLnB4aQ==) | `68.59% <100%> (+0.93%)` | :arrow_up: |\n   | [python/pyarrow/serialization.pxi](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvc2VyaWFsaXphdGlvbi5weGk=) | `76.21% <100%> (\u00f8)` | :arrow_up: |\n   | [python/pyarrow/\\_parquet.pyx](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvX3BhcnF1ZXQucHl4) | `68.98% <33.33%> (-0.14%)` | :arrow_down: |\n   | [python/pyarrow/feather.pxi](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvZmVhdGhlci5weGk=) | `67.44% <50%> (\u00f8)` | :arrow_up: |\n   | [python/pyarrow/io.pxi](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvaW8ucHhp) | `60.59% <60%> (+0.02%)` | :arrow_up: |\n   | [python/pyarrow/tests/test\\_ipc.py](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvdGVzdHMvdGVzdF9pcGMucHk=) | `99.46% <99.06%> (-0.54%)` | :arrow_down: |\n   | [go/arrow/math/uint64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC91aW50NjRfYW1kNjQuZ28=) | | |\n   | [go/arrow/type\\_traits\\_numeric.gen.go](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree#diff-Z28vYXJyb3cvdHlwZV90cmFpdHNfbnVtZXJpYy5nZW4uZ28=) | | |\n   | ... and [54 more](https://codecov.io/gh/apache/arrow/pull/2314/diff?src=pr&el=tree-more) | |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/2314?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/2314?src=pr&el=footer). Last update [566e398...73437a2](https://codecov.io/gh/apache/arrow/pull/2314?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T05:39:57.074+0000",
                    "updated": "2018-07-24T05:39:57.074+0000",
                    "started": "2018-07-24T05:39:57.073+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126444",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126510",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "xhochy commented on a change in pull request #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314#discussion_r204669369\n \n \n\n ##########\n File path: python/pyarrow/io.pxi\n ##########\n @@ -935,6 +935,14 @@ cdef class BufferOutputStream(NativeFile):\n         self.closed = True\n         return pyarrow_wrap_buffer(<shared_ptr[CBuffer]> self.buffer)\n \n+    def getvalue(self):\n+        \"\"\"\n+        Alias for get_result.\n+\n+        TODO(wesm): Should get_result be deprecated?\n \n Review comment:\n   Yes, we should deprecate this. Having a function twice is misleading UX.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T08:38:45.296+0000",
                    "updated": "2018-07-24T08:38:45.296+0000",
                    "started": "2018-07-24T08:38:45.295+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126510",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126664",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314#issuecomment-407443572\n \n \n   Added FutureWarning. Will merge on green build\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T15:14:49.222+0000",
                    "updated": "2018-07-24T15:14:49.222+0000",
                    "started": "2018-07-24T15:14:49.221+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126664",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126666",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314#discussion_r204798671\n \n \n\n ##########\n File path: python/pyarrow/ipc.py\n ##########\n @@ -131,7 +131,7 @@ def open_file(source, footer_offset=None):\n     Parameters\n     ----------\n     source : str, pyarrow.NativeFile, or file-like Python object\n \n Review comment:\n   \"str\" should become \"bytes/buffer-like\" as well.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T15:18:12.824+0000",
                    "updated": "2018-07-24T15:18:12.824+0000",
                    "started": "2018-07-24T15:18:12.823+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126666",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126672",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314#discussion_r204802723\n \n \n\n ##########\n File path: python/pyarrow/ipc.py\n ##########\n @@ -131,7 +131,7 @@ def open_file(source, footer_offset=None):\n     Parameters\n     ----------\n     source : str, pyarrow.NativeFile, or file-like Python object\n \n Review comment:\n   Thanks. Fixed\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T15:28:18.784+0000",
                    "updated": "2018-07-24T15:28:18.784+0000",
                    "started": "2018-07-24T15:28:18.784+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126672",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126828",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314#issuecomment-407522548\n \n \n   Appears the coverage got stuck. Merging\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T19:22:54.629+0000",
                    "updated": "2018-07-24T19:22:54.629+0000",
                    "started": "2018-07-24T19:22:54.628+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126828",
                    "issueId": "13172517"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/worklog/126829",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm closed pull request #2314: ARROW-2859: [Python] Accept buffer-like objects as sources in open_file, open_stream APIs\nURL: https://github.com/apache/arrow/pull/2314\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/python/doc/source/ipc.rst b/python/doc/source/ipc.rst\nindex 51d523cd85..738ae1dff2 100644\n--- a/python/doc/source/ipc.rst\n+++ b/python/doc/source/ipc.rst\n@@ -79,7 +79,7 @@ particular stream. Now we can do:\n       writer.write_batch(batch)\n    writer.close()\n \n-   buf = sink.get_result()\n+   buf = sink.getvalue()\n    buf.size\n \n Now ``buf`` contains the complete stream as an in-memory byte buffer. We can\n@@ -119,7 +119,7 @@ The :class:`~pyarrow.RecordBatchFileWriter` has the same API as\n       writer.write_batch(batch)\n    writer.close()\n \n-   buf = sink.get_result()\n+   buf = sink.getvalue()\n    buf.size\n \n The difference between :class:`~pyarrow.RecordBatchFileReader` and\ndiff --git a/python/doc/source/memory.rst b/python/doc/source/memory.rst\nindex cd8983a6da..8fcf5f548e 100644\n--- a/python/doc/source/memory.rst\n+++ b/python/doc/source/memory.rst\n@@ -206,7 +206,7 @@ file interfaces that can read and write to Arrow Buffers.\n    writer = pa.BufferOutputStream()\n    writer.write(b'hello, friends')\n \n-   buf = writer.get_result()\n+   buf = writer.getvalue()\n    buf\n    buf.size\n    reader = pa.BufferReader(buf)\ndiff --git a/python/pyarrow/_orc.pyx b/python/pyarrow/_orc.pyx\nindex cf04f48a32..c95bea2834 100644\n--- a/python/pyarrow/_orc.pyx\n+++ b/python/pyarrow/_orc.pyx\n@@ -41,13 +41,13 @@ cdef class ORCReader:\n     def __cinit__(self, MemoryPool memory_pool=None):\n         self.allocator = maybe_unbox_memory_pool(memory_pool)\n \n-    def open(self, object source):\n+    def open(self, object source, c_bool use_memory_map=True):\n         cdef:\n             shared_ptr[RandomAccessFile] rd_handle\n \n         self.source = source\n \n-        get_reader(source, &rd_handle)\n+        get_reader(source, use_memory_map, &rd_handle)\n         with nogil:\n             check_status(ORCFileReader.Open(rd_handle, self.allocator,\n                                             &self.reader))\ndiff --git a/python/pyarrow/_parquet.pyx b/python/pyarrow/_parquet.pyx\nindex e40a57c1a0..983ff8d8a9 100644\n--- a/python/pyarrow/_parquet.pyx\n+++ b/python/pyarrow/_parquet.pyx\n@@ -636,7 +636,8 @@ cdef class ParquetReader:\n         self.allocator = maybe_unbox_memory_pool(memory_pool)\n         self._metadata = None\n \n-    def open(self, object source, FileMetaData metadata=None):\n+    def open(self, object source, c_bool use_memory_map=True,\n+             FileMetaData metadata=None):\n         cdef:\n             shared_ptr[RandomAccessFile] rd_handle\n             shared_ptr[CFileMetaData] c_metadata\n@@ -648,7 +649,7 @@ cdef class ParquetReader:\n \n         self.source = source\n \n-        get_reader(source, &rd_handle)\n+        get_reader(source, use_memory_map, &rd_handle)\n         with nogil:\n             check_status(OpenFile(rd_handle, self.allocator, properties,\n                                   c_metadata, &self.reader))\ndiff --git a/python/pyarrow/feather.pxi b/python/pyarrow/feather.pxi\nindex 37c7f92445..937e275409 100644\n--- a/python/pyarrow/feather.pxi\n+++ b/python/pyarrow/feather.pxi\n@@ -75,9 +75,9 @@ cdef class FeatherReader:\n     def __cinit__(self):\n         pass\n \n-    def open(self, source):\n+    def open(self, source, c_bool use_memory_map=True):\n         cdef shared_ptr[RandomAccessFile] reader\n-        get_reader(source, &reader)\n+        get_reader(source, use_memory_map, &reader)\n \n         with nogil:\n             check_status(CFeatherReader.Open(reader, &self.reader))\ndiff --git a/python/pyarrow/io.pxi b/python/pyarrow/io.pxi\nindex ad9bf0e349..8d35d0d4b0 100644\n--- a/python/pyarrow/io.pxi\n+++ b/python/pyarrow/io.pxi\n@@ -930,6 +930,22 @@ cdef class BufferOutputStream(NativeFile):\n         self.closed = False\n \n     def get_result(self):\n+        \"\"\"\n+        Deprecated as of 0.10.0. Alias for getvalue()\n+        \"\"\"\n+        warnings.warn(\"BufferOutputStream.get_result() has been renamed \"\n+                      \"to getvalue(), will be removed in 0.11.0\",\n+                      FutureWarning)\n+        return self.getvalue()\n+\n+    def getvalue(self):\n+        \"\"\"\n+        Finalize output stream and return result as pyarrow.Buffer.\n+\n+        Returns\n+        -------\n+        value : Buffer\n+        \"\"\"\n         with nogil:\n             check_status(self.wr_file.get().Close())\n         self.closed = True\n@@ -994,7 +1010,14 @@ def foreign_buffer(address, size, base):\n     return pyarrow_wrap_buffer(buf)\n \n \n-cdef get_reader(object source, shared_ptr[RandomAccessFile]* reader):\n+def as_buffer(object o):\n+    if isinstance(o, Buffer):\n+        return o\n+    return py_buffer(o)\n+\n+\n+cdef get_reader(object source, c_bool use_memory_map,\n+                shared_ptr[RandomAccessFile]* reader):\n     cdef NativeFile nf\n \n     try:\n@@ -1006,7 +1029,10 @@ cdef get_reader(object source, shared_ptr[RandomAccessFile]* reader):\n             # Optimistically hope this is file-like\n             source = PythonFile(source, mode='r')\n     else:\n-        source = memory_map(source_path, mode='r')\n+        if use_memory_map:\n+            source = memory_map(source_path, mode='r')\n+        else:\n+            source = OSFile(source_path, mode='r')\n \n     if isinstance(source, NativeFile):\n         nf = source\ndiff --git a/python/pyarrow/ipc.pxi b/python/pyarrow/ipc.pxi\nindex ccc2f64c49..2f51142b3d 100644\n--- a/python/pyarrow/ipc.pxi\n+++ b/python/pyarrow/ipc.pxi\n@@ -239,7 +239,13 @@ cdef get_input_stream(object source, shared_ptr[InputStream]* out):\n     cdef:\n         shared_ptr[RandomAccessFile] file_handle\n \n-    get_reader(source, &file_handle)\n+    try:\n+        source = as_buffer(source)\n+    except TypeError:\n+        # Non-buffer-like\n+        pass\n+\n+    get_reader(source, True, &file_handle)\n     out[0] = <shared_ptr[InputStream]> file_handle\n \n \n@@ -334,7 +340,12 @@ cdef class _RecordBatchFileReader:\n         pass\n \n     def _open(self, source, footer_offset=None):\n-        get_reader(source, &self.file)\n+        try:\n+            source = as_buffer(source)\n+        except TypeError:\n+            pass\n+\n+        get_reader(source, True, &self.file)\n \n         cdef int64_t offset = 0\n         if footer_offset is not None:\n@@ -522,7 +533,7 @@ def read_schema(obj):\n     if isinstance(obj, Message):\n         raise NotImplementedError(type(obj))\n \n-    get_reader(obj, &cpp_file)\n+    get_reader(obj, True, &cpp_file)\n \n     with nogil:\n         check_status(ReadSchema(cpp_file.get(), &result))\ndiff --git a/python/pyarrow/ipc.py b/python/pyarrow/ipc.py\nindex bed2dd6f2f..989e976875 100644\n--- a/python/pyarrow/ipc.py\n+++ b/python/pyarrow/ipc.py\n@@ -52,8 +52,8 @@ class RecordBatchStreamReader(lib._RecordBatchReader, _ReadPandasOption):\n \n     Parameters\n     ----------\n-    source : str, pyarrow.NativeFile, or file-like Python object\n-        Either a file path, or a readable file object\n+    source : bytes/buffer-like, pyarrow.NativeFile, or file-like Python object\n+        Either an in-memory buffer, or a readable file object\n     \"\"\"\n     def __init__(self, source):\n         self._open(source)\n@@ -80,8 +80,8 @@ class RecordBatchFileReader(lib._RecordBatchFileReader, _ReadPandasOption):\n \n     Parameters\n     ----------\n-    source : str, pyarrow.NativeFile, or file-like Python object\n-        Either a file path, or a readable file object\n+    source : bytes/buffer-like, pyarrow.NativeFile, or file-like Python object\n+        Either an in-memory buffer, or a readable file object\n     footer_offset : int, default None\n         If the file is embedded in some larger file, this is the byte offset to\n         the very end of the file data\n@@ -111,8 +111,8 @@ def open_stream(source):\n \n     Parameters\n     ----------\n-    source : str, pyarrow.NativeFile, or file-like Python object\n-        Either a file path, or a readable file object\n+    source : bytes/buffer-like, pyarrow.NativeFile, or file-like Python object\n+        Either an in-memory buffer, or a readable file object\n     footer_offset : int, default None\n         If the file is embedded in some larger file, this is the byte offset to\n         the very end of the file data\n@@ -130,8 +130,8 @@ def open_file(source, footer_offset=None):\n \n     Parameters\n     ----------\n-    source : str, pyarrow.NativeFile, or file-like Python object\n-        Either a file path, or a readable file object\n+    source : bytes/buffer-like, pyarrow.NativeFile, or file-like Python object\n+        Either an in-memory buffer, or a readable file object\n     footer_offset : int, default None\n         If the file is embedded in some larger file, this is the byte offset to\n         the very end of the file data\ndiff --git a/python/pyarrow/lib.pxd b/python/pyarrow/lib.pxd\nindex 29e3e3ab27..e3923613ac 100644\n--- a/python/pyarrow/lib.pxd\n+++ b/python/pyarrow/lib.pxd\n@@ -357,7 +357,8 @@ cdef class NativeFile:\n     cdef read_handle(self, shared_ptr[RandomAccessFile]* file)\n     cdef write_handle(self, shared_ptr[OutputStream]* file)\n \n-cdef get_reader(object source, shared_ptr[RandomAccessFile]* reader)\n+cdef get_reader(object source, c_bool use_memory_map,\n+                shared_ptr[RandomAccessFile]* reader)\n cdef get_writer(object source, shared_ptr[OutputStream]* writer)\n \n cdef dict box_metadata(const CKeyValueMetadata* sp_metadata)\ndiff --git a/python/pyarrow/serialization.pxi b/python/pyarrow/serialization.pxi\nindex 1ec607355a..6407347467 100644\n--- a/python/pyarrow/serialization.pxi\n+++ b/python/pyarrow/serialization.pxi\n@@ -372,7 +372,7 @@ def read_serialized(source, base=None):\n     serialized : the serialized data\n     \"\"\"\n     cdef shared_ptr[RandomAccessFile] stream\n-    get_reader(source, &stream)\n+    get_reader(source, True, &stream)\n \n     cdef SerializedPyObject serialized = SerializedPyObject()\n     serialized.base = base\ndiff --git a/python/pyarrow/tests/test_io.py b/python/pyarrow/tests/test_io.py\nindex f1994b38a7..eafa40c18b 100644\n--- a/python/pyarrow/tests/test_io.py\n+++ b/python/pyarrow/tests/test_io.py\n@@ -545,7 +545,7 @@ def test_memory_output_stream():\n     for i in range(K):\n         f.write(val)\n \n-    buf = f.get_result()\n+    buf = f.getvalue()\n \n     assert len(buf) == len(val) * K\n     assert buf.to_pybytes() == val * K\n@@ -554,7 +554,7 @@ def test_memory_output_stream():\n def test_inmemory_write_after_closed():\n     f = pa.BufferOutputStream()\n     f.write(b'ok')\n-    f.get_result()\n+    f.getvalue()\n \n     with pytest.raises(ValueError):\n         f.write(b'not ok')\n@@ -586,7 +586,7 @@ def test_nativefile_write_memoryview():\n     f.write(arr)\n     f.write(bytearray(data))\n \n-    buf = f.get_result()\n+    buf = f.getvalue()\n \n     assert buf.to_pybytes() == data * 2\n \n@@ -610,7 +610,7 @@ def test_mock_output_stream():\n         f1.write(val)\n         f2.write(val)\n \n-    assert f1.size() == len(f2.get_result())\n+    assert f1.size() == len(f2.getvalue())\n \n     # Do the same test with a pandas DataFrame\n     val = pd.DataFrame({'a': [1, 2, 3]})\n@@ -627,7 +627,7 @@ def test_mock_output_stream():\n     stream_writer1.close()\n     stream_writer2.close()\n \n-    assert f1.size() == len(f2.get_result())\n+    assert f1.size() == len(f2.getvalue())\n \n \n # ----------------------------------------------------------------------\ndiff --git a/python/pyarrow/tests/test_ipc.py b/python/pyarrow/tests/test_ipc.py\nindex a779fb2593..115d6bdbfe 100644\n--- a/python/pyarrow/tests/test_ipc.py\n+++ b/python/pyarrow/tests/test_ipc.py\n@@ -18,6 +18,7 @@\n import io\n import pytest\n import socket\n+import sys\n import threading\n \n import numpy as np\n@@ -26,19 +27,19 @@\n                                  assert_series_equal)\n import pandas as pd\n \n-from pyarrow.compat import unittest\n import pyarrow as pa\n \n \n-class MessagingTest(object):\n+class IpcFixture(object):\n \n-    def setUp(self):\n-        self.sink = self._get_sink()\n+    def __init__(self, sink_factory=lambda: io.BytesIO()):\n+        self._sink_factory = sink_factory\n+        self.sink = self.get_sink()\n \n-    def _get_sink(self):\n-        return io.BytesIO()\n+    def get_sink(self):\n+        return self._sink_factory()\n \n-    def _get_source(self):\n+    def get_source(self):\n         return self.sink.getvalue()\n \n     def write_batches(self, num_batches=5, as_table=False):\n@@ -70,20 +71,14 @@ def write_batches(self, num_batches=5, as_table=False):\n         return frames, batches\n \n \n-class TestFile(MessagingTest, unittest.TestCase):\n-    # Also tests writing zero-copy NumPy array with additional padding\n+class FileFormatFixture(IpcFixture):\n \n     def _get_writer(self, sink, schema):\n         return pa.RecordBatchFileWriter(sink, schema)\n \n-    def test_empty_file(self):\n-        buf = io.BytesIO(b'')\n-        with pytest.raises(pa.ArrowInvalid):\n-            pa.open_file(buf)\n-\n     def _check_roundtrip(self, as_table=False):\n         _, batches = self.write_batches(as_table=as_table)\n-        file_contents = pa.BufferReader(self._get_source())\n+        file_contents = pa.BufferReader(self.get_source())\n \n         reader = pa.open_file(file_contents)\n \n@@ -95,231 +90,333 @@ def _check_roundtrip(self, as_table=False):\n             assert batches[i].equals(batch)\n             assert reader.schema.equals(batches[0].schema)\n \n-    def test_simple_roundtrip(self):\n-        self._check_roundtrip(as_table=False)\n \n-    def test_write_table(self):\n-        self._check_roundtrip(as_table=True)\n+class StreamFormatFixture(IpcFixture):\n \n-    def test_read_all(self):\n-        _, batches = self.write_batches()\n-        file_contents = pa.BufferReader(self._get_source())\n+    def _get_writer(self, sink, schema):\n+        return pa.RecordBatchStreamWriter(sink, schema)\n \n-        reader = pa.open_file(file_contents)\n \n-        result = reader.read_all()\n-        expected = pa.Table.from_batches(batches)\n-        assert result.equals(expected)\n+class MessageFixture(IpcFixture):\n \n-    def test_read_pandas(self):\n-        frames, _ = self.write_batches()\n+    def _get_writer(self, sink, schema):\n+        return pa.RecordBatchStreamWriter(sink, schema)\n \n-        file_contents = pa.BufferReader(self._get_source())\n-        reader = pa.open_file(file_contents)\n-        result = reader.read_pandas()\n \n-        expected = pd.concat(frames)\n-        assert_frame_equal(result, expected)\n+@pytest.fixture\n+def ipc_fixture():\n+    return IpcFixture()\n \n \n-class TestStream(MessagingTest, unittest.TestCase):\n+@pytest.fixture\n+def file_fixture():\n+    return FileFormatFixture()\n \n-    def _get_writer(self, sink, schema):\n-        return pa.RecordBatchStreamWriter(sink, schema)\n \n-    def test_empty_stream(self):\n-        buf = io.BytesIO(b'')\n-        with pytest.raises(pa.ArrowInvalid):\n-            pa.open_stream(buf)\n+@pytest.fixture\n+def stream_fixture():\n+    return StreamFormatFixture()\n \n-    def test_categorical_roundtrip(self):\n-        df = pd.DataFrame({\n-            'one': np.random.randn(5),\n-            'two': pd.Categorical(['foo', np.nan, 'bar', 'foo', 'foo'],\n-                                  categories=['foo', 'bar'],\n-                                  ordered=True)\n-        })\n-        batch = pa.RecordBatch.from_pandas(df)\n-        writer = self._get_writer(self.sink, batch.schema)\n-        writer.write_batch(pa.RecordBatch.from_pandas(df))\n-        writer.close()\n \n-        table = (pa.open_stream(pa.BufferReader(self._get_source()))\n-                 .read_all())\n-        assert_frame_equal(table.to_pandas(), df)\n+def test_empty_file():\n+    buf = b''\n+    with pytest.raises(pa.ArrowInvalid):\n+        pa.open_file(pa.BufferReader(buf))\n \n-    def test_stream_write_dispatch(self):\n-        # ARROW-1616\n-        df = pd.DataFrame({\n-            'one': np.random.randn(5),\n-            'two': pd.Categorical(['foo', np.nan, 'bar', 'foo', 'foo'],\n-                                  categories=['foo', 'bar'],\n-                                  ordered=True)\n-        })\n-        table = pa.Table.from_pandas(df, preserve_index=False)\n-        batch = pa.RecordBatch.from_pandas(df, preserve_index=False)\n-        writer = self._get_writer(self.sink, table.schema)\n-        writer.write(table)\n-        writer.write(batch)\n-        writer.close()\n \n-        table = (pa.open_stream(pa.BufferReader(self._get_source()))\n-                 .read_all())\n-        assert_frame_equal(table.to_pandas(),\n-                           pd.concat([df, df], ignore_index=True))\n+def test_file_simple_roundtrip(file_fixture):\n+    file_fixture._check_roundtrip(as_table=False)\n \n-    def test_stream_write_table_batches(self):\n-        # ARROW-504\n-        df = pd.DataFrame({\n-            'one': np.random.randn(20),\n-        })\n \n-        b1 = pa.RecordBatch.from_pandas(df[:10], preserve_index=False)\n-        b2 = pa.RecordBatch.from_pandas(df, preserve_index=False)\n+def test_file_write_table(file_fixture):\n+    file_fixture._check_roundtrip(as_table=True)\n \n-        table = pa.Table.from_batches([b1, b2, b1])\n \n-        writer = self._get_writer(self.sink, table.schema)\n-        writer.write_table(table, chunksize=15)\n-        writer.close()\n+@pytest.mark.parametrize(\"sink_factory\", [\n+    lambda: io.BytesIO(),\n+    lambda: pa.BufferOutputStream()\n+])\n+def test_file_read_all(sink_factory):\n+    fixture = FileFormatFixture(sink_factory)\n \n-        batches = list(pa.open_stream(pa.BufferReader(self._get_source())))\n+    _, batches = fixture.write_batches()\n+    file_contents = pa.BufferReader(fixture.get_source())\n \n-        assert list(map(len, batches)) == [10, 15, 5, 10]\n-        result_table = pa.Table.from_batches(batches)\n-        assert_frame_equal(result_table.to_pandas(),\n-                           pd.concat([df[:10], df, df[:10]],\n-                                     ignore_index=True))\n+    reader = pa.open_file(file_contents)\n \n-    def test_simple_roundtrip(self):\n-        _, batches = self.write_batches()\n-        file_contents = pa.BufferReader(self._get_source())\n-        reader = pa.open_stream(file_contents)\n+    result = reader.read_all()\n+    expected = pa.Table.from_batches(batches)\n+    assert result.equals(expected)\n \n-        assert reader.schema.equals(batches[0].schema)\n \n-        total = 0\n-        for i, next_batch in enumerate(reader):\n-            assert next_batch.equals(batches[i])\n-            total += 1\n+def test_open_file_from_buffer(file_fixture):\n+    # ARROW-2859; APIs accept the buffer protocol\n+    _, batches = file_fixture.write_batches()\n+    source = file_fixture.get_source()\n \n-        assert total == len(batches)\n+    reader1 = pa.open_file(source)\n+    reader2 = pa.open_file(pa.BufferReader(source))\n+    reader3 = pa.RecordBatchFileReader(source)\n \n-        with pytest.raises(StopIteration):\n-            reader.get_next_batch()\n+    result1 = reader1.read_all()\n+    result2 = reader2.read_all()\n+    result3 = reader3.read_all()\n \n-    def test_read_all(self):\n-        _, batches = self.write_batches()\n-        file_contents = pa.BufferReader(self._get_source())\n-        reader = pa.open_stream(file_contents)\n+    assert result1.equals(result2)\n+    assert result1.equals(result3)\n \n-        result = reader.read_all()\n-        expected = pa.Table.from_batches(batches)\n-        assert result.equals(expected)\n \n+def test_file_read_pandas(file_fixture):\n+    frames, _ = file_fixture.write_batches()\n \n-class TestMessageReader(MessagingTest, unittest.TestCase):\n+    file_contents = pa.BufferReader(file_fixture.get_source())\n+    reader = pa.open_file(file_contents)\n+    result = reader.read_pandas()\n \n-    def _get_example_messages(self):\n-        _, batches = self.write_batches()\n-        file_contents = self._get_source()\n-        buf_reader = pa.BufferReader(file_contents)\n-        reader = pa.MessageReader.open_stream(buf_reader)\n-        return batches, list(reader)\n+    expected = pd.concat(frames)\n+    assert_frame_equal(result, expected)\n+\n+\n+@pytest.mark.skipif(sys.version_info < (3, 6),\n+                    reason=\"need Python 3.6\")\n+def test_file_pathlib(file_fixture, tmpdir):\n+    import pathlib\n+\n+    _, batches = file_fixture.write_batches()\n+    source = file_fixture.get_source()\n+\n+    path = tmpdir.join('file.arrow').strpath\n+    with open(path, 'wb') as f:\n+        f.write(source)\n+\n+    t1 = pa.open_file(pathlib.Path(path)).read_all()\n+    t2 = pa.open_file(pa.OSFile(path)).read_all()\n+\n+    assert t1.equals(t2)\n+\n+\n+def test_empty_stream():\n+    buf = io.BytesIO(b'')\n+    with pytest.raises(pa.ArrowInvalid):\n+        pa.open_stream(buf)\n+\n+\n+def test_stream_categorical_roundtrip(stream_fixture):\n+    df = pd.DataFrame({\n+        'one': np.random.randn(5),\n+        'two': pd.Categorical(['foo', np.nan, 'bar', 'foo', 'foo'],\n+                              categories=['foo', 'bar'],\n+                              ordered=True)\n+    })\n+    batch = pa.RecordBatch.from_pandas(df)\n+    writer = stream_fixture._get_writer(stream_fixture.sink, batch.schema)\n+    writer.write_batch(pa.RecordBatch.from_pandas(df))\n+    writer.close()\n+\n+    table = (pa.open_stream(pa.BufferReader(stream_fixture.get_source()))\n+             .read_all())\n+    assert_frame_equal(table.to_pandas(), df)\n+\n+\n+def test_open_stream_from_buffer(stream_fixture):\n+    # ARROW-2859\n+    _, batches = stream_fixture.write_batches()\n+    source = stream_fixture.get_source()\n+\n+    reader1 = pa.open_stream(source)\n+    reader2 = pa.open_stream(pa.BufferReader(source))\n+    reader3 = pa.RecordBatchStreamReader(source)\n+\n+    result1 = reader1.read_all()\n+    result2 = reader2.read_all()\n+    result3 = reader3.read_all()\n+\n+    assert result1.equals(result2)\n+    assert result1.equals(result3)\n+\n+\n+def test_stream_write_dispatch(stream_fixture):\n+    # ARROW-1616\n+    df = pd.DataFrame({\n+        'one': np.random.randn(5),\n+        'two': pd.Categorical(['foo', np.nan, 'bar', 'foo', 'foo'],\n+                              categories=['foo', 'bar'],\n+                              ordered=True)\n+    })\n+    table = pa.Table.from_pandas(df, preserve_index=False)\n+    batch = pa.RecordBatch.from_pandas(df, preserve_index=False)\n+    writer = stream_fixture._get_writer(stream_fixture.sink, table.schema)\n+    writer.write(table)\n+    writer.write(batch)\n+    writer.close()\n+\n+    table = (pa.open_stream(pa.BufferReader(stream_fixture.get_source()))\n+             .read_all())\n+    assert_frame_equal(table.to_pandas(),\n+                       pd.concat([df, df], ignore_index=True))\n \n-    def _get_writer(self, sink, schema):\n-        return pa.RecordBatchStreamWriter(sink, schema)\n \n-    def test_ctors_no_segfault(self):\n-        with pytest.raises(TypeError):\n-            repr(pa.Message())\n-\n-        with pytest.raises(TypeError):\n-            repr(pa.MessageReader())\n-\n-    def test_message_reader(self):\n-        _, messages = self._get_example_messages()\n-\n-        assert len(messages) == 6\n-        assert messages[0].type == 'schema'\n-        for msg in messages[1:]:\n-            assert msg.type == 'record batch'\n-\n-    def test_serialize_read_message(self):\n-        _, messages = self._get_example_messages()\n-\n-        msg = messages[0]\n-        buf = msg.serialize()\n-\n-        restored = pa.read_message(buf)\n-        restored2 = pa.read_message(pa.BufferReader(buf))\n-        restored3 = pa.read_message(buf.to_pybytes())\n-\n-        assert msg.equals(restored)\n-        assert msg.equals(restored2)\n-        assert msg.equals(restored3)\n-\n-    def test_read_record_batch(self):\n-        batches, messages = self._get_example_messages()\n-\n-        for batch, message in zip(batches, messages[1:]):\n-            read_batch = pa.read_record_batch(message, batch.schema)\n-            assert read_batch.equals(batch)\n-\n-    def test_read_pandas(self):\n-        frames, _ = self.write_batches()\n-        file_contents = pa.BufferReader(self._get_source())\n-        reader = pa.open_stream(file_contents)\n-        result = reader.read_pandas()\n-\n-        expected = pd.concat(frames)\n-        assert_frame_equal(result, expected)\n-\n-\n-class TestSocket(MessagingTest, unittest.TestCase):\n-\n-    class StreamReaderServer(threading.Thread):\n-\n-        def init(self, do_read_all):\n-            self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n-            self._sock.bind(('127.0.0.1', 0))\n-            self._sock.listen(1)\n-            host, port = self._sock.getsockname()\n-            self._do_read_all = do_read_all\n-            self._schema = None\n-            self._batches = []\n-            self._table = None\n-            return port\n-\n-        def run(self):\n-            connection, client_address = self._sock.accept()\n-            try:\n-                source = connection.makefile(mode='rb')\n-                reader = pa.open_stream(source)\n-                self._schema = reader.schema\n-                if self._do_read_all:\n-                    self._table = reader.read_all()\n-                else:\n-                    for i, batch in enumerate(reader):\n-                        self._batches.append(batch)\n-            finally:\n-                connection.close()\n-\n-        def get_result(self):\n-            return(self._schema, self._table if self._do_read_all\n-                   else self._batches)\n-\n-    def setUp(self):\n-        # NOTE: must start and stop server in test\n+def test_stream_write_table_batches(stream_fixture):\n+    # ARROW-504\n+    df = pd.DataFrame({\n+        'one': np.random.randn(20),\n+    })\n+\n+    b1 = pa.RecordBatch.from_pandas(df[:10], preserve_index=False)\n+    b2 = pa.RecordBatch.from_pandas(df, preserve_index=False)\n+\n+    table = pa.Table.from_batches([b1, b2, b1])\n+\n+    writer = stream_fixture._get_writer(stream_fixture.sink, table.schema)\n+    writer.write_table(table, chunksize=15)\n+    writer.close()\n+\n+    batches = list(pa.open_stream(stream_fixture.get_source()))\n+\n+    assert list(map(len, batches)) == [10, 15, 5, 10]\n+    result_table = pa.Table.from_batches(batches)\n+    assert_frame_equal(result_table.to_pandas(),\n+                       pd.concat([df[:10], df, df[:10]],\n+                                 ignore_index=True))\n+\n+\n+def test_stream_simple_roundtrip(stream_fixture):\n+    _, batches = stream_fixture.write_batches()\n+    file_contents = pa.BufferReader(stream_fixture.get_source())\n+    reader = pa.open_stream(file_contents)\n+\n+    assert reader.schema.equals(batches[0].schema)\n+\n+    total = 0\n+    for i, next_batch in enumerate(reader):\n+        assert next_batch.equals(batches[i])\n+        total += 1\n+\n+    assert total == len(batches)\n+\n+    with pytest.raises(StopIteration):\n+        reader.get_next_batch()\n+\n+\n+def test_stream_read_all(stream_fixture):\n+    _, batches = stream_fixture.write_batches()\n+    file_contents = pa.BufferReader(stream_fixture.get_source())\n+    reader = pa.open_stream(file_contents)\n+\n+    result = reader.read_all()\n+    expected = pa.Table.from_batches(batches)\n+    assert result.equals(expected)\n+\n+\n+def test_stream_read_pandas(stream_fixture):\n+    frames, _ = stream_fixture.write_batches()\n+    file_contents = stream_fixture.get_source()\n+    reader = pa.open_stream(file_contents)\n+    result = reader.read_pandas()\n+\n+    expected = pd.concat(frames)\n+    assert_frame_equal(result, expected)\n+\n+\n+@pytest.fixture\n+def example_messages(stream_fixture):\n+    _, batches = stream_fixture.write_batches()\n+    file_contents = stream_fixture.get_source()\n+    buf_reader = pa.BufferReader(file_contents)\n+    reader = pa.MessageReader.open_stream(buf_reader)\n+    return batches, list(reader)\n+\n+\n+def test_message_ctors_no_segfault():\n+    with pytest.raises(TypeError):\n+        repr(pa.Message())\n+\n+    with pytest.raises(TypeError):\n+        repr(pa.MessageReader())\n+\n+\n+def test_message_reader(example_messages):\n+    _, messages = example_messages\n+\n+    assert len(messages) == 6\n+    assert messages[0].type == 'schema'\n+    for msg in messages[1:]:\n+        assert msg.type == 'record batch'\n+\n+\n+def test_message_serialize_read_message(example_messages):\n+    _, messages = example_messages\n+\n+    msg = messages[0]\n+    buf = msg.serialize()\n+\n+    restored = pa.read_message(buf)\n+    restored2 = pa.read_message(pa.BufferReader(buf))\n+    restored3 = pa.read_message(buf.to_pybytes())\n+\n+    assert msg.equals(restored)\n+    assert msg.equals(restored2)\n+    assert msg.equals(restored3)\n+\n+\n+def test_message_read_record_batch(example_messages):\n+    batches, messages = example_messages\n+\n+    for batch, message in zip(batches, messages[1:]):\n+        read_batch = pa.read_record_batch(message, batch.schema)\n+        assert read_batch.equals(batch)\n+\n+\n+# ----------------------------------------------------------------------\n+# Socket streaming testa\n+\n+\n+class StreamReaderServer(threading.Thread):\n+\n+    def init(self, do_read_all):\n+        self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n+        self._sock.bind(('127.0.0.1', 0))\n+        self._sock.listen(1)\n+        host, port = self._sock.getsockname()\n+        self._do_read_all = do_read_all\n+        self._schema = None\n+        self._batches = []\n+        self._table = None\n+        return port\n+\n+    def run(self):\n+        connection, client_address = self._sock.accept()\n+        try:\n+            source = connection.makefile(mode='rb')\n+            reader = pa.open_stream(source)\n+            self._schema = reader.schema\n+            if self._do_read_all:\n+                self._table = reader.read_all()\n+            else:\n+                for i, batch in enumerate(reader):\n+                    self._batches.append(batch)\n+        finally:\n+            connection.close()\n+\n+    def get_result(self):\n+        return(self._schema, self._table if self._do_read_all\n+               else self._batches)\n+\n+\n+class SocketStreamFixture(IpcFixture):\n+\n+    def __init__(self):\n+        # XXX(wesm): test will decide when to start socket server. This should\n+        # probably be refactored\n         pass\n \n     def start_server(self, do_read_all):\n-        self._server = TestSocket.StreamReaderServer()\n+        self._server = StreamReaderServer()\n         port = self._server.init(do_read_all)\n         self._server.start()\n         self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n         self._sock.connect(('127.0.0.1', port))\n-        self.sink = self._get_sink()\n+        self.sink = self.get_sink()\n \n     def stop_and_get_result(self):\n         import struct\n@@ -329,38 +426,40 @@ def stop_and_get_result(self):\n         self._server.join()\n         return self._server.get_result()\n \n-    def _get_sink(self):\n+    def get_sink(self):\n         return self._sock.makefile(mode='wb')\n \n     def _get_writer(self, sink, schema):\n         return pa.RecordBatchStreamWriter(sink, schema)\n \n-    def test_simple_roundtrip(self):\n-        self.start_server(do_read_all=False)\n-        _, writer_batches = self.write_batches()\n-        reader_schema, reader_batches = self.stop_and_get_result()\n \n-        assert reader_schema.equals(writer_batches[0].schema)\n-        assert len(reader_batches) == len(writer_batches)\n-        for i, batch in enumerate(writer_batches):\n-            assert reader_batches[i].equals(batch)\n+@pytest.fixture\n+def socket_fixture():\n+    return SocketStreamFixture()\n+\n+\n+def test_socket_simple_roundtrip(socket_fixture):\n+    socket_fixture.start_server(do_read_all=False)\n+    _, writer_batches = socket_fixture.write_batches()\n+    reader_schema, reader_batches = socket_fixture.stop_and_get_result()\n \n-    def test_read_all(self):\n-        self.start_server(do_read_all=True)\n-        _, writer_batches = self.write_batches()\n-        _, result = self.stop_and_get_result()\n+    assert reader_schema.equals(writer_batches[0].schema)\n+    assert len(reader_batches) == len(writer_batches)\n+    for i, batch in enumerate(writer_batches):\n+        assert reader_batches[i].equals(batch)\n \n-        expected = pa.Table.from_batches(writer_batches)\n-        assert result.equals(expected)\n \n+def test_socket_read_all(socket_fixture):\n+    socket_fixture.start_server(do_read_all=True)\n+    _, writer_batches = socket_fixture.write_batches()\n+    _, result = socket_fixture.stop_and_get_result()\n \n-class TestInMemoryFile(TestFile):\n+    expected = pa.Table.from_batches(writer_batches)\n+    assert result.equals(expected)\n \n-    def _get_sink(self):\n-        return pa.BufferOutputStream()\n \n-    def _get_source(self):\n-        return self.sink.get_result()\n+# ----------------------------------------------------------------------\n+# Miscellaneous IPC tests\n \n \n def test_ipc_zero_copy_numpy():\n@@ -369,7 +468,7 @@ def test_ipc_zero_copy_numpy():\n     batch = pa.RecordBatch.from_pandas(df)\n     sink = pa.BufferOutputStream()\n     write_file(batch, sink)\n-    buffer = sink.get_result()\n+    buffer = sink.getvalue()\n     reader = pa.BufferReader(buffer)\n \n     batches = read_file(reader)\n@@ -389,7 +488,7 @@ def test_ipc_stream_no_batches():\n     writer = pa.RecordBatchStreamWriter(sink, table.schema)\n     writer.close()\n \n-    source = sink.get_result()\n+    source = sink.getvalue()\n     reader = pa.open_stream(source)\n     result = reader.read_all()\n \ndiff --git a/python/pyarrow/tests/test_parquet.py b/python/pyarrow/tests/test_parquet.py\nindex d7473e9035..1d30737aea 100644\n--- a/python/pyarrow/tests/test_parquet.py\n+++ b/python/pyarrow/tests/test_parquet.py\n@@ -396,7 +396,7 @@ def test_pandas_parquet_native_file_roundtrip(tmpdir):\n     arrow_table = pa.Table.from_pandas(df)\n     imos = pa.BufferOutputStream()\n     _write_table(arrow_table, imos, version=\"2.0\")\n-    buf = imos.get_result()\n+    buf = imos.getvalue()\n     reader = pa.BufferReader(buf)\n     df_read = _read_table(reader).to_pandas()\n     tm.assert_frame_equal(df, df_read)\n@@ -424,7 +424,7 @@ def test_parquet_incremental_file_build(tmpdir):\n \n     writer.close()\n \n-    buf = out.get_result()\n+    buf = out.getvalue()\n     result = _read_table(pa.BufferReader(buf))\n \n     expected = pd.concat(frames, ignore_index=True)\n@@ -439,7 +439,7 @@ def test_read_pandas_column_subset(tmpdir):\n     arrow_table = pa.Table.from_pandas(df)\n     imos = pa.BufferOutputStream()\n     _write_table(arrow_table, imos, version=\"2.0\")\n-    buf = imos.get_result()\n+    buf = imos.getvalue()\n     reader = pa.BufferReader(buf)\n     df_read = pq.read_pandas(reader, columns=['strings', 'uint8']).to_pandas()\n     tm.assert_frame_equal(df[['strings', 'uint8']], df_read)\n@@ -451,7 +451,7 @@ def test_pandas_parquet_empty_roundtrip(tmpdir):\n     arrow_table = pa.Table.from_pandas(df)\n     imos = pa.BufferOutputStream()\n     _write_table(arrow_table, imos, version=\"2.0\")\n-    buf = imos.get_result()\n+    buf = imos.getvalue()\n     reader = pa.BufferReader(buf)\n     df_read = _read_table(reader).to_pandas()\n     tm.assert_frame_equal(df, df_read)\n@@ -2108,7 +2108,7 @@ def test_parquet_writer_context_obj(tmpdir):\n \n             frames.append(df.copy())\n \n-    buf = out.get_result()\n+    buf = out.getvalue()\n     result = _read_table(pa.BufferReader(buf))\n \n     expected = pd.concat(frames, ignore_index=True)\n@@ -2143,7 +2143,7 @@ def test_parquet_writer_context_obj_with_exception(tmpdir):\n     except Exception as e:\n         assert str(e) == error_text\n \n-    buf = out.get_result()\n+    buf = out.getvalue()\n     result = _read_table(pa.BufferReader(buf))\n \n     expected = pd.concat(frames, ignore_index=True)\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-07-24T19:23:22.524+0000",
                    "updated": "2018-07-24T19:23:22.524+0000",
                    "started": "2018-07-24T19:23:22.524+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "126829",
                    "issueId": "13172517"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 5400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@6da2f348[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4809b24e[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1335a1d9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@16abea33[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@11a4ebc8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@413b71a7[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7f3e2b30[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@360dac96[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@c1eb34[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@1aed04c2[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1404cb04[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@4fb6ac0e[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 5400,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Jul 24 19:23:13 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-07-24T19:23:13.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2859/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2018-07-16T23:32:32.000+0000",
        "updated": "2018-07-24T19:23:22.000+0000",
        "timeoriginalestimate": null,
        "description": "I have hit this rough edge several times when doing interactive demos. If we can do so safely then this would improve usability",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "1.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 5400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Handle objects exporting the buffer protocol in open_stream, open_file, and RecordBatch*Reader APIs",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/comment/16546179",
                    "id": "16546179",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "On which methods is that?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2018-07-17T08:24:26.165+0000",
                    "updated": "2018-07-17T08:24:26.165+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172517/comment/16554700",
                    "id": "16554700",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 2314\n[https://github.com/apache/arrow/pull/2314]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-07-24T19:23:13.085+0000",
                    "updated": "2018-07-24T19:23:13.085+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|i3vyc7:",
        "customfield_12314139": null
    }
}