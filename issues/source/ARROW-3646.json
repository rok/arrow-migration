{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13194921",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921",
    "key": "ARROW-3646",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343858",
                "id": "12343858",
                "description": "",
                "name": "0.12.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-01-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343066",
                "id": "12343066",
                "description": "",
                "name": "0.11.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-10-08"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12547620",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12547620",
                "type": {
                    "id": "12310051",
                    "name": "Supercedes",
                    "inward": "is superceded by",
                    "outward": "supercedes",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310051"
                },
                "outwardIssue": {
                    "id": "13194843",
                    "key": "ARROW-3645",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194843",
                    "fields": {
                        "summary": "[Python] Document compression support in Sphinx",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "aggregateprogress": {
            "progress": 12000,
            "total": 12000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 12000,
            "total": 12000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3646/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 20,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/160686",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou opened a new pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873\n \n \n   Add the ``pa.input_stream`` and ``pa.output_stream`` factory functions.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-30T15:48:27.623+0000",
                    "updated": "2018-10-30T15:48:27.623+0000",
                    "started": "2018-10-30T15:48:27.622+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "160686",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/160729",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io commented on issue #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#issuecomment-434382513\n \n \n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/2873?src=pr&el=h1) Report\n   > Merging [#2873](https://codecov.io/gh/apache/arrow/pull/2873?src=pr&el=desc) into [master](https://codecov.io/gh/apache/arrow/commit/b5fafd81f48578c92e8118700457e82224aab13d?src=pr&el=desc) will **increase** coverage by `0.93%`.\n   > The diff coverage is `94.25%`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/2873/graphs/tree.svg?width=650&token=LpTCFbqVT1&height=150&src=pr)](https://codecov.io/gh/apache/arrow/pull/2873?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #2873      +/-   ##\n   ==========================================\n   + Coverage   87.55%   88.49%   +0.93%     \n   ==========================================\n     Files         411      348      -63     \n     Lines       63818    59819    -3999     \n   ==========================================\n   - Hits        55874    52935    -2939     \n   + Misses       7870     6884     -986     \n   + Partials       74        0      -74\n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/2873?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [python/pyarrow/\\_\\_init\\_\\_.py](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvX19pbml0X18ucHk=) | `69.23% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [python/pyarrow/compat.py](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvY29tcGF0LnB5) | `76.77% <100%> (+0.3%)` | :arrow_up: |\n   | [python/pyarrow/tests/test\\_io.py](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvdGVzdHMvdGVzdF9pby5weQ==) | `98.94% <100%> (+0.25%)` | :arrow_up: |\n   | [python/pyarrow/io.pxi](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-cHl0aG9uL3B5YXJyb3cvaW8ucHhp) | `65.64% <84.04%> (+2.69%)` | :arrow_up: |\n   | [rust/src/record\\_batch.rs](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-cnVzdC9zcmMvcmVjb3JkX2JhdGNoLnJz) | | |\n   | [go/arrow/array/table.go](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-Z28vYXJyb3cvYXJyYXkvdGFibGUuZ28=) | | |\n   | [rust/src/util/bit\\_util.rs](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-cnVzdC9zcmMvdXRpbC9iaXRfdXRpbC5ycw==) | | |\n   | [go/arrow/math/uint64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC91aW50NjRfYW1kNjQuZ28=) | | |\n   | [go/arrow/internal/testing/tools/bool.go](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-Z28vYXJyb3cvaW50ZXJuYWwvdGVzdGluZy90b29scy9ib29sLmdv) | | |\n   | [go/arrow/internal/bitutil/bitutil.go](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree#diff-Z28vYXJyb3cvaW50ZXJuYWwvYml0dXRpbC9iaXR1dGlsLmdv) | | |\n   | ... and [58 more](https://codecov.io/gh/apache/arrow/pull/2873/diff?src=pr&el=tree-more) | |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/2873?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/2873?src=pr&el=footer). Last update [b5fafd8...76a3eff](https://codecov.io/gh/apache/arrow/pull/2873?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-30T16:53:33.316+0000",
                    "updated": "2018-10-30T16:53:33.316+0000",
                    "started": "2018-10-30T16:53:33.316+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "160729",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163031",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231105633\n \n \n\n ##########\n File path: python/doc/source/memory.rst\n ##########\n @@ -70,11 +74,42 @@ required, and such conversions are also zero-copy:\n \n    memoryview(buf)\n \n-.. _io.native_file:\n-\n-Native Files\n+Memory Pools\n ------------\n \n+All memory allocations and deallocations (like ``malloc`` and ``free`` in C)\n+are tracked in an instance of ``arrow::MemoryPool``. This means that we can\n+then precisely track amount of memory that has been allocated:\n+\n+.. ipython:: python\n+\n+   pa.total_allocated_bytes()\n+\n+PyArrow uses a default built-in memory pool, but in the future there may be\n+additional memory pools (and subpools) to choose from.  Let's allocate\n \n Review comment:\n   ```suggestion\r\n   additional memory pools (and subpools) to choose from. Let's allocate\r\n   ```\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T12:37:15.434+0000",
                    "updated": "2018-11-06T12:37:15.434+0000",
                    "started": "2018-11-06T12:37:15.433+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163031",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163042",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231111753\n \n \n\n ##########\n File path: python/doc/source/memory.rst\n ##########\n @@ -70,11 +74,42 @@ required, and such conversions are also zero-copy:\n \n    memoryview(buf)\n \n-.. _io.native_file:\n-\n-Native Files\n+Memory Pools\n ------------\n \n+All memory allocations and deallocations (like ``malloc`` and ``free`` in C)\n+are tracked in an instance of ``arrow::MemoryPool``. This means that we can\n+then precisely track amount of memory that has been allocated:\n+\n+.. ipython:: python\n+\n+   pa.total_allocated_bytes()\n+\n+PyArrow uses a default built-in memory pool, but in the future there may be\n+additional memory pools (and subpools) to choose from.  Let's allocate\n \n Review comment:\n   Putting two spaces after a period is a [common convention](https://devguide.python.org/documenting/#use-of-whitespace). I'm not sure whether we have any guidelines on that. @wesm @xhochy \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T12:58:24.266+0000",
                    "updated": "2018-11-06T12:58:24.266+0000",
                    "started": "2018-11-06T12:58:24.265+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163042",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163043",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231112851\n \n \n\n ##########\n File path: python/pyarrow/tests/test_io.py\n ##########\n @@ -1050,3 +1055,218 @@ def test_compressed_roundtrip(compression):\n     with pa.CompressedInputStream(raw, compression) as compressed:\n         got = compressed.read()\n         assert got == data\n+\n+\n+# ----------------------------------------------------------------------\n+# High-level API\n+\n+if PY2:\n+    def gzip_compress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with gzip.GzipFile(fn, 'wb') as f:\n+                f.write(data)\n+            with open(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+\n+    def gzip_decompress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with open(fn, 'wb') as f:\n+                f.write(data)\n+            with gzip.GzipFile(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+else:\n+    gzip_compress = gzip.compress\n+    gzip_decompress = gzip.decompress\n+\n+\n+def test_input_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    for arg in [pa.py_buffer(data), memoryview(data)]:\n+        stream = pa.input_stream(arg)\n+        assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    stream = pa.input_stream(memoryview(gz_data))\n+    assert stream.read() == gz_data\n+    stream = pa.input_stream(memoryview(gz_data), compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_file_path(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'input_stream'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(data)\n+\n+    stream = pa.input_stream(file_path)\n+    assert stream.read() == data\n+    stream = pa.input_stream(str(file_path))\n+    assert stream.read() == data\n+    if pathlib is not None:\n \n Review comment:\n   Pathlib is already present in the testing suite https://github.com/apache/arrow/blob/e26806eeb4dcaa07b2f7dd7a7b3da2d0fdb42276/python/pyarrow/tests/conftest.py#L20-L23\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:02:16.601+0000",
                    "updated": "2018-11-06T13:02:16.601+0000",
                    "started": "2018-11-06T13:02:16.600+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163043",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163044",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231113161\n \n \n\n ##########\n File path: python/pyarrow/tests/test_io.py\n ##########\n @@ -1050,3 +1055,218 @@ def test_compressed_roundtrip(compression):\n     with pa.CompressedInputStream(raw, compression) as compressed:\n         got = compressed.read()\n         assert got == data\n+\n+\n+# ----------------------------------------------------------------------\n+# High-level API\n+\n+if PY2:\n+    def gzip_compress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with gzip.GzipFile(fn, 'wb') as f:\n+                f.write(data)\n+            with open(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+\n+    def gzip_decompress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with open(fn, 'wb') as f:\n+                f.write(data)\n+            with gzip.GzipFile(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+else:\n+    gzip_compress = gzip.compress\n+    gzip_decompress = gzip.decompress\n+\n+\n+def test_input_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    for arg in [pa.py_buffer(data), memoryview(data)]:\n+        stream = pa.input_stream(arg)\n+        assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    stream = pa.input_stream(memoryview(gz_data))\n+    assert stream.read() == gz_data\n+    stream = pa.input_stream(memoryview(gz_data), compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_file_path(tmpdir):\n \n Review comment:\n   Theres is a fixture called `tempdir` which is a `pathlib.Path` variant of pytest's `tmpdir` fixture.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:03:25.684+0000",
                    "updated": "2018-11-06T13:03:25.684+0000",
                    "started": "2018-11-06T13:03:25.684+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163044",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163045",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231113842\n \n \n\n ##########\n File path: python/pyarrow/tests/test_io.py\n ##########\n @@ -1050,3 +1055,218 @@ def test_compressed_roundtrip(compression):\n     with pa.CompressedInputStream(raw, compression) as compressed:\n         got = compressed.read()\n         assert got == data\n+\n+\n+# ----------------------------------------------------------------------\n+# High-level API\n+\n+if PY2:\n+    def gzip_compress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with gzip.GzipFile(fn, 'wb') as f:\n+                f.write(data)\n+            with open(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+\n+    def gzip_decompress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with open(fn, 'wb') as f:\n+                f.write(data)\n+            with gzip.GzipFile(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+else:\n+    gzip_compress = gzip.compress\n+    gzip_decompress = gzip.decompress\n+\n+\n+def test_input_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    for arg in [pa.py_buffer(data), memoryview(data)]:\n+        stream = pa.input_stream(arg)\n+        assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    stream = pa.input_stream(memoryview(gz_data))\n+    assert stream.read() == gz_data\n+    stream = pa.input_stream(memoryview(gz_data), compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_file_path(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'input_stream'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(data)\n+\n+    stream = pa.input_stream(file_path)\n+    assert stream.read() == data\n+    stream = pa.input_stream(str(file_path))\n+    assert stream.read() == data\n+    if pathlib is not None:\n \n Review comment:\n   Ok, I see.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:05:52.417+0000",
                    "updated": "2018-11-06T13:05:52.417+0000",
                    "started": "2018-11-06T13:05:52.416+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163045",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163046",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231113875\n \n \n\n ##########\n File path: python/pyarrow/tests/test_io.py\n ##########\n @@ -1050,3 +1055,218 @@ def test_compressed_roundtrip(compression):\n     with pa.CompressedInputStream(raw, compression) as compressed:\n         got = compressed.read()\n         assert got == data\n+\n+\n+# ----------------------------------------------------------------------\n+# High-level API\n+\n+if PY2:\n+    def gzip_compress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with gzip.GzipFile(fn, 'wb') as f:\n+                f.write(data)\n+            with open(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+\n+    def gzip_decompress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with open(fn, 'wb') as f:\n+                f.write(data)\n+            with gzip.GzipFile(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+else:\n+    gzip_compress = gzip.compress\n+    gzip_decompress = gzip.decompress\n+\n+\n+def test_input_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    for arg in [pa.py_buffer(data), memoryview(data)]:\n+        stream = pa.input_stream(arg)\n+        assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    stream = pa.input_stream(memoryview(gz_data))\n+    assert stream.read() == gz_data\n+    stream = pa.input_stream(memoryview(gz_data), compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_file_path(tmpdir):\n \n Review comment:\n   Yuck...\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:05:58.612+0000",
                    "updated": "2018-11-06T13:05:58.612+0000",
                    "started": "2018-11-06T13:05:58.611+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163046",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163048",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231114678\n \n \n\n ##########\n File path: python/pyarrow/io.pxi\n ##########\n @@ -1363,3 +1393,117 @@ def decompress(object buf, decompressed_size=None, codec='lz4',\n                                  output_size, output_buffer))\n \n     return pybuf if asbytes else out_buf\n+\n+\n+def input_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow input stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for reading\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly decompression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n+\n+    if isinstance(source, NativeFile):\n+        stream = source\n+    elif source_path is not None:\n+        stream = OSFile(source_path, 'r')\n+    elif isinstance(source, (Buffer, memoryview)):\n+        stream = BufferReader(as_buffer(source))\n+    elif isinstance(source, BufferedIOBase):\n+        if not source.readable():\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    elif file_type is not None and isinstance(source, file_type):\n+        # Python 2 file type\n+        if 'r' not in source.mode and '+' not in source.mode:\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    else:\n+        raise TypeError(\"pa.input_stream() called with instance of '{}'\"\n+                        .format(source.__class__))\n+\n+    if compression_type != CompressionType_UNCOMPRESSED:\n+        stream = CompressedInputStream.create(stream, compression_type)\n+\n+    return stream\n+\n+\n+def output_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow output stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for writing\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly compression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n+\n+    if isinstance(source, NativeFile):\n+        stream = source\n+    elif source_path is not None:\n+        stream = OSFile(source_path, 'w')\n+    elif isinstance(source, (Buffer, memoryview)):\n+        stream = FixedSizeBufferWriter(as_buffer(source))\n+    elif isinstance(source, BufferedIOBase):\n+        if not source.writable():\n+            raise TypeError(\"pa.output_stream() called with non-writable file\")\n+        stream = PythonFile(source, 'w')\n+    elif file_type is not None and isinstance(source, file_type):\n+        # Python 2 file type\n+        if 'w' not in source.mode and '+' not in source.mode:\n+            raise TypeError(\"pa.output_stream() called with non-writable file\")\n \n Review comment:\n   We should move this validation to `PythonFile`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:08:51.538+0000",
                    "updated": "2018-11-06T13:08:51.538+0000",
                    "started": "2018-11-06T13:08:51.538+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163048",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163049",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231116778\n \n \n\n ##########\n File path: python/pyarrow/io.pxi\n ##########\n @@ -1363,3 +1393,117 @@ def decompress(object buf, decompressed_size=None, codec='lz4',\n                                  output_size, output_buffer))\n \n     return pybuf if asbytes else out_buf\n+\n+\n+def input_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow input stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for reading\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly decompression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n+\n+    if isinstance(source, NativeFile):\n+        stream = source\n+    elif source_path is not None:\n+        stream = OSFile(source_path, 'r')\n+    elif isinstance(source, (Buffer, memoryview)):\n+        stream = BufferReader(as_buffer(source))\n+    elif isinstance(source, BufferedIOBase):\n+        if not source.readable():\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    elif file_type is not None and isinstance(source, file_type):\n+        # Python 2 file type\n+        if 'r' not in source.mode and '+' not in source.mode:\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    else:\n+        raise TypeError(\"pa.input_stream() called with instance of '{}'\"\n+                        .format(source.__class__))\n+\n+    if compression_type != CompressionType_UNCOMPRESSED:\n+        stream = CompressedInputStream.create(stream, compression_type)\n+\n+    return stream\n+\n+\n+def output_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow output stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for writing\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly compression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n \n Review comment:\n   The two implementation looks almost identical, could We factor out the common parts?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:15:47.853+0000",
                    "updated": "2018-11-06T13:15:47.853+0000",
                    "started": "2018-11-06T13:15:47.852+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163049",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163051",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231116778\n \n \n\n ##########\n File path: python/pyarrow/io.pxi\n ##########\n @@ -1363,3 +1393,117 @@ def decompress(object buf, decompressed_size=None, codec='lz4',\n                                  output_size, output_buffer))\n \n     return pybuf if asbytes else out_buf\n+\n+\n+def input_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow input stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for reading\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly decompression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n+\n+    if isinstance(source, NativeFile):\n+        stream = source\n+    elif source_path is not None:\n+        stream = OSFile(source_path, 'r')\n+    elif isinstance(source, (Buffer, memoryview)):\n+        stream = BufferReader(as_buffer(source))\n+    elif isinstance(source, BufferedIOBase):\n+        if not source.readable():\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    elif file_type is not None and isinstance(source, file_type):\n+        # Python 2 file type\n+        if 'r' not in source.mode and '+' not in source.mode:\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    else:\n+        raise TypeError(\"pa.input_stream() called with instance of '{}'\"\n+                        .format(source.__class__))\n+\n+    if compression_type != CompressionType_UNCOMPRESSED:\n+        stream = CompressedInputStream.create(stream, compression_type)\n+\n+    return stream\n+\n+\n+def output_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow output stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for writing\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly compression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n \n Review comment:\n   The two implementation looks almost identical (including compression detection and stream instantiation), could We factor out the common parts?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:16:42.723+0000",
                    "updated": "2018-11-06T13:16:42.723+0000",
                    "started": "2018-11-06T13:16:42.722+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163051",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163053",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231118038\n \n \n\n ##########\n File path: python/doc/source/memory.rst\n ##########\n @@ -70,11 +74,42 @@ required, and such conversions are also zero-copy:\n \n    memoryview(buf)\n \n-.. _io.native_file:\n-\n-Native Files\n+Memory Pools\n ------------\n \n+All memory allocations and deallocations (like ``malloc`` and ``free`` in C)\n+are tracked in an instance of ``arrow::MemoryPool``. This means that we can\n+then precisely track amount of memory that has been allocated:\n+\n+.. ipython:: python\n+\n+   pa.total_allocated_bytes()\n+\n+PyArrow uses a default built-in memory pool, but in the future there may be\n+additional memory pools (and subpools) to choose from.  Let's allocate\n \n Review comment:\n   It seems like both conventions are used in the rst docs.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:19:32.203+0000",
                    "updated": "2018-11-06T13:19:32.203+0000",
                    "started": "2018-11-06T13:19:32.202+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163053",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163054",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kszucs commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231118376\n \n \n\n ##########\n File path: python/pyarrow/tests/test_io.py\n ##########\n @@ -1050,3 +1055,218 @@ def test_compressed_roundtrip(compression):\n     with pa.CompressedInputStream(raw, compression) as compressed:\n         got = compressed.read()\n         assert got == data\n+\n+\n+# ----------------------------------------------------------------------\n+# High-level API\n+\n+if PY2:\n+    def gzip_compress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with gzip.GzipFile(fn, 'wb') as f:\n+                f.write(data)\n+            with open(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+\n+    def gzip_decompress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with open(fn, 'wb') as f:\n+                f.write(data)\n+            with gzip.GzipFile(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+else:\n+    gzip_compress = gzip.compress\n+    gzip_decompress = gzip.decompress\n+\n+\n+def test_input_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    for arg in [pa.py_buffer(data), memoryview(data)]:\n+        stream = pa.input_stream(arg)\n+        assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    stream = pa.input_stream(memoryview(gz_data))\n+    assert stream.read() == gz_data\n+    stream = pa.input_stream(memoryview(gz_data), compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_file_path(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'input_stream'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(data)\n+\n+    stream = pa.input_stream(file_path)\n+    assert stream.read() == data\n+    stream = pa.input_stream(str(file_path))\n+    assert stream.read() == data\n+    if pathlib is not None:\n+        stream = pa.input_stream(pathlib.Path(str(file_path)))\n+        assert stream.read() == data\n+\n+\n+def test_input_stream_file_path_compressed(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    gz_data = gzip_compress(data)\n+    file_path = tmpdir / 'input_stream.gz'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(gz_data)\n+\n+    stream = pa.input_stream(file_path)\n+    assert stream.read() == data\n+    stream = pa.input_stream(str(file_path))\n+    assert stream.read() == data\n+    if pathlib is not None:\n+        stream = pa.input_stream(pathlib.Path(str(file_path)))\n+        assert stream.read() == data\n+\n+    stream = pa.input_stream(file_path, compression='gzip')\n+    assert stream.read() == data\n+    stream = pa.input_stream(file_path, compression=None)\n+    assert stream.read() == gz_data\n+\n+\n+def test_input_stream_python_file(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    bio = BytesIO(data)\n+\n+    stream = pa.input_stream(bio)\n+    assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    bio = BytesIO(gz_data)\n+    stream = pa.input_stream(bio)\n+    assert stream.read() == gz_data\n+    bio.seek(0)\n+    stream = pa.input_stream(bio, compression='gzip')\n+    assert stream.read() == data\n+\n+    file_path = tmpdir / 'input_stream'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(data)\n+    with open(str(file_path), 'rb') as f:\n+        stream = pa.input_stream(f)\n+        assert stream.read() == data\n+\n+\n+def test_input_stream_native_file():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    gz_data = gzip_compress(data)\n+    reader = pa.BufferReader(gz_data)\n+    stream = pa.input_stream(reader)\n+    assert stream is reader\n+    reader = pa.BufferReader(gz_data)\n+    stream = pa.input_stream(reader, compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_errors(tmpdir):\n+    buf = memoryview(b\"\")\n+    with pytest.raises(ValueError):\n+        pa.input_stream(buf, compression=\"foo\")\n+\n+    for arg in [bytearray(), StringIO()]:\n+        with pytest.raises(TypeError):\n+            pa.input_stream(arg)\n+\n+    with pytest.raises(IOError):\n+        pa.input_stream(\"non_existent_file\")\n+\n+    with open(str(tmpdir / 'new_file'), 'wb') as f:\n+        with pytest.raises(TypeError, match=\"called with non-readable file\"):\n+            pa.input_stream(f)\n+\n+\n+def test_output_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    buf = bytearray(len(data))\n+    stream = pa.output_stream(pa.py_buffer(buf))\n+    stream.write(data)\n+    assert buf == data\n+\n+    buf = bytearray(len(data))\n+    stream = pa.output_stream(memoryview(buf))\n+    stream.write(data)\n+    assert buf == data\n+\n+\n+def test_output_stream_file_path(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'output_stream'\n+\n+    def check_data(file_path, data):\n+        with pa.output_stream(file_path) as stream:\n+            stream.write(data)\n+        with open(str(file_path), 'rb') as f:\n+            assert f.read() == data\n+\n+    check_data(file_path, data)\n+    check_data(str(file_path), data)\n+    if pathlib is not None:\n+        check_data(pathlib.Path(str(file_path)), data)\n+\n+\n+def test_output_stream_file_path_compressed(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'output_stream.gz'\n+\n+    def check_data(file_path, data, **kwargs):\n+        with pa.output_stream(file_path, **kwargs) as stream:\n+            stream.write(data)\n+        with open(str(file_path), 'rb') as f:\n+            return f.read()\n+\n+    assert gzip_decompress(check_data(file_path, data)) == data\n+    assert gzip_decompress(check_data(str(file_path), data)) == data\n+    if pathlib is not None:\n+        assert gzip_decompress(\n+            check_data(pathlib.Path(str(file_path)), data)) == data\n+\n+    assert gzip_decompress(\n+        check_data(file_path, data, compression='gzip')) == data\n+    assert check_data(file_path, data, compression=None) == data\n+\n+\n+def test_output_stream_python_file(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+\n+    def check_data(data, **kwargs):\n+        # XXX cannot use BytesIO because stream.close() is necessary\n+        # to finish writing compressed data, but it will also close the\n+        # underlying BytesiO\n \n Review comment:\n   Typo `BytesIO`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T13:20:37.235+0000",
                    "updated": "2018-11-06T13:20:37.235+0000",
                    "started": "2018-11-06T13:20:37.234+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163054",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163083",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231150889\n \n \n\n ##########\n File path: python/pyarrow/io.pxi\n ##########\n @@ -1363,3 +1393,117 @@ def decompress(object buf, decompressed_size=None, codec='lz4',\n                                  output_size, output_buffer))\n \n     return pybuf if asbytes else out_buf\n+\n+\n+def input_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow input stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for reading\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly decompression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n+\n+    if isinstance(source, NativeFile):\n+        stream = source\n+    elif source_path is not None:\n+        stream = OSFile(source_path, 'r')\n+    elif isinstance(source, (Buffer, memoryview)):\n+        stream = BufferReader(as_buffer(source))\n+    elif isinstance(source, BufferedIOBase):\n+        if not source.readable():\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    elif file_type is not None and isinstance(source, file_type):\n+        # Python 2 file type\n+        if 'r' not in source.mode and '+' not in source.mode:\n+            raise TypeError(\"pa.input_stream() called with non-readable file\")\n+        stream = PythonFile(source, 'r')\n+    else:\n+        raise TypeError(\"pa.input_stream() called with instance of '{}'\"\n+                        .format(source.__class__))\n+\n+    if compression_type != CompressionType_UNCOMPRESSED:\n+        stream = CompressedInputStream.create(stream, compression_type)\n+\n+    return stream\n+\n+\n+def output_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow output stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for writing\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly compression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    if compression == 'detect':\n+        if source_path is not None:\n+            compression_type = _get_compression_type_by_filename(source_path)\n+        else:\n+            compression_type = CompressionType_UNCOMPRESSED\n+    else:\n+        compression_type = _get_compression_type(compression)\n \n Review comment:\n   Stream instantiation is slightly different. We could still factor output compression detection.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T14:49:08.869+0000",
                    "updated": "2018-11-06T14:49:08.869+0000",
                    "started": "2018-11-06T14:49:08.868+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163083",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163087",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#discussion_r231156820\n \n \n\n ##########\n File path: python/doc/source/memory.rst\n ##########\n @@ -70,11 +74,42 @@ required, and such conversions are also zero-copy:\n \n    memoryview(buf)\n \n-.. _io.native_file:\n-\n-Native Files\n+Memory Pools\n ------------\n \n+All memory allocations and deallocations (like ``malloc`` and ``free`` in C)\n+are tracked in an instance of ``arrow::MemoryPool``. This means that we can\n+then precisely track amount of memory that has been allocated:\n+\n+.. ipython:: python\n+\n+   pa.total_allocated_bytes()\n+\n+PyArrow uses a default built-in memory pool, but in the future there may be\n+additional memory pools (and subpools) to choose from.  Let's allocate\n \n Review comment:\n   AP Stylebook for journalism today is 1 space. 2 spaces seems to be a remnant of the typewriter era \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-06T15:02:40.843+0000",
                    "updated": "2018-11-06T15:02:40.843+0000",
                    "started": "2018-11-06T15:02:40.843+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163087",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163500",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou closed pull request #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/python/doc/source/api.rst b/python/doc/source/api.rst\nindex 69534e61f1..caa2d65d82 100644\n--- a/python/doc/source/api.rst\n+++ b/python/doc/source/api.rst\n@@ -204,8 +204,8 @@ Tensor type and Functions\n \n .. _api.io:\n \n-Input / Output and Shared Memory\n---------------------------------\n+In-Memory Buffers\n+-----------------\n \n .. autosummary::\n    :toctree: generated/\n@@ -217,10 +217,23 @@ Input / Output and Shared Memory\n    foreign_buffer\n    Buffer\n    ResizableBuffer\n+\n+Input / Output and Shared Memory\n+--------------------------------\n+\n+.. autosummary::\n+   :toctree: generated/\n+\n+   input_stream\n+   output_stream\n    BufferReader\n    BufferOutputStream\n+   FixedSizeBufferWriter\n    NativeFile\n+   OSFile\n    MemoryMappedFile\n+   CompressedInputStream\n+   CompressedOutputStream\n    memory_map\n    create_memory_map\n    PythonFile\ndiff --git a/python/doc/source/memory.rst b/python/doc/source/memory.rst\nindex 8fcf5f548e..1ee81e754d 100644\n--- a/python/doc/source/memory.rst\n+++ b/python/doc/source/memory.rst\n@@ -18,6 +18,7 @@\n .. currentmodule:: pyarrow\n .. _io:\n \n+========================\n Memory and IO Interfaces\n ========================\n \n@@ -25,8 +26,11 @@ This section will introduce you to the major concepts in PyArrow's memory\n management and IO systems:\n \n * Buffers\n-* File-like and stream-like objects\n * Memory pools\n+* File-like and stream-like objects\n+\n+Referencing and Allocating Memory\n+=================================\n \n pyarrow.Buffer\n --------------\n@@ -70,11 +74,42 @@ required, and such conversions are also zero-copy:\n \n    memoryview(buf)\n \n-.. _io.native_file:\n-\n-Native Files\n+Memory Pools\n ------------\n \n+All memory allocations and deallocations (like ``malloc`` and ``free`` in C)\n+are tracked in an instance of ``arrow::MemoryPool``. This means that we can\n+then precisely track amount of memory that has been allocated:\n+\n+.. ipython:: python\n+\n+   pa.total_allocated_bytes()\n+\n+PyArrow uses a default built-in memory pool, but in the future there may be\n+additional memory pools (and subpools) to choose from. Let's allocate\n+a resizable ``Buffer`` from the default pool:\n+\n+.. ipython:: python\n+\n+   buf = pa.allocate_buffer(1024, resizable=True)\n+   pa.total_allocated_bytes()\n+   buf.resize(2048)\n+   pa.total_allocated_bytes()\n+\n+The default allocator requests memory in a minimum increment of 64 bytes. If\n+the buffer is garbaged-collected, all of the memory is freed:\n+\n+.. ipython:: python\n+\n+   buf = None\n+   pa.total_allocated_bytes()\n+\n+\n+Input and Output\n+================\n+\n+.. _io.native_file:\n+\n The Arrow C++ libraries have several abstract interfaces for different kinds of\n IO objects:\n \n@@ -86,8 +121,7 @@ IO objects:\n \n In the interest of making these objects behave more like Python's built-in\n ``file`` objects, we have defined a :class:`~pyarrow.NativeFile` base class\n-which is intended to mimic Python files and able to be used in functions where\n-a Python file (such as ``file`` or ``BytesIO``) is expected.\n+which implements the same API as regular Python file objects.\n \n :class:`~pyarrow.NativeFile` has some important features which make it\n preferable to using Python files with PyArrow where possible:\n@@ -106,41 +140,70 @@ There are several kinds of :class:`~pyarrow.NativeFile` options available:\n   as a file\n * :class:`~pyarrow.BufferOutputStream`, for writing data in-memory, producing a\n   Buffer at the end\n+* :class:`~pyarrow.FixedSizeBufferWriter`, for writing data into an already\n+  allocated Buffer\n * :class:`~pyarrow.HdfsFile`, for reading and writing data to the Hadoop Filesystem\n * :class:`~pyarrow.PythonFile`, for interfacing with Python file objects in C++\n+* :class:`~pyarrow.CompressedInputStream` and\n+  :class:`~pyarrow.CompressedOutputStream`, for on-the-fly compression or\n+  decompression to/from another stream\n \n-We will discuss these in the following sections after explaining memory pools.\n+There are also high-level APIs to make instantiating common kinds of streams\n+easier.\n \n-Memory Pools\n-------------\n+High-Level API\n+--------------\n \n-All memory allocations and deallocations (like ``malloc`` and ``free`` in C)\n-are tracked in an instance of ``arrow::MemoryPool``. This means that we can\n-then precisely track amount of memory that has been allocated:\n+Input Streams\n+~~~~~~~~~~~~~\n \n-.. ipython:: python\n+The :func:`~pyarrow.input_stream` function allows creating a readable\n+:class:`~pyarrow.NativeFile` from various kinds of sources.\n \n-   pa.total_allocated_bytes()\n+* If passed a :class:`~pyarrow.Buffer` or a ``memoryview`` object, a\n+  :class:`~pyarrow.BufferReader` will be returned:\n \n-PyArrow uses a default built-in memory pool, but in the future there may be\n-additional memory pools (and subpools) to choose from. Let's consider an\n-``BufferOutputStream``, which is like a ``BytesIO``:\n+   .. ipython:: python\n \n-.. ipython:: python\n+      buf = memoryview(b\"some data\")\n+      stream = pa.input_stream(buf)\n+      stream.read(4)\n \n-   stream = pa.BufferOutputStream()\n-   stream.write(b'foo')\n-   pa.total_allocated_bytes()\n-   for i in range(1024): stream.write(b'foo')\n-   pa.total_allocated_bytes()\n+* If passed a string or file path, it will open the given file on disk\n+  for reading, creating a :class:`~pyarrow.OSFile`.  Optionally, the file\n+  can be compressed: if its filename ends with a recognized extension\n+  such as ``.gz``, its contents will automatically be decompressed on\n+  reading.\n \n-The default allocator requests memory in a minimum increment of 64 bytes. If\n-the stream is garbaged-collected, all of the memory is freed:\n+  .. ipython:: python\n+\n+     import gzip\n+     with gzip.open('example.gz', 'wb') as f:\n+         f.write(b'some data\\n' * 3)\n+\n+     stream = pa.input_stream('example.gz')\n+     stream.read()\n+\n+* If passed a Python file object, it will wrapped in a :class:`PythonFile`\n+  such that the Arrow C++ libraries can read data from it (at the expense\n+  of a slight overhead).\n+\n+Output Streams\n+~~~~~~~~~~~~~~\n+\n+:func:`~pyarrow.output_stream` is the equivalent function for output streams\n+and allows creating a writable :class:`~pyarrow.NativeFile`.  It has the same\n+features as explained above for :func:`~pyarrow.input_stream`, such as being\n+able to write to buffers or do on-the-fly compression.\n \n .. ipython:: python\n \n-   stream = None\n-   pa.total_allocated_bytes()\n+   with pa.output_stream('example1.dat') as stream:\n+       stream.write(b'some data')\n+\n+   f = open('example1.dat', 'rb')\n+   f.read()\n+\n \n On-Disk and Memory Mapped Files\n -------------------------------\n@@ -151,17 +214,17 @@ write:\n \n .. ipython:: python\n \n-   with open('example.dat', 'wb') as f:\n+   with open('example2.dat', 'wb') as f:\n        f.write(b'some example data')\n \n Using pyarrow's :class:`~pyarrow.OSFile` class, you can write:\n \n .. ipython:: python\n \n-   with pa.OSFile('example2.dat', 'wb') as f:\n+   with pa.OSFile('example3.dat', 'wb') as f:\n        f.write(b'some example data')\n \n-For reading files, you can use ``OSFile`` or\n+For reading files, you can use :class:`~pyarrow.OSFile` or\n :class:`~pyarrow.MemoryMappedFile`. The difference between these is that\n :class:`~pyarrow.OSFile` allocates new memory on each read, like Python file\n objects. In reads from memory maps, the library constructs a buffer referencing\n@@ -169,8 +232,8 @@ the mapped memory without any memory allocation or copying:\n \n .. ipython:: python\n \n-   file_obj = pa.OSFile('example.dat')\n-   mmap = pa.memory_map('example.dat')\n+   file_obj = pa.OSFile('example2.dat')\n+   mmap = pa.memory_map('example3.dat')\n    file_obj.read(4)\n    mmap.read(4)\n \ndiff --git a/python/pyarrow/__init__.py b/python/pyarrow/__init__.py\nindex 558cf46ac8..12c2285f2d 100644\n--- a/python/pyarrow/__init__.py\n+++ b/python/pyarrow/__init__.py\n@@ -101,17 +101,19 @@ def parse_git(root, **kwargs):\n                          default_memory_pool, logging_memory_pool,\n                          proxy_memory_pool, log_memory_allocations)\n \n+# I/O\n from pyarrow.lib import (HdfsFile, NativeFile, PythonFile,\n                          CompressedInputStream, CompressedOutputStream,\n                          FixedSizeBufferWriter,\n                          BufferReader, BufferOutputStream,\n                          OSFile, MemoryMappedFile, memory_map,\n                          create_memory_map, have_libhdfs, have_libhdfs3,\n-                         MockOutputStream)\n+                         MockOutputStream, input_stream, output_stream)\n \n from pyarrow.lib import (ChunkedArray, Column, RecordBatch, Table,\n                          concat_tables)\n \n+# Exceptions\n from pyarrow.lib import (ArrowException,\n                          ArrowKeyError,\n                          ArrowInvalid,\ndiff --git a/python/pyarrow/compat.py b/python/pyarrow/compat.py\nindex 16e8ce6237..a481db0d53 100644\n--- a/python/pyarrow/compat.py\n+++ b/python/pyarrow/compat.py\n@@ -78,6 +78,7 @@ class Categorical(ClassPlaceholder):\n         from decimal import Decimal\n \n     unicode_type = unicode\n+    file_type = file\n     lzip = zip\n     zip = itertools.izip\n     zip_longest = itertools.izip_longest\n@@ -113,6 +114,7 @@ def unichar(s):\n         import pickle as builtin_pickle\n \n     unicode_type = str\n+    file_type = None\n     def lzip(*x):\n         return list(zip(*x))\n     long = int\ndiff --git a/python/pyarrow/io.pxi b/python/pyarrow/io.pxi\nindex 1c74caf738..9f7dc7bc83 100644\n--- a/python/pyarrow/io.pxi\n+++ b/python/pyarrow/io.pxi\n@@ -26,10 +26,11 @@ import sys\n import threading\n import time\n import warnings\n-from io import BufferedIOBase, UnsupportedOperation\n+from io import BufferedIOBase, IOBase, UnsupportedOperation\n \n from pyarrow.util import _stringify_path\n-from pyarrow.compat import builtin_pickle, frombytes, tobytes, encode_file_path\n+from pyarrow.compat import (\n+    builtin_pickle, frombytes, tobytes, encode_file_path, file_type)\n \n \n # 64K\n@@ -566,26 +567,54 @@ cdef class PythonFile(NativeFile):\n \n         if mode is None:\n             try:\n-                mode = handle.mode\n+                inferred_mode = handle.mode\n             except AttributeError:\n                 # Not all file-like objects have a mode attribute\n                 # (e.g. BytesIO)\n                 try:\n-                    mode = 'w' if handle.writable() else 'r'\n+                    inferred_mode = 'w' if handle.writable() else 'r'\n                 except AttributeError:\n                     raise ValueError(\"could not infer open mode for file-like \"\n                                      \"object %r, please pass it explicitly\"\n                                      % (handle,))\n-        if mode.startswith('w'):\n-            self.set_output_stream(\n-                shared_ptr[OutputStream](new PyOutputStream(handle)))\n-            self.is_writable = True\n-        elif mode.startswith('r'):\n+        else:\n+            inferred_mode = mode\n+\n+        if inferred_mode.startswith('w'):\n+            kind = 'w'\n+        elif inferred_mode.startswith('r'):\n+            kind = 'r'\n+        else:\n+            raise ValueError('Invalid file mode: {0}'.format(mode))\n+\n+        # If mode was given, check it matches the given file\n+        if mode is not None:\n+            if isinstance(handle, IOBase):\n+                # Python 3 IO object\n+                if kind == 'r':\n+                    if not handle.readable():\n+                        raise TypeError(\"readable file expected\")\n+                else:\n+                    if not handle.writable():\n+                        raise TypeError(\"writable file expected\")\n+            elif file_type is not None and isinstance(handle, file_type):\n+                # Python 2 file type\n+                if kind == 'r':\n+                    if 'r' not in handle.mode and '+' not in handle.mode:\n+                        raise TypeError(\"readable file expected\")\n+                else:\n+                    if 'w' not in handle.mode and '+' not in handle.mode:\n+                        raise TypeError(\"writable file expected\")\n+            # (other duck-typed file-like objects are possible)\n+\n+        if kind == 'r':\n             self.set_random_access_file(\n                 shared_ptr[RandomAccessFile](new PyReadableFile(handle)))\n             self.is_readable = True\n         else:\n-            raise ValueError('Invalid file mode: {0}'.format(mode))\n+            self.set_output_stream(\n+                shared_ptr[OutputStream](new PyOutputStream(handle)))\n+            self.is_writable = True\n \n     def truncate(self, pos=None):\n         self.handle.truncate(pos)\n@@ -1029,17 +1058,38 @@ cdef class BufferReader(NativeFile):\n         Buffer buffer\n \n     def __cinit__(self, object obj):\n-\n-        if isinstance(obj, Buffer):\n-            self.buffer = obj\n-        else:\n-            self.buffer = py_buffer(obj)\n-\n+        self.buffer = as_buffer(obj)\n         self.set_random_access_file(shared_ptr[RandomAccessFile](\n             new CBufferReader(self.buffer.buffer)))\n         self.is_readable = True\n \n \n+cdef shared_ptr[InputStream] _make_compressed_input_stream(\n+        shared_ptr[InputStream] stream,\n+        CompressionType compression_type) except *:\n+    cdef:\n+        shared_ptr[CCompressedInputStream] compressed_stream\n+        unique_ptr[CCodec] codec\n+\n+    check_status(CCodec.Create(compression_type, &codec))\n+    check_status(CCompressedInputStream.Make(codec.get(), stream,\n+                                             &compressed_stream))\n+    return <shared_ptr[InputStream]> compressed_stream\n+\n+\n+cdef shared_ptr[OutputStream] _make_compressed_output_stream(\n+        shared_ptr[OutputStream] stream,\n+        CompressionType compression_type) except *:\n+    cdef:\n+        shared_ptr[CCompressedOutputStream] compressed_stream\n+        unique_ptr[CCodec] codec\n+\n+    check_status(CCodec.Create(compression_type, &codec))\n+    check_status(CCompressedOutputStream.Make(codec.get(), stream,\n+                                              &compressed_stream))\n+    return <shared_ptr[OutputStream]> compressed_stream\n+\n+\n cdef class CompressedInputStream(NativeFile):\n     \"\"\"\n     An input stream wrapper which decompresses data on the fly.\n@@ -1051,22 +1101,29 @@ cdef class CompressedInputStream(NativeFile):\n         The compression type (\"bz2\", \"brotli\", \"gzip\", \"lz4\", \"snappy\"\n         or \"zstd\")\n     \"\"\"\n-    def __cinit__(self, NativeFile stream, compression):\n+    def __init__(self, NativeFile stream, compression):\n         cdef:\n             CompressionType compression_type\n-            shared_ptr[CCompressedInputStream] compressed_stream\n-            unique_ptr[CCodec] codec\n \n         compression_type = _get_compression_type(compression)\n         if compression_type == CompressionType_UNCOMPRESSED:\n             raise ValueError(\"Invalid value for compression: %r\"\n                              % (compression,))\n+        self._init(stream, compression_type)\n+\n+    @staticmethod\n+    cdef create(NativeFile stream, CompressionType compression_type):\n+        cdef:\n+            CompressedInputStream self\n \n-        check_status(CCodec.Create(compression_type, &codec))\n-        check_status(CCompressedInputStream.Make(codec.get(),\n-                                                 stream.get_input_stream(),\n-                                                 &compressed_stream))\n-        self.set_input_stream(<shared_ptr[InputStream]> compressed_stream)\n+        self = CompressedInputStream.__new__(CompressedInputStream)\n+        self._init(stream, compression_type)\n+        return self\n+\n+    cdef _init(self, NativeFile stream, CompressionType compression_type):\n+        self.set_input_stream(\n+            _make_compressed_input_stream(stream.get_input_stream(),\n+                                          compression_type))\n         self.is_readable = True\n \n \n@@ -1081,28 +1138,35 @@ cdef class CompressedOutputStream(NativeFile):\n         The compression type (\"bz2\", \"brotli\", \"gzip\", \"lz4\", \"snappy\"\n         or \"zstd\")\n     \"\"\"\n-    def __cinit__(self, NativeFile stream, compression):\n+    def __init__(self, NativeFile stream, compression):\n         cdef:\n             CompressionType compression_type\n-            shared_ptr[CCompressedOutputStream] compressed_stream\n-            unique_ptr[CCodec] codec\n \n         compression_type = _get_compression_type(compression)\n         if compression_type == CompressionType_UNCOMPRESSED:\n             raise ValueError(\"Invalid value for compression: %r\"\n                              % (compression,))\n+        self._init(stream, compression_type)\n+\n+    @staticmethod\n+    cdef create(NativeFile stream, CompressionType compression_type):\n+        cdef:\n+            CompressedOutputStream self\n \n-        check_status(CCodec.Create(compression_type, &codec))\n-        check_status(CCompressedOutputStream.Make(codec.get(),\n-                                                  stream.get_output_stream(),\n-                                                  &compressed_stream))\n-        self.set_output_stream(<shared_ptr[OutputStream]> compressed_stream)\n+        self = CompressedOutputStream.__new__(CompressedOutputStream)\n+        self._init(stream, compression_type)\n+        return self\n+\n+    cdef _init(self, NativeFile stream, CompressionType compression_type):\n+        self.set_output_stream(\n+            _make_compressed_output_stream(stream.get_output_stream(),\n+                                           compression_type))\n         self.is_writable = True\n \n \n def py_buffer(object obj):\n     \"\"\"\n-    Construct an Arrow buffer from a Python bytes object\n+    Construct an Arrow buffer from a Python bytes-like or buffer-like object\n     \"\"\"\n     cdef shared_ptr[CBuffer] buf\n     check_status(PyBuffer.FromPyObject(obj, &buf))\n@@ -1180,10 +1244,8 @@ cdef get_input_stream(object source, c_bool use_memory_map,\n     input_stream = nf.get_input_stream()\n \n     if compression_type != CompressionType_UNCOMPRESSED:\n-        check_status(CCodec.Create(compression_type, &codec))\n-        check_status(CCompressedInputStream.Make(codec.get(), input_stream,\n-                                                 &compressed_stream))\n-        input_stream = <shared_ptr[InputStream]> compressed_stream\n+        input_stream = _make_compressed_input_stream(input_stream,\n+                                                     compression_type)\n \n     out[0] = input_stream\n \n@@ -1210,7 +1272,7 @@ cdef get_writer(object source, shared_ptr[OutputStream]* writer):\n \n # ---------------------------------------------------------------------\n \n-cdef CompressionType _get_compression_type(object name):\n+cdef CompressionType _get_compression_type(object name) except *:\n     if name is None or name == 'uncompressed':\n         return CompressionType_UNCOMPRESSED\n     elif name == 'bz2':\n@@ -1230,7 +1292,7 @@ cdef CompressionType _get_compression_type(object name):\n                          .format(str(name)))\n \n \n-cdef CompressionType _get_compression_type_by_filename(filename):\n+cdef CompressionType _get_compression_type_by_filename(filename) except *:\n     if filename.endswith('.bz2'):\n         return CompressionType_BZ2\n     elif filename.endswith('.gz'):\n@@ -1273,9 +1335,7 @@ def compress(object buf, codec='lz4', asbytes=False, memory_pool=None):\n     with nogil:\n         check_status(CCodec.Create(c_codec, &compressor))\n \n-    if not isinstance(buf, Buffer):\n-        buf = py_buffer(buf)\n-\n+    buf = as_buffer(buf)\n     c_buf = (<Buffer> buf).buffer.get()\n \n     cdef int64_t max_output_size = (compressor.get()\n@@ -1338,9 +1398,7 @@ def decompress(object buf, decompressed_size=None, codec='lz4',\n     with nogil:\n         check_status(CCodec.Create(c_codec, &compressor))\n \n-    if not isinstance(buf, Buffer):\n-        buf = py_buffer(buf)\n-\n+    buf = as_buffer(buf)\n     c_buf = (<Buffer> buf).buffer.get()\n \n     if decompressed_size is None:\n@@ -1363,3 +1421,108 @@ def decompress(object buf, decompressed_size=None, codec='lz4',\n                                  output_size, output_buffer))\n \n     return pybuf if asbytes else out_buf\n+\n+\n+cdef CompressionType _stream_compression_argument(\n+        compression, source_path) except *:\n+    if compression == 'detect':\n+        if source_path is not None:\n+            return _get_compression_type_by_filename(source_path)\n+        else:\n+            return CompressionType_UNCOMPRESSED\n+    else:\n+        return _get_compression_type(compression)\n+\n+\n+def input_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow input stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for reading\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly decompression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    compression_type = _stream_compression_argument(compression, source_path)\n+\n+    if isinstance(source, NativeFile):\n+        stream = source\n+    elif source_path is not None:\n+        stream = OSFile(source_path, 'r')\n+    elif isinstance(source, (Buffer, memoryview)):\n+        stream = BufferReader(as_buffer(source))\n+    elif isinstance(source, BufferedIOBase):\n+        stream = PythonFile(source, 'r')\n+    elif file_type is not None and isinstance(source, file_type):\n+        # Python 2 file type\n+        stream = PythonFile(source, 'r')\n+    else:\n+        raise TypeError(\"pa.input_stream() called with instance of '{}'\"\n+                        .format(source.__class__))\n+\n+    if compression_type != CompressionType_UNCOMPRESSED:\n+        stream = CompressedInputStream.create(stream, compression_type)\n+\n+    return stream\n+\n+\n+def output_stream(source, compression='detect'):\n+    \"\"\"\n+    Create an Arrow output stream.\n+\n+    Parameters\n+    ----------\n+    source: str, Path, buffer, file-like object, ...\n+        The source to open for writing\n+    compression: str or None\n+        The compression algorithm to use for on-the-fly compression.\n+        If \"detect\" and source is a file path, then compression will be\n+        chosen based on the file extension.\n+        If None, no compression will be applied.\n+        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\n+    \"\"\"\n+    cdef:\n+        CompressionType compression_type\n+        NativeFile stream\n+\n+    try:\n+        source_path = _stringify_path(source)\n+    except TypeError:\n+        source_path = None\n+\n+    compression_type = _stream_compression_argument(compression, source_path)\n+\n+    if isinstance(source, NativeFile):\n+        stream = source\n+    elif source_path is not None:\n+        stream = OSFile(source_path, 'w')\n+    elif isinstance(source, (Buffer, memoryview)):\n+        stream = FixedSizeBufferWriter(as_buffer(source))\n+    elif isinstance(source, BufferedIOBase):\n+        stream = PythonFile(source, 'w')\n+    elif file_type is not None and isinstance(source, file_type):\n+        # Python 2 file type\n+        stream = PythonFile(source, 'w')\n+    else:\n+        raise TypeError(\"pa.output_stream() called with instance of '{}'\"\n+                        .format(source.__class__))\n+\n+    if compression_type != CompressionType_UNCOMPRESSED:\n+        stream = CompressedOutputStream.create(stream, compression_type)\n+\n+    return stream\ndiff --git a/python/pyarrow/tests/test_io.py b/python/pyarrow/tests/test_io.py\nindex a648c7d0c8..f54f03a9ff 100644\n--- a/python/pyarrow/tests/test_io.py\n+++ b/python/pyarrow/tests/test_io.py\n@@ -16,7 +16,7 @@\n # under the License.\n \n import bz2\n-from io import (BytesIO, TextIOWrapper, BufferedIOBase, IOBase)\n+from io import (BytesIO, StringIO, TextIOWrapper, BufferedIOBase, IOBase)\n import gc\n import gzip\n import os\n@@ -26,11 +26,16 @@\n import tempfile\n import weakref\n \n+try:\n+    import pathlib\n+except ImportError:\n+    import pathlib2 as pathlib\n+\n import numpy as np\n \n import pandas as pd\n \n-from pyarrow.compat import u, guid\n+from pyarrow.compat import u, guid, PY2\n import pyarrow as pa\n \n \n@@ -1050,3 +1055,214 @@ def test_compressed_roundtrip(compression):\n     with pa.CompressedInputStream(raw, compression) as compressed:\n         got = compressed.read()\n         assert got == data\n+\n+\n+# ----------------------------------------------------------------------\n+# High-level API\n+\n+if PY2:\n+    def gzip_compress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with gzip.GzipFile(fn, 'wb') as f:\n+                f.write(data)\n+            with open(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+\n+    def gzip_decompress(data):\n+        fd, fn = tempfile.mkstemp(suffix='.gz')\n+        try:\n+            os.close(fd)\n+            with open(fn, 'wb') as f:\n+                f.write(data)\n+            with gzip.GzipFile(fn, 'rb') as f:\n+                return f.read()\n+        finally:\n+            os.unlink(fn)\n+else:\n+    gzip_compress = gzip.compress\n+    gzip_decompress = gzip.decompress\n+\n+\n+def test_input_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    for arg in [pa.py_buffer(data), memoryview(data)]:\n+        stream = pa.input_stream(arg)\n+        assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    stream = pa.input_stream(memoryview(gz_data))\n+    assert stream.read() == gz_data\n+    stream = pa.input_stream(memoryview(gz_data), compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_file_path(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'input_stream'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(data)\n+\n+    stream = pa.input_stream(file_path)\n+    assert stream.read() == data\n+    stream = pa.input_stream(str(file_path))\n+    assert stream.read() == data\n+    stream = pa.input_stream(pathlib.Path(str(file_path)))\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_file_path_compressed(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    gz_data = gzip_compress(data)\n+    file_path = tmpdir / 'input_stream.gz'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(gz_data)\n+\n+    stream = pa.input_stream(file_path)\n+    assert stream.read() == data\n+    stream = pa.input_stream(str(file_path))\n+    assert stream.read() == data\n+    stream = pa.input_stream(pathlib.Path(str(file_path)))\n+    assert stream.read() == data\n+\n+    stream = pa.input_stream(file_path, compression='gzip')\n+    assert stream.read() == data\n+    stream = pa.input_stream(file_path, compression=None)\n+    assert stream.read() == gz_data\n+\n+\n+def test_input_stream_python_file(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    bio = BytesIO(data)\n+\n+    stream = pa.input_stream(bio)\n+    assert stream.read() == data\n+\n+    gz_data = gzip_compress(data)\n+    bio = BytesIO(gz_data)\n+    stream = pa.input_stream(bio)\n+    assert stream.read() == gz_data\n+    bio.seek(0)\n+    stream = pa.input_stream(bio, compression='gzip')\n+    assert stream.read() == data\n+\n+    file_path = tmpdir / 'input_stream'\n+    with open(str(file_path), 'wb') as f:\n+        f.write(data)\n+    with open(str(file_path), 'rb') as f:\n+        stream = pa.input_stream(f)\n+        assert stream.read() == data\n+\n+\n+def test_input_stream_native_file():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    gz_data = gzip_compress(data)\n+    reader = pa.BufferReader(gz_data)\n+    stream = pa.input_stream(reader)\n+    assert stream is reader\n+    reader = pa.BufferReader(gz_data)\n+    stream = pa.input_stream(reader, compression='gzip')\n+    assert stream.read() == data\n+\n+\n+def test_input_stream_errors(tmpdir):\n+    buf = memoryview(b\"\")\n+    with pytest.raises(ValueError):\n+        pa.input_stream(buf, compression=\"foo\")\n+\n+    for arg in [bytearray(), StringIO()]:\n+        with pytest.raises(TypeError):\n+            pa.input_stream(arg)\n+\n+    with pytest.raises(IOError):\n+        pa.input_stream(\"non_existent_file\")\n+\n+    with open(str(tmpdir / 'new_file'), 'wb') as f:\n+        with pytest.raises(TypeError, match=\"readable file expected\"):\n+            pa.input_stream(f)\n+\n+\n+def test_output_stream_buffer():\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    buf = bytearray(len(data))\n+    stream = pa.output_stream(pa.py_buffer(buf))\n+    stream.write(data)\n+    assert buf == data\n+\n+    buf = bytearray(len(data))\n+    stream = pa.output_stream(memoryview(buf))\n+    stream.write(data)\n+    assert buf == data\n+\n+\n+def test_output_stream_file_path(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'output_stream'\n+\n+    def check_data(file_path, data):\n+        with pa.output_stream(file_path) as stream:\n+            stream.write(data)\n+        with open(str(file_path), 'rb') as f:\n+            assert f.read() == data\n+\n+    check_data(file_path, data)\n+    check_data(str(file_path), data)\n+    check_data(pathlib.Path(str(file_path)), data)\n+\n+\n+def test_output_stream_file_path_compressed(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+    file_path = tmpdir / 'output_stream.gz'\n+\n+    def check_data(file_path, data, **kwargs):\n+        with pa.output_stream(file_path, **kwargs) as stream:\n+            stream.write(data)\n+        with open(str(file_path), 'rb') as f:\n+            return f.read()\n+\n+    assert gzip_decompress(check_data(file_path, data)) == data\n+    assert gzip_decompress(check_data(str(file_path), data)) == data\n+    assert gzip_decompress(\n+        check_data(pathlib.Path(str(file_path)), data)) == data\n+\n+    assert gzip_decompress(\n+        check_data(file_path, data, compression='gzip')) == data\n+    assert check_data(file_path, data, compression=None) == data\n+\n+\n+def test_output_stream_python_file(tmpdir):\n+    data = b\"some test data\\n\" * 10 + b\"eof\\n\"\n+\n+    def check_data(data, **kwargs):\n+        # XXX cannot use BytesIO because stream.close() is necessary\n+        # to finish writing compressed data, but it will also close the\n+        # underlying BytesIO\n+        fn = str(tmpdir / 'output_stream_file')\n+        with open(fn, 'wb') as f:\n+            with pa.output_stream(f, **kwargs) as stream:\n+                stream.write(data)\n+        with open(fn, 'rb') as f:\n+            return f.read()\n+\n+    assert check_data(data) == data\n+    assert gzip_decompress(check_data(data, compression='gzip')) == data\n+\n+\n+def test_output_stream_errors(tmpdir):\n+    buf = memoryview(bytearray())\n+    with pytest.raises(ValueError):\n+        pa.output_stream(buf, compression=\"foo\")\n+\n+    for arg in [bytearray(), StringIO()]:\n+        with pytest.raises(TypeError):\n+            pa.output_stream(arg)\n+\n+    fn = str(tmpdir / 'new_file')\n+    with open(fn, 'wb') as f:\n+        pass\n+    with open(fn, 'rb') as f:\n+        with pytest.raises(TypeError, match=\"writable file expected\"):\n+            pa.output_stream(f)\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-07T17:12:05.951+0000",
                    "updated": "2018-11-07T17:12:05.951+0000",
                    "started": "2018-11-07T17:12:05.950+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163500",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163501",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on issue #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#issuecomment-436701958\n \n \n   Thanks for the review @kszucs !\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-07T17:12:11.159+0000",
                    "updated": "2018-11-07T17:12:11.159+0000",
                    "started": "2018-11-07T17:12:11.158+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163501",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163504",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#issuecomment-436705090\n \n \n   I will have a look and leave my comments also. I'm recovering from international travel and should start becoming a bit more engaged on code reviews in the next week\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-07T17:20:47.499+0000",
                    "updated": "2018-11-07T17:20:47.499+0000",
                    "started": "2018-11-07T17:20:47.498+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163504",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163853",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on issue #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#issuecomment-436938673\n \n \n   By \"generic IO\" you mean reading and writing non-Arrow data? In that regard I'm not sure we're more interesting than the standard Python IO stack.\r\n   \r\n   By the way, I plan to try and write a blog post about the CSV reader, but before that I'd like to make it a bit more usable.\r\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-08T09:59:03.594+0000",
                    "updated": "2018-11-08T09:59:03.594+0000",
                    "started": "2018-11-08T09:59:03.593+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163853",
                    "issueId": "13194921"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/worklog/163895",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #2873: ARROW-3646: [Python] High-level IO API\nURL: https://github.com/apache/arrow/pull/2873#issuecomment-436982096\n \n \n   Well, I think the portability aspect of the IO stack is interesting: can be used in C++ only or any language that has bindings. I don't know of a comparable project \r\n   \r\n   Might be worth waiting to do more blog posts about the IO stack until we have a bit better file system support, eg S3 and Google Cloud Storage, which ought to get done in 2019\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-11-08T12:45:38.911+0000",
                    "updated": "2018-11-08T12:45:38.911+0000",
                    "started": "2018-11-08T12:45:38.910+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "163895",
                    "issueId": "13194921"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 12000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@20937030[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@458c9705[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4f264a89[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@6e33c8d7[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@a44c9d8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@3f4973e[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7efbe7cb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@e7eedb3[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@22d8ffad[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@532d1af[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2456bb7d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@5d3cd931[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 12000,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Nov 07 17:11:55 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-11-07T17:11:55.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3646/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2018-10-29T18:09:53.000+0000",
        "updated": "2018-11-08T12:45:38.000+0000",
        "timeoriginalestimate": null,
        "description": "Currently, creating IO streams requires invoking various constructors with irregular names. It would be nice to expose a higher-level interface.\r\n\r\nFor example:\r\n{code:python}\r\ndef open_reader(source, compression='detect'):\r\n    \"\"\"\r\n    Create an Arrow input stream.\r\n\r\n    Parameters\r\n    ----------\r\n    source: str, Path, buffer, file-like object, ...\r\n        The source to open for reading\r\n    compression: str or None\r\n        The compression algorithm to use for on-the-fly decompression.\r\n        If 'detect' and source is a file path, then compression will be\r\n        chosen based on the file extension.\r\n        If None, no compression will be applied.\r\n        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\r\n    \"\"\"\r\n\r\ndef open_writer(source, compression='detect'):\r\n    \"\"\"\r\n    Create an Arrow output stream.\r\n\r\n    Parameters\r\n    ----------\r\n    source: str, Path, buffer, file-like object, ...\r\n        The source to open for writing\r\n    compression: str or None\r\n        The compression algorithm to use for on-the-fly compression.\r\n        If 'detect' and source is a file path, then compression will be\r\n        chosen based on the file extension.\r\n        If None, no compression will be applied.\r\n        Otherwise, a well-known algorithm name must be supplied (e.g. \"gzip\")\r\n    \"\"\"\r\n{code}\r\n\r\nThoughts?",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "3h 20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 12000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Add convenience factories to create IO streams",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/comment/16667727",
                    "id": "16667727",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Could call them {{pyarrow.input_stream}} or {{pyarrow.output_stream}} or something like that, too. We should probably rename {{pa.open_file}} and {{pa.open_stream}} to something that is clear that they are IPC message files/streams",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-10-29T20:37:35.032+0000",
                    "updated": "2018-10-29T20:37:35.032+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13194921/comment/16678518",
                    "id": "16678518",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Issue resolved by pull request 2873\n[https://github.com/apache/arrow/pull/2873]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2018-11-07T17:11:55.759+0000",
                    "updated": "2018-11-07T17:11:55.759+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|i3zrmv:",
        "customfield_12314139": null
    }
}