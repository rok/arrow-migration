{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13322291",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291",
    "key": "ARROW-9707",
    "fields": {
        "parent": {
            "id": "13316701",
            "key": "ARROW-9464",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13316701",
            "fields": {
                "summary": "[Rust] [DataFusion] Physical plan refactor to support optimization rules and more efficient use of threads",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                    "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                    "name": "Closed",
                    "id": "6",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                        "id": 3,
                        "key": "done",
                        "colorName": "green",
                        "name": "Done"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "id": "4",
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                    "name": "Improvement",
                    "subtask": false,
                    "avatarId": 21140
                }
            }
        },
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12348823",
                "id": "12348823",
                "description": "",
                "name": "3.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-01-25"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/6",
            "id": "6",
            "description": "The problem isn't valid and it can't be fixed.",
            "name": "Invalid"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "1.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12601311",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12601311",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13335287",
                    "key": "ARROW-10303",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335287",
                    "fields": {
                        "summary": "[Rust] Parallel type transformation in CSV reader",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
                            "name": "Minor",
                            "id": "4"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/5",
                            "id": "5",
                            "description": "General wishlist item.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Wish",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
            "name": "andygrove",
            "key": "andygrove",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
            },
            "displayName": "Andy Grove",
            "active": true,
            "timeZone": "America/Denver"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "name": "Closed",
            "id": "6",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333773",
                "id": "12333773",
                "name": "Rust"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12335005",
                "id": "12335005",
                "name": "Rust - DataFusion"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
            "name": "andygrove",
            "key": "andygrove",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
            },
            "displayName": "Andy Grove",
            "active": true,
            "timeZone": "America/Denver"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
            "name": "andygrove",
            "key": "andygrove",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
            },
            "displayName": "Andy Grove",
            "active": true,
            "timeZone": "America/Denver"
        },
        "aggregateprogress": {
            "progress": 14400,
            "total": 14400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 14400,
            "total": 14400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-9707/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 24,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491586",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove opened a new pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283\n\n\n   This PR introduces a scheduler for query execution that breaks a physical plan down into a DAG of query stages based on changes in partitioning. Each stage represents a portion of the query where partitions (tasks) can be executed in parallel on a thread pool.\r\n   \r\n   The intent is for the scheduler to decide how to allocate tasks to threads/cores and move all the threading logic out of the executors themselves. \r\n   \r\n   The code is based on a working prototype that I had previously implemented in Ballista (also ASL 2.0) and myself and @jorgecarleitao have been the only contributors to this code so far and we both have signed CLAs on file.\r\n   \r\n   The current code compiles but is not complete and doesn't actually work yet. I will try and get this fully working for the 2.0.0 release if others think this is a good approach.\r\n   \r\n   \r\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-26T17:53:43.260+0000",
                    "updated": "2020-09-26T17:53:43.260+0000",
                    "started": "2020-09-26T17:53:43.260+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491586",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491587",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699527610\n\n\n   FYI @jorgecarleitao @alamb @alippai @vertexclique @svenwb since you have all commented on the related JIRA and design document.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-26T17:56:07.492+0000",
                    "updated": "2020-09-26T17:56:07.492+0000",
                    "started": "2020-09-26T17:56:07.492+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491587",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491590",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699528805\n\n\n   https://issues.apache.org/jira/browse/ARROW-9707\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-26T18:06:38.237+0000",
                    "updated": "2020-09-26T18:06:38.237+0000",
                    "started": "2020-09-26T18:06:38.236+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491590",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491603",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r495491244\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n+            let stage = stage.borrow_mut();\n+            let status = stage_status_map.get(&stage.id).unwrap();\n+            match status {\n+                StageStatus::Pending => {\n+                    // have prior stages already completed ?\n+                    if stage.prior_stages.iter().all(|id| {\n+                        match stage_status_map.get(id) {\n+                            Some(StageStatus::Completed) => true,\n+                            _ => false,\n+                        }\n+                    }) {\n+                        println!(\"Running stage {}\", stage.id);\n+                        let plan = stage\n+                            .plan\n+                            .as_ref()\n+                            .expect(\"all stages should have plans at execution time\");\n+\n+                        let stage_start = Instant::now();\n+\n+                        let exec = plan;\n+                        let parts = exec.output_partitioning().partition_count();\n+\n+                        // build queue of tasks per executor\n+                        let mut next_executor_id = 0;\n+                        let mut executor_tasks: HashMap<String, Vec<ExecutionTask>> =\n+                            HashMap::new();\n+                        #[allow(clippy::needless_range_loop)]\n+                        for i in 0..executors.len() {\n+                            //executor_tasks.insert(executors[i].id.clone(), vec![]);\n+                        }\n+                        for partition in 0..parts {\n+                            let task = ExecutionTask::new(\n+                                job.id,\n+                                stage.id,\n+                                partition,\n\nReview comment:\n       Does this call imply that an execution plan node with multiple partitions could be run by multiple threads concurrently?\r\n   \n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n+            let stage = stage.borrow_mut();\n+            let status = stage_status_map.get(&stage.id).unwrap();\n+            match status {\n+                StageStatus::Pending => {\n+                    // have prior stages already completed ?\n+                    if stage.prior_stages.iter().all(|id| {\n+                        match stage_status_map.get(id) {\n+                            Some(StageStatus::Completed) => true,\n+                            _ => false,\n+                        }\n+                    }) {\n+                        println!(\"Running stage {}\", stage.id);\n+                        let plan = stage\n+                            .plan\n+                            .as_ref()\n+                            .expect(\"all stages should have plans at execution time\");\n+\n+                        let stage_start = Instant::now();\n+\n+                        let exec = plan;\n+                        let parts = exec.output_partitioning().partition_count();\n+\n+                        // build queue of tasks per executor\n+                        let mut next_executor_id = 0;\n+                        let mut executor_tasks: HashMap<String, Vec<ExecutionTask>> =\n+                            HashMap::new();\n+                        #[allow(clippy::needless_range_loop)]\n+                        for i in 0..executors.len() {\n+                            //executor_tasks.insert(executors[i].id.clone(), vec![]);\n+                        }\n+                        for partition in 0..parts {\n+                            let task = ExecutionTask::new(\n+                                job.id,\n+                                stage.id,\n+                                partition,\n+                                plan.clone(),\n+                                shuffle_location_map.clone(),\n+                            );\n+\n+                            // load balance across the executors\n+                            let executor_meta = &executors[next_executor_id];\n+                            next_executor_id += 1;\n+                            if next_executor_id == executors.len() {\n+                                next_executor_id = 0;\n+                            }\n+\n+                            let queue = executor_tasks\n+                                .get_mut(&executor_meta.id)\n+                                .expect(\"executor queue should exist\");\n+\n+                            queue.push(task);\n\nReview comment:\n       I wonder how this will handle data flowing in a plan where a producer (eg scan) can make data faster than the consumer (eg aggregate) can consume it. \n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-26T20:19:46.999+0000",
                    "updated": "2020-09-26T20:19:46.999+0000",
                    "started": "2020-09-26T20:19:46.999+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491603",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491605",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r495493604\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n+            let stage = stage.borrow_mut();\n+            let status = stage_status_map.get(&stage.id).unwrap();\n+            match status {\n+                StageStatus::Pending => {\n+                    // have prior stages already completed ?\n+                    if stage.prior_stages.iter().all(|id| {\n+                        match stage_status_map.get(id) {\n+                            Some(StageStatus::Completed) => true,\n+                            _ => false,\n+                        }\n+                    }) {\n+                        println!(\"Running stage {}\", stage.id);\n+                        let plan = stage\n+                            .plan\n+                            .as_ref()\n+                            .expect(\"all stages should have plans at execution time\");\n+\n+                        let stage_start = Instant::now();\n+\n+                        let exec = plan;\n+                        let parts = exec.output_partitioning().partition_count();\n+\n+                        // build queue of tasks per executor\n+                        let mut next_executor_id = 0;\n+                        let mut executor_tasks: HashMap<String, Vec<ExecutionTask>> =\n+                            HashMap::new();\n+                        #[allow(clippy::needless_range_loop)]\n+                        for i in 0..executors.len() {\n+                            //executor_tasks.insert(executors[i].id.clone(), vec![]);\n+                        }\n+                        for partition in 0..parts {\n+                            let task = ExecutionTask::new(\n+                                job.id,\n+                                stage.id,\n+                                partition,\n\nReview comment:\n       Yes, The tasks within each stage represent partitions that can be run in parallel.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-26T20:42:15.761+0000",
                    "updated": "2020-09-26T20:42:15.761+0000",
                    "started": "2020-09-26T20:42:15.761+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491605",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491609",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r495494081\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n+            let stage = stage.borrow_mut();\n+            let status = stage_status_map.get(&stage.id).unwrap();\n+            match status {\n+                StageStatus::Pending => {\n+                    // have prior stages already completed ?\n+                    if stage.prior_stages.iter().all(|id| {\n+                        match stage_status_map.get(id) {\n+                            Some(StageStatus::Completed) => true,\n+                            _ => false,\n+                        }\n+                    }) {\n+                        println!(\"Running stage {}\", stage.id);\n+                        let plan = stage\n+                            .plan\n+                            .as_ref()\n+                            .expect(\"all stages should have plans at execution time\");\n+\n+                        let stage_start = Instant::now();\n+\n+                        let exec = plan;\n+                        let parts = exec.output_partitioning().partition_count();\n+\n+                        // build queue of tasks per executor\n+                        let mut next_executor_id = 0;\n+                        let mut executor_tasks: HashMap<String, Vec<ExecutionTask>> =\n+                            HashMap::new();\n+                        #[allow(clippy::needless_range_loop)]\n+                        for i in 0..executors.len() {\n+                            //executor_tasks.insert(executors[i].id.clone(), vec![]);\n+                        }\n+                        for partition in 0..parts {\n+                            let task = ExecutionTask::new(\n+                                job.id,\n+                                stage.id,\n+                                partition,\n+                                plan.clone(),\n+                                shuffle_location_map.clone(),\n+                            );\n+\n+                            // load balance across the executors\n+                            let executor_meta = &executors[next_executor_id];\n+                            next_executor_id += 1;\n+                            if next_executor_id == executors.len() {\n+                                next_executor_id = 0;\n+                            }\n+\n+                            let queue = executor_tasks\n+                                .get_mut(&executor_meta.id)\n+                                .expect(\"executor queue should exist\");\n+\n+                            queue.push(task);\n\nReview comment:\n       Within each query stage, it is still a pull model. The leaf query stages will typically be a scan wrapped by some other operators. With the currently supported DataFusion operators, the `MergeExec` is essentially the shuffle exchange that would represent query stage boundaries. For example, `LocalLimit` and `HashAggregate(mode=Final)` operators would not start executing until their input query stages complete. This is not dissimilar to how `MergeExec` works today in that it blocks on the input threads, but it is occupying a thread itself while it waits in the current model but with the scheduler model, the `MergeExec` (possibly replaced with `ShuffleReader`) would not start running until the input stages have completed. I'm not sure if that totally answers your question but hopefully sheds a little more light on this design.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-26T20:48:06.912+0000",
                    "updated": "2020-09-26T20:48:06.912+0000",
                    "started": "2020-09-26T20:48:06.911+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491609",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491666",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699591199\n\n\n   This is super exciting!!!! Thanks a lot @andygrove for pushing this through!\r\n   \r\n   I am trying to understand how this is related to other executing architectures in Rust (e.g. Tokyo) and more broadly to the traits in the crate [`futures`](https://docs.rs/crate/futures/0.3.5).\r\n   \r\n   My current hypothesis is that this may be simpler if we leverage some of the existing traits in `futures`.\r\n   \r\n   In my current understanding of DataFusion's Execlution plan, `ExecutionPlan` behaves like an `IntoIter` whose Iterator iterates over parts of a partition, via `execute(part_index)`, where `part_index`'s range is given by `output_partitioning().partition_count()` (Longer version [here](https://docs.google.com/document/d/1yREyFSA1Fx1WMC0swUAZBbNlKPmTyebzAiQ8Eu6Ynpg/edit?usp=sharing)).\r\n   \r\n   In fact, with [some dull changes](https://github.com/jorgecarleitao/arrow/pull/8) (test [here](https://github.com/jorgecarleitao/arrow/pull/8/files#diff-f92f5cc2c20e4cfba21c282e728d53e4R68-R92)), we can iterate over a full partition as follows:\r\n   \r\n   ```rust\r\n   let plan: &dyn ExecutionPlan = ...\r\n   \r\n   plan.into_iter().map(|maybe_part| {\r\n       let part = maybe_part.unwrap();  // todo handle error via special flatten\r\n       part.into_iter().map(|maybe_batch| {\r\n           println!(\"{:?}\", maybe_batch?.num_rows());\r\n           Ok(())\r\n       })\r\n   })\r\n   .flatten()\r\n   .collect::<Result<()>>()?;\r\n   ```\r\n   \r\n   The problem with this is that it requires each node to be responsible for spawning threads, which, as identified in ARROW-9707, is problematic.\r\n   \r\n   To address this, we need to make `execute` something that a scheduler can chew in parts. For that reason, I think that #8285 , that proposes `execute` to be `async`, is beautiful!\r\n   \r\n   **But**, If `execute` is `async`, then I think that `ExecutionPlan` could implement [`IntoStream`](https://docs.rs/futures/0.3.5/futures/future/struct.IntoStream.html). In this scenario, `ExecutionPlan` would become\r\n   \r\n   >  an object that knows know to convert itself into a stream of record batch iterators\r\n   \r\n   The advantage is that any scheduler that consumes [`futures::Stream`](https://docs.rs/futures/0.3.5/futures/stream/trait.Stream.html) can pick this stream and execute it. Since it now knows how to stop in the middle of `execute` in case something is blocking it (including any of its `input`s), it can switch tasks ad-hoc. In other words, IMO we can leverage any async library to run this stream.\r\n   \r\n   In this scenario, one idea to address ARROW-9707 is:\r\n   \r\n   1. land #8285\r\n   2. implement `IntoStream` for `ExecutionPlan`\r\n   3. migrate our calls of `thread:spawn`  in the different nodes to `.await`\r\n   4. pick a scheduler from the shelf and run the stream using it.\r\n   \r\n   If we want some customization (e.g. logging, some special naming for the tasks), we can always add a `trait DataFusionStream: Stream<...>` and implement it on top of `Stream`.\r\n   \r\n   Note that this would effectively make our `ExecutionPlan` to be a dynamically-typed stream adapter (a-la [futures::stream::Select](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.9/futures/stream/struct.Select.html), but dynamic): it consumes one or more streams, and it outputs a new stream. Conceptually, IMO this is exactly what an `ExecutionPlan` plan is.\r\n   \r\n   In a distributed environment, the main difference would be that the physical planner would plan `ExecutionPlan` whose `execute` includes submitting a job to a worker and wait for the result (e.g. via a TCP channel); the result is still a stream though, and the scheduler can decide to wait for network + node's compute and perform a switch, the same way it can wait for I/O.\r\n   \r\n   I am sorry that I only came up with this idea now. I finally understood the implications of #8285.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-27T06:10:44.043+0000",
                    "updated": "2020-09-27T06:10:44.043+0000",
                    "started": "2020-09-27T06:10:44.042+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491666",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491667",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao edited a comment on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699591199\n\n\n   This is super exciting!!!! Thanks a lot @andygrove for pushing this through!\r\n   \r\n   I am trying to understand how this is related to other executing architectures in Rust (e.g. Tokyo) and more broadly to the traits in the crate [`futures`](https://docs.rs/crate/futures/0.3.5).\r\n   \r\n   My current hypothesis is that this may be simpler if we leverage some of the existing traits in `futures`.\r\n   \r\n   In my current understanding of DataFusion's Execlution plan, `ExecutionPlan` behaves like an `IntoIter` whose Iterator iterates over parts of a partition, via `execute(part_index)`, where `part_index`'s range is given by `output_partitioning().partition_count()` (Longer version [here](https://docs.google.com/document/d/1yREyFSA1Fx1WMC0swUAZBbNlKPmTyebzAiQ8Eu6Ynpg/edit?usp=sharing)).\r\n   \r\n   In fact, with [some dull changes](https://github.com/jorgecarleitao/arrow/pull/8) (test [here](https://github.com/jorgecarleitao/arrow/pull/8/files#diff-f92f5cc2c20e4cfba21c282e728d53e4R68-R92)), we can iterate over a full partition as follows:\r\n   \r\n   ```rust\r\n   let plan: &dyn ExecutionPlan = ...\r\n   \r\n   plan.into_iter().map(|maybe_part| {\r\n       let part = maybe_part.unwrap();  // todo handle error via special flatten\r\n       part.into_iter().map(|maybe_batch| {\r\n           println!(\"{:?}\", maybe_batch?.num_rows());\r\n           Ok(())\r\n       })\r\n   })\r\n   .flatten()\r\n   .collect::<Result<()>>()?;\r\n   ```\r\n   \r\n   The problem with this is that it requires each node to be responsible for spawning threads, which, as identified in ARROW-9707, is problematic.\r\n   \r\n   To address this, we need to make `execute` something that a scheduler can chew in parts. For that reason, I think that #8285 , that proposes `execute` to be `async`, is beautiful!\r\n   \r\n   **But**, If `execute` is `async`, then I think that `ExecutionPlan` could implement [`IntoStream`](https://docs.rs/futures/0.3.5/futures/future/struct.IntoStream.html) in the same way it can currently implement [`IntoIter`](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html). In this scenario, `ExecutionPlan` would become\r\n   \r\n   >  an object that knows know to convert itself into a stream of record batch iterators\r\n   \r\n   The advantage is that any scheduler that consumes [`futures::Stream`](https://docs.rs/futures/0.3.5/futures/stream/trait.Stream.html) can pick this stream and execute it. Since it now knows how to stop in the middle of `execute` in case something is blocking it (including any of its `input`s), it can switch tasks ad-hoc. In other words, IMO we can leverage any async library to run this stream.\r\n   \r\n   In this scenario, one idea to address ARROW-9707 is:\r\n   \r\n   1. land #8285\r\n   2. implement `IntoStream` for `ExecutionPlan`\r\n   3. migrate our calls of `thread:spawn`  in the different nodes to `.await`\r\n   4. pick a scheduler from the shelf and run the stream using it.\r\n   \r\n   If we want some customization (e.g. logging, some special naming for the tasks), we can always add a `trait DataFusionStream: Stream<...>` and implement it on top of `Stream`.\r\n   \r\n   Note that this would effectively make our `ExecutionPlan` to be a dynamically-typed stream adapter (a-la [futures::stream::Select](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.9/futures/stream/struct.Select.html), but dynamic): it consumes one or more streams, and it outputs a new stream. Conceptually, IMO this is exactly what an `ExecutionPlan` plan is.\r\n   \r\n   In a distributed environment, the main difference would be that the physical planner would plan `ExecutionPlan` whose `execute` includes submitting a job to a worker and wait for the result (e.g. via a TCP channel); the result is still a stream though, and the scheduler can decide to wait for network + node's compute and perform a switch, the same way it can wait for I/O.\r\n   \r\n   I am sorry that I only came up with this idea now. I finally understood the implications of #8285.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-27T06:25:01.975+0000",
                    "updated": "2020-09-27T06:25:01.975+0000",
                    "started": "2020-09-27T06:25:01.975+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491667",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491715",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699655553\n\n\n   @jorgecarleitao Async/await helps a lot but we also need our own scheduler to orchestrate how a query is executed. I am going to write up something more detailed with my reasoning on this soon but here is one example. When I run the TPC-H query I am testing against a data set that has 240 Parquet files. If we just try and run everything at once with async/await and have tokio do the scheduling, we will end up with 240 files open at once with reads happening against all of them, which is inefficient. It is better to process a smaller number of files concurrently (better use of page caches, fewer file handles open, etc) and process them in batches. \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-27T16:19:40.392+0000",
                    "updated": "2020-09-27T16:19:40.392+0000",
                    "started": "2020-09-27T16:19:40.392+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491715",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491720",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699658056\n\n\n   It makes sense, @andygrove.\r\n   \r\n   Note that I do not disagree with us having a custom scheduler. I was noting that we could separate the two problems: one problem is creation of tasks, and the other is the scheduling of said tasks. When we spawn tasks in `executionPlan::execute`, we may be mixing these two.\r\n   \r\n   The same way that we expose execution details of a node via (`output_partitioning`), we can expose other execution details (e.g. `is_scan()`), that our custom scheduler can use to e.g. limit concurrency.\r\n   \r\n   Regardless, this is in no way a blocker or anything, and we can leave this discussion for a future iteration - I agree that what you are doing here is really great stuff and we should go for it \ud83d\ude80 \r\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-27T16:40:35.237+0000",
                    "updated": "2020-09-27T16:40:35.237+0000",
                    "started": "2020-09-27T16:40:35.237+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491720",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491759",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r495617565\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n+            let stage = stage.borrow_mut();\n+            let status = stage_status_map.get(&stage.id).unwrap();\n+            match status {\n+                StageStatus::Pending => {\n+                    // have prior stages already completed ?\n+                    if stage.prior_stages.iter().all(|id| {\n+                        match stage_status_map.get(id) {\n+                            Some(StageStatus::Completed) => true,\n+                            _ => false,\n+                        }\n+                    }) {\n+                        println!(\"Running stage {}\", stage.id);\n+                        let plan = stage\n+                            .plan\n+                            .as_ref()\n+                            .expect(\"all stages should have plans at execution time\");\n+\n+                        let stage_start = Instant::now();\n+\n+                        let exec = plan;\n+                        let parts = exec.output_partitioning().partition_count();\n+\n+                        // build queue of tasks per executor\n+                        let mut next_executor_id = 0;\n+                        let mut executor_tasks: HashMap<String, Vec<ExecutionTask>> =\n+                            HashMap::new();\n+                        #[allow(clippy::needless_range_loop)]\n+                        for i in 0..executors.len() {\n+                            //executor_tasks.insert(executors[i].id.clone(), vec![]);\n+                        }\n+                        for partition in 0..parts {\n+                            let task = ExecutionTask::new(\n+                                job.id,\n+                                stage.id,\n+                                partition,\n+                                plan.clone(),\n+                                shuffle_location_map.clone(),\n+                            );\n+\n+                            // load balance across the executors\n+                            let executor_meta = &executors[next_executor_id];\n+                            next_executor_id += 1;\n+                            if next_executor_id == executors.len() {\n+                                next_executor_id = 0;\n+                            }\n+\n+                            let queue = executor_tasks\n+                                .get_mut(&executor_meta.id)\n+                                .expect(\"executor queue should exist\");\n+\n+                            queue.push(task);\n\nReview comment:\n       I think I understand what you are saying.\r\n   \r\n   For what it is worth, I think this code will intersect with the async executor (as with the async mode we'll already have a \"scheduler\" in something that maps works to threads, assuming we break up the work into tasks.\r\n   \r\n   We may want a scheduler that prevents too much of the plan starting (aka not starting all stages at once) but I am bullish about the async approach!\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-27T21:20:38.595+0000",
                    "updated": "2020-09-27T21:20:38.595+0000",
                    "started": "2020-09-27T21:20:38.595+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491759",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491767",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alippai commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699695827\n\n\n   @andygrove I think now you understand all my issues I had previously. The scheduler proposal and the recent comments regarding the concurrency are all superb, I think you are on track. Thanks for listening about my fears previously.\r\n   \r\n   My only note: https://github.com/apache/arrow/pull/8283#issuecomment-699655553 likely you want to read a largish partition in \"one go\". AFAIR HDFS creates ~128MB large parquet chunks. Reading ~100MB large parquet files, or large columns with tens of MBs of data in one go will likely increase the throughput. While using local disks values over a few MBs won't make any difference, but using S3, HDFS, GPFS, NFS it can be beneficial. \r\n   \r\n   I couldn't find how the TPC-H parquet files you test with are structured, can you give me some pointers?\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-27T22:25:49.726+0000",
                    "updated": "2020-09-27T22:25:49.726+0000",
                    "started": "2020-09-27T22:25:49.726+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491767",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/491772",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alippai edited a comment on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-699695827\n\n\n   @andygrove I think now you understand all my issues I had previously. The scheduler proposal and the recent comments regarding the concurrency are all superb, I think you are on track. Thanks for listening for my newbie concerns.\r\n   \r\n   My only note: https://github.com/apache/arrow/pull/8283#issuecomment-699655553 likely you want to read a largish partition in \"one go\". AFAIR HDFS creates ~128MB large parquet chunks. Reading ~100MB large parquet files, or large columns with tens of MBs of data in one go will likely increase the throughput. While using local disks values over a few MBs won't make any difference, but using S3, HDFS, GPFS, NFS it can be beneficial. \r\n   \r\n   I couldn't find how the TPC-H parquet files you test with are structured, can you give me some pointers?\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-28T00:33:44.408+0000",
                    "updated": "2020-09-28T00:33:44.408+0000",
                    "started": "2020-09-28T00:33:44.408+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "491772",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/492101",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-700197576\n\n\n   > When I run the TPC-H query I am testing against a data set that has 240 Parquet files. If we just try and run everything at once with async/await and have tokio do the scheduling, we will end up with 240 files open at once with reads happening against all of them, which is inefficient.\r\n   \r\n   One way to avoid this type of resource usage explosion is if the Parquet reader itself limits the number of outstanding `Task`s that it submits. For example, with a tokio channel or something.\r\n   \r\n   It seems to me the challenge is not really \"scheduling\" per se, but more \"resource allocation\"\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-28T18:12:13.985+0000",
                    "updated": "2020-09-28T18:12:13.985+0000",
                    "started": "2020-09-28T18:12:13.985+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492101",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/492102",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-700198208\n\n\n   BTW @jorgecarleitao  -- I really like your ideas regarding using async streams in `ExecutionPlan` -- I think it sounds like a very elegant way to implement back pressure (and avoid starting too many things at once)\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-28T18:13:27.596+0000",
                    "updated": "2020-09-28T18:13:27.596+0000",
                    "started": "2020-09-28T18:13:27.596+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492102",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/492103",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#issuecomment-700199462\n\n\n   That makes sense, and we already have some funky channel and thread\n   interaction in the DataFusion parquet reader that we could probably adapt\n   fairly easily. We could introduce a config setting for max concurrent\n   parquet readers.\n   \n   On Mon, Sep 28, 2020 at 12:12 PM Andrew Lamb <notifications@github.com>\n   wrote:\n   \n   > When I run the TPC-H query I am testing against a data set that has 240\n   > Parquet files. If we just try and run everything at once with async/await\n   > and have tokio do the scheduling, we will end up with 240 files open at\n   > once with reads happening against all of them, which is inefficient.\n   >\n   > One way to avoid this type of resource usage explosion is if the Parquet\n   > reader itself limits the number of outstanding Tasks that it submits. For\n   > example, with a tokio channel or something.\n   >\n   > It seems to me the challenge is not really \"scheduling\" per se, but more\n   > \"resource allocation\"\n   >\n   > \u2014\n   > You are receiving this because you were mentioned.\n   > Reply to this email directly, view it on GitHub\n   > <https://github.com/apache/arrow/pull/8283#issuecomment-700197576>, or\n   > unsubscribe\n   > <https://github.com/notifications/unsubscribe-auth/AAHEBRGAPSBS2HWZRE2PI73SIDGX5ANCNFSM4R3A4JHA>\n   > .\n   >\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-28T18:15:51.499+0000",
                    "updated": "2020-09-28T18:15:51.499+0000",
                    "started": "2020-09-28T18:15:51.498+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492103",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/492858",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vertexclique commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r497387507\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n\nReview comment:\n       Can `into_par_iter()` from rayon suitable in here?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-30T09:57:42.463+0000",
                    "updated": "2020-09-30T09:57:42.463+0000",
                    "started": "2020-09-30T09:57:42.462+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492858",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/492868",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r497406955\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n\nReview comment:\n       I think Rayon has its own thread pool, so if we used into_par_iter() / Rayon that might interfere / confuse things with using an async executor.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-30T10:31:26.852+0000",
                    "updated": "2020-09-30T10:31:26.852+0000",
                    "started": "2020-09-30T10:31:26.852+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492868",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/501010",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r505295915\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n\nReview comment:\n       I tried it Rayon here: https://github.com/jorgecarleitao/arrow/pull/15/files, and I think that it may be the way to go: leverage Rayon's thread pool for CPU-bounded stuff, and tokio's thread pool for non-blocking stuff (e.g. network).\r\n   Tokio itself recommends using Rayon for blocking stuff.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-15T07:55:44.623+0000",
                    "updated": "2020-10-15T07:55:44.623+0000",
                    "started": "2020-10-15T07:55:44.622+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501010",
                    "issueId": "13322291"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/worklog/501045",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on a change in pull request #8283:\nURL: https://github.com/apache/arrow/pull/8283#discussion_r505414968\n\n\n\n##########\nFile path: rust/datafusion/src/scheduler/mod.rs\n##########\n@@ -0,0 +1,381 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use std::cell::RefCell;\n+use std::collections::HashMap;\n+use std::rc::Rc;\n+use std::sync::Arc;\n+use std::thread;\n+use std::time::Duration;\n+use std::time::Instant;\n+\n+use crate::arrow::record_batch::RecordBatch;\n+use crate::error::ExecutionError;\n+use crate::error::Result;\n+use crate::physical_plan::shuffle::{ShuffleExchangeExec, ShuffleReaderExec};\n+use crate::physical_plan::ExecutionPlan;\n+\n+use crate::execution::context::ExecutionContext;\n+use uuid::Uuid;\n+\n+/// A Job typically represents a single query and the query is executed in stages. Stages are\n+/// separated by map operations (shuffles) to re-partition data before the next stage starts.\n+#[derive(Debug)]\n+pub struct Job {\n+    /// Job UUID\n+    pub id: Uuid,\n+    /// A list of stages within this job. There can be dependencies between stages to form\n+    /// a directed acyclic graph (DAG).\n+    pub stages: Vec<Rc<RefCell<Stage>>>,\n+    /// The root stage id that produces the final results\n+    pub root_stage_id: usize,\n+}\n+\n+impl Job {\n+    pub fn explain(&self) {\n+        println!(\"Job {} has {} stages:\\n\", self.id, self.stages.len());\n+        self.stages.iter().for_each(|stage| {\n+            let stage = stage.as_ref().borrow();\n+            println!(\"Stage {}:\\n\", stage.id);\n+            if stage.prior_stages.is_empty() {\n+                println!(\"Stage {} has no dependencies.\", stage.id);\n+            } else {\n+                println!(\n+                    \"Stage {} depends on stages {:?}.\",\n+                    stage.id, stage.prior_stages\n+                );\n+            }\n+            println!(\n+                \"\\n{:?}\\n\",\n+                stage\n+                    .plan\n+                    .as_ref()\n+                    .expect(\"Stages should always have a plan\")\n+            );\n+        })\n+    }\n+}\n+\n+/// A query stage represents a portion of a physical plan with the same partitioning\n+/// scheme throughout, meaning that each partition can be executed in parallel. Query\n+/// stages form a DAG.\n+#[derive(Debug)]\n+pub struct Stage {\n+    /// Stage id which is unique within a job.\n+    pub id: usize,\n+    /// A list of stages that must complete before this stage can execute.\n+    pub prior_stages: Vec<usize>,\n+    /// The physical plan to execute for this stage\n+    pub plan: Option<Arc<dyn ExecutionPlan>>,\n+}\n+\n+impl Stage {\n+    /// Create a new empty stage with the specified id.\n+    fn new(id: usize) -> Self {\n+        Self {\n+            id,\n+            prior_stages: vec![],\n+            plan: None,\n+        }\n+    }\n+}\n+\n+/// Task that can be sent to an executor for execution. Tasks represent single partitions\n+/// within stagees.\n+#[derive(Debug, Clone)]\n+pub struct ExecutionTask {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+    pub(crate) plan: Arc<dyn ExecutionPlan>,\n+    pub(crate) shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+}\n+\n+impl ExecutionTask {\n+    pub fn new(\n+        job_uuid: Uuid,\n+        stage_id: usize,\n+        partition_id: usize,\n+        plan: Arc<dyn ExecutionPlan>,\n+        shuffle_locations: HashMap<ShuffleId, ExecutorMeta>,\n+    ) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+            plan,\n+            shuffle_locations,\n+        }\n+    }\n+\n+    pub fn key(&self) -> String {\n+        format!(\"{}.{}.{}\", self.job_uuid, self.stage_id, self.partition_id)\n+    }\n+}\n+\n+/// Unique identifier for the output shuffle partition of an operator.\n+#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n+pub struct ShuffleId {\n+    pub(crate) job_uuid: Uuid,\n+    pub(crate) stage_id: usize,\n+    pub(crate) partition_id: usize,\n+}\n+\n+impl ShuffleId {\n+    pub fn new(job_uuid: Uuid, stage_id: usize, partition_id: usize) -> Self {\n+        Self {\n+            job_uuid,\n+            stage_id,\n+            partition_id,\n+        }\n+    }\n+}\n+\n+/// Create a Job (DAG of stages) from a physical execution plan.\n+pub fn create_job(plan: Arc<dyn ExecutionPlan>) -> Result<Job> {\n+    let mut scheduler = JobScheduler::new();\n+    scheduler.create_job(plan)?;\n+    Ok(scheduler.job)\n+}\n+\n+pub struct JobScheduler {\n+    job: Job,\n+    next_stage_id: usize,\n+}\n+\n+impl JobScheduler {\n+    fn new() -> Self {\n+        let job = Job {\n+            id: Uuid::new_v4(),\n+            stages: vec![],\n+            root_stage_id: 0,\n+        };\n+        Self {\n+            job,\n+            next_stage_id: 0,\n+        }\n+    }\n+\n+    fn create_job(&mut self, plan: Arc<dyn ExecutionPlan>) -> Result<()> {\n+        let new_stage_id = self.next_stage_id;\n+        self.next_stage_id += 1;\n+        let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+        self.job.stages.push(new_stage.clone());\n+        let plan = self.visit_plan(plan, new_stage.clone())?;\n+        new_stage.as_ref().borrow_mut().plan = Some(plan);\n+        Ok(())\n+    }\n+\n+    fn visit_plan(\n+        &mut self,\n+        plan: Arc<dyn ExecutionPlan>,\n+        current_stage: Rc<RefCell<Stage>>,\n+    ) -> Result<Arc<dyn ExecutionPlan>> {\n+        if let Some(exchange) =\n+            plan.as_ref().as_any().downcast_ref::<ShuffleExchangeExec>()\n+        {\n+            // shuffle indicates that we need a new stage\n+            let new_stage_id = self.next_stage_id;\n+            self.next_stage_id += 1;\n+            let new_stage = Rc::new(RefCell::new(Stage::new(new_stage_id)));\n+            self.job.stages.push(new_stage.clone());\n+\n+            // the children need to be part of this new stage\n+            let shuffle_input =\n+                self.visit_plan(exchange.child.clone(), new_stage.clone())?;\n+\n+            new_stage.as_ref().borrow_mut().plan = Some(shuffle_input);\n+\n+            // the current stage depends on this new stage\n+            current_stage\n+                .as_ref()\n+                .borrow_mut()\n+                .prior_stages\n+                .push(new_stage_id);\n+\n+            // return a shuffle reader to read the results from the stage\n+            let n = exchange.child.output_partitioning().partition_count();\n+\n+            let shuffle_id = (0..n)\n+                .map(|n| ShuffleId {\n+                    job_uuid: self.job.id,\n+                    stage_id: new_stage_id,\n+                    partition_id: n,\n+                })\n+                .collect();\n+            Ok(Arc::new(ShuffleReaderExec::new(\n+                exchange.schema(),\n+                shuffle_id,\n+            )))\n+        } else {\n+            let new_children = plan\n+                .children()\n+                .iter()\n+                .map(|child| self.visit_plan(child.clone(), current_stage.clone()))\n+                .collect::<Result<Vec<_>>>()?;\n+            plan.with_new_children(new_children)\n+        }\n+    }\n+}\n+\n+enum StageStatus {\n+    Pending,\n+    Completed,\n+}\n+\n+enum TaskStatus {\n+    Pending(Instant),\n+    Running(Instant),\n+    Completed(ShuffleId),\n+    Failed(String),\n+}\n+\n+#[derive(Debug, Clone)]\n+struct ExecutorShuffleIds {\n+    executor_id: String,\n+    shuffle_ids: Vec<ShuffleId>,\n+}\n+\n+/// Execute a job directly against executors as starting point\n+pub async fn execute_job(job: &Job, ctx: &ExecutionContext) -> Result<Vec<RecordBatch>> {\n+    let executors: Vec<ExecutorMeta> = vec![]; //ctx.get_executor_ids().await?;\n+\n+    println!(\"Executors: {:?}\", executors);\n+\n+    if executors.is_empty() {\n+        println!(\"no executors found\");\n+        return Err(ExecutionError::General(\n+            \"no executors available\".to_string(),\n+        ));\n+    }\n+\n+    let mut shuffle_location_map: HashMap<ShuffleId, ExecutorMeta> = HashMap::new();\n+\n+    let mut stage_status_map = HashMap::new();\n+\n+    for stage in &job.stages {\n+        let stage = stage.borrow_mut();\n+        stage_status_map.insert(stage.id, StageStatus::Pending);\n+    }\n+\n+    // loop until all stages are complete\n+    let mut num_completed = 0;\n+    while num_completed < job.stages.len() {\n+        num_completed = 0;\n+\n+        //TODO do stages in parallel when possible\n+        for stage in &job.stages {\n\nReview comment:\n       I left some comments on https://github.com/jorgecarleitao/arrow/pull/15/files#r505414319\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-15T09:56:10.342+0000",
                    "updated": "2020-10-15T09:56:10.342+0000",
                    "started": "2020-10-15T09:56:10.342+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501045",
                    "issueId": "13322291"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 14400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@4ccce465[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@70666b04[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@63f3f016[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@200e9927[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2fcc40f7[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@5958a535[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@25579d48[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@71c4ff64[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3cc2c253[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@202fa9f3[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@390bcd63[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@6f623af9[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 14400,
        "customfield_12312520": null,
        "customfield_12312521": "Sat Nov 14 16:00:09 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-11-14T16:00:09.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-9707/watchers",
            "watchCount": 6,
            "isWatching": false
        },
        "created": "2020-08-12T15:25:40.000+0000",
        "updated": "2020-11-14T16:00:09.000+0000",
        "timeoriginalestimate": null,
        "description": "The current threading model is very simple and does not scale. We currently use 1-2 dedicated threads per partition and they all run simultaneously, which is a huge problem if you have more partitions than logical or physical cores.\r\n\r\nThis task is to re-implement the threading model so that query execution uses a fixed (configurable) number of threads. Work will be broken down into stages and tasks and each in-process executor (running on a dedicated thread) will process its queue of tasks.\r\n\r\nThis process will be driven by a scheduler.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "4h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 14400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/attachment/13012090",
                "id": "13012090",
                "filename": "image-2020-09-24-22-46-46-959.png",
                "author": {
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=alippai",
                    "name": "alippai",
                    "key": "alippai",
                    "avatarUrls": {
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                        "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                        "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                    },
                    "displayName": "Adam Lippai",
                    "active": true,
                    "timeZone": "Etc/UTC"
                },
                "created": "2020-09-24T20:46:46.208+0000",
                "size": 257690,
                "mimeType": "image/png",
                "content": "https://issues.apache.org/jira/secure/attachment/13012090/image-2020-09-24-22-46-46-959.png"
            }
        ],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Rust] [DataFusion] Re-implement threading model",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17176481",
                    "id": "17176481",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I'll be curious what approach you take to prevent IO steps from blocking CPU work, we still haven't sorted out how we're dealing with that broadly in C++",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-08-12T16:59:51.654+0000",
                    "updated": "2020-08-12T16:59:51.654+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17176493",
                    "id": "17176493",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "body": "One approach I accidentally stumbled on was to have a dedicated thread\nreading from disk and then have other operators running with async and\nusing channels to send batches from the disk reader to the downstream\noperators. This is roughly how things are implemented today in DataFusion\n(but not leveraging async).\n\nThe advantage of this approach is that the reader thread is at least\nrunning in parallel to downstream operators processing previous batches.\nThe downside of course is having a dedicated thread per operator that reads\nfrom disk.\n\nI would be interested in making the Parquet crate async so that we can test\nasync end to end (even though I've been told that async is not good for\nfile io) but unfortunately the work to do that is non-trivial.\n\nOn Wed, Aug 12, 2020 at 11:00 AM Wes McKinney (Jira) <jira@apache.org>\n\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "created": "2020-08-12T17:12:00.073+0000",
                    "updated": "2020-08-12T17:12:00.073+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17176522",
                    "id": "17176522",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "[~andygrove] I am also very interested in this change (it is something we have been studying / thinking about this with [~pauldix]. What you have outlined (a fixed and configurable number of threads) is exactly our use case. I would enjoy collaborating with you if you have any need ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-08-12T18:11:25.008+0000",
                    "updated": "2020-08-12T18:11:25.008+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17176552",
                    "id": "17176552",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "body": "[~alamb]That would be great. I think [~jorgecarleitao] may also be interested. I have already prototyped this out but would welcome a design review before making the changes in DataFusion. I will start a Google doc for us to discuss this and will post a link here soon.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "created": "2020-08-12T19:28:20.648+0000",
                    "updated": "2020-08-12T19:28:20.648+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17176635",
                    "id": "17176635",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "body": "Here's the Google doc: https://docs.google.com/document/d/1NUiIKxgdiKrEv1H4JXVmk_nxq-eG9et7LKPD91Du-Io/edit?usp=sharing",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "created": "2020-08-12T22:38:23.728+0000",
                    "updated": "2020-08-12T22:38:23.728+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17195581",
                    "id": "17195581",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
                        "name": "jorgecarleitao",
                        "key": "jorgecarleitao",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
                        },
                        "displayName": "Jorge Leit\u00e3o",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Sold! Feel free to assign issues directly to me if you need help, even if just writing tests or documentation :)",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
                        "name": "jorgecarleitao",
                        "key": "jorgecarleitao",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
                        },
                        "displayName": "Jorge Leit\u00e3o",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2020-09-14T16:37:35.595+0000",
                    "updated": "2020-09-14T16:37:35.595+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17201435",
                    "id": "17201435",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
                        "name": "jorgecarleitao",
                        "key": "jorgecarleitao",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
                        },
                        "displayName": "Jorge Leit\u00e3o",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "I thought a bit about this, and I have an hypothesis: the core pattern in DataFusion today is:\r\n # {{ExecutionPlan}} is an iterator of\u00a0{{RecordBatchReader}} via the function {{build}}\r\n # {{RecordBatchReaders}} is an iterator of\u00a0{{RecordBatch}} via {{next_batch}}\r\n # {{ExecutionPlan}} 's\u00a0{{size_hint}} is given by {{output_partitioning}}\r\n # {{RecordBatchReaders}}'s {{size_hint}}\u00a0 is unknown, as it typically comes from scaning through a file\r\n\r\nIf this hypothesis holds, IMO we could convert {{ExecutionPlan}} to allow an {{IntoIter<Item=IntoIter<Item=RecordBatch>>}}\r\n\r\nwhich would allow to flatten the iterator over a set of threads. Threads switch context during I/O, e.g. when a thread finishes reading a block of batches in a CSV, it can switch to execute whatever it is happening in another place.\r\n\r\nThis will also give more visibility to a scheduler, as it has all the necessary information it needs to schedule tasks.\r\n\r\n[this answer in SO|https://stackoverflow.com/a/53176418/931303] uses IntoIter of IntoIter to implement a generic (single-threaded) {{merge_sort}}. This would also allow other architectures, as they would offload whole partitions to different processes. In our context, something like this (all static for now\r\n\r\n\r\n{code:java}\r\nfn merge_sorted<IterT: 'static + Send, IterIterT, T: 'static + Ord + Clone + fmt::Debug + Send>(arrays: IterIterT) -> Vec<T>\r\nwhere\r\n    IterT: IntoIterator<Item = T>,\r\n    IterIterT: IntoIterator<Item = IterT>,\r\n{\r\n    let all_values = Arc::new(Mutex::new(vec![]));\r\n    let threads: Vec<JoinHandle<()>> = arrays.into_iter().map(|array| {\r\n        let mutex_clone = Arc::clone(&all_values);\r\n        thread::spawn(move || {\r\n            let mut values: Vec<T> = array.into_iter().collect();\r\n            values.sort(); // this is wrong, but all information is available to do it\r\n            mutex_clone.lock().unwrap().extend_from_slice(&values);\r\n        })\r\n    }).collect();\r\n    for thread in threads {\r\n        thread.join().unwrap()\r\n    }\r\n    let result = all_values.lock().unwrap().clone();\r\n    result\r\n}\r\n{code}",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
                        "name": "jorgecarleitao",
                        "key": "jorgecarleitao",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
                        },
                        "displayName": "Jorge Leit\u00e3o",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2020-09-24T10:33:30.130+0000",
                    "updated": "2020-09-24T10:34:17.544+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17201716",
                    "id": "17201716",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "[~jorgecarleitao] -- I like this proposal. The one thing I always come back to is \"where is `thread::spawn`called\" -- is it called inside the plan (in which case we could end up spawning a lot of threads based on how many input partitions the data had.\r\n\r\nI wonder if there is some way to use a thread-pool here (or maybe that is a straightforward extension to what you are proposing).",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-09-24T18:29:23.530+0000",
                    "updated": "2020-09-24T18:29:23.530+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17201762",
                    "id": "17201762",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alippai",
                        "name": "alippai",
                        "key": "alippai",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Adam Lippai",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Speaking about the thread pools, my last suggestion wasn't accepted (or declined): [https://docs.google.com/document/d/1_wc6diy3YrRgEIhVIGzrO5AK8yhwfjWlmKtGnvbsrrY/edit#heading=h.4f9v08zbs2z3]\r\n\r\nThe use-case might be different, but recently Bevy created a rust task scheduler using context-specific threadpools: [https://bevyengine.org/news/bevy-0-2/]\r\n\r\nMy understanding is that Bevy and the linked GDocs (DAG vs 2-3 staged pipeline vs generic threadpool) is similar approach and I find it the most generic (but acceptable) solution.\r\n\r\n\u00a0\r\n\r\n\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alippai",
                        "name": "alippai",
                        "key": "alippai",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Adam Lippai",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2020-09-24T20:51:09.496+0000",
                    "updated": "2020-09-24T20:51:09.496+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17215335",
                    "id": "17215335",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "FWIW now that DataFusion uses `async` -- https://github.com/apache/arrow/pull/8285 -- I think the number of threads issue cited in this PR is a non-issue (as DataFusion no longer launches its own threads)",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-10-16T10:45:19.618+0000",
                    "updated": "2020-10-16T10:45:19.618+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13322291/comment/17232058",
                    "id": "17232058",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "body": "Closing this is as invalid because things have changed a lot since this was filed and we have now moved away from explicit thread management (mostly).",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "created": "2020-11-14T16:00:09.927+0000",
                    "updated": "2020-11-14T16:00:09.927+0000"
                }
            ],
            "maxResults": 11,
            "total": 11,
            "startAt": 0
        },
        "customfield_12311820": "0|z0hp80:",
        "customfield_12314139": null
    }
}