{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13335657",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657",
    "key": "ARROW-10320",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12348823",
                "id": "12348823",
                "description": "",
                "name": "3.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-01-25"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
            "name": "jorgecarleitao",
            "key": "jorgecarleitao",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
            },
            "displayName": "Jorge Leit\u00e3o",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333773",
                "id": "12333773",
                "name": "Rust"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12335005",
                "id": "12335005",
                "name": "Rust - DataFusion"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
            "name": "jorgecarleitao",
            "key": "jorgecarleitao",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
            },
            "displayName": "Jorge Leit\u00e3o",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
            "name": "jorgecarleitao",
            "key": "jorgecarleitao",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
            },
            "displayName": "Jorge Leit\u00e3o",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 12600,
            "total": 12600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 12600,
            "total": 12600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-10320/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 21,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501239",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao opened a new pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473\n\n\n   Recently, we introduced `async` to `execute`. This allowed us to parallelize multiple partitions as we denote an execution of a part (of a partition) as the unit of work. However, a part is often a large task composing multiple batches and steps.\r\n   \r\n   This PR makes all our execution nodes return a [futures::Stream](https://docs.rs/futures/0.3.6/futures/stream/trait.Stream.html) instead of an Iterator. For reference, a Stream is an iterator of futures, which in this case is a future of a `Result<RecordBatch>`.\r\n   \r\n   This effectively breaks the execution in smaller units of work (on which an individual unit is an operation returns a `Result<RecordBatch>`) allowing each task to chew smaller bits.\r\n   \r\n   This adds `futures` as a direct dependency of DataFusion (it was only a dev-dependency).\r\n   \r\n   This leads to a +10% degradation in aggregates in micro benchmarking, which IMO is expected given that there is more context switching to handle. However, I expect (hope?) this to be independent of the number of batches and partitions, and be offset by any async work we perform to our sources (readers) and sinks (writers).\r\n   \r\n   I did not take the time to optimize - the primary goal was to implement the idea, have it compile and pass tests, and have some discussion about it. I expect that we should be able to replace some of our operations by `join_all`, thereby scheduling multiple tasks at once (instead of waiting one by one).\r\n   \r\n   <details>\r\n    <summary>Benchmarks</summary>\r\n   \r\n   Aggregates:\r\n   ```\r\n   aggregate_query_no_group_by 15 12                                                                            \r\n                           time:   [908.71 us 961.16 us 1.0193 ms]\r\n                           change: [+5.9644% +10.567% +15.382%] (p = 0.00 < 0.05)\r\n                           Performance has regressed.\r\n   Found 7 outliers among 100 measurements (7.00%)\r\n     2 (2.00%) high mild\r\n     5 (5.00%) high severe\r\n   \r\n   aggregate_query_group_by 15 12                                                                            \r\n                           time:   [6.6902 ms 7.0747 ms 7.5420 ms]\r\n                           change: [+4.5521% +10.510% +18.352%] (p = 0.00 < 0.05)\r\n                           Performance has regressed.\r\n   Found 8 outliers among 100 measurements (8.00%)\r\n     2 (2.00%) high mild\r\n     6 (6.00%) high severe\r\n   \r\n   aggregate_query_group_by_with_filter 15 12                                                                             \r\n                           time:   [2.8901 ms 2.9207 ms 2.9531 ms]\r\n                           change: [-16.357% -8.7619% -2.2536%] (p = 0.01 < 0.05)\r\n                           Performance has improved.\r\n   Found 3 outliers among 100 measurements (3.00%)\r\n     3 (3.00%) high mild\r\n   ```\r\n   \r\n   Math:\r\n   ```\r\n   sqrt_20_9               time:   [6.9844 ms 7.0582 ms 7.1363 ms]                      \r\n                           change: [+0.0557% +1.5625% +3.0408%] (p = 0.05 < 0.05)\r\n                           Change within noise threshold.\r\n   Found 3 outliers among 100 measurements (3.00%)\r\n     2 (2.00%) high mild\r\n     1 (1.00%) high severe\r\n   \r\n   sqrt_20_12              time:   [2.8350 ms 2.9504 ms 3.1204 ms]                        \r\n                           change: [+3.8751% +8.2857% +14.671%] (p = 0.00 < 0.05)\r\n                           Performance has regressed.\r\n   Found 5 outliers among 100 measurements (5.00%)\r\n     2 (2.00%) high mild\r\n     3 (3.00%) high severe\r\n   \r\n   sqrt_22_12              time:   [14.888 ms 15.242 ms 15.620 ms]                       \r\n                           change: [+7.6388% +10.709% +14.098%] (p = 0.00 < 0.05)\r\n                           Performance has regressed.\r\n   Found 5 outliers among 100 measurements (5.00%)\r\n     3 (3.00%) high mild\r\n     2 (2.00%) high severe\r\n   \r\n   sqrt_22_14              time:   [23.710 ms 23.817 ms 23.953 ms]                       \r\n                           change: [-4.3401% -3.1824% -2.0952%] (p = 0.00 < 0.05)\r\n                           Performance has improved.\r\n   Found 11 outliers among 100 measurements (11.00%)\r\n     5 (5.00%) high mild\r\n     6 (6.00%) high severe\r\n   ```\r\n   </details>\r\n   \r\n   I admit that this is a bit outside my comfort zone, and someone with more experience in `async/await` could be of help.\r\n   \r\n   IMO this would integrate very nicely with ARROW-10307, ARROW-9275, I _think_ it would also help ARROW-9707, and I _think_ that it also opens the possibility consuming / producing batches from/to sources and sinks from flight.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-15T18:56:49.560+0000",
                    "updated": "2020-10-15T18:56:49.560+0000",
                    "started": "2020-10-15T18:56:49.559+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501239",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501240",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-709528557\n\n\n   FYI @alamb @vertexclique @maxburke\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-15T18:58:33.099+0000",
                    "updated": "2020-10-15T18:58:33.099+0000",
                    "started": "2020-10-15T18:58:33.099+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501240",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501244",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-709533249\n\n\n   https://issues.apache.org/jira/browse/ARROW-10320\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-15T19:07:03.934+0000",
                    "updated": "2020-10-15T19:07:03.934+0000",
                    "started": "2020-10-15T19:07:03.934+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501244",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501336",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-709648906\n\n\n   This is great to see. I ran a quick TPC-H query 1 benchmark against the 100 GB data set with this PR and saw no noticeable difference in performance, so the microbenchmark might not be so relevant here.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-15T23:55:46.108+0000",
                    "updated": "2020-10-15T23:55:46.108+0000",
                    "started": "2020-10-15T23:55:46.108+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501336",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501525",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on a change in pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#discussion_r506288365\n\n\n\n##########\nFile path: rust/datafusion/src/datasource/memory.rs\n##########\n@@ -135,6 +134,7 @@ mod tests {\n     use super::*;\n     use arrow::array::Int32Array;\n     use arrow::datatypes::{DataType, Field, Schema};\n+    use futures::StreamExt;\n\nReview comment:\n       If we are worried about a new dependency on `futures` we maybe could upgrade the version of tokio instead and  use the `StreamExt` from `tokio` instead from `futures`: https://docs.rs/tokio/0.3.0/tokio/stream/trait.StreamExt.html\r\n   \r\n   \r\n   \r\n   \n\n##########\nFile path: rust/datafusion/src/physical_plan/common.rs\n##########\n@@ -31,53 +32,58 @@ use array::{\n };\n use arrow::datatypes::{DataType, SchemaRef};\n use arrow::error::Result as ArrowResult;\n-use arrow::record_batch::{RecordBatch, RecordBatchReader};\n+use arrow::record_batch::RecordBatch;\n use arrow::{\n     array::{self, ArrayRef},\n     datatypes::Schema,\n };\n+use futures::{Stream, TryStreamExt};\n \n-/// Iterator over a vector of record batches\n-pub struct RecordBatchIterator {\n+/// Stream of record batches\n+pub struct SizedRecordBatchStream {\n\nReview comment:\n       `BufferedRecordBatchStream` might be more descriptive of what this struct does\n\n##########\nFile path: rust/datafusion/src/physical_plan/filter.rs\n##########\n@@ -98,72 +102,76 @@ impl ExecutionPlan for FilterExec {\n         }\n     }\n \n-    async fn execute(&self, partition: usize) -> Result<SendableRecordBatchReader> {\n-        Ok(Box::new(FilterExecIter {\n+    async fn execute(&self, partition: usize) -> Result<SendableRecordBatchStream> {\n+        Ok(Box::pin(FilterExecStream {\n             schema: self.input.schema().clone(),\n             predicate: self.predicate.clone(),\n             input: self.input.execute(partition).await?,\n         }))\n     }\n }\n \n-/// The FilterExec iterator wraps the input iterator and applies the predicate expression to\n+/// The FilterExec streams wraps the input iterator and applies the predicate expression to\n /// determine which rows to include in its output batches\n-struct FilterExecIter {\n+struct FilterExecStream {\n     /// Output schema, which is the same as the input schema for this operator\n     schema: SchemaRef,\n     /// The expression to filter on. This expression must evaluate to a boolean value.\n     predicate: Arc<dyn PhysicalExpr>,\n     /// The input partition to filter.\n-    input: SendableRecordBatchReader,\n+    input: SendableRecordBatchStream,\n+}\n+\n+fn batch_filter(\n+    batch: &RecordBatch,\n+    predicate: &Arc<dyn PhysicalExpr>,\n+) -> ArrowResult<RecordBatch> {\n+    predicate\n+        .evaluate(&batch)\n+        .map_err(ExecutionError::into_arrow_external_error)\n+        .and_then(|array| {\n+            array\n+                .as_any()\n+                .downcast_ref::<BooleanArray>()\n+                .ok_or(\n+                    ExecutionError::InternalError(\n+                        \"Filter predicate evaluated to non-boolean value\".to_string(),\n+                    )\n+                    .into_arrow_external_error(),\n+                )\n+                // apply predicate to each column\n+                .and_then(|predicate| {\n+                    batch\n+                        .columns()\n+                        .iter()\n+                        .map(|column| filter(column.as_ref(), predicate))\n+                        .collect::<ArrowResult<Vec<_>>>()\n+                })\n+        })\n+        // build RecordBatch\n+        .and_then(|columns| RecordBatch::try_new(batch.schema().clone(), columns))\n }\n \n-impl Iterator for FilterExecIter {\n+impl Stream for FilterExecStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    /// Get the next batch\n-    fn next(&mut self) -> Option<ArrowResult<RecordBatch>> {\n-        match self.input.next() {\n-            Some(Ok(batch)) => {\n-                // evaluate the filter predicate to get a boolean array indicating which rows\n-                // to include in the output\n-                Some(\n-                    self.predicate\n-                        .evaluate(&batch)\n-                        .map_err(ExecutionError::into_arrow_external_error)\n-                        .and_then(|array| {\n-                            array\n-                                .as_any()\n-                                .downcast_ref::<BooleanArray>()\n-                                .ok_or(\n-                                    ExecutionError::InternalError(\n-                                        \"Filter predicate evaluated to non-boolean value\"\n-                                            .to_string(),\n-                                    )\n-                                    .into_arrow_external_error(),\n-                                )\n-                                // apply predicate to each column\n-                                .and_then(|predicate| {\n-                                    batch\n-                                        .columns()\n-                                        .iter()\n-                                        .map(|column| filter(column.as_ref(), predicate))\n-                                        .collect::<ArrowResult<Vec<_>>>()\n-                                })\n-                        })\n-                        // build RecordBatch\n-                        .and_then(|columns| {\n-                            RecordBatch::try_new(batch.schema().clone(), columns)\n-                        }),\n-                )\n-            }\n+    fn poll_next(\n+        mut self: Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n+        self.input.poll_next_unpin(cx).map(|x| match x {\n+            Some(Ok(batch)) => Some(batch_filter(&batch, &self.predicate)),\n\nReview comment:\n       this is nice -- it means the code doesn't have to have read all the batches in order to filter each one\n\n##########\nFile path: rust/datafusion/tests/user_defined_plan.rs\n##########\n@@ -468,51 +469,69 @@ fn accumulate_batch(\n         .expect(\"Column 1 is not revenue\");\n \n     for row in 0..num_rows {\n-        add_row(top_values, customer_id.value(row), revenue.value(row), k);\n+        add_row(\n+            &mut top_values,\n+            customer_id.value(row),\n+            revenue.value(row),\n+            k,\n+        );\n     }\n-    Ok(())\n+    Ok(top_values)\n }\n \n-impl Iterator for TopKReader {\n+impl Stream for TopKReader {\n     type Item = std::result::Result<RecordBatch, ArrowError>;\n \n-    /// Reads the next `RecordBatch`.\n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        mut self: std::pin::Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         if self.done {\n-            return None;\n+            return Poll::Ready(None);\n         }\n-\n-        // Hard coded implementation for sales / customer_id example\n-        let mut top_values: BTreeMap<i64, String> = BTreeMap::new();\n+        // this aggregates and thus returns a single RecordBatch.\n+        self.done = true;\n \n         // take this as immutable\n-        let k = &self.k;\n+        let k = self.k;\n+        let schema = self.schema().clone();\n \n-        self.input\n+        let top_values = self\n+            .input\n             .as_mut()\n-            .into_iter()\n-            .map(|batch| accumulate_batch(&batch?, &mut top_values, k))\n-            .collect::<Result<()>>()\n-            .unwrap();\n-\n-        // make output by walking over the map backwards (so values are descending)\n-        let (revenue, customer): (Vec<i64>, Vec<&String>) =\n-            top_values.iter().rev().unzip();\n-\n-        let customer: Vec<&str> = customer.iter().map(|&s| &**s).collect();\n+            // Hard coded implementation for sales / customer_id example as BTree\n+            .try_fold(\n+                BTreeMap::<i64, String>::new(),\n+                move |top_values, batch| async move {\n+                    accumulate_batch(&batch, top_values, &k)\n+                        .map_err(ExecutionError::into_arrow_external_error)\n+                },\n+            );\n+\n+        let top_values = top_values.map(|top_values| match top_values {\n+            Ok(top_values) => {\n+                // make output by walking over the map backwards (so values are descending)\n+                let (revenue, customer): (Vec<i64>, Vec<&String>) =\n+                    top_values.iter().rev().unzip();\n+\n+                let customer: Vec<&str> = customer.iter().map(|&s| &**s).collect();\n+                Ok(RecordBatch::try_new(\n+                    schema,\n+                    vec![\n+                        Arc::new(StringArray::from(customer)),\n+                        Arc::new(Int64Array::from(revenue)),\n+                    ],\n+                )?)\n+            }\n+            Err(e) => Err(e),\n+        });\n+        let mut top_values = Box::pin(top_values.into_stream());\n\nReview comment:\n       this is very cool to see how the user defined code got transformed to a `Stream`\n\n##########\nFile path: rust/datafusion/src/physical_plan/merge.rs\n##########\n@@ -100,27 +103,29 @@ impl ExecutionPlan for MergeExec {\n                 self.input.execute(0).await\n             }\n             _ => {\n-                let tasks = (0..input_partitions)\n-                    .map(|part_i| {\n-                        let input = self.input.clone();\n-                        tokio::spawn(async move {\n-                            let it = input.execute(part_i).await?;\n-                            common::collect(it)\n-                        })\n+                let tasks = (0..input_partitions).map(|part_i| {\n+                    let input = self.input.clone();\n+                    tokio::spawn(async move {\n+                        let stream = input.execute(part_i).await?;\n+                        common::collect(stream).await\n\nReview comment:\n       I am still concerned that these calls to `collect` effectively buffer all the input before producing any output -- this both will likely consume more memory than needed as well as being a 'pipeline breaker' (nothing that relies on the output of the `Merge` can run until *all* of the merge inputs have been produced). \r\n   \r\n   We could peraps use `chain` here to fuse the streams together -- https://docs.rs/tokio/0.3.0/tokio/stream/trait.StreamExt.html#method.chain. Using chain would avoid the need to buffer the intermediate results (aka the collect), but  it would also likely cause the input partitions to run one after the other rather than in parallel_\r\n   \r\n   Another thought I had would be to use something fancier like a `channel` that all the substreams write to. \r\n   \r\n   But in any event that could be done in some future PR -- I think this code is better than master, and a step forward. \r\n   \r\n   \n\n##########\nFile path: rust/datafusion/src/physical_plan/parquet.rs\n##########\n@@ -197,24 +197,27 @@ fn read_file(\n     Ok(())\n }\n \n-struct ParquetIterator {\n+struct ParquetStream {\n     schema: SchemaRef,\n     response_rx: Receiver<Option<ArrowResult<RecordBatch>>>,\n }\n \n-impl Iterator for ParquetIterator {\n+impl Stream for ParquetStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        self: std::pin::Pin<&mut Self>,\n+        _: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         match self.response_rx.recv() {\n\nReview comment:\n       This is getting closer to `async` parquet reader \ud83d\udc4d \n\n##########\nFile path: rust/datafusion/src/physical_plan/hash_aggregate.rs\n##########\n@@ -505,62 +513,88 @@ fn aggregate_batch(\n \n             // 1.3\n             match mode {\n-                AggregateMode::Partial => accum.update_batch(values),\n-                AggregateMode::Final => accum.merge_batch(values),\n+                AggregateMode::Partial => {\n+                    accum.update_batch(values)?;\n+                }\n+                AggregateMode::Final => {\n+                    accum.merge_batch(values)?;\n+                }\n             }\n+            Ok(accum)\n         })\n-        .collect::<Result<()>>()\n+        .collect::<Result<Vec<_>>>()\n }\n \n-impl Iterator for HashAggregateIterator {\n+impl Stream for HashAggregateStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        mut self: std::pin::Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         if self.finished {\n-            return None;\n+            return Poll::Ready(None);\n         }\n \n         // return single batch\n         self.finished = true;\n \n-        let mut accumulators = match create_accumulators(&self.aggr_expr) {\n+        let accumulators = match create_accumulators(&self.aggr_expr) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n \n         let expressions = match aggregate_expressions(&self.aggr_expr, &self.mode) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n+        let expressions = Arc::new(expressions);\n \n         let mode = self.mode;\n         let schema = self.schema();\n \n         // 1 for each batch, update / merge accumulators with the expressions' values\n-        match self\n+        // future is ready when all batches are computed\n+        let future = self\n             .input\n             .as_mut()\n-            .into_iter()\n-            .map(|batch| {\n-                aggregate_batch(&mode, &batch?, &mut accumulators, &expressions)\n-                    .map_err(ExecutionError::into_arrow_external_error)\n-            })\n-            .collect::<ArrowResult<()>>()\n-        {\n-            Err(e) => return Some(Err(e)),\n-            Ok(_) => {}\n-        }\n+            .try_fold(\n+                // pass the expressions on every fold to handle closures' mutability\n+                (accumulators, expressions),\n\nReview comment:\n       this is cool -- to incrementally accumulate the aggregates in the strems\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T11:18:49.059+0000",
                    "updated": "2020-10-16T11:18:49.059+0000",
                    "started": "2020-10-16T11:18:49.058+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501525",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501540",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vertexclique commented on a change in pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#discussion_r506357109\n\n\n\n##########\nFile path: rust/datafusion/src/physical_plan/hash_aggregate.rs\n##########\n@@ -331,72 +337,74 @@ impl GroupedHashAggregateIterator {\n }\n \n type AccumulatorSet = Vec<Box<dyn Accumulator>>;\n+type Accumulators = FnvHashMap<Vec<GroupByScalar>, (AccumulatorSet, Box<Vec<u32>>)>;\n \n-impl Iterator for GroupedHashAggregateIterator {\n+impl Stream for GroupedHashAggregateStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        mut self: std::pin::Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         if self.finished {\n-            return None;\n+            return Poll::Ready(None);\n         }\n \n         // return single batch\n         self.finished = true;\n \n-        let mode = &self.mode;\n-        let group_expr = &self.group_expr;\n-        let aggr_expr = &self.aggr_expr;\n+        let mode = self.mode.clone();\n+        let group_expr = self.group_expr.clone();\n+        let aggr_expr = self.aggr_expr.clone();\n+        let schema = self.schema.clone();\n \n         // the expressions to evaluate the batch, one vec of expressions per aggregation\n         let aggregate_expressions = match aggregate_expressions(&aggr_expr, &mode) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n \n         // mapping key -> (set of accumulators, indices of the key in the batch)\n         // * the indexes are updated at each row\n         // * the accumulators are updated at the end of each batch\n         // * the indexes are `clear`ed at the end of each batch\n-        let mut accumulators: FnvHashMap<\n-            Vec<GroupByScalar>,\n-            (AccumulatorSet, Box<Vec<u32>>),\n-        > = FnvHashMap::default();\n+        //let mut accumulators: Accumulators = FnvHashMap::default();\n \n         // iterate over all input batches and update the accumulators\n-        match self\n-            .input\n-            .as_mut()\n-            .into_iter()\n-            .map(|batch| {\n+        let future = self.input.as_mut().try_fold(\n+            Accumulators::default(),\n+            |accumulators, batch| async {\n                 group_aggregate_batch(\n                     &mode,\n                     &group_expr,\n                     &aggr_expr,\n-                    &batch?,\n-                    &mut accumulators,\n+                    batch,\n+                    accumulators,\n                     &aggregate_expressions,\n                 )\n                 .map_err(ExecutionError::into_arrow_external_error)\n-            })\n-            .collect::<ArrowResult<()>>()\n-        {\n-            Err(e) => return Some(Err(e)),\n-            Ok(_) => {}\n-        }\n+            },\n+        );\n \n-        Some(\n-            create_batch_from_map(\n-                &self.mode,\n-                &accumulators,\n-                self.group_expr.len(),\n-                &self.schema,\n-            )\n-            .map_err(ExecutionError::into_arrow_external_error),\n-        )\n+        let future = future.map(|accumulators| match accumulators {\n+            Ok(accumulators) => {\n+                create_batch_from_map(&mode, &accumulators, group_expr.len(), &schema)\n+            }\n+            Err(e) => Err(e),\n+        });\n\nReview comment:\n       Can you use `map` instead of pattern matching? since err escalation looks redundant.\n\n##########\nFile path: rust/datafusion/src/physical_plan/hash_aggregate.rs\n##########\n@@ -505,62 +513,88 @@ fn aggregate_batch(\n \n             // 1.3\n             match mode {\n-                AggregateMode::Partial => accum.update_batch(values),\n-                AggregateMode::Final => accum.merge_batch(values),\n+                AggregateMode::Partial => {\n+                    accum.update_batch(values)?;\n+                }\n+                AggregateMode::Final => {\n+                    accum.merge_batch(values)?;\n+                }\n             }\n+            Ok(accum)\n         })\n-        .collect::<Result<()>>()\n+        .collect::<Result<Vec<_>>>()\n }\n \n-impl Iterator for HashAggregateIterator {\n+impl Stream for HashAggregateStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        mut self: std::pin::Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         if self.finished {\n-            return None;\n+            return Poll::Ready(None);\n         }\n \n         // return single batch\n         self.finished = true;\n \n-        let mut accumulators = match create_accumulators(&self.aggr_expr) {\n+        let accumulators = match create_accumulators(&self.aggr_expr) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n \n         let expressions = match aggregate_expressions(&self.aggr_expr, &self.mode) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n+        let expressions = Arc::new(expressions);\n \n         let mode = self.mode;\n         let schema = self.schema();\n \n         // 1 for each batch, update / merge accumulators with the expressions' values\n-        match self\n+        // future is ready when all batches are computed\n+        let future = self\n             .input\n             .as_mut()\n-            .into_iter()\n-            .map(|batch| {\n-                aggregate_batch(&mode, &batch?, &mut accumulators, &expressions)\n-                    .map_err(ExecutionError::into_arrow_external_error)\n-            })\n-            .collect::<ArrowResult<()>>()\n-        {\n-            Err(e) => return Some(Err(e)),\n-            Ok(_) => {}\n-        }\n+            .try_fold(\n+                // pass the expressions on every fold to handle closures' mutability\n+                (accumulators, expressions),\n+                |(acc, expr), batch| async move {\n+                    aggregate_batch(&mode, &batch, acc, &expr)\n+                        .map_err(ExecutionError::into_arrow_external_error)\n+                        .map(|agg| (agg, expr))\n+                },\n+            )\n+            // pick the accumulators (disregard the expressions)\n+            .map(|e| e.map(|e| e.0));\n+\n+        let future = future.map(|b| {\n+            match b {\n+                Err(e) => return Err(e),\n+                Ok(acc) => {\n+                    // 2 convert values to a record batch\n\nReview comment:\n       2 is `to` i presume. Right :) ?\n\n##########\nFile path: rust/datafusion/src/physical_plan/hash_aggregate.rs\n##########\n@@ -505,62 +513,88 @@ fn aggregate_batch(\n \n             // 1.3\n             match mode {\n-                AggregateMode::Partial => accum.update_batch(values),\n-                AggregateMode::Final => accum.merge_batch(values),\n+                AggregateMode::Partial => {\n+                    accum.update_batch(values)?;\n+                }\n+                AggregateMode::Final => {\n+                    accum.merge_batch(values)?;\n+                }\n             }\n+            Ok(accum)\n         })\n-        .collect::<Result<()>>()\n+        .collect::<Result<Vec<_>>>()\n }\n \n-impl Iterator for HashAggregateIterator {\n+impl Stream for HashAggregateStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        mut self: std::pin::Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         if self.finished {\n-            return None;\n+            return Poll::Ready(None);\n         }\n \n         // return single batch\n         self.finished = true;\n \n-        let mut accumulators = match create_accumulators(&self.aggr_expr) {\n+        let accumulators = match create_accumulators(&self.aggr_expr) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n \n         let expressions = match aggregate_expressions(&self.aggr_expr, &self.mode) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n+        let expressions = Arc::new(expressions);\n \n         let mode = self.mode;\n         let schema = self.schema();\n \n         // 1 for each batch, update / merge accumulators with the expressions' values\n-        match self\n+        // future is ready when all batches are computed\n+        let future = self\n             .input\n             .as_mut()\n-            .into_iter()\n-            .map(|batch| {\n-                aggregate_batch(&mode, &batch?, &mut accumulators, &expressions)\n-                    .map_err(ExecutionError::into_arrow_external_error)\n-            })\n-            .collect::<ArrowResult<()>>()\n-        {\n-            Err(e) => return Some(Err(e)),\n-            Ok(_) => {}\n-        }\n+            .try_fold(\n+                // pass the expressions on every fold to handle closures' mutability\n+                (accumulators, expressions),\n+                |(acc, expr), batch| async move {\n+                    aggregate_batch(&mode, &batch, acc, &expr)\n+                        .map_err(ExecutionError::into_arrow_external_error)\n+                        .map(|agg| (agg, expr))\n+                },\n+            )\n+            // pick the accumulators (disregard the expressions)\n+            .map(|e| e.map(|e| e.0));\n+\n+        let future = future.map(|b| {\n+            match b {\n+                Err(e) => return Err(e),\n+                Ok(acc) => {\n+                    // 2 convert values to a record batch\n+                    finalize_aggregation(&acc, &mode)\n+                        .map_err(ExecutionError::into_arrow_external_error)\n+                        .and_then(|columns| RecordBatch::try_new(schema.clone(), columns))\n+                }\n+            }\n+        });\n\nReview comment:\n       Same map simplification here probably.\n\n##########\nFile path: rust/datafusion/src/datasource/memory.rs\n##########\n@@ -135,6 +134,7 @@ mod tests {\n     use super::*;\n     use arrow::array::Int32Array;\n     use arrow::datatypes::{DataType, Field, Schema};\n+    use futures::StreamExt;\n\nReview comment:\n       Please not do that. Futures interfaces are not compatible with other APIs in the ecosystem. This is a good implementation which is adaptable to tokio, async-std, bastion and others.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T12:24:34.841+0000",
                    "updated": "2020-10-16T12:24:34.841+0000",
                    "started": "2020-10-16T12:24:34.841+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501540",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501566",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710075328\n\n\n   I am still not entirely happy with this, and I think that we need a further step to make this work well, which is the reason I placed this back to draft.\r\n   \r\n   Essentially, I misinterpreted what a `Stream` is used for. A `stream` of record batches will only return the next batch _after_ the previous one was (async) computed. Therefore, we can't parallelize, as we are blocked by the execution of the previous batch. Therefore, this PR is only useful for situations on which we are reading batches that, we may need to wait for.\r\n   \r\n   I think that the solution is to put a `future` as the `Item` of the `Stream`, so that we can collect all those futures and perform `join_all().await`, thereby sending every task to the scheduler.\r\n   \r\n   PR #8480 is the proposal for that. I doubles the performance of the larger projections benchmarks (purely due to scheduling / threading).\r\n   \r\n   Note that each PR solves a different problem: this one is related to the fact that some batches may not be available yet (and thus we should not block), the other one is related to the fact that some operations can be parallelized (and thus we should `spawn`). I think that together they address the main issues.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:17:25.298+0000",
                    "updated": "2020-10-16T14:17:25.298+0000",
                    "started": "2020-10-16T14:17:25.298+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501566",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501567",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao edited a comment on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710075328\n\n\n   I am still not entirely happy with this, and I think that we need a further step to make this work well, which is the reason I placed this back to draft.\r\n   \r\n   Essentially, I misinterpreted what a `Stream` is used for. A `stream` of record batches will only return the next batch _after_ the previous one was (async) computed. Therefore, we can't parallelize, as we are blocked by the execution of the previous batch. Therefore, this PR is only useful for situations on which we are reading batches that we may need to wait for.\r\n   \r\n   I think that the solution is to put a `future` as the `Item` of the `Stream`, so that we can collect all those futures and perform `join_all().await`, thereby sending every task to the scheduler.\r\n   \r\n   PR #8480 is the proposal for that. I doubles the performance of the larger projections benchmarks (purely due to scheduling / threading).\r\n   \r\n   Note that each PR solves a different problem: this one is related to the fact that some batches may not be available yet (and thus we should not block), the other one is related to the fact that some operations can be parallelized (and thus we should `spawn`). I think that together they address the main issues.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:17:59.331+0000",
                    "updated": "2020-10-16T14:17:59.331+0000",
                    "started": "2020-10-16T14:17:59.331+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501567",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501568",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao edited a comment on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710075328\n\n\n   I am still not entirely happy with this, and I think that we need a further step to make this work well, which is the reason I placed this back to draft.\r\n   \r\n   Essentially, I misinterpreted what a `Stream` is used for. A `stream` of record batches will only return the next batch _after_ the previous one was (async) computed. Therefore, we can't parallelize, as we are blocked by the execution of the previous batch. Therefore, this PR is only useful for situations on which we are reading batches that we may need to wait for.\r\n   \r\n   I think that the solution is to put a `future` as the `Item` of the `Stream`, so that we can collect all those futures and perform `join_all().await`, thereby sending every task to the scheduler.\r\n   \r\n   PR #8480 is the proposal for that. It doubles the performance of the larger projections benchmarks (purely due to scheduling / threading).\r\n   \r\n   Note that each PR solves a different problem: this one is related to the fact that some batches may not be available yet (and thus we should not block), the other one is related to the fact that some operations can be parallelized (and thus we should `spawn`). I think that together they address the main issues.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:18:13.533+0000",
                    "updated": "2020-10-16T14:18:13.533+0000",
                    "started": "2020-10-16T14:18:13.532+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501568",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501577",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710090984\n\n\n   > A `stream` of record batches will only return the next batch _after_ the previous one was (async) computed. Therefore, we can't parallelize, as we are blocked by the execution of the previous batch.\r\n   \r\n   That sounds like exactly what we need. We compute partitions in parallel and each partition produces an ordered set of batches. In some cases, it is critical that the order is deterministic.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:45:51.387+0000",
                    "updated": "2020-10-16T14:45:51.387+0000",
                    "started": "2020-10-16T14:45:51.387+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501577",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501578",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove edited a comment on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710090984\n\n\n   > A `stream` of record batches will only return the next batch _after_ the previous one was (async) computed. Therefore, we can't parallelize, as we are blocked by the execution of the previous batch.\r\n   \r\n   That sounds like exactly what we need. We compute partitions in parallel and each partition produces an ordered set of batches. In some cases, it is critical that the order is deterministic.\r\n   \r\n   The benefit of this PR is that we don't need to wait for each operator to complete before the next one starts.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:47:15.720+0000",
                    "updated": "2020-10-16T14:47:15.720+0000",
                    "started": "2020-10-16T14:47:15.720+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501578",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501579",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on a change in pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#discussion_r506503915\n\n\n\n##########\nFile path: rust/datafusion/src/physical_plan/merge.rs\n##########\n@@ -100,27 +103,29 @@ impl ExecutionPlan for MergeExec {\n                 self.input.execute(0).await\n             }\n             _ => {\n-                let tasks = (0..input_partitions)\n-                    .map(|part_i| {\n-                        let input = self.input.clone();\n-                        tokio::spawn(async move {\n-                            let it = input.execute(part_i).await?;\n-                            common::collect(it)\n-                        })\n+                let tasks = (0..input_partitions).map(|part_i| {\n+                    let input = self.input.clone();\n+                    tokio::spawn(async move {\n+                        let stream = input.execute(part_i).await?;\n+                        common::collect(stream).await\n\nReview comment:\n       Yes, collect is the reason we don't see better performance from this PR IMO. I agree that this can be fixed in a separate PR.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:48:29.294+0000",
                    "updated": "2020-10-16T14:48:29.294+0000",
                    "started": "2020-10-16T14:48:29.294+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501579",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501580",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove edited a comment on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710090984\n\n\n   > A `stream` of record batches will only return the next batch _after_ the previous one was (async) computed. Therefore, we can't parallelize, as we are blocked by the execution of the previous batch.\r\n   \r\n   That sounds like exactly what we need. We compute partitions in parallel and each partition produces an ordered set of batches. In some cases, it is critical that the order is deterministic.\r\n   \r\n   The benefit of this PR is that we don't need to wait for each operator to complete before the next one starts (once we remove the use of `collect` everywhere).\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:49:32.410+0000",
                    "updated": "2020-10-16T14:49:32.410+0000",
                    "started": "2020-10-16T14:49:32.410+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501580",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501584",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710096379\n\n\n   > A stream of record batches will only return the next batch after the previous one was (async) computed. Therefore, we can't parallelize, as we are blocked by the execution of the previous batch. Therefore, this PR is only useful for situations on which we are reading batches that we may need to wait for.\r\n   \r\n   @jorgecarleitao  -- I personally think leaving the interface to be `Stream<RecordBatch>` is the way to go. \r\n   \r\n   Among other things, this interface allows \"backpressure\" so that we don't end up buffering intermediate results if one operator (e.g. filter) can produce record batches than its consumer can process them (e.g. aggregate). \r\n   \r\n   If we want to add additional parallelism with a tunable cost of additional buffering, we could keep the interface of this PR and add an operator like \"Buffer\". Buffer would calculate and store some number of `RecordBatches`, perhaps in a channel, as separate tasks in advance of when a batch was requested. \r\n   \r\n   Then the user of DataFusion could control how much more buffering they were willing to accept in order to get more parallelism. \r\n   \r\n   I think an approach like https://github.com/apache/arrow/pull/8480 is cool, but the choice of the aggregate, for example, to compute the input as fast as possible in new tasks, even if the aggregate\r\n   \r\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-16T14:55:27.996+0000",
                    "updated": "2020-10-16T14:55:27.996+0000",
                    "started": "2020-10-16T14:55:27.996+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501584",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501731",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#discussion_r506791355\n\n\n\n##########\nFile path: rust/datafusion/src/physical_plan/hash_aggregate.rs\n##########\n@@ -505,62 +513,88 @@ fn aggregate_batch(\n \n             // 1.3\n             match mode {\n-                AggregateMode::Partial => accum.update_batch(values),\n-                AggregateMode::Final => accum.merge_batch(values),\n+                AggregateMode::Partial => {\n+                    accum.update_batch(values)?;\n+                }\n+                AggregateMode::Final => {\n+                    accum.merge_batch(values)?;\n+                }\n             }\n+            Ok(accum)\n         })\n-        .collect::<Result<()>>()\n+        .collect::<Result<Vec<_>>>()\n }\n \n-impl Iterator for HashAggregateIterator {\n+impl Stream for HashAggregateStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        mut self: std::pin::Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         if self.finished {\n-            return None;\n+            return Poll::Ready(None);\n         }\n \n         // return single batch\n         self.finished = true;\n \n-        let mut accumulators = match create_accumulators(&self.aggr_expr) {\n+        let accumulators = match create_accumulators(&self.aggr_expr) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n \n         let expressions = match aggregate_expressions(&self.aggr_expr, &self.mode) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n+        let expressions = Arc::new(expressions);\n \n         let mode = self.mode;\n         let schema = self.schema();\n \n         // 1 for each batch, update / merge accumulators with the expressions' values\n-        match self\n+        // future is ready when all batches are computed\n+        let future = self\n             .input\n             .as_mut()\n-            .into_iter()\n-            .map(|batch| {\n-                aggregate_batch(&mode, &batch?, &mut accumulators, &expressions)\n-                    .map_err(ExecutionError::into_arrow_external_error)\n-            })\n-            .collect::<ArrowResult<()>>()\n-        {\n-            Err(e) => return Some(Err(e)),\n-            Ok(_) => {}\n-        }\n+            .try_fold(\n+                // pass the expressions on every fold to handle closures' mutability\n+                (accumulators, expressions),\n+                |(acc, expr), batch| async move {\n+                    aggregate_batch(&mode, &batch, acc, &expr)\n+                        .map_err(ExecutionError::into_arrow_external_error)\n+                        .map(|agg| (agg, expr))\n+                },\n+            )\n+            // pick the accumulators (disregard the expressions)\n+            .map(|e| e.map(|e| e.0));\n+\n+        let future = future.map(|b| {\n+            match b {\n+                Err(e) => return Err(e),\n+                Ok(acc) => {\n+                    // 2 convert values to a record batch\n\nReview comment:\n       it is `2.`, referring to the item number two in the list of items above.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-17T04:13:40.997+0000",
                    "updated": "2020-10-17T04:13:40.997+0000",
                    "started": "2020-10-17T04:13:40.996+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501731",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501732",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#issuecomment-710744576\n\n\n   I agree with you that #8480 has other issues that we want to avoid. Therefore, I placed this back as ready to review.\r\n   \r\n   Thanks a lot for the comments so far: this concurrency stuff is new to me and thus your guidance is really appreciated here.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-17T04:15:54.377+0000",
                    "updated": "2020-10-17T04:15:54.377+0000",
                    "started": "2020-10-17T04:15:54.376+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501732",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/501904",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#discussion_r507174314\n\n\n\n##########\nFile path: rust/datafusion/src/physical_plan/common.rs\n##########\n@@ -31,53 +32,58 @@ use array::{\n };\n use arrow::datatypes::{DataType, SchemaRef};\n use arrow::error::Result as ArrowResult;\n-use arrow::record_batch::{RecordBatch, RecordBatchReader};\n+use arrow::record_batch::RecordBatch;\n use arrow::{\n     array::{self, ArrayRef},\n     datatypes::Schema,\n };\n+use futures::{Stream, TryStreamExt};\n \n-/// Iterator over a vector of record batches\n-pub struct RecordBatchIterator {\n+/// Stream of record batches\n+pub struct SizedRecordBatchStream {\n\nReview comment:\n       I was thinking to reserve `Buffered` to a stream that buffers N entries. This one is already initialized with everything via `new`. This is more like the [`iter`](https://docs.rs/futures/0.3.6/futures/stream/fn.iter.html), with a fixed known len and a known schema. IMO we should avoid using this struct, as it requires us to collect to it somewhere.\r\n   \n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-18T15:05:57.186+0000",
                    "updated": "2020-10-18T15:05:57.186+0000",
                    "started": "2020-10-18T15:05:57.186+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "501904",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/502090",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on a change in pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#discussion_r507632793\n\n\n\n##########\nFile path: rust/datafusion/src/physical_plan/common.rs\n##########\n@@ -31,53 +32,58 @@ use array::{\n };\n use arrow::datatypes::{DataType, SchemaRef};\n use arrow::error::Result as ArrowResult;\n-use arrow::record_batch::{RecordBatch, RecordBatchReader};\n+use arrow::record_batch::RecordBatch;\n use arrow::{\n     array::{self, ArrayRef},\n     datatypes::Schema,\n };\n+use futures::{Stream, TryStreamExt};\n \n-/// Iterator over a vector of record batches\n-pub struct RecordBatchIterator {\n+/// Stream of record batches\n+pub struct SizedRecordBatchStream {\n\nReview comment:\n       Yeah, I was thinking it would be nice to imply in this struct's name somehow that it should be avoided if possible, because, as you say, it requires buffering / collecting up the `RecordBatch`es before producing any results\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-19T10:16:52.016+0000",
                    "updated": "2020-10-19T10:16:52.016+0000",
                    "started": "2020-10-19T10:16:52.016+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "502090",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/502523",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473#discussion_r508230895\n\n\n\n##########\nFile path: rust/datafusion/src/physical_plan/hash_aggregate.rs\n##########\n@@ -331,72 +337,74 @@ impl GroupedHashAggregateIterator {\n }\n \n type AccumulatorSet = Vec<Box<dyn Accumulator>>;\n+type Accumulators = FnvHashMap<Vec<GroupByScalar>, (AccumulatorSet, Box<Vec<u32>>)>;\n \n-impl Iterator for GroupedHashAggregateIterator {\n+impl Stream for GroupedHashAggregateStream {\n     type Item = ArrowResult<RecordBatch>;\n \n-    fn next(&mut self) -> Option<Self::Item> {\n+    fn poll_next(\n+        mut self: std::pin::Pin<&mut Self>,\n+        cx: &mut Context<'_>,\n+    ) -> Poll<Option<Self::Item>> {\n         if self.finished {\n-            return None;\n+            return Poll::Ready(None);\n         }\n \n         // return single batch\n         self.finished = true;\n \n-        let mode = &self.mode;\n-        let group_expr = &self.group_expr;\n-        let aggr_expr = &self.aggr_expr;\n+        let mode = self.mode.clone();\n+        let group_expr = self.group_expr.clone();\n+        let aggr_expr = self.aggr_expr.clone();\n+        let schema = self.schema.clone();\n \n         // the expressions to evaluate the batch, one vec of expressions per aggregation\n         let aggregate_expressions = match aggregate_expressions(&aggr_expr, &mode) {\n             Ok(e) => e,\n-            Err(e) => return Some(Err(ExecutionError::into_arrow_external_error(e))),\n+            Err(e) => {\n+                return Poll::Ready(Some(Err(ExecutionError::into_arrow_external_error(\n+                    e,\n+                ))))\n+            }\n         };\n \n         // mapping key -> (set of accumulators, indices of the key in the batch)\n         // * the indexes are updated at each row\n         // * the accumulators are updated at the end of each batch\n         // * the indexes are `clear`ed at the end of each batch\n-        let mut accumulators: FnvHashMap<\n-            Vec<GroupByScalar>,\n-            (AccumulatorSet, Box<Vec<u32>>),\n-        > = FnvHashMap::default();\n+        //let mut accumulators: Accumulators = FnvHashMap::default();\n \n         // iterate over all input batches and update the accumulators\n-        match self\n-            .input\n-            .as_mut()\n-            .into_iter()\n-            .map(|batch| {\n+        let future = self.input.as_mut().try_fold(\n+            Accumulators::default(),\n+            |accumulators, batch| async {\n                 group_aggregate_batch(\n                     &mode,\n                     &group_expr,\n                     &aggr_expr,\n-                    &batch?,\n-                    &mut accumulators,\n+                    batch,\n+                    accumulators,\n                     &aggregate_expressions,\n                 )\n                 .map_err(ExecutionError::into_arrow_external_error)\n-            })\n-            .collect::<ArrowResult<()>>()\n-        {\n-            Err(e) => return Some(Err(e)),\n-            Ok(_) => {}\n-        }\n+            },\n+        );\n \n-        Some(\n-            create_batch_from_map(\n-                &self.mode,\n-                &accumulators,\n-                self.group_expr.len(),\n-                &self.schema,\n-            )\n-            .map_err(ExecutionError::into_arrow_external_error),\n-        )\n+        let future = future.map(|accumulators| match accumulators {\n+            Ok(accumulators) => {\n+                create_batch_from_map(&mode, &accumulators, group_expr.len(), &schema)\n+            }\n+            Err(e) => Err(e),\n+        });\n\nReview comment:\n       Good point. Fixed (and below).\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-20T06:07:10.962+0000",
                    "updated": "2020-10-20T06:07:10.962+0000",
                    "started": "2020-10-20T06:07:10.962+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "502523",
                    "issueId": "13335657"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/worklog/502809",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao closed pull request #8473:\nURL: https://github.com/apache/arrow/pull/8473\n\n\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-20T18:23:38.477+0000",
                    "updated": "2020-10-20T18:23:38.477+0000",
                    "started": "2020-10-20T18:23:38.477+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "502809",
                    "issueId": "13335657"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 12600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@46958d7c[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@105eeabc[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3ee6d99d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@590adff7[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@32696734[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@745dd3ab[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7c7fc68c[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@73055b93[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@a2cd200[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@10768865[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@12bf6741[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@4bbf6f46[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 12600,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Oct 20 18:23:44 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-10-20T18:23:44.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-10320/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2020-10-15T18:43:31.000+0000",
        "updated": "2020-10-22T05:16:32.000+0000",
        "timeoriginalestimate": null,
        "description": "So that we the unit of work is a single record batch instead of a part of a partition.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "3.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 12600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Rust] Convert RecordBatchIterator to a Stream",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13335657/comment/17217845",
                    "id": "17217845",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
                        "name": "jorgecarleitao",
                        "key": "jorgecarleitao",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
                        },
                        "displayName": "Jorge Leit\u00e3o",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Issue resolved by pull request 8473\n[https://github.com/apache/arrow/pull/8473]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorgecarleitao",
                        "name": "jorgecarleitao",
                        "key": "jorgecarleitao",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jorgecarleitao&avatarId=43827",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jorgecarleitao&avatarId=43827",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jorgecarleitao&avatarId=43827",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jorgecarleitao&avatarId=43827"
                        },
                        "displayName": "Jorge Leit\u00e3o",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2020-10-20T18:23:44.587+0000",
                    "updated": "2020-10-20T18:23:44.587+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0jqnc:",
        "customfield_12314139": null
    }
}