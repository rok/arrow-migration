{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13389187",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187",
    "key": "ARROW-13313",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12349983",
                "id": "12349983",
                "description": "",
                "name": "5.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-07-28"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12619228",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12619228",
                "type": {
                    "id": "12310460",
                    "name": "Child-Issue",
                    "inward": "is a child of",
                    "outward": "is a parent of",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310460"
                },
                "inwardIssue": {
                    "id": "13376404",
                    "key": "ARROW-12633",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13376404",
                    "fields": {
                        "summary": "[C++] Query engine umbrella issue",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 11400,
            "total": 11400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 11400,
            "total": 11400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13313/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 19,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621608",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz opened a new pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705\n\n\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T19:57:38.909+0000",
                    "updated": "2021-07-12T19:57:38.909+0000",
                    "started": "2021-07-12T19:57:38.908+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621608",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621638",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#issuecomment-878540110\n\n\n   https://issues.apache.org/jira/browse/ARROW-13313\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T20:00:55.055+0000",
                    "updated": "2021-07-12T20:00:55.055+0000",
                    "started": "2021-07-12T20:00:55.055+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621638",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621702",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668204365\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.h\n##########\n@@ -243,12 +244,17 @@ ExecNode* MakeSourceNode(ExecPlan* plan, std::string label,\n \n /// \\brief Add a sink node which forwards to an AsyncGenerator<ExecBatch>\n ///\n-/// Emitted batches will not be ordered; instead they will be tagged with the `seq` at\n-/// which they were received.\n+/// Emitted batches will not be ordered.\n ARROW_EXPORT\n std::function<Future<util::optional<ExecBatch>>()> MakeSinkNode(ExecNode* input,\n                                                                 std::string label);\n \n+/// \\brief Add a sink node which forwards to a RecordBatchReader\n+///\n+/// Emitted batches will not be ordered.\n+ARROW_EXPORT\n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input, std::string label);\n\nReview comment:\n       Looks like this isn't used anywhere in this PR.\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n+      KernelContext ctx{plan()->exec_context()};\n+      ctx.SetState(states_[0][i].get());\n+\n+      for (size_t thread_index = 1; thread_index < thread_indices_.size();\n+           ++thread_index) {\n+        RETURN_NOT_OK(\n+            kernels_[i]->merge(&ctx, std::move(*states_[thread_index][i]), ctx.state()));\n+      }\n+      RETURN_NOT_OK(kernels_[i]->finalize(&ctx, &batch.values[i]));\n+    }\n+    lock->unlock();\n+\n+    outputs_[0]->InputReceived(this, 0, batch);\n+\n+    finished_.MarkFinished();\n+    return Status::OK();\n+  }\n+\n+  Future<> finished_ = Future<>::MakeFinished();\n+  std::vector<const ScalarAggregateKernel*> kernels_;\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states_;\n+  std::unordered_map<std::thread::id, size_t> thread_indices_;\n+  std::mutex mutex_;\n+  int num_received_ = 0, num_total_;\n+};\n+\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates) {\n+  if (input->output_schema()->num_fields() != static_cast<int>(aggregates.size())) {\n+    return Status::Invalid(\"Provided \", aggregates.size(),\n\nReview comment:\n       So to compute multiple aggregates of one field, we'd need to have some helper node to duplicate the column reference?\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.h\n##########\n@@ -243,12 +244,17 @@ ExecNode* MakeSourceNode(ExecPlan* plan, std::string label,\n \n /// \\brief Add a sink node which forwards to an AsyncGenerator<ExecBatch>\n ///\n-/// Emitted batches will not be ordered; instead they will be tagged with the `seq` at\n-/// which they were received.\n+/// Emitted batches will not be ordered.\n ARROW_EXPORT\n std::function<Future<util::optional<ExecBatch>>()> MakeSinkNode(ExecNode* input,\n                                                                 std::string label);\n \n+/// \\brief Add a sink node which forwards to a RecordBatchReader\n+///\n+/// Emitted batches will not be ordered.\n+ARROW_EXPORT\n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input, std::string label);\n\nReview comment:\n       Additionally it seems it'd be more useful to reorder them right? Though maybe that should be a separate node.\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.h\n##########\n@@ -265,9 +271,15 @@ Result<ExecNode*> MakeFilterNode(ExecNode* input, std::string label, Expression\n /// this node to produce a corresponding output column.\n ///\n /// If exprs are not already bound, they will be bound against the input's schema.\n+/// If names are not provided, the string representations of exprs will be used.\n ARROW_EXPORT\n Result<ExecNode*> MakeProjectNode(ExecNode* input, std::string label,\n-                                  std::vector<Expression> exprs);\n+                                  std::vector<Expression> exprs,\n+                                  std::vector<std::string> names = {});\n+\n+ARROW_EXPORT\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates);\n\nReview comment:\n       nit: this is ostensibly a public API, but references an internal struct?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T20:08:34.256+0000",
                    "updated": "2021-07-12T20:08:34.256+0000",
                    "started": "2021-07-12T20:08:34.256+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621702",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621709",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668221912\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n+      KernelContext ctx{plan()->exec_context()};\n+      ctx.SetState(states_[0][i].get());\n+\n+      for (size_t thread_index = 1; thread_index < thread_indices_.size();\n+           ++thread_index) {\n+        RETURN_NOT_OK(\n+            kernels_[i]->merge(&ctx, std::move(*states_[thread_index][i]), ctx.state()));\n+      }\n+      RETURN_NOT_OK(kernels_[i]->finalize(&ctx, &batch.values[i]));\n+    }\n+    lock->unlock();\n+\n+    outputs_[0]->InputReceived(this, 0, batch);\n+\n+    finished_.MarkFinished();\n+    return Status::OK();\n+  }\n+\n+  Future<> finished_ = Future<>::MakeFinished();\n+  std::vector<const ScalarAggregateKernel*> kernels_;\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states_;\n+  std::unordered_map<std::thread::id, size_t> thread_indices_;\n+  std::mutex mutex_;\n+  int num_received_ = 0, num_total_;\n+};\n+\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates) {\n+  if (input->output_schema()->num_fields() != static_cast<int>(aggregates.size())) {\n+    return Status::Invalid(\"Provided \", aggregates.size(),\n\nReview comment:\n       That'd be a ProjectNode whose expressions repeat a field reference, for example:\r\n   \r\n   ```c++\r\n     ASSERT_OK_AND_ASSIGN(auto projection,\r\n                          MakeProjectNode(source, \"project\", {field_ref(\"i32\"), field_ref(\"i32\")}));\r\n   \r\n     ASSERT_OK_AND_ASSIGN(auto scalar_agg,\r\n                          MakeScalarAggregateNode(projection, \"scalar_agg\",\r\n                                                  {{\"sum\", nullptr}, {\"mean\", nullptr}}));\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T20:09:39.453+0000",
                    "updated": "2021-07-12T20:09:39.453+0000",
                    "started": "2021-07-12T20:09:39.453+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621709",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621711",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668226804\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.h\n##########\n@@ -243,12 +244,17 @@ ExecNode* MakeSourceNode(ExecPlan* plan, std::string label,\n \n /// \\brief Add a sink node which forwards to an AsyncGenerator<ExecBatch>\n ///\n-/// Emitted batches will not be ordered; instead they will be tagged with the `seq` at\n-/// which they were received.\n+/// Emitted batches will not be ordered.\n ARROW_EXPORT\n std::function<Future<util::optional<ExecBatch>>()> MakeSinkNode(ExecNode* input,\n                                                                 std::string label);\n \n+/// \\brief Add a sink node which forwards to a RecordBatchReader\n+///\n+/// Emitted batches will not be ordered.\n+ARROW_EXPORT\n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input, std::string label);\n\nReview comment:\n       Dataset scans can preserve ordering based on fragment/batch index, but this is only possible for graphs which don't include a pipeline breaker. I could provide `BatchGen dataset::BatchesInOrder(BatchGen)` to apply fragment/batch ordering if possible.\r\n   \r\n   This is mostly here to provide for non-async consumption of an ExecPlan and to avoid requiring R to write bindings for ExecBatch\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T20:17:56.661+0000",
                    "updated": "2021-07-12T20:17:56.661+0000",
                    "started": "2021-07-12T20:17:56.660+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621711",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621712",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668227228\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.h\n##########\n@@ -265,9 +271,15 @@ Result<ExecNode*> MakeFilterNode(ExecNode* input, std::string label, Expression\n /// this node to produce a corresponding output column.\n ///\n /// If exprs are not already bound, they will be bound against the input's schema.\n+/// If names are not provided, the string representations of exprs will be used.\n ARROW_EXPORT\n Result<ExecNode*> MakeProjectNode(ExecNode* input, std::string label,\n-                                  std::vector<Expression> exprs);\n+                                  std::vector<Expression> exprs,\n+                                  std::vector<std::string> names = {});\n+\n+ARROW_EXPORT\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates);\n\nReview comment:\n       At some point it may be promoted to public or replaced, but that's out of scope for this PR\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T20:18:30.079+0000",
                    "updated": "2021-07-12T20:18:30.079+0000",
                    "started": "2021-07-12T20:18:30.078+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621712",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621714",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668227525\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.h\n##########\n@@ -243,12 +244,17 @@ ExecNode* MakeSourceNode(ExecPlan* plan, std::string label,\n \n /// \\brief Add a sink node which forwards to an AsyncGenerator<ExecBatch>\n ///\n-/// Emitted batches will not be ordered; instead they will be tagged with the `seq` at\n-/// which they were received.\n+/// Emitted batches will not be ordered.\n ARROW_EXPORT\n std::function<Future<util::optional<ExecBatch>>()> MakeSinkNode(ExecNode* input,\n                                                                 std::string label);\n \n+/// \\brief Add a sink node which forwards to a RecordBatchReader\n+///\n+/// Emitted batches will not be ordered.\n+ARROW_EXPORT\n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input, std::string label);\n\nReview comment:\n       Ah, ok, just wasn't sure of the use here. If it's for R, sounds good.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T20:18:57.186+0000",
                    "updated": "2021-07-12T20:18:57.186+0000",
                    "started": "2021-07-12T20:18:57.186+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621714",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621732",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668255841\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n+      KernelContext ctx{plan()->exec_context()};\n+      ctx.SetState(states_[0][i].get());\n+\n+      for (size_t thread_index = 1; thread_index < thread_indices_.size();\n+           ++thread_index) {\n+        RETURN_NOT_OK(\n+            kernels_[i]->merge(&ctx, std::move(*states_[thread_index][i]), ctx.state()));\n+      }\n+      RETURN_NOT_OK(kernels_[i]->finalize(&ctx, &batch.values[i]));\n+    }\n+    lock->unlock();\n+\n+    outputs_[0]->InputReceived(this, 0, batch);\n+\n+    finished_.MarkFinished();\n+    return Status::OK();\n+  }\n+\n+  Future<> finished_ = Future<>::MakeFinished();\n+  std::vector<const ScalarAggregateKernel*> kernels_;\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states_;\n+  std::unordered_map<std::thread::id, size_t> thread_indices_;\n+  std::mutex mutex_;\n+  int num_received_ = 0, num_total_;\n+};\n+\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates) {\n+  if (input->output_schema()->num_fields() != static_cast<int>(aggregates.size())) {\n+    return Status::Invalid(\"Provided \", aggregates.size(),\n+                           \" aggregates, expected one for each field of \",\n+                           input->output_schema()->ToString());\n+  }\n+\n+  auto exec_ctx = input->plan()->exec_context();\n+\n+  std::vector<std::shared_ptr<ScalarAggregateFunction>> functions(aggregates.size());\n+  std::vector<const ScalarAggregateKernel*> kernels(aggregates.size());\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states(\n+      exec_ctx->executor() ? exec_ctx->executor()->GetCapacity() : 1);\n+  FieldVector fields(aggregates.size());\n+\n+  for (size_t i = 0; i < aggregates.size(); ++i) {\n+    ARROW_ASSIGN_OR_RAISE(auto function,\n+                          exec_ctx->func_registry()->GetFunction(aggregates[i].function));\n+    if (function->kind() != Function::SCALAR_AGGREGATE) {\n+      return Status::Invalid(\"Provided non ScalarAggregateFunction \",\n+                             aggregates[i].function);\n+    }\n+\n+    functions[i] = checked_pointer_cast<ScalarAggregateFunction>(std::move(function));\n\nReview comment:\n       Nit: Isn't `function` sufficient?  I don't see it referenced outside the loop scope.  Do you need to gather the vector of functions for some other reason?\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n\nReview comment:\n       This lock could probably be removed.  We might want to make a note to measure this with micro benchmarks someday.  Only one thread should be finishing anyways and the \"what state blocks have we used\" map could probably be a lock free structure.\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n+      KernelContext ctx{plan()->exec_context()};\n+      ctx.SetState(states_[0][i].get());\n+\n+      for (size_t thread_index = 1; thread_index < thread_indices_.size();\n+           ++thread_index) {\n+        RETURN_NOT_OK(\n+            kernels_[i]->merge(&ctx, std::move(*states_[thread_index][i]), ctx.state()));\n+      }\n+      RETURN_NOT_OK(kernels_[i]->finalize(&ctx, &batch.values[i]));\n+    }\n+    lock->unlock();\n+\n+    outputs_[0]->InputReceived(this, 0, batch);\n+\n+    finished_.MarkFinished();\n+    return Status::OK();\n+  }\n+\n+  Future<> finished_ = Future<>::MakeFinished();\n+  std::vector<const ScalarAggregateKernel*> kernels_;\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states_;\n+  std::unordered_map<std::thread::id, size_t> thread_indices_;\n+  std::mutex mutex_;\n+  int num_received_ = 0, num_total_;\n+};\n+\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates) {\n+  if (input->output_schema()->num_fields() != static_cast<int>(aggregates.size())) {\n+    return Status::Invalid(\"Provided \", aggregates.size(),\n+                           \" aggregates, expected one for each field of \",\n+                           input->output_schema()->ToString());\n+  }\n+\n+  auto exec_ctx = input->plan()->exec_context();\n+\n+  std::vector<std::shared_ptr<ScalarAggregateFunction>> functions(aggregates.size());\n+  std::vector<const ScalarAggregateKernel*> kernels(aggregates.size());\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states(\n+      exec_ctx->executor() ? exec_ctx->executor()->GetCapacity() : 1);\n+  FieldVector fields(aggregates.size());\n+\n+  for (size_t i = 0; i < aggregates.size(); ++i) {\n+    ARROW_ASSIGN_OR_RAISE(auto function,\n+                          exec_ctx->func_registry()->GetFunction(aggregates[i].function));\n+    if (function->kind() != Function::SCALAR_AGGREGATE) {\n+      return Status::Invalid(\"Provided non ScalarAggregateFunction \",\n+                             aggregates[i].function);\n+    }\n+\n+    functions[i] = checked_pointer_cast<ScalarAggregateFunction>(std::move(function));\n+\n+    auto in_type = ValueDescr::Array(input->output_schema()->fields()[i]->type());\n+\n+    ARROW_ASSIGN_OR_RAISE(const Kernel* kernel, functions[i]->DispatchExact({in_type}));\n+    kernels[i] = static_cast<const ScalarAggregateKernel*>(kernel);\n+\n+    if (aggregates[i].options == nullptr) {\n+      aggregates[i].options = functions[i]->default_options();\n+    }\n+\n+    KernelContext kernel_ctx{exec_ctx};\n+    for (auto& thread_local_states : states) {\n+      thread_local_states.resize(kernels.size());\n+      ARROW_ASSIGN_OR_RAISE(\n+          thread_local_states[i],\n+          kernels[i]->init(&kernel_ctx, KernelInitArgs{kernels[i],\n\nReview comment:\n       Nit: Minor thing but could this maybe be a helper function on the kernel `init_all` which takes in a vector of states and runs init on each one?\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n\nReview comment:\n       Maybe someday in the future we could merge each kernel on its own thread but that can be for a future PR.\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n\nReview comment:\n       Very minor thought, but having utility Iterator<RB> + schema => RBR and Generator<RB> + schema => RBR could be useful and then it would be more clear that the main goal here is ExecBatch -> RecordBatch.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-12T21:47:48.688+0000",
                    "updated": "2021-07-12T21:47:48.688+0000",
                    "started": "2021-07-12T21:47:48.688+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621732",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621969",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668709238\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n+      KernelContext ctx{plan()->exec_context()};\n+      ctx.SetState(states_[0][i].get());\n+\n+      for (size_t thread_index = 1; thread_index < thread_indices_.size();\n+           ++thread_index) {\n+        RETURN_NOT_OK(\n+            kernels_[i]->merge(&ctx, std::move(*states_[thread_index][i]), ctx.state()));\n+      }\n+      RETURN_NOT_OK(kernels_[i]->finalize(&ctx, &batch.values[i]));\n+    }\n+    lock->unlock();\n+\n+    outputs_[0]->InputReceived(this, 0, batch);\n+\n+    finished_.MarkFinished();\n+    return Status::OK();\n+  }\n+\n+  Future<> finished_ = Future<>::MakeFinished();\n+  std::vector<const ScalarAggregateKernel*> kernels_;\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states_;\n+  std::unordered_map<std::thread::id, size_t> thread_indices_;\n+  std::mutex mutex_;\n+  int num_received_ = 0, num_total_;\n+};\n+\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates) {\n+  if (input->output_schema()->num_fields() != static_cast<int>(aggregates.size())) {\n+    return Status::Invalid(\"Provided \", aggregates.size(),\n+                           \" aggregates, expected one for each field of \",\n+                           input->output_schema()->ToString());\n+  }\n+\n+  auto exec_ctx = input->plan()->exec_context();\n+\n+  std::vector<std::shared_ptr<ScalarAggregateFunction>> functions(aggregates.size());\n+  std::vector<const ScalarAggregateKernel*> kernels(aggregates.size());\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states(\n+      exec_ctx->executor() ? exec_ctx->executor()->GetCapacity() : 1);\n+  FieldVector fields(aggregates.size());\n+\n+  for (size_t i = 0; i < aggregates.size(); ++i) {\n+    ARROW_ASSIGN_OR_RAISE(auto function,\n+                          exec_ctx->func_registry()->GetFunction(aggregates[i].function));\n+    if (function->kind() != Function::SCALAR_AGGREGATE) {\n+      return Status::Invalid(\"Provided non ScalarAggregateFunction \",\n+                             aggregates[i].function);\n+    }\n+\n+    functions[i] = checked_pointer_cast<ScalarAggregateFunction>(std::move(function));\n\nReview comment:\n       I suppose not. I'll remove the vector\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T12:21:08.760+0000",
                    "updated": "2021-07-13T12:21:08.760+0000",
                    "started": "2021-07-13T12:21:08.759+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621969",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621972",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668709472\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n+      KernelContext ctx{plan()->exec_context()};\n+      ctx.SetState(states_[0][i].get());\n+\n+      for (size_t thread_index = 1; thread_index < thread_indices_.size();\n+           ++thread_index) {\n+        RETURN_NOT_OK(\n+            kernels_[i]->merge(&ctx, std::move(*states_[thread_index][i]), ctx.state()));\n+      }\n+      RETURN_NOT_OK(kernels_[i]->finalize(&ctx, &batch.values[i]));\n+    }\n+    lock->unlock();\n+\n+    outputs_[0]->InputReceived(this, 0, batch);\n+\n+    finished_.MarkFinished();\n+    return Status::OK();\n+  }\n+\n+  Future<> finished_ = Future<>::MakeFinished();\n+  std::vector<const ScalarAggregateKernel*> kernels_;\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states_;\n+  std::unordered_map<std::thread::id, size_t> thread_indices_;\n+  std::mutex mutex_;\n+  int num_received_ = 0, num_total_;\n+};\n+\n+Result<ExecNode*> MakeScalarAggregateNode(ExecNode* input, std::string label,\n+                                          std::vector<internal::Aggregate> aggregates) {\n+  if (input->output_schema()->num_fields() != static_cast<int>(aggregates.size())) {\n+    return Status::Invalid(\"Provided \", aggregates.size(),\n+                           \" aggregates, expected one for each field of \",\n+                           input->output_schema()->ToString());\n+  }\n+\n+  auto exec_ctx = input->plan()->exec_context();\n+\n+  std::vector<std::shared_ptr<ScalarAggregateFunction>> functions(aggregates.size());\n+  std::vector<const ScalarAggregateKernel*> kernels(aggregates.size());\n+  std::vector<std::vector<std::unique_ptr<KernelState>>> states(\n+      exec_ctx->executor() ? exec_ctx->executor()->GetCapacity() : 1);\n+  FieldVector fields(aggregates.size());\n+\n+  for (size_t i = 0; i < aggregates.size(); ++i) {\n+    ARROW_ASSIGN_OR_RAISE(auto function,\n+                          exec_ctx->func_registry()->GetFunction(aggregates[i].function));\n+    if (function->kind() != Function::SCALAR_AGGREGATE) {\n+      return Status::Invalid(\"Provided non ScalarAggregateFunction \",\n+                             aggregates[i].function);\n+    }\n+\n+    functions[i] = checked_pointer_cast<ScalarAggregateFunction>(std::move(function));\n+\n+    auto in_type = ValueDescr::Array(input->output_schema()->fields()[i]->type());\n+\n+    ARROW_ASSIGN_OR_RAISE(const Kernel* kernel, functions[i]->DispatchExact({in_type}));\n+    kernels[i] = static_cast<const ScalarAggregateKernel*>(kernel);\n+\n+    if (aggregates[i].options == nullptr) {\n+      aggregates[i].options = functions[i]->default_options();\n+    }\n+\n+    KernelContext kernel_ctx{exec_ctx};\n+    for (auto& thread_local_states : states) {\n+      thread_local_states.resize(kernels.size());\n+      ARROW_ASSIGN_OR_RAISE(\n+          thread_local_states[i],\n+          kernels[i]->init(&kernel_ctx, KernelInitArgs{kernels[i],\n\nReview comment:\n       SGTM\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T12:21:29.459+0000",
                    "updated": "2021-07-13T12:21:29.459+0000",
                    "started": "2021-07-13T12:21:29.459+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621972",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621974",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668710690\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n\nReview comment:\n       I'll extract those helpers\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T12:23:07.532+0000",
                    "updated": "2021-07-13T12:23:07.532+0000",
                    "started": "2021-07-13T12:23:07.532+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621974",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621976",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668714108\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n\nReview comment:\n       Merging scalar aggregates is pretty trivial so I'd guess we don't gain much with parallelization. Worth investigating in a follow up, though\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T12:27:58.858+0000",
                    "updated": "2021-07-13T12:27:58.858+0000",
                    "started": "2021-07-13T12:27:58.858+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621976",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/621978",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668718212\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n\nReview comment:\n       InputReceived(last batch) might be called concurrently with InputFinished, so those two must synchronize to ensure only one does the finishing. It'd certainly be helpful to introduce less clumsy control flow in these classes\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T12:33:33.719+0000",
                    "updated": "2021-07-13T12:33:33.719+0000",
                    "started": "2021-07-13T12:33:33.718+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "621978",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/622032",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668828170\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n\nReview comment:\n       Question: to implement something like ARROW-12710 (string concat aggregate kernel) we'll need to know the order of inputs in the kernels (or will have to feed results into the kernel in order) - how do we plan to handle that? Passing down seq and having each kernel reorder inputs itself, or perhaps with an upstream ExecNode that orders its inputs? This also applies to the group by node.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T14:37:48.836+0000",
                    "updated": "2021-07-13T14:37:48.836+0000",
                    "started": "2021-07-13T14:37:48.836+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "622032",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/622054",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668873010\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n\nReview comment:\n       `seq` is not an indication of order, it's only a tag in the range `[0, seq_stop)` (where `seq_stop` is set by `InputFinished`) so we could not use it to order results.\r\n   \r\n   As specified in ARROW-12710, the `KernelState` of the string concat agg kernel will need to include ordering criteria so that `merge(move(state1), &state0)` can be guaranteed equivalent to `merge(move(state0), &state1)`. Furthermore, `merge` cannot actually concatenate anything because if we happened to first `merge(move(state0), &state3)` we'd have no way to insert `state1, state2` in the middle later. Actual concatenation would have to wait for `finalize`. \r\n   \r\n   Those ordering criteria could be synthesized from (for example) fragment/batch index information, but the presence of `O(N)` state in a scalar agg kernel's State is suspect to me and I'm not sure it's a great match for ScalarAggregateKernel.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T15:25:03.193+0000",
                    "updated": "2021-07-13T15:25:03.193+0000",
                    "started": "2021-07-13T15:25:03.193+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "622054",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/622059",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r668882748\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n\nReview comment:\n       Ah thanks, sorry for the misunderstanding (I need to stop thinking only about datasets).\r\n   \r\n   I suppose it only makes sense to talk about 'order' when directly downstream from a scan or explicit sort, then. And any aggregates that have O(N) state might properly belong as their own ExecNode.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T15:36:17.797+0000",
                    "updated": "2021-07-13T15:36:17.797+0000",
                    "started": "2021-07-13T15:36:17.797+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "622059",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/622233",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r669103875\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -1323,5 +1323,86 @@ TEST(ScanNode, MaterializationOfVirtualColumn) {\n               Finishes(ResultWith(UnorderedElementsAreArray(expected))));\n }\n \n+TEST(ScanNode, MinimalEndToEnd) {\n+  // NB: This test is here for didactic purposes\n+\n+  // Specify a MemoryPool and ThreadPool for the ExecPlan\n+  compute::ExecContext exec_context(default_memory_pool(), internal::GetCpuThreadPool());\n+\n+  // A ScanNode is constructed from an ExecPlan (into which it is inserted),\n+  // a Dataset (whose batches will be scanned), and ScanOptions (to specify a filter for\n+  // predicate pushdown, a projection to skip materialization of unnecessary columns, ...)\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<compute::ExecPlan> plan,\n+                       compute::ExecPlan::Make(&exec_context));\n+\n+  std::shared_ptr<Dataset> dataset = std::make_shared<InMemoryDataset>(\n+      TableFromJSON(schema({field(\"a\", int32()), field(\"b\", boolean())}),\n+                    {\n+                        R\"([{\"a\": 1,    \"b\": null},\n+                            {\"a\": 2,    \"b\": true}])\",\n+                        R\"([{\"a\": null, \"b\": true},\n+                            {\"a\": 3,    \"b\": false}])\",\n+                        R\"([{\"a\": null, \"b\": true},\n+                            {\"a\": 4,    \"b\": false}])\",\n+                        R\"([{\"a\": 5,    \"b\": null},\n+                            {\"a\": 6,    \"b\": false},\n+                            {\"a\": 7,    \"b\": false}])\",\n+                    }));\n+\n+  auto options = std::make_shared<ScanOptions>();\n+  // sync scanning is not supported by ScanNode\n+  options->use_async = true;\n+  // for now, we must replicate the dataset schema here\n+  options->dataset_schema = dataset->schema();\n+  // specify the filter\n+  compute::Expression b_is_true = field_ref(\"b\");\n+  ASSERT_OK_AND_ASSIGN(b_is_true, b_is_true.Bind(*dataset->schema()));\n+  options->filter = b_is_true;\n+  // for now, specify the projection as the full project expression (eventually this can\n+  // just be a list of materialized field names)\n+  compute::Expression a_times_2 = call(\"multiply\", {field_ref(\"a\"), literal(2)});\n+  ASSERT_OK_AND_ASSIGN(a_times_2, a_times_2.Bind(*dataset->schema()));\n+  options->projection = call(\"project\", {a_times_2}, compute::ProjectOptions{{\"a * 2\"}});\n+\n+  // construct the scan node\n+  ASSERT_OK_AND_ASSIGN(compute::ExecNode * scan,\n+                       dataset::MakeScanNode(plan.get(), dataset, options));\n+\n+  // pipe the scan node into a filter node\n+  ASSERT_OK_AND_ASSIGN(compute::ExecNode * filter,\n+                       compute::MakeFilterNode(scan, \"filter\", b_is_true));\n+\n+  // pipe the filter node into a project node\n+  // NB: we're using the project node factory which preserves fragment/batch index\n+  // tagging, so we *can* reorder later if we choose. The tags will not appear in\n+  // our output.\n+  ASSERT_OK_AND_ASSIGN(compute::ExecNode * project,\n+                       dataset::MakeAugmentedProjectNode(filter, \"project\", {a_times_2}));\n+\n+  // finally, pipe the project node into a sink node\n+  // NB: if we don't need ordering, we could use compute::MakeSinkNode instead\n+  ASSERT_OK_AND_ASSIGN(auto sink_gen, dataset::MakeOrderedSinkNode(project, \"sink\"));\n\nReview comment:\n       Thanks for the example! I do like this setup a lot more since it is clearer what all the steps are in reading a dataset + everything is neatly separated. It is not that the current scanner does not separate up the various stages of its pipeline, but the pipeline in the scanner is rather tied together while this is clearly partitioned. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T20:55:28.506+0000",
                    "updated": "2021-07-13T20:55:28.506+0000",
                    "started": "2021-07-13T20:55:28.505+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "622233",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/622234",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz closed pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705\n\n\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T20:58:46.942+0000",
                    "updated": "2021-07-13T20:58:46.942+0000",
                    "started": "2021-07-13T20:58:46.942+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "622234",
                    "issueId": "13389187"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/worklog/622245",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10705:\nURL: https://github.com/apache/arrow/pull/10705#discussion_r669115135\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/exec_plan.cc\n##########\n@@ -601,5 +618,215 @@ AsyncGenerator<util::optional<ExecBatch>> MakeSinkNode(ExecNode* input,\n   return out;\n }\n \n+std::shared_ptr<RecordBatchReader> MakeSinkNodeReader(ExecNode* input,\n+                                                      std::string label) {\n+  struct Impl : RecordBatchReader {\n+    std::shared_ptr<Schema> schema() const override { return schema_; }\n+    Status ReadNext(std::shared_ptr<RecordBatch>* record_batch) override {\n+      ARROW_ASSIGN_OR_RAISE(auto batch, iterator_.Next());\n+      if (batch) {\n+        ARROW_ASSIGN_OR_RAISE(*record_batch, batch->ToRecordBatch(schema_, pool_));\n+      } else {\n+        *record_batch = IterationEnd<std::shared_ptr<RecordBatch>>();\n+      }\n+      return Status::OK();\n+    }\n+\n+    MemoryPool* pool_;\n+    std::shared_ptr<Schema> schema_;\n+    Iterator<util::optional<ExecBatch>> iterator_;\n+  };\n+\n+  auto out = std::make_shared<Impl>();\n+  out->pool_ = input->plan()->exec_context()->memory_pool();\n+  out->schema_ = input->output_schema();\n+  out->iterator_ = MakeGeneratorIterator(MakeSinkNode(input, std::move(label)));\n+  return out;\n+}\n+\n+struct ScalarAggregateNode : ExecNode {\n+  ScalarAggregateNode(ExecNode* input, std::string label,\n+                      std::shared_ptr<Schema> output_schema,\n+                      std::vector<const ScalarAggregateKernel*> kernels,\n+                      std::vector<std::vector<std::unique_ptr<KernelState>>> states)\n+      : ExecNode(input->plan(), std::move(label), {input}, {\"target\"},\n+                 /*output_schema=*/std::move(output_schema),\n+                 /*num_outputs=*/1),\n+        kernels_(std::move(kernels)),\n+        states_(std::move(states)) {}\n+\n+  const char* kind_name() override { return \"ScalarAggregateNode\"; }\n+\n+  Status DoConsume(const ExecBatch& batch,\n+                   const std::vector<std::unique_ptr<KernelState>>& states) {\n+    for (size_t i = 0; i < states.size(); ++i) {\n+      KernelContext batch_ctx{plan()->exec_context()};\n+      batch_ctx.SetState(states[i].get());\n+      ExecBatch single_column_batch{{batch.values[i]}, batch.length};\n+      RETURN_NOT_OK(kernels_[i]->consume(&batch_ctx, single_column_batch));\n+    }\n+    return Status::OK();\n+  }\n+\n+  void InputReceived(ExecNode* input, int seq, ExecBatch batch) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    auto it =\n+        thread_indices_.emplace(std::this_thread::get_id(), thread_indices_.size()).first;\n+    ++num_received_;\n+    auto thread_index = it->second;\n+\n+    lock.unlock();\n+\n+    const auto& thread_local_state = states_[thread_index];\n+    Status st = DoConsume(std::move(batch), thread_local_state);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+      return;\n+    }\n+\n+    lock.lock();\n+    st = MaybeFinish(&lock);\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int seq) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    std::unique_lock<std::mutex> lock(mutex_);\n+    num_total_ = seq;\n+    Status st = MaybeFinish(&lock);\n+\n+    if (!st.ok()) {\n+      outputs_[0]->ErrorReceived(this, std::move(st));\n+    }\n+  }\n+\n+  Status StartProducing() override {\n+    finished_ = Future<>::Make();\n+    // Scalar aggregates will only output a single batch\n+    outputs_[0]->InputFinished(this, 1);\n+    return Status::OK();\n+  }\n+\n+  void PauseProducing(ExecNode* output) override {}\n+\n+  void ResumeProducing(ExecNode* output) override {}\n+\n+  void StopProducing(ExecNode* output) override {\n+    DCHECK_EQ(output, outputs_[0]);\n+    StopProducing();\n+  }\n+\n+  void StopProducing() override {\n+    inputs_[0]->StopProducing(this);\n+    finished_.MarkFinished();\n+  }\n+\n+  Future<> finished() override { return finished_; }\n+\n+ private:\n+  Status MaybeFinish(std::unique_lock<std::mutex>* lock) {\n+    if (num_received_ != num_total_) return Status::OK();\n+\n+    if (finished_.is_finished()) return Status::OK();\n+\n+    ExecBatch batch{{}, 1};\n+    batch.values.resize(kernels_.size());\n+\n+    for (size_t i = 0; i < kernels_.size(); ++i) {\n\nReview comment:\n       Ah, In my head \"merge\" meant something more like a merge sort.  I agree, if it's just summing up a sum/mean/etc. counter across the various states then I agree it's not necessary.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-13T21:14:07.541+0000",
                    "updated": "2021-07-13T21:14:07.541+0000",
                    "started": "2021-07-13T21:14:07.540+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "622245",
                    "issueId": "13389187"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 11400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@7f997d5c[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@9775e33[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1063d84[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@32337d51[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4f7f52d8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@742a88e7[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@44f071fb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@6d0055c1[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@58dc232b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@7891f567[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3f292c27[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@50e8c85e[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 11400,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Jul 13 20:58:38 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-07-13T20:58:38.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13313/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2021-07-12T16:27:04.000+0000",
        "updated": "2021-07-13T21:14:08.000+0000",
        "timeoriginalestimate": null,
        "description": "Provide an ExecNode which wraps ScalarAggregateFunctions",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "3h 10m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 11400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Compute] Add ScalarAggregateNode",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13389187/comment/17380167",
                    "id": "17380167",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 10705\n[https://github.com/apache/arrow/pull/10705]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-07-13T20:58:38.636+0000",
                    "updated": "2021-07-13T20:58:38.636+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0svb4:",
        "customfield_12314139": null
    }
}