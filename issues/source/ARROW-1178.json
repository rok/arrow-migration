{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13084092",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13084092",
    "key": "ARROW-1178",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341352",
                "id": "12341352",
                "name": "0.8.0",
                "archived": false,
                "released": true,
                "releaseDate": "2017-12-18"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12508150",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12508150",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13083509",
                    "key": "ARROW-1167",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13083509",
                    "fields": {
                        "summary": "[Python] Create chunked BinaryArray in Table.from_pandas when a column's data exceeds 2GB",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1178/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2968762b[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1b8e5e26[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4758c65a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@2ececff9[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@380bf741[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@4cb39816[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4dd8edcc[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@15315289[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@72e71e91[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@22444bf3[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@287864fa[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@3742de66[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Nov 27 09:27:08 UTC 2017",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2017-11-27T09:27:08.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1178/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2017-07-02T22:23:45.000+0000",
        "updated": "2017-11-27T09:27:08.000+0000",
        "timeoriginalestimate": null,
        "description": "Will provide a fix for ARROW-1167",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Create alternative to Table.from_pandas that yields a list of RecordBatch objects with a given chunk size",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13084092/comment/16089166",
                    "id": "16089166",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "This is a fair bit of work to do in generality. I think we can sort out a simpler fix for ARROW-1167. Will move that one to 0.5.0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-07-16T22:45:11.576+0000",
                    "updated": "2017-07-16T22:45:11.576+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13084092/comment/16266190",
                    "id": "16266190",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I will add a {{Table.to_batches}} instance method",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-11-26T21:19:53.112+0000",
                    "updated": "2017-11-26T21:19:53.112+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13084092/comment/16266359",
                    "id": "16266359",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm opened a new pull request #1364: ARROW-1178: [C++/Python] Add option to set chunksize in TableBatchReader, Table.to_batches method\nURL: https://github.com/apache/arrow/pull/1364\n \n \n   This also fixes ARROW-504 by adding a chunksize option when writing tables to a RecordBatch stream in Python\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T04:39:18.719+0000",
                    "updated": "2017-11-27T04:39:18.719+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13084092/comment/16266554",
                    "id": "16266554",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy closed pull request #1364: ARROW-1178: [C++/Python] Add option to set chunksize in TableBatchReader, Table.to_batches method\nURL: https://github.com/apache/arrow/pull/1364\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/cpp/src/arrow/ipc/writer.cc b/cpp/src/arrow/ipc/writer.cc\nindex 3c1db0615..fb766a9a7 100644\n--- a/cpp/src/arrow/ipc/writer.cc\n+++ b/cpp/src/arrow/ipc/writer.cc\n@@ -651,9 +651,13 @@ Status GetTensorSize(const Tensor& tensor, int64_t* size) {\n \n RecordBatchWriter::~RecordBatchWriter() {}\n \n-Status RecordBatchWriter::WriteTable(const Table& table) {\n+Status RecordBatchWriter::WriteTable(const Table& table, int64_t max_chunksize) {\n   TableBatchReader reader(table);\n \n+  if (max_chunksize > 0) {\n+    reader.set_chunksize(max_chunksize);\n+  }\n+\n   std::shared_ptr<RecordBatch> batch;\n   while (true) {\n     RETURN_NOT_OK(reader.ReadNext(&batch));\n@@ -666,6 +670,8 @@ Status RecordBatchWriter::WriteTable(const Table& table) {\n   return Status::OK();\n }\n \n+Status RecordBatchWriter::WriteTable(const Table& table) { return WriteTable(table, -1); }\n+\n // ----------------------------------------------------------------------\n // Stream writer implementation\n \ndiff --git a/cpp/src/arrow/ipc/writer.h b/cpp/src/arrow/ipc/writer.h\nindex cedac45e7..457dcb4ec 100644\n--- a/cpp/src/arrow/ipc/writer.h\n+++ b/cpp/src/arrow/ipc/writer.h\n@@ -65,6 +65,12 @@ class ARROW_EXPORT RecordBatchWriter {\n   /// \\return Status\n   Status WriteTable(const Table& table);\n \n+  /// \\brief Write Table with a particular chunksize\n+  /// \\param[in] table table to write\n+  /// \\param[in] max_chunksize maximum chunk size for table chunks\n+  /// \\return Status\n+  Status WriteTable(const Table& table, int64_t max_chunksize);\n+\n   /// \\brief Perform any logic necessary to finish the stream\n   ///\n   /// \\return Status\ndiff --git a/cpp/src/arrow/table-test.cc b/cpp/src/arrow/table-test.cc\nindex e77d3aa8b..8a2288710 100644\n--- a/cpp/src/arrow/table-test.cc\n+++ b/cpp/src/arrow/table-test.cc\n@@ -586,4 +586,37 @@ TEST_F(TestTableBatchReader, ReadNext) {\n   ASSERT_EQ(nullptr, batch);\n }\n \n+TEST_F(TestTableBatchReader, Chunksize) {\n+  auto a1 = MakeRandomArray<Int32Array>(10);\n+  auto a2 = MakeRandomArray<Int32Array>(20);\n+  auto a3 = MakeRandomArray<Int32Array>(10);\n+\n+  auto sch1 = arrow::schema({field(\"f1\", int32())});\n+  auto t1 = Table::Make(sch1, {column(sch1->field(0), {a1, a2, a3})});\n+\n+  TableBatchReader i1(*t1);\n+\n+  i1.set_chunksize(15);\n+\n+  std::shared_ptr<RecordBatch> batch;\n+  ASSERT_OK(i1.ReadNext(&batch));\n+  ASSERT_OK(batch->Validate());\n+  ASSERT_EQ(10, batch->num_rows());\n+\n+  ASSERT_OK(i1.ReadNext(&batch));\n+  ASSERT_OK(batch->Validate());\n+  ASSERT_EQ(15, batch->num_rows());\n+\n+  ASSERT_OK(i1.ReadNext(&batch));\n+  ASSERT_OK(batch->Validate());\n+  ASSERT_EQ(5, batch->num_rows());\n+\n+  ASSERT_OK(i1.ReadNext(&batch));\n+  ASSERT_OK(batch->Validate());\n+  ASSERT_EQ(10, batch->num_rows());\n+\n+  ASSERT_OK(i1.ReadNext(&batch));\n+  ASSERT_EQ(nullptr, batch);\n+}\n+\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/table.cc b/cpp/src/arrow/table.cc\nindex 8f3f19576..129524b7e 100644\n--- a/cpp/src/arrow/table.cc\n+++ b/cpp/src/arrow/table.cc\n@@ -19,6 +19,7 @@\n \n #include <algorithm>\n #include <cstdlib>\n+#include <limits>\n #include <memory>\n #include <sstream>\n \n@@ -403,7 +404,8 @@ class TableBatchReader::TableBatchReaderImpl {\n         column_data_(table.num_columns()),\n         chunk_numbers_(table.num_columns(), 0),\n         chunk_offsets_(table.num_columns(), 0),\n-        absolute_row_position_(0) {\n+        absolute_row_position_(0),\n+        max_chunksize_(std::numeric_limits<int64_t>::max()) {\n     for (int i = 0; i < table.num_columns(); ++i) {\n       column_data_[i] = table.column(i)->data().get();\n     }\n@@ -416,7 +418,7 @@ class TableBatchReader::TableBatchReaderImpl {\n     }\n \n     // Determine the minimum contiguous slice across all columns\n-    int64_t chunksize = table_.num_rows();\n+    int64_t chunksize = std::min(table_.num_rows(), max_chunksize_);\n     std::vector<const Array*> chunks(table_.num_columns());\n     for (int i = 0; i < table_.num_columns(); ++i) {\n       auto chunk = column_data_[i]->chunk(chunk_numbers_[i]).get();\n@@ -430,8 +432,7 @@ class TableBatchReader::TableBatchReaderImpl {\n     }\n \n     // Slice chunks and advance chunk index as appropriate\n-    std::vector<std::shared_ptr<ArrayData>> batch_data;\n-    batch_data.reserve(table_.num_columns());\n+    std::vector<std::shared_ptr<ArrayData>> batch_data(table_.num_columns());\n \n     for (int i = 0; i < table_.num_columns(); ++i) {\n       // Exhausted chunk\n@@ -441,7 +442,7 @@ class TableBatchReader::TableBatchReaderImpl {\n       if ((chunk->length() - offset) == chunksize) {\n         ++chunk_numbers_[i];\n         chunk_offsets_[i] = 0;\n-        if (chunk_offsets_[i] > 0) {\n+        if (offset > 0) {\n           // Need to slice\n           slice_data = chunk->Slice(offset, chunksize)->data();\n         } else {\n@@ -449,9 +450,10 @@ class TableBatchReader::TableBatchReaderImpl {\n           slice_data = chunk->data();\n         }\n       } else {\n+        chunk_offsets_[i] += chunksize;\n         slice_data = chunk->Slice(offset, chunksize)->data();\n       }\n-      batch_data.emplace_back(std::move(slice_data));\n+      batch_data[i] = std::move(slice_data);\n     }\n \n     absolute_row_position_ += chunksize;\n@@ -462,12 +464,15 @@ class TableBatchReader::TableBatchReaderImpl {\n \n   std::shared_ptr<Schema> schema() const { return table_.schema(); }\n \n+  void set_chunksize(int64_t chunksize) { max_chunksize_ = chunksize; }\n+\n  private:\n   const Table& table_;\n   std::vector<ChunkedArray*> column_data_;\n   std::vector<int> chunk_numbers_;\n   std::vector<int64_t> chunk_offsets_;\n   int64_t absolute_row_position_;\n+  int64_t max_chunksize_;\n };\n \n TableBatchReader::TableBatchReader(const Table& table) {\n@@ -478,6 +483,10 @@ TableBatchReader::~TableBatchReader() {}\n \n std::shared_ptr<Schema> TableBatchReader::schema() const { return impl_->schema(); }\n \n+void TableBatchReader::set_chunksize(int64_t chunksize) {\n+  impl_->set_chunksize(chunksize);\n+}\n+\n Status TableBatchReader::ReadNext(std::shared_ptr<RecordBatch>* out) {\n   return impl_->ReadNext(out);\n }\ndiff --git a/cpp/src/arrow/table.h b/cpp/src/arrow/table.h\nindex d0312d93c..c813b32ad 100644\n--- a/cpp/src/arrow/table.h\n+++ b/cpp/src/arrow/table.h\n@@ -197,6 +197,8 @@ class ARROW_EXPORT TableBatchReader : public RecordBatchReader {\n \n   Status ReadNext(std::shared_ptr<RecordBatch>* out) override;\n \n+  void set_chunksize(int64_t chunksize);\n+\n  private:\n   class TableBatchReaderImpl;\n   std::unique_ptr<TableBatchReaderImpl> impl_;\ndiff --git a/python/pyarrow/includes/libarrow.pxd b/python/pyarrow/includes/libarrow.pxd\nindex 5d68607ef..14211787c 100644\n--- a/python/pyarrow/includes/libarrow.pxd\n+++ b/python/pyarrow/includes/libarrow.pxd\n@@ -456,6 +456,13 @@ cdef extern from \"arrow/api.h\" namespace \"arrow\" nogil:\n         shared_ptr[CTable] ReplaceSchemaMetadata(\n             const shared_ptr[CKeyValueMetadata]& metadata)\n \n+    cdef cppclass RecordBatchReader:\n+        CStatus ReadNext(shared_ptr[CRecordBatch]* out)\n+\n+    cdef cppclass TableBatchReader(RecordBatchReader):\n+        TableBatchReader(const CTable& table)\n+        void set_chunksize(int64_t chunksize)\n+\n     cdef cppclass CTensor\" arrow::Tensor\":\n         shared_ptr[CDataType] type()\n         shared_ptr[CBuffer] data()\n@@ -692,7 +699,7 @@ cdef extern from \"arrow/ipc/api.h\" namespace \"arrow::ipc\" nogil:\n         CStatus Close()\n         CStatus WriteRecordBatch(const CRecordBatch& batch,\n                                  c_bool allow_64bit)\n-        CStatus WriteTable(const CTable& table)\n+        CStatus WriteTable(const CTable& table, int64_t max_chunksize)\n \n     cdef cppclass CRecordBatchReader\" arrow::ipc::RecordBatchReader\":\n         shared_ptr[CSchema] schema()\ndiff --git a/python/pyarrow/ipc.pxi b/python/pyarrow/ipc.pxi\nindex 27e916775..e5639137d 100644\n--- a/python/pyarrow/ipc.pxi\n+++ b/python/pyarrow/ipc.pxi\n@@ -202,7 +202,7 @@ cdef class _RecordBatchWriter:\n             check_status(self.writer.get()\n                          .WriteRecordBatch(deref(batch.batch), 1))\n \n-    def write_table(self, Table table):\n+    def write_table(self, Table table, chunksize=None):\n         \"\"\"\n         Write RecordBatch to stream\n \n@@ -210,8 +210,16 @@ cdef class _RecordBatchWriter:\n         ----------\n         batch : RecordBatch\n         \"\"\"\n+        cdef:\n+            # Chunksize must be > 0 to have any impact\n+            int64_t c_chunksize = -1\n+\n+        if chunksize is not None:\n+            c_chunksize = chunksize\n+\n         with nogil:\n-            check_status(self.writer.get().WriteTable(table.table[0]))\n+            check_status(self.writer.get().WriteTable(table.table[0],\n+                                                      c_chunksize))\n \n     def close(self):\n         \"\"\"\ndiff --git a/python/pyarrow/table.pxi b/python/pyarrow/table.pxi\nindex 8c5b8bbc3..b03ee2670 100644\n--- a/python/pyarrow/table.pxi\n+++ b/python/pyarrow/table.pxi\n@@ -971,6 +971,44 @@ cdef class Table:\n \n         return pyarrow_wrap_table(c_table)\n \n+    def to_batches(self, chunksize=None):\n+        \"\"\"\n+        Convert Table to list of (contiguous) RecordBatch objects, with optimal\n+        maximum chunk size\n+\n+        Parameters\n+        ----------\n+        chunksize : int, default None\n+            Maximum size for RecordBatch chunks. Individual chunks may be\n+            smaller depending on the chunk layout of individual columns\n+\n+        Returns\n+        -------\n+        batches : list of RecordBatch\n+        \"\"\"\n+        cdef:\n+            unique_ptr[TableBatchReader] reader\n+            int64_t c_chunksize\n+            list result = []\n+            shared_ptr[CRecordBatch] batch\n+\n+        reader.reset(new TableBatchReader(deref(self.table)))\n+\n+        if chunksize is not None:\n+            c_chunksize = chunksize\n+            reader.get().set_chunksize(c_chunksize)\n+\n+        while True:\n+            with nogil:\n+                check_status(reader.get().ReadNext(&batch))\n+\n+            if batch.get() == NULL:\n+                break\n+\n+            result.append(pyarrow_wrap_batch(batch))\n+\n+        return result\n+\n     def to_pandas(self, nthreads=None, strings_to_categorical=False,\n                   memory_pool=None, zero_copy_only=False):\n         \"\"\"\ndiff --git a/python/pyarrow/tests/test_ipc.py b/python/pyarrow/tests/test_ipc.py\nindex 5033ea957..9cd5f8076 100644\n--- a/python/pyarrow/tests/test_ipc.py\n+++ b/python/pyarrow/tests/test_ipc.py\n@@ -168,6 +168,29 @@ def test_stream_write_dispatch(self):\n         assert_frame_equal(table.to_pandas(),\n                            pd.concat([df, df], ignore_index=True))\n \n+    def test_stream_write_table_batches(self):\n+        # ARROW-504\n+        df = pd.DataFrame({\n+            'one': np.random.randn(20),\n+        })\n+\n+        b1 = pa.RecordBatch.from_pandas(df[:10], preserve_index=False)\n+        b2 = pa.RecordBatch.from_pandas(df, preserve_index=False)\n+\n+        table = pa.Table.from_batches([b1, b2, b1])\n+\n+        writer = self._get_writer(self.sink, table.schema)\n+        writer.write_table(table, chunksize=15)\n+        writer.close()\n+\n+        batches = list(pa.open_stream(pa.BufferReader(self._get_source())))\n+\n+        assert list(map(len, batches)) == [10, 15, 5, 10]\n+        result_table = pa.Table.from_batches(batches)\n+        assert_frame_equal(result_table.to_pandas(),\n+                           pd.concat([df[:10], df, df[:10]],\n+                                     ignore_index=True))\n+\n     def test_simple_roundtrip(self):\n         _, batches = self.write_batches()\n         file_contents = pa.BufferReader(self._get_source())\ndiff --git a/python/pyarrow/tests/test_table.py b/python/pyarrow/tests/test_table.py\nindex cd05fb8e1..ab012340c 100644\n--- a/python/pyarrow/tests/test_table.py\n+++ b/python/pyarrow/tests/test_table.py\n@@ -213,6 +213,31 @@ def test_recordbatchlist_schema_equals():\n         pa.Table.from_batches([batch1, batch2])\n \n \n+def test_table_to_batches():\n+    df1 = pd.DataFrame({'a': list(range(10))})\n+    df2 = pd.DataFrame({'a': list(range(10, 30))})\n+\n+    batch1 = pa.RecordBatch.from_pandas(df1, preserve_index=False)\n+    batch2 = pa.RecordBatch.from_pandas(df2, preserve_index=False)\n+\n+    table = pa.Table.from_batches([batch1, batch2, batch1])\n+\n+    expected_df = pd.concat([df1, df2, df1], ignore_index=True)\n+\n+    batches = table.to_batches()\n+    assert len(batches) == 3\n+\n+    assert_frame_equal(pa.Table.from_batches(batches).to_pandas(),\n+                       expected_df)\n+\n+    batches = table.to_batches(chunksize=15)\n+    assert list(map(len, batches)) == [10, 15, 5, 10]\n+\n+    assert_frame_equal(table.to_pandas(), expected_df)\n+    assert_frame_equal(pa.Table.from_batches(batches).to_pandas(),\n+                       expected_df)\n+\n+\n def test_table_basics():\n     data = [\n         pa.array(range(5)),\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T09:26:26.540+0000",
                    "updated": "2017-11-27T09:26:26.540+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13084092/comment/16266555",
                    "id": "16266555",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=uwe",
                        "name": "uwe",
                        "key": "xhochy",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=xhochy&avatarId=30652",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xhochy&avatarId=30652",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xhochy&avatarId=30652",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xhochy&avatarId=30652"
                        },
                        "displayName": "Uwe Korn",
                        "active": true,
                        "timeZone": "Europe/Berlin"
                    },
                    "body": "Issue resolved by pull request 1364\n[https://github.com/apache/arrow/pull/1364]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=uwe",
                        "name": "uwe",
                        "key": "xhochy",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=xhochy&avatarId=30652",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xhochy&avatarId=30652",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xhochy&avatarId=30652",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xhochy&avatarId=30652"
                        },
                        "displayName": "Uwe Korn",
                        "active": true,
                        "timeZone": "Europe/Berlin"
                    },
                    "created": "2017-11-27T09:27:08.529+0000",
                    "updated": "2017-11-27T09:27:08.529+0000"
                }
            ],
            "maxResults": 5,
            "total": 5,
            "startAt": 0
        },
        "customfield_12311820": "0|i3h047:",
        "customfield_12314139": null
    }
}