{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13437842",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842",
    "key": "ARROW-16122",
    "fields": {
        "parent": {
            "id": "13437825",
            "key": "ARROW-16119",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13437825",
            "fields": {
                "summary": "[Python] Deprecate the legacy ParquetDataset custom python-based implementation",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/4",
                    "description": "This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/reopened.png",
                    "name": "Reopened",
                    "id": "4",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                        "id": 2,
                        "key": "new",
                        "colorName": "blue-gray",
                        "name": "To Do"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
                    "id": "3",
                    "description": "A task that needs to be done.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
                    "name": "Task",
                    "subtask": false,
                    "avatarId": 21148
                }
            }
        },
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351051",
                "id": "12351051",
                "description": "",
                "name": "8.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-05-06"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=alenka",
            "name": "alenka",
            "key": "alenkaf",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
            },
            "displayName": "Alenka Frim",
            "active": true,
            "timeZone": "Europe/Ljubljana"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
            "name": "jorisvandenbossche",
            "key": "jorisvandenbossche",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Joris Van den Bossche",
            "active": true,
            "timeZone": "Europe/Brussels"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
            "name": "jorisvandenbossche",
            "key": "jorisvandenbossche",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Joris Van den Bossche",
            "active": true,
            "timeZone": "Europe/Brussels"
        },
        "aggregateprogress": {
            "progress": 18000,
            "total": 18000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 18000,
            "total": 18000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16122/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 30,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/753304",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF opened a new pull request, #12811:\nURL: https://github.com/apache/arrow/pull/12811\n\n   This PR tries to amend `pq.write_to_dataset` to:\r\n   \r\n   1. raise a deprecation warning for `use_legacy_dataset=True` and already switch the default to `False`.\r\n   2. raise deprecation warnings for all keywords (when `use_legacy_dataset=True`) that won't be supported in the new implementation.\n\n\n",
                    "created": "2022-04-06T10:58:04.204+0000",
                    "updated": "2022-04-06T10:58:04.204+0000",
                    "started": "2022-04-06T10:58:04.203+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "753304",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/753324",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#issuecomment-1090179382\n\n   https://issues.apache.org/jira/browse/ARROW-16122\n\n\n",
                    "created": "2022-04-06T11:51:37.658+0000",
                    "updated": "2022-04-06T11:51:37.658+0000",
                    "started": "2022-04-06T11:51:37.658+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "753324",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/753883",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r844824953\n\n\n##########\npython/pyarrow/parquet.py:\n##########\n@@ -2236,26 +2236,18 @@ def write_to_dataset(table, root_path, partition_cols=None,\n         and allow you to override the partition filename. If nothing is\n         passed, the filename will consist of a uuid.\n     use_legacy_dataset : bool\n-        Default is True unless a ``pyarrow.fs`` filesystem is passed.\n-        Set to False to enable the new code path (experimental, using the\n-        new Arrow Dataset API). This is more efficient when using partition\n-        columns, but does not (yet) support `partition_filename_cb` and\n-        `metadata_collector` keywords.\n+        Default is False. Set to True to use the the legacy behaviour\n+        (this option is deprecated, and the legacy implementation will be\n+        removed in a future version). The legacy implementation still\n+        supports `partition_filename_cb` and `metadata_collector` keywords\n+        but is less efficient when using partition columns.\n     **kwargs : dict,\n         Additional kwargs for write_table function. See docstring for\n         `write_table` or `ParquetWriter` for more information.\n         Using `metadata_collector` in kwargs allows one to collect the\n         file metadata instances of dataset pieces. The file paths in the\n         ColumnChunkMetaData will be set relative to `root_path`.\n     \"\"\"\n-    if use_legacy_dataset is None:\n-        # if a new filesystem is passed -> default to new implementation\n-        if isinstance(filesystem, FileSystem):\n\nReview Comment:\n   I was thinking that we could still let it default to None, and only interpret that as True _if_ `partition_filename_cb` is specififed. \r\n   \r\n   Because currently, if you were using `partition_filename_cb` (but didn't specify `use_legacy_dataset=True`, since that was not needed until now), that will directly start to raise an error. While we could maybe start with having it raise a deprecation warning.\n\n\n\n##########\npython/pyarrow/parquet.py:\n##########\n@@ -2341,6 +2340,11 @@ def file_visitor(written_file):\n     else:\n         if partition_filename_cb:\n             outfile = partition_filename_cb(None)\n+\n+            # raise for unsupported keywords\n+            warnings.warn(\n+                _DEPR_MSG.format(\"partition_filename_cb\", \"\"),\n+                FutureWarning, stacklevel=2)\n\nReview Comment:\n   I would maybe try to provide a customized deprecation message in this case, so we can give some more detail how you can replace `partition_filename_cb` in the new way (with the base_template)\r\n   \r\n   Also, the `partition_filename_cb` seems to be used above as well (in the `if` branch), so we would want to deprecate it in that case as well?\n\n\n\n",
                    "created": "2022-04-07T07:51:43.924+0000",
                    "updated": "2022-04-07T07:51:43.924+0000",
                    "started": "2022-04-07T07:51:43.923+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "753883",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754193",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845291213\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   So the reason that this is otherwise failing, is because with the new dataset implementation, we are using a fixed file name (`part-0.parquet`), while before we where using a uuid filename. And so therefore, with the non-legacy writer, it is each time overwriting the same file inside the loop.\r\n   \r\n   To what extent would this be something that users also could bump into? We could in theory use the `basename_template` argument to replicate this \"uuid\" filename behaviour inside `pq.write_to_dataset`.\n\n\n\n",
                    "created": "2022-04-07T15:45:58.969+0000",
                    "updated": "2022-04-07T15:45:58.969+0000",
                    "started": "2022-04-07T15:45:58.969+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754193",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754196",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845292683\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1531,8 +1531,8 @@ def test_dataset_read_dictionary(tempdir, use_legacy_dataset):\n     t1 = pa.table([[util.rands(10) for i in range(5)] * 10], names=['f0'])\n     t2 = pa.table([[util.rands(10) for i in range(5)] * 10], names=['f0'])\n     # TODO pass use_legacy_dataset (need to fix unique names)\n-    pq.write_to_dataset(t1, root_path=str(path))\n-    pq.write_to_dataset(t2, root_path=str(path))\n+    pq.write_to_dataset(t1, root_path=str(path), use_legacy_dataset=True)\n+    pq.write_to_dataset(t2, root_path=str(path), use_legacy_dataset=True)\n\nReview Comment:\n   Same here as my comment above (https://github.com/apache/arrow/pull/12811/files#r845291213), as the TODO comment also indicates: calling this twice with `use_legacy_dataset=False` would overwrite the same file.\n\n\n\n",
                    "created": "2022-04-07T15:47:20.868+0000",
                    "updated": "2022-04-07T15:47:20.868+0000",
                    "started": "2022-04-07T15:47:20.868+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754196",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754210",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845304218\n\n\n##########\npython/pyarrow/tests/test_dataset.py:\n##########\n@@ -937,7 +937,7 @@ def _create_dataset_for_fragments(tempdir, chunk_size=None, filesystem=None):\n     path = str(tempdir / \"test_parquet_dataset\")\n \n     # write_to_dataset currently requires pandas\n-    pq.write_to_dataset(table, path,\n+    pq.write_to_dataset(table, path, use_legacy_dataset=True,\n                         partition_cols=[\"part\"], chunk_size=chunk_size)\n\nReview Comment:\n   So here this fails with using the new dataset implementation, because `dataset.write_dataset(..)` doesn't support the parquet `row_group_size` keyword (to which `chunk_size` gets translated). The `ParquetFileWriteOptions` doesn't support this keyword. \r\n   \r\n   On the parquet side, this is also the only keyword that is not passed to the `ParquetWriter` init (and thus to parquet's `WriterProperties` or `ArrowWriterProperties`), but to the actual `write_table` call. In C++ this can be seen at\r\n   \r\n   https://github.com/apache/arrow/blob/76d064c729f5e2287bf2a2d5e02d1fb192ae5738/cpp/src/parquet/arrow/writer.h#L62-L71\r\n   \r\n   cc @westonpace do you remember if this has been discussed before how the `row_group_size`/`chunk_size` setting from Parquet fits into the dataset API?\n\n\n\n",
                    "created": "2022-04-07T15:58:20.000+0000",
                    "updated": "2022-04-07T15:58:20.000+0000",
                    "started": "2022-04-07T15:58:19.999+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754210",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754213",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845311683\n\n\n##########\npython/pyarrow/tests/test_dataset.py:\n##########\n@@ -937,7 +937,7 @@ def _create_dataset_for_fragments(tempdir, chunk_size=None, filesystem=None):\n     path = str(tempdir / \"test_parquet_dataset\")\n \n     # write_to_dataset currently requires pandas\n-    pq.write_to_dataset(table, path,\n+    pq.write_to_dataset(table, path, use_legacy_dataset=True,\n                         partition_cols=[\"part\"], chunk_size=chunk_size)\n\nReview Comment:\n   The dataset API now has a `max_rows_per_group`, but that doesn't necessarily directly relate to Parquet row groups? \r\n   \r\n   It's more generic about how many rows are written in one go, but so effectively is therefore also a max parquet row group size? (since those need to be written in one go)\n\n\n\n##########\npython/pyarrow/tests/test_dataset.py:\n##########\n@@ -937,7 +937,7 @@ def _create_dataset_for_fragments(tempdir, chunk_size=None, filesystem=None):\n     path = str(tempdir / \"test_parquet_dataset\")\n \n     # write_to_dataset currently requires pandas\n-    pq.write_to_dataset(table, path,\n+    pq.write_to_dataset(table, path, use_legacy_dataset=True,\n                         partition_cols=[\"part\"], chunk_size=chunk_size)\n\nReview Comment:\n   The dataset API now has a `max_rows_per_group`, I see, but that doesn't necessarily directly relate to Parquet row groups? \r\n   \r\n   It's more generic about how many rows are written in one go, but so effectively is therefore also a max parquet row group size? (since those need to be written in one go)\n\n\n\n",
                    "created": "2022-04-07T16:04:50.469+0000",
                    "updated": "2022-04-07T16:04:50.469+0000",
                    "started": "2022-04-07T16:04:50.468+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754213",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754455",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845863555\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   Of course, makes sense.\r\n   Yes, I think we should add what you are suggesting to the `pq.write_to_dataset`. Will try and commit for review!\n\n\n\n",
                    "created": "2022-04-08T08:21:42.960+0000",
                    "updated": "2022-04-08T08:21:42.960+0000",
                    "started": "2022-04-08T08:21:42.959+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754455",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754456",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845864090\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1531,8 +1531,8 @@ def test_dataset_read_dictionary(tempdir, use_legacy_dataset):\n     t1 = pa.table([[util.rands(10) for i in range(5)] * 10], names=['f0'])\n     t2 = pa.table([[util.rands(10) for i in range(5)] * 10], names=['f0'])\n     # TODO pass use_legacy_dataset (need to fix unique names)\n-    pq.write_to_dataset(t1, root_path=str(path))\n-    pq.write_to_dataset(t2, root_path=str(path))\n+    pq.write_to_dataset(t1, root_path=str(path), use_legacy_dataset=True)\n+    pq.write_to_dataset(t2, root_path=str(path), use_legacy_dataset=True)\n\nReview Comment:\n   Not sure why I didn't get this yesterday \ud83e\udd26\u200d\u2640\ufe0f \n\n\n\n",
                    "created": "2022-04-08T08:22:23.155+0000",
                    "updated": "2022-04-08T08:22:23.155+0000",
                    "started": "2022-04-08T08:22:23.154+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754456",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754468",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845909851\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   Hm, thinking aloud: `existing_data_behavior` controls how the dataset will handle data that already exists. If I implement a unique way of writing parquet files when using the new API in `wrtie_to_dataset` I will also have to set `existing_data_behavior` to be `overwrite_or_ignore`. That will then make trouble when exposing the same parameter in https://issues.apache.org/jira/browse/ARROW-15757.\r\n   \r\n   I could do a check if the parameter is specified or not. But am not sure if there will be additional complications ..\n\n\n\n",
                    "created": "2022-04-08T09:13:02.522+0000",
                    "updated": "2022-04-08T09:13:02.522+0000",
                    "started": "2022-04-08T09:13:02.521+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754468",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754469",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r845909851\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   Hm, thinking aloud: `existing_data_behavior` controls how the dataset will handle data that already exists. If I implement a unique way of writing parquet files when using the new API in `wrtie_to_dataset` I will also have to set `existing_data_behavior` to be `overwrite_or_ignore`. That will then make trouble when exposing the same parameter in https://issues.apache.org/jira/browse/ARROW-15757.\r\n   \r\n   I could do a check if the parameter is specified or not. But am not sure if there will be additional complications.\n\n\n\n",
                    "created": "2022-04-08T09:13:17.570+0000",
                    "updated": "2022-04-08T09:13:17.570+0000",
                    "started": "2022-04-08T09:13:17.569+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754469",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/754609",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r846131904\n\n\n##########\npython/pyarrow/parquet.py:\n##########\n@@ -2233,11 +2236,48 @@ def write_to_dataset(table, root_path, partition_cols=None,\n         and allow you to override the partition filename. If nothing is\n         passed, the filename will consist of a uuid.\n     use_legacy_dataset : bool\n-        Default is True unless a ``pyarrow.fs`` filesystem is passed.\n-        Set to False to enable the new code path (experimental, using the\n-        new Arrow Dataset API). This is more efficient when using partition\n-        columns, but does not (yet) support `partition_filename_cb` and\n-        `metadata_collector` keywords.\n+        Default is False. Set to True to use the the legacy behaviour\n+        (this option is deprecated, and the legacy implementation will be\n+        removed in a future version). The legacy implementation still\n+        supports `partition_filename_cb` and `metadata_collector` keywords\n+        but is less efficient when using partition columns.\n+    format : FileFormat or str\n+        The format in which to write the dataset. Currently supported:\n+        \"parquet\", \"ipc\"/\"arrow\"/\"feather\", and \"csv\". If a FileSystemDataset\n+        is being written and `format` is not specified, it defaults to the\n+        same format as the specified FileSystemDataset. When writing a\n+        Table or RecordBatch, this keyword is required.\n+    file_options : pyarrow.dataset.FileWriteOptions, optional\n+        FileFormat specific write options, created using the\n+        ``FileFormat.make_write_options()`` function.\n+    use_threads : bool, default True\n+        Write files in parallel. If enabled, then maximum parallelism will be\n+        used determined by the number of available CPU cores.\n+    schema : Schema, optional\n+    partitioning : Partitioning or list[str], optional\n+        The partitioning scheme specified with the ``partitioning()``\n+        function or a list of field names. When providing a list of\n+        field names, you can use ``partitioning_flavor`` to drive which\n+        partitioning type should be used.\n+    file_visitor : function\n+        If set, this function will be called with a WrittenFile instance\n+        for each file created during the call.  This object will have both\n+        a path attribute and a metadata attribute.\n+\n+        The path attribute will be a string containing the path to\n+        the created file.\n+\n+        The metadata attribute will be the parquet metadata of the file.\n+        This metadata will have the file path attribute set and can be used\n+        to build a _metadata file.  The metadata attribute will be None if\n+        the format is not parquet.\n+\n+        Example visitor which simple collects the filenames created::\n+\n+            visited_paths = []\n+\n+            def file_visitor(written_file):\n+                visited_paths.append(written_file.path)\n\nReview Comment:\n   @jorisvandenbossche should other keywords also be passed? (partitioning_flavor, max_*)\n\n\n\n",
                    "created": "2022-04-08T13:49:59.624+0000",
                    "updated": "2022-04-08T13:49:59.624+0000",
                    "started": "2022-04-08T13:49:59.624+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "754609",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757322",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r851085571\n\n\n##########\npython/pyarrow/parquet/__init__.py:\n##########\n@@ -3082,6 +3155,11 @@ def file_visitor(written_file):\n             _mkdir_if_not_exists(fs, '/'.join([root_path, subdir]))\n             if partition_filename_cb:\n                 outfile = partition_filename_cb(keys)\n+\n+                # raise for unsupported keywords\n+                warnings.warn(\n+                    _DEPR_MSG.format(\"partition_filename_cb\", msg3),\n+                    FutureWarning, stacklevel=2)\n\nReview Comment:\n   Since this is in a for loop, we would raise the warning multiple times. I think you can check for the keyword and raise the warning once before the actual writing code (eg where you now define the `msg3`)\n\n\n\n##########\npython/pyarrow/parquet/__init__.py:\n##########\n@@ -2962,11 +2965,48 @@ def write_to_dataset(table, root_path, partition_cols=None,\n         and allow you to override the partition filename. If nothing is\n         passed, the filename will consist of a uuid.\n     use_legacy_dataset : bool\n-        Default is True unless a ``pyarrow.fs`` filesystem is passed.\n-        Set to False to enable the new code path (experimental, using the\n-        new Arrow Dataset API). This is more efficient when using partition\n-        columns, but does not (yet) support `partition_filename_cb` and\n-        `metadata_collector` keywords.\n+        Default is False. Set to True to use the the legacy behaviour\n+        (this option is deprecated, and the legacy implementation will be\n+        removed in a future version). The legacy implementation still\n+        supports `partition_filename_cb` and `metadata_collector` keywords\n+        but is less efficient when using partition columns.\n+    format : FileFormat or str\n\nReview Comment:\n   I would leave out the `format`, since this should always be \"parquet\" (so we can hardcode that value). We don't want that users can use `pyarrow.parquet.write_to_dataset` to write eg Feather files\n\n\n\n##########\npython/pyarrow/parquet/__init__.py:\n##########\n@@ -2962,11 +2965,48 @@ def write_to_dataset(table, root_path, partition_cols=None,\n         and allow you to override the partition filename. If nothing is\n         passed, the filename will consist of a uuid.\n     use_legacy_dataset : bool\n-        Default is True unless a ``pyarrow.fs`` filesystem is passed.\n-        Set to False to enable the new code path (experimental, using the\n-        new Arrow Dataset API). This is more efficient when using partition\n-        columns, but does not (yet) support `partition_filename_cb` and\n-        `metadata_collector` keywords.\n+        Default is False. Set to True to use the the legacy behaviour\n+        (this option is deprecated, and the legacy implementation will be\n+        removed in a future version). The legacy implementation still\n+        supports `partition_filename_cb` and `metadata_collector` keywords\n+        but is less efficient when using partition columns.\n+    format : FileFormat or str\n\nReview Comment:\n   And it is actually still hardcoded in the code below, so passing this keyword currently wouldn't have any effect. Or is it only added to raise a warning in the legacy case?\n\n\n\n",
                    "created": "2022-04-15T07:01:22.085+0000",
                    "updated": "2022-04-15T07:01:22.085+0000",
                    "started": "2022-04-15T07:01:22.085+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757322",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757330",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r851112317\n\n\n##########\npython/pyarrow/parquet/__init__.py:\n##########\n@@ -2962,11 +2965,48 @@ def write_to_dataset(table, root_path, partition_cols=None,\n         and allow you to override the partition filename. If nothing is\n         passed, the filename will consist of a uuid.\n     use_legacy_dataset : bool\n-        Default is True unless a ``pyarrow.fs`` filesystem is passed.\n-        Set to False to enable the new code path (experimental, using the\n-        new Arrow Dataset API). This is more efficient when using partition\n-        columns, but does not (yet) support `partition_filename_cb` and\n-        `metadata_collector` keywords.\n+        Default is False. Set to True to use the the legacy behaviour\n+        (this option is deprecated, and the legacy implementation will be\n+        removed in a future version). The legacy implementation still\n+        supports `partition_filename_cb` and `metadata_collector` keywords\n+        but is less efficient when using partition columns.\n+    format : FileFormat or str\n\nReview Comment:\n   Oh, you are absolutely right - this doesn't make any sense (it was added as a try to expose all `write_dataset` keywords). Will remove it.\n\n\n\n",
                    "created": "2022-04-15T07:23:38.211+0000",
                    "updated": "2022-04-15T07:23:38.211+0000",
                    "started": "2022-04-15T07:23:38.210+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757330",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757341",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r851128672\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   So what I don't understand here is that the `dataset.write_dataset` function has a default to raise an error if there is existing data? But then why doesn't the above test fail with that error? (instead of failing in the test because we now overwrote the files)\n\n\n\n",
                    "created": "2022-04-15T07:57:16.929+0000",
                    "updated": "2022-04-15T07:57:16.929+0000",
                    "started": "2022-04-15T07:57:16.929+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757341",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757342",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r851129892\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   Thinking more about this: if we switch the default as we are now doing, I think we _should_ try to preserve the current behaviour of overwriting/adding data (otherwise it would be a quite breaking change for people using `pq.write_to_dataset` this way). We can still try to deprecate this and later move towards the same default as the dataset.write_dataset implementation. \r\n   But that can be done in a later stage with a proper deprecation warning (eg detect if the directory already exists and is not empty, and in that case indicate this will start raising an error in the future).\n\n\n\n",
                    "created": "2022-04-15T07:59:47.092+0000",
                    "updated": "2022-04-15T07:59:47.092+0000",
                    "started": "2022-04-15T07:59:47.092+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757342",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757346",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r851133972\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   Yes, good point.\r\n   I will step back and redo the issue in a way that the default stays `True` and it raises a deprecation warning in this case.\r\n   \r\n   For the later stage is it worth creating a JIRA already?\n\n\n\n",
                    "created": "2022-04-15T08:08:32.769+0000",
                    "updated": "2022-04-15T08:08:32.769+0000",
                    "started": "2022-04-15T08:08:32.768+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757346",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757349",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r851135533\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   In this case where the default will still be True, does exposing `write_dataset` keywords still makes sense or should we wait once the default changes?\n\n\n\n",
                    "created": "2022-04-15T08:11:33.043+0000",
                    "updated": "2022-04-15T08:11:33.043+0000",
                    "started": "2022-04-15T08:11:33.043+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757349",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757381",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on code in PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#discussion_r851226263\n\n\n##########\npython/pyarrow/tests/parquet/test_dataset.py:\n##########\n@@ -1290,7 +1290,7 @@ def _test_write_to_dataset_no_partitions(base_path,\n     # Without partitions, append files to root_path\n     n = 5\n     for i in range(n):\n-        pq.write_to_dataset(output_table, base_path,\n+        pq.write_to_dataset(output_table, base_path, use_legacy_dataset=True,\n\nReview Comment:\n   Follow up on this thread: I kept the new implementation as the default and added the use of `basename_template` to mimic the legacy behaviour.\r\n   \r\n   At a later stage I think it will be important to rearrange the keywords for `write_to_dataset` to first list the keywords connected to the new API.\n\n\n\n",
                    "created": "2022-04-15T11:41:38.948+0000",
                    "updated": "2022-04-15T11:41:38.948+0000",
                    "started": "2022-04-15T11:41:38.947+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757381",
                    "issueId": "13437842"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/worklog/757385",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "AlenkaF commented on PR #12811:\nURL: https://github.com/apache/arrow/pull/12811#issuecomment-1100070916\n\n   @jorisvandenbossche the PR should be ready now. I exposed `basename_template` and it now mimics the legacy behaviour.\n\n\n",
                    "created": "2022-04-15T12:16:02.925+0000",
                    "updated": "2022-04-15T12:16:02.925+0000",
                    "started": "2022-04-15T12:16:02.924+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "757385",
                    "issueId": "13437842"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 18000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@4fdb4b22[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@44b2e20f[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@198f476e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@4afe6cca[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@45396fe9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@d153cf5[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6e42ae0e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@57630730[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@592b7c12[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@7dfd0156[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6b4f239[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@49213f58[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 18000,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Apr 21 07:49:30 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-04-21T07:49:30.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16122/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2022-04-05T11:49:50.000+0000",
        "updated": "2022-04-23T08:21:12.000+0000",
        "timeoriginalestimate": null,
        "description": "Currently, the {{pq.write_to_dataset}} function also had a {{use_legacy_dataset}} keyword, but we should:\r\n\r\n1) in case of {{use_legacy_dataset=True}}, ensure we raise deprecation warnings for all keywords that won't be supported in the new implementation (eg {{partition_filename_cb}})\r\n2) raise a deprecation warning for {{use_legacy_dataset=True}}, and/or already switch the default?",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 18000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Change use_legacy_dataset default and deprecate no-longer supported keywords in parquet.write_to_dataset",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13437842/comment/17525491",
                    "id": "17525491",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "Issue resolved by pull request 12811\n[https://github.com/apache/arrow/pull/12811]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2022-04-21T07:49:30.312+0000",
                    "updated": "2022-04-21T07:49:30.312+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z115uo:",
        "customfield_12314139": null
    }
}