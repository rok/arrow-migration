{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13447976",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976",
    "key": "ARROW-16713",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351550",
                "id": "12351550",
                "name": "9.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-08-03"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=sakras",
            "name": "sakras",
            "key": "sakras",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Sasha Krassovsky",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=sakras",
            "name": "sakras",
            "key": "sakras",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Sasha Krassovsky",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=sakras",
            "name": "sakras",
            "key": "sakras",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Sasha Krassovsky",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 16200,
            "total": 16200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 16200,
            "total": 16200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16713/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 27,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779195",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#issuecomment-1148960177\n\n   https://issues.apache.org/jira/browse/ARROW-16713\n\n\n",
                    "created": "2022-06-07T17:24:23.223+0000",
                    "updated": "2022-06-07T17:24:23.223+0000",
                    "started": "2022-06-07T17:24:23.223+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779195",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779239",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#issuecomment-1149110088\n\n   Looks good to me.\r\n   \r\n   I have only a few comments:\r\n   1. I would like ProbeBatches to be implemented outside of HashJoinImpl by calling ProbeSingleBatch method of HashJoinImpl. That way the implementation of ProbeBatches can be shared between both current HashJoinImpl and SwissJoin's implementation of it.\r\n   2. finished_mutex_ in hash_join.cc is probably not used anymore and could be removed.\r\n   3. I think I would prefer if AccumulationQueue was thread-safe than having HashJoinNode managing mutexes for accumulation queues. I see that in this implementation AccumulationQueue is sometimes used on a single-thread or in a read-only way, where the mutex is not necessary, but I would still prefer to extract a vector of exec batches in a thread-safe way from AccumulationQueue and use it instead in such situations. Or alternatively having a state flag in AccumulationQueue saying that it is read-only and doesn't require a mutex.\n\n\n",
                    "created": "2022-06-07T20:03:45.689+0000",
                    "updated": "2022-06-07T20:03:45.689+0000",
                    "started": "2022-06-07T20:03:45.688+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779239",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779247",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#issuecomment-1149124849\n\n   1. That's true. I did think it would be cleaner to have batches that are being operated on be owned by the data structure that's doing the work. For `ProbeBatches` specifically I could make a special \"probing accumulation queue\" that gets moved into instead. \r\n   2. Good point, will remove\r\n   3. I initially did have it be thread-safe, but then I realized that most of them would have locks managed externally anyway: for spilling we'll be using PartitionLocks and for HashJoinNode we use the mutexes to protect stuff other than the AccumulationQueues, so in neither case will we actually ever use the AccumulationQueue's mutex. \n\n\n",
                    "created": "2022-06-07T20:19:14.610+0000",
                    "updated": "2022-06-07T20:19:14.610+0000",
                    "started": "2022-06-07T20:19:14.610+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779247",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779251",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#issuecomment-1149134406\n\n   Re AccumulationQueue: then it becomes just a vector, and maybe doesn't need promoting it to a separate class in a separate file\r\n   \n\n\n",
                    "created": "2022-06-07T20:29:04.892+0000",
                    "updated": "2022-06-07T20:29:04.892+0000",
                    "started": "2022-06-07T20:29:04.891+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779251",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779581",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892487699\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join.cc:\n##########\n@@ -789,159 +603,30 @@ class HashJoinBasicImpl : public HashJoinImpl {\n     return Status::OK();\n   }\n \n-  Status BuildBloomFilter_on_finished(size_t thread_index) {\n-    if (cancelled_) return Status::Cancelled(\"Hash join cancelled\");\n-    ARROW_DCHECK(pushdown_target_);\n-    RETURN_NOT_OK(pushdown_target_->PushBloomFilter(\n-        thread_index, std::move(bloom_filter_), std::move(column_map_)));\n-    return BuildHashTable(thread_index);\n-  }\n-\n   Status BuildHashTable_on_finished(size_t thread_index) {\n-    if (cancelled_) {\n-      return Status::Cancelled(\"Hash join cancelled\");\n-    }\n-\n-    right_batches_.clear();\n-\n-    bool proceed;\n-    {\n-      std::lock_guard<std::mutex> lock(left_batches_mutex_);\n-      std::lock_guard<std::mutex> lock_finish(finished_mutex_);\n-      left_queue_bloom_finished_ =\n-          left_queue_bloom_finished_ || num_expected_bloom_filters_ == 0;\n-      proceed = !has_hash_table_ && left_queue_bloom_finished_;\n-      has_hash_table_ = true;\n-    }\n-    if (proceed) RETURN_NOT_OK(ProbeQueuedBatches(thread_index));\n-\n-    return Status::OK();\n-  }\n-\n-  void RegisterBuildBloomFilter() {\n-    task_group_bloom_ = scheduler_->RegisterTaskGroup(\n-        [this](size_t thread_index, int64_t task_id) -> Status {\n-          return BuildBloomFilter_exec_task(thread_index, task_id);\n-        },\n-        [this](size_t thread_index) -> Status {\n-          return BuildBloomFilter_on_finished(thread_index);\n-        });\n-  }\n-\n-  void RegisterBuildHashTable() {\n-    task_group_build_ = scheduler_->RegisterTaskGroup(\n-        [this](size_t thread_index, int64_t task_id) -> Status {\n-          return BuildHashTable_exec_task(thread_index, task_id);\n-        },\n-        [this](size_t thread_index) -> Status {\n-          return BuildHashTable_on_finished(thread_index);\n-        });\n+    build_batches_.Clear();\n\nReview Comment:\n   This seems redundant given that you moved out of here above.  Maybe just a `DCHECK_EQ(0, build_batches_.size())`?\n\n\n\n##########\ncpp/src/arrow/compute/exec/accumulation_queue.h:\n##########\n@@ -0,0 +1,52 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+#include <cstdint>\n+#include <vector>\n+#include \"arrow/compute/exec.h\"\n\nReview Comment:\n   ```suggestion\r\n   #pragma once\r\n   \r\n   #include <cstdint>\r\n   #include <vector>\r\n   \r\n   #include \"arrow/compute/exec.h\"\r\n   ```\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n+    }\n+    if (proceed) {\n+      return push_.all_received_callback_();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FilterBatches(size_t thread_index, AccumulationQueue batches,\n+                       FilterFinishedCallback on_finished) {\n+    eval_.batches_ = std::move(batches);\n+    eval_.on_finished_ = std::move(on_finished);\n+\n+    if (eval_.num_expected_bloom_filters_ == 0)\n+      return eval_.on_finished_(thread_index, std::move(eval_.batches_));\n+\n+    return scheduler_->StartTaskGroup(thread_index, eval_.task_id_,\n+                                      /*num_tasks=*/eval_.batches_.batch_count());\n+  }\n+\n+  Status FilterSingleBatch(size_t thread_index, ExecBatch& batch) {\n+    if (disable_bloom_filter_ || batch.length == 0) return Status::OK();\n+    int64_t bit_vector_bytes = bit_util::BytesForBits(batch.length);\n+    std::vector<uint8_t> selected(bit_vector_bytes);\n+    std::vector<uint32_t> hashes(batch.length);\n+    std::vector<uint8_t> bv(bit_vector_bytes);\n+\n+    ARROW_ASSIGN_OR_RAISE(util::TempVectorStack * stack, GetStack(thread_index));\n+\n+    // Start with full selection for the current batch\n+    memset(selected.data(), 0xff, bit_vector_bytes);\n+    for (size_t ifilter = 0; ifilter < eval_.num_expected_bloom_filters_; ifilter++) {\n+      std::vector<Datum> keys(eval_.received_maps_[ifilter].size());\n+      for (size_t i = 0; i < keys.size(); i++) {\n+        int input_idx = eval_.received_maps_[ifilter][i];\n+        keys[i] = batch[input_idx];\n+        if (keys[i].is_scalar()) {\n+          ARROW_ASSIGN_OR_RAISE(\n+              keys[i],\n+              MakeArrayFromScalar(*keys[i].scalar(), batch.length, ctx_->memory_pool()));\n+        }\n+      }\n+      ARROW_ASSIGN_OR_RAISE(ExecBatch key_batch, ExecBatch::Make(std::move(keys)));\n+      RETURN_NOT_OK(Hashing32::HashBatch(key_batch, hashes.data(),\n+                                         ctx_->cpu_info()->hardware_flags(), stack, 0,\n+                                         key_batch.length));\n+\n+      eval_.received_filters_[ifilter]->Find(ctx_->cpu_info()->hardware_flags(),\n+                                             key_batch.length, hashes.data(), bv.data());\n+      arrow::internal::BitmapAnd(bv.data(), 0, selected.data(), 0, key_batch.length, 0,\n+                                 selected.data());\n+    }\n+    auto selected_buffer =\n+        arrow::internal::make_unique<Buffer>(selected.data(), bit_vector_bytes);\n+    ArrayData selected_arraydata(boolean(), batch.length,\n+                                 {nullptr, std::move(selected_buffer)});\n+    Datum selected_datum(selected_arraydata);\n+    FilterOptions options;\n+    size_t first_nonscalar = batch.values.size();\n+    for (size_t i = 0; i < batch.values.size(); i++) {\n+      if (!batch.values[i].is_scalar()) {\n+        ARROW_ASSIGN_OR_RAISE(batch.values[i],\n+                              Filter(batch.values[i], selected_datum, options, ctx_));\n+        first_nonscalar = std::min(first_nonscalar, i);\n+        ARROW_DCHECK_EQ(batch.values[i].length(), batch.values[first_nonscalar].length());\n+      }\n+    }\n+    // If they're all Scalar, then the length of the batch is the number of set bits\n+    if (first_nonscalar == batch.values.size())\n+      batch.length = arrow::internal::CountSetBits(selected.data(), 0, batch.length);\n+    else\n+      batch.length = batch.values[first_nonscalar].length();\n+    return Status::OK();\n+  }\n+\n+  Status BuildBloomFilter_exec_task(size_t thread_index, int64_t task_id);\n+\n+  Status BuildBloomFilter_on_finished(size_t thread_index) {\n+    return build_.on_finished_(thread_index, std::move(build_.batches_));\n+  }\n+\n+  // The Bloom filter is built on the build side of some upstream join. For a join to\n+  // evaluate the Bloom filter on its input columns, it has to rearrange its input columns\n+  // to match the column order of the Bloom filter.\n+  //\n+  // The first part of the pair is the HashJoin to actually perform the pushdown into.\n+  // The second part is a mapping such that column_map[i] is the index of key i in\n+  // the first part's input.\n+  // If we should disable Bloom filter, returns nullptr and an empty vector, and sets\n+  // the disable_bloom_filter_ flag.\n+  std::pair<HashJoinNode*, std::vector<int>> GetPushdownTarget(HashJoinNode* start);\n+\n+  Result<util::TempVectorStack*> GetStack(size_t thread_index) {\n+    if (!tld_[thread_index].is_init) {\n+      RETURN_NOT_OK(tld_[thread_index].stack.Init(\n+          ctx_->memory_pool(), 4 * util::MiniBatch::kMiniBatchLength * sizeof(uint32_t)));\n+      tld_[thread_index].is_init = true;\n+    }\n+    return &tld_[thread_index].stack;\n+  }\n+\n+  bool disable_bloom_filter_;\n+  HashJoinNode* owner_;\n+  ExecContext* ctx_;\n+  TaskScheduler* scheduler_;\n+\n+  struct ThreadLocalData {\n+    bool is_init = false;\n+    util::TempVectorStack stack;\n+  };\n+  std::vector<ThreadLocalData> tld_;\n+\n+  struct {\n+    int task_id_;\n+    std::unique_ptr<BloomFilterBuilder> builder_;\n+    AccumulationQueue batches_;\n+    BuildFinishedCallback on_finished_;\n+  } build_;\n+\n+  struct {\n+    std::unique_ptr<BlockedBloomFilter> bloom_filter_;\n+    HashJoinNode* pushdown_target_;\n+    std::vector<int> column_map_;\n+    FiltersReceivedCallback all_received_callback_;\n\nReview Comment:\n   This feels more like an `eval_` thing?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n+    }\n+    if (proceed) {\n+      return push_.all_received_callback_();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FilterBatches(size_t thread_index, AccumulationQueue batches,\n+                       FilterFinishedCallback on_finished) {\n+    eval_.batches_ = std::move(batches);\n+    eval_.on_finished_ = std::move(on_finished);\n+\n+    if (eval_.num_expected_bloom_filters_ == 0)\n+      return eval_.on_finished_(thread_index, std::move(eval_.batches_));\n+\n+    return scheduler_->StartTaskGroup(thread_index, eval_.task_id_,\n+                                      /*num_tasks=*/eval_.batches_.batch_count());\n+  }\n+\n+  Status FilterSingleBatch(size_t thread_index, ExecBatch& batch) {\n+    if (disable_bloom_filter_ || batch.length == 0) return Status::OK();\n+    int64_t bit_vector_bytes = bit_util::BytesForBits(batch.length);\n+    std::vector<uint8_t> selected(bit_vector_bytes);\n+    std::vector<uint32_t> hashes(batch.length);\n+    std::vector<uint8_t> bv(bit_vector_bytes);\n+\n+    ARROW_ASSIGN_OR_RAISE(util::TempVectorStack * stack, GetStack(thread_index));\n+\n+    // Start with full selection for the current batch\n+    memset(selected.data(), 0xff, bit_vector_bytes);\n+    for (size_t ifilter = 0; ifilter < eval_.num_expected_bloom_filters_; ifilter++) {\n+      std::vector<Datum> keys(eval_.received_maps_[ifilter].size());\n+      for (size_t i = 0; i < keys.size(); i++) {\n+        int input_idx = eval_.received_maps_[ifilter][i];\n+        keys[i] = batch[input_idx];\n+        if (keys[i].is_scalar()) {\n+          ARROW_ASSIGN_OR_RAISE(\n+              keys[i],\n+              MakeArrayFromScalar(*keys[i].scalar(), batch.length, ctx_->memory_pool()));\n+        }\n+      }\n+      ARROW_ASSIGN_OR_RAISE(ExecBatch key_batch, ExecBatch::Make(std::move(keys)));\n+      RETURN_NOT_OK(Hashing32::HashBatch(key_batch, hashes.data(),\n+                                         ctx_->cpu_info()->hardware_flags(), stack, 0,\n+                                         key_batch.length));\n+\n+      eval_.received_filters_[ifilter]->Find(ctx_->cpu_info()->hardware_flags(),\n+                                             key_batch.length, hashes.data(), bv.data());\n+      arrow::internal::BitmapAnd(bv.data(), 0, selected.data(), 0, key_batch.length, 0,\n+                                 selected.data());\n+    }\n+    auto selected_buffer =\n+        arrow::internal::make_unique<Buffer>(selected.data(), bit_vector_bytes);\n+    ArrayData selected_arraydata(boolean(), batch.length,\n+                                 {nullptr, std::move(selected_buffer)});\n+    Datum selected_datum(selected_arraydata);\n+    FilterOptions options;\n+    size_t first_nonscalar = batch.values.size();\n+    for (size_t i = 0; i < batch.values.size(); i++) {\n+      if (!batch.values[i].is_scalar()) {\n+        ARROW_ASSIGN_OR_RAISE(batch.values[i],\n+                              Filter(batch.values[i], selected_datum, options, ctx_));\n+        first_nonscalar = std::min(first_nonscalar, i);\n+        ARROW_DCHECK_EQ(batch.values[i].length(), batch.values[first_nonscalar].length());\n+      }\n+    }\n+    // If they're all Scalar, then the length of the batch is the number of set bits\n+    if (first_nonscalar == batch.values.size())\n+      batch.length = arrow::internal::CountSetBits(selected.data(), 0, batch.length);\n+    else\n+      batch.length = batch.values[first_nonscalar].length();\n+    return Status::OK();\n+  }\n+\n+  Status BuildBloomFilter_exec_task(size_t thread_index, int64_t task_id);\n+\n+  Status BuildBloomFilter_on_finished(size_t thread_index) {\n+    return build_.on_finished_(thread_index, std::move(build_.batches_));\n+  }\n+\n+  // The Bloom filter is built on the build side of some upstream join. For a join to\n+  // evaluate the Bloom filter on its input columns, it has to rearrange its input columns\n+  // to match the column order of the Bloom filter.\n+  //\n+  // The first part of the pair is the HashJoin to actually perform the pushdown into.\n+  // The second part is a mapping such that column_map[i] is the index of key i in\n+  // the first part's input.\n+  // If we should disable Bloom filter, returns nullptr and an empty vector, and sets\n+  // the disable_bloom_filter_ flag.\n+  std::pair<HashJoinNode*, std::vector<int>> GetPushdownTarget(HashJoinNode* start);\n+\n+  Result<util::TempVectorStack*> GetStack(size_t thread_index) {\n+    if (!tld_[thread_index].is_init) {\n+      RETURN_NOT_OK(tld_[thread_index].stack.Init(\n+          ctx_->memory_pool(), 4 * util::MiniBatch::kMiniBatchLength * sizeof(uint32_t)));\n+      tld_[thread_index].is_init = true;\n+    }\n+    return &tld_[thread_index].stack;\n+  }\n+\n+  bool disable_bloom_filter_;\n+  HashJoinNode* owner_;\n\nReview Comment:\n   It seems this is only used to access the schema projection maps.  Maybe just take a pointer to that instead?  Then it would be clearer why this is needed.\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join.cc:\n##########\n@@ -1105,16 +745,15 @@ class HashJoinBasicImpl : public HashJoinImpl {\n   HashJoinSchema* schema_mgr_;\n   std::vector<JoinKeyCmp> key_cmp_;\n   Expression filter_;\n-  std::unique_ptr<TaskScheduler> scheduler_;\n-  int task_group_bloom_;\n+  TaskScheduler* scheduler_;\n   int task_group_build_;\n-  int task_group_bloom_filter_queued_;\n-  int task_group_queued_;\n   int task_group_scan_;\n \n   // Callbacks\n   //\n   OutputBatchCallback output_batch_callback_;\n+  BuildFinishedCallback build_finished_callback_;\n+  ProbeFinishedCallback probe_finished_callback_;\n\nReview Comment:\n   Is this used?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n\nReview Comment:\n   I think there would be some value here in comments explaining the general strategy of what we are trying to do (or maybe, as has also been discussed, we just need more general design documents).  Maybe just some short comments on each of these methods and a paragraph on the struct itself.\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n\nReview Comment:\n   `ARROW_DCHECK_EQ` & `ARROW_DCHECK_LE`?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n\nReview Comment:\n   Can we use constants instead of `1`?  Something like `accumulators_[kBuildSide]`.  Or, if there is only ever going to be two, can we just have `build_accumulator` and `probe_accumulator`?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n+    }\n+    if (proceed) {\n+      return push_.all_received_callback_();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FilterBatches(size_t thread_index, AccumulationQueue batches,\n+                       FilterFinishedCallback on_finished) {\n+    eval_.batches_ = std::move(batches);\n+    eval_.on_finished_ = std::move(on_finished);\n+\n+    if (eval_.num_expected_bloom_filters_ == 0)\n+      return eval_.on_finished_(thread_index, std::move(eval_.batches_));\n+\n+    return scheduler_->StartTaskGroup(thread_index, eval_.task_id_,\n+                                      /*num_tasks=*/eval_.batches_.batch_count());\n+  }\n+\n+  Status FilterSingleBatch(size_t thread_index, ExecBatch& batch) {\n\nReview Comment:\n   Arrow's style suggests we take in `ExecBatch*` for a mutable argument.\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n+    return Status::OK();\n+  }\n+\n+  Status OnBuildSideFinished(size_t thread_index) {\n+    return pushdown_context_.BuildBloomFilter(\n+        thread_index, std::move(accumulators_[1]),\n+        [this](size_t thread_index, AccumulationQueue batches) {\n+          return OnBloomFilterFinished(thread_index, std::move(batches));\n+        });\n+  }\n+\n+  Status OnBloomFilterFinished(size_t thread_index, AccumulationQueue batches) {\n+    RETURN_NOT_OK(pushdown_context_.PushBloomFilter());\n+    return impl_->BuildHashTable(\n+        thread_index, std::move(batches),\n+        [this](size_t thread_index) { return OnHashTableFinished(thread_index); });\n+  }\n+\n+  Status OnHashTableFinished(size_t thread_index) {\n+    bool should_probe;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_probe = queued_batches_filtered_ && !hash_table_ready_;\n+      hash_table_ready_ = true;\n+    }\n+    if (should_probe) {\n+      return ProbeQueuedBatches(thread_index);\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status OnProbeSideBatch(size_t thread_index, ExecBatch batch) {\n+    bool should_filter;\n+    bool should_accum;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_filter = bloom_filters_ready_;\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) {\n+        accumulators_[0].InsertBatch(std::move(batch));\n+        return Status::OK();\n+      }\n+    }\n+    if (should_filter)\n\nReview Comment:\n   Is this check needed?  How can we get here if `should_filter` is false?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n+    return Status::OK();\n+  }\n+\n+  Status OnBuildSideFinished(size_t thread_index) {\n+    return pushdown_context_.BuildBloomFilter(\n+        thread_index, std::move(accumulators_[1]),\n+        [this](size_t thread_index, AccumulationQueue batches) {\n+          return OnBloomFilterFinished(thread_index, std::move(batches));\n+        });\n+  }\n+\n+  Status OnBloomFilterFinished(size_t thread_index, AccumulationQueue batches) {\n+    RETURN_NOT_OK(pushdown_context_.PushBloomFilter());\n+    return impl_->BuildHashTable(\n+        thread_index, std::move(batches),\n+        [this](size_t thread_index) { return OnHashTableFinished(thread_index); });\n+  }\n+\n+  Status OnHashTableFinished(size_t thread_index) {\n+    bool should_probe;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_probe = queued_batches_filtered_ && !hash_table_ready_;\n+      hash_table_ready_ = true;\n+    }\n+    if (should_probe) {\n+      return ProbeQueuedBatches(thread_index);\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status OnProbeSideBatch(size_t thread_index, ExecBatch batch) {\n+    bool should_filter;\n+    bool should_accum;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_filter = bloom_filters_ready_;\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) {\n\nReview Comment:\n   I'm not 100% sure I'm following this but it seems like `should_accum` will be true if the bloom filters are ready but the hash table is not ready.  Couldn't we run filter single batch and then accumulate in that case?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n\nReview Comment:\n   Given that this is a .cc file, why are some of these defined inline and some are only declared here?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n+    return Status::OK();\n+  }\n+\n+  Status OnBuildSideFinished(size_t thread_index) {\n+    return pushdown_context_.BuildBloomFilter(\n+        thread_index, std::move(accumulators_[1]),\n+        [this](size_t thread_index, AccumulationQueue batches) {\n+          return OnBloomFilterFinished(thread_index, std::move(batches));\n+        });\n+  }\n+\n+  Status OnBloomFilterFinished(size_t thread_index, AccumulationQueue batches) {\n+    RETURN_NOT_OK(pushdown_context_.PushBloomFilter());\n+    return impl_->BuildHashTable(\n+        thread_index, std::move(batches),\n+        [this](size_t thread_index) { return OnHashTableFinished(thread_index); });\n+  }\n+\n+  Status OnHashTableFinished(size_t thread_index) {\n+    bool should_probe;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_probe = queued_batches_filtered_ && !hash_table_ready_;\n+      hash_table_ready_ = true;\n+    }\n+    if (should_probe) {\n+      return ProbeQueuedBatches(thread_index);\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status OnProbeSideBatch(size_t thread_index, ExecBatch batch) {\n+    bool should_filter;\n+    bool should_accum;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_filter = bloom_filters_ready_;\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) {\n+        accumulators_[0].InsertBatch(std::move(batch));\n+        return Status::OK();\n+      }\n+    }\n+    if (should_filter)\n+      RETURN_NOT_OK(pushdown_context_.FilterSingleBatch(thread_index, batch));\n+\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) accumulators_[0].InsertBatch(std::move(batch));\n\nReview Comment:\n   Couldn't this just be `if (!hash_table_ready_)`?\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n+    }\n+    if (proceed) {\n+      return push_.all_received_callback_();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FilterBatches(size_t thread_index, AccumulationQueue batches,\n+                       FilterFinishedCallback on_finished) {\n+    eval_.batches_ = std::move(batches);\n+    eval_.on_finished_ = std::move(on_finished);\n+\n+    if (eval_.num_expected_bloom_filters_ == 0)\n\nReview Comment:\n   Why not check for `disable_bloom_filter_` here too?  Then it seems like you wouldn't have to check in `FilterSingleBatch`\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -780,9 +983,228 @@ class HashJoinNode : public ExecNode {\n   std::unique_ptr<HashJoinSchema> schema_mgr_;\n   std::unique_ptr<HashJoinImpl> impl_;\n   util::AsyncTaskGroup task_group_;\n+  std::unique_ptr<TaskScheduler> scheduler_;\n+  util::AccumulationQueue accumulators_[2];\n+  util::AccumulationQueue queued_batches_to_probe_;\n+\n+  std::mutex build_side_mutex_;\n+  std::mutex probe_side_mutex_;\n+\n+  int task_group_probe_;\n+  bool bloom_filters_ready_ = false;\n+  bool hash_table_ready_ = false;\n+  bool queued_batches_filtered_ = false;\n+  bool queued_batches_probed_ = false;\n+  bool probe_side_finished_ = false;\n+\n+  friend struct BloomFilterPushdownContext;\n   bool disable_bloom_filter_;\n+  BloomFilterPushdownContext pushdown_context_;\n };\n \n+void BloomFilterPushdownContext::Init(HashJoinNode* owner, size_t num_threads,\n+                                      TaskScheduler* scheduler,\n+                                      FiltersReceivedCallback on_bloom_filters_received,\n+                                      bool disable_bloom_filter,\n+                                      bool use_sync_execution) {\n+  owner_ = owner;\n+  ctx_ = owner->plan_->exec_context();\n+  scheduler_ = scheduler;\n+  tld_.resize(num_threads);\n+  disable_bloom_filter_ = disable_bloom_filter;\n+  std::tie(push_.pushdown_target_, push_.column_map_) = GetPushdownTarget(owner);\n+  push_.all_received_callback_ = std::move(on_bloom_filters_received);\n+  if (!disable_bloom_filter_) {\n+    ARROW_CHECK(push_.pushdown_target_);\n+    push_.bloom_filter_ = arrow::internal::make_unique<BlockedBloomFilter>();\n+    push_.pushdown_target_->pushdown_context_.ExpectBloomFilter();\n+\n+    build_.builder_ = BloomFilterBuilder::Make(\n+        use_sync_execution ? BloomFilterBuildStrategy::SINGLE_THREADED\n+                           : BloomFilterBuildStrategy::PARALLEL);\n+\n+    build_.task_id_ = scheduler_->RegisterTaskGroup(\n+        [this](size_t thread_index, int64_t task_id) {\n+          return BuildBloomFilter_exec_task(thread_index, task_id);\n+        },\n+        [this](size_t thread_index) {\n+          return BuildBloomFilter_on_finished(thread_index);\n+        });\n+  }\n+\n+  eval_.task_id_ = scheduler_->RegisterTaskGroup(\n+      [this](size_t thread_index, int64_t task_id) {\n+        return FilterSingleBatch(thread_index, eval_.batches_[task_id]);\n+      },\n+      [this](size_t thread_index) {\n+        return eval_.on_finished_(thread_index, std::move(eval_.batches_));\n+      });\n+}\n+\n+Status BloomFilterPushdownContext::StartProducing() {\n+  if (eval_.num_expected_bloom_filters_ == 0) return push_.all_received_callback_();\n\nReview Comment:\n   This is fine but is there any reason we can't just call this from `Init`?\n\n\n\n",
                    "created": "2022-06-08T16:48:08.222+0000",
                    "updated": "2022-06-08T16:48:08.222+0000",
                    "started": "2022-06-08T16:48:08.221+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779581",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779582",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#issuecomment-1150157900\n\n   > Re AccumulationQueue: then it becomes just a vector, and maybe doesn't need promoting it to a separate class in a separate file\r\n   \r\n   This is true.  The only difference I see between the accumulation queue and a vector of batches at the moment is `row_count()` but, on second examination, it doesn't seem we are currently using `row_count()` anywhere.\n\n\n",
                    "created": "2022-06-08T16:50:32.328+0000",
                    "updated": "2022-06-08T16:50:32.328+0000",
                    "started": "2022-06-08T16:50:32.327+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779582",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779623",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#issuecomment-1150277667\n\n   `row_count` is used for the Bloom filter build (in only one spot). I kind of like AccumulationQueue because it also disallows copying, and the `Append` function is handy. Also in the next PR I'll be adding a `SpillingAccumulationQueue`, so I kind of like having a name for these. I'm fine getting rid of it though too though\n\n\n",
                    "created": "2022-06-08T18:53:25.113+0000",
                    "updated": "2022-06-08T18:53:25.113+0000",
                    "started": "2022-06-08T18:53:25.113+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779623",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779624",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892750760\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -780,9 +983,228 @@ class HashJoinNode : public ExecNode {\n   std::unique_ptr<HashJoinSchema> schema_mgr_;\n   std::unique_ptr<HashJoinImpl> impl_;\n   util::AsyncTaskGroup task_group_;\n+  std::unique_ptr<TaskScheduler> scheduler_;\n+  util::AccumulationQueue accumulators_[2];\n+  util::AccumulationQueue queued_batches_to_probe_;\n+\n+  std::mutex build_side_mutex_;\n+  std::mutex probe_side_mutex_;\n+\n+  int task_group_probe_;\n+  bool bloom_filters_ready_ = false;\n+  bool hash_table_ready_ = false;\n+  bool queued_batches_filtered_ = false;\n+  bool queued_batches_probed_ = false;\n+  bool probe_side_finished_ = false;\n+\n+  friend struct BloomFilterPushdownContext;\n   bool disable_bloom_filter_;\n+  BloomFilterPushdownContext pushdown_context_;\n };\n \n+void BloomFilterPushdownContext::Init(HashJoinNode* owner, size_t num_threads,\n+                                      TaskScheduler* scheduler,\n+                                      FiltersReceivedCallback on_bloom_filters_received,\n+                                      bool disable_bloom_filter,\n+                                      bool use_sync_execution) {\n+  owner_ = owner;\n+  ctx_ = owner->plan_->exec_context();\n+  scheduler_ = scheduler;\n+  tld_.resize(num_threads);\n+  disable_bloom_filter_ = disable_bloom_filter;\n+  std::tie(push_.pushdown_target_, push_.column_map_) = GetPushdownTarget(owner);\n+  push_.all_received_callback_ = std::move(on_bloom_filters_received);\n+  if (!disable_bloom_filter_) {\n+    ARROW_CHECK(push_.pushdown_target_);\n+    push_.bloom_filter_ = arrow::internal::make_unique<BlockedBloomFilter>();\n+    push_.pushdown_target_->pushdown_context_.ExpectBloomFilter();\n+\n+    build_.builder_ = BloomFilterBuilder::Make(\n+        use_sync_execution ? BloomFilterBuildStrategy::SINGLE_THREADED\n+                           : BloomFilterBuildStrategy::PARALLEL);\n+\n+    build_.task_id_ = scheduler_->RegisterTaskGroup(\n+        [this](size_t thread_index, int64_t task_id) {\n+          return BuildBloomFilter_exec_task(thread_index, task_id);\n+        },\n+        [this](size_t thread_index) {\n+          return BuildBloomFilter_on_finished(thread_index);\n+        });\n+  }\n+\n+  eval_.task_id_ = scheduler_->RegisterTaskGroup(\n+      [this](size_t thread_index, int64_t task_id) {\n+        return FilterSingleBatch(thread_index, eval_.batches_[task_id]);\n+      },\n+      [this](size_t thread_index) {\n+        return eval_.on_finished_(thread_index, std::move(eval_.batches_));\n+      });\n+}\n+\n+Status BloomFilterPushdownContext::StartProducing() {\n+  if (eval_.num_expected_bloom_filters_ == 0) return push_.all_received_callback_();\n\nReview Comment:\n   We may not have received all calls to `ExpectBloomFilter` inside of `PrepareToProduce`, we need `StartProducing` because that's the earliest we're guaranteed that the Bloom filters have sorted themselves out.\n\n\n\n",
                    "created": "2022-06-08T18:54:43.965+0000",
                    "updated": "2022-06-08T18:54:43.965+0000",
                    "started": "2022-06-08T18:54:43.964+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779624",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779626",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892755442\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n+    }\n+    if (proceed) {\n+      return push_.all_received_callback_();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FilterBatches(size_t thread_index, AccumulationQueue batches,\n+                       FilterFinishedCallback on_finished) {\n+    eval_.batches_ = std::move(batches);\n+    eval_.on_finished_ = std::move(on_finished);\n+\n+    if (eval_.num_expected_bloom_filters_ == 0)\n+      return eval_.on_finished_(thread_index, std::move(eval_.batches_));\n+\n+    return scheduler_->StartTaskGroup(thread_index, eval_.task_id_,\n+                                      /*num_tasks=*/eval_.batches_.batch_count());\n+  }\n+\n+  Status FilterSingleBatch(size_t thread_index, ExecBatch& batch) {\n+    if (disable_bloom_filter_ || batch.length == 0) return Status::OK();\n+    int64_t bit_vector_bytes = bit_util::BytesForBits(batch.length);\n+    std::vector<uint8_t> selected(bit_vector_bytes);\n+    std::vector<uint32_t> hashes(batch.length);\n+    std::vector<uint8_t> bv(bit_vector_bytes);\n+\n+    ARROW_ASSIGN_OR_RAISE(util::TempVectorStack * stack, GetStack(thread_index));\n+\n+    // Start with full selection for the current batch\n+    memset(selected.data(), 0xff, bit_vector_bytes);\n+    for (size_t ifilter = 0; ifilter < eval_.num_expected_bloom_filters_; ifilter++) {\n+      std::vector<Datum> keys(eval_.received_maps_[ifilter].size());\n+      for (size_t i = 0; i < keys.size(); i++) {\n+        int input_idx = eval_.received_maps_[ifilter][i];\n+        keys[i] = batch[input_idx];\n+        if (keys[i].is_scalar()) {\n+          ARROW_ASSIGN_OR_RAISE(\n+              keys[i],\n+              MakeArrayFromScalar(*keys[i].scalar(), batch.length, ctx_->memory_pool()));\n+        }\n+      }\n+      ARROW_ASSIGN_OR_RAISE(ExecBatch key_batch, ExecBatch::Make(std::move(keys)));\n+      RETURN_NOT_OK(Hashing32::HashBatch(key_batch, hashes.data(),\n+                                         ctx_->cpu_info()->hardware_flags(), stack, 0,\n+                                         key_batch.length));\n+\n+      eval_.received_filters_[ifilter]->Find(ctx_->cpu_info()->hardware_flags(),\n+                                             key_batch.length, hashes.data(), bv.data());\n+      arrow::internal::BitmapAnd(bv.data(), 0, selected.data(), 0, key_batch.length, 0,\n+                                 selected.data());\n+    }\n+    auto selected_buffer =\n+        arrow::internal::make_unique<Buffer>(selected.data(), bit_vector_bytes);\n+    ArrayData selected_arraydata(boolean(), batch.length,\n+                                 {nullptr, std::move(selected_buffer)});\n+    Datum selected_datum(selected_arraydata);\n+    FilterOptions options;\n+    size_t first_nonscalar = batch.values.size();\n+    for (size_t i = 0; i < batch.values.size(); i++) {\n+      if (!batch.values[i].is_scalar()) {\n+        ARROW_ASSIGN_OR_RAISE(batch.values[i],\n+                              Filter(batch.values[i], selected_datum, options, ctx_));\n+        first_nonscalar = std::min(first_nonscalar, i);\n+        ARROW_DCHECK_EQ(batch.values[i].length(), batch.values[first_nonscalar].length());\n+      }\n+    }\n+    // If they're all Scalar, then the length of the batch is the number of set bits\n+    if (first_nonscalar == batch.values.size())\n+      batch.length = arrow::internal::CountSetBits(selected.data(), 0, batch.length);\n+    else\n+      batch.length = batch.values[first_nonscalar].length();\n+    return Status::OK();\n+  }\n+\n+  Status BuildBloomFilter_exec_task(size_t thread_index, int64_t task_id);\n+\n+  Status BuildBloomFilter_on_finished(size_t thread_index) {\n+    return build_.on_finished_(thread_index, std::move(build_.batches_));\n+  }\n+\n+  // The Bloom filter is built on the build side of some upstream join. For a join to\n+  // evaluate the Bloom filter on its input columns, it has to rearrange its input columns\n+  // to match the column order of the Bloom filter.\n+  //\n+  // The first part of the pair is the HashJoin to actually perform the pushdown into.\n+  // The second part is a mapping such that column_map[i] is the index of key i in\n+  // the first part's input.\n+  // If we should disable Bloom filter, returns nullptr and an empty vector, and sets\n+  // the disable_bloom_filter_ flag.\n+  std::pair<HashJoinNode*, std::vector<int>> GetPushdownTarget(HashJoinNode* start);\n+\n+  Result<util::TempVectorStack*> GetStack(size_t thread_index) {\n+    if (!tld_[thread_index].is_init) {\n+      RETURN_NOT_OK(tld_[thread_index].stack.Init(\n+          ctx_->memory_pool(), 4 * util::MiniBatch::kMiniBatchLength * sizeof(uint32_t)));\n+      tld_[thread_index].is_init = true;\n+    }\n+    return &tld_[thread_index].stack;\n+  }\n+\n+  bool disable_bloom_filter_;\n+  HashJoinNode* owner_;\n\nReview Comment:\n   I also use `owner` to figure out the start point of the pushdown search and also for the ExecContext. That said, that's only needed inside of `Init`, so I've changed the member to just be a `HashJoinSchema`, but `Init` will still need the owner. \n\n\n\n",
                    "created": "2022-06-08T18:58:59.494+0000",
                    "updated": "2022-06-08T18:58:59.494+0000",
                    "started": "2022-06-08T18:58:59.493+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779626",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779627",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892758053\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n+    return Status::OK();\n+  }\n+\n+  Status OnBuildSideFinished(size_t thread_index) {\n+    return pushdown_context_.BuildBloomFilter(\n+        thread_index, std::move(accumulators_[1]),\n+        [this](size_t thread_index, AccumulationQueue batches) {\n+          return OnBloomFilterFinished(thread_index, std::move(batches));\n+        });\n+  }\n+\n+  Status OnBloomFilterFinished(size_t thread_index, AccumulationQueue batches) {\n+    RETURN_NOT_OK(pushdown_context_.PushBloomFilter());\n+    return impl_->BuildHashTable(\n+        thread_index, std::move(batches),\n+        [this](size_t thread_index) { return OnHashTableFinished(thread_index); });\n+  }\n+\n+  Status OnHashTableFinished(size_t thread_index) {\n+    bool should_probe;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_probe = queued_batches_filtered_ && !hash_table_ready_;\n+      hash_table_ready_ = true;\n+    }\n+    if (should_probe) {\n+      return ProbeQueuedBatches(thread_index);\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status OnProbeSideBatch(size_t thread_index, ExecBatch batch) {\n+    bool should_filter;\n+    bool should_accum;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_filter = bloom_filters_ready_;\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) {\n+        accumulators_[0].InsertBatch(std::move(batch));\n+        return Status::OK();\n+      }\n+    }\n+    if (should_filter)\n\nReview Comment:\n   Good point, fixed it. \n\n\n\n",
                    "created": "2022-06-08T19:01:54.724+0000",
                    "updated": "2022-06-08T19:01:54.724+0000",
                    "started": "2022-06-08T19:01:54.723+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779627",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779628",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892758327\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n+    return Status::OK();\n+  }\n+\n+  Status OnBuildSideFinished(size_t thread_index) {\n+    return pushdown_context_.BuildBloomFilter(\n+        thread_index, std::move(accumulators_[1]),\n+        [this](size_t thread_index, AccumulationQueue batches) {\n+          return OnBloomFilterFinished(thread_index, std::move(batches));\n+        });\n+  }\n+\n+  Status OnBloomFilterFinished(size_t thread_index, AccumulationQueue batches) {\n+    RETURN_NOT_OK(pushdown_context_.PushBloomFilter());\n+    return impl_->BuildHashTable(\n+        thread_index, std::move(batches),\n+        [this](size_t thread_index) { return OnHashTableFinished(thread_index); });\n+  }\n+\n+  Status OnHashTableFinished(size_t thread_index) {\n+    bool should_probe;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_probe = queued_batches_filtered_ && !hash_table_ready_;\n+      hash_table_ready_ = true;\n+    }\n+    if (should_probe) {\n+      return ProbeQueuedBatches(thread_index);\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status OnProbeSideBatch(size_t thread_index, ExecBatch batch) {\n+    bool should_filter;\n+    bool should_accum;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_filter = bloom_filters_ready_;\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) {\n+        accumulators_[0].InsertBatch(std::move(batch));\n+        return Status::OK();\n+      }\n+    }\n+    if (should_filter)\n+      RETURN_NOT_OK(pushdown_context_.FilterSingleBatch(thread_index, batch));\n+\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) accumulators_[0].InsertBatch(std::move(batch));\n\nReview Comment:\n   Yep, good point\n\n\n\n",
                    "created": "2022-06-08T19:02:14.749+0000",
                    "updated": "2022-06-08T19:02:14.749+0000",
                    "started": "2022-06-08T19:02:14.749+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779628",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779629",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892759134\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n+    return Status::OK();\n+  }\n+\n+  Status OnBuildSideFinished(size_t thread_index) {\n+    return pushdown_context_.BuildBloomFilter(\n+        thread_index, std::move(accumulators_[1]),\n+        [this](size_t thread_index, AccumulationQueue batches) {\n+          return OnBloomFilterFinished(thread_index, std::move(batches));\n+        });\n+  }\n+\n+  Status OnBloomFilterFinished(size_t thread_index, AccumulationQueue batches) {\n+    RETURN_NOT_OK(pushdown_context_.PushBloomFilter());\n+    return impl_->BuildHashTable(\n+        thread_index, std::move(batches),\n+        [this](size_t thread_index) { return OnHashTableFinished(thread_index); });\n+  }\n+\n+  Status OnHashTableFinished(size_t thread_index) {\n+    bool should_probe;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_probe = queued_batches_filtered_ && !hash_table_ready_;\n+      hash_table_ready_ = true;\n+    }\n+    if (should_probe) {\n+      return ProbeQueuedBatches(thread_index);\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status OnProbeSideBatch(size_t thread_index, ExecBatch batch) {\n+    bool should_filter;\n+    bool should_accum;\n+    {\n+      std::lock_guard<std::mutex> guard(probe_side_mutex_);\n+      should_filter = bloom_filters_ready_;\n+      should_accum = !should_filter || !hash_table_ready_;\n+      if (should_accum) {\n\nReview Comment:\n   Yep, I think I've simplified this section to be correct.\n\n\n\n",
                    "created": "2022-06-08T19:03:19.818+0000",
                    "updated": "2022-06-08T19:03:19.818+0000",
                    "started": "2022-06-08T19:03:19.818+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779629",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779631",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892760948\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -516,6 +684,125 @@ class HashJoinNode : public ExecNode {\n \n   const char* kind_name() const override { return \"HashJoinNode\"; }\n \n+  Status OnBuildSideBatch(size_t thread_index, ExecBatch batch) {\n+    std::lock_guard<std::mutex> guard(build_side_mutex_);\n+    accumulators_[1].InsertBatch(std::move(batch));\n\nReview Comment:\n   Done\n\n\n\n",
                    "created": "2022-06-08T19:05:01.830+0000",
                    "updated": "2022-06-08T19:05:01.830+0000",
                    "started": "2022-06-08T19:05:01.830+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779631",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779632",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892762033\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n+    }\n+    if (proceed) {\n+      return push_.all_received_callback_();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FilterBatches(size_t thread_index, AccumulationQueue batches,\n+                       FilterFinishedCallback on_finished) {\n+    eval_.batches_ = std::move(batches);\n+    eval_.on_finished_ = std::move(on_finished);\n+\n+    if (eval_.num_expected_bloom_filters_ == 0)\n+      return eval_.on_finished_(thread_index, std::move(eval_.batches_));\n+\n+    return scheduler_->StartTaskGroup(thread_index, eval_.task_id_,\n+                                      /*num_tasks=*/eval_.batches_.batch_count());\n+  }\n+\n+  Status FilterSingleBatch(size_t thread_index, ExecBatch& batch) {\n+    if (disable_bloom_filter_ || batch.length == 0) return Status::OK();\n+    int64_t bit_vector_bytes = bit_util::BytesForBits(batch.length);\n+    std::vector<uint8_t> selected(bit_vector_bytes);\n+    std::vector<uint32_t> hashes(batch.length);\n+    std::vector<uint8_t> bv(bit_vector_bytes);\n+\n+    ARROW_ASSIGN_OR_RAISE(util::TempVectorStack * stack, GetStack(thread_index));\n+\n+    // Start with full selection for the current batch\n+    memset(selected.data(), 0xff, bit_vector_bytes);\n+    for (size_t ifilter = 0; ifilter < eval_.num_expected_bloom_filters_; ifilter++) {\n+      std::vector<Datum> keys(eval_.received_maps_[ifilter].size());\n+      for (size_t i = 0; i < keys.size(); i++) {\n+        int input_idx = eval_.received_maps_[ifilter][i];\n+        keys[i] = batch[input_idx];\n+        if (keys[i].is_scalar()) {\n+          ARROW_ASSIGN_OR_RAISE(\n+              keys[i],\n+              MakeArrayFromScalar(*keys[i].scalar(), batch.length, ctx_->memory_pool()));\n+        }\n+      }\n+      ARROW_ASSIGN_OR_RAISE(ExecBatch key_batch, ExecBatch::Make(std::move(keys)));\n+      RETURN_NOT_OK(Hashing32::HashBatch(key_batch, hashes.data(),\n+                                         ctx_->cpu_info()->hardware_flags(), stack, 0,\n+                                         key_batch.length));\n+\n+      eval_.received_filters_[ifilter]->Find(ctx_->cpu_info()->hardware_flags(),\n+                                             key_batch.length, hashes.data(), bv.data());\n+      arrow::internal::BitmapAnd(bv.data(), 0, selected.data(), 0, key_batch.length, 0,\n+                                 selected.data());\n+    }\n+    auto selected_buffer =\n+        arrow::internal::make_unique<Buffer>(selected.data(), bit_vector_bytes);\n+    ArrayData selected_arraydata(boolean(), batch.length,\n+                                 {nullptr, std::move(selected_buffer)});\n+    Datum selected_datum(selected_arraydata);\n+    FilterOptions options;\n+    size_t first_nonscalar = batch.values.size();\n+    for (size_t i = 0; i < batch.values.size(); i++) {\n+      if (!batch.values[i].is_scalar()) {\n+        ARROW_ASSIGN_OR_RAISE(batch.values[i],\n+                              Filter(batch.values[i], selected_datum, options, ctx_));\n+        first_nonscalar = std::min(first_nonscalar, i);\n+        ARROW_DCHECK_EQ(batch.values[i].length(), batch.values[first_nonscalar].length());\n+      }\n+    }\n+    // If they're all Scalar, then the length of the batch is the number of set bits\n+    if (first_nonscalar == batch.values.size())\n+      batch.length = arrow::internal::CountSetBits(selected.data(), 0, batch.length);\n+    else\n+      batch.length = batch.values[first_nonscalar].length();\n+    return Status::OK();\n+  }\n+\n+  Status BuildBloomFilter_exec_task(size_t thread_index, int64_t task_id);\n+\n+  Status BuildBloomFilter_on_finished(size_t thread_index) {\n+    return build_.on_finished_(thread_index, std::move(build_.batches_));\n+  }\n+\n+  // The Bloom filter is built on the build side of some upstream join. For a join to\n+  // evaluate the Bloom filter on its input columns, it has to rearrange its input columns\n+  // to match the column order of the Bloom filter.\n+  //\n+  // The first part of the pair is the HashJoin to actually perform the pushdown into.\n+  // The second part is a mapping such that column_map[i] is the index of key i in\n+  // the first part's input.\n+  // If we should disable Bloom filter, returns nullptr and an empty vector, and sets\n+  // the disable_bloom_filter_ flag.\n+  std::pair<HashJoinNode*, std::vector<int>> GetPushdownTarget(HashJoinNode* start);\n+\n+  Result<util::TempVectorStack*> GetStack(size_t thread_index) {\n+    if (!tld_[thread_index].is_init) {\n+      RETURN_NOT_OK(tld_[thread_index].stack.Init(\n+          ctx_->memory_pool(), 4 * util::MiniBatch::kMiniBatchLength * sizeof(uint32_t)));\n+      tld_[thread_index].is_init = true;\n+    }\n+    return &tld_[thread_index].stack;\n+  }\n+\n+  bool disable_bloom_filter_;\n+  HashJoinNode* owner_;\n+  ExecContext* ctx_;\n+  TaskScheduler* scheduler_;\n+\n+  struct ThreadLocalData {\n+    bool is_init = false;\n+    util::TempVectorStack stack;\n+  };\n+  std::vector<ThreadLocalData> tld_;\n+\n+  struct {\n+    int task_id_;\n+    std::unique_ptr<BloomFilterBuilder> builder_;\n+    AccumulationQueue batches_;\n+    BuildFinishedCallback on_finished_;\n+  } build_;\n+\n+  struct {\n+    std::unique_ptr<BlockedBloomFilter> bloom_filter_;\n+    HashJoinNode* pushdown_target_;\n+    std::vector<int> column_map_;\n+    FiltersReceivedCallback all_received_callback_;\n\nReview Comment:\n   I agree, it belongs on the receiver not the pusher. I've moved it.\n\n\n\n",
                    "created": "2022-06-08T19:06:20.163+0000",
                    "updated": "2022-06-08T19:06:20.163+0000",
                    "started": "2022-06-08T19:06:20.163+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779632",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779633",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892764291\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n+    bool proceed;\n+    {\n+      std::lock_guard<std::mutex> guard(eval_.receive_mutex_);\n+      eval_.received_filters_.emplace_back(std::move(filter));\n+      eval_.received_maps_.emplace_back(std::move(column_map));\n+      proceed = eval_.num_expected_bloom_filters_ == eval_.received_filters_.size();\n+\n+      ARROW_DCHECK(eval_.received_filters_.size() == eval_.received_maps_.size());\n+      ARROW_DCHECK(eval_.received_filters_.size() <= eval_.num_expected_bloom_filters_);\n+    }\n+    if (proceed) {\n+      return push_.all_received_callback_();\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FilterBatches(size_t thread_index, AccumulationQueue batches,\n+                       FilterFinishedCallback on_finished) {\n+    eval_.batches_ = std::move(batches);\n+    eval_.on_finished_ = std::move(on_finished);\n+\n+    if (eval_.num_expected_bloom_filters_ == 0)\n\nReview Comment:\n   Actually I think `FilterSingleBatch` should be checking `num_expected_bloom_filters_` not `disable_bloom_filter_`. Disabling bloom filter disables building it, not receiving it. \n\n\n\n",
                    "created": "2022-06-08T19:09:20.361+0000",
                    "updated": "2022-06-08T19:09:20.361+0000",
                    "started": "2022-06-08T19:09:20.360+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779633",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779634",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892765212\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n\nReview Comment:\n   The things that need to access `HashJoinNode` need to be defined below `HashJoinNode`'s definition.\n\n\n\n",
                    "created": "2022-06-08T19:10:25.426+0000",
                    "updated": "2022-06-08T19:10:25.426+0000",
                    "started": "2022-06-08T19:10:25.425+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779634",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779635",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892765505\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join.cc:\n##########\n@@ -1105,16 +745,15 @@ class HashJoinBasicImpl : public HashJoinImpl {\n   HashJoinSchema* schema_mgr_;\n   std::vector<JoinKeyCmp> key_cmp_;\n   Expression filter_;\n-  std::unique_ptr<TaskScheduler> scheduler_;\n-  int task_group_bloom_;\n+  TaskScheduler* scheduler_;\n   int task_group_build_;\n-  int task_group_bloom_filter_queued_;\n-  int task_group_queued_;\n   int task_group_scan_;\n \n   // Callbacks\n   //\n   OutputBatchCallback output_batch_callback_;\n+  BuildFinishedCallback build_finished_callback_;\n+  ProbeFinishedCallback probe_finished_callback_;\n\nReview Comment:\n   Nope, removed.\n\n\n\n",
                    "created": "2022-06-08T19:10:50.456+0000",
                    "updated": "2022-06-08T19:10:50.456+0000",
                    "started": "2022-06-08T19:10:50.456+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779635",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779636",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892765981\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join.cc:\n##########\n@@ -789,159 +603,30 @@ class HashJoinBasicImpl : public HashJoinImpl {\n     return Status::OK();\n   }\n \n-  Status BuildBloomFilter_on_finished(size_t thread_index) {\n-    if (cancelled_) return Status::Cancelled(\"Hash join cancelled\");\n-    ARROW_DCHECK(pushdown_target_);\n-    RETURN_NOT_OK(pushdown_target_->PushBloomFilter(\n-        thread_index, std::move(bloom_filter_), std::move(column_map_)));\n-    return BuildHashTable(thread_index);\n-  }\n-\n   Status BuildHashTable_on_finished(size_t thread_index) {\n-    if (cancelled_) {\n-      return Status::Cancelled(\"Hash join cancelled\");\n-    }\n-\n-    right_batches_.clear();\n-\n-    bool proceed;\n-    {\n-      std::lock_guard<std::mutex> lock(left_batches_mutex_);\n-      std::lock_guard<std::mutex> lock_finish(finished_mutex_);\n-      left_queue_bloom_finished_ =\n-          left_queue_bloom_finished_ || num_expected_bloom_filters_ == 0;\n-      proceed = !has_hash_table_ && left_queue_bloom_finished_;\n-      has_hash_table_ = true;\n-    }\n-    if (proceed) RETURN_NOT_OK(ProbeQueuedBatches(thread_index));\n-\n-    return Status::OK();\n-  }\n-\n-  void RegisterBuildBloomFilter() {\n-    task_group_bloom_ = scheduler_->RegisterTaskGroup(\n-        [this](size_t thread_index, int64_t task_id) -> Status {\n-          return BuildBloomFilter_exec_task(thread_index, task_id);\n-        },\n-        [this](size_t thread_index) -> Status {\n-          return BuildBloomFilter_on_finished(thread_index);\n-        });\n-  }\n-\n-  void RegisterBuildHashTable() {\n-    task_group_build_ = scheduler_->RegisterTaskGroup(\n-        [this](size_t thread_index, int64_t task_id) -> Status {\n-          return BuildHashTable_exec_task(thread_index, task_id);\n-        },\n-        [this](size_t thread_index) -> Status {\n-          return BuildHashTable_on_finished(thread_index);\n-        });\n+    build_batches_.Clear();\n\nReview Comment:\n   Done\n\n\n\n",
                    "created": "2022-06-08T19:11:30.466+0000",
                    "updated": "2022-06-08T19:11:30.466+0000",
                    "started": "2022-06-08T19:11:30.465+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779636",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779638",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r892773105\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_node.cc:\n##########\n@@ -454,6 +456,172 @@ Status HashJoinSchema::CollectFilterColumns(std::vector<FieldRef>& left_filter,\n   return Status::OK();\n }\n \n+class HashJoinNode;\n+\n+struct BloomFilterPushdownContext {\n+  using BuildFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  using FiltersReceivedCallback = std::function<Status()>;\n+  using FilterFinishedCallback = std::function<Status(size_t, AccumulationQueue)>;\n+  void Init(HashJoinNode* owner, size_t num_threads, TaskScheduler* scheduler,\n+            FiltersReceivedCallback on_bloom_filters_received, bool disable_bloom_filter,\n+            bool use_sync_execution);\n+\n+  Status StartProducing();\n+\n+  void ExpectBloomFilter() { eval_.num_expected_bloom_filters_ += 1; }\n+\n+  Status BuildBloomFilter(size_t thread_index, AccumulationQueue batches,\n+                          BuildFinishedCallback on_finished);\n+\n+  Status PushBloomFilter();\n+\n+  Status ReceiveBloomFilter(std::unique_ptr<BlockedBloomFilter> filter,\n+                            std::vector<int> column_map) {\n\nReview Comment:\n   Added a comment.\n\n\n\n",
                    "created": "2022-06-08T19:20:41.267+0000",
                    "updated": "2022-06-08T19:20:41.267+0000",
                    "started": "2022-06-08T19:20:41.267+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779638",
                    "issueId": "13447976"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/worklog/779870",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on code in PR #13332:\nURL: https://github.com/apache/arrow/pull/13332#discussion_r893354156\n\n\n##########\ncpp/src/arrow/compute/exec/accumulation_queue.h:\n##########\n@@ -0,0 +1,54 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/compute/exec.h\"\n+\n+namespace arrow {\n+namespace util {\n+using arrow::compute::ExecBatch;\n+class AccumulationQueue {\n+ public:\n+  AccumulationQueue() : row_count_(0) {}\n+  ~AccumulationQueue() = default;\n+\n+  // We should never be copying ExecBatch around\n+  AccumulationQueue(const AccumulationQueue&) = delete;\n+  AccumulationQueue& operator=(const AccumulationQueue&) = delete;\n+\n+  AccumulationQueue(AccumulationQueue&& that);\n+  AccumulationQueue& operator=(AccumulationQueue&& that);\n+\n+  void Append(AccumulationQueue&& that);\n\nReview Comment:\n   Minor nit: `Append` makes me think of python's append (i.e. inserting one item).  It would be nice to have a name that quickly encapsulated both the fact that we are operating on a range and moving the items.  Maybe `TransferRange`?\n\n\n\n##########\ncpp/src/arrow/compute/exec/accumulation_queue.h:\n##########\n@@ -0,0 +1,54 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/compute/exec.h\"\n+\n+namespace arrow {\n+namespace util {\n+using arrow::compute::ExecBatch;\n+class AccumulationQueue {\n+ public:\n+  AccumulationQueue() : row_count_(0) {}\n+  ~AccumulationQueue() = default;\n+\n+  // We should never be copying ExecBatch around\n+  AccumulationQueue(const AccumulationQueue&) = delete;\n+  AccumulationQueue& operator=(const AccumulationQueue&) = delete;\n+\n+  AccumulationQueue(AccumulationQueue&& that);\n+  AccumulationQueue& operator=(AccumulationQueue&& that);\n+\n+  void Append(AccumulationQueue&& that);\n+  void InsertBatch(ExecBatch batch);\n+  int64_t row_count() { return row_count_; }\n+  size_t batch_count() { return batches_.size(); }\n\nReview Comment:\n   It would be nice to get some consistency with how we use `int64_t`, `uint64_t`, and `size_t` within the engine.  Do you have any convention suggestions?\n\n\n\n##########\ncpp/src/arrow/compute/exec/accumulation_queue.h:\n##########\n@@ -0,0 +1,54 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/compute/exec.h\"\n+\n+namespace arrow {\n+namespace util {\n+using arrow::compute::ExecBatch;\n+class AccumulationQueue {\n\nReview Comment:\n   ```suggestion\r\n   /// \\brief A container that accumulates batches until they are ready to\r\n   ///    be processed\r\n   class AccumulationQueue {\r\n   ```\n\n\n\n##########\ncpp/src/arrow/compute/exec/hash_join_benchmark.cc:\n##########\n@@ -124,67 +128,60 @@ class JoinBenchmark {\n \n     schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n     Expression filter = literal(true);\n-    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n-                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_with_schema.schema,\n+                                left_keys, *r_batches_with_schema.schema, right_keys,\n+                                filter, \"l_\", \"r_\"));\n \n     join_ = *HashJoinImpl::MakeBasic();\n \n-    HashJoinImpl* bloom_filter_pushdown_target = nullptr;\n-    std::vector<int> key_input_map;\n-\n-    bool bloom_filter_does_not_apply_to_join =\n-        settings.join_type == JoinType::LEFT_ANTI ||\n-        settings.join_type == JoinType::LEFT_OUTER ||\n-        settings.join_type == JoinType::FULL_OUTER;\n-    if (settings.bloom_filter && !bloom_filter_does_not_apply_to_join) {\n-      bloom_filter_pushdown_target = join_.get();\n-      SchemaProjectionMap probe_key_to_input = schema_mgr_->proj_maps[0].map(\n-          HashJoinProjection::KEY, HashJoinProjection::INPUT);\n-      int num_keys = probe_key_to_input.num_cols;\n-      for (int i = 0; i < num_keys; i++)\n-        key_input_map.push_back(probe_key_to_input.get(i));\n-    }\n-\n     omp_set_num_threads(settings.num_threads);\n     auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n #pragma omp task\n       { DCHECK_OK(func(omp_get_thread_num())); }\n       return Status::OK();\n     };\n \n+    scheduler_ = TaskScheduler::Make();\n     DCHECK_OK(join_->Init(\n-        ctx_.get(), settings.join_type, !is_parallel, settings.num_threads,\n-        schema_mgr_.get(), std::move(key_cmp), std::move(filter), [](ExecBatch) {},\n-        [](int64_t x) {}, schedule_callback, bloom_filter_pushdown_target,\n-        std::move(key_input_map)));\n+        ctx_.get(), settings.join_type, settings.num_threads, schema_mgr_.get(),\n+        std::move(key_cmp), std::move(filter), [](ExecBatch) {}, [](int64_t x) {},\n+        scheduler_.get()));\n+\n+    task_group_probe_ = scheduler_->RegisterTaskGroup(\n+        [this](size_t thread_index, int64_t task_id) -> Status {\n+          return join_->ProbeSingleBatch(thread_index, std::move(l_batches_[task_id]));\n+        },\n+        [this](size_t thread_index) -> Status {\n+          return join_->ProbingFinished(thread_index);\n+        });\n+\n+    scheduler_->RegisterEnd();\n+\n+    DCHECK_OK(scheduler_->StartScheduling(\n+        0 /*thread index*/, std::move(schedule_callback),\n+        static_cast<int>(2 * settings.num_threads) /*concurrent tasks*/, !is_parallel));\n   }\n \n   void RunJoin() {\n #pragma omp parallel\n     {\n       int tid = omp_get_thread_num();\n-#pragma omp for nowait\n-      for (auto it = r_batches_.batches.begin(); it != r_batches_.batches.end(); ++it)\n-        DCHECK_OK(join_->InputReceived(tid, /*side=*/1, *it));\n-#pragma omp for nowait\n-      for (auto it = l_batches_.batches.begin(); it != l_batches_.batches.end(); ++it)\n-        DCHECK_OK(join_->InputReceived(tid, /*side=*/0, *it));\n-\n-#pragma omp barrier\n-\n-#pragma omp single nowait\n-      { DCHECK_OK(join_->InputFinished(tid, /*side=*/1)); }\n-\n-#pragma omp single nowait\n-      { DCHECK_OK(join_->InputFinished(tid, /*side=*/0)); }\n+#pragma omp single\n\nReview Comment:\n   Is OpenMP still being used here if you have a `single` inside of a `parallel` and nothing else?\n\n\n\n",
                    "created": "2022-06-09T10:53:23.915+0000",
                    "updated": "2022-06-09T10:53:23.915+0000",
                    "started": "2022-06-09T10:53:23.915+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "779870",
                    "issueId": "13447976"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 16200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@22cc5c3b[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@52b2b2dd[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5950af70[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@1eb3cadd[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5980d350[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@28e38f5d[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@74949e1e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@74f14773[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2bb400ee[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@1f99fba2[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4fade221[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@3199ee78[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 16200,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Jun 16 22:27:05 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-06-16T22:27:05.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16713/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2022-06-01T16:06:18.000+0000",
        "updated": "2022-06-16T22:27:05.000+0000",
        "timeoriginalestimate": null,
        "description": "This is part of the preparatory refactoring for spilling (ARROW-16389)\r\n\r\n\u00a0",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "4.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 16200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Pull join accumulation outside of HashJoinImpl",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13447976/comment/17555318",
                    "id": "17555318",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 13332\n[https://github.com/apache/arrow/pull/13332]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-06-16T22:27:05.987+0000",
                    "updated": "2022-06-16T22:27:05.987+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z12vmg:",
        "customfield_12314139": null
    }
}