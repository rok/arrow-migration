{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13372456",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456",
    "key": "ARROW-12386",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12349983",
                "id": "12349983",
                "description": "",
                "name": "5.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-07-28"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
            "name": "westonpace",
            "key": "westonpace",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Weston Pace",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
            "name": "westonpace",
            "key": "westonpace",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Weston Pace",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
            "name": "westonpace",
            "key": "westonpace",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Weston Pace",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "aggregateprogress": {
            "progress": 7800,
            "total": 7800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 7800,
            "total": 7800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12386/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 13,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/585273",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#issuecomment-822640874\n\n\n   https://issues.apache.org/jira/browse/ARROW-12386\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-19T17:22:51.114+0000",
                    "updated": "2021-04-19T17:22:51.114+0000",
                    "started": "2021-04-19T17:22:51.114+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "585273",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/587833",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619189262\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner.cc\n##########\n@@ -480,13 +492,24 @@ Result<std::shared_ptr<Table>> AsyncScanner::ToTable() {\n   return table_fut.result();\n }\n \n+Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync() {\n+  return ScanBatchesUnorderedAsync(internal::GetCpuThreadPool());\n+}\n+\n Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync(\n     internal::Executor* cpu_executor) {\n   auto self = shared_from_this();\n   ARROW_ASSIGN_OR_RAISE(auto fragment_gen, GetFragments());\n   ARROW_ASSIGN_OR_RAISE(auto batch_gen_gen,\n                         FragmentsToBatches(self, std::move(fragment_gen)));\n-  return MakeConcatenatedGenerator(std::move(batch_gen_gen));\n+  auto batch_gen_gen_readahead = MakeSerialReadaheadGenerator(\n+      std::move(batch_gen_gen), scan_options_->fragment_readahead);\n+  return MakeMergedGenerator(std::move(batch_gen_gen_readahead),\n+                             scan_options_->fragment_readahead);\n+}\n\nReview comment:\n       So here we're teeing up at most `fragment_readahead` active fragments, of which we can queue up to `fragment_readahead` batches? And the net effect is that we read from each fragment in parallel.\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -115,7 +116,7 @@ class TestScanner : public DatasetFixtureMixinWithParam<TestScannerParams> {\n \n     AssertScanBatchesUnorderedEquals(expected.get(), scanner.get(), 1);\n   }\n-};\n+};  // namespace dataset\n\nReview comment:\n       I'm not sure what happened here - clang-format added this to the class declaration?\r\n   \r\n   (N.B. How are you using clang-format? I don't think it does this to me.)\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+            }\n+          }\n+        }\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  struct FragmentStats {\n+    int last_index;\n+    bool seen;\n+  };\n+\n+  std::vector<FragmentStats> GetFragmentStats(const std::vector<int>& order) {\n+    auto last_indices = GetLastIndices(order);\n+    std::vector<FragmentStats> fragment_stats;\n+    for (std::size_t i = 0; i < last_indices.size(); i++) {\n+      fragment_stats.push_back({last_indices[i], false});\n+    }\n+    return fragment_stats;\n+  }\n+\n+  /// When data arrives out of order then we first have to buffer up 1 item in order to\n+  /// know when the last item has arrived (so we can mark it as the last).  This means\n+  /// sometimes we deliver an item and don't get one (first in a fragment) and sometimes\n+  /// we deliver an item and we end up getting two (last in a fragment)\n+  std::vector<EnumeratedRecordBatch> DeliverAndCollect(\n+      std::vector<int> order, EnumeratedRecordBatchGenerator gen) {\n+    std::vector<EnumeratedRecordBatch> collected;\n+    auto fragment_stats = GetFragmentStats(order);\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      if (static_cast<int>(i) == fragment_stats[fragment_index].last_index) {\n+        dataset_->FinishFragment(fragment_index);\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+      if (!fragment_stats[fragment_index].seen) {\n+        fragment_stats[fragment_index].seen = true;\n+      } else {\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  std::shared_ptr<Scanner> MakeScanner(int fragment_readahead = 0) {\n+    ScannerBuilder builder(dataset_);\n+    // Reordering tests only make sense for async\n+    builder.UseAsync(true);\n+    if (fragment_readahead != 0) {\n+      builder.FragmentReadahead(fragment_readahead);\n+    }\n+    EXPECT_OK_AND_ASSIGN(auto scanner, builder.Finish());\n+    return scanner;\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<TaggedRecordBatch>& batches,\n+                            std::vector<int> expected_order) {\n+    ASSERT_EQ(expected_order.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_order[i], batches[i].record_batch->num_rows());\n+    }\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<EnumeratedRecordBatch>& batches,\n+                            std::vector<int> expected_batch_indices,\n+                            std::vector<int> expected_row_sizes) {\n+    ASSERT_EQ(expected_batch_indices.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_row_sizes[i], batches[i].record_batch.value->num_rows());\n+      ASSERT_EQ(expected_batch_indices[i], batches[i].record_batch.index);\n+    }\n+  }\n+\n+  std::shared_ptr<ControlledDataset> dataset_;\n+};\n+\n+TEST_F(TestReordering, ScanBatches) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 1, 4, 2, 3});\n+}\n+\n+TEST_F(TestReordering, ScanBatchesUnordered) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 0, 1, 1, 2}, {0, 2, 3, 1, 4});\n+}\n+\n+struct BatchConsumer {\n+  explicit BatchConsumer(EnumeratedRecordBatchGenerator generator)\n+      : generator(generator), next() {}\n+\n+  void AssertCanConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK(next);\n+    next = Future<EnumeratedRecordBatch>();\n+  }\n+\n+  void AssertCannotConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    SleepABit();\n+    ASSERT_FALSE(next.is_finished());\n+  }\n+\n+  void AssertFinished() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK_AND_ASSIGN(auto last, next);\n+    ASSERT_TRUE(IsIterationEnd(last));\n+  }\n+\n+  EnumeratedRecordBatchGenerator generator;\n+  Future<EnumeratedRecordBatch> next;\n+};\n+\n+TEST_F(TestReordering, FileReadahead) {\n+  auto scanner = MakeScanner(1);\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  BatchConsumer consumer(std::move(batch_gen));\n+  dataset_->DeliverBatch(0, 0);\n+  dataset_->DeliverBatch(0, 1);\n+  consumer.AssertCanConsume();\n+  consumer.AssertCannotConsume();\n+  dataset_->DeliverBatch(1, 0);\n+  consumer.AssertCannotConsume();\n+  dataset_->FinishFragment(1);\n\nReview comment:\n       Since this is an unordered scan, why can't we deliver the last batch for fragment 1 at this point?\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n\nReview comment:\n       (This is all to check my understanding, this is somewhat tricky\u2026)\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n\nReview comment:\n       nit: bonus record batch?\r\n   also nit: as explained below, this is because of the buffering?\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n\nReview comment:\n       So `seen_fragment` is basically, 'have we delivered a batch to this fragment before' (since we can only expect to pull a batch on the 2nd delivery)?\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n\nReview comment:\n       Ah though the usage below makes it clearer.\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n\nReview comment:\n       I had to read this a few times to figure out what was going on. Given a vector which maps the Nth batch delivered to the Kth fragment, we get a vector mapping each fragment to the index of the last batch it delivered?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T13:15:13.827+0000",
                    "updated": "2021-04-23T13:15:13.827+0000",
                    "started": "2021-04-23T13:15:13.826+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587833",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588118",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619474881\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner.cc\n##########\n@@ -480,13 +492,24 @@ Result<std::shared_ptr<Table>> AsyncScanner::ToTable() {\n   return table_fut.result();\n }\n \n+Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync() {\n+  return ScanBatchesUnorderedAsync(internal::GetCpuThreadPool());\n+}\n+\n Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync(\n     internal::Executor* cpu_executor) {\n   auto self = shared_from_this();\n   ARROW_ASSIGN_OR_RAISE(auto fragment_gen, GetFragments());\n   ARROW_ASSIGN_OR_RAISE(auto batch_gen_gen,\n                         FragmentsToBatches(self, std::move(fragment_gen)));\n-  return MakeConcatenatedGenerator(std::move(batch_gen_gen));\n+  auto batch_gen_gen_readahead = MakeSerialReadaheadGenerator(\n+      std::move(batch_gen_gen), scan_options_->fragment_readahead);\n+  return MakeMergedGenerator(std::move(batch_gen_gen_readahead),\n+                             scan_options_->fragment_readahead);\n+}\n\nReview comment:\n       > So here we're teeing up at most fragment_readahead active fragments, of which we can queue up to fragment_readahead batches?\r\n   I don't know that I would phrase it that way.  The first part `we're teeing up at most fragment_readahead active fragments` is correct.  Each active fragment will queue 1 batch.  So across all active fragments there will be `fragment_readahead` queued batches.  However, there is not `fragment_readahead` batches per fragment.  I'm not sure which you were describing.\r\n   \r\n   The last sentence is correct assuming that both `batch_gen_gen` and the generated emitted by `batch_gen_gen` are truly asynchronous (e.g. they are calling `Executor::Submit` at some point).  The naive `FileFormat::ScanBatches` blocks and isn't truly asynchronous and so `MakeMergedGenerator` won't add parallelism.\n\n##########\nFile path: cpp/src/arrow/dataset/scanner.cc\n##########\n@@ -480,13 +492,24 @@ Result<std::shared_ptr<Table>> AsyncScanner::ToTable() {\n   return table_fut.result();\n }\n \n+Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync() {\n+  return ScanBatchesUnorderedAsync(internal::GetCpuThreadPool());\n+}\n+\n Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync(\n     internal::Executor* cpu_executor) {\n   auto self = shared_from_this();\n   ARROW_ASSIGN_OR_RAISE(auto fragment_gen, GetFragments());\n   ARROW_ASSIGN_OR_RAISE(auto batch_gen_gen,\n                         FragmentsToBatches(self, std::move(fragment_gen)));\n-  return MakeConcatenatedGenerator(std::move(batch_gen_gen));\n+  auto batch_gen_gen_readahead = MakeSerialReadaheadGenerator(\n+      std::move(batch_gen_gen), scan_options_->fragment_readahead);\n+  return MakeMergedGenerator(std::move(batch_gen_gen_readahead),\n+                             scan_options_->fragment_readahead);\n+}\n\nReview comment:\n       > So here we're teeing up at most fragment_readahead active fragments, of which we can queue up to fragment_readahead batches?\r\n   \r\n   I don't know that I would phrase it that way.  The first part `we're teeing up at most fragment_readahead active fragments` is correct.  Each active fragment will queue 1 batch.  So across all active fragments there will be `fragment_readahead` queued batches.  However, there is not `fragment_readahead` batches per fragment.  I'm not sure which you were describing.\r\n   \r\n   The last sentence is correct assuming that both `batch_gen_gen` and the generated emitted by `batch_gen_gen` are truly asynchronous (e.g. they are calling `Executor::Submit` at some point).  The naive `FileFormat::ScanBatches` blocks and isn't truly asynchronous and so `MakeMergedGenerator` won't add parallelism.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T20:19:57.118+0000",
                    "updated": "2021-04-23T20:19:57.118+0000",
                    "started": "2021-04-23T20:19:57.117+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588118",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588120",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619477344\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -115,7 +116,7 @@ class TestScanner : public DatasetFixtureMixinWithParam<TestScannerParams> {\n \n     AssertScanBatchesUnorderedEquals(expected.get(), scanner.get(), 1);\n   }\n-};\n+};  // namespace dataset\n\nReview comment:\n       I am using whatever version of clang-format ships with VSCode and it has format-on-save enabled.  This happens when I am in the middle of modifying some method and cutting/pasting code and end up (one way or another) with an extra closing brace.  E.g. I save with something like...\r\n   \r\n   ```\r\n   int foo() {\r\n     auto x = [] {}};\r\n   }\r\n   ```\r\n   \r\n   Then it seems that `clang-format` decides that final brace must be the closing brace for the namespace and so it adds the comment.  Later, when I fix the error and resave, it does not remove the namespace comment.\r\n   \r\n   I will investigate if a newer version of clang-format addresses this.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T20:25:14.081+0000",
                    "updated": "2021-04-23T20:25:14.081+0000",
                    "started": "2021-04-23T20:25:14.081+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588120",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588124",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619478106\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n\nReview comment:\n       Your interpretation is correct.  Later one, when we've delivered the last batch for the fragment, we also want to close the fragment (so it delivers an end-token on the iterator).\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T20:26:46.668+0000",
                    "updated": "2021-04-23T20:26:46.668+0000",
                    "started": "2021-04-23T20:26:46.667+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588124",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588131",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619478321\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -115,7 +116,7 @@ class TestScanner : public DatasetFixtureMixinWithParam<TestScannerParams> {\n \n     AssertScanBatchesUnorderedEquals(expected.get(), scanner.get(), 1);\n   }\n-};\n+};  // namespace dataset\n\nReview comment:\n       Interesting, FWIW I've only ever used the `format` target from our build scripts which doesn't have this issue.\n\n##########\nFile path: cpp/src/arrow/dataset/scanner.cc\n##########\n@@ -480,13 +492,24 @@ Result<std::shared_ptr<Table>> AsyncScanner::ToTable() {\n   return table_fut.result();\n }\n \n+Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync() {\n+  return ScanBatchesUnorderedAsync(internal::GetCpuThreadPool());\n+}\n+\n Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync(\n     internal::Executor* cpu_executor) {\n   auto self = shared_from_this();\n   ARROW_ASSIGN_OR_RAISE(auto fragment_gen, GetFragments());\n   ARROW_ASSIGN_OR_RAISE(auto batch_gen_gen,\n                         FragmentsToBatches(self, std::move(fragment_gen)));\n-  return MakeConcatenatedGenerator(std::move(batch_gen_gen));\n+  auto batch_gen_gen_readahead = MakeSerialReadaheadGenerator(\n+      std::move(batch_gen_gen), scan_options_->fragment_readahead);\n+  return MakeMergedGenerator(std::move(batch_gen_gen_readahead),\n+                             scan_options_->fragment_readahead);\n+}\n\nReview comment:\n       Ah ok, thanks for the explanation. I think I got mixed up because I thought MakeMergedGenerator could also itself queue up to one item per source.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T20:30:46.538+0000",
                    "updated": "2021-04-23T20:30:46.538+0000",
                    "started": "2021-04-23T20:30:46.538+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588131",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588133",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619480153\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+            }\n+          }\n+        }\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  struct FragmentStats {\n+    int last_index;\n+    bool seen;\n+  };\n+\n+  std::vector<FragmentStats> GetFragmentStats(const std::vector<int>& order) {\n+    auto last_indices = GetLastIndices(order);\n+    std::vector<FragmentStats> fragment_stats;\n+    for (std::size_t i = 0; i < last_indices.size(); i++) {\n+      fragment_stats.push_back({last_indices[i], false});\n+    }\n+    return fragment_stats;\n+  }\n+\n+  /// When data arrives out of order then we first have to buffer up 1 item in order to\n+  /// know when the last item has arrived (so we can mark it as the last).  This means\n+  /// sometimes we deliver an item and don't get one (first in a fragment) and sometimes\n+  /// we deliver an item and we end up getting two (last in a fragment)\n+  std::vector<EnumeratedRecordBatch> DeliverAndCollect(\n+      std::vector<int> order, EnumeratedRecordBatchGenerator gen) {\n+    std::vector<EnumeratedRecordBatch> collected;\n+    auto fragment_stats = GetFragmentStats(order);\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      if (static_cast<int>(i) == fragment_stats[fragment_index].last_index) {\n+        dataset_->FinishFragment(fragment_index);\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+      if (!fragment_stats[fragment_index].seen) {\n+        fragment_stats[fragment_index].seen = true;\n+      } else {\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  std::shared_ptr<Scanner> MakeScanner(int fragment_readahead = 0) {\n+    ScannerBuilder builder(dataset_);\n+    // Reordering tests only make sense for async\n+    builder.UseAsync(true);\n+    if (fragment_readahead != 0) {\n+      builder.FragmentReadahead(fragment_readahead);\n+    }\n+    EXPECT_OK_AND_ASSIGN(auto scanner, builder.Finish());\n+    return scanner;\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<TaggedRecordBatch>& batches,\n+                            std::vector<int> expected_order) {\n+    ASSERT_EQ(expected_order.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_order[i], batches[i].record_batch->num_rows());\n+    }\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<EnumeratedRecordBatch>& batches,\n+                            std::vector<int> expected_batch_indices,\n+                            std::vector<int> expected_row_sizes) {\n+    ASSERT_EQ(expected_batch_indices.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_row_sizes[i], batches[i].record_batch.value->num_rows());\n+      ASSERT_EQ(expected_batch_indices[i], batches[i].record_batch.index);\n+    }\n+  }\n+\n+  std::shared_ptr<ControlledDataset> dataset_;\n+};\n+\n+TEST_F(TestReordering, ScanBatches) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 1, 4, 2, 3});\n+}\n+\n+TEST_F(TestReordering, ScanBatchesUnordered) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 0, 1, 1, 2}, {0, 2, 3, 1, 4});\n+}\n+\n+struct BatchConsumer {\n+  explicit BatchConsumer(EnumeratedRecordBatchGenerator generator)\n+      : generator(generator), next() {}\n+\n+  void AssertCanConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK(next);\n+    next = Future<EnumeratedRecordBatch>();\n+  }\n+\n+  void AssertCannotConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    SleepABit();\n+    ASSERT_FALSE(next.is_finished());\n+  }\n+\n+  void AssertFinished() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK_AND_ASSIGN(auto last, next);\n+    ASSERT_TRUE(IsIterationEnd(last));\n+  }\n+\n+  EnumeratedRecordBatchGenerator generator;\n+  Future<EnumeratedRecordBatch> next;\n+};\n+\n+TEST_F(TestReordering, FileReadahead) {\n+  auto scanner = MakeScanner(1);\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  BatchConsumer consumer(std::move(batch_gen));\n+  dataset_->DeliverBatch(0, 0);\n+  dataset_->DeliverBatch(0, 1);\n+  consumer.AssertCanConsume();\n+  consumer.AssertCannotConsume();\n+  dataset_->DeliverBatch(1, 0);\n+  consumer.AssertCannotConsume();\n+  dataset_->FinishFragment(1);\n\nReview comment:\n       The purpose of this test is to make sure we are enforcing `fragment_readahead`.  Since `fragment_readahead` is set to 1 we will only read one fragment at a time.  So fragment 0 is the only \"active\" fragment and fragment 1 is still stuck in `batch_gen_gen`.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T20:31:02.222+0000",
                    "updated": "2021-04-23T20:31:02.222+0000",
                    "started": "2021-04-23T20:31:02.222+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588133",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588143",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619485334\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n\nReview comment:\n       Yes, that is correct.  And yes, these tests are rather tricky.  This test attempts to programmatically figure out what the output order should be based on the input order.  Another approach I could take is the approach in `TEST_F(TestReordering, FileReadahead)`.  In that test we explicitly specify the output order, leaving it up to the test author to figure out what it should be.\r\n   \r\n   While the test is tricky I felt it served as a sort of \"self-documentation\" of the foibles that need to be considered when looking at expected batch ordering.\r\n   \r\n   On the other hand, we could just get rid of the buffering.  I've created ARROW-12523 to consider that possibility.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T20:42:24.859+0000",
                    "updated": "2021-04-23T20:42:24.859+0000",
                    "started": "2021-04-23T20:42:24.859+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588143",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588146",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619486400\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n\nReview comment:\n       I think it's overall OK, just had to read it carefully and get all the context paged back in. (GitHub reviews aren't the best for seeing all the other stuff going on.) Though if that could be removed, that would also be great. Obviously it doesn't have to hold up things here though.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T20:44:46.717+0000",
                    "updated": "2021-04-23T20:44:46.717+0000",
                    "started": "2021-04-23T20:44:46.716+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588146",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/588243",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r619576323\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -115,7 +116,7 @@ class TestScanner : public DatasetFixtureMixinWithParam<TestScannerParams> {\n \n     AssertScanBatchesUnorderedEquals(expected.get(), scanner.get(), 1);\n   }\n-};\n+};  // namespace dataset\n\nReview comment:\n       I removed it manually for now.  I tried `ninja format` which runs `cd /home/pace/dev/arrow/cpp/conbench-build && /home/pace/anaconda3/envs/conbench2/bin/python3.7 /h.../dev/arrow/cpp/build-support/lint_exclusions.txt --source_dir /home/pace/dev/arrow/cpp/src --fix --quiet` and it had the same issue.  Although presumably, if you are doing format manually, you wouldn't run format until after everything is compiling correctly so this wouldn't be an issue.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-24T03:54:16.838+0000",
                    "updated": "2021-04-24T03:54:16.838+0000",
                    "started": "2021-04-24T03:54:16.838+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "588243",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/589141",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r620225452\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+            }\n+          }\n+        }\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  struct FragmentStats {\n+    int last_index;\n+    bool seen;\n+  };\n+\n+  std::vector<FragmentStats> GetFragmentStats(const std::vector<int>& order) {\n+    auto last_indices = GetLastIndices(order);\n+    std::vector<FragmentStats> fragment_stats;\n+    for (std::size_t i = 0; i < last_indices.size(); i++) {\n+      fragment_stats.push_back({last_indices[i], false});\n+    }\n+    return fragment_stats;\n+  }\n+\n+  /// When data arrives out of order then we first have to buffer up 1 item in order to\n+  /// know when the last item has arrived (so we can mark it as the last).  This means\n+  /// sometimes we deliver an item and don't get one (first in a fragment) and sometimes\n+  /// we deliver an item and we end up getting two (last in a fragment)\n+  std::vector<EnumeratedRecordBatch> DeliverAndCollect(\n+      std::vector<int> order, EnumeratedRecordBatchGenerator gen) {\n+    std::vector<EnumeratedRecordBatch> collected;\n+    auto fragment_stats = GetFragmentStats(order);\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      if (static_cast<int>(i) == fragment_stats[fragment_index].last_index) {\n+        dataset_->FinishFragment(fragment_index);\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+      if (!fragment_stats[fragment_index].seen) {\n+        fragment_stats[fragment_index].seen = true;\n+      } else {\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  std::shared_ptr<Scanner> MakeScanner(int fragment_readahead = 0) {\n+    ScannerBuilder builder(dataset_);\n+    // Reordering tests only make sense for async\n+    builder.UseAsync(true);\n+    if (fragment_readahead != 0) {\n+      builder.FragmentReadahead(fragment_readahead);\n+    }\n+    EXPECT_OK_AND_ASSIGN(auto scanner, builder.Finish());\n+    return scanner;\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<TaggedRecordBatch>& batches,\n+                            std::vector<int> expected_order) {\n+    ASSERT_EQ(expected_order.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_order[i], batches[i].record_batch->num_rows());\n+    }\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<EnumeratedRecordBatch>& batches,\n+                            std::vector<int> expected_batch_indices,\n+                            std::vector<int> expected_row_sizes) {\n+    ASSERT_EQ(expected_batch_indices.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_row_sizes[i], batches[i].record_batch.value->num_rows());\n+      ASSERT_EQ(expected_batch_indices[i], batches[i].record_batch.index);\n+    }\n+  }\n+\n+  std::shared_ptr<ControlledDataset> dataset_;\n+};\n+\n+TEST_F(TestReordering, ScanBatches) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 1, 4, 2, 3});\n+}\n+\n+TEST_F(TestReordering, ScanBatchesUnordered) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 0, 1, 1, 2}, {0, 2, 3, 1, 4});\n+}\n+\n+struct BatchConsumer {\n+  explicit BatchConsumer(EnumeratedRecordBatchGenerator generator)\n+      : generator(generator), next() {}\n+\n+  void AssertCanConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK(next);\n+    next = Future<EnumeratedRecordBatch>();\n+  }\n+\n+  void AssertCannotConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    SleepABit();\n+    ASSERT_FALSE(next.is_finished());\n+  }\n+\n+  void AssertFinished() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK_AND_ASSIGN(auto last, next);\n+    ASSERT_TRUE(IsIterationEnd(last));\n+  }\n+\n+  EnumeratedRecordBatchGenerator generator;\n+  Future<EnumeratedRecordBatch> next;\n+};\n+\n+TEST_F(TestReordering, FileReadahead) {\n+  auto scanner = MakeScanner(1);\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  BatchConsumer consumer(std::move(batch_gen));\n+  dataset_->DeliverBatch(0, 0);\n+  dataset_->DeliverBatch(0, 1);\n+  consumer.AssertCanConsume();\n+  consumer.AssertCannotConsume();\n+  dataset_->DeliverBatch(1, 0);\n+  consumer.AssertCannotConsume();\n+  dataset_->FinishFragment(1);\n\nReview comment:\n       It might be nice to explain inline why we expect to get/not get a batch, or at least put something like `MakeScanner(/*fragment_readahead=*/1)` to call out the readahead level.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-26T11:55:37.928+0000",
                    "updated": "2021-04-26T11:55:37.928+0000",
                    "started": "2021-04-26T11:55:37.927+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "589141",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/590147",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076#discussion_r621809458\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/scanner_test.cc\n##########\n@@ -390,6 +391,284 @@ TEST_P(TestScanner, Head) {\n INSTANTIATE_TEST_SUITE_P(TestScannerThreading, TestScanner,\n                          ::testing::ValuesIn(TestScannerParams::Values()));\n \n+/// These ControlledXyz classes allow for controlling the order in which things are\n+/// delivered so that we can test out of order resequencing.  The dataset allows\n+/// batches to be delivered on any fragment.  When delivering batches a num_rows\n+/// parameter is taken which can be used to differentiate batches.\n+class ControlledFragment : public Fragment {\n+ public:\n+  ControlledFragment(std::shared_ptr<Schema> schema)\n+      : Fragment(literal(true), std::move(schema)) {}\n+\n+  Result<ScanTaskIterator> Scan(std::shared_ptr<ScanOptions> options) override {\n+    return Status::NotImplemented(\n+        \"Not needed for testing.  Sync can only return things in-order.\");\n+  }\n+  Result<std::shared_ptr<Schema>> ReadPhysicalSchemaImpl() override {\n+    return physical_schema_;\n+  }\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledFragment\"; }\n+\n+  Result<RecordBatchGenerator> ScanBatchesAsync(\n+      const std::shared_ptr<ScanOptions>& options) override {\n+    return record_batch_generator_;\n+  };\n+\n+  void Finish() { ARROW_UNUSED(record_batch_generator_.producer().Close()); }\n+  void DeliverBatch(uint32_t num_rows) {\n+    auto batch = ConstantArrayGenerator::Zeroes(num_rows, physical_schema_);\n+    record_batch_generator_.producer().Push(std::move(batch));\n+  }\n+\n+ private:\n+  PushGenerator<std::shared_ptr<RecordBatch>> record_batch_generator_;\n+};\n+\n+// TODO(ARROW-8163) Add testing for fragments arriving out of order\n+class ControlledDataset : public Dataset {\n+ public:\n+  explicit ControlledDataset(int num_fragments)\n+      : Dataset(arrow::schema({field(\"i32\", int32())})), fragments_() {\n+    for (int i = 0; i < num_fragments; i++) {\n+      fragments_.push_back(std::make_shared<ControlledFragment>(schema_));\n+    }\n+  }\n+\n+  std::string type_name() const override { return \"scanner_test.cc::ControlledDataset\"; }\n+  Result<std::shared_ptr<Dataset>> ReplaceSchema(\n+      std::shared_ptr<Schema> schema) const override {\n+    return Status::NotImplemented(\"Should not be called by unit test\");\n+  }\n+\n+  void DeliverBatch(int fragment_index, int num_rows) {\n+    fragments_[fragment_index]->DeliverBatch(num_rows);\n+  }\n+\n+  void FinishFragment(int fragment_index) { fragments_[fragment_index]->Finish(); }\n+\n+ protected:\n+  virtual Result<FragmentIterator> GetFragmentsImpl(Expression predicate) {\n+    std::vector<std::shared_ptr<Fragment>> casted_fragments(fragments_.begin(),\n+                                                            fragments_.end());\n+    return MakeVectorIterator(std::move(casted_fragments));\n+  }\n+\n+ private:\n+  std::vector<std::shared_ptr<ControlledFragment>> fragments_;\n+};\n+\n+constexpr int kNumFragments = 2;\n+\n+class TestReordering : public ::testing::Test {\n+ public:\n+  void SetUp() override { dataset_ = std::make_shared<ControlledDataset>(kNumFragments); }\n+\n+  // Given a vector of fragment indices (one per batch) return a vector\n+  // (one per fragment) mapping fragment index to the last occurrence of that\n+  // index in order\n+  //\n+  // This allows us to know when to mark a fragment as finished\n+  std::vector<int> GetLastIndices(const std::vector<int>& order) {\n+    std::vector<int> last_indices(kNumFragments);\n+    for (int i = 0; i < kNumFragments; i++) {\n+      auto last_p = std::find(order.rbegin(), order.rend(), i);\n+      EXPECT_NE(last_p, order.rend());\n+      last_indices[i] = std::distance(last_p, order.rend()) - 1;\n+    }\n+    return last_indices;\n+  }\n+\n+  /// We buffer one item in order to enumerate it (technically this could be avoided if\n+  /// delivering in order but easier to have a single code path).  We also can't deliver\n+  /// items that don't come next.  These two facts make for some pretty complex logic\n+  /// to determine when items are ready to be collected.\n+  std::vector<TaggedRecordBatch> DeliverAndCollect(std::vector<int> order,\n+                                                   TaggedRecordBatchGenerator gen) {\n+    std::vector<TaggedRecordBatch> collected;\n+    auto last_indices = GetLastIndices(order);\n+    int num_fragments = last_indices.size();\n+    std::vector<int> batches_seen_for_fragment(num_fragments);\n+    auto current_fragment_index = 0;\n+    auto seen_fragment = false;\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      batches_seen_for_fragment[fragment_index]++;\n+      if (static_cast<int>(i) == last_indices[fragment_index]) {\n+        dataset_->FinishFragment(fragment_index);\n+      }\n+      if (current_fragment_index == fragment_index) {\n+        if (seen_fragment) {\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+        } else {\n+          seen_fragment = true;\n+        }\n+        if (static_cast<int>(i) == last_indices[fragment_index]) {\n+          // Immediately collect your bonus fragment\n+          EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+          collected.push_back(std::move(next));\n+          // Now collect any batches freed up that couldn't be delivered because they came\n+          // from the wrong fragment\n+          auto last_fragment_index = fragment_index;\n+          fragment_index++;\n+          seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+          while (fragment_index < num_fragments &&\n+                 fragment_index != last_fragment_index) {\n+            last_fragment_index = fragment_index;\n+            for (int j = 0; j < batches_seen_for_fragment[fragment_index] - 1; j++) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+            }\n+            if (static_cast<int>(i) >= last_indices[fragment_index]) {\n+              EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+              collected.push_back(std::move(next));\n+              fragment_index++;\n+              seen_fragment = batches_seen_for_fragment[fragment_index] > 0;\n+            }\n+          }\n+        }\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  struct FragmentStats {\n+    int last_index;\n+    bool seen;\n+  };\n+\n+  std::vector<FragmentStats> GetFragmentStats(const std::vector<int>& order) {\n+    auto last_indices = GetLastIndices(order);\n+    std::vector<FragmentStats> fragment_stats;\n+    for (std::size_t i = 0; i < last_indices.size(); i++) {\n+      fragment_stats.push_back({last_indices[i], false});\n+    }\n+    return fragment_stats;\n+  }\n+\n+  /// When data arrives out of order then we first have to buffer up 1 item in order to\n+  /// know when the last item has arrived (so we can mark it as the last).  This means\n+  /// sometimes we deliver an item and don't get one (first in a fragment) and sometimes\n+  /// we deliver an item and we end up getting two (last in a fragment)\n+  std::vector<EnumeratedRecordBatch> DeliverAndCollect(\n+      std::vector<int> order, EnumeratedRecordBatchGenerator gen) {\n+    std::vector<EnumeratedRecordBatch> collected;\n+    auto fragment_stats = GetFragmentStats(order);\n+    for (std::size_t i = 0; i < order.size(); i++) {\n+      auto fragment_index = order[i];\n+      dataset_->DeliverBatch(fragment_index, i);\n+      if (static_cast<int>(i) == fragment_stats[fragment_index].last_index) {\n+        dataset_->FinishFragment(fragment_index);\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+      if (!fragment_stats[fragment_index].seen) {\n+        fragment_stats[fragment_index].seen = true;\n+      } else {\n+        EXPECT_FINISHES_OK_AND_ASSIGN(auto next, gen());\n+        collected.push_back(std::move(next));\n+      }\n+    }\n+    return collected;\n+  }\n+\n+  std::shared_ptr<Scanner> MakeScanner(int fragment_readahead = 0) {\n+    ScannerBuilder builder(dataset_);\n+    // Reordering tests only make sense for async\n+    builder.UseAsync(true);\n+    if (fragment_readahead != 0) {\n+      builder.FragmentReadahead(fragment_readahead);\n+    }\n+    EXPECT_OK_AND_ASSIGN(auto scanner, builder.Finish());\n+    return scanner;\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<TaggedRecordBatch>& batches,\n+                            std::vector<int> expected_order) {\n+    ASSERT_EQ(expected_order.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_order[i], batches[i].record_batch->num_rows());\n+    }\n+  }\n+\n+  void AssertBatchesInOrder(const std::vector<EnumeratedRecordBatch>& batches,\n+                            std::vector<int> expected_batch_indices,\n+                            std::vector<int> expected_row_sizes) {\n+    ASSERT_EQ(expected_batch_indices.size(), batches.size());\n+    for (std::size_t i = 0; i < batches.size(); i++) {\n+      ASSERT_EQ(expected_row_sizes[i], batches[i].record_batch.value->num_rows());\n+      ASSERT_EQ(expected_batch_indices[i], batches[i].record_batch.index);\n+    }\n+  }\n+\n+  std::shared_ptr<ControlledDataset> dataset_;\n+};\n+\n+TEST_F(TestReordering, ScanBatches) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 1, 4, 2, 3});\n+}\n+\n+TEST_F(TestReordering, ScanBatchesUnordered) {\n+  auto scanner = MakeScanner();\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  auto collected = DeliverAndCollect({0, 0, 1, 1, 0}, std::move(batch_gen));\n+  AssertBatchesInOrder(collected, {0, 0, 1, 1, 2}, {0, 2, 3, 1, 4});\n+}\n+\n+struct BatchConsumer {\n+  explicit BatchConsumer(EnumeratedRecordBatchGenerator generator)\n+      : generator(generator), next() {}\n+\n+  void AssertCanConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK(next);\n+    next = Future<EnumeratedRecordBatch>();\n+  }\n+\n+  void AssertCannotConsume() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    SleepABit();\n+    ASSERT_FALSE(next.is_finished());\n+  }\n+\n+  void AssertFinished() {\n+    if (!next.is_valid()) {\n+      next = generator();\n+    }\n+    ASSERT_FINISHES_OK_AND_ASSIGN(auto last, next);\n+    ASSERT_TRUE(IsIterationEnd(last));\n+  }\n+\n+  EnumeratedRecordBatchGenerator generator;\n+  Future<EnumeratedRecordBatch> next;\n+};\n+\n+TEST_F(TestReordering, FileReadahead) {\n+  auto scanner = MakeScanner(1);\n+  ASSERT_OK_AND_ASSIGN(auto batch_gen, scanner->ScanBatchesUnorderedAsync());\n+  BatchConsumer consumer(std::move(batch_gen));\n+  dataset_->DeliverBatch(0, 0);\n+  dataset_->DeliverBatch(0, 1);\n+  consumer.AssertCanConsume();\n+  consumer.AssertCannotConsume();\n+  dataset_->DeliverBatch(1, 0);\n+  consumer.AssertCannotConsume();\n+  dataset_->FinishFragment(1);\n\nReview comment:\n       I added a bit more description.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-28T04:45:01.590+0000",
                    "updated": "2021-04-28T04:45:01.590+0000",
                    "started": "2021-04-28T04:45:01.589+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "590147",
                    "issueId": "13372456"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/worklog/590328",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm closed pull request #10076:\nURL: https://github.com/apache/arrow/pull/10076\n\n\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-28T12:06:56.378+0000",
                    "updated": "2021-04-28T12:06:56.378+0000",
                    "started": "2021-04-28T12:06:56.377+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "590328",
                    "issueId": "13372456"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 7800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2887f17d[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3ead548c[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6e8c45d1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@3a5175b8[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@73420e71[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@30ea0cf9[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3c4475f8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@d892b7d[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6edb8d3b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@eb6d9dd[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@11c28646[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@55d485c0[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 7800,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Apr 28 12:06:36 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-04-28T12:06:36.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12386/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2021-04-14T16:54:02.000+0000",
        "updated": "2021-04-28T12:06:57.000+0000",
        "timeoriginalestimate": null,
        "description": "Whether we pull from files in parallel or not is controlled by how we merge the batch streams in `AsyncScanner::ScanBatchesUnorderedAsync`.\u00a0 Currently we are relying on `MakeConcatenatedGenerator` which is incorrect.\u00a0 This is needed because `MakeMergedGenerator` pulls from its source (an `EnumeratingGenerator`) in an async reentrant fashion.\u00a0 `MakeMergedGenerator` should not do this.\u00a0 If some kind of readahead is truly necessary there then use `MakeReadaheadGenerator`.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "2h 10m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 7800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Support file parallelism in AsyncScanner",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372456/comment/17334684",
                    "id": "17334684",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 10076\n[https://github.com/apache/arrow/pull/10076]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-04-28T12:06:36.838+0000",
                    "updated": "2021-04-28T12:06:36.838+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0q094:",
        "customfield_12314139": null
    }
}