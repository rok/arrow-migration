{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13120792",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792",
    "key": "ARROW-1860",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343066",
                "id": "12343066",
                "description": "",
                "name": "0.11.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-10-08"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "flight",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "1.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 1800,
            "total": 1800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 1800,
            "total": 1800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1860/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 3,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/worklog/104296",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500#issuecomment-390798036\n \n \n   > why do you want to pad data? \r\n   \r\n   I'll need to revisit this patch from a few months ago and remember why I thought this. The basic idea is for messages to be relocatable and deterministic (e.g. if you were to hash the metadata, you would always get the same hash). By always aligning the stream before writing a message, you guarantee that the message metadata and body have the exact same contents.\r\n   \r\n   Given the time that has passed, it'll probably make sense to start this patch over. There's a unit test here that can be taken over, but the rest of the refactoring should probably be started from from the codebase as it is now. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-05-21T22:08:35.071+0000",
                    "updated": "2018-05-21T22:08:35.071+0000",
                    "started": "2018-05-21T22:08:35.070+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "104296",
                    "issueId": "13120792"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/worklog/117437",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500#issuecomment-401402194\n \n \n   Abandoning this PR for now. I would like to start again on this later in the year\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-06-29T16:13:34.080+0000",
                    "updated": "2018-06-29T16:13:34.080+0000",
                    "started": "2018-06-29T16:13:34.080+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "117437",
                    "issueId": "13120792"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/worklog/117438",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm closed pull request #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/cpp/src/arrow/CMakeLists.txt b/cpp/src/arrow/CMakeLists.txt\nindex 74674bebb4..9d60cbcd0e 100644\n--- a/cpp/src/arrow/CMakeLists.txt\n+++ b/cpp/src/arrow/CMakeLists.txt\n@@ -113,6 +113,7 @@ if (ARROW_IPC)\n     ipc/message.cc\n     ipc/metadata-internal.cc\n     ipc/reader.cc\n+    ipc/util.cc\n     ipc/writer.cc\n   )\n   SET(ARROW_SRCS ${ARROW_SRCS}\ndiff --git a/cpp/src/arrow/ipc/ipc-read-write-test.cc b/cpp/src/arrow/ipc/ipc-read-write-test.cc\nindex 1fcbdac5eb..d3b9e3b588 100644\n--- a/cpp/src/arrow/ipc/ipc-read-write-test.cc\n+++ b/cpp/src/arrow/ipc/ipc-read-write-test.cc\n@@ -22,12 +22,14 @@\n #include <string>\n #include <vector>\n \n+#include \"flatbuffers/flatbuffers.h\"\n #include \"gtest/gtest.h\"\n \n #include \"arrow/array.h\"\n #include \"arrow/buffer.h\"\n #include \"arrow/io/memory.h\"\n #include \"arrow/io/test-common.h\"\n+#include \"arrow/ipc/Message_generated.h\"\n #include \"arrow/ipc/api.h\"\n #include \"arrow/ipc/metadata-internal.h\"\n #include \"arrow/ipc/test-common.h\"\n@@ -246,6 +248,57 @@ TEST_F(TestIpcRoundTrip, MetadataVersion) {\n   ASSERT_EQ(MetadataVersion::V4, message->metadata_version());\n }\n \n+TEST_F(TestIpcRoundTrip, WriteMetadataUnaligned) {\n+  ASSERT_OK(\n+      io::MemoryMapFixture::InitMemoryMap(1 << 16, \"test-metadata-unaligned\", &mmap_));\n+  ASSERT_OK(mmap_->Seek(3));\n+\n+  std::string metadata = \"some metadata\";\n+\n+  // 17 bytes + 7 bytes padding\n+  const int64_t padded_metadata_size = 24;\n+\n+  auto metadata_buf = std::make_shared<Buffer>(metadata);\n+\n+  int32_t out_metadata_size = 0;\n+  ASSERT_OK(internal::WriteMessage(*metadata_buf, mmap_.get(), &out_metadata_size));\n+  ASSERT_EQ(padded_metadata_size, out_metadata_size);\n+\n+  int64_t stream_position = 0;\n+  ASSERT_OK(mmap_->Tell(&stream_position));\n+  ASSERT_EQ(32, stream_position);\n+\n+  // Write Message object\n+  flatbuffers::FlatBufferBuilder fbb;\n+\n+  const int64_t fake_body_size = 27;\n+  auto message =\n+      flatbuf::CreateMessage(fbb, internal::kCurrentMetadataVersion,\n+                             flatbuf::MessageHeader_RecordBatch, 0, fake_body_size);\n+  fbb.Finish(message);\n+\n+  auto fb = std::make_shared<Buffer>(fbb.GetBufferPointer(), fbb.GetSize());\n+\n+  ASSERT_OK(mmap_->Seek(3));\n+  Message msg(fb, nullptr);\n+\n+  int64_t out_length = 0;\n+  int64_t message_size = BitUtil::RoundUpToMultipleOf8(fb->size() + 4);\n+  ASSERT_OK(msg.SerializeTo(mmap_.get(), &out_length));\n+  ASSERT_EQ(message_size, out_length);\n+\n+  // Read back\n+  std::unique_ptr<Message> result;\n+  ASSERT_OK(mmap_->Seek(3));\n+  ASSERT_OK(ReadMessage(mmap_.get(), &result));\n+  ASSERT_OK(mmap_->Tell(&stream_position));\n+  ASSERT_EQ(message_size + 8 + fake_body_size, stream_position);\n+\n+  const Buffer& result_meta = *result->metadata();\n+  const Buffer& expected_meta = *fb;\n+  ASSERT_TRUE(result_meta.Equals(expected_meta, expected_meta.size()));\n+}\n+\n TEST_P(TestIpcRoundTrip, SliceRoundTrip) {\n   std::shared_ptr<RecordBatch> batch;\n   ASSERT_OK((*GetParam())(&batch));  // NOLINT clang-tidy gtest issue\ndiff --git a/cpp/src/arrow/ipc/message.cc b/cpp/src/arrow/ipc/message.cc\nindex 1835cefde0..895cf0b7cc 100644\n--- a/cpp/src/arrow/ipc/message.cc\n+++ b/cpp/src/arrow/ipc/message.cc\n@@ -28,6 +28,7 @@\n #include \"arrow/ipc/Message_generated.h\"\n #include \"arrow/ipc/Schema_generated.h\"\n #include \"arrow/ipc/metadata-internal.h\"\n+#include \"arrow/ipc/util.h\"\n #include \"arrow/status.h\"\n #include \"arrow/util/logging.h\"\n \n@@ -208,6 +209,8 @@ Status ReadMessage(int64_t offset, int32_t metadata_length, io::RandomAccessFile\n }\n \n Status ReadMessage(io::InputStream* file, std::unique_ptr<Message>* message) {\n+  RETURN_NOT_OK(internal::AlignInputStream(file));\n+\n   int32_t message_length = 0;\n   int64_t bytes_read = 0;\n   RETURN_NOT_OK(file->Read(sizeof(int32_t), &bytes_read,\ndiff --git a/cpp/src/arrow/ipc/metadata-internal.cc b/cpp/src/arrow/ipc/metadata-internal.cc\nindex af1d6c8515..6b96f1cada 100644\n--- a/cpp/src/arrow/ipc/metadata-internal.cc\n+++ b/cpp/src/arrow/ipc/metadata-internal.cc\n@@ -895,19 +895,21 @@ Status GetTensorMetadata(const Buffer& metadata, std::shared_ptr<DataType>* type\n // ----------------------------------------------------------------------\n // Implement message writing\n \n-Status WriteMessage(const Buffer& message, io::OutputStream* file,\n-                    int32_t* message_length) {\n-  // Need to write 4 bytes (message size), the message, plus padding to\n-  // end on an 8-byte offset\n-  int64_t start_offset;\n-  RETURN_NOT_OK(file->Tell(&start_offset));\n-\n-  int32_t padded_message_length = static_cast<int32_t>(message.size()) + 4;\n-  const int32_t remainder =\n-      (padded_message_length + static_cast<int32_t>(start_offset)) % 8;\n+int64_t GetSerializedMetadataSize(int64_t metadata_size) {\n+  int64_t padded_metadata_size = metadata_size + 4;\n+  const int32_t remainder = padded_metadata_size % 8;\n   if (remainder != 0) {\n-    padded_message_length += 8 - remainder;\n+    padded_metadata_size += 8 - remainder;\n   }\n+  return padded_metadata_size;\n+}\n+\n+Status WriteMessage(const Buffer& message, io::OutputStream* file,\n+                    int32_t* message_length) {\n+  RETURN_NOT_OK(internal::AlignOutputStream(file));\n+\n+  int32_t padded_message_length =\n+      static_cast<int32_t>(GetSerializedMetadataSize(message.size()));\n \n   // The returned message size includes the length prefix, the flatbuffer,\n   // plus padding\ndiff --git a/cpp/src/arrow/ipc/metadata-internal.h b/cpp/src/arrow/ipc/metadata-internal.h\nindex 380f3c9eb1..970be9007e 100644\n--- a/cpp/src/arrow/ipc/metadata-internal.h\n+++ b/cpp/src/arrow/ipc/metadata-internal.h\n@@ -96,6 +96,8 @@ Status GetTensorMetadata(const Buffer& metadata, std::shared_ptr<DataType>* type\n                          std::vector<int64_t>* shape, std::vector<int64_t>* strides,\n                          std::vector<std::string>* dim_names);\n \n+int64_t GetSerializedMetadataSize(int64_t flatbuffer_size);\n+\n /// Write a serialized message metadata with a length-prefix and padding to an\n /// 8-byte offset\n ///\ndiff --git a/cpp/src/arrow/ipc/reader.cc b/cpp/src/arrow/ipc/reader.cc\nindex cc3b6e5578..5f73225fda 100644\n--- a/cpp/src/arrow/ipc/reader.cc\n+++ b/cpp/src/arrow/ipc/reader.cc\n@@ -710,8 +710,6 @@ Status ReadRecordBatch(const std::shared_ptr<Schema>& schema, io::InputStream* f\n \n Status ReadTensor(int64_t offset, io::RandomAccessFile* file,\n                   std::shared_ptr<Tensor>* out) {\n-  // Respect alignment of Tensor messages (see WriteTensor)\n-  offset = PaddedLength(offset);\n   RETURN_NOT_OK(file->Seek(offset));\n \n   std::unique_ptr<Message> message;\ndiff --git a/cpp/src/arrow/ipc/util.cc b/cpp/src/arrow/ipc/util.cc\nnew file mode 100644\nindex 0000000000..fd1bef5df5\n--- /dev/null\n+++ b/cpp/src/arrow/ipc/util.cc\n@@ -0,0 +1,62 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/ipc/util.h\"\n+\n+#include <cstdint>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace ipc {\n+namespace internal {\n+\n+// Adds padding bytes if necessary to ensure all memory blocks are written on\n+// 8-byte boundaries.\n+Status AlignOutputStream(io::OutputStream* stream, int64_t alignment) {\n+  int64_t position;\n+  RETURN_NOT_OK(stream->Tell(&position));\n+  int64_t remainder = PaddedLength(position, alignment) - position;\n+  if (remainder > 0) {\n+    return stream->Write(kPaddingBytes, remainder);\n+  }\n+  return Status::OK();\n+}\n+\n+Status AlignInputStream(io::InputStream* stream, int64_t alignment) {\n+  int64_t position;\n+  RETURN_NOT_OK(stream->Tell(&position));\n+  int64_t remainder = PaddedLength(position, alignment) - position;\n+\n+  static uint8_t kScratchBuffer[8] = {0};\n+  if (remainder > 0) {\n+    int64_t bytes_read = 0;\n+    RETURN_NOT_OK(stream->Read(remainder, &bytes_read, kScratchBuffer));\n+\n+    // If we are not at EOS, ensure we can read the exact number of bytes to\n+    // next 8-byte offset\n+    if (bytes_read > 0 && bytes_read != remainder) {\n+      return Status::IOError(\"Unable to align InputStream\");\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+}  // namespace internal\n+}  // namespace ipc\n+}  // namespace arrow\ndiff --git a/cpp/src/arrow/ipc/util.h b/cpp/src/arrow/ipc/util.h\nindex 412f31215e..6bb4c2fac6 100644\n--- a/cpp/src/arrow/ipc/util.h\n+++ b/cpp/src/arrow/ipc/util.h\n@@ -39,6 +39,17 @@ static inline int64_t PaddedLength(int64_t nbytes, int64_t alignment = kArrowAli\n   return ((nbytes + alignment - 1) / alignment) * alignment;\n }\n \n+namespace internal {\n+\n+// Adds padding bytes if necessary to ensure all memory blocks are written on\n+// 8-byte boundaries.\n+Status AlignOutputStream(io::OutputStream* stream,\n+                         int64_t alignment = kArrowIpcAlignment);\n+\n+Status AlignInputStream(io::InputStream* stream, int64_t alignment = kArrowIpcAlignment);\n+\n+}  // namespace internal\n+\n }  // namespace ipc\n }  // namespace arrow\n \ndiff --git a/cpp/src/arrow/ipc/writer.cc b/cpp/src/arrow/ipc/writer.cc\nindex c6aa770127..64b283f226 100644\n--- a/cpp/src/arrow/ipc/writer.cc\n+++ b/cpp/src/arrow/ipc/writer.cc\n@@ -46,6 +46,58 @@ namespace ipc {\n using internal::FileBlock;\n using internal::kArrowMagicBytes;\n \n+// ----------------------------------------------------------------------\n+// Writing a generic IPC message\n+\n+int64_t PreparedMessage::GetTotalSize() const {\n+  int64_t metadata_size = internal::GetSerializedMetadataSize(this->metadata->size());\n+  return metadata_size + this->total_body_length;\n+}\n+\n+Status PreparedMessage::WriteTo(io::OutputStream* dst, int32_t* out_metadata_length,\n+                                int64_t* out_body_length) const {\n+  RETURN_NOT_OK(internal::WriteMessage(*this->metadata, dst, out_metadata_length));\n+\n+#ifndef NDEBUG\n+  int64_t current_position = -1;\n+  RETURN_NOT_OK(dst->Tell(&current_position));\n+  DCHECK(BitUtil::IsMultipleOf8(current_position));\n+#endif\n+\n+  // Now write the buffers\n+  int64_t body_length = 0;\n+  for (size_t i = 0; i < this->body_buffers.size(); ++i) {\n+    const Buffer* buffer = this->body_buffers[i].get();\n+    int64_t size = 0;\n+    int64_t padding = 0;\n+\n+    // The buffer might be null if we are handling zero row lengths.\n+    if (buffer) {\n+      size = buffer->size();\n+      padding = BitUtil::RoundUpToMultipleOf8(size) - size;\n+    }\n+\n+    if (size > 0) {\n+      RETURN_NOT_OK(dst->Write(buffer->data(), size));\n+      body_length += size;\n+    }\n+\n+    if (padding > 0) {\n+      RETURN_NOT_OK(dst->Write(kPaddingBytes, padding));\n+      body_length += padding;\n+    }\n+  }\n+\n+#ifndef NDEBUG\n+  RETURN_NOT_OK(dst->Tell(&current_position));\n+  DCHECK(BitUtil::IsMultipleOf8(current_position));\n+#endif\n+\n+  *out_body_length = body_length;\n+\n+  return Status::OK();\n+}\n+\n // ----------------------------------------------------------------------\n // Record batch write path\n \n@@ -124,20 +176,27 @@ class RecordBatchSerializer : public ArrayVisitor {\n       std::shared_ptr<Buffer> bitmap;\n       RETURN_NOT_OK(GetTruncatedBitmap(arr.offset(), arr.length(), arr.null_bitmap(),\n                                        pool_, &bitmap));\n-      buffers_.push_back(bitmap);\n+      buffers_.emplace_back(std::move(bitmap));\n     } else {\n+      static const std::shared_ptr<Buffer> kNullBuffer =\n+          std::make_shared<Buffer>(nullptr, 0);\n       // Push a dummy zero-length buffer, not to be copied\n-      buffers_.push_back(std::make_shared<Buffer>(nullptr, 0));\n+      buffers_.push_back(kNullBuffer);\n     }\n     return arr.Accept(this);\n   }\n \n-  Status Assemble(const RecordBatch& batch, int64_t* body_length) {\n-    if (field_nodes_.size() > 0) {\n-      field_nodes_.clear();\n-      buffer_meta_.clear();\n-      buffers_.clear();\n-    }\n+  // Override this for writing dictionary metadata\n+  virtual Status WriteMetadataMessage(int64_t num_rows, int64_t body_length,\n+                                      std::shared_ptr<Buffer>* out) {\n+    return WriteRecordBatchMessage(num_rows, body_length, field_nodes_, buffer_meta_,\n+                                   out);\n+  }\n+\n+  Status Prepare(const RecordBatch& batch, PreparedMessage* out) {\n+    field_nodes_.clear();\n+    buffer_meta_.clear();\n+    buffers_.clear();\n \n     // Perform depth-first traversal of the row-batch\n     for (int i = 0; i < batch.num_columns(); ++i) {\n@@ -166,67 +225,18 @@ class RecordBatchSerializer : public ArrayVisitor {\n       offset += size + padding;\n     }\n \n-    *body_length = offset - buffer_start_offset_;\n-    DCHECK(BitUtil::IsMultipleOf8(*body_length));\n-\n-    return Status::OK();\n-  }\n-\n-  // Override this for writing dictionary metadata\n-  virtual Status WriteMetadataMessage(int64_t num_rows, int64_t body_length,\n-                                      std::shared_ptr<Buffer>* out) {\n-    return WriteRecordBatchMessage(num_rows, body_length, field_nodes_, buffer_meta_,\n-                                   out);\n-  }\n+    int64_t body_length = offset - buffer_start_offset_;\n+    DCHECK(BitUtil::IsMultipleOf8(body_length));\n \n-  Status Write(const RecordBatch& batch, io::OutputStream* dst, int32_t* metadata_length,\n-               int64_t* body_length) {\n-    RETURN_NOT_OK(Assemble(batch, body_length));\n-\n-#ifndef NDEBUG\n-    int64_t start_position, current_position;\n-    RETURN_NOT_OK(dst->Tell(&start_position));\n-#endif\n-\n-    // Now that we have computed the locations of all of the buffers in shared\n-    // memory, the data header can be converted to a flatbuffer and written out\n+    // Now that we have computed the locations of all of the buffers in the\n+    // body, the data header can be converted to a flatbuffer and written out\n     //\n     // Note: The memory written here is prefixed by the size of the flatbuffer\n     // itself as an int32_t.\n-    std::shared_ptr<Buffer> metadata_fb;\n-    RETURN_NOT_OK(WriteMetadataMessage(batch.num_rows(), *body_length, &metadata_fb));\n-    RETURN_NOT_OK(internal::WriteMessage(*metadata_fb, dst, metadata_length));\n-\n-#ifndef NDEBUG\n-    RETURN_NOT_OK(dst->Tell(&current_position));\n-    DCHECK(BitUtil::IsMultipleOf8(current_position));\n-#endif\n-\n-    // Now write the buffers\n-    for (size_t i = 0; i < buffers_.size(); ++i) {\n-      const Buffer* buffer = buffers_[i].get();\n-      int64_t size = 0;\n-      int64_t padding = 0;\n-\n-      // The buffer might be null if we are handling zero row lengths.\n-      if (buffer) {\n-        size = buffer->size();\n-        padding = BitUtil::RoundUpToMultipleOf8(size) - size;\n-      }\n-\n-      if (size > 0) {\n-        RETURN_NOT_OK(dst->Write(buffer->data(), size));\n-      }\n+    RETURN_NOT_OK(WriteMetadataMessage(batch.num_rows(), body_length, &out->metadata));\n \n-      if (padding > 0) {\n-        RETURN_NOT_OK(dst->Write(kPaddingBytes, padding));\n-      }\n-    }\n-\n-#ifndef NDEBUG\n-    RETURN_NOT_OK(dst->Tell(&current_position));\n-    DCHECK(BitUtil::IsMultipleOf8(current_position));\n-#endif\n+    out->body_buffers = std::move(buffers_);\n+    out->total_body_length = body_length;\n \n     return Status::OK();\n   }\n@@ -504,14 +514,14 @@ class DictionaryWriter : public RecordBatchSerializer {\n                                   buffer_meta_, out);\n   }\n \n-  Status Write(int64_t dictionary_id, const std::shared_ptr<Array>& dictionary,\n-               io::OutputStream* dst, int32_t* metadata_length, int64_t* body_length) {\n+  Status Prepare(int64_t dictionary_id, const std::shared_ptr<Array>& dictionary,\n+                 PreparedMessage* out) {\n     dictionary_id_ = dictionary_id;\n \n     // Make a dummy record batch. A bit tedious as we have to make a schema\n     auto schema = arrow::schema({arrow::field(\"dictionary\", dictionary->type())});\n     auto batch = RecordBatch::Make(schema, dictionary->length(), {dictionary});\n-    return RecordBatchSerializer::Write(*batch, dst, metadata_length, body_length);\n+    return RecordBatchSerializer::Prepare(*batch, out);\n   }\n \n  private:\n@@ -519,25 +529,45 @@ class DictionaryWriter : public RecordBatchSerializer {\n   int64_t dictionary_id_;\n };\n \n-// Adds padding bytes if necessary to ensure all memory blocks are written on\n-// 64-byte boundaries.\n-Status AlignStreamPosition(io::OutputStream* stream) {\n-  int64_t position;\n-  RETURN_NOT_OK(stream->Tell(&position));\n-  int64_t remainder = PaddedLength(position) - position;\n-  if (remainder > 0) {\n-    return stream->Write(kPaddingBytes, remainder);\n-  }\n-  return Status::OK();\n-}\n-\n Status WriteRecordBatch(const RecordBatch& batch, int64_t buffer_start_offset,\n                         io::OutputStream* dst, int32_t* metadata_length,\n                         int64_t* body_length, MemoryPool* pool, int max_recursion_depth,\n                         bool allow_64bit) {\n+  PreparedMessage message;\n   RecordBatchSerializer writer(pool, buffer_start_offset, max_recursion_depth,\n                                allow_64bit);\n-  return writer.Write(batch, dst, metadata_length, body_length);\n+  RETURN_NOT_OK(writer.Prepare(batch, &message));\n+  return message.WriteTo(dst, metadata_length, body_length);\n+}\n+\n+Status WriteDictionary(int64_t dictionary_id, const std::shared_ptr<Array>& dictionary,\n+                       int64_t buffer_start_offset, io::OutputStream* dst,\n+                       int32_t* metadata_length, int64_t* body_length, MemoryPool* pool) {\n+  PreparedMessage message;\n+  DictionaryWriter writer(pool, buffer_start_offset, kMaxNestingDepth, false);\n+  RETURN_NOT_OK(writer.Prepare(dictionary_id, dictionary, &message));\n+  return message.WriteTo(dst, metadata_length, body_length);\n+}\n+\n+Status PrepareRecordBatchMessage(const RecordBatch& batch, MemoryPool* pool,\n+                                 PreparedMessage* message, int max_recursion_depth) {\n+  RecordBatchSerializer writer(pool, 0, max_recursion_depth, true);\n+  return writer.Prepare(batch, message);\n+}\n+\n+Status PrepareDictionaryMessage(int64_t dictionary_id,\n+                                const std::shared_ptr<Array>& dictionary,\n+                                MemoryPool* pool, PreparedMessage* message,\n+                                int max_recursion_depth) {\n+  DictionaryWriter writer(pool, 0, kMaxNestingDepth, false);\n+  return writer.Prepare(dictionary_id, dictionary, message);\n+}\n+\n+Status GetRecordBatchSize(const RecordBatch& batch, int64_t* size) {\n+  PreparedMessage message;\n+  RETURN_NOT_OK(PrepareRecordBatchMessage(batch, default_memory_pool(), &message));\n+  *size = message.GetTotalSize();\n+  return Status::OK();\n }\n \n Status WriteRecordBatchStream(const std::vector<std::shared_ptr<RecordBatch>>& batches,\n@@ -553,13 +583,6 @@ Status WriteRecordBatchStream(const std::vector<std::shared_ptr<RecordBatch>>& b\n   return Status::OK();\n }\n \n-Status WriteLargeRecordBatch(const RecordBatch& batch, int64_t buffer_start_offset,\n-                             io::OutputStream* dst, int32_t* metadata_length,\n-                             int64_t* body_length, MemoryPool* pool) {\n-  return WriteRecordBatch(batch, buffer_start_offset, dst, metadata_length, body_length,\n-                          pool, kMaxNestingDepth, true);\n-}\n-\n namespace {\n \n Status WriteTensorHeader(const Tensor& tensor, io::OutputStream* dst,\n@@ -618,8 +641,6 @@ Status GetContiguousTensor(const Tensor& tensor, MemoryPool* pool,\n \n Status WriteTensor(const Tensor& tensor, io::OutputStream* dst, int32_t* metadata_length,\n                    int64_t* body_length) {\n-  RETURN_NOT_OK(AlignStreamPosition(dst));\n-\n   if (tensor.is_contiguous()) {\n     RETURN_NOT_OK(WriteTensorHeader(tensor, dst, metadata_length, body_length));\n     auto data = tensor.data();\n@@ -649,10 +670,10 @@ Status WriteTensor(const Tensor& tensor, io::OutputStream* dst, int32_t* metadat\n   }\n }\n \n-Status GetTensorMessage(const Tensor& tensor, MemoryPool* pool,\n-                        std::unique_ptr<Message>* out) {\n-  const Tensor* tensor_to_write = &tensor;\n+Status PrepareTensorMessage(const Tensor& tensor, MemoryPool* pool,\n+                            PreparedMessage* out) {\n   std::unique_ptr<Tensor> temp_tensor;\n+  const Tensor* tensor_to_write = &tensor;\n \n   if (!tensor.is_contiguous()) {\n     RETURN_NOT_OK(GetContiguousTensor(tensor, pool, &temp_tensor));\n@@ -660,26 +681,23 @@ Status GetTensorMessage(const Tensor& tensor, MemoryPool* pool,\n   }\n \n   std::shared_ptr<Buffer> metadata;\n-  RETURN_NOT_OK(internal::WriteTensorMessage(*tensor_to_write, 0, &metadata));\n-  out->reset(new Message(metadata, tensor_to_write->data()));\n-  return Status::OK();\n-}\n+  RETURN_NOT_OK(internal::WriteTensorMessage(*tensor_to_write, 0, &out->metadata));\n+  auto data = tensor_to_write->data();\n+  out->body_buffers = {data};\n \n-Status WriteDictionary(int64_t dictionary_id, const std::shared_ptr<Array>& dictionary,\n-                       int64_t buffer_start_offset, io::OutputStream* dst,\n-                       int32_t* metadata_length, int64_t* body_length, MemoryPool* pool) {\n-  DictionaryWriter writer(pool, buffer_start_offset, kMaxNestingDepth, false);\n-  return writer.Write(dictionary_id, dictionary, dst, metadata_length, body_length);\n+  if (data) {\n+    out->total_body_length = BitUtil::RoundUpToMultipleOf8(data->size());\n+  } else {\n+    out->total_body_length = 0;\n+  }\n+  return Status::OK();\n }\n \n-Status GetRecordBatchSize(const RecordBatch& batch, int64_t* size) {\n-  // emulates the behavior of Write without actually writing\n-  int32_t metadata_length = 0;\n-  int64_t body_length = 0;\n-  io::MockOutputStream dst;\n-  RETURN_NOT_OK(WriteRecordBatch(batch, 0, &dst, &metadata_length, &body_length,\n-                                 default_memory_pool(), kMaxNestingDepth, true));\n-  *size = dst.GetExtentBytesWritten();\n+Status GetTensorMessage(const Tensor& tensor, MemoryPool* pool,\n+                        std::unique_ptr<Message>* out) {\n+  PreparedMessage tensor_message;\n+  RETURN_NOT_OK(PrepareTensorMessage(tensor, pool, &tensor_message));\n+  out->reset(new Message(tensor_message.metadata, tensor_message.body_buffers[0]));\n   return Status::OK();\n }\n \ndiff --git a/cpp/src/arrow/ipc/writer.h b/cpp/src/arrow/ipc/writer.h\nindex 013783ee0a..f401386e50 100644\n--- a/cpp/src/arrow/ipc/writer.h\n+++ b/cpp/src/arrow/ipc/writer.h\n@@ -48,6 +48,28 @@ class OutputStream;\n \n namespace ipc {\n \n+/// \\class PreparedMessage\n+/// \\brief An encapsulated IPC message ready to be written to some OutputStream\n+///\n+/// This data structure allows us to prepare a message once (e.g. by traversing\n+/// a RecordBatch) and write it later. This can be helpful if you need to\n+/// compute the total size of a message before beginning to write it.\n+struct ARROW_EXPORT PreparedMessage {\n+  std::shared_ptr<Buffer> metadata;\n+\n+  // One or more buffers to be written end-to-end to form the message body,\n+  // including any padding to 8-byte offsets\n+  std::vector<std::shared_ptr<Buffer>> body_buffers;\n+\n+  // Body length to be populated by the producer of this message\n+  int64_t total_body_length;\n+\n+  int64_t GetTotalSize() const;\n+\n+  Status WriteTo(io::OutputStream* stream, int32_t* out_metadata_length,\n+                 int64_t* out_body_length) const;\n+};\n+\n /// \\class RecordBatchWriter\n /// \\brief Abstract interface for writing a stream of record batches\n class ARROW_EXPORT RecordBatchWriter {\n@@ -187,6 +209,21 @@ Status WriteRecordBatch(const RecordBatch& batch, int64_t buffer_start_offset,\n                         int max_recursion_depth = kMaxNestingDepth,\n                         bool allow_64bit = false);\n \n+/// \\brief Created a PreparedMessage from a RecordBatch, which can later be\n+/// written to an OutputStream\n+ARROW_EXPORT\n+Status PrepareRecordBatchMessage(const RecordBatch& batch, MemoryPool* pool,\n+                                 PreparedMessage* message,\n+                                 int max_recursion_depth = kMaxNestingDepth);\n+\n+/// \\brief Created a PreparedMessage from an array representing a\n+/// DictionaryBatch, which can later be written to an OutputStream\n+ARROW_EXPORT\n+Status PrepareDictionaryMessage(int64_t dictionary_id,\n+                                const std::shared_ptr<Array>& dictionary,\n+                                MemoryPool* pool, PreparedMessage* message,\n+                                int max_recursion_depth = kMaxNestingDepth);\n+\n /// \\brief Serialize record batch as encapsulated IPC message in a new buffer\n ///\n /// \\param[in] batch the record batch\n@@ -269,6 +306,11 @@ ARROW_EXPORT\n Status WriteTensor(const Tensor& tensor, io::OutputStream* dst, int32_t* metadata_length,\n                    int64_t* body_length);\n \n+/// \\brief Create a PreparedMessage from a Tensor, which can later be\n+/// written to an OutputStream\n+ARROW_EXPORT\n+Status PrepareTensorMessage(const Tensor& tensor, MemoryPool* pool, PreparedMessage* out);\n+\n }  // namespace ipc\n }  // namespace arrow\n \n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-06-29T16:13:34.735+0000",
                    "updated": "2018-06-29T16:13:34.735+0000",
                    "started": "2018-06-29T16:13:34.735+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "117438",
                    "issueId": "13120792"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": 1800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@5246df5[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@79d27f8f[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@60a7d851[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@a63fdcd[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@57a59bd9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@438e300b[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1db50d7b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@8ad1695[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@73ad2f0a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@4191571c[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@74fa4480[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@1403ed34[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 1800,
        "customfield_12312520": null,
        "customfield_12312521": "Fri Sep 21 18:20:36 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-09-21T18:20:36.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1860/watchers",
            "watchCount": 4,
            "isWatching": false
        },
        "created": "2017-11-26T16:43:59.000+0000",
        "updated": "2018-09-21T18:20:40.000+0000",
        "timeoriginalestimate": null,
        "description": "Currently, when you need to pre-allocate space for a record batch or a stream (schema + dictionaries + record batches), you must make multiple passes over the data structures of interest (and use e.g. {{MockOutputStream}} to compute the size of the output buffer). It would be useful to make a single pass to \"prepare\" the IPC payload for both sizing and writing to prevent having to make multiple passes",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "0.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 1800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/attachment/12902454",
                "id": "12902454",
                "filename": "text.html",
                "author": {
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=Brian.Bowman%40sas.com",
                    "name": "Brian.Bowman@sas.com",
                    "key": "brian.bowman@sas.com",
                    "avatarUrls": {
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                        "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                        "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                    },
                    "displayName": "Brian Bowman",
                    "active": true,
                    "timeZone": "Etc/UTC"
                },
                "created": "2017-12-15T22:14:00.377+0000",
                "size": 2132,
                "mimeType": "text/html",
                "content": "https://issues.apache.org/jira/secure/attachment/12902454/text.html"
            }
        ],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Add data structure to \"stage\" a sequence of IPC messages from in-memory data",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16330782",
                    "id": "16330782",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "[~1xuepanchen1] I'm going to take a look at this if you don't mind. There are some nuances in the IPC writer around handling sliced bitmaps (see https://github.com/apache/arrow/blob/master/cpp/src/arrow/ipc/writer.cc#L125), and I want to see if we can improve the write performance in microbenchmarks while doing this refactoring",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-01-18T17:08:14.091+0000",
                    "updated": "2018-01-18T17:08:14.091+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16337899",
                    "id": "16337899",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I'm running into a slight issue with this refactoring around output streams which are currently at a position that is not a multiple of 8. \r\n\r\nsee https://github.com/apache/arrow/blob/master/cpp/src/arrow/ipc/metadata-internal.cc#L903\r\n\r\nThis results in the entire message payload being non-deterministic depending on the state of the OutputStream. I don't think it will impact any applications, but I suggest we write padding bytes at the _start_ to an 8-byte offset and then begin writing the message. This is the same approach used by {{WriteTensor}} in https://github.com/apache/arrow/blob/master/cpp/src/arrow/ipc/writer.cc#L621. \r\n\r\n[~robertnishihara] [~pcmoritz] [~xhochy] does this seem reasonable?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-01-24T17:06:06.874+0000",
                    "updated": "2018-01-24T17:06:06.874+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16338164",
                    "id": "16338164",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm opened a new pull request #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500\n \n \n   The purpose of this is to decompose a record batch into its serialized Flatbuffer metadata and sequence of buffers that form its body so that the total output size can be computed, e.g. for writing to a shared memory segment. Prior to this, one would have to call `GetRecordBatchSize`, allocate memory, then `WriteRecordBatch` which duplicates work. \r\n   \r\n   This also introduces a change to how padding is handled in unaligned streams to make the message contents deterministic. This makes record batches consistent with the way that tensors were already being written, with alignment bytes being written first to move the stream position to a multiple of 8, then beginning to write the metadata and message body.\r\n   \r\n   The unaligned stream case isn't being handled consistently on the read path yet, so I'll fix that and add a test. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-01-24T20:23:48.236+0000",
                    "updated": "2018-01-24T20:23:48.236+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16338267",
                    "id": "16338267",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500#issuecomment-360281545\n \n \n   Handled alignment on the read side, also. One question this brings up is whether the Java stream writer writes padded / aligned messages. I believe it does (this is checked for in C++: https://github.com/apache/arrow/blob/master/cpp/src/arrow/ipc/writer.cc#L854). But we should make sure. This is a case where having the Spark integration tests would be really helpful (cc @BryanCutler @icexelloss) \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-01-24T21:36:27.565+0000",
                    "updated": "2018-01-24T21:36:27.565+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16361514",
                    "id": "16361514",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500#issuecomment-365077357\n \n \n   Picking this up again\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-02-12T22:00:36.620+0000",
                    "updated": "2018-02-12T22:00:36.620+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16361562",
                    "id": "16361562",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500#issuecomment-365091190\n \n \n   So it seems that not all Python file objects support the `tell` operation, for example the `_io.BufferedReader` that you get calling `makefile` on a socket. That's the last issue here -- I think probably the best way to deal with this is to implement a `PyInputStream` in https://github.com/apache/arrow/blob/master/cpp/src/arrow/python/io.h and handle the stream position bookkeeping internally, if that sounds good to folks\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-02-12T22:53:44.544+0000",
                    "updated": "2018-02-12T22:53:44.544+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16394781",
                    "id": "16394781",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Moving this to 0.10.0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-03-12T03:46:01.616+0000",
                    "updated": "2018-03-12T03:46:01.616+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16432016",
                    "id": "16432016",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "pitrou commented on issue #1500: ARROW-1860: [C++] Introduce ipc::PreparedMessage data structure to avoid making multiple passes over record batches\nURL: https://github.com/apache/arrow/pull/1500#issuecomment-380045557\n \n \n   > So it seems that not all Python file objects support the tell operation, for example the _io.BufferedReader that you get calling makefile on a socket.\r\n   \r\n   Yes, non-seekable files generally don't support tell() either.\r\n   I'm a bit surprised that you need this: if writing to a generic output stream, why do you want to pad data? Padding only sounds useful when writing to a true random access file that may be e.g. memory-mapped.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-10T10:04:17.407+0000",
                    "updated": "2018-04-10T10:04:17.407+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16598010",
                    "id": "16598010",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I will need to revisit this in the context of Flight RPC, where this data structure may be used to coordinate writes onto the GRPC output stream",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-08-30T22:48:00.465+0000",
                    "updated": "2018-08-30T22:48:00.465+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13120792/comment/16624001",
                    "id": "16624001",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Resolved in https://github.com/apache/arrow/commit/db0ef22dd68ae00e11f09da40b6734c1d9770b57#diff-caf39e9e4747cfd6c97822e76dbac4e5",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-09-21T18:20:36.164+0000",
                    "updated": "2018-09-21T18:20:36.164+0000"
                }
            ],
            "maxResults": 10,
            "total": 10,
            "startAt": 0
        },
        "customfield_12311820": "0|i3n71b:",
        "customfield_12314139": null
    }
}