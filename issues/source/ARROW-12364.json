{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13372051",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051",
    "key": "ARROW-12364",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12349983",
                "id": "12349983",
                "description": "",
                "name": "5.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-07-28"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "dataset",
            "parquet",
            "pull-request-available",
            "python"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12348823",
                "id": "12348823",
                "description": "",
                "name": "3.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-01-25"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12617913",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12617913",
                "type": {
                    "id": "12310660",
                    "name": "Completes",
                    "inward": "is fixed by",
                    "outward": "fixes",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310660"
                },
                "inwardIssue": {
                    "id": "13338137",
                    "key": "ARROW-10440",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13338137",
                    "fields": {
                        "summary": "[C++][Dataset][Python] Add a callback to visit file writers just before Finish()",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
            "name": "westonpace",
            "key": "westonpace",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Weston Pace",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12337837",
                "id": "12337837",
                "name": "Parquet"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ldacey",
            "name": "ldacey",
            "key": "ldacey",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Lance Dacey",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ldacey",
            "name": "ldacey",
            "key": "ldacey",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Lance Dacey",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 21600,
            "total": 21600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 21600,
            "total": 21600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12364/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 36,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/616921",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace opened a new pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628\n\n\n   Created writer_post_finish (similar to writer_pre_finish) to visit dataset-created files after Finish.  Added a similar file_visitor concept to pyarrow which maps to writer_post_finish.  Connected the legacy metadata_collector to the file_visitor so that parquet datasets created with use_legacy_dataset=True can support metadata_collector.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-06-30T04:29:59.444+0000",
                    "updated": "2021-06-30T04:29:59.444+0000",
                    "started": "2021-06-30T04:29:59.444+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "616921",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/616922",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#issuecomment-871086977\n\n\n   https://issues.apache.org/jira/browse/ARROW-12364\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-06-30T04:30:24.327+0000",
                    "updated": "2021-06-30T04:30:24.327+0000",
                    "started": "2021-06-30T04:30:24.327+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "616922",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/616965",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#issuecomment-871209883\n\n\n   This PR now includes #10619 .  Some notes for review:\r\n   \r\n    * Ben and I took parallel approaches at this.  Ben's approach was to mirror the C++ API and create a FileWriter to wrap CFileWriter.  My approach was to create a WrittenFile class which is just the path & metadata (if present) and expose that as `file_visitor`.  I'm happy to switch if we feel the other is better.  My rationale was \"FileWriter is an internal class, best to hide the concept and only expose what is needed.\"\r\n    * The existing metadata_collector is a bit clunky when working with partitioned datasets.  The _metadata file does not contain the partition columns.  This does appear to be the intent (with common_metadata, if it exists, containing the full schema) but without a working spark/hadoop setup I can't be completely certain.\r\n    * The existing tests for metadata_collector were calling write_dataset on the same directory multiple times and expecting multiple files to be created (since the legacy writer uses a guid for naming).  This seems somewhat related to ARROW-12358.  I just updated the test to call write_dataset once with a partitioned column.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-06-30T08:40:54.098+0000",
                    "updated": "2021-06-30T08:40:54.098+0000",
                    "started": "2021-06-30T08:40:54.098+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "616965",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/616966",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace edited a comment on pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#issuecomment-871209883\n\n\n   This PR now includes #10619 .  Some notes for review:\r\n   \r\n    * Ben and I took parallel approaches at this.  Ben's approach was to mirror the C++ API and create a FileWriter to wrap CFileWriter.  My approach was to create a WrittenFile class which is just the path & metadata (if present) and expose that as `file_visitor`.  I'm happy to switch if we feel the other is better.  My rationale was \"FileWriter is an internal class, best to hide the concept and only expose what is needed.\"\r\n    * ARROW-10440 added a visitor to be called right before finish was called on a file.  For metadata_collector to work I needed to create a visitor that is called right after finish is called on the file so I added the second visitor as part of this PR.\r\n    * The existing metadata_collector is a bit clunky when working with partitioned datasets.  The _metadata file does not contain the partition columns.  This does appear to be the intent (with common_metadata, if it exists, containing the full schema) but without a working spark/hadoop setup I can't be completely certain.\r\n    * The existing tests for metadata_collector were calling write_dataset on the same directory multiple times and expecting multiple files to be created (since the legacy writer uses a guid for naming).  This seems somewhat related to ARROW-12358.  I just updated the test to call write_dataset once with a partitioned column.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-06-30T08:42:44.569+0000",
                    "updated": "2021-06-30T08:42:44.569+0000",
                    "started": "2021-06-30T08:42:44.569+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "616966",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/617243",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#issuecomment-871678908\n\n\n   @bkietz @jorisvandenbossche would appreciate any review if you have time.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-06-30T19:44:20.750+0000",
                    "updated": "2021-06-30T19:44:20.750+0000",
                    "started": "2021-06-30T19:44:20.749+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "617243",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/617266",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r661774861\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3025,14 +3072,68 @@ def _filesystemdataset_write(\n         CFileSystemDatasetWriteOptions c_options\n         shared_ptr[CScanner] c_scanner\n         vector[shared_ptr[CRecordBatch]] c_batches\n+        dict visit_args\n+        function[cb_writer_finish] c_post_finish_cb\n \n     c_options.file_write_options = file_options.unwrap()\n     c_options.filesystem = filesystem.unwrap()\n     c_options.base_dir = tobytes(_stringify_path(base_dir))\n     c_options.partitioning = partitioning.unwrap()\n     c_options.max_partitions = max_partitions\n     c_options.basename_template = tobytes(basename_template)\n+    c_post_finish_cb = _filesystemdataset_write_visitor\n\nReview comment:\n       This seems to be unused\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3095,10 +3104,24 @@ def test_write_dataset_use_threads(tempdir):\n         pa.schema([(\"part\", pa.string())]), flavor=\"hive\")\n \n     target1 = tempdir / 'partitioned1'\n+    paths_written = []\n+\n+    def file_visitor(written_file):\n+        paths_written.append(written_file.path)\n+\n     ds.write_dataset(\n         dataset, target1, format=\"feather\", partitioning=partitioning,\n-        use_threads=True\n+        use_threads=True, file_visitor=file_visitor\n     )\n+    expected_paths = [\n+        target1 / 'part=a' / 'part-0.feather',\n+        target1 / 'part=a' / 'part-1.feather',\n+        target1 / 'part=b' / 'part-0.feather',\n+        target1 / 'part=b' / 'part-1.feather'\n+    ]\n+    for path in paths_written:\n+        assert pathlib.Path(path) in expected_paths\n\nReview comment:\n       This technically only requires that paths_written is a subset of expected_paths\r\n   ```suggestion\r\n       assert set(map(pathlib.Path, paths_written)) == {\r\n           target1 / 'part=a' / 'part-0.feather',\r\n           target1 / 'part=a' / 'part-1.feather',\r\n           target1 / 'part=b' / 'part-0.feather',\r\n           target1 / 'part=b' / 'part-1.feather',\r\n       }\r\n   ```\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3025,14 +3072,68 @@ def _filesystemdataset_write(\n         CFileSystemDatasetWriteOptions c_options\n         shared_ptr[CScanner] c_scanner\n         vector[shared_ptr[CRecordBatch]] c_batches\n+        dict visit_args\n+        function[cb_writer_finish] c_post_finish_cb\n \n     c_options.file_write_options = file_options.unwrap()\n     c_options.filesystem = filesystem.unwrap()\n     c_options.base_dir = tobytes(_stringify_path(base_dir))\n     c_options.partitioning = partitioning.unwrap()\n     c_options.max_partitions = max_partitions\n     c_options.basename_template = tobytes(basename_template)\n+    c_post_finish_cb = _filesystemdataset_write_visitor\n+    if file_visitor is not None:\n+        visit_args = {'base_dir': c_options.base_dir,\n+                      'file_visitor': file_visitor}\n+        c_options.writer_post_finish = BindFunction[cb_writer_finish_internal](\n+            &_filesystemdataset_write_visitor, visit_args)\n \n     c_scanner = data.unwrap()\n     with nogil:\n         check_status(CFileSystemDataset.Write(c_options, c_scanner))\n+\n+\n+# basic test to roundtrip through a BoundFunction\n\nReview comment:\n       This should probably be moved to `_common.pyx`, or maybe inlined in `test_cython.py`\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3009,6 +3009,52 @@ def _get_partition_keys(Expression partition_expression):\n     return out\n \n \n+ctypedef CParquetFileWriter* _CParquetFileWriterPtr\n+\n+cdef class WrittenFile(_Weakrefable):\n+    \"\"\"\n+    Metadata information about files written as\n+    part of a dataset write operation\n+    \"\"\"\n+\n+    \"\"\"The full path to the created file\"\"\"\n+    cdef public str path\n+    \"\"\"If the file is a parquet file this will contain the parquet metadata\"\"\"\n+    cdef public object metadata\n+\n+    def __init__(self, path, metadata):\n+        self.path = path\n+        self.metadata = metadata\n+\n+cdef void _filesystemdataset_write_visitor(\n+        dict visit_args,\n+        CFileWriter* file_writer):\n+    cdef:\n+        str path\n+        str base_dir\n+        WrittenFile written_file\n+        FileMetaData parquet_metadata\n+        CParquetFileWriter* parquet_file_writer\n+\n+    if file_writer == nullptr:\n\nReview comment:\n       When would this happen? That seems like it should be considered a pure error on the part of FileSystemDataset::Write\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3009,6 +3009,52 @@ def _get_partition_keys(Expression partition_expression):\n     return out\n \n \n+ctypedef CParquetFileWriter* _CParquetFileWriterPtr\n+\n+cdef class WrittenFile(_Weakrefable):\n+    \"\"\"\n+    Metadata information about files written as\n+    part of a dataset write operation\n+    \"\"\"\n+\n+    \"\"\"The full path to the created file\"\"\"\n+    cdef public str path\n+    \"\"\"If the file is a parquet file this will contain the parquet metadata\"\"\"\n+    cdef public object metadata\n+\n+    def __init__(self, path, metadata):\n+        self.path = path\n+        self.metadata = metadata\n+\n+cdef void _filesystemdataset_write_visitor(\n+        dict visit_args,\n+        CFileWriter* file_writer):\n+    cdef:\n+        str path\n+        str base_dir\n+        WrittenFile written_file\n+        FileMetaData parquet_metadata\n+        CParquetFileWriter* parquet_file_writer\n+\n+    if file_writer == nullptr:\n+        return\n+\n+    parquet_metadata = None\n+    path = frombytes(deref(file_writer).destination().path)\n+    base_dir = frombytes(visit_args['base_dir'])\n\nReview comment:\n       please move this into the `if metadata:` block, since it's only used there\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3009,6 +3009,52 @@ def _get_partition_keys(Expression partition_expression):\n     return out\n \n \n+ctypedef CParquetFileWriter* _CParquetFileWriterPtr\n+\n+cdef class WrittenFile(_Weakrefable):\n\nReview comment:\n       Since this is essentially a named tuple with optional properties based on the format, I think it'd be better to just use a `dict` instead\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-06-30T20:32:05.601+0000",
                    "updated": "2021-06-30T20:32:05.601+0000",
                    "started": "2021-06-30T20:32:05.600+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "617266",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/618282",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r663270490\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3025,14 +3072,68 @@ def _filesystemdataset_write(\n         CFileSystemDatasetWriteOptions c_options\n         shared_ptr[CScanner] c_scanner\n         vector[shared_ptr[CRecordBatch]] c_batches\n+        dict visit_args\n+        function[cb_writer_finish] c_post_finish_cb\n \n     c_options.file_write_options = file_options.unwrap()\n     c_options.filesystem = filesystem.unwrap()\n     c_options.base_dir = tobytes(_stringify_path(base_dir))\n     c_options.partitioning = partitioning.unwrap()\n     c_options.max_partitions = max_partitions\n     c_options.basename_template = tobytes(basename_template)\n+    c_post_finish_cb = _filesystemdataset_write_visitor\n\nReview comment:\n       Removed.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-02T22:28:52.309+0000",
                    "updated": "2021-07-02T22:28:52.309+0000",
                    "started": "2021-07-02T22:28:52.309+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "618282",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/618283",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r663270720\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3025,14 +3072,68 @@ def _filesystemdataset_write(\n         CFileSystemDatasetWriteOptions c_options\n         shared_ptr[CScanner] c_scanner\n         vector[shared_ptr[CRecordBatch]] c_batches\n+        dict visit_args\n+        function[cb_writer_finish] c_post_finish_cb\n \n     c_options.file_write_options = file_options.unwrap()\n     c_options.filesystem = filesystem.unwrap()\n     c_options.base_dir = tobytes(_stringify_path(base_dir))\n     c_options.partitioning = partitioning.unwrap()\n     c_options.max_partitions = max_partitions\n     c_options.basename_template = tobytes(basename_template)\n+    c_post_finish_cb = _filesystemdataset_write_visitor\n+    if file_visitor is not None:\n+        visit_args = {'base_dir': c_options.base_dir,\n+                      'file_visitor': file_visitor}\n+        c_options.writer_post_finish = BindFunction[cb_writer_finish_internal](\n+            &_filesystemdataset_write_visitor, visit_args)\n \n     c_scanner = data.unwrap()\n     with nogil:\n         check_status(CFileSystemDataset.Write(c_options, c_scanner))\n+\n+\n+# basic test to roundtrip through a BoundFunction\n\nReview comment:\n       I just got rid of this.  It came along with your experiment and I don't know that we really need it.  Now that BindFunction is actually used we test it indirectly that way.\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3009,6 +3009,52 @@ def _get_partition_keys(Expression partition_expression):\n     return out\n \n \n+ctypedef CParquetFileWriter* _CParquetFileWriterPtr\n+\n+cdef class WrittenFile(_Weakrefable):\n+    \"\"\"\n+    Metadata information about files written as\n+    part of a dataset write operation\n+    \"\"\"\n+\n+    \"\"\"The full path to the created file\"\"\"\n+    cdef public str path\n+    \"\"\"If the file is a parquet file this will contain the parquet metadata\"\"\"\n+    cdef public object metadata\n+\n+    def __init__(self, path, metadata):\n+        self.path = path\n+        self.metadata = metadata\n+\n+cdef void _filesystemdataset_write_visitor(\n+        dict visit_args,\n+        CFileWriter* file_writer):\n+    cdef:\n+        str path\n+        str base_dir\n+        WrittenFile written_file\n+        FileMetaData parquet_metadata\n+        CParquetFileWriter* parquet_file_writer\n+\n+    if file_writer == nullptr:\n+        return\n+\n+    parquet_metadata = None\n+    path = frombytes(deref(file_writer).destination().path)\n+    base_dir = frombytes(visit_args['base_dir'])\n\nReview comment:\n       Done.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-02T22:29:37.613+0000",
                    "updated": "2021-07-02T22:29:37.613+0000",
                    "started": "2021-07-02T22:29:37.613+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "618283",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/618284",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r663271097\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3009,6 +3009,52 @@ def _get_partition_keys(Expression partition_expression):\n     return out\n \n \n+ctypedef CParquetFileWriter* _CParquetFileWriterPtr\n+\n+cdef class WrittenFile(_Weakrefable):\n+    \"\"\"\n+    Metadata information about files written as\n+    part of a dataset write operation\n+    \"\"\"\n+\n+    \"\"\"The full path to the created file\"\"\"\n+    cdef public str path\n+    \"\"\"If the file is a parquet file this will contain the parquet metadata\"\"\"\n+    cdef public object metadata\n+\n+    def __init__(self, path, metadata):\n+        self.path = path\n+        self.metadata = metadata\n+\n+cdef void _filesystemdataset_write_visitor(\n+        dict visit_args,\n+        CFileWriter* file_writer):\n+    cdef:\n+        str path\n+        str base_dir\n+        WrittenFile written_file\n+        FileMetaData parquet_metadata\n+        CParquetFileWriter* parquet_file_writer\n+\n+    if file_writer == nullptr:\n\nReview comment:\n       Yep, I was thinking of writing a dataset to something other than a filesystem but there is no reason to think it would use a the same method.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-02T22:31:01.456+0000",
                    "updated": "2021-07-02T22:31:01.456+0000",
                    "started": "2021-07-02T22:31:01.456+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "618284",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/618285",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r663271279\n\n\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3095,10 +3104,24 @@ def test_write_dataset_use_threads(tempdir):\n         pa.schema([(\"part\", pa.string())]), flavor=\"hive\")\n \n     target1 = tempdir / 'partitioned1'\n+    paths_written = []\n+\n+    def file_visitor(written_file):\n+        paths_written.append(written_file.path)\n+\n     ds.write_dataset(\n         dataset, target1, format=\"feather\", partitioning=partitioning,\n-        use_threads=True\n+        use_threads=True, file_visitor=file_visitor\n     )\n+    expected_paths = [\n+        target1 / 'part=a' / 'part-0.feather',\n+        target1 / 'part=a' / 'part-1.feather',\n+        target1 / 'part=b' / 'part-0.feather',\n+        target1 / 'part=b' / 'part-1.feather'\n+    ]\n+    for path in paths_written:\n+        assert pathlib.Path(path) in expected_paths\n\nReview comment:\n       That was intentional.  Only two paths are written but I don't know if part-0.feather goes in part=a or part=b (since it is multithreaded).  I refined the check to be a little clearer and added a comment.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-02T22:31:56.706+0000",
                    "updated": "2021-07-02T22:31:56.706+0000",
                    "started": "2021-07-02T22:31:56.706+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "618285",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/618287",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r663271957\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -3009,6 +3009,52 @@ def _get_partition_keys(Expression partition_expression):\n     return out\n \n \n+ctypedef CParquetFileWriter* _CParquetFileWriterPtr\n+\n+cdef class WrittenFile(_Weakrefable):\n\nReview comment:\n       Hmm...I'm not sure I agree.  The same could be said of ReadOptions, ParseOptions, etc.  Since this is part of the public API and the available keys are well defined I think it best to create a class so it can be documented and communicated exactly what should be provided.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-02T22:34:37.511+0000",
                    "updated": "2021-07-02T22:34:37.511+0000",
                    "started": "2021-07-02T22:34:37.511+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "618287",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/618289",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#issuecomment-873287330\n\n\n   Thanks for the review @bkietz.  I've addressed the changes you requested.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-02T22:35:25.102+0000",
                    "updated": "2021-07-02T22:35:25.102+0000",
                    "started": "2021-07-02T22:35:25.101+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "618289",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/618683",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r663986392\n\n\n\n##########\nFile path: python/pyarrow/parquet.py\n##########\n@@ -1958,8 +1958,11 @@ def write_to_dataset(table, root_path, partition_cols=None,\n             \"implementation.\"\n         )\n         metadata_collector = kwargs.pop('metadata_collector', None)\n+        file_visitor = None\n         if metadata_collector is not None:\n-            raise ValueError(msg.format(\"metadata_collector\"))\n+            def file_visitor(written_file):\n+                if written_file.metadata:\n\nReview comment:\n       Is this `if` check needed (in theory)? Since this will always be parquet files in this case\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2672,47 +2672,56 @@ def test_feather_format(tempdir, dataset_reader):\n         dataset_reader.to_table(ds.dataset(basedir, format=\"feather\"))\n \n \n-def _create_parquet_dataset_simple(root_path):\n+def _create_parquet_dataset_simple(root_path, use_legacy_dataset):\n     import pyarrow.parquet as pq\n \n     metadata_collector = []\n \n-    for i in range(4):\n-        table = pa.table({'f1': [i] * 10, 'f2': np.random.randn(10)})\n-        pq.write_to_dataset(\n-            table, str(root_path), metadata_collector=metadata_collector\n-        )\n+    f1_vals = [item for chunk in range(4) for item in [chunk] * 10]\n+\n+    table = pa.table({'f1': f1_vals, 'f2': np.random.randn(40)})\n+    pq.write_to_dataset(\n+        table, str(root_path), partition_cols=['f1'],\n+        use_legacy_dataset=use_legacy_dataset,\n+        metadata_collector=metadata_collector\n+    )\n+\n+    partitionless_schema = pa.schema([pa.field('f2', pa.float64())])\n \n     metadata_path = str(root_path / '_metadata')\n     # write _metadata file\n     pq.write_metadata(\n-        table.schema, metadata_path,\n+        partitionless_schema, metadata_path,\n         metadata_collector=metadata_collector\n     )\n-    return metadata_path, table\n+    return metadata_path, partitionless_schema\n \n \n @pytest.mark.parquet\n @pytest.mark.pandas  # write_to_dataset currently requires pandas\n-def test_parquet_dataset_factory(tempdir):\n+@pytest.mark.parametrize('use_legacy_dataset', [False, True])\n+def test_parquet_dataset_factory(tempdir, use_legacy_dataset):\n     root_path = tempdir / \"test_parquet_dataset\"\n-    metadata_path, table = _create_parquet_dataset_simple(root_path)\n+    metadata_path, partitionless_schema = _create_parquet_dataset_simple(\n+        root_path, use_legacy_dataset)\n     dataset = ds.parquet_dataset(metadata_path)\n-    assert dataset.schema.equals(table.schema)\n+    assert dataset.schema.equals(partitionless_schema)\n\nReview comment:\n       This doesn't seem right to me? I think the dataset's schema should include the partition columns?\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -731,6 +731,9 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         (e.g. S3)\n     max_partitions : int, default 1024\n         Maximum number of partitions any batch may be written into.\n+    file_visitor : Function\n+        If set, this function will be called with a WrittenFile instance\n+        for each file created during the call.\n\nReview comment:\n       Should we also mention that the Parquet metadata has been updated with the written file path?\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -731,6 +731,9 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         (e.g. S3)\n     max_partitions : int, default 1024\n         Maximum number of partitions any batch may be written into.\n+    file_visitor : Function\n+        If set, this function will be called with a WrittenFile instance\n+        for each file created during the call.\n\nReview comment:\n       Since \"WrittenFile\" is not a generally know pyarrow class, I would give a bit more details on this (eg the fact that you can get the path and (if parquet) metadata. \r\n   \r\n   And maybe also give an example use case, something like \"For example, this enables to collect the paths or metadata of all written files\"\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2672,47 +2672,56 @@ def test_feather_format(tempdir, dataset_reader):\n         dataset_reader.to_table(ds.dataset(basedir, format=\"feather\"))\n \n \n-def _create_parquet_dataset_simple(root_path):\n+def _create_parquet_dataset_simple(root_path, use_legacy_dataset):\n     import pyarrow.parquet as pq\n \n     metadata_collector = []\n \n-    for i in range(4):\n-        table = pa.table({'f1': [i] * 10, 'f2': np.random.randn(10)})\n-        pq.write_to_dataset(\n-            table, str(root_path), metadata_collector=metadata_collector\n-        )\n+    f1_vals = [item for chunk in range(4) for item in [chunk] * 10]\n+\n+    table = pa.table({'f1': f1_vals, 'f2': np.random.randn(40)})\n+    pq.write_to_dataset(\n+        table, str(root_path), partition_cols=['f1'],\n+        use_legacy_dataset=use_legacy_dataset,\n+        metadata_collector=metadata_collector\n+    )\n+\n+    partitionless_schema = pa.schema([pa.field('f2', pa.float64())])\n \n     metadata_path = str(root_path / '_metadata')\n     # write _metadata file\n     pq.write_metadata(\n-        table.schema, metadata_path,\n+        partitionless_schema, metadata_path,\n\nReview comment:\n       Is this change needed?\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2810,11 +2819,11 @@ def test_parquet_dataset_lazy_filtering(tempdir, open_logging_fs):\n \n     # filtering fragments should not open any file\n     with assert_opens([]):\n-        list(dataset.get_fragments(ds.field(\"f1\") > 15))\n+        list(dataset.get_fragments(ds.field(\"f2\") > 15))\n\nReview comment:\n       The \"f2\" column is random normal around 0, so this filter will never yield anything\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3269,8 +3308,19 @@ def test_write_dataset_parquet(tempdir):\n \n     # using default \"parquet\" format string\n \n+    files_correct_metadata = 0\n+\n+    def file_visitor(written_file):\n+        nonlocal files_correct_metadata\n+        if (written_file.metadata is not None and\n+                written_file.metadata.num_columns == 3):\n+            files_correct_metadata += 1\n\nReview comment:\n       Can you maybe move this into a separate test? (it makes reading the current test for basic functionality a bit complicated IMO)\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2795,7 +2804,7 @@ def test_parquet_dataset_lazy_filtering(tempdir, open_logging_fs):\n     # created with ParquetDatasetFactory from a _metadata file\n \n     root_path = tempdir / \"test_parquet_dataset_lazy_filtering\"\n-    metadata_path, _ = _create_parquet_dataset_simple(root_path)\n+    metadata_path, _ = _create_parquet_dataset_simple(root_path, True)\n\nReview comment:\n       You can also add a default for this keyword in the helper function\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3130,19 +3159,29 @@ def test_write_table(tempdir):\n \n     # with partitioning\n     base_dir = tempdir / 'partitioned'\n+    expected_paths = [\n+        base_dir / \"part=a\", base_dir / \"part=a\" / \"dat_0.arrow\",\n+        base_dir / \"part=b\", base_dir / \"part=b\" / \"dat_1.arrow\"\n+    ]\n+\n+    visited_paths = []\n+\n+    def file_visitor(written_file):\n+        nonlocal visited_paths\n\nReview comment:\n       Is this `nonlocal` needed?\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3095,10 +3104,30 @@ def test_write_dataset_use_threads(tempdir):\n         pa.schema([(\"part\", pa.string())]), flavor=\"hive\")\n \n     target1 = tempdir / 'partitioned1'\n+    paths_written = []\n+\n+    def file_visitor(written_file):\n+        print(f'Visiting {written_file.path}')\n\nReview comment:\n       We should probably remove this print statement at the end before merging? \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-05T15:00:19.879+0000",
                    "updated": "2021-07-05T15:00:19.879+0000",
                    "started": "2021-07-05T15:00:19.879+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "618683",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/619015",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r663986392\n\n\n\n##########\nFile path: python/pyarrow/parquet.py\n##########\n@@ -1958,8 +1958,11 @@ def write_to_dataset(table, root_path, partition_cols=None,\n             \"implementation.\"\n         )\n         metadata_collector = kwargs.pop('metadata_collector', None)\n+        file_visitor = None\n         if metadata_collector is not None:\n-            raise ValueError(msg.format(\"metadata_collector\"))\n+            def file_visitor(written_file):\n+                if written_file.metadata:\n\nReview comment:\n       Is this `if` check needed (in theory)? Since this will always be parquet files in this case\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2672,47 +2672,56 @@ def test_feather_format(tempdir, dataset_reader):\n         dataset_reader.to_table(ds.dataset(basedir, format=\"feather\"))\n \n \n-def _create_parquet_dataset_simple(root_path):\n+def _create_parquet_dataset_simple(root_path, use_legacy_dataset):\n     import pyarrow.parquet as pq\n \n     metadata_collector = []\n \n-    for i in range(4):\n-        table = pa.table({'f1': [i] * 10, 'f2': np.random.randn(10)})\n-        pq.write_to_dataset(\n-            table, str(root_path), metadata_collector=metadata_collector\n-        )\n+    f1_vals = [item for chunk in range(4) for item in [chunk] * 10]\n+\n+    table = pa.table({'f1': f1_vals, 'f2': np.random.randn(40)})\n+    pq.write_to_dataset(\n+        table, str(root_path), partition_cols=['f1'],\n+        use_legacy_dataset=use_legacy_dataset,\n+        metadata_collector=metadata_collector\n+    )\n+\n+    partitionless_schema = pa.schema([pa.field('f2', pa.float64())])\n \n     metadata_path = str(root_path / '_metadata')\n     # write _metadata file\n     pq.write_metadata(\n-        table.schema, metadata_path,\n+        partitionless_schema, metadata_path,\n         metadata_collector=metadata_collector\n     )\n-    return metadata_path, table\n+    return metadata_path, partitionless_schema\n \n \n @pytest.mark.parquet\n @pytest.mark.pandas  # write_to_dataset currently requires pandas\n-def test_parquet_dataset_factory(tempdir):\n+@pytest.mark.parametrize('use_legacy_dataset', [False, True])\n+def test_parquet_dataset_factory(tempdir, use_legacy_dataset):\n     root_path = tempdir / \"test_parquet_dataset\"\n-    metadata_path, table = _create_parquet_dataset_simple(root_path)\n+    metadata_path, partitionless_schema = _create_parquet_dataset_simple(\n+        root_path, use_legacy_dataset)\n     dataset = ds.parquet_dataset(metadata_path)\n-    assert dataset.schema.equals(table.schema)\n+    assert dataset.schema.equals(partitionless_schema)\n\nReview comment:\n       This doesn't seem right to me? I think the dataset's schema should include the partition columns?\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -731,6 +731,9 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         (e.g. S3)\n     max_partitions : int, default 1024\n         Maximum number of partitions any batch may be written into.\n+    file_visitor : Function\n+        If set, this function will be called with a WrittenFile instance\n+        for each file created during the call.\n\nReview comment:\n       Should we also mention that the Parquet metadata has been updated with the written file path?\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -731,6 +731,9 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         (e.g. S3)\n     max_partitions : int, default 1024\n         Maximum number of partitions any batch may be written into.\n+    file_visitor : Function\n+        If set, this function will be called with a WrittenFile instance\n+        for each file created during the call.\n\nReview comment:\n       Since \"WrittenFile\" is not a generally know pyarrow class, I would give a bit more details on this (eg the fact that you can get the path and (if parquet) metadata. \r\n   \r\n   And maybe also give an example use case, something like \"For example, this enables to collect the paths or metadata of all written files\"\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2672,47 +2672,56 @@ def test_feather_format(tempdir, dataset_reader):\n         dataset_reader.to_table(ds.dataset(basedir, format=\"feather\"))\n \n \n-def _create_parquet_dataset_simple(root_path):\n+def _create_parquet_dataset_simple(root_path, use_legacy_dataset):\n     import pyarrow.parquet as pq\n \n     metadata_collector = []\n \n-    for i in range(4):\n-        table = pa.table({'f1': [i] * 10, 'f2': np.random.randn(10)})\n-        pq.write_to_dataset(\n-            table, str(root_path), metadata_collector=metadata_collector\n-        )\n+    f1_vals = [item for chunk in range(4) for item in [chunk] * 10]\n+\n+    table = pa.table({'f1': f1_vals, 'f2': np.random.randn(40)})\n+    pq.write_to_dataset(\n+        table, str(root_path), partition_cols=['f1'],\n+        use_legacy_dataset=use_legacy_dataset,\n+        metadata_collector=metadata_collector\n+    )\n+\n+    partitionless_schema = pa.schema([pa.field('f2', pa.float64())])\n \n     metadata_path = str(root_path / '_metadata')\n     # write _metadata file\n     pq.write_metadata(\n-        table.schema, metadata_path,\n+        partitionless_schema, metadata_path,\n\nReview comment:\n       Is this change needed?\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2810,11 +2819,11 @@ def test_parquet_dataset_lazy_filtering(tempdir, open_logging_fs):\n \n     # filtering fragments should not open any file\n     with assert_opens([]):\n-        list(dataset.get_fragments(ds.field(\"f1\") > 15))\n+        list(dataset.get_fragments(ds.field(\"f2\") > 15))\n\nReview comment:\n       The \"f2\" column is random normal around 0, so this filter will never yield anything\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3269,8 +3308,19 @@ def test_write_dataset_parquet(tempdir):\n \n     # using default \"parquet\" format string\n \n+    files_correct_metadata = 0\n+\n+    def file_visitor(written_file):\n+        nonlocal files_correct_metadata\n+        if (written_file.metadata is not None and\n+                written_file.metadata.num_columns == 3):\n+            files_correct_metadata += 1\n\nReview comment:\n       Can you maybe move this into a separate test? (it makes reading the current test for basic functionality a bit complicated IMO)\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2795,7 +2804,7 @@ def test_parquet_dataset_lazy_filtering(tempdir, open_logging_fs):\n     # created with ParquetDatasetFactory from a _metadata file\n \n     root_path = tempdir / \"test_parquet_dataset_lazy_filtering\"\n-    metadata_path, _ = _create_parquet_dataset_simple(root_path)\n+    metadata_path, _ = _create_parquet_dataset_simple(root_path, True)\n\nReview comment:\n       You can also add a default for this keyword in the helper function\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3130,19 +3159,29 @@ def test_write_table(tempdir):\n \n     # with partitioning\n     base_dir = tempdir / 'partitioned'\n+    expected_paths = [\n+        base_dir / \"part=a\", base_dir / \"part=a\" / \"dat_0.arrow\",\n+        base_dir / \"part=b\", base_dir / \"part=b\" / \"dat_1.arrow\"\n+    ]\n+\n+    visited_paths = []\n+\n+    def file_visitor(written_file):\n+        nonlocal visited_paths\n\nReview comment:\n       Is this `nonlocal` needed?\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3095,10 +3104,30 @@ def test_write_dataset_use_threads(tempdir):\n         pa.schema([(\"part\", pa.string())]), flavor=\"hive\")\n \n     target1 = tempdir / 'partitioned1'\n+    paths_written = []\n+\n+    def file_visitor(written_file):\n+        print(f'Visiting {written_file.path}')\n\nReview comment:\n       We should probably remove this print statement at the end before merging? \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-06T11:01:31.744+0000",
                    "updated": "2021-07-06T11:01:31.744+0000",
                    "started": "2021-07-06T11:01:31.743+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "619015",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/619891",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r665248325\n\n\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -731,6 +731,9 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         (e.g. S3)\n     max_partitions : int, default 1024\n         Maximum number of partitions any batch may be written into.\n+    file_visitor : Function\n+        If set, this function will be called with a WrittenFile instance\n+        for each file created during the call.\n\nReview comment:\n       I added a bit more details as suggested.  I added the bit about the parquet metadata and the written file path in the WrittenFile.metadata docstring.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-07T10:31:51.117+0000",
                    "updated": "2021-07-07T10:31:51.117+0000",
                    "started": "2021-07-07T10:31:51.117+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "619891",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/619892",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r665248434\n\n\n\n##########\nFile path: python/pyarrow/parquet.py\n##########\n@@ -1958,8 +1958,11 @@ def write_to_dataset(table, root_path, partition_cols=None,\n             \"implementation.\"\n         )\n         metadata_collector = kwargs.pop('metadata_collector', None)\n+        file_visitor = None\n         if metadata_collector is not None:\n-            raise ValueError(msg.format(\"metadata_collector\"))\n+            def file_visitor(written_file):\n+                if written_file.metadata:\n\nReview comment:\n       I suppose not, I have removed it.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-07T10:32:04.490+0000",
                    "updated": "2021-07-07T10:32:04.490+0000",
                    "started": "2021-07-07T10:32:04.490+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "619892",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/619893",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r665249658\n\n\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2672,47 +2672,56 @@ def test_feather_format(tempdir, dataset_reader):\n         dataset_reader.to_table(ds.dataset(basedir, format=\"feather\"))\n \n \n-def _create_parquet_dataset_simple(root_path):\n+def _create_parquet_dataset_simple(root_path, use_legacy_dataset):\n     import pyarrow.parquet as pq\n \n     metadata_collector = []\n \n-    for i in range(4):\n-        table = pa.table({'f1': [i] * 10, 'f2': np.random.randn(10)})\n-        pq.write_to_dataset(\n-            table, str(root_path), metadata_collector=metadata_collector\n-        )\n+    f1_vals = [item for chunk in range(4) for item in [chunk] * 10]\n+\n+    table = pa.table({'f1': f1_vals, 'f2': np.random.randn(40)})\n+    pq.write_to_dataset(\n+        table, str(root_path), partition_cols=['f1'],\n+        use_legacy_dataset=use_legacy_dataset,\n+        metadata_collector=metadata_collector\n+    )\n+\n+    partitionless_schema = pa.schema([pa.field('f2', pa.float64())])\n \n     metadata_path = str(root_path / '_metadata')\n     # write _metadata file\n     pq.write_metadata(\n-        table.schema, metadata_path,\n+        partitionless_schema, metadata_path,\n         metadata_collector=metadata_collector\n     )\n-    return metadata_path, table\n+    return metadata_path, partitionless_schema\n \n \n @pytest.mark.parquet\n @pytest.mark.pandas  # write_to_dataset currently requires pandas\n-def test_parquet_dataset_factory(tempdir):\n+@pytest.mark.parametrize('use_legacy_dataset', [False, True])\n+def test_parquet_dataset_factory(tempdir, use_legacy_dataset):\n     root_path = tempdir / \"test_parquet_dataset\"\n-    metadata_path, table = _create_parquet_dataset_simple(root_path)\n+    metadata_path, partitionless_schema = _create_parquet_dataset_simple(\n+        root_path, use_legacy_dataset)\n     dataset = ds.parquet_dataset(metadata_path)\n-    assert dataset.schema.equals(table.schema)\n+    assert dataset.schema.equals(partitionless_schema)\n\nReview comment:\n       I agree with you that it isn't right (and now there is https://stackoverflow.com/questions/68277701/write-pandas-dataframe-parquet-metadata-with-partition-columns#comment120671321_68277701 ).  However, that was the legacy behavior, and I'd rather not tackle it as part of this PR.  I have opened up ARROW-13269 to address it.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-07T10:33:48.347+0000",
                    "updated": "2021-07-07T10:33:48.347+0000",
                    "started": "2021-07-07T10:33:48.347+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "619893",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/619894",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r665249741\n\n\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2795,7 +2804,7 @@ def test_parquet_dataset_lazy_filtering(tempdir, open_logging_fs):\n     # created with ParquetDatasetFactory from a _metadata file\n \n     root_path = tempdir / \"test_parquet_dataset_lazy_filtering\"\n-    metadata_path, _ = _create_parquet_dataset_simple(root_path)\n+    metadata_path, _ = _create_parquet_dataset_simple(root_path, True)\n\nReview comment:\n       I added the default.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-07T10:34:01.516+0000",
                    "updated": "2021-07-07T10:34:01.516+0000",
                    "started": "2021-07-07T10:34:01.516+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "619894",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/619895",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r665250153\n\n\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -2810,11 +2819,11 @@ def test_parquet_dataset_lazy_filtering(tempdir, open_logging_fs):\n \n     # filtering fragments should not open any file\n     with assert_opens([]):\n-        list(dataset.get_fragments(ds.field(\"f1\") > 15))\n+        list(dataset.get_fragments(ds.field(\"f2\") > 15))\n\nReview comment:\n       I changed f2 to be int64 values 0, 10, 20, 30.  f1 is no longer usable because it got removed from the schema because it was a partition column.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-07T10:34:44.665+0000",
                    "updated": "2021-07-07T10:34:44.665+0000",
                    "started": "2021-07-07T10:34:44.664+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "619895",
                    "issueId": "13372051"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/worklog/619896",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10628:\nURL: https://github.com/apache/arrow/pull/10628#discussion_r665251058\n\n\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -3095,10 +3104,30 @@ def test_write_dataset_use_threads(tempdir):\n         pa.schema([(\"part\", pa.string())]), flavor=\"hive\")\n \n     target1 = tempdir / 'partitioned1'\n+    paths_written = []\n+\n+    def file_visitor(written_file):\n+        print(f'Visiting {written_file.path}')\n\nReview comment:\n       Oops.  Removed.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-07-07T10:36:07.991+0000",
                    "updated": "2021-07-07T10:36:07.991+0000",
                    "started": "2021-07-07T10:36:07.991+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "619896",
                    "issueId": "13372051"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/5",
            "id": "5",
            "description": "General wishlist item.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Wish",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 21600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@17330e4f[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2243fd13[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@608ae228[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@5d9c304f[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@b6586f5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@422f94f0[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7503a53f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@49a1ed98[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6e549877[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@50e21959[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@38207427[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@7eab9396[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 21600,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Jul 14 19:55:23 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-07-14T19:55:23.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12364/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2021-04-13T13:34:00.000+0000",
        "updated": "2021-07-14T19:55:30.000+0000",
        "timeoriginalestimate": null,
        "description": "The legacy pq.write_to_dataset() has an option to save metadata to a list when writing partitioned data.\r\n{code:python}\r\n    collector = []\r\n    pq.write_to_dataset(\r\n        table=table,\r\n        root_path=output_path,\r\n        use_legacy_dataset=True,\r\n        metadata_collector=collector,\r\n    )\r\n    fragments = []\r\n    for piece in collector:\r\n        files.append(filesystem.sep.join([output_path, piece.row_group(0).column(0).file_path]))\r\n{code}\r\nThis allows me to save a list of the specific parquet files which were created when writing the partitions to storage. I use this when scheduling tasks with Airflow.\r\n\r\nTask A downloads data and partitions it --> Task B reads the file fragments which were just saved and transforms it --> Task C creates a list of dataset filters from the file fragments I transformed, reads each filter to into a table and then processes the data further (normally dropping duplicates or selecting a subset of the columns) and saves it for visualization\r\n{code:java}\r\nfragments = ['dev/date_id=20180111/transform-split-20210301013200-68.parquet', 'dev/date_id=20180114/transform-split-20210301013200-69.parquet', 'dev/date_id=20180128/transform-split-20210301013200-57.parquet', ]\r\n{code}\r\nI can use this list downstream to do two things:\r\n 1) I can read the list of fragments directly as a new dataset and transform the data\r\n{code:java}\r\nds.dataset(fragments)\r\n{code}\r\n2) I can generate filters from the fragment paths which were saved using ds._get_partition_keys(). This allows me to query the dataset and retrieve all fragments within the partition. For example, if I partition by date and I process data every 30 minutes I might have 48 individual file fragments within a single partition. I need to know to query the *entire* partition instead of reading a single fragment.\r\n{code:java}\r\ndef consolidate_filters(fragments):\r\n    \"\"\"Retrieves the partition_expressions from a list of dataset fragments to build a list of unique filters\"\"\"\r\n    filters = []\r\n    for frag in fragments:\r\n        partitions = ds._get_partition_keys(frag.partition_expression)\r\n        filter = [(k, \"==\", v) for k, v in partitions.items()]\r\n        if filter not in filters:\r\n            filters.append(filter)\r\n    return filters\r\n\r\nfilter_expression = pq._filters_to_expression(\r\n                filters=consolidate_filters(fragments=fragments)\r\n            )\r\n{code}\r\nMy current problem is that when I use ds.write_dataset(), I do not have a convenient method for generating a list of the file fragments I just saved. My only choice is to use basename_template and fs.glob() to find a list of the files based on the basename_template pattern. This is much slower and a waste of listing files on blob storage. [Related stackoverflow question with the basis of the approach I am using now |https://stackoverflow.com/questions/66252660/pyarrow-identify-the-fragments-written-or-filters-used-when-writing-a-parquet/66266585#66266585]",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "6h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 21600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] [Dataset] Add metadata_collector option to ds.write_dataset()",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": "Ubuntu 18.04",
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/comment/17367199",
                    "id": "17367199",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=ldacey",
                        "name": "ldacey",
                        "key": "ldacey",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Lance Dacey",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Hi @jorisvandenbossche, you asked me to create a separate issue for the metadata collector for ds.write_dataset. Just wanted to make sure that you had a chance to take a look.\r\n\r\nI had to switch back to the legacy dataset writer for most projects. Using fs.glob() can be very slow on very large datasets with many thousands of files, and my workflow often depends on knowing which files were written during a previous Airflow task.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=ldacey",
                        "name": "ldacey",
                        "key": "ldacey",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Lance Dacey",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2021-06-22T10:29:11.012+0000",
                    "updated": "2021-06-22T10:29:11.012+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/comment/17367552",
                    "id": "17367552",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=ldacey",
                        "name": "ldacey",
                        "key": "ldacey",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Lance Dacey",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "I think this is taken care of by\u00a0ARROW-10440",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=ldacey",
                        "name": "ldacey",
                        "key": "ldacey",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Lance Dacey",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2021-06-22T17:35:50.869+0000",
                    "updated": "2021-06-22T17:35:50.869+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/comment/17367612",
                    "id": "17367612",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "ARROW-10440 looks like it will be C++ only.\u00a0 I'd suggest we leave this open for the python implementation.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2021-06-22T18:45:51.469+0000",
                    "updated": "2021-06-22T18:46:14.241+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13372051/comment/17380837",
                    "id": "17380837",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 10628\n[https://github.com/apache/arrow/pull/10628]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-07-14T19:55:23.273+0000",
                    "updated": "2021-07-14T19:55:23.273+0000"
                }
            ],
            "maxResults": 4,
            "total": 4,
            "startAt": 0
        },
        "customfield_12311820": "0|z0pxrc:",
        "customfield_12314139": null
    }
}