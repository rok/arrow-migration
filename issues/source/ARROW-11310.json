{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13353163",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163",
    "key": "ARROW-11310",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12349493",
                "id": "12349493",
                "description": "",
                "name": "4.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-04-26"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
            "name": "Minor",
            "id": "4"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=houqp",
            "name": "houqp",
            "key": "houqp",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "QP Hou",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333773",
                "id": "12333773",
                "name": "Rust"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=houqp",
            "name": "houqp",
            "key": "houqp",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "QP Hou",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=houqp",
            "name": "houqp",
            "key": "houqp",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "QP Hou",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "aggregateprogress": {
            "progress": 15600,
            "total": 15600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 15600,
            "total": 15600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-11310/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 26,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/537607",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp opened a new pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256\n\n\n   Sending out PR for early review while I work on finishing up the following TODOs:\r\n   \r\n   - [ ] List type support\r\n   - [ ] Dictionary type support\r\n   - [ ] Date & Time types support\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-19T04:21:52.929+0000",
                    "updated": "2021-01-19T04:21:52.929+0000",
                    "started": "2021-01-19T04:21:52.929+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "537607",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/537608",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#issuecomment-762592205\n\n\n   https://issues.apache.org/jira/browse/ARROW-11310\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-19T04:22:17.436+0000",
                    "updated": "2021-01-19T04:22:17.436+0000",
                    "started": "2021-01-19T04:22:17.436+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "537608",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/537609",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io commented on pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#issuecomment-762596751\n\n\n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=h1) Report\n   > Merging [#9256](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=desc) (3c9fae3) into [master](https://codecov.io/gh/apache/arrow/commit/1393188e1aa1b3d59993ce7d4ade7f7ac8570959?el=desc) (1393188) will **decrease** coverage by `0.00%`.\n   > The diff coverage is `79.20%`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/9256/graphs/tree.svg?width=650&height=150&src=pr&token=LpTCFbqVT1)](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #9256      +/-   ##\n   ==========================================\n   - Coverage   81.61%   81.60%   -0.01%     \n   ==========================================\n     Files         215      216       +1     \n     Lines       51867    51987     +120     \n   ==========================================\n   + Hits        42329    42422      +93     \n   - Misses       9538     9565      +27     \n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [rust/arrow/src/json/writer.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvanNvbi93cml0ZXIucnM=) | `72.91% <72.91%> (\u00f8)` | |\n   | [rust/parquet/src/arrow/schema.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9wYXJxdWV0L3NyYy9hcnJvdy9zY2hlbWEucnM=) | `91.66% <100.00%> (+0.16%)` | :arrow_up: |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=footer). Last update [69a9a1c...0c68983](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-19T04:40:17.309+0000",
                    "updated": "2021-01-19T04:40:17.309+0000",
                    "started": "2021-01-19T04:40:17.308+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "537609",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/537611",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io edited a comment on pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#issuecomment-762596751\n\n\n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=h1) Report\n   > Merging [#9256](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=desc) (0c68983) into [master](https://codecov.io/gh/apache/arrow/commit/1393188e1aa1b3d59993ce7d4ade7f7ac8570959?el=desc) (1393188) will **decrease** coverage by `0.01%`.\n   > The diff coverage is `79.20%`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/9256/graphs/tree.svg?width=650&height=150&src=pr&token=LpTCFbqVT1)](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #9256      +/-   ##\n   ==========================================\n   - Coverage   81.61%   81.59%   -0.02%     \n   ==========================================\n     Files         215      216       +1     \n     Lines       51867    51987     +120     \n   ==========================================\n   + Hits        42329    42421      +92     \n   - Misses       9538     9566      +28     \n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [rust/arrow/src/json/writer.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvanNvbi93cml0ZXIucnM=) | `72.91% <72.91%> (\u00f8)` | |\n   | [rust/parquet/src/arrow/schema.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9wYXJxdWV0L3NyYy9hcnJvdy9zY2hlbWEucnM=) | `91.66% <100.00%> (+0.16%)` | :arrow_up: |\n   | [rust/parquet/src/encodings/encoding.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9wYXJxdWV0L3NyYy9lbmNvZGluZ3MvZW5jb2RpbmcucnM=) | `94.86% <0.00%> (-0.20%)` | :arrow_down: |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=footer). Last update [69a9a1c...0c68983](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-19T04:53:48.800+0000",
                    "updated": "2021-01-19T04:53:48.800+0000",
                    "started": "2021-01-19T04:53:48.799+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "537611",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/540900",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r563499210\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n\nReview comment:\n       Same here. Try using `arr.iter()`\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n\nReview comment:\n       This won't take nulls into account.\r\n   \r\n   One way to go here is to use \r\n   \r\n   ```rust\r\n   rows.iter_mut().zip(primitive_arr.iter()).take(row_count).for_each(|(row, maybe_value)| {\r\n   ...\r\n   })\r\n   ```\r\n   \r\n   `maybe_value` will be of type `Option<T::Native>`, where `None` represents a null value.\r\n   \r\n   \n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n+            }\n+        }\n+        DataType::Int8 => {\n+            set_column_by_primitive_type::<Int8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int16 => {\n+            set_column_by_primitive_type::<Int16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int32 => {\n+            set_column_by_primitive_type::<Int32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int64 => {\n+            set_column_by_primitive_type::<Int64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt8 => {\n+            set_column_by_primitive_type::<UInt8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt16 => {\n+            set_column_by_primitive_type::<UInt16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt32 => {\n+            set_column_by_primitive_type::<UInt32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt64 => {\n+            set_column_by_primitive_type::<UInt64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float32 => {\n+            set_column_by_primitive_type::<Float32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float64 => {\n+            set_column_by_primitive_type::<Float64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Utf8 => {\n+            let strarr = as_string_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), strarr.value(i).into());\n+            }\n+        }\n+        DataType::Struct(_) => {\n+            let arr = as_struct_array(array);\n+            let inner_col_names = arr.column_names();\n+\n+            let mut inner_objs = iter::repeat(JsonMap::new())\n+                .take(row_count)\n+                .collect::<Vec<JsonMap<String, Value>>>();\n+\n+            arr.columns()\n+                .iter()\n+                .enumerate()\n+                .for_each(|(j, struct_col)| {\n+                    set_column_for_json_rows(\n+                        &mut inner_objs,\n+                        row_count,\n+                        struct_col,\n+                        inner_col_names[j],\n+                    );\n+                });\n+\n+            rows.iter_mut()\n+                .take(row_count)\n+                .zip(inner_objs.into_iter())\n+                .for_each(|(row, obj)| {\n+                    row.insert(col_name.to_string(), Value::Object(obj));\n+                });\n+        }\n+        _ => {\n+            panic!(format!(\"Unsupported datatype: {:#?}\", array.data_type()));\n+        }\n+    }\n+}\n+\n+pub fn record_batches_to_json_rows(\n+    batches: &[RecordBatch],\n+) -> Vec<JsonMap<String, Value>> {\n+    let mut rows: Vec<JsonMap<String, Value>> = iter::repeat(JsonMap::new())\n+        .take(batches.iter().map(|b| b.num_rows()).sum())\n+        .collect();\n+\n+    if !rows.is_empty() {\n+        let schema = batches[0].schema();\n+        let mut base = 0;\n+        batches.iter().for_each(|batch| {\n+            let row_count = batch.num_rows();\n+            batch.columns().iter().enumerate().for_each(|(j, col)| {\n+                let col_name = schema.field(j).name();\n+                set_column_for_json_rows(&mut rows[base..], row_count, col, col_name);\n+            });\n+            base += row_count;\n+        });\n+    }\n+\n+    rows\n+}\n+\n+/// A JSON writer\n+#[derive(Debug)]\n+pub struct Writer<W: Write> {\n+    writer: BufWriter<W>,\n+}\n+\n+impl<W: Write> Writer<W> {\n+    pub fn new(writer: W) -> Self {\n+        Self::from_buf_writer(BufWriter::new(writer))\n+    }\n+\n+    pub fn from_buf_writer(writer: BufWriter<W>) -> Self {\n+        Self { writer }\n+    }\n+\n+    pub fn write_row(&mut self, row: &Value) -> Result<()> {\n+        self.writer.write_all(&serde_json::to_vec(row)?)?;\n+        self.writer.write_all(b\"\\n\")?;\n+        Ok(())\n+    }\n+\n+    pub fn write_batches(&mut self, batches: &[RecordBatch]) -> Result<()> {\n+        for row in record_batches_to_json_rows(batches) {\n+            self.write_row(&Value::Object(row))?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use std::fs::{read_to_string, File};\n+    use std::sync::Arc;\n+\n+    use crate::json::reader::*;\n+\n+    use super::*;\n+\n+    #[test]\n+    fn write_simple_rows() {\n+        let schema = Schema::new(vec![\n+            Field::new(\"a\", DataType::Int32, false),\n+            Field::new(\"b\", DataType::Utf8, false),\n+        ]);\n+\n+        let a = Int32Array::from(vec![1, 2, 3, 4, 5]);\n\nReview comment:\n       could have use `vec![Some(1), None, Some(3), Some(4,) Some(5)]`, so that we also test null values?\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n+            }\n+        }\n+        DataType::Int8 => {\n+            set_column_by_primitive_type::<Int8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int16 => {\n+            set_column_by_primitive_type::<Int16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int32 => {\n+            set_column_by_primitive_type::<Int32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int64 => {\n+            set_column_by_primitive_type::<Int64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt8 => {\n+            set_column_by_primitive_type::<UInt8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt16 => {\n+            set_column_by_primitive_type::<UInt16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt32 => {\n+            set_column_by_primitive_type::<UInt32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt64 => {\n+            set_column_by_primitive_type::<UInt64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float32 => {\n+            set_column_by_primitive_type::<Float32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float64 => {\n+            set_column_by_primitive_type::<Float64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Utf8 => {\n+            let strarr = as_string_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), strarr.value(i).into());\n\nReview comment:\n       same here.\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n+            }\n+        }\n+        DataType::Int8 => {\n+            set_column_by_primitive_type::<Int8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int16 => {\n+            set_column_by_primitive_type::<Int16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int32 => {\n+            set_column_by_primitive_type::<Int32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int64 => {\n+            set_column_by_primitive_type::<Int64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt8 => {\n+            set_column_by_primitive_type::<UInt8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt16 => {\n+            set_column_by_primitive_type::<UInt16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt32 => {\n+            set_column_by_primitive_type::<UInt32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt64 => {\n+            set_column_by_primitive_type::<UInt64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float32 => {\n+            set_column_by_primitive_type::<Float32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float64 => {\n+            set_column_by_primitive_type::<Float64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Utf8 => {\n+            let strarr = as_string_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), strarr.value(i).into());\n+            }\n+        }\n+        DataType::Struct(_) => {\n+            let arr = as_struct_array(array);\n+            let inner_col_names = arr.column_names();\n+\n+            let mut inner_objs = iter::repeat(JsonMap::new())\n+                .take(row_count)\n+                .collect::<Vec<JsonMap<String, Value>>>();\n+\n+            arr.columns()\n+                .iter()\n+                .enumerate()\n+                .for_each(|(j, struct_col)| {\n+                    set_column_for_json_rows(\n+                        &mut inner_objs,\n+                        row_count,\n+                        struct_col,\n+                        inner_col_names[j],\n+                    );\n+                });\n+\n+            rows.iter_mut()\n+                .take(row_count)\n+                .zip(inner_objs.into_iter())\n+                .for_each(|(row, obj)| {\n+                    row.insert(col_name.to_string(), Value::Object(obj));\n+                });\n+        }\n+        _ => {\n+            panic!(format!(\"Unsupported datatype: {:#?}\", array.data_type()));\n+        }\n+    }\n+}\n+\n+pub fn record_batches_to_json_rows(\n+    batches: &[RecordBatch],\n+) -> Vec<JsonMap<String, Value>> {\n+    let mut rows: Vec<JsonMap<String, Value>> = iter::repeat(JsonMap::new())\n+        .take(batches.iter().map(|b| b.num_rows()).sum())\n+        .collect();\n+\n+    if !rows.is_empty() {\n+        let schema = batches[0].schema();\n+        let mut base = 0;\n+        batches.iter().for_each(|batch| {\n+            let row_count = batch.num_rows();\n+            batch.columns().iter().enumerate().for_each(|(j, col)| {\n+                let col_name = schema.field(j).name();\n+                set_column_for_json_rows(&mut rows[base..], row_count, col, col_name);\n+            });\n+            base += row_count;\n+        });\n+    }\n+\n+    rows\n+}\n+\n+/// A JSON writer\n+#[derive(Debug)]\n+pub struct Writer<W: Write> {\n+    writer: BufWriter<W>,\n+}\n+\n+impl<W: Write> Writer<W> {\n+    pub fn new(writer: W) -> Self {\n+        Self::from_buf_writer(BufWriter::new(writer))\n+    }\n+\n+    pub fn from_buf_writer(writer: BufWriter<W>) -> Self {\n+        Self { writer }\n+    }\n+\n+    pub fn write_row(&mut self, row: &Value) -> Result<()> {\n+        self.writer.write_all(&serde_json::to_vec(row)?)?;\n+        self.writer.write_all(b\"\\n\")?;\n+        Ok(())\n+    }\n+\n+    pub fn write_batches(&mut self, batches: &[RecordBatch]) -> Result<()> {\n+        for row in record_batches_to_json_rows(batches) {\n+            self.write_row(&Value::Object(row))?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use std::fs::{read_to_string, File};\n+    use std::sync::Arc;\n+\n+    use crate::json::reader::*;\n+\n+    use super::*;\n+\n+    #[test]\n+    fn write_simple_rows() {\n+        let schema = Schema::new(vec![\n+            Field::new(\"a\", DataType::Int32, false),\n+            Field::new(\"b\", DataType::Utf8, false),\n+        ]);\n+\n+        let a = Int32Array::from(vec![1, 2, 3, 4, 5]);\n+        let b = StringArray::from(vec![\"a\", \"b\", \"c\", \"d\", \"e\"]);\n+\n+        let batch =\n+            RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a), Arc::new(b)])\n+                .unwrap();\n+\n+        let mut buf = Vec::new();\n+        {\n+            let mut writer = Writer::new(&mut buf);\n+            writer.write_batches(&vec![batch]).unwrap();\n+        }\n+\n+        assert_eq!(\n+            String::from_utf8(buf).unwrap(),\n+            r#\"{\"a\":1,\"b\":\"a\"}\n+{\"a\":2,\"b\":\"b\"}\n+{\"a\":3,\"b\":\"c\"}\n+{\"a\":4,\"b\":\"d\"}\n+{\"a\":5,\"b\":\"e\"}\n+\"#\n+        );\n+    }\n+\n+    fn test_write_for_file(test_file: &str) {\n+        let builder = ReaderBuilder::new()\n+            .infer_schema(None)\n+            .with_batch_size(1024);\n+        let mut reader: Reader<File> = builder\n+            .build::<File>(File::open(test_file).unwrap())\n+            .unwrap();\n+        let batch = reader.next().unwrap().unwrap();\n+\n+        let mut buf = Vec::new();\n+        {\n+            let mut writer = Writer::new(&mut buf);\n+            writer.write_batches(&vec![batch]).unwrap();\n+        }\n+\n+        let result = String::from_utf8(buf).unwrap();\n+        let expected = read_to_string(test_file).unwrap();\n+        for (r, e) in result.lines().zip(expected.lines()) {\n+            assert_eq!(\n+                serde_json::from_str::<Value>(r).unwrap(),\n+                serde_json::from_str::<Value>(e).unwrap()\n+            );\n+        }\n+    }\n+\n+    #[test]\n+    fn write_basic_rows() {\n+        test_write_for_file(\"test/data/basic.json\");\n\nReview comment:\n       AFAI understand this will populate a file and not delete it at the end.\r\n   \r\n   Would it be possible to write to a byte stream or something instead of a file? Alternatively, use `tmp` or something?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-25T07:10:04.139+0000",
                    "updated": "2021-01-25T07:10:04.139+0000",
                    "started": "2021-01-25T07:10:04.138+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "540900",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/541762",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r563499210\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n\nReview comment:\n       Same here. Try using `arr.iter()`\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n\nReview comment:\n       This won't take nulls into account.\r\n   \r\n   One way to go here is to use \r\n   \r\n   ```rust\r\n   rows.iter_mut().zip(primitive_arr.iter()).take(row_count).for_each(|(row, maybe_value)| {\r\n   ...\r\n   })\r\n   ```\r\n   \r\n   `maybe_value` will be of type `Option<T::Native>`, where `None` represents a null value.\r\n   \r\n   \n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n+            }\n+        }\n+        DataType::Int8 => {\n+            set_column_by_primitive_type::<Int8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int16 => {\n+            set_column_by_primitive_type::<Int16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int32 => {\n+            set_column_by_primitive_type::<Int32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int64 => {\n+            set_column_by_primitive_type::<Int64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt8 => {\n+            set_column_by_primitive_type::<UInt8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt16 => {\n+            set_column_by_primitive_type::<UInt16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt32 => {\n+            set_column_by_primitive_type::<UInt32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt64 => {\n+            set_column_by_primitive_type::<UInt64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float32 => {\n+            set_column_by_primitive_type::<Float32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float64 => {\n+            set_column_by_primitive_type::<Float64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Utf8 => {\n+            let strarr = as_string_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), strarr.value(i).into());\n+            }\n+        }\n+        DataType::Struct(_) => {\n+            let arr = as_struct_array(array);\n+            let inner_col_names = arr.column_names();\n+\n+            let mut inner_objs = iter::repeat(JsonMap::new())\n+                .take(row_count)\n+                .collect::<Vec<JsonMap<String, Value>>>();\n+\n+            arr.columns()\n+                .iter()\n+                .enumerate()\n+                .for_each(|(j, struct_col)| {\n+                    set_column_for_json_rows(\n+                        &mut inner_objs,\n+                        row_count,\n+                        struct_col,\n+                        inner_col_names[j],\n+                    );\n+                });\n+\n+            rows.iter_mut()\n+                .take(row_count)\n+                .zip(inner_objs.into_iter())\n+                .for_each(|(row, obj)| {\n+                    row.insert(col_name.to_string(), Value::Object(obj));\n+                });\n+        }\n+        _ => {\n+            panic!(format!(\"Unsupported datatype: {:#?}\", array.data_type()));\n+        }\n+    }\n+}\n+\n+pub fn record_batches_to_json_rows(\n+    batches: &[RecordBatch],\n+) -> Vec<JsonMap<String, Value>> {\n+    let mut rows: Vec<JsonMap<String, Value>> = iter::repeat(JsonMap::new())\n+        .take(batches.iter().map(|b| b.num_rows()).sum())\n+        .collect();\n+\n+    if !rows.is_empty() {\n+        let schema = batches[0].schema();\n+        let mut base = 0;\n+        batches.iter().for_each(|batch| {\n+            let row_count = batch.num_rows();\n+            batch.columns().iter().enumerate().for_each(|(j, col)| {\n+                let col_name = schema.field(j).name();\n+                set_column_for_json_rows(&mut rows[base..], row_count, col, col_name);\n+            });\n+            base += row_count;\n+        });\n+    }\n+\n+    rows\n+}\n+\n+/// A JSON writer\n+#[derive(Debug)]\n+pub struct Writer<W: Write> {\n+    writer: BufWriter<W>,\n+}\n+\n+impl<W: Write> Writer<W> {\n+    pub fn new(writer: W) -> Self {\n+        Self::from_buf_writer(BufWriter::new(writer))\n+    }\n+\n+    pub fn from_buf_writer(writer: BufWriter<W>) -> Self {\n+        Self { writer }\n+    }\n+\n+    pub fn write_row(&mut self, row: &Value) -> Result<()> {\n+        self.writer.write_all(&serde_json::to_vec(row)?)?;\n+        self.writer.write_all(b\"\\n\")?;\n+        Ok(())\n+    }\n+\n+    pub fn write_batches(&mut self, batches: &[RecordBatch]) -> Result<()> {\n+        for row in record_batches_to_json_rows(batches) {\n+            self.write_row(&Value::Object(row))?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use std::fs::{read_to_string, File};\n+    use std::sync::Arc;\n+\n+    use crate::json::reader::*;\n+\n+    use super::*;\n+\n+    #[test]\n+    fn write_simple_rows() {\n+        let schema = Schema::new(vec![\n+            Field::new(\"a\", DataType::Int32, false),\n+            Field::new(\"b\", DataType::Utf8, false),\n+        ]);\n+\n+        let a = Int32Array::from(vec![1, 2, 3, 4, 5]);\n\nReview comment:\n       could have use `vec![Some(1), None, Some(3), Some(4,) Some(5)]`, so that we also test null values?\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n+            }\n+        }\n+        DataType::Int8 => {\n+            set_column_by_primitive_type::<Int8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int16 => {\n+            set_column_by_primitive_type::<Int16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int32 => {\n+            set_column_by_primitive_type::<Int32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int64 => {\n+            set_column_by_primitive_type::<Int64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt8 => {\n+            set_column_by_primitive_type::<UInt8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt16 => {\n+            set_column_by_primitive_type::<UInt16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt32 => {\n+            set_column_by_primitive_type::<UInt32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt64 => {\n+            set_column_by_primitive_type::<UInt64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float32 => {\n+            set_column_by_primitive_type::<Float32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float64 => {\n+            set_column_by_primitive_type::<Float64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Utf8 => {\n+            let strarr = as_string_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), strarr.value(i).into());\n\nReview comment:\n       same here.\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n+            }\n+        }\n+        DataType::Int8 => {\n+            set_column_by_primitive_type::<Int8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int16 => {\n+            set_column_by_primitive_type::<Int16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int32 => {\n+            set_column_by_primitive_type::<Int32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int64 => {\n+            set_column_by_primitive_type::<Int64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt8 => {\n+            set_column_by_primitive_type::<UInt8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt16 => {\n+            set_column_by_primitive_type::<UInt16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt32 => {\n+            set_column_by_primitive_type::<UInt32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt64 => {\n+            set_column_by_primitive_type::<UInt64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float32 => {\n+            set_column_by_primitive_type::<Float32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float64 => {\n+            set_column_by_primitive_type::<Float64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Utf8 => {\n+            let strarr = as_string_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), strarr.value(i).into());\n+            }\n+        }\n+        DataType::Struct(_) => {\n+            let arr = as_struct_array(array);\n+            let inner_col_names = arr.column_names();\n+\n+            let mut inner_objs = iter::repeat(JsonMap::new())\n+                .take(row_count)\n+                .collect::<Vec<JsonMap<String, Value>>>();\n+\n+            arr.columns()\n+                .iter()\n+                .enumerate()\n+                .for_each(|(j, struct_col)| {\n+                    set_column_for_json_rows(\n+                        &mut inner_objs,\n+                        row_count,\n+                        struct_col,\n+                        inner_col_names[j],\n+                    );\n+                });\n+\n+            rows.iter_mut()\n+                .take(row_count)\n+                .zip(inner_objs.into_iter())\n+                .for_each(|(row, obj)| {\n+                    row.insert(col_name.to_string(), Value::Object(obj));\n+                });\n+        }\n+        _ => {\n+            panic!(format!(\"Unsupported datatype: {:#?}\", array.data_type()));\n+        }\n+    }\n+}\n+\n+pub fn record_batches_to_json_rows(\n+    batches: &[RecordBatch],\n+) -> Vec<JsonMap<String, Value>> {\n+    let mut rows: Vec<JsonMap<String, Value>> = iter::repeat(JsonMap::new())\n+        .take(batches.iter().map(|b| b.num_rows()).sum())\n+        .collect();\n+\n+    if !rows.is_empty() {\n+        let schema = batches[0].schema();\n+        let mut base = 0;\n+        batches.iter().for_each(|batch| {\n+            let row_count = batch.num_rows();\n+            batch.columns().iter().enumerate().for_each(|(j, col)| {\n+                let col_name = schema.field(j).name();\n+                set_column_for_json_rows(&mut rows[base..], row_count, col, col_name);\n+            });\n+            base += row_count;\n+        });\n+    }\n+\n+    rows\n+}\n+\n+/// A JSON writer\n+#[derive(Debug)]\n+pub struct Writer<W: Write> {\n+    writer: BufWriter<W>,\n+}\n+\n+impl<W: Write> Writer<W> {\n+    pub fn new(writer: W) -> Self {\n+        Self::from_buf_writer(BufWriter::new(writer))\n+    }\n+\n+    pub fn from_buf_writer(writer: BufWriter<W>) -> Self {\n+        Self { writer }\n+    }\n+\n+    pub fn write_row(&mut self, row: &Value) -> Result<()> {\n+        self.writer.write_all(&serde_json::to_vec(row)?)?;\n+        self.writer.write_all(b\"\\n\")?;\n+        Ok(())\n+    }\n+\n+    pub fn write_batches(&mut self, batches: &[RecordBatch]) -> Result<()> {\n+        for row in record_batches_to_json_rows(batches) {\n+            self.write_row(&Value::Object(row))?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use std::fs::{read_to_string, File};\n+    use std::sync::Arc;\n+\n+    use crate::json::reader::*;\n+\n+    use super::*;\n+\n+    #[test]\n+    fn write_simple_rows() {\n+        let schema = Schema::new(vec![\n+            Field::new(\"a\", DataType::Int32, false),\n+            Field::new(\"b\", DataType::Utf8, false),\n+        ]);\n+\n+        let a = Int32Array::from(vec![1, 2, 3, 4, 5]);\n+        let b = StringArray::from(vec![\"a\", \"b\", \"c\", \"d\", \"e\"]);\n+\n+        let batch =\n+            RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a), Arc::new(b)])\n+                .unwrap();\n+\n+        let mut buf = Vec::new();\n+        {\n+            let mut writer = Writer::new(&mut buf);\n+            writer.write_batches(&vec![batch]).unwrap();\n+        }\n+\n+        assert_eq!(\n+            String::from_utf8(buf).unwrap(),\n+            r#\"{\"a\":1,\"b\":\"a\"}\n+{\"a\":2,\"b\":\"b\"}\n+{\"a\":3,\"b\":\"c\"}\n+{\"a\":4,\"b\":\"d\"}\n+{\"a\":5,\"b\":\"e\"}\n+\"#\n+        );\n+    }\n+\n+    fn test_write_for_file(test_file: &str) {\n+        let builder = ReaderBuilder::new()\n+            .infer_schema(None)\n+            .with_batch_size(1024);\n+        let mut reader: Reader<File> = builder\n+            .build::<File>(File::open(test_file).unwrap())\n+            .unwrap();\n+        let batch = reader.next().unwrap().unwrap();\n+\n+        let mut buf = Vec::new();\n+        {\n+            let mut writer = Writer::new(&mut buf);\n+            writer.write_batches(&vec![batch]).unwrap();\n+        }\n+\n+        let result = String::from_utf8(buf).unwrap();\n+        let expected = read_to_string(test_file).unwrap();\n+        for (r, e) in result.lines().zip(expected.lines()) {\n+            assert_eq!(\n+                serde_json::from_str::<Value>(r).unwrap(),\n+                serde_json::from_str::<Value>(e).unwrap()\n+            );\n+        }\n+    }\n+\n+    #[test]\n+    fn write_basic_rows() {\n+        test_write_for_file(\"test/data/basic.json\");\n\nReview comment:\n       AFAI understand this will populate a file and not delete it at the end.\r\n   \r\n   Would it be possible to write to a byte stream or something instead of a file? Alternatively, use `tmp` or something?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-26T04:17:48.299+0000",
                    "updated": "2021-01-26T04:17:48.299+0000",
                    "started": "2021-01-26T04:17:48.299+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "541762",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/542040",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r564283209\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n\nReview comment:\n       Good catch, will update the code and add test cases.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-26T06:51:54.355+0000",
                    "updated": "2021-01-26T06:51:54.355+0000",
                    "started": "2021-01-26T06:51:54.354+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "542040",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/542638",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r565027825\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,301 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn set_column_by_primitive_type<T: ArrowPrimitiveType>(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    let primitive_arr = as_primitive_array::<T>(array);\n+    for (i, row) in rows.iter_mut().enumerate().take(row_count) {\n+        row.insert(\n+            col_name.to_string(),\n+            primitive_arr\n+                .value(i)\n+                .into_json_value()\n+                .unwrap_or(Value::Null),\n+        );\n+    }\n+}\n+\n+fn set_column_for_json_rows(\n+    rows: &mut [JsonMap<String, Value>],\n+    row_count: usize,\n+    array: &ArrayRef,\n+    col_name: &str,\n+) {\n+    match array.data_type() {\n+        DataType::Null => {\n+            for row in rows.iter_mut().take(row_count) {\n+                row.insert(col_name.to_string(), Value::Null);\n+            }\n+        }\n+        DataType::Boolean => {\n+            let arr = as_boolean_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), arr.value(i).into());\n+            }\n+        }\n+        DataType::Int8 => {\n+            set_column_by_primitive_type::<Int8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int16 => {\n+            set_column_by_primitive_type::<Int16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int32 => {\n+            set_column_by_primitive_type::<Int32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Int64 => {\n+            set_column_by_primitive_type::<Int64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt8 => {\n+            set_column_by_primitive_type::<UInt8Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt16 => {\n+            set_column_by_primitive_type::<UInt16Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt32 => {\n+            set_column_by_primitive_type::<UInt32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::UInt64 => {\n+            set_column_by_primitive_type::<UInt64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float32 => {\n+            set_column_by_primitive_type::<Float32Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Float64 => {\n+            set_column_by_primitive_type::<Float64Type>(rows, row_count, array, col_name)\n+        }\n+        DataType::Utf8 => {\n+            let strarr = as_string_array(array);\n+            for (i, row) in rows.iter_mut().take(row_count).enumerate() {\n+                row.insert(col_name.to_string(), strarr.value(i).into());\n+            }\n+        }\n+        DataType::Struct(_) => {\n+            let arr = as_struct_array(array);\n+            let inner_col_names = arr.column_names();\n+\n+            let mut inner_objs = iter::repeat(JsonMap::new())\n+                .take(row_count)\n+                .collect::<Vec<JsonMap<String, Value>>>();\n+\n+            arr.columns()\n+                .iter()\n+                .enumerate()\n+                .for_each(|(j, struct_col)| {\n+                    set_column_for_json_rows(\n+                        &mut inner_objs,\n+                        row_count,\n+                        struct_col,\n+                        inner_col_names[j],\n+                    );\n+                });\n+\n+            rows.iter_mut()\n+                .take(row_count)\n+                .zip(inner_objs.into_iter())\n+                .for_each(|(row, obj)| {\n+                    row.insert(col_name.to_string(), Value::Object(obj));\n+                });\n+        }\n+        _ => {\n+            panic!(format!(\"Unsupported datatype: {:#?}\", array.data_type()));\n+        }\n+    }\n+}\n+\n+pub fn record_batches_to_json_rows(\n+    batches: &[RecordBatch],\n+) -> Vec<JsonMap<String, Value>> {\n+    let mut rows: Vec<JsonMap<String, Value>> = iter::repeat(JsonMap::new())\n+        .take(batches.iter().map(|b| b.num_rows()).sum())\n+        .collect();\n+\n+    if !rows.is_empty() {\n+        let schema = batches[0].schema();\n+        let mut base = 0;\n+        batches.iter().for_each(|batch| {\n+            let row_count = batch.num_rows();\n+            batch.columns().iter().enumerate().for_each(|(j, col)| {\n+                let col_name = schema.field(j).name();\n+                set_column_for_json_rows(&mut rows[base..], row_count, col, col_name);\n+            });\n+            base += row_count;\n+        });\n+    }\n+\n+    rows\n+}\n+\n+/// A JSON writer\n+#[derive(Debug)]\n+pub struct Writer<W: Write> {\n+    writer: BufWriter<W>,\n+}\n+\n+impl<W: Write> Writer<W> {\n+    pub fn new(writer: W) -> Self {\n+        Self::from_buf_writer(BufWriter::new(writer))\n+    }\n+\n+    pub fn from_buf_writer(writer: BufWriter<W>) -> Self {\n+        Self { writer }\n+    }\n+\n+    pub fn write_row(&mut self, row: &Value) -> Result<()> {\n+        self.writer.write_all(&serde_json::to_vec(row)?)?;\n+        self.writer.write_all(b\"\\n\")?;\n+        Ok(())\n+    }\n+\n+    pub fn write_batches(&mut self, batches: &[RecordBatch]) -> Result<()> {\n+        for row in record_batches_to_json_rows(batches) {\n+            self.write_row(&Value::Object(row))?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use std::fs::{read_to_string, File};\n+    use std::sync::Arc;\n+\n+    use crate::json::reader::*;\n+\n+    use super::*;\n+\n+    #[test]\n+    fn write_simple_rows() {\n+        let schema = Schema::new(vec![\n+            Field::new(\"a\", DataType::Int32, false),\n+            Field::new(\"b\", DataType::Utf8, false),\n+        ]);\n+\n+        let a = Int32Array::from(vec![1, 2, 3, 4, 5]);\n+        let b = StringArray::from(vec![\"a\", \"b\", \"c\", \"d\", \"e\"]);\n+\n+        let batch =\n+            RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a), Arc::new(b)])\n+                .unwrap();\n+\n+        let mut buf = Vec::new();\n+        {\n+            let mut writer = Writer::new(&mut buf);\n+            writer.write_batches(&vec![batch]).unwrap();\n+        }\n+\n+        assert_eq!(\n+            String::from_utf8(buf).unwrap(),\n+            r#\"{\"a\":1,\"b\":\"a\"}\n+{\"a\":2,\"b\":\"b\"}\n+{\"a\":3,\"b\":\"c\"}\n+{\"a\":4,\"b\":\"d\"}\n+{\"a\":5,\"b\":\"e\"}\n+\"#\n+        );\n+    }\n+\n+    fn test_write_for_file(test_file: &str) {\n+        let builder = ReaderBuilder::new()\n+            .infer_schema(None)\n+            .with_batch_size(1024);\n+        let mut reader: Reader<File> = builder\n+            .build::<File>(File::open(test_file).unwrap())\n+            .unwrap();\n+        let batch = reader.next().unwrap().unwrap();\n+\n+        let mut buf = Vec::new();\n+        {\n+            let mut writer = Writer::new(&mut buf);\n+            writer.write_batches(&vec![batch]).unwrap();\n+        }\n+\n+        let result = String::from_utf8(buf).unwrap();\n+        let expected = read_to_string(test_file).unwrap();\n+        for (r, e) in result.lines().zip(expected.lines()) {\n+            assert_eq!(\n+                serde_json::from_str::<Value>(r).unwrap(),\n+                serde_json::from_str::<Value>(e).unwrap()\n+            );\n+        }\n+    }\n+\n+    #[test]\n+    fn write_basic_rows() {\n+        test_write_for_file(\"test/data/basic.json\");\n\nReview comment:\n       This function reads json test file from existing test data, serializes it to an in memory byte stream, then use that result to compare against the same test file from disk for diff. So there should be no disk write involved.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-27T04:55:46.888+0000",
                    "updated": "2021-01-27T04:55:46.888+0000",
                    "started": "2021-01-27T04:55:46.888+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "542638",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/542650",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io edited a comment on pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#issuecomment-762596751\n\n\n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=h1) Report\n   > Merging [#9256](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=desc) (f200959) into [master](https://codecov.io/gh/apache/arrow/commit/3e47777441795c1970a22f6bad103da3e867dc98?el=desc) (3e47777) will **decrease** coverage by `0.01%`.\n   > The diff coverage is `84.58%`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/9256/graphs/tree.svg?width=650&height=150&src=pr&token=LpTCFbqVT1)](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #9256      +/-   ##\n   ==========================================\n   - Coverage   81.89%   81.87%   -0.02%     \n   ==========================================\n     Files         215      216       +1     \n     Lines       52988    53097     +109     \n   ==========================================\n   + Hits        43392    43474      +82     \n   - Misses       9596     9623      +27     \n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [rust/arrow/src/array/array\\_struct.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvYXJyYXkvYXJyYXlfc3RydWN0LnJz) | `88.43% <\u00f8> (\u00f8)` | |\n   | [rust/arrow/src/array/equal/utils.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvYXJyYXkvZXF1YWwvdXRpbHMucnM=) | `75.49% <0.00%> (\u00f8)` | |\n   | [rust/arrow/src/bytes.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvYnl0ZXMucnM=) | `53.12% <\u00f8> (\u00f8)` | |\n   | [rust/arrow/src/compute/kernels/aggregate.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvY29tcHV0ZS9rZXJuZWxzL2FnZ3JlZ2F0ZS5ycw==) | `74.93% <\u00f8> (\u00f8)` | |\n   | [rust/arrow/src/ipc/gen/SparseTensor.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvaXBjL2dlbi9TcGFyc2VUZW5zb3IucnM=) | `0.00% <0.00%> (\u00f8)` | |\n   | [rust/arrow/src/ipc/gen/Tensor.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9hcnJvdy9zcmMvaXBjL2dlbi9UZW5zb3IucnM=) | `0.00% <0.00%> (\u00f8)` | |\n   | [rust/benchmarks/src/bin/nyctaxi.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9iZW5jaG1hcmtzL3NyYy9iaW4vbnljdGF4aS5ycw==) | `0.00% <\u00f8> (\u00f8)` | |\n   | [rust/benchmarks/src/bin/tpch.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9iZW5jaG1hcmtzL3NyYy9iaW4vdHBjaC5ycw==) | `6.97% <0.00%> (\u00f8)` | |\n   | [rust/datafusion/src/datasource/memory.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9kYXRhZnVzaW9uL3NyYy9kYXRhc291cmNlL21lbW9yeS5ycw==) | `79.75% <0.00%> (\u00f8)` | |\n   | [rust/datafusion/src/logical\\_plan/operators.rs](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree#diff-cnVzdC9kYXRhZnVzaW9uL3NyYy9sb2dpY2FsX3BsYW4vb3BlcmF0b3JzLnJz) | `75.00% <\u00f8> (\u00f8)` | |\n   | ... and [136 more](https://codecov.io/gh/apache/arrow/pull/9256/diff?src=pr&el=tree-more) | |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=footer). Last update [5665a0c...f200959](https://codecov.io/gh/apache/arrow/pull/9256?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-27T05:15:58.367+0000",
                    "updated": "2021-01-27T05:15:58.367+0000",
                    "started": "2021-01-27T05:15:58.367+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "542650",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/544968",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r567489241\n\n\n\n##########\nFile path: rust/arrow/src/array/cast.rs\n##########\n@@ -40,12 +40,20 @@ where\n         .expect(\"Unable to downcast to dictionary array\")\n }\n \n-pub fn as_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n+pub fn as_generic_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n\nReview comment:\n       breaking change to make naming more consistent with array type.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-01-31T21:49:01.203+0000",
                    "updated": "2021-01-31T21:49:01.203+0000",
                    "started": "2021-01-31T21:49:01.203+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "544968",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545118",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp commented on pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#issuecomment-770626148\n\n\n   @jorgecarleitao @nevi-me ready for review.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-01T07:09:10.487+0000",
                    "updated": "2021-02-01T07:09:10.487+0000",
                    "started": "2021-02-01T07:09:10.487+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545118",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545548",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r568090293\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,635 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn primitive_array_to_json<T: ArrowPrimitiveType>(array: &ArrayRef) -> Vec<Value> {\n+    as_primitive_array::<T>(array)\n+        .iter()\n+        .map(|maybe_value| match maybe_value {\n+            Some(v) => v.into_json_value().unwrap_or(Value::Null),\n+            None => Value::Null,\n+        })\n+        .collect()\n+}\n+\n+fn struct_array_to_jsonmap_array(\n+    array: &StructArray,\n+    row_count: usize,\n+) -> Vec<JsonMap<String, Value>> {\n+    let inner_col_names = array.column_names();\n+\n+    let mut inner_objs = iter::repeat(JsonMap::new())\n+        .take(row_count)\n+        .collect::<Vec<JsonMap<String, Value>>>();\n+\n+    array\n+        .columns()\n+        .iter()\n+        .enumerate()\n+        .for_each(|(j, struct_col)| {\n+            set_column_for_json_rows(\n+                &mut inner_objs,\n+                row_count,\n+                struct_col,\n+                inner_col_names[j],\n+            );\n+        });\n+\n+    inner_objs\n+}\n+\n+pub fn array_to_json_array(array: &ArrayRef) -> Vec<Value> {\n+    match array.data_type() {\n+        DataType::Null => iter::repeat(Value::Null).take(array.len()).collect(),\n+        DataType::Boolean => as_boolean_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+\n+        DataType::Utf8 => as_string_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Int8 => primitive_array_to_json::<Int8Type>(array),\n+        DataType::Int16 => primitive_array_to_json::<Int16Type>(array),\n+        DataType::Int32 => primitive_array_to_json::<Int32Type>(array),\n+        DataType::Int64 => primitive_array_to_json::<Int64Type>(array),\n+        DataType::UInt8 => primitive_array_to_json::<UInt8Type>(array),\n+        DataType::UInt16 => primitive_array_to_json::<UInt16Type>(array),\n+        DataType::UInt32 => primitive_array_to_json::<UInt32Type>(array),\n+        DataType::UInt64 => primitive_array_to_json::<UInt64Type>(array),\n+        DataType::Float32 => primitive_array_to_json::<Float32Type>(array),\n+        DataType::Float64 => primitive_array_to_json::<Float64Type>(array),\n+        DataType::List(_) => as_list_array(array)\n\nReview comment:\n       ```rust\r\n           DataType::List(_) => as_large_list_array(array)\r\n               .iter()\r\n               .map(|maybe_value| match maybe_value {\r\n                   Some(v) => Value::Array(array_to_json_array(&v)),\r\n                   None => Value::Null,\r\n               })\r\n               .collect(),\r\n   ```\r\n   \r\n   for completeness?\n\n##########\nFile path: rust/arrow/src/array/cast.rs\n##########\n@@ -40,12 +40,20 @@ where\n         .expect(\"Unable to downcast to dictionary array\")\n }\n \n-pub fn as_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n+pub fn as_generic_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n     arr.as_any()\n         .downcast_ref::<GenericListArray<S>>()\n         .expect(\"Unable to downcast to list array\")\n }\n \n+pub fn as_list_array(arr: &ArrayRef) -> &ListArray {\n\nReview comment:\n       Not sure whether we need an extra public function for a one-liner.\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,635 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn primitive_array_to_json<T: ArrowPrimitiveType>(array: &ArrayRef) -> Vec<Value> {\n+    as_primitive_array::<T>(array)\n+        .iter()\n+        .map(|maybe_value| match maybe_value {\n+            Some(v) => v.into_json_value().unwrap_or(Value::Null),\n+            None => Value::Null,\n+        })\n+        .collect()\n+}\n+\n+fn struct_array_to_jsonmap_array(\n+    array: &StructArray,\n+    row_count: usize,\n+) -> Vec<JsonMap<String, Value>> {\n+    let inner_col_names = array.column_names();\n+\n+    let mut inner_objs = iter::repeat(JsonMap::new())\n+        .take(row_count)\n+        .collect::<Vec<JsonMap<String, Value>>>();\n+\n+    array\n+        .columns()\n+        .iter()\n+        .enumerate()\n+        .for_each(|(j, struct_col)| {\n+            set_column_for_json_rows(\n+                &mut inner_objs,\n+                row_count,\n+                struct_col,\n+                inner_col_names[j],\n+            );\n+        });\n+\n+    inner_objs\n+}\n+\n+pub fn array_to_json_array(array: &ArrayRef) -> Vec<Value> {\n+    match array.data_type() {\n+        DataType::Null => iter::repeat(Value::Null).take(array.len()).collect(),\n+        DataType::Boolean => as_boolean_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+\n+        DataType::Utf8 => as_string_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Int8 => primitive_array_to_json::<Int8Type>(array),\n+        DataType::Int16 => primitive_array_to_json::<Int16Type>(array),\n+        DataType::Int32 => primitive_array_to_json::<Int32Type>(array),\n+        DataType::Int64 => primitive_array_to_json::<Int64Type>(array),\n+        DataType::UInt8 => primitive_array_to_json::<UInt8Type>(array),\n+        DataType::UInt16 => primitive_array_to_json::<UInt16Type>(array),\n+        DataType::UInt32 => primitive_array_to_json::<UInt32Type>(array),\n+        DataType::UInt64 => primitive_array_to_json::<UInt64Type>(array),\n+        DataType::Float32 => primitive_array_to_json::<Float32Type>(array),\n+        DataType::Float64 => primitive_array_to_json::<Float64Type>(array),\n+        DataType::List(_) => as_list_array(array)\n\nReview comment:\n       ```rust\r\n           DataType::LargeList(_) => as_large_list_array(array)\r\n               .iter()\r\n               .map(|maybe_value| match maybe_value {\r\n                   Some(v) => Value::Array(array_to_json_array(&v)),\r\n                   None => Value::Null,\r\n               })\r\n               .collect(),\r\n   ```\r\n   \r\n   for completeness?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-01T19:45:14.219+0000",
                    "updated": "2021-02-01T19:45:14.219+0000",
                    "started": "2021-02-01T19:45:14.219+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545548",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545550",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#issuecomment-771111068\n\n\n   cc @andygrove @alamb @nevi-me @sunchao \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-01T19:46:00.589+0000",
                    "updated": "2021-02-01T19:46:00.589+0000",
                    "started": "2021-02-01T19:46:00.589+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545550",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545606",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nevi-me commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r568118067\n\n\n\n##########\nFile path: rust/arrow/src/array/cast.rs\n##########\n@@ -40,12 +40,20 @@ where\n         .expect(\"Unable to downcast to dictionary array\")\n }\n \n-pub fn as_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n+pub fn as_generic_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n     arr.as_any()\n         .downcast_ref::<GenericListArray<S>>()\n         .expect(\"Unable to downcast to list array\")\n }\n \n+pub fn as_list_array(arr: &ArrayRef) -> &ListArray {\n\nReview comment:\n       We should probably inline them. I'm indifferent on whether we want to just keep as_generic_list or also the 2 more specific ones.\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,635 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn primitive_array_to_json<T: ArrowPrimitiveType>(array: &ArrayRef) -> Vec<Value> {\n+    as_primitive_array::<T>(array)\n+        .iter()\n+        .map(|maybe_value| match maybe_value {\n+            Some(v) => v.into_json_value().unwrap_or(Value::Null),\n+            None => Value::Null,\n+        })\n+        .collect()\n+}\n+\n+fn struct_array_to_jsonmap_array(\n+    array: &StructArray,\n+    row_count: usize,\n+) -> Vec<JsonMap<String, Value>> {\n+    let inner_col_names = array.column_names();\n+\n+    let mut inner_objs = iter::repeat(JsonMap::new())\n+        .take(row_count)\n+        .collect::<Vec<JsonMap<String, Value>>>();\n+\n+    array\n+        .columns()\n+        .iter()\n+        .enumerate()\n+        .for_each(|(j, struct_col)| {\n+            set_column_for_json_rows(\n+                &mut inner_objs,\n+                row_count,\n+                struct_col,\n+                inner_col_names[j],\n+            );\n+        });\n+\n+    inner_objs\n+}\n+\n+pub fn array_to_json_array(array: &ArrayRef) -> Vec<Value> {\n+    match array.data_type() {\n+        DataType::Null => iter::repeat(Value::Null).take(array.len()).collect(),\n+        DataType::Boolean => as_boolean_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+\n+        DataType::Utf8 => as_string_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Int8 => primitive_array_to_json::<Int8Type>(array),\n+        DataType::Int16 => primitive_array_to_json::<Int16Type>(array),\n+        DataType::Int32 => primitive_array_to_json::<Int32Type>(array),\n+        DataType::Int64 => primitive_array_to_json::<Int64Type>(array),\n+        DataType::UInt8 => primitive_array_to_json::<UInt8Type>(array),\n+        DataType::UInt16 => primitive_array_to_json::<UInt16Type>(array),\n+        DataType::UInt32 => primitive_array_to_json::<UInt32Type>(array),\n+        DataType::UInt64 => primitive_array_to_json::<UInt64Type>(array),\n+        DataType::Float32 => primitive_array_to_json::<Float32Type>(array),\n+        DataType::Float64 => primitive_array_to_json::<Float64Type>(array),\n+        DataType::List(_) => as_list_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => Value::Array(array_to_json_array(&v)),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Struct(_) => {\n+            let jsonmaps =\n+                struct_array_to_jsonmap_array(as_struct_array(array), array.len());\n+            jsonmaps.into_iter().map(Value::Object).collect()\n+        }\n+        _ => {\n\nReview comment:\n       I think there'd be demand for dictionary support, but we can add that separately\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-01T21:31:28.752+0000",
                    "updated": "2021-02-01T21:31:28.752+0000",
                    "started": "2021-02-01T21:31:28.751+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545606",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545687",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r568205865\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,635 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn primitive_array_to_json<T: ArrowPrimitiveType>(array: &ArrayRef) -> Vec<Value> {\n+    as_primitive_array::<T>(array)\n+        .iter()\n+        .map(|maybe_value| match maybe_value {\n+            Some(v) => v.into_json_value().unwrap_or(Value::Null),\n+            None => Value::Null,\n+        })\n+        .collect()\n+}\n+\n+fn struct_array_to_jsonmap_array(\n+    array: &StructArray,\n+    row_count: usize,\n+) -> Vec<JsonMap<String, Value>> {\n+    let inner_col_names = array.column_names();\n+\n+    let mut inner_objs = iter::repeat(JsonMap::new())\n+        .take(row_count)\n+        .collect::<Vec<JsonMap<String, Value>>>();\n+\n+    array\n+        .columns()\n+        .iter()\n+        .enumerate()\n+        .for_each(|(j, struct_col)| {\n+            set_column_for_json_rows(\n+                &mut inner_objs,\n+                row_count,\n+                struct_col,\n+                inner_col_names[j],\n+            );\n+        });\n+\n+    inner_objs\n+}\n+\n+pub fn array_to_json_array(array: &ArrayRef) -> Vec<Value> {\n+    match array.data_type() {\n+        DataType::Null => iter::repeat(Value::Null).take(array.len()).collect(),\n+        DataType::Boolean => as_boolean_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+\n+        DataType::Utf8 => as_string_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Int8 => primitive_array_to_json::<Int8Type>(array),\n+        DataType::Int16 => primitive_array_to_json::<Int16Type>(array),\n+        DataType::Int32 => primitive_array_to_json::<Int32Type>(array),\n+        DataType::Int64 => primitive_array_to_json::<Int64Type>(array),\n+        DataType::UInt8 => primitive_array_to_json::<UInt8Type>(array),\n+        DataType::UInt16 => primitive_array_to_json::<UInt16Type>(array),\n+        DataType::UInt32 => primitive_array_to_json::<UInt32Type>(array),\n+        DataType::UInt64 => primitive_array_to_json::<UInt64Type>(array),\n+        DataType::Float32 => primitive_array_to_json::<Float32Type>(array),\n+        DataType::Float64 => primitive_array_to_json::<Float64Type>(array),\n+        DataType::List(_) => as_list_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => Value::Array(array_to_json_array(&v)),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Struct(_) => {\n+            let jsonmaps =\n+                struct_array_to_jsonmap_array(as_struct_array(array), array.len());\n+            jsonmaps.into_iter().map(Value::Object).collect()\n+        }\n+        _ => {\n\nReview comment:\n       Yes I agree -- on both counts :)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-01T23:09:29.621+0000",
                    "updated": "2021-02-01T23:09:29.621+0000",
                    "started": "2021-02-01T23:09:29.621+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545687",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545803",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r568339523\n\n\n\n##########\nFile path: rust/arrow/src/array/cast.rs\n##########\n@@ -40,12 +40,20 @@ where\n         .expect(\"Unable to downcast to dictionary array\")\n }\n \n-pub fn as_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n+pub fn as_generic_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n     arr.as_any()\n         .downcast_ref::<GenericListArray<S>>()\n         .expect(\"Unable to downcast to list array\")\n }\n \n+pub fn as_list_array(arr: &ArrayRef) -> &ListArray {\n\nReview comment:\n       @jorgecarleitao the main reason for adding that is to keep these two cast function names consistent with others. i.e. for a particular `FooBarArray` type, there exists a `as_foo_bar_array` cast function. However, if you have strong opinion on this, I am happy to remove it.\r\n   \r\n   I have added the inline annotation.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-02T05:53:31.373+0000",
                    "updated": "2021-02-02T05:53:31.373+0000",
                    "started": "2021-02-02T05:53:31.373+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545803",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545804",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r568340019\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,635 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn primitive_array_to_json<T: ArrowPrimitiveType>(array: &ArrayRef) -> Vec<Value> {\n+    as_primitive_array::<T>(array)\n+        .iter()\n+        .map(|maybe_value| match maybe_value {\n+            Some(v) => v.into_json_value().unwrap_or(Value::Null),\n+            None => Value::Null,\n+        })\n+        .collect()\n+}\n+\n+fn struct_array_to_jsonmap_array(\n+    array: &StructArray,\n+    row_count: usize,\n+) -> Vec<JsonMap<String, Value>> {\n+    let inner_col_names = array.column_names();\n+\n+    let mut inner_objs = iter::repeat(JsonMap::new())\n+        .take(row_count)\n+        .collect::<Vec<JsonMap<String, Value>>>();\n+\n+    array\n+        .columns()\n+        .iter()\n+        .enumerate()\n+        .for_each(|(j, struct_col)| {\n+            set_column_for_json_rows(\n+                &mut inner_objs,\n+                row_count,\n+                struct_col,\n+                inner_col_names[j],\n+            );\n+        });\n+\n+    inner_objs\n+}\n+\n+pub fn array_to_json_array(array: &ArrayRef) -> Vec<Value> {\n+    match array.data_type() {\n+        DataType::Null => iter::repeat(Value::Null).take(array.len()).collect(),\n+        DataType::Boolean => as_boolean_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+\n+        DataType::Utf8 => as_string_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Int8 => primitive_array_to_json::<Int8Type>(array),\n+        DataType::Int16 => primitive_array_to_json::<Int16Type>(array),\n+        DataType::Int32 => primitive_array_to_json::<Int32Type>(array),\n+        DataType::Int64 => primitive_array_to_json::<Int64Type>(array),\n+        DataType::UInt8 => primitive_array_to_json::<UInt8Type>(array),\n+        DataType::UInt16 => primitive_array_to_json::<UInt16Type>(array),\n+        DataType::UInt32 => primitive_array_to_json::<UInt32Type>(array),\n+        DataType::UInt64 => primitive_array_to_json::<UInt64Type>(array),\n+        DataType::Float32 => primitive_array_to_json::<Float32Type>(array),\n+        DataType::Float64 => primitive_array_to_json::<Float64Type>(array),\n+        DataType::List(_) => as_list_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => Value::Array(array_to_json_array(&v)),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Struct(_) => {\n+            let jsonmaps =\n+                struct_array_to_jsonmap_array(as_struct_array(array), array.len());\n+            jsonmaps.into_iter().map(Value::Object).collect()\n+        }\n+        _ => {\n\nReview comment:\n       yeah, i was planning to add dictionary support, but this patch set already grew larger than I expected, so I decided to leave that to a follow up PR for easier review.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-02T05:55:04.836+0000",
                    "updated": "2021-02-02T05:55:04.836+0000",
                    "started": "2021-02-02T05:55:04.836+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545804",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545805",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "houqp commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r568340019\n\n\n\n##########\nFile path: rust/arrow/src/json/writer.rs\n##########\n@@ -0,0 +1,635 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! JSON Writer\n+//!\n+//! This JSON writer allows converting Arrow record batches into array of JSON objects. It also\n+//! provides a Writer struct to help serialize record batches directly into line-delimited JSON\n+//! objects as bytes.\n+//!\n+//! Serialize record batches into array of JSON objects:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let json_rows = json::writer::record_batches_to_json_rows(&[batch]);\n+//! assert_eq!(\n+//!     serde_json::Value::Object(json_rows[1].clone()),\n+//!     serde_json::json!({\"a\": 2}),\n+//! );\n+//! ```\n+//!\n+//! Serialize record batches into line-delimited JSON bytes:\n+//!\n+//! ```\n+//! use std::sync::Arc;\n+//!\n+//! use arrow::array::Int32Array;\n+//! use arrow::datatypes::{DataType, Field, Schema};\n+//! use arrow::json;\n+//! use arrow::record_batch::RecordBatch;\n+//!\n+//! let schema = Schema::new(vec![Field::new(\"a\", DataType::Int32, false)]);\n+//! let a = Int32Array::from(vec![1, 2, 3]);\n+//! let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(a)]).unwrap();\n+//!\n+//! let buf = Vec::new();\n+//! let mut writer = json::Writer::new(buf);\n+//! writer.write_batches(&vec![batch]).unwrap();\n+//! ```\n+\n+use std::io::{BufWriter, Write};\n+use std::iter;\n+\n+use serde_json::map::Map as JsonMap;\n+use serde_json::Value;\n+\n+use crate::array::*;\n+use crate::datatypes::*;\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+fn primitive_array_to_json<T: ArrowPrimitiveType>(array: &ArrayRef) -> Vec<Value> {\n+    as_primitive_array::<T>(array)\n+        .iter()\n+        .map(|maybe_value| match maybe_value {\n+            Some(v) => v.into_json_value().unwrap_or(Value::Null),\n+            None => Value::Null,\n+        })\n+        .collect()\n+}\n+\n+fn struct_array_to_jsonmap_array(\n+    array: &StructArray,\n+    row_count: usize,\n+) -> Vec<JsonMap<String, Value>> {\n+    let inner_col_names = array.column_names();\n+\n+    let mut inner_objs = iter::repeat(JsonMap::new())\n+        .take(row_count)\n+        .collect::<Vec<JsonMap<String, Value>>>();\n+\n+    array\n+        .columns()\n+        .iter()\n+        .enumerate()\n+        .for_each(|(j, struct_col)| {\n+            set_column_for_json_rows(\n+                &mut inner_objs,\n+                row_count,\n+                struct_col,\n+                inner_col_names[j],\n+            );\n+        });\n+\n+    inner_objs\n+}\n+\n+pub fn array_to_json_array(array: &ArrayRef) -> Vec<Value> {\n+    match array.data_type() {\n+        DataType::Null => iter::repeat(Value::Null).take(array.len()).collect(),\n+        DataType::Boolean => as_boolean_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+\n+        DataType::Utf8 => as_string_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => v.into(),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Int8 => primitive_array_to_json::<Int8Type>(array),\n+        DataType::Int16 => primitive_array_to_json::<Int16Type>(array),\n+        DataType::Int32 => primitive_array_to_json::<Int32Type>(array),\n+        DataType::Int64 => primitive_array_to_json::<Int64Type>(array),\n+        DataType::UInt8 => primitive_array_to_json::<UInt8Type>(array),\n+        DataType::UInt16 => primitive_array_to_json::<UInt16Type>(array),\n+        DataType::UInt32 => primitive_array_to_json::<UInt32Type>(array),\n+        DataType::UInt64 => primitive_array_to_json::<UInt64Type>(array),\n+        DataType::Float32 => primitive_array_to_json::<Float32Type>(array),\n+        DataType::Float64 => primitive_array_to_json::<Float64Type>(array),\n+        DataType::List(_) => as_list_array(array)\n+            .iter()\n+            .map(|maybe_value| match maybe_value {\n+                Some(v) => Value::Array(array_to_json_array(&v)),\n+                None => Value::Null,\n+            })\n+            .collect(),\n+        DataType::Struct(_) => {\n+            let jsonmaps =\n+                struct_array_to_jsonmap_array(as_struct_array(array), array.len());\n+            jsonmaps.into_iter().map(Value::Object).collect()\n+        }\n+        _ => {\n\nReview comment:\n       yeah, i was planning to add dictionary support, but this patch set grew larger than I expected, so I decided to leave that to a follow up PR for easier review.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-02T05:55:17.758+0000",
                    "updated": "2021-02-02T05:55:17.758+0000",
                    "started": "2021-02-02T05:55:17.758+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545805",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/545807",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorgecarleitao commented on a change in pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#discussion_r568340343\n\n\n\n##########\nFile path: rust/arrow/src/array/cast.rs\n##########\n@@ -40,12 +40,20 @@ where\n         .expect(\"Unable to downcast to dictionary array\")\n }\n \n-pub fn as_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n+pub fn as_generic_list_array<S: OffsetSizeTrait>(arr: &ArrayRef) -> &GenericListArray<S> {\n     arr.as_any()\n         .downcast_ref::<GenericListArray<S>>()\n         .expect(\"Unable to downcast to list array\")\n }\n \n+pub fn as_list_array(arr: &ArrayRef) -> &ListArray {\n\nReview comment:\n       Makes sense. Let's keep it \ud83d\udc4d\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-02T05:55:54.596+0000",
                    "updated": "2021-02-02T05:55:54.596+0000",
                    "started": "2021-02-02T05:55:54.596+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "545807",
                    "issueId": "13353163"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/worklog/546261",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "alamb commented on pull request #9256:\nURL: https://github.com/apache/arrow/pull/9256#issuecomment-771974198\n\n\n   I plan to review this PR later today and merge unless I hear otherwise\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-02T20:50:18.043+0000",
                    "updated": "2021-02-02T20:50:18.043+0000",
                    "started": "2021-02-02T20:50:18.042+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "546261",
                    "issueId": "13353163"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
            "id": "3",
            "description": "A task that needs to be done.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
            "name": "Task",
            "subtask": false,
            "avatarId": 21148
        },
        "timespent": 15600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@5280a857[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7ae79c46[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3b25444a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@7de6eac4[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@54b7f564[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@3c33d02a[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2d25d4f2[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@675fbb58[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@ca87e02[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@2e385d3d[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2d398e4c[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@372675c8[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 15600,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Feb 02 22:47:40 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-02-02T22:47:40.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-11310/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2021-01-19T03:13:24.000+0000",
        "updated": "2021-02-03T01:31:56.000+0000",
        "timeoriginalestimate": null,
        "description": null,
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "4h 20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 15600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Rust] Implement arrow JSON writer",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13353163/comment/17277512",
                    "id": "17277512",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 9256\n[https://github.com/apache/arrow/pull/9256]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=alamb",
                        "name": "alamb",
                        "key": "alamb",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=alamb&avatarId=43364",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=alamb&avatarId=43364",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=alamb&avatarId=43364",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=alamb&avatarId=43364"
                        },
                        "displayName": "Andrew Lamb",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-02-02T22:47:40.652+0000",
                    "updated": "2021-02-02T22:47:40.652+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0mqqg:",
        "customfield_12314139": null
    }
}