{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13188941",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941",
    "key": "ARROW-3409",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343858",
                "id": "12343858",
                "description": "",
                "name": "0.12.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-01-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343066",
                "id": "12343066",
                "description": "",
                "name": "0.11.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-10-08"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12544638",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12544638",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13071629",
                    "key": "ARROW-1019",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629",
                    "fields": {
                        "summary": "[C++] Implement input stream and output stream with Gzip codec",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "aggregateprogress": {
            "progress": 13200,
            "total": 13200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 13200,
            "total": 13200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3409/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 26,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/150823",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou opened a new pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696\n \n \n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-03T16:41:47.060+0000",
                    "updated": "2018-10-03T16:41:47.060+0000",
                    "started": "2018-10-03T16:41:47.059+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "150823",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151473",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222863813\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_lz4.cc\n ##########\n @@ -18,17 +18,258 @@\n #include \"arrow/util/compression_lz4.h\"\n \n #include <cstdint>\n+#include <sstream>\n \n #include <lz4.h>\n+#include <lz4frame.h>\n \n #include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n #include \"arrow/util/macros.h\"\n \n namespace arrow {\n namespace util {\n \n // ----------------------------------------------------------------------\n-// Lz4 implementation\n+// Lz4 decompressor implementation\n+\n+class LZ4Decompressor : public Decompressor {\n+ public:\n+  LZ4Decompressor() {}\n+\n+  ~LZ4Decompressor() override {\n+    if (ctx_ != nullptr) {\n+      ARROW_UNUSED(LZ4F_freeDecompressionContext(ctx_));\n+    }\n+  }\n+\n+  Status Init() {\n+    LZ4F_errorCode_t ret;\n+    finished_ = false;\n+\n+    ret = LZ4F_createDecompressionContext(&ctx_, LZ4F_VERSION);\n+    if (LZ4F_isError(ret)) {\n+      return LZ4Error(ret, \"LZ4 init failed: \");\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    auto src = input;\n+    auto dst = output;\n+    auto srcSize = static_cast<size_t>(input_len);\n+    auto dstCapacity = static_cast<size_t>(output_len);\n+    size_t ret;\n+\n+    ret = LZ4F_decompress(ctx_, dst, &dstCapacity, src, &srcSize, nullptr /* options */);\n+    if (LZ4F_isError(ret)) {\n+      return LZ4Error(ret, \"LZ4 decompress failed: \");\n+    }\n+    *bytes_read = static_cast<int64_t>(srcSize);\n+    *bytes_written = static_cast<int64_t>(dstCapacity);\n+    *need_more_output = (*bytes_read == 0 && *bytes_written == 0);\n+    finished_ = (ret == 0);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return finished_; }\n+\n+ protected:\n+  Status LZ4Error(LZ4F_errorCode_t ret, const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg << LZ4F_getErrorName(ret);\n+    return Status::IOError(ss.str());\n+  }\n+\n+  LZ4F_dctx* ctx_ = nullptr;\n+  bool finished_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Lz4 compressor implementation\n+\n+class LZ4Compressor : public Compressor {\n+ public:\n+  LZ4Compressor() {}\n+\n+  ~LZ4Compressor() override {\n+    if (ctx_ != nullptr) {\n+      ARROW_UNUSED(LZ4F_freeCompressionContext(ctx_));\n+    }\n+  }\n+\n+  Status Init() {\n+    LZ4F_errorCode_t ret;\n+    memset(&prefs_, 0, sizeof(prefs_));\n+    first_time_ = true;\n+\n+    ret = LZ4F_createCompressionContext(&ctx_, LZ4F_VERSION);\n+    if (LZ4F_isError(ret)) {\n+      return LZ4Error(ret, \"LZ4 init failed: \");\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Compress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                  uint8_t* output, int64_t* bytes_read, int64_t* bytes_written) override;\n+\n+  Status Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+               bool* should_retry) override;\n+\n+  Status End(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+             bool* should_retry) override;\n+\n+ protected:\n+  Status LZ4Error(LZ4F_errorCode_t ret, const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg << LZ4F_getErrorName(ret);\n+    return Status::IOError(ss.str());\n+  }\n+\n+  LZ4F_cctx* ctx_ = nullptr;\n+  LZ4F_preferences_t prefs_;\n+  bool first_time_;\n+};\n+\n+Status LZ4Compressor::Compress(int64_t input_len, const uint8_t* input,\n+                               int64_t output_len, uint8_t* output, int64_t* bytes_read,\n+                               int64_t* bytes_written) {\n+  auto src = input;\n+  auto dst = output;\n+  auto srcSize = static_cast<size_t>(input_len);\n+  auto dstCapacity = static_cast<size_t>(output_len);\n+  size_t ret;\n+\n+  *bytes_read = 0;\n+  *bytes_written = 0;\n+\n+  if (first_time_) {\n \n Review comment:\n   This block (until line 168) is repeated 3 times with a minor variant (first parameter to LZ4F_compressBound), I think a private method could remove this redundancy or macro if there's too much parameter to carry.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:31.957+0000",
                    "updated": "2018-10-05T01:30:31.957+0000",
                    "started": "2018-10-05T01:30:31.956+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151473",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151474",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222871107\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_brotli.cc\n ##########\n @@ -19,19 +19,180 @@\n \n #include <cstddef>\n #include <cstdint>\n+#include <sstream>\n \n #include <brotli/decode.h>\n #include <brotli/encode.h>\n #include <brotli/types.h>\n \n #include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n #include \"arrow/util/macros.h\"\n \n namespace arrow {\n namespace util {\n \n // ----------------------------------------------------------------------\n-// Brotli implementation\n+// Brotli decompressor implementation\n+\n+class BrotliDecompressor : public Decompressor {\n+ public:\n+  BrotliDecompressor() {}\n+\n+  ~BrotliDecompressor() override {\n+    if (state_ != nullptr) {\n+      BrotliDecoderDestroyInstance(state_);\n+    }\n+  }\n+\n+  Status Init() {\n+    state_ = BrotliDecoderCreateInstance(nullptr, nullptr, nullptr);\n+    if (state_ == nullptr) {\n+      return BrotliError(\"Brotli init failed\");\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    auto avail_in = static_cast<size_t>(input_len);\n+    auto avail_out = static_cast<size_t>(output_len);\n+    BrotliDecoderResult ret;\n+\n+    ret = BrotliDecoderDecompressStream(state_, &avail_in, &input, &avail_out, &output,\n+                                        nullptr /* total_out */);\n+    if (ret == BROTLI_DECODER_RESULT_ERROR) {\n+      return BrotliError(BrotliDecoderGetErrorCode(state_), \"Brotli decompress failed: \");\n+    }\n+    *need_more_output = (ret == BROTLI_DECODER_RESULT_NEEDS_MORE_OUTPUT);\n+    *bytes_read = static_cast<int64_t>(input_len - avail_in);\n+    *bytes_written = static_cast<int64_t>(output_len - avail_out);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return BrotliDecoderIsFinished(state_); }\n+\n+ protected:\n+  Status BrotliError(const char* msg) { return Status::IOError(msg); }\n+\n+  Status BrotliError(BrotliDecoderErrorCode code, const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg << BrotliDecoderErrorString(code);\n+    return Status::IOError(ss.str());\n+  }\n+\n+  BrotliDecoderState* state_ = nullptr;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Brotli compressor implementation\n+\n+class BrotliCompressor : public Compressor {\n+ public:\n+  BrotliCompressor() {}\n+\n+  ~BrotliCompressor() override {\n+    if (state_ != nullptr) {\n+      BrotliEncoderDestroyInstance(state_);\n+    }\n+  }\n+\n+  Status Init() {\n+    state_ = BrotliEncoderCreateInstance(nullptr, nullptr, nullptr);\n+    if (state_ == nullptr) {\n+      return BrotliError(\"Brotli init failed\");\n+    }\n+    // Brotli compression quality is max (11) by default, which is slow\n+    if (!BrotliEncoderSetParameter(state_, BROTLI_PARAM_QUALITY, 8)) {\n \n Review comment:\n   `constexpr auto kBrotliDefaultQuality = 8;`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.441+0000",
                    "updated": "2018-10-05T01:30:32.441+0000",
                    "started": "2018-10-05T01:30:32.440+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151474",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151475",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222869016\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n+    stream_.next_out = reinterpret_cast<Bytef*>(output);\n+    stream_.avail_out = static_cast<uInt>(output_len);\n+    int ret;\n+\n+    ret = inflate(&stream_, Z_SYNC_FLUSH);\n+    if (ret == Z_DATA_ERROR || ret == Z_STREAM_ERROR || ret == Z_MEM_ERROR) {\n+      return ZlibError(\"zlib inflate failed: \");\n+    }\n+    if (ret == Z_NEED_DICT) {\n+      return ZlibError(\"zlib inflate failed (need preset dictionary): \");\n+    }\n+    if (ret == Z_BUF_ERROR) {\n+      // No progress was possible\n+      *bytes_read = 0;\n+      *bytes_written = 0;\n+      *need_more_output = true;\n+    } else {\n+      // Some progress has been made\n+      *bytes_read = input_len - stream_.avail_in;\n+      *bytes_written = output_len - stream_.avail_out;\n+      *need_more_output = false;\n+    }\n+    finished_ = (ret == Z_STREAM_END);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return finished_; }\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+  bool finished_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// gzip compressor implementation\n+\n+class GZipCompressor : public Compressor {\n+ public:\n+  GZipCompressor() : initialized_(false) {}\n+\n+  ~GZipCompressor() override {\n+    if (initialized_) {\n+      deflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = deflateInit2(&stream_, Z_DEFAULT_COMPRESSION, Z_DEFLATED, window_bits, 9,\n \n Review comment:\n   9?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.577+0000",
                    "updated": "2018-10-05T01:30:32.577+0000",
                    "started": "2018-10-05T01:30:32.577+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151475",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151476",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222868674\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n \n Review comment:\n   When `input_len > UINT_MAX` avail_in is truncated to 0 (see https://coliru.stacked-crooked.com/a/e8e64f3d7b473acd) which will enter in a weird state. In wouldn't be surprised if users tries to decompress file greater than 4GB.\r\n   \r\n   I suggest to emulate `std::clamp` with (0, std::numeric_limits<uInt>::max()).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.670+0000",
                    "updated": "2018-10-05T01:30:32.670+0000",
                    "started": "2018-10-05T01:30:32.670+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151476",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151477",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222402141\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zstd.cc\n ##########\n @@ -52,8 +220,10 @@ int64_t ZSTDCodec::MaxCompressedLen(int64_t input_len,\n Status ZSTDCodec::Compress(int64_t input_len, const uint8_t* input,\n                            int64_t output_buffer_len, uint8_t* output_buffer,\n                            int64_t* output_length) {\n-  *output_length = ZSTD_compress(output_buffer, static_cast<size_t>(output_buffer_len),\n-                                 input, static_cast<size_t>(input_len), 1);\n+  // XXX level = 1 probably doesn't compress very much\n+  *output_length =\n+      ZSTD_compress(output_buffer, static_cast<size_t>(output_buffer_len), input,\n+                    static_cast<size_t>(input_len), 1 /* compressionLevel */);\n \n Review comment:\n   `constexpr auto kZstdDefaultCompressionLevel = 1;`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.720+0000",
                    "updated": "2018-10-05T01:30:32.720+0000",
                    "started": "2018-10-05T01:30:32.719+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151477",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151478",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222871223\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression.h\n ##########\n @@ -21,32 +21,112 @@\n #include <cstdint>\n #include <memory>\n \n-#include \"arrow/status.h\"\n #include \"arrow/util/visibility.h\"\n \n namespace arrow {\n \n+class Status;\n+\n struct Compression {\n   enum type { UNCOMPRESSED, SNAPPY, GZIP, BROTLI, ZSTD, LZ4, LZO };\n };\n \n namespace util {\n \n+/// \\brief Streaming compressor interface\n+///\n+class ARROW_EXPORT Compressor {\n+ public:\n+  virtual ~Compressor();\n+\n+  /// \\brief Compress some input.\n+  ///\n+  /// If bytes_read is 0 on return, then a larger output buffer should be supplied.\n+  virtual Status Compress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                          uint8_t* output, int64_t* bytes_read,\n+                          int64_t* bytes_written) = 0;\n+\n+  /// \\brief Flush part of the compressed output.\n \n Review comment:\n   Why and when should the user call Flush?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.865+0000",
                    "updated": "2018-10-05T01:30:32.865+0000",
                    "started": "2018-10-05T01:30:32.865+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151478",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151479",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222865094\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n+    stream_.next_out = reinterpret_cast<Bytef*>(output);\n+    stream_.avail_out = static_cast<uInt>(output_len);\n+    int ret;\n+\n+    ret = inflate(&stream_, Z_SYNC_FLUSH);\n+    if (ret == Z_DATA_ERROR || ret == Z_STREAM_ERROR || ret == Z_MEM_ERROR) {\n+      return ZlibError(\"zlib inflate failed: \");\n+    }\n+    if (ret == Z_NEED_DICT) {\n+      return ZlibError(\"zlib inflate failed (need preset dictionary): \");\n+    }\n+    if (ret == Z_BUF_ERROR) {\n+      // No progress was possible\n+      *bytes_read = 0;\n+      *bytes_written = 0;\n+      *need_more_output = true;\n+    } else {\n \n Review comment:\n   I'd `assert(ret = Z_OK)` or fail graciously just in case that a shared lib gzip returns something new.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.874+0000",
                    "updated": "2018-10-05T01:30:32.874+0000",
                    "started": "2018-10-05T01:30:32.874+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151479",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151480",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222868712\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n+    stream_.next_out = reinterpret_cast<Bytef*>(output);\n+    stream_.avail_out = static_cast<uInt>(output_len);\n \n Review comment:\n   Ditto.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.960+0000",
                    "updated": "2018-10-05T01:30:32.960+0000",
                    "started": "2018-10-05T01:30:32.959+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151480",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151481",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222864334\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n \n Review comment:\n   Prefer switch statement with default returning error, gcc will even warn you if your search is non exhaustive (-Wswitch-enum) if someone ever changes GZipCodec.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.961+0000",
                    "updated": "2018-10-05T01:30:32.961+0000",
                    "started": "2018-10-05T01:30:32.960+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151481",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151482",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222868983\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n+    stream_.next_out = reinterpret_cast<Bytef*>(output);\n+    stream_.avail_out = static_cast<uInt>(output_len);\n+    int ret;\n+\n+    ret = inflate(&stream_, Z_SYNC_FLUSH);\n+    if (ret == Z_DATA_ERROR || ret == Z_STREAM_ERROR || ret == Z_MEM_ERROR) {\n+      return ZlibError(\"zlib inflate failed: \");\n+    }\n+    if (ret == Z_NEED_DICT) {\n+      return ZlibError(\"zlib inflate failed (need preset dictionary): \");\n+    }\n+    if (ret == Z_BUF_ERROR) {\n+      // No progress was possible\n+      *bytes_read = 0;\n+      *bytes_written = 0;\n+      *need_more_output = true;\n+    } else {\n+      // Some progress has been made\n+      *bytes_read = input_len - stream_.avail_in;\n+      *bytes_written = output_len - stream_.avail_out;\n+      *need_more_output = false;\n+    }\n+    finished_ = (ret == Z_STREAM_END);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return finished_; }\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+  bool finished_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// gzip compressor implementation\n+\n+class GZipCompressor : public Compressor {\n+ public:\n+  GZipCompressor() : initialized_(false) {}\n+\n+  ~GZipCompressor() override {\n+    if (initialized_) {\n+      deflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n \n Review comment:\n   Same for switch.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.985+0000",
                    "updated": "2018-10-05T01:30:32.985+0000",
                    "started": "2018-10-05T01:30:32.985+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151482",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151483",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222870685\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression-test.cc\n ##########\n @@ -69,25 +71,303 @@ void CheckCodecRoundtrip(const vector<uint8_t>& data) {\n   ASSERT_EQ(data, decompressed);\n }\n \n-template <Compression::type CODEC>\n-void CheckCodec() {\n+// Check the streaming compressor against one-shot decompression\n+\n+void CheckStreamingCompressor(Codec* codec, const vector<uint8_t>& data) {\n+  std::shared_ptr<Compressor> compressor;\n+  ASSERT_OK(codec->MakeCompressor(&compressor));\n+\n+  std::vector<uint8_t> compressed;\n+  int64_t compressed_size = 0;\n+  const uint8_t* input = data.data();\n+  int64_t remaining = data.size();\n+\n+  compressed.resize(10);\n+  bool do_flush = false;\n+\n+  while (remaining > 0) {\n+    // Feed a small amount each time\n+    int64_t input_len = std::min(remaining, static_cast<int64_t>(1111));\n+    int64_t output_len = compressed.size() - compressed_size;\n+    uint8_t* output = compressed.data() + compressed_size;\n+    int64_t bytes_read, bytes_written;\n+    ASSERT_OK(compressor->Compress(input_len, input, output_len, output, &bytes_read,\n+                                   &bytes_written));\n+    ASSERT_LE(bytes_read, input_len);\n+    ASSERT_LE(bytes_written, output_len);\n+    compressed_size += bytes_written;\n+    input += bytes_read;\n+    remaining -= bytes_read;\n+    if (bytes_read == 0) {\n+      compressed.resize(compressed.capacity() * 2);\n+    }\n+    // Once every two iterations, do a flush\n+    if (do_flush) {\n+      bool should_retry = false;\n+      do {\n+        output_len = compressed.size() - compressed_size;\n+        output = compressed.data() + compressed_size;\n+        ASSERT_OK(compressor->Flush(output_len, output, &bytes_written, &should_retry));\n+        ASSERT_LE(bytes_written, output_len);\n+        compressed_size += bytes_written;\n+        if (should_retry) {\n+          compressed.resize(compressed.capacity() * 2);\n+        }\n+      } while (should_retry);\n+    }\n+    do_flush = !do_flush;\n+  }\n+\n+  // End the compressed stream\n+  bool should_retry = false;\n+  do {\n+    int64_t output_len = compressed.size() - compressed_size;\n+    uint8_t* output = compressed.data() + compressed_size;\n+    int64_t bytes_written;\n+    ASSERT_OK(compressor->End(output_len, output, &bytes_written, &should_retry));\n+    ASSERT_LE(bytes_written, output_len);\n+    compressed_size += bytes_written;\n+    if (should_retry) {\n+      compressed.resize(compressed.capacity() * 2);\n+    }\n+  } while (should_retry);\n+\n+  // Check decompressing the compressed data\n+  std::vector<uint8_t> decompressed(data.size());\n+  ASSERT_OK(codec->Decompress(compressed_size, compressed.data(), decompressed.size(),\n+                              decompressed.data()));\n+\n+  ASSERT_EQ(data, decompressed);\n+}\n+\n+// Check the streaming decompressor against one-shot compression\n+\n+void CheckStreamingDecompressor(Codec* codec, const vector<uint8_t>& data) {\n+  // Create compressed data\n+  int64_t max_compressed_len = codec->MaxCompressedLen(data.size(), data.data());\n+  std::vector<uint8_t> compressed(max_compressed_len);\n+  int64_t compressed_size;\n+  ASSERT_OK(codec->Compress(data.size(), data.data(), max_compressed_len,\n+                            compressed.data(), &compressed_size));\n+  compressed.resize(compressed_size);\n+\n+  // Run streaming decompression\n+  std::shared_ptr<Decompressor> decompressor;\n+  ASSERT_OK(codec->MakeDecompressor(&decompressor));\n+\n+  std::vector<uint8_t> decompressed;\n+  int64_t decompressed_size = 0;\n+  const uint8_t* input = compressed.data();\n+  int64_t remaining = compressed.size();\n+\n+  decompressed.resize(10);\n+  while (!decompressor->IsFinished()) {\n+    // Feed a small amount each time\n+    int64_t input_len = std::min(remaining, static_cast<int64_t>(23));\n+    int64_t output_len = decompressed.size() - decompressed_size;\n+    uint8_t* output = decompressed.data() + decompressed_size;\n+    int64_t bytes_read, bytes_written;\n+    bool need_more_output;\n+    ASSERT_OK(decompressor->Decompress(input_len, input, output_len, output, &bytes_read,\n+                                       &bytes_written, &need_more_output));\n+    ASSERT_LE(bytes_read, input_len);\n+    ASSERT_LE(bytes_written, output_len);\n+    ASSERT_TRUE(need_more_output || bytes_written > 0 || bytes_read > 0)\n+        << \"Decompression not progressing anymore\";\n+    if (need_more_output) {\n+      decompressed.resize(decompressed.capacity() * 2);\n+    }\n+    decompressed_size += bytes_written;\n+    input += bytes_read;\n+    remaining -= bytes_read;\n+  }\n+  ASSERT_TRUE(decompressor->IsFinished());\n+  ASSERT_EQ(remaining, 0);\n+\n+  // Check the decompressed data\n+  decompressed.resize(decompressed_size);\n+  ASSERT_EQ(data.size(), decompressed_size);\n+  ASSERT_EQ(data, decompressed);\n+}\n+\n+// Check the streaming compressor and decompressor together\n+\n+void CheckStreamingRoundtrip(Codec* codec, const vector<uint8_t>& data) {\n+  std::shared_ptr<Compressor> compressor;\n+  std::shared_ptr<Decompressor> decompressor;\n+  ASSERT_OK(codec->MakeCompressor(&compressor));\n+  ASSERT_OK(codec->MakeDecompressor(&decompressor));\n+\n+  std::default_random_engine engine(42);\n+  std::uniform_int_distribution<int> buf_size_distribution(10, 40);\n+\n+  auto make_buf_size = [&]() -> int64_t { return buf_size_distribution(engine); };\n+\n+  // Compress...\n+\n+  std::vector<uint8_t> compressed(1);\n+  int64_t compressed_size = 0;\n+  {\n+    const uint8_t* input = data.data();\n+    int64_t remaining = data.size();\n+\n+    while (remaining > 0) {\n+      // Feed a varying amount each time\n+      int64_t input_len = std::min(remaining, make_buf_size());\n+      int64_t output_len = compressed.size() - compressed_size;\n+      uint8_t* output = compressed.data() + compressed_size;\n+      int64_t bytes_read, bytes_written;\n+      ASSERT_OK(compressor->Compress(input_len, input, output_len, output, &bytes_read,\n+                                     &bytes_written));\n+      ASSERT_LE(bytes_read, input_len);\n+      ASSERT_LE(bytes_written, output_len);\n+      compressed_size += bytes_written;\n+      input += bytes_read;\n+      remaining -= bytes_read;\n+      if (bytes_read == 0) {\n+        compressed.resize(compressed.capacity() * 2);\n+      }\n+    }\n+    // End the compressed stream\n+    bool should_retry = false;\n+    do {\n+      int64_t output_len = compressed.size() - compressed_size;\n+      uint8_t* output = compressed.data() + compressed_size;\n+      int64_t bytes_written;\n+      ASSERT_OK(compressor->End(output_len, output, &bytes_written, &should_retry));\n+      ASSERT_LE(bytes_written, output_len);\n+      compressed_size += bytes_written;\n+      if (should_retry) {\n+        compressed.resize(compressed.capacity() * 2);\n+      }\n+    } while (should_retry);\n+\n+    compressed.resize(compressed_size);\n+  }\n+\n+  // Then decompress...\n+\n+  std::vector<uint8_t> decompressed(2);\n+  int64_t decompressed_size = 0;\n+  {\n+    const uint8_t* input = compressed.data();\n+    int64_t remaining = compressed.size();\n+\n+    while (!decompressor->IsFinished()) {\n+      // Feed a varying amount each time\n+      int64_t input_len = std::min(remaining, make_buf_size());\n+      int64_t output_len = decompressed.size() - decompressed_size;\n+      uint8_t* output = decompressed.data() + decompressed_size;\n+      int64_t bytes_read, bytes_written;\n+      bool need_more_output;\n+      ASSERT_OK(decompressor->Decompress(input_len, input, output_len, output,\n+                                         &bytes_read, &bytes_written, &need_more_output));\n+      ASSERT_LE(bytes_read, input_len);\n+      ASSERT_LE(bytes_written, output_len);\n+      ASSERT_TRUE(need_more_output || bytes_written > 0 || bytes_read > 0)\n+          << \"Decompression not progressing anymore\";\n+      if (need_more_output) {\n+        decompressed.resize(decompressed.capacity() * 2);\n+      }\n+      decompressed_size += bytes_written;\n+      input += bytes_read;\n+      remaining -= bytes_read;\n+    }\n+    ASSERT_EQ(remaining, 0);\n+    decompressed.resize(decompressed_size);\n+  }\n+\n+  ASSERT_EQ(data.size(), decompressed.size());\n+  ASSERT_EQ(data, decompressed);\n+}\n+\n+class CodecTest : public ::testing::TestWithParam<Compression::type> {\n+ protected:\n+  Compression::type GetCompression() { return GetParam(); }\n+\n+  std::unique_ptr<Codec> MakeCodec() {\n+    std::unique_ptr<Codec> codec;\n+    ABORT_NOT_OK(Codec::Create(GetCompression(), &codec));\n+    return codec;\n+  }\n+};\n+\n+TEST_P(CodecTest, CodecRoundtrip) {\n   int sizes[] = {0, 10000, 100000};\n   for (int data_size : sizes) {\n     vector<uint8_t> data(data_size);\n     random_bytes(data_size, 1234, data.data());\n-    CheckCodecRoundtrip<CODEC>(data);\n+    CheckCodecRoundtrip(GetCompression(), data);\n+  }\n+}\n+\n+TEST_P(CodecTest, StreamingCompressor) {\n+  if (GetCompression() == Compression::SNAPPY) {\n+    // SKIP: snappy doesn't support streaming compression\n+    return;\n+  }\n+  if (GetCompression() == Compression::LZ4) {\n+    // SKIP: LZ4 streaming compression uses the LZ4 framing format,\n+    // which must be tested against a streaming decompressor\n+    return;\n+  }\n+\n+  int sizes[] = {0, 10, 100000};\n+  for (int data_size : sizes) {\n+    vector<uint8_t> data(data_size);\n+    random_bytes(data_size, 1234, data.data());\n \n Review comment:\n   I would recommend testing on actual files (or very low entropy random) since uniform random data is not very compressible, thus there's less chance you trigger the buffer errors (if any) since input_size ~ output_size.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.988+0000",
                    "updated": "2018-10-05T01:30:32.988+0000",
                    "started": "2018-10-05T01:30:32.987+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151483",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151484",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222869560\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n+    stream_.next_out = reinterpret_cast<Bytef*>(output);\n+    stream_.avail_out = static_cast<uInt>(output_len);\n+    int ret;\n+\n+    ret = inflate(&stream_, Z_SYNC_FLUSH);\n+    if (ret == Z_DATA_ERROR || ret == Z_STREAM_ERROR || ret == Z_MEM_ERROR) {\n+      return ZlibError(\"zlib inflate failed: \");\n+    }\n+    if (ret == Z_NEED_DICT) {\n+      return ZlibError(\"zlib inflate failed (need preset dictionary): \");\n+    }\n+    if (ret == Z_BUF_ERROR) {\n+      // No progress was possible\n+      *bytes_read = 0;\n+      *bytes_written = 0;\n+      *need_more_output = true;\n+    } else {\n+      // Some progress has been made\n+      *bytes_read = input_len - stream_.avail_in;\n+      *bytes_written = output_len - stream_.avail_out;\n+      *need_more_output = false;\n+    }\n+    finished_ = (ret == Z_STREAM_END);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return finished_; }\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+  bool finished_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// gzip compressor implementation\n+\n+class GZipCompressor : public Compressor {\n+ public:\n+  GZipCompressor() : initialized_(false) {}\n+\n+  ~GZipCompressor() override {\n+    if (initialized_) {\n+      deflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = deflateInit2(&stream_, Z_DEFAULT_COMPRESSION, Z_DEFLATED, window_bits, 9,\n+                            Z_DEFAULT_STRATEGY)) != Z_OK) {\n+      return ZlibError(\"zlib deflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Compress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                  uint8_t* output, int64_t* bytes_read, int64_t* bytes_written) override;\n+\n+  Status Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+               bool* should_retry) override;\n+\n+  Status End(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+             bool* should_retry) override;\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+};\n+\n+Status GZipCompressor::Compress(int64_t input_len, const uint8_t* input,\n+                                int64_t output_len, uint8_t* output, int64_t* bytes_read,\n+                                int64_t* bytes_written) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+  stream_.avail_in = static_cast<uInt>(input_len);\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n+\n+  int64_t ret = 0;\n+  ret = deflate(&stream_, Z_NO_FLUSH);\n+  if (ret == Z_STREAM_ERROR) {\n+    return ZlibError(\"zlib compress failed: \");\n+  }\n+  if (ret == Z_OK) {\n+    // Some progress has been made\n+    *bytes_read = input_len - stream_.avail_in;\n+    *bytes_written = output_len - stream_.avail_out;\n+  } else {\n+    // No progress was possible\n+    DCHECK_EQ(ret, Z_BUF_ERROR);\n+    *bytes_read = 0;\n+    *bytes_written = 0;\n+  }\n+  return Status::OK();\n+}\n+\n+Status GZipCompressor::Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+                             bool* should_retry) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.avail_in = 0;\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n+\n+  int64_t ret = 0;\n+  ret = deflate(&stream_, Z_SYNC_FLUSH);\n+  if (ret == Z_STREAM_ERROR) {\n+    return ZlibError(\"zlib flush failed: \");\n+  }\n+  if (ret == Z_OK) {\n+    *bytes_written = output_len - stream_.avail_out;\n+  } else {\n+    DCHECK_EQ(ret, Z_BUF_ERROR);\n+    *bytes_written = 0;\n+  }\n+  // \"If deflate returns with avail_out == 0, this function must be called\n+  //  again with the same value of the flush parameter and more output space\n+  //  (updated avail_out), until the flush is complete (deflate returns\n+  //  with non-zero avail_out).\"\n+  *should_retry = (*bytes_written == 0);\n+  return Status::OK();\n+}\n+\n+Status GZipCompressor::End(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+                           bool* should_retry) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.avail_in = 0;\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n+\n+  int64_t ret = 0;\n \n Review comment:\n   Why on 2 lines?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:32.996+0000",
                    "updated": "2018-10-05T01:30:32.996+0000",
                    "started": "2018-10-05T01:30:32.995+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151484",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151485",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222869451\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n+    stream_.next_out = reinterpret_cast<Bytef*>(output);\n+    stream_.avail_out = static_cast<uInt>(output_len);\n+    int ret;\n+\n+    ret = inflate(&stream_, Z_SYNC_FLUSH);\n+    if (ret == Z_DATA_ERROR || ret == Z_STREAM_ERROR || ret == Z_MEM_ERROR) {\n+      return ZlibError(\"zlib inflate failed: \");\n+    }\n+    if (ret == Z_NEED_DICT) {\n+      return ZlibError(\"zlib inflate failed (need preset dictionary): \");\n+    }\n+    if (ret == Z_BUF_ERROR) {\n+      // No progress was possible\n+      *bytes_read = 0;\n+      *bytes_written = 0;\n+      *need_more_output = true;\n+    } else {\n+      // Some progress has been made\n+      *bytes_read = input_len - stream_.avail_in;\n+      *bytes_written = output_len - stream_.avail_out;\n+      *need_more_output = false;\n+    }\n+    finished_ = (ret == Z_STREAM_END);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return finished_; }\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+  bool finished_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// gzip compressor implementation\n+\n+class GZipCompressor : public Compressor {\n+ public:\n+  GZipCompressor() : initialized_(false) {}\n+\n+  ~GZipCompressor() override {\n+    if (initialized_) {\n+      deflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = deflateInit2(&stream_, Z_DEFAULT_COMPRESSION, Z_DEFLATED, window_bits, 9,\n+                            Z_DEFAULT_STRATEGY)) != Z_OK) {\n+      return ZlibError(\"zlib deflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Compress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                  uint8_t* output, int64_t* bytes_read, int64_t* bytes_written) override;\n+\n+  Status Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+               bool* should_retry) override;\n+\n+  Status End(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+             bool* should_retry) override;\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+};\n+\n+Status GZipCompressor::Compress(int64_t input_len, const uint8_t* input,\n+                                int64_t output_len, uint8_t* output, int64_t* bytes_read,\n+                                int64_t* bytes_written) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+  stream_.avail_in = static_cast<uInt>(input_len);\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n+\n+  int64_t ret = 0;\n+  ret = deflate(&stream_, Z_NO_FLUSH);\n+  if (ret == Z_STREAM_ERROR) {\n+    return ZlibError(\"zlib compress failed: \");\n+  }\n+  if (ret == Z_OK) {\n+    // Some progress has been made\n+    *bytes_read = input_len - stream_.avail_in;\n+    *bytes_written = output_len - stream_.avail_out;\n+  } else {\n+    // No progress was possible\n+    DCHECK_EQ(ret, Z_BUF_ERROR);\n+    *bytes_read = 0;\n+    *bytes_written = 0;\n+  }\n+  return Status::OK();\n+}\n+\n+Status GZipCompressor::Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+                             bool* should_retry) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.avail_in = 0;\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n \n Review comment:\n   Again truncation could lead to infinite loop because user tries to grow buffer in-definitively (since should_retry == true and bytes_written == 0).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T01:30:33.004+0000",
                    "updated": "2018-10-05T01:30:33.004+0000",
                    "started": "2018-10-05T01:30:33.004+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151485",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151540",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222931424\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_lz4.cc\n ##########\n @@ -18,17 +18,258 @@\n #include \"arrow/util/compression_lz4.h\"\n \n #include <cstdint>\n+#include <sstream>\n \n #include <lz4.h>\n+#include <lz4frame.h>\n \n #include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n #include \"arrow/util/macros.h\"\n \n namespace arrow {\n namespace util {\n \n // ----------------------------------------------------------------------\n-// Lz4 implementation\n+// Lz4 decompressor implementation\n+\n+class LZ4Decompressor : public Decompressor {\n+ public:\n+  LZ4Decompressor() {}\n+\n+  ~LZ4Decompressor() override {\n+    if (ctx_ != nullptr) {\n+      ARROW_UNUSED(LZ4F_freeDecompressionContext(ctx_));\n+    }\n+  }\n+\n+  Status Init() {\n+    LZ4F_errorCode_t ret;\n+    finished_ = false;\n+\n+    ret = LZ4F_createDecompressionContext(&ctx_, LZ4F_VERSION);\n+    if (LZ4F_isError(ret)) {\n+      return LZ4Error(ret, \"LZ4 init failed: \");\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    auto src = input;\n+    auto dst = output;\n+    auto srcSize = static_cast<size_t>(input_len);\n+    auto dstCapacity = static_cast<size_t>(output_len);\n+    size_t ret;\n+\n+    ret = LZ4F_decompress(ctx_, dst, &dstCapacity, src, &srcSize, nullptr /* options */);\n+    if (LZ4F_isError(ret)) {\n+      return LZ4Error(ret, \"LZ4 decompress failed: \");\n+    }\n+    *bytes_read = static_cast<int64_t>(srcSize);\n+    *bytes_written = static_cast<int64_t>(dstCapacity);\n+    *need_more_output = (*bytes_read == 0 && *bytes_written == 0);\n+    finished_ = (ret == 0);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return finished_; }\n+\n+ protected:\n+  Status LZ4Error(LZ4F_errorCode_t ret, const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg << LZ4F_getErrorName(ret);\n+    return Status::IOError(ss.str());\n+  }\n+\n+  LZ4F_dctx* ctx_ = nullptr;\n+  bool finished_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Lz4 compressor implementation\n+\n+class LZ4Compressor : public Compressor {\n+ public:\n+  LZ4Compressor() {}\n+\n+  ~LZ4Compressor() override {\n+    if (ctx_ != nullptr) {\n+      ARROW_UNUSED(LZ4F_freeCompressionContext(ctx_));\n+    }\n+  }\n+\n+  Status Init() {\n+    LZ4F_errorCode_t ret;\n+    memset(&prefs_, 0, sizeof(prefs_));\n+    first_time_ = true;\n+\n+    ret = LZ4F_createCompressionContext(&ctx_, LZ4F_VERSION);\n+    if (LZ4F_isError(ret)) {\n+      return LZ4Error(ret, \"LZ4 init failed: \");\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Compress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                  uint8_t* output, int64_t* bytes_read, int64_t* bytes_written) override;\n+\n+  Status Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+               bool* should_retry) override;\n+\n+  Status End(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+             bool* should_retry) override;\n+\n+ protected:\n+  Status LZ4Error(LZ4F_errorCode_t ret, const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg << LZ4F_getErrorName(ret);\n+    return Status::IOError(ss.str());\n+  }\n+\n+  LZ4F_cctx* ctx_ = nullptr;\n+  LZ4F_preferences_t prefs_;\n+  bool first_time_;\n+};\n+\n+Status LZ4Compressor::Compress(int64_t input_len, const uint8_t* input,\n+                               int64_t output_len, uint8_t* output, int64_t* bytes_read,\n+                               int64_t* bytes_written) {\n+  auto src = input;\n+  auto dst = output;\n+  auto srcSize = static_cast<size_t>(input_len);\n+  auto dstCapacity = static_cast<size_t>(output_len);\n+  size_t ret;\n+\n+  *bytes_read = 0;\n+  *bytes_written = 0;\n+\n+  if (first_time_) {\n \n Review comment:\n   I initially tried with a helper method but it didn't reduce linecount much. I'll try with a macro.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T08:41:48.670+0000",
                    "updated": "2018-10-05T08:41:48.670+0000",
                    "started": "2018-10-05T08:41:48.669+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151540",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151541",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222931552\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n \n Review comment:\n   Right. We're generally not very careful to test for truncation :-/\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T08:42:19.825+0000",
                    "updated": "2018-10-05T08:42:19.825+0000",
                    "started": "2018-10-05T08:42:19.824+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151541",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151542",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222932055\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n+    stream_.next_out = reinterpret_cast<Bytef*>(output);\n+    stream_.avail_out = static_cast<uInt>(output_len);\n+    int ret;\n+\n+    ret = inflate(&stream_, Z_SYNC_FLUSH);\n+    if (ret == Z_DATA_ERROR || ret == Z_STREAM_ERROR || ret == Z_MEM_ERROR) {\n+      return ZlibError(\"zlib inflate failed: \");\n+    }\n+    if (ret == Z_NEED_DICT) {\n+      return ZlibError(\"zlib inflate failed (need preset dictionary): \");\n+    }\n+    if (ret == Z_BUF_ERROR) {\n+      // No progress was possible\n+      *bytes_read = 0;\n+      *bytes_written = 0;\n+      *need_more_output = true;\n+    } else {\n+      // Some progress has been made\n+      *bytes_read = input_len - stream_.avail_in;\n+      *bytes_written = output_len - stream_.avail_out;\n+      *need_more_output = false;\n+    }\n+    finished_ = (ret == Z_STREAM_END);\n+    return Status::OK();\n+  }\n+\n+  bool IsFinished() override { return finished_; }\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+  bool finished_;\n+};\n+\n+// ----------------------------------------------------------------------\n+// gzip compressor implementation\n+\n+class GZipCompressor : public Compressor {\n+ public:\n+  GZipCompressor() : initialized_(false) {}\n+\n+  ~GZipCompressor() override {\n+    if (initialized_) {\n+      deflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = deflateInit2(&stream_, Z_DEFAULT_COMPRESSION, Z_DEFLATED, window_bits, 9,\n+                            Z_DEFAULT_STRATEGY)) != Z_OK) {\n+      return ZlibError(\"zlib deflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Compress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                  uint8_t* output, int64_t* bytes_read, int64_t* bytes_written) override;\n+\n+  Status Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+               bool* should_retry) override;\n+\n+  Status End(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+             bool* should_retry) override;\n+\n+ protected:\n+  Status ZlibError(const char* prefix_msg) {\n+    std::stringstream ss;\n+    ss << prefix_msg;\n+    if (stream_.msg && *stream_.msg) {\n+      ss << stream_.msg;\n+    } else {\n+      ss << \"(unknown error)\";\n+    }\n+    return Status::IOError(ss.str());\n+  }\n+\n+  z_stream stream_;\n+  bool initialized_;\n+};\n+\n+Status GZipCompressor::Compress(int64_t input_len, const uint8_t* input,\n+                                int64_t output_len, uint8_t* output, int64_t* bytes_read,\n+                                int64_t* bytes_written) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+  stream_.avail_in = static_cast<uInt>(input_len);\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n+\n+  int64_t ret = 0;\n+  ret = deflate(&stream_, Z_NO_FLUSH);\n+  if (ret == Z_STREAM_ERROR) {\n+    return ZlibError(\"zlib compress failed: \");\n+  }\n+  if (ret == Z_OK) {\n+    // Some progress has been made\n+    *bytes_read = input_len - stream_.avail_in;\n+    *bytes_written = output_len - stream_.avail_out;\n+  } else {\n+    // No progress was possible\n+    DCHECK_EQ(ret, Z_BUF_ERROR);\n+    *bytes_read = 0;\n+    *bytes_written = 0;\n+  }\n+  return Status::OK();\n+}\n+\n+Status GZipCompressor::Flush(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+                             bool* should_retry) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.avail_in = 0;\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n+\n+  int64_t ret = 0;\n+  ret = deflate(&stream_, Z_SYNC_FLUSH);\n+  if (ret == Z_STREAM_ERROR) {\n+    return ZlibError(\"zlib flush failed: \");\n+  }\n+  if (ret == Z_OK) {\n+    *bytes_written = output_len - stream_.avail_out;\n+  } else {\n+    DCHECK_EQ(ret, Z_BUF_ERROR);\n+    *bytes_written = 0;\n+  }\n+  // \"If deflate returns with avail_out == 0, this function must be called\n+  //  again with the same value of the flush parameter and more output space\n+  //  (updated avail_out), until the flush is complete (deflate returns\n+  //  with non-zero avail_out).\"\n+  *should_retry = (*bytes_written == 0);\n+  return Status::OK();\n+}\n+\n+Status GZipCompressor::End(int64_t output_len, uint8_t* output, int64_t* bytes_written,\n+                           bool* should_retry) {\n+  DCHECK(initialized_) << \"Called on non-initialized stream\";\n+\n+  stream_.avail_in = 0;\n+  stream_.next_out = reinterpret_cast<Bytef*>(output);\n+  stream_.avail_out = static_cast<uInt>(output_len);\n+\n+  int64_t ret = 0;\n \n Review comment:\n   Nothing special, it's the style used (arbitrarily) throughout this PR.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T08:44:01.964+0000",
                    "updated": "2018-10-05T08:44:01.964+0000",
                    "started": "2018-10-05T08:44:01.963+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151542",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151543",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222932119\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression-test.cc\n ##########\n @@ -69,25 +71,303 @@ void CheckCodecRoundtrip(const vector<uint8_t>& data) {\n   ASSERT_EQ(data, decompressed);\n }\n \n-template <Compression::type CODEC>\n-void CheckCodec() {\n+// Check the streaming compressor against one-shot decompression\n+\n+void CheckStreamingCompressor(Codec* codec, const vector<uint8_t>& data) {\n+  std::shared_ptr<Compressor> compressor;\n+  ASSERT_OK(codec->MakeCompressor(&compressor));\n+\n+  std::vector<uint8_t> compressed;\n+  int64_t compressed_size = 0;\n+  const uint8_t* input = data.data();\n+  int64_t remaining = data.size();\n+\n+  compressed.resize(10);\n+  bool do_flush = false;\n+\n+  while (remaining > 0) {\n+    // Feed a small amount each time\n+    int64_t input_len = std::min(remaining, static_cast<int64_t>(1111));\n+    int64_t output_len = compressed.size() - compressed_size;\n+    uint8_t* output = compressed.data() + compressed_size;\n+    int64_t bytes_read, bytes_written;\n+    ASSERT_OK(compressor->Compress(input_len, input, output_len, output, &bytes_read,\n+                                   &bytes_written));\n+    ASSERT_LE(bytes_read, input_len);\n+    ASSERT_LE(bytes_written, output_len);\n+    compressed_size += bytes_written;\n+    input += bytes_read;\n+    remaining -= bytes_read;\n+    if (bytes_read == 0) {\n+      compressed.resize(compressed.capacity() * 2);\n+    }\n+    // Once every two iterations, do a flush\n+    if (do_flush) {\n+      bool should_retry = false;\n+      do {\n+        output_len = compressed.size() - compressed_size;\n+        output = compressed.data() + compressed_size;\n+        ASSERT_OK(compressor->Flush(output_len, output, &bytes_written, &should_retry));\n+        ASSERT_LE(bytes_written, output_len);\n+        compressed_size += bytes_written;\n+        if (should_retry) {\n+          compressed.resize(compressed.capacity() * 2);\n+        }\n+      } while (should_retry);\n+    }\n+    do_flush = !do_flush;\n+  }\n+\n+  // End the compressed stream\n+  bool should_retry = false;\n+  do {\n+    int64_t output_len = compressed.size() - compressed_size;\n+    uint8_t* output = compressed.data() + compressed_size;\n+    int64_t bytes_written;\n+    ASSERT_OK(compressor->End(output_len, output, &bytes_written, &should_retry));\n+    ASSERT_LE(bytes_written, output_len);\n+    compressed_size += bytes_written;\n+    if (should_retry) {\n+      compressed.resize(compressed.capacity() * 2);\n+    }\n+  } while (should_retry);\n+\n+  // Check decompressing the compressed data\n+  std::vector<uint8_t> decompressed(data.size());\n+  ASSERT_OK(codec->Decompress(compressed_size, compressed.data(), decompressed.size(),\n+                              decompressed.data()));\n+\n+  ASSERT_EQ(data, decompressed);\n+}\n+\n+// Check the streaming decompressor against one-shot compression\n+\n+void CheckStreamingDecompressor(Codec* codec, const vector<uint8_t>& data) {\n+  // Create compressed data\n+  int64_t max_compressed_len = codec->MaxCompressedLen(data.size(), data.data());\n+  std::vector<uint8_t> compressed(max_compressed_len);\n+  int64_t compressed_size;\n+  ASSERT_OK(codec->Compress(data.size(), data.data(), max_compressed_len,\n+                            compressed.data(), &compressed_size));\n+  compressed.resize(compressed_size);\n+\n+  // Run streaming decompression\n+  std::shared_ptr<Decompressor> decompressor;\n+  ASSERT_OK(codec->MakeDecompressor(&decompressor));\n+\n+  std::vector<uint8_t> decompressed;\n+  int64_t decompressed_size = 0;\n+  const uint8_t* input = compressed.data();\n+  int64_t remaining = compressed.size();\n+\n+  decompressed.resize(10);\n+  while (!decompressor->IsFinished()) {\n+    // Feed a small amount each time\n+    int64_t input_len = std::min(remaining, static_cast<int64_t>(23));\n+    int64_t output_len = decompressed.size() - decompressed_size;\n+    uint8_t* output = decompressed.data() + decompressed_size;\n+    int64_t bytes_read, bytes_written;\n+    bool need_more_output;\n+    ASSERT_OK(decompressor->Decompress(input_len, input, output_len, output, &bytes_read,\n+                                       &bytes_written, &need_more_output));\n+    ASSERT_LE(bytes_read, input_len);\n+    ASSERT_LE(bytes_written, output_len);\n+    ASSERT_TRUE(need_more_output || bytes_written > 0 || bytes_read > 0)\n+        << \"Decompression not progressing anymore\";\n+    if (need_more_output) {\n+      decompressed.resize(decompressed.capacity() * 2);\n+    }\n+    decompressed_size += bytes_written;\n+    input += bytes_read;\n+    remaining -= bytes_read;\n+  }\n+  ASSERT_TRUE(decompressor->IsFinished());\n+  ASSERT_EQ(remaining, 0);\n+\n+  // Check the decompressed data\n+  decompressed.resize(decompressed_size);\n+  ASSERT_EQ(data.size(), decompressed_size);\n+  ASSERT_EQ(data, decompressed);\n+}\n+\n+// Check the streaming compressor and decompressor together\n+\n+void CheckStreamingRoundtrip(Codec* codec, const vector<uint8_t>& data) {\n+  std::shared_ptr<Compressor> compressor;\n+  std::shared_ptr<Decompressor> decompressor;\n+  ASSERT_OK(codec->MakeCompressor(&compressor));\n+  ASSERT_OK(codec->MakeDecompressor(&decompressor));\n+\n+  std::default_random_engine engine(42);\n+  std::uniform_int_distribution<int> buf_size_distribution(10, 40);\n+\n+  auto make_buf_size = [&]() -> int64_t { return buf_size_distribution(engine); };\n+\n+  // Compress...\n+\n+  std::vector<uint8_t> compressed(1);\n+  int64_t compressed_size = 0;\n+  {\n+    const uint8_t* input = data.data();\n+    int64_t remaining = data.size();\n+\n+    while (remaining > 0) {\n+      // Feed a varying amount each time\n+      int64_t input_len = std::min(remaining, make_buf_size());\n+      int64_t output_len = compressed.size() - compressed_size;\n+      uint8_t* output = compressed.data() + compressed_size;\n+      int64_t bytes_read, bytes_written;\n+      ASSERT_OK(compressor->Compress(input_len, input, output_len, output, &bytes_read,\n+                                     &bytes_written));\n+      ASSERT_LE(bytes_read, input_len);\n+      ASSERT_LE(bytes_written, output_len);\n+      compressed_size += bytes_written;\n+      input += bytes_read;\n+      remaining -= bytes_read;\n+      if (bytes_read == 0) {\n+        compressed.resize(compressed.capacity() * 2);\n+      }\n+    }\n+    // End the compressed stream\n+    bool should_retry = false;\n+    do {\n+      int64_t output_len = compressed.size() - compressed_size;\n+      uint8_t* output = compressed.data() + compressed_size;\n+      int64_t bytes_written;\n+      ASSERT_OK(compressor->End(output_len, output, &bytes_written, &should_retry));\n+      ASSERT_LE(bytes_written, output_len);\n+      compressed_size += bytes_written;\n+      if (should_retry) {\n+        compressed.resize(compressed.capacity() * 2);\n+      }\n+    } while (should_retry);\n+\n+    compressed.resize(compressed_size);\n+  }\n+\n+  // Then decompress...\n+\n+  std::vector<uint8_t> decompressed(2);\n+  int64_t decompressed_size = 0;\n+  {\n+    const uint8_t* input = compressed.data();\n+    int64_t remaining = compressed.size();\n+\n+    while (!decompressor->IsFinished()) {\n+      // Feed a varying amount each time\n+      int64_t input_len = std::min(remaining, make_buf_size());\n+      int64_t output_len = decompressed.size() - decompressed_size;\n+      uint8_t* output = decompressed.data() + decompressed_size;\n+      int64_t bytes_read, bytes_written;\n+      bool need_more_output;\n+      ASSERT_OK(decompressor->Decompress(input_len, input, output_len, output,\n+                                         &bytes_read, &bytes_written, &need_more_output));\n+      ASSERT_LE(bytes_read, input_len);\n+      ASSERT_LE(bytes_written, output_len);\n+      ASSERT_TRUE(need_more_output || bytes_written > 0 || bytes_read > 0)\n+          << \"Decompression not progressing anymore\";\n+      if (need_more_output) {\n+        decompressed.resize(decompressed.capacity() * 2);\n+      }\n+      decompressed_size += bytes_written;\n+      input += bytes_read;\n+      remaining -= bytes_read;\n+    }\n+    ASSERT_EQ(remaining, 0);\n+    decompressed.resize(decompressed_size);\n+  }\n+\n+  ASSERT_EQ(data.size(), decompressed.size());\n+  ASSERT_EQ(data, decompressed);\n+}\n+\n+class CodecTest : public ::testing::TestWithParam<Compression::type> {\n+ protected:\n+  Compression::type GetCompression() { return GetParam(); }\n+\n+  std::unique_ptr<Codec> MakeCodec() {\n+    std::unique_ptr<Codec> codec;\n+    ABORT_NOT_OK(Codec::Create(GetCompression(), &codec));\n+    return codec;\n+  }\n+};\n+\n+TEST_P(CodecTest, CodecRoundtrip) {\n   int sizes[] = {0, 10000, 100000};\n   for (int data_size : sizes) {\n     vector<uint8_t> data(data_size);\n     random_bytes(data_size, 1234, data.data());\n-    CheckCodecRoundtrip<CODEC>(data);\n+    CheckCodecRoundtrip(GetCompression(), data);\n+  }\n+}\n+\n+TEST_P(CodecTest, StreamingCompressor) {\n+  if (GetCompression() == Compression::SNAPPY) {\n+    // SKIP: snappy doesn't support streaming compression\n+    return;\n+  }\n+  if (GetCompression() == Compression::LZ4) {\n+    // SKIP: LZ4 streaming compression uses the LZ4 framing format,\n+    // which must be tested against a streaming decompressor\n+    return;\n+  }\n+\n+  int sizes[] = {0, 10, 100000};\n+  for (int data_size : sizes) {\n+    vector<uint8_t> data(data_size);\n+    random_bytes(data_size, 1234, data.data());\n \n Review comment:\n   Yes, you're right.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T08:44:13.158+0000",
                    "updated": "2018-10-05T08:44:13.158+0000",
                    "started": "2018-10-05T08:44:13.157+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151543",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151545",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222933140\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression.h\n ##########\n @@ -21,32 +21,112 @@\n #include <cstdint>\n #include <memory>\n \n-#include \"arrow/status.h\"\n #include \"arrow/util/visibility.h\"\n \n namespace arrow {\n \n+class Status;\n+\n struct Compression {\n   enum type { UNCOMPRESSED, SNAPPY, GZIP, BROTLI, ZSTD, LZ4, LZO };\n };\n \n namespace util {\n \n+/// \\brief Streaming compressor interface\n+///\n+class ARROW_EXPORT Compressor {\n+ public:\n+  virtual ~Compressor();\n+\n+  /// \\brief Compress some input.\n+  ///\n+  /// If bytes_read is 0 on return, then a larger output buffer should be supplied.\n+  virtual Status Compress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                          uint8_t* output, int64_t* bytes_read,\n+                          int64_t* bytes_written) = 0;\n+\n+  /// \\brief Flush part of the compressed output.\n \n Review comment:\n   That's a good question. The end goal of this PR is to allow implementing https://issues.apache.org/jira/browse/ARROW-1019 (compressed input and output streams), where we'd like to expose a flush operation (for output streams).\r\n   \r\n   (unfortunately the semantics of flushing may be compressor-dependent: in some cases, perhaps not _all_ output is flushed, or the output is not valid compressed data until you've called End())\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T08:47:55.560+0000",
                    "updated": "2018-10-05T08:47:55.560+0000",
                    "started": "2018-10-05T08:47:55.560+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151545",
                    "issueId": "13188941"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/worklog/151573",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #2696: ARROW-3409: [C++] Streaming compression and decompression interfaces\nURL: https://github.com/apache/arrow/pull/2696#discussion_r222960836\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression_zlib.cc\n ##########\n @@ -47,6 +47,238 @@ static constexpr int GZIP_CODEC = 16;\n // Determine if this is libz or gzip from header.\n static constexpr int DETECT_CODEC = 32;\n \n+// ----------------------------------------------------------------------\n+// gzip decompressor implementation\n+\n+class GZipDecompressor : public Decompressor {\n+ public:\n+  GZipDecompressor() : initialized_(false) {}\n+\n+  ~GZipDecompressor() override {\n+    if (initialized_) {\n+      inflateEnd(&stream_);\n+    }\n+  }\n+\n+  Status Init(GZipCodec::Format format) {\n+    DCHECK(!initialized_);\n+    memset(&stream_, 0, sizeof(stream_));\n+    finished_ = false;\n+\n+    int ret;\n+    // Initialize to run specified format\n+    int window_bits = WINDOW_BITS;\n+    if (format == GZipCodec::DEFLATE) {\n+      window_bits = -window_bits;\n+    } else if (format == GZipCodec::GZIP) {\n+      window_bits += GZIP_CODEC;\n+    }\n+    if ((ret = inflateInit2(&stream_, window_bits)) != Z_OK) {\n+      return ZlibError(\"zlib inflateInit failed: \");\n+    } else {\n+      initialized_ = true;\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Decompress(int64_t input_len, const uint8_t* input, int64_t output_len,\n+                    uint8_t* output, int64_t* bytes_read, int64_t* bytes_written,\n+                    bool* need_more_output) override {\n+    stream_.next_in = const_cast<Bytef*>(reinterpret_cast<const Bytef*>(input));\n+    stream_.avail_in = static_cast<uInt>(input_len);\n \n Review comment:\n   Sometimes it the chance is quite low, in this specific case (compression buffer), I think a user will hit this at least once sooner than later.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-05T10:27:27.151+0000",
                    "updated": "2018-10-05T10:27:27.151+0000",
                    "started": "2018-10-05T10:27:27.150+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "151573",
                    "issueId": "13188941"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 13200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@75d18409[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7c5e47fa[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@298c1cce[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@2763ef92[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@13579627[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@627abb35[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2b59b1d8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@13fed45e[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3cb78ea8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@ba33918[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6d928ec5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@8abfb0d[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 13200,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Oct 15 12:16:14 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-10-15T12:16:14.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3409/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2018-10-02T18:30:07.000+0000",
        "updated": "2018-10-15T12:16:26.000+0000",
        "timeoriginalestimate": null,
        "description": "Currently the compression and decompression methods offered in {{arrow/util/compression.h}} are one-shot. We also need to expose streaming compressor and decompressor interfaces.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "3h 40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 13200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Add streaming compression interfaces",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941/comment/16650128",
                    "id": "16650128",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Issue resolved by pull request 2696\n[https://github.com/apache/arrow/pull/2696]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2018-10-15T12:16:14.279+0000",
                    "updated": "2018-10-15T12:16:14.279+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|i3yqxr:",
        "customfield_12314139": null
    }
}