{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13442660",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660",
    "key": "ARROW-16427",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351550",
                "id": "12351550",
                "name": "9.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-08-03"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "JDBC",
            "Java",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350591",
                "id": "12350591",
                "description": "",
                "name": "7.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-02-03"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12640203",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12640203",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13445496",
                    "key": "ARROW-16600",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13445496",
                    "fields": {
                        "summary": "[Java] Enable configurable scale coercion of BigDecimal",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12639814",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12639814",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13444489",
                    "key": "ARROW-16538",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13444489",
                    "fields": {
                        "summary": "[Java] Refactor FakeResultSet to support arbitrary tests",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
                            "name": "Minor",
                            "id": "4"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
            "name": "toddfarmer",
            "key": "JIRAUSER288796",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
            },
            "displayName": "Todd Farmer",
            "active": true,
            "timeZone": "America/Boise"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328933",
                "id": "12328933",
                "name": "Java"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
            "name": "jswenson",
            "key": "jswenson",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Jonathan Swenson",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
            "name": "jswenson",
            "key": "jswenson",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Jonathan Swenson",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 4200,
            "total": 4200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 4200,
            "total": 4200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16427/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 7,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/worklog/770846",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #13166:\nURL: https://github.com/apache/arrow/pull/13166#issuecomment-1127712806\n\n   https://issues.apache.org/jira/browse/ARROW-16427\n\n\n",
                    "created": "2022-05-16T14:00:15.011+0000",
                    "updated": "2022-05-16T14:00:15.011+0000",
                    "started": "2022-05-16T14:00:15.010+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "770846",
                    "issueId": "13442660"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/worklog/771493",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #13166:\nURL: https://github.com/apache/arrow/pull/13166#discussion_r875103930\n\n\n##########\njava/adapter/jdbc/src/test/java/org/apache/arrow/adapter/jdbc/h2/JdbcToArrowTest.java:\n##########\n@@ -311,4 +320,146 @@ public void testMockDataTypes() throws SQLException {\n     assertEquals(\"1\", element.getString());\n   }\n \n+  @Test\n+  public void testUnreliableMetaDataPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildIncorrectPrecisionAndScaleMetaDataResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    assertFalse(\"No more rows!\", rs.next());\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+          allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+          .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+          .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      fail(\"Expected to fail due to mismatched metadata!\");\n+      iter.close();\n+    } catch (Exception ex) {\n+      // expected to fail\n+    }\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 18, 2);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+    config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      fail(\"Should not fail with explicit metadata supplied!\");\n+    }\n+\n+  }\n+\n+  @Test\n+  public void testInconsistentPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildVaryingPrecisionAndScaleResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    rs.next();\n+    BigDecimal bd2 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000300.0000001\", new BigDecimal(\"1000000000300.0000001\"), bd2);\n+    assertEquals(\"Value scale should be 7\", 7, bd2.scale());\n+    assertEquals(\"Value precision should be 20\", 20, bd2.precision());\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 20, 7);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      // Fails here due to ARROW-16427:\n+      // fail(\"Failed to process ResultSet\");\n\nReview Comment:\n   If we don't expect this to fail anymore, should we remove the try-catch (or uncomment the fail) instead of swallowing exceptions?\n\n\n\n",
                    "created": "2022-05-17T17:54:04.521+0000",
                    "updated": "2022-05-17T17:54:04.521+0000",
                    "started": "2022-05-17T17:54:04.520+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "771493",
                    "issueId": "13442660"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/worklog/771506",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "toddfarmer commented on code in PR #13166:\nURL: https://github.com/apache/arrow/pull/13166#discussion_r875139658\n\n\n##########\njava/adapter/jdbc/src/test/java/org/apache/arrow/adapter/jdbc/h2/JdbcToArrowTest.java:\n##########\n@@ -311,4 +320,146 @@ public void testMockDataTypes() throws SQLException {\n     assertEquals(\"1\", element.getString());\n   }\n \n+  @Test\n+  public void testUnreliableMetaDataPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildIncorrectPrecisionAndScaleMetaDataResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    assertFalse(\"No more rows!\", rs.next());\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+          allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+          .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+          .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      fail(\"Expected to fail due to mismatched metadata!\");\n+      iter.close();\n+    } catch (Exception ex) {\n+      // expected to fail\n+    }\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 18, 2);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+    config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      fail(\"Should not fail with explicit metadata supplied!\");\n+    }\n+\n+  }\n+\n+  @Test\n+  public void testInconsistentPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildVaryingPrecisionAndScaleResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    rs.next();\n+    BigDecimal bd2 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000300.0000001\", new BigDecimal(\"1000000000300.0000001\"), bd2);\n+    assertEquals(\"Value scale should be 7\", 7, bd2.scale());\n+    assertEquals(\"Value precision should be 20\", 20, bd2.precision());\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 20, 7);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      // Fails here due to ARROW-16427:\n+      // fail(\"Failed to process ResultSet\");\n\nReview Comment:\n   It does fail today.  My proposal is to break out the task to enable configurable automatic coercion to greater-scale BigDecimals in a separate task.  If you agree, I'll open a new task, update the comment to reference that issue, and start work on that after this is closed.  This work only allows explicit type mapping via configuration for known-consistent ResultSets.  Further work is needed to enable support for inconsistent ResultSets, where scale differs by row.\n\n\n\n",
                    "created": "2022-05-17T18:24:51.481+0000",
                    "updated": "2022-05-17T18:24:51.481+0000",
                    "started": "2022-05-17T18:24:51.481+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "771506",
                    "issueId": "13442660"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/worklog/771510",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on code in PR #13166:\nURL: https://github.com/apache/arrow/pull/13166#discussion_r875147256\n\n\n##########\njava/adapter/jdbc/src/test/java/org/apache/arrow/adapter/jdbc/h2/JdbcToArrowTest.java:\n##########\n@@ -311,4 +320,146 @@ public void testMockDataTypes() throws SQLException {\n     assertEquals(\"1\", element.getString());\n   }\n \n+  @Test\n+  public void testUnreliableMetaDataPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildIncorrectPrecisionAndScaleMetaDataResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    assertFalse(\"No more rows!\", rs.next());\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+          allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+          .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+          .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      fail(\"Expected to fail due to mismatched metadata!\");\n+      iter.close();\n+    } catch (Exception ex) {\n+      // expected to fail\n+    }\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 18, 2);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+    config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      fail(\"Should not fail with explicit metadata supplied!\");\n+    }\n+\n+  }\n+\n+  @Test\n+  public void testInconsistentPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildVaryingPrecisionAndScaleResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    rs.next();\n+    BigDecimal bd2 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000300.0000001\", new BigDecimal(\"1000000000300.0000001\"), bd2);\n+    assertEquals(\"Value scale should be 7\", 7, bd2.scale());\n+    assertEquals(\"Value precision should be 20\", 20, bd2.precision());\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 20, 7);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      // Fails here due to ARROW-16427:\n+      // fail(\"Failed to process ResultSet\");\n\nReview Comment:\n   Ah, then I misunderstood. Ok, breaking out a separate task for that makes sense. \r\n   \r\n   Can we \"xfail\" this? I suppose JUnit doesn't support that explicitly but we should assert that it does throw here?\n\n\n\n",
                    "created": "2022-05-17T18:34:17.410+0000",
                    "updated": "2022-05-17T18:34:17.410+0000",
                    "started": "2022-05-17T18:34:17.409+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "771510",
                    "issueId": "13442660"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/worklog/771536",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "toddfarmer commented on code in PR #13166:\nURL: https://github.com/apache/arrow/pull/13166#discussion_r875201487\n\n\n##########\njava/adapter/jdbc/src/test/java/org/apache/arrow/adapter/jdbc/h2/JdbcToArrowTest.java:\n##########\n@@ -311,4 +320,146 @@ public void testMockDataTypes() throws SQLException {\n     assertEquals(\"1\", element.getString());\n   }\n \n+  @Test\n+  public void testUnreliableMetaDataPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildIncorrectPrecisionAndScaleMetaDataResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    assertFalse(\"No more rows!\", rs.next());\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+          allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+          .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+          .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      fail(\"Expected to fail due to mismatched metadata!\");\n+      iter.close();\n+    } catch (Exception ex) {\n+      // expected to fail\n+    }\n+\n+    // reset the ResultSet:\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 18, 2);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+    config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      fail(\"Should not fail with explicit metadata supplied!\");\n+    }\n+\n+  }\n+\n+  @Test\n+  public void testInconsistentPrecisionAndScale() throws Exception {\n+    BufferAllocator allocator = new RootAllocator(Integer.MAX_VALUE);\n+    int x = 0;\n+    final int targetRows = 0;\n+    ResultSet rs = buildVaryingPrecisionAndScaleResultSet();\n+    ResultSetMetaData rsmd = rs.getMetaData();\n+    assertEquals(\"Column type should be Types.DECIMAL\", Types.DECIMAL, rsmd.getColumnType(1));\n+    assertEquals(\"Column scale should be zero\", 0, rsmd.getScale(1));\n+    assertEquals(\"Column precision should be zero\", 0, rsmd.getPrecision(1));\n+    rs.next();\n+    BigDecimal bd1 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000000000.01\", new BigDecimal(\"1000000000000000.01\"), bd1);\n+    assertEquals(\"Value scale should be 2\", 2, bd1.scale());\n+    assertEquals(\"Value precision should be 18\", 18, bd1.precision());\n+    rs.next();\n+    BigDecimal bd2 = rs.getBigDecimal(1);\n+    assertEquals(\"Value should be 1000000000300.0000001\", new BigDecimal(\"1000000000300.0000001\"), bd2);\n+    assertEquals(\"Value scale should be 7\", 7, bd2.scale());\n+    assertEquals(\"Value precision should be 20\", 20, bd2.precision());\n+    rs.beforeFirst();\n+    JdbcFieldInfo explicitMappingField = new JdbcFieldInfo(Types.DECIMAL, 20, 7);\n+    Map<Integer, JdbcFieldInfo> explicitMapping = new HashMap<>();\n+    explicitMapping.put(1, explicitMappingField);\n+\n+    JdbcToArrowConfig config = new JdbcToArrowConfigBuilder(\n+            allocator, JdbcToArrowUtils.getUtcCalendar(), /* include metadata */ false)\n+            .setReuseVectorSchemaRoot(reuseVectorSchemaRoot)\n+            .setExplicitTypesByColumnIndex(explicitMapping)\n+            .build();\n+    try {\n+      ArrowVectorIterator iter = JdbcToArrow.sqlToArrowVectorIterator(rs, config);\n+      while (iter.hasNext()) {\n+        iter.next();\n+      }\n+      iter.close();\n+    } catch (Exception ex) {\n+      // Fails here due to ARROW-16427:\n+      // fail(\"Failed to process ResultSet\");\n\nReview Comment:\n   I moved the comment and failure test around, and have referenced ARROW-16600 (just created to track the configurable coercion work).\n\n\n\n",
                    "created": "2022-05-17T19:44:13.456+0000",
                    "updated": "2022-05-17T19:44:13.456+0000",
                    "started": "2022-05-17T19:44:13.456+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "771536",
                    "issueId": "13442660"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/worklog/772055",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm closed pull request #13166: ARROW-16427: [Java] Provide explicit column type mapping\nURL: https://github.com/apache/arrow/pull/13166\n\n\n",
                    "created": "2022-05-18T17:52:31.602+0000",
                    "updated": "2022-05-18T17:52:31.602+0000",
                    "started": "2022-05-18T17:52:31.602+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "772055",
                    "issueId": "13442660"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/worklog/772155",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "ursabot commented on PR #13166:\nURL: https://github.com/apache/arrow/pull/13166#issuecomment-1130608954\n\n   Benchmark runs are scheduled for baseline = 3df2e0568240d6b629c0a3163df21a1a2a160810 and contender = 05bd8fdd801d4c9bcf57950b79c9a133a49d38bb. 05bd8fdd801d4c9bcf57950b79c9a133a49d38bb is a master commit associated with this PR. Results will be available as each benchmark for each run completes.\n   Conbench compare runs links:\n   [Finished :arrow_down:0.0% :arrow_up:0.0%] [ec2-t3-xlarge-us-east-2](https://conbench.ursa.dev/compare/runs/00e03294be7b4b5585fd2ccfc6a7ac26...be7025ca8b0543a4b30788d5392724bd/)\n   [Failed :arrow_down:1.4% :arrow_up:1.17%] [test-mac-arm](https://conbench.ursa.dev/compare/runs/bd75c05adc7d455d934637b4ee67ad42...7bbe071457e14178825017e969d42229/)\n   [Failed :arrow_down:0.0% :arrow_up:5.51%] [ursa-i9-9960x](https://conbench.ursa.dev/compare/runs/ac356b066bb1437882443db5c916cd30...f9956316f5114c9d8260079d37dad6a9/)\n   [Finished :arrow_down:0.87% :arrow_up:0.12%] [ursa-thinkcentre-m75q](https://conbench.ursa.dev/compare/runs/a883c208901241edbe46f7ecbc45f976...4986c30e90f64701998c709022f83dce/)\n   Buildkite builds:\n   [Finished] [`05bd8fdd` ec2-t3-xlarge-us-east-2](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ec2-t3-xlarge-us-east-2/builds/786)\n   [Failed] [`05bd8fdd` test-mac-arm](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-test-mac-arm/builds/783)\n   [Failed] [`05bd8fdd` ursa-i9-9960x](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-i9-9960x/builds/773)\n   [Finished] [`05bd8fdd` ursa-thinkcentre-m75q](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-thinkcentre-m75q/builds/789)\n   [Finished] [`3df2e056` ec2-t3-xlarge-us-east-2](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ec2-t3-xlarge-us-east-2/builds/785)\n   [Failed] [`3df2e056` test-mac-arm](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-test-mac-arm/builds/782)\n   [Failed] [`3df2e056` ursa-i9-9960x](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-i9-9960x/builds/772)\n   [Finished] [`3df2e056` ursa-thinkcentre-m75q](https://buildkite.com/apache-arrow/arrow-bci-benchmark-on-ursa-thinkcentre-m75q/builds/788)\n   Supported benchmarks:\n   ec2-t3-xlarge-us-east-2: Supported benchmark langs: Python, R. Runs only benchmarks with cloud = True\n   test-mac-arm: Supported benchmark langs: C++, Python, R\n   ursa-i9-9960x: Supported benchmark langs: Python, R, JavaScript\n   ursa-thinkcentre-m75q: Supported benchmark langs: C++, Java\n   \n\n\n",
                    "created": "2022-05-18T22:12:24.602+0000",
                    "updated": "2022-05-18T22:12:24.602+0000",
                    "started": "2022-05-18T22:12:24.602+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "772155",
                    "issueId": "13442660"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "id": "1",
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "name": "Bug",
            "subtask": false,
            "avatarId": 21133
        },
        "timespent": 4200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@7bb99ab4[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4bd0d613[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2c8bd5a5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@61a6ee69[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@75ce10c3[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6a03d4b3[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@18d702ab[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@4ed4627e[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4b192b6f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@3fcbd8f3[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1f2957fb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@720311f2[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 4200,
        "customfield_12312520": null,
        "customfield_12312521": "Wed May 18 17:52:32 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-05-18T17:52:32.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16427/watchers",
            "watchCount": 4,
            "isWatching": true
        },
        "created": "2022-04-30T21:19:21.000+0000",
        "updated": "2022-05-18T22:12:25.000+0000",
        "timeoriginalestimate": null,
        "description": "When a JDBC driver returns a Numeric type that doesn't exactly align with what is in the JDBC metadata, jdbcToArrowVectors / sqlToArrowVectorIterator fails to process the result (failing on serializing the the value into the BigDecimalVector).\u00a0\r\n\r\nIt appears as though this is because JDBC drivers can return BigDecimal / Numeric values that are different between the metadata and not consistent between each of the rows.\u00a0\r\n\r\nIs there a recommended course of action to represent a variable precision / scale decimal vector? In any case it does not seem possible to convert JDBC data with the built in utilities that uses these numeric types when they come in this form.\u00a0\r\n\r\nIt seems like both the Oracle and the Postgres JDBC driver also returns metadata with a 0,0 precision / scale when values in the result set have different (and varied) precision / scale.\u00a0\r\n\r\nAn example:\u00a0\r\n\r\nAgainst postgres, running a simple SQL query that produces numeric types can lead to a JDBC result set with BigDecimal values with variable decimal precision/scale.\u00a0\r\n{code:java}\r\nSELECT value FROM (\r\n  SELECT 1000000000000000.01 AS \"value\" \r\n  UNION SELECT 1000000000300.0000001\r\n) a {code}\r\n\u00a0\r\n\r\nThe postgres JDBC adapter produces a result set that looks like the following:\u00a0\r\n\r\n\u00a0\r\n||\u00a0||value||precision||scale||\r\n|metadata|N/A|0|0|\r\n|row 1|1000000000000000.01|18|2|\r\n|row 2|1000000000300.0000001|20|7|\r\n\r\n\u00a0\r\n\r\nEven a result set that returns a single value may Numeric values with precision / scale that do not match the precision / scale in the ResultSetMetadata.\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\nSELECT AVG(one) from (\r\n  SELECT 1000000000000000.01 as \"one\" \r\n  UNION select 1000000000300.0000001\r\n) a {code}\r\nproduces a result set that looks like this\r\n\r\n\u00a0\r\n||\u00a0||value||precision||scale||\r\n|metadata|N/A|0|0|\r\n|row 1|500500000000150.0050001|22|7|\r\n\r\n\u00a0\r\n\r\nWhen processing the result set using the simple jdbcToArrowVectors (or sqlToArrowVectorIterator) this fails to set the values extracted from the result set into the the DecimalVector\r\n\r\n\u00a0\r\n{code:java}\r\nval calendar = JdbcToArrowUtils.getUtcCalendar()\r\nval schema = JdbcToArrowUtils.jdbcToArrowSchema(rs.metaData, calendar)\r\nval root = VectorSchemaRoot.create(schema, RootAllocator())\r\nval vectors = JdbcToArrowUtils.jdbcToArrowVectors(rs, root, calendar) {code}\r\nError:\r\n\r\n\u00a0\r\n{code:java}\r\nException in thread \"main\" java.lang.IndexOutOfBoundsException: index: 0, length: 1 (expected: range(0, 0))\r\n\u00a0 \u00a0 at org.apache.arrow.memory.ArrowBuf.checkIndexD(ArrowBuf.java:318)\r\n\u00a0 \u00a0 at org.apache.arrow.memory.ArrowBuf.chk(ArrowBuf.java:305)\r\n\u00a0 \u00a0 at org.apache.arrow.memory.ArrowBuf.getByte(ArrowBuf.java:507)\r\n\u00a0 \u00a0 at org.apache.arrow.vector.BitVectorHelper.setBit(BitVectorHelper.java:85)\r\n\u00a0 \u00a0 at org.apache.arrow.vector.DecimalVector.set(DecimalVector.java:354)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.consumer.DecimalConsumer$NullableDecimalConsumer.consume(DecimalConsumer.java:61)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.consumer.CompositeJdbcConsumer.consume(CompositeJdbcConsumer.java:46)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.JdbcToArrowUtils.jdbcToArrowVectors(JdbcToArrowUtils.java:369)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.JdbcToArrowUtils.jdbcToArrowVectors(JdbcToArrowUtils.java:321) {code}\r\n\u00a0\r\n\r\nusing `sqlToArrowVectorIterator` also fails with an error trying to set data into the vector: (requires a little bit of trickery to force creation of the package private configuration)\r\n\r\n\u00a0\r\n{code:java}\r\nException in thread \"main\" java.lang.RuntimeException: Error occurred while getting next schema root.\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.next(ArrowVectorIterator.java:179)\r\n\u00a0 \u00a0 at com.acme.dataformat.ArrowResultSetProcessor.processResultSet(ArrowResultSetProcessor.kt:31)\r\n\u00a0 \u00a0 at com.acme.AppKt.main(App.kt:54)\r\n\u00a0 \u00a0 at com.acme.AppKt.main(App.kt)\r\nCaused by: java.lang.RuntimeException: Error occurred while consuming data.\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.consumeData(ArrowVectorIterator.java:121)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.load(ArrowVectorIterator.java:153)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.next(ArrowVectorIterator.java:175)\r\n\u00a0 \u00a0 ... 3 more\r\nCaused by: java.lang.UnsupportedOperationException: BigDecimal scale must equal that in the Arrow vector: 7 != 0\r\n\u00a0 \u00a0 at org.apache.arrow.vector.util.DecimalUtility.checkPrecisionAndScale(DecimalUtility.java:95)\r\n\u00a0 \u00a0 at org.apache.arrow.vector.DecimalVector.set(DecimalVector.java:355)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.consumer.DecimalConsumer$NullableDecimalConsumer.consume(DecimalConsumer.java:61)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.consumer.CompositeJdbcConsumer.consume(CompositeJdbcConsumer.java:46)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.consumeData(ArrowVectorIterator.java:113)\r\n\u00a0 \u00a0 ... 5 more {code}\r\n\u00a0\r\n\r\n\u00a0",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "1h 10m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 4200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Java] jdbcToArrowVectors / sqlToArrowVectorIterator fails to handle variable decimal precision / scale",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17535140",
                    "id": "17535140",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "body": "Thanks for reporting this, [~jswenson] !\u00a0 I've verified the behavior as you've described.\u00a0 In the face of unreliable ResultSetMetaData from the JDBC vendor, it seems likely we will need to supply a fallback configuration option to allow explicit definition of mapping.\u00a0 I don't believe the scale and precision of the resulting Arrow vectors can be resized dynamically based on values read in after allocation/creation.\r\n\r\nThere is a JdbcFieldInfo object that allows explicit definition of precision and scale, but this seems to be configurable only for applying to elements of list/array types.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "created": "2022-05-11T23:46:33.694+0000",
                    "updated": "2022-05-12T15:26:43.208+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17535926",
                    "id": "17535926",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "cc [~rpimike1022]\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2022-05-12T07:33:02.257+0000",
                    "updated": "2022-05-12T07:33:02.257+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17535928",
                    "id": "17535928",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "So if the JDBC-to-Arrow interface is streaming, it seems a configuration option is the only way to go about this.\r\n\r\nAlso cc [~lidavidm] as that's an interesting JDBC (and presumably ODBC) gotcha.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2022-05-12T07:34:45.199+0000",
                    "updated": "2022-05-12T07:34:45.199+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17536073",
                    "id": "17536073",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "The other choice could be a canonical extension type (presumably something like Struct { decimal: FixedSizeBinary(16), precision: UInt32, scale: Int32 }). I agree the configuration option is probably the only way to handle this right now.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-05-12T12:08:12.516+0000",
                    "updated": "2022-05-12T12:08:12.516+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17536352",
                    "id": "17536352",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "It appears as though there is some capabilities in configuring the type mapping and the like by passing a type mapping function when constructing, {{JdbcToArrowConfig}} but from the looks of things, that path is currently unsupported (the {color:#505f79}{{JdbcToArrowConfig}}{color} constructor is package private).\u00a0\r\n\r\nHowever, even if that were supported (mapping {{decimal(0,0)}} to the struct type from [~lidavidm]'s comment), there would not be a corresponding way to configure the a JdbcConsumer for more complex types like this as {{{}ArrowVectorIterator{}}}'s initialize method calls the static {{JdbcToArrowUtils.getConsumer}}{color:#172b4d} method.\u00a0{color}\r\n\r\nI don't know how many other databases do things like this, but from a [stackoverflow post|https://stackoverflow.com/questions/1410267/oracle-resultsetmetadata-getprecision-getscale?rq=1] I found that perhaps Oracle does something similar.\u00a0\r\n\r\nIn general I'm interested in any plans for additional configurability of this module to allow for supporting more complex JDBC types. postgres: timestamp with timezone, intervals, UUIDs, etc / bigquery: nested and repeated fields. I've considered implementing something similar to work around some of these issues, but so much already exists in this system today that it would be hard to walk away from.\r\n\r\nI'm also interested in this configuration class as it appears as though it also supports re-use of the {{VectorSchemaRoot}} which would make writing out a binary payload using {{ArrowStreamWriter}} (which takes a single {{{}VectorSchemaRoot{}}}) upon instantiation.\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-05-12T21:30:59.577+0000",
                    "updated": "2022-05-12T21:30:59.577+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17536755",
                    "id": "17536755",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "body": "I've been working on enabling configuration of explicit type mapping of top-level columns (not just array sub-elements), and found that there's still a problem as it relates to inconsistent scales.\u00a0 From the example provided:\r\n||\u00a0||value||precision||scale||\r\n|metadata|N/A|0|0|\r\n|row 1|1000000000000000.01|18|2|\r\n|row 2|1000000000300.0000001|20|7|\r\n\r\nEven if configured to provision a vector with an initial scale of 7, the first row fails to be converted because of the mismatch in scale:\r\n{code:java}\r\nCaused by: java.lang.RuntimeException: Error occurred while consuming data.\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.consumeData(ArrowVectorIterator.java:129)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.load(ArrowVectorIterator.java:161)\r\n\u00a0 \u00a0 at org.apache.arrow.adapter.jdbc.ArrowVectorIterator.next(ArrowVectorIterator.java:186)\r\n\u00a0 \u00a0 ... 54 more\r\nCaused by: java.lang.UnsupportedOperationException: BigDecimal scale must equal that in the Arrow vector: 2 != 7{code}\r\nThe value could have the scale implicitly increased from 1000000000000000.01 to 1000000000000000.0100000 - but that could be a lossy conversion.\u00a0 The actual original value with a scale of 7 could actually have been 1000000000000000.0114236, rounded down to 1000000000000000.01 when the scale of 2 was applied.\u00a0 I wonder whether these are edge cases - e.g., results synthesized from non-tabular data.\u00a0 If that's the case, and we can _generally_ assume consistency in precision and scale within a single column of a resultset, the configuration option makes sense.\u00a0 If that's the case, I'd propose we defer work on scale conversion to support inconsistent scale within a single column to a separate task.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "created": "2022-05-13T16:28:16.922+0000",
                    "updated": "2022-05-13T16:28:16.922+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17536788",
                    "id": "17536788",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "In postgres it is possible to do this with data directly from a table.\u00a0\r\n\r\nIf the table is declared as type numeric it will be created with the defaults: 0 precision 0 scale.\u00a0\r\n\r\nFrom the [postgres docs|https://www.postgresql.org/docs/current/datatype-numeric.html#DATATYPE-NUMERIC-DECIMAL]:\u00a0\r\n{quote}Specifying:\r\nNUMERIC\r\nwithout any precision or scale creates an\u00a0\u201cunconstrained numeric\u201d\u00a0column in which numeric values of any length can be stored, up to the implementation limits. A column of this kind will not coerce input values to any particular scale, whereas\u00a0{{numeric}}\u00a0columns with a declared scale will coerce input values to that scale. (The\u00a0SQL\u00a0standard requires a default scale of 0, i.e., coercion to integer precision. We find this a bit useless. If you're concerned about portability, always specify the precision and scale explicitly.)\r\n{quote}\r\nIf you set up a table with an \"unconstrained\" numeric column like this:\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\ntest=# create table numeric_test(num numeric);\r\nCREATE TABLE\r\n\r\ntest=# select column_name, numeric_precision, numeric_scale from information_schema.columns where table_name = 'numeric_test';\r\n\u00a0column_name | numeric_precision | numeric_scale\u00a0\r\n-------------+-------------------+---------------\r\n\u00a0num \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\r\n(1 row)\r\n\r\ntest=# insert into numeric_test values (1000000000000000.01);\r\nINSERT 0 1\r\n\r\ntest=# insert into numeric_test values (1000000000300.0000001);\r\nINSERT 0 1\r\n\r\ntest=# select * from numeric_test;\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 num \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\r\n-----------------------\r\n\u00a0\u00a0 1000000000000000.01\r\n\u00a01000000000300.0000001\r\n(2 rows) {code}\r\n\u00a0\r\n\r\nThe result come back in JDBC as described in the issue.\u00a0\r\n||\u00a0||value||precision||scale||\r\n|meta|N/A|0|0|\r\n|row 1|100000000000000.01|18|2|\r\n|row 2|1000000000300.0000001|20|7|\r\n\r\n\u00a0\r\n----\r\nAnother example is when you use the average function over integers. While this SQL statement is contrived, it comes from a usecase of taking the average of a table in a demo dataset I use.\u00a0\r\n{code:java}\r\nselect x, avg(y), count(*) from (\r\n  select 1 as x, 2 as y union select 1, 3 union select 1, 5 union \r\n  select 2, 6 union select 2, 9 union select 2, 10 union \r\n  select 3, 11 union select 3, 24 union select 3, 19 union select 3, 11 union select 3, 29 union \r\n  select 3, 18 union select 3, 22 union select 3, 11 union select 3, 21 union \r\n  select 4, 1 union select 4, 2\r\n) a group by x; {code}\r\n\u00a0\r\n\r\nThis query returns the data as follows via JDBC:\r\n||\u00a0||value||precision||scale||\r\n|meta|N/A|0|0|\r\n|1|1.5000000000000000|17|16|\r\n|2|20.5714285714285714|18|16|\r\n|3|3.3333333333333333|17|16|\r\n|4|8.3333333333333333|17|16|\r\n\r\nIn this case, the scale is at least consistent in the result set, but the precision is not.\u00a0\r\n\r\nIf you were to create a table from this query with CTAS\u00a0\r\n{noformat}\r\ntest=# CREATE TABLE example AS SELECT ...\r\nSELECT 4\r\n\r\ntest=# select column_name, numeric_precision, numeric_scale from information_schema.columns where table_name = 'example';\r\n\u00a0column_name | numeric_precision | numeric_scale\u00a0\r\n-------------+-------------------+---------------\r\n\u00a0x \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 32 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0\r\n\u00a0avg \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\r\n\u00a0count \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 64 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0\r\n(3 rows){noformat}\r\nNotably the avg column created has a null (unconstrained) precision and scale. The results of selecting from this table via JDBC come back identical to the simple select query with a precision / scale of zero and a constant scale (16) and variable precision (18).\r\n\r\n\u00a0\r\n----\r\nIf you set up a table using a specified precision / scale:\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\ntest=# create table numeric_seven_test(num numeric(22, 7));\r\nCREATE TABLE\r\n\r\ntest=# insert into numeric_seven_test values (1000000000300.0000001);\r\nINSERT 0 1\r\n\r\ntest=# insert into numeric_seven_test values (100000000000000.01);\r\nINSERT 0 1\r\n\r\ntest=# select column_name, numeric_precision, numeric_scale from information_schema.columns where table_name = 'numeric_seven_test';\r\n\u00a0column_name | numeric_precision | numeric_scale\u00a0\r\n-------------+-------------------+---------------\r\n\u00a0num \u00a0 \u00a0 \u00a0 \u00a0 |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 22 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 7\r\n(1 row)\r\n \u00a0\r\ntest=# select * from numeric_seven_test;\r\n\u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 num\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\r\n-------------------------\r\n\u00a0\u00a0 1000000000300.0000001\r\n\u00a0100000000000000.0100000\r\n(2 rows){code}\r\n\u00a0\r\n\r\nI'm not exactly sure why, but in order to contain the values I specified, I needed to increase the precision to 22 (rather than 20) in the above examples.\r\n\r\nWhen I pull these values back with JDBC, I get the following.\u00a0\r\n\r\n\u00a0\r\n||\u00a0||value||precision||scale||\r\n|meta|N/A|22|7|\r\n|row 1|1000000000300.0000001|20|7|\r\n|row 2|100000000000000.0100000|22|7|\r\n\r\n\u00a0\r\n\r\n\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-05-13T17:38:56.850+0000",
                    "updated": "2022-05-13T17:38:56.850+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17536860",
                    "id": "17536860",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "body": "The code evaluates precision and scale differently, requiring only that the target precision be _at least_ the same precision as the value being mapped to the vector.\u00a0 This differs from handling of scale, which requires exact matching:\r\n{code:java}\r\n/**\r\n * Check that the BigDecimal scale equals the vectorScale and that the BigDecimal precision is\r\n * less than or equal to the vectorPrecision. If not, then an UnsupportedOperationException is\r\n * thrown, otherwise returns true.\r\n */\r\npublic static boolean checkPrecisionAndScale(BigDecimal value, int vectorPrecision, int vectorScale) {\r\n  if (value.scale() != vectorScale) {\r\n    throw new UnsupportedOperationException(\"BigDecimal scale must equal that in the Arrow vector: \" +\r\n        value.scale() + \" != \" + vectorScale);\r\n  }\r\n  if (value.precision() > vectorPrecision) {\r\n    throw new UnsupportedOperationException(\"BigDecimal precision can not be greater than that in the Arrow \" +\r\n      \"vector: \" + value.precision() + \" > \" + vectorPrecision);\r\n  }\r\n  return true;\r\n} {code}\r\nIn that context, configuration will support the use cases except for the first, where postgres returns rows with differing scale values for the same column.\u00a0 If we're comfortable separating these concerns, I'll propose a PR to enable configurable mapping, and open a new issue to track handling the rows with differing scale values problem.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "created": "2022-05-13T20:07:05.868+0000",
                    "updated": "2022-05-13T20:07:05.868+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17537665",
                    "id": "17537665",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "[~toddfarmer] \u2013 I'm unsure what the implications of the configurable mapping would be. Would the idea be to force the scale (and min precision) in configuration? And then coerce the JDBC BigDecimal values to that (regardless of what they come back from the JDBC driver as)?\u00a0\r\n\r\nMaybe I'm not understanding the nuance. I think it is likely reasonable to break these into two efforts from a development standpoint. I'm mostly just curious how I might be able to utilize the first effort here.\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-05-16T17:05:53.148+0000",
                    "updated": "2022-05-16T17:05:53.148+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17537676",
                    "id": "17537676",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "body": "[~jswenson] - That is my thinking, yes.\u00a0 It's also likely that future code to enable coercion should rely on explicit configuration.\u00a0 At least one of the sample data sets you supplied earlier could make use of the proposed configuration (no coercion) code:\r\n||\u00a0||value||precision||scale||\r\n|meta|N/A|0|0|\r\n|1|1.5000000000000000|17|16|\r\n|2|20.5714285714285714|18|16|\r\n|3|3.3333333333333333|17|16|\r\n|4|8.3333333333333333|17|16|\r\n\r\nIn such a case, the scale and precision are constant (enough) across the actual data, but are not reliably represented in the ResultSetMetaData.\u00a0 The ability to configure mapping will provide relief in such scenarios.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "created": "2022-05-16T17:22:09.665+0000",
                    "updated": "2022-05-16T17:22:09.665+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17537722",
                    "id": "17537722",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Due to the dynamic nature of the way that the system I'm using writes / generates queries, I don't believe that I'll be able to \"guess\" the correct precision and scale for a query, but I can see how this could be useful for queries that are more static / known ahead of time.\r\n\r\nI can't think of any great ways to select the correct configuration dynamically (other than perhaps looking at the first row ahead of time or something \u2013 which isn't really possible with ForwardOnlyResultSets). But I could see how this step goes in the right direction.\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jswenson",
                        "name": "jswenson",
                        "key": "jswenson",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Jonathan Swenson",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-05-16T18:44:35.028+0000",
                    "updated": "2022-05-16T18:44:35.028+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17538431",
                    "id": "17538431",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "body": "Opened ARROW-16600 to track related work allowing configurable coercion of BigDecimal scale.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "created": "2022-05-17T19:42:59.358+0000",
                    "updated": "2022-05-17T19:42:59.358+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13442660/comment/17538988",
                    "id": "17538988",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 13166\n[https://github.com/apache/arrow/pull/13166]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2022-05-18T17:52:32.447+0000",
                    "updated": "2022-05-18T17:52:32.447+0000"
                }
            ],
            "maxResults": 13,
            "total": 13,
            "startAt": 0
        },
        "customfield_12311820": "0|z11z08:",
        "customfield_12314139": null
    }
}