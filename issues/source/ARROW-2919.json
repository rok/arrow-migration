{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13174840",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840",
    "key": "ARROW-2919",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343858",
                "id": "12343858",
                "description": "",
                "name": "0.12.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-01-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
            "name": "Minor",
            "id": "4"
        },
        "labels": [
            "hdfs",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341707",
                "id": "12341707",
                "description": "",
                "name": "0.9.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-03-19"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=mauzhang",
            "name": "mauzhang",
            "key": "mauzhang",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Manu Zhang",
            "active": true,
            "timeZone": "Asia/Shanghai"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=mauzhang",
            "name": "mauzhang",
            "key": "mauzhang",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Manu Zhang",
            "active": true,
            "timeZone": "Asia/Shanghai"
        },
        "aggregateprogress": {
            "progress": 3000,
            "total": 3000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 3000,
            "total": 3000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2919/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 6,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/worklog/176349",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm opened a new pull request #3209: ARROW-2919: [C++/Python] Improve HdfsFile error messages, fix Python unit test suite\nURL: https://github.com/apache/arrow/pull/3209\n \n \n   This also resolves ARROW-3957 and ARROW-4053.\r\n   \r\n   Summary:\r\n   \r\n   * Properly initialize NativeFile when opening from HDFS. This was broken when the \"closed\" property was added and some other refactoring, and wasn't caught because these tests aren't being run regularly\r\n   * Slightly improves the handling of filesystem URIs -- there were some tests that failed without these changes because the docker-compose HDFS containers don't allow writes from $USER\r\n   * Improve error message when calling \"info\" on a file that does not exist\r\n   * Improve error message when calling `ls` on a directory that does not exist\r\n   * Suggest checking whether you are connecting to the right HDFS port when getting errno 255\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-18T03:41:54.210+0000",
                    "updated": "2018-12-18T03:41:54.210+0000",
                    "started": "2018-12-18T03:41:54.209+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "176349",
                    "issueId": "13174840"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/worklog/176468",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #3209: ARROW-2919: [C++/Python] Improve HdfsFile error messages, fix Python unit test suite\nURL: https://github.com/apache/arrow/pull/3209#discussion_r242486850\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -845,16 +862,18 @@ class ParquetDataset(object):\n     def __init__(self, path_or_paths, filesystem=None, schema=None,\n                  metadata=None, split_row_groups=False, validate_schema=True,\n                  filters=None, metadata_nthreads=1):\n-        if filesystem is None:\n-            a_path = path_or_paths\n-            if isinstance(a_path, list):\n-                a_path = a_path[0]\n-            self.fs = _get_fs_from_path(a_path)\n-        else:\n-            self.fs = _ensure_filesystem(filesystem)\n+        a_path = path_or_paths\n+        if isinstance(a_path, list):\n+            a_path = a_path[0]\n \n+        self.fs, _ = _get_filesystem_and_path(filesystem, a_path)\n         self.paths = path_or_paths\n \n Review comment:\n   This temporary assignment looks a bit superfluous. You could just access `path_or_paths` below.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-18T10:45:43.008+0000",
                    "updated": "2018-12-18T10:45:43.008+0000",
                    "started": "2018-12-18T10:45:43.008+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "176468",
                    "issueId": "13174840"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/worklog/176469",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #3209: ARROW-2919: [C++/Python] Improve HdfsFile error messages, fix Python unit test suite\nURL: https://github.com/apache/arrow/pull/3209#discussion_r242485045\n \n \n\n ##########\n File path: cpp/src/arrow/io/hdfs-test.cc\n ##########\n @@ -257,6 +257,22 @@ TYPED_TEST(TestHadoopFileSystem, GetPathInfo) {\n   ASSERT_EQ(size, info.size);\n }\n \n+TYPED_TEST(TestHadoopFileSystem, GetPathInfoNotExist) {\n+  // ARROW-2919: Test that the error message is reasonable\n+  SKIP_IF_NO_DRIVER();\n+\n+  ASSERT_OK(this->MakeScratchDir());\n+  auto path = this->ScratchPath(\"path-does-not-exist\");\n+\n+  HdfsPathInfo info;\n+  Status s = this->client_->GetPathInfo(path, &info);\n \n Review comment:\n   Assert that the Status is a particular error?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-18T10:45:43.010+0000",
                    "updated": "2018-12-18T10:45:43.010+0000",
                    "started": "2018-12-18T10:45:43.009+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "176469",
                    "issueId": "13174840"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/worklog/176601",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #3209: ARROW-2919: [C++/Python] Improve HdfsFile error messages, fix Python unit test suite\nURL: https://github.com/apache/arrow/pull/3209#discussion_r242610431\n \n \n\n ##########\n File path: cpp/src/arrow/io/hdfs-test.cc\n ##########\n @@ -257,6 +257,22 @@ TYPED_TEST(TestHadoopFileSystem, GetPathInfo) {\n   ASSERT_EQ(size, info.size);\n }\n \n+TYPED_TEST(TestHadoopFileSystem, GetPathInfoNotExist) {\n+  // ARROW-2919: Test that the error message is reasonable\n+  SKIP_IF_NO_DRIVER();\n+\n+  ASSERT_OK(this->MakeScratchDir());\n+  auto path = this->ScratchPath(\"path-does-not-exist\");\n+\n+  HdfsPathInfo info;\n+  Status s = this->client_->GetPathInfo(path, &info);\n \n Review comment:\n   done\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-18T16:33:17.324+0000",
                    "updated": "2018-12-18T16:33:17.324+0000",
                    "started": "2018-12-18T16:33:17.323+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "176601",
                    "issueId": "13174840"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/worklog/176603",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #3209: ARROW-2919: [C++/Python] Improve HdfsFile error messages, fix Python unit test suite\nURL: https://github.com/apache/arrow/pull/3209#discussion_r242610903\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -845,16 +862,18 @@ class ParquetDataset(object):\n     def __init__(self, path_or_paths, filesystem=None, schema=None,\n                  metadata=None, split_row_groups=False, validate_schema=True,\n                  filters=None, metadata_nthreads=1):\n-        if filesystem is None:\n-            a_path = path_or_paths\n-            if isinstance(a_path, list):\n-                a_path = a_path[0]\n-            self.fs = _get_fs_from_path(a_path)\n-        else:\n-            self.fs = _ensure_filesystem(filesystem)\n+        a_path = path_or_paths\n+        if isinstance(a_path, list):\n+            a_path = a_path[0]\n \n+        self.fs, _ = _get_filesystem_and_path(filesystem, a_path)\n         self.paths = path_or_paths\n \n Review comment:\n   fixed\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-18T16:34:27.654+0000",
                    "updated": "2018-12-18T16:34:27.654+0000",
                    "started": "2018-12-18T16:34:27.653+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "176603",
                    "issueId": "13174840"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/worklog/176655",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm closed pull request #3209: ARROW-2919: [C++/Python] Improve HdfsFile error messages, fix Python unit test suite\nURL: https://github.com/apache/arrow/pull/3209\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/cpp/src/arrow/io/hdfs-test.cc b/cpp/src/arrow/io/hdfs-test.cc\nindex c853b20126..08a7e13a1f 100644\n--- a/cpp/src/arrow/io/hdfs-test.cc\n+++ b/cpp/src/arrow/io/hdfs-test.cc\n@@ -257,6 +257,23 @@ TYPED_TEST(TestHadoopFileSystem, GetPathInfo) {\n   ASSERT_EQ(size, info.size);\n }\n \n+TYPED_TEST(TestHadoopFileSystem, GetPathInfoNotExist) {\n+  // ARROW-2919: Test that the error message is reasonable\n+  SKIP_IF_NO_DRIVER();\n+\n+  ASSERT_OK(this->MakeScratchDir());\n+  auto path = this->ScratchPath(\"path-does-not-exist\");\n+\n+  HdfsPathInfo info;\n+  Status s = this->client_->GetPathInfo(path, &info);\n+  ASSERT_TRUE(s.IsIOError());\n+\n+  const std::string error_message = s.ToString();\n+\n+  // Check that the file path is found in the error message\n+  ASSERT_LT(error_message.find(path), std::string::npos);\n+}\n+\n TYPED_TEST(TestHadoopFileSystem, AppendToFile) {\n   SKIP_IF_NO_DRIVER();\n \n@@ -377,6 +394,8 @@ TYPED_TEST(TestHadoopFileSystem, LargeFile) {\n   std::shared_ptr<HdfsReadableFile> file;\n   ASSERT_OK(this->client_->OpenReadable(path, &file));\n \n+  ASSERT_FALSE(file->closed());\n+\n   std::shared_ptr<Buffer> buffer;\n   ASSERT_OK(AllocateBuffer(nullptr, size, &buffer));\n \ndiff --git a/cpp/src/arrow/io/hdfs.cc b/cpp/src/arrow/io/hdfs.cc\nindex 6f01f75eec..030b84853d 100644\n--- a/cpp/src/arrow/io/hdfs.cc\n+++ b/cpp/src/arrow/io/hdfs.cc\n@@ -43,14 +43,27 @@ using std::size_t;\n namespace arrow {\n namespace io {\n \n-#define CHECK_FAILURE(RETURN_VALUE, WHAT)                                             \\\n-  do {                                                                                \\\n-    if (RETURN_VALUE == -1) {                                                         \\\n-      std::stringstream ss;                                                           \\\n-      ss << \"HDFS \" << WHAT << \" failed, errno: \" << errno << \" (\" << strerror(errno) \\\n-         << \")\";                                                                      \\\n-      return Status::IOError(ss.str());                                               \\\n-    }                                                                                 \\\n+namespace {\n+\n+std::string TranslateErrno(int error_code) {\n+  std::stringstream ss;\n+  ss << error_code << \" (\" << strerror(error_code) << \")\";\n+  if (error_code == 255) {\n+    // Unknown error can occur if the host is correct but the port is not\n+    ss << \" Please check that you are connecting to the correct HDFS RPC port\";\n+  }\n+  return ss.str();\n+}\n+\n+}  // namespace\n+\n+#define CHECK_FAILURE(RETURN_VALUE, WHAT)                                   \\\n+  do {                                                                      \\\n+    if (RETURN_VALUE == -1) {                                               \\\n+      std::stringstream ss;                                                 \\\n+      ss << \"HDFS \" << WHAT << \" failed, errno: \" << TranslateErrno(errno); \\\n+      return Status::IOError(ss.str());                                     \\\n+    }                                                                       \\\n   } while (0)\n \n static constexpr int kDefaultHdfsBufferSize = 1 << 16;\n@@ -99,6 +112,16 @@ class HdfsAnyFileImpl {\n   bool is_open_;\n };\n \n+namespace {\n+\n+Status GetPathInfoFailed(const std::string& path) {\n+  std::stringstream ss;\n+  ss << \"Calling GetPathInfo for \" << path << \" failed. errno: \" << TranslateErrno(errno);\n+  return Status::IOError(ss.str());\n+}\n+\n+}  // namespace\n+\n // Private implementation for read-only files\n class HdfsReadableFile::HdfsReadableFileImpl : public HdfsAnyFileImpl {\n  public:\n@@ -180,7 +203,7 @@ class HdfsReadableFile::HdfsReadableFileImpl : public HdfsAnyFileImpl {\n   Status GetSize(int64_t* size) {\n     hdfsFileInfo* entry = driver_->GetPathInfo(fs_, path_.c_str());\n     if (entry == nullptr) {\n-      return Status::IOError(\"HDFS: GetPathInfo failed\");\n+      return GetPathInfoFailed(path_);\n     }\n \n     *size = entry->mSize;\n@@ -204,7 +227,7 @@ HdfsReadableFile::HdfsReadableFile(MemoryPool* pool) {\n   impl_.reset(new HdfsReadableFileImpl(pool));\n }\n \n-HdfsReadableFile::~HdfsReadableFile() { DCHECK(impl_->Close().ok()); }\n+HdfsReadableFile::~HdfsReadableFile() { DCHECK_OK(impl_->Close()); }\n \n Status HdfsReadableFile::Close() { return impl_->Close(); }\n \n@@ -272,7 +295,7 @@ class HdfsOutputStream::HdfsOutputStreamImpl : public HdfsAnyFileImpl {\n \n HdfsOutputStream::HdfsOutputStream() { impl_.reset(new HdfsOutputStreamImpl()); }\n \n-HdfsOutputStream::~HdfsOutputStream() { DCHECK(impl_->Close().ok()); }\n+HdfsOutputStream::~HdfsOutputStream() { DCHECK_OK(impl_->Close()); }\n \n Status HdfsOutputStream::Close() { return impl_->Close(); }\n \n@@ -399,7 +422,7 @@ class HadoopFileSystem::HadoopFileSystemImpl {\n     hdfsFileInfo* entry = driver_->GetPathInfo(fs_, path.c_str());\n \n     if (entry == nullptr) {\n-      return Status::IOError(\"HDFS: GetPathInfo failed\");\n+      return GetPathInfoFailed(path);\n     }\n \n     SetPathInfo(entry, info);\n@@ -444,8 +467,8 @@ class HadoopFileSystem::HadoopFileSystemImpl {\n         num_entries = 0;\n       } else {\n         std::stringstream ss;\n-        ss << \"HDFS list directory failed, errno: \" << errno << \" (\" << strerror(errno)\n-           << \")\";\n+        ss << \"HDFS list directory of \" << path\n+           << \" failed, errno: \" << TranslateErrno(errno);\n         return Status::IOError(ss.str());\n       }\n     }\ndiff --git a/cpp/src/gandiva/CMakeLists.txt b/cpp/src/gandiva/CMakeLists.txt\nindex 8052db5e85..23ad93e201 100644\n--- a/cpp/src/gandiva/CMakeLists.txt\n+++ b/cpp/src/gandiva/CMakeLists.txt\n@@ -83,7 +83,7 @@ endif()\n ADD_ARROW_LIB(gandiva\n   SOURCES ${SRC_FILES}\n   OUTPUTS GANDIVA_LIBRARIES\n-  DEPENDENCIES precompiled\n+  DEPENDENCIES arrow_dependencies precompiled\n   EXTRA_INCLUDES\n   $<TARGET_PROPERTY:LLVM::LLVM_INTERFACE,INTERFACE_INCLUDE_DIRECTORIES>\n   SHARED_LINK_LIBS arrow_shared\ndiff --git a/python/pyarrow/filesystem.py b/python/pyarrow/filesystem.py\nindex 8188a2607e..98efb1e3ec 100644\n--- a/python/pyarrow/filesystem.py\n+++ b/python/pyarrow/filesystem.py\n@@ -390,7 +390,7 @@ def _ensure_filesystem(fs):\n         return fs\n \n \n-def _get_fs_from_path(path):\n+def get_filesystem_from_uri(path):\n     \"\"\"\n     return filesystem from path which could be an HDFS URI\n     \"\"\"\n@@ -411,4 +411,4 @@ def _get_fs_from_path(path):\n     else:\n         fs = LocalFileSystem.get_instance()\n \n-    return fs\n+    return fs, parsed_uri.path\ndiff --git a/python/pyarrow/io-hdfs.pxi b/python/pyarrow/io-hdfs.pxi\nindex e7a322ea46..d93bd790ea 100644\n--- a/python/pyarrow/io-hdfs.pxi\n+++ b/python/pyarrow/io-hdfs.pxi\n@@ -433,6 +433,9 @@ cdef class HadoopFileSystem:\n \n             out.set_random_access_file(\n                 <shared_ptr[RandomAccessFile]> rd_handle)\n+            out.is_readable = True\n+\n+        assert not out.closed\n \n         if c_buffer_size == 0:\n             c_buffer_size = 2 ** 16\ndiff --git a/python/pyarrow/parquet.py b/python/pyarrow/parquet.py\nindex feaa890fc6..a520acece9 100644\n--- a/python/pyarrow/parquet.py\n+++ b/python/pyarrow/parquet.py\n@@ -18,6 +18,7 @@\n from collections import defaultdict\n from concurrent import futures\n \n+from six.moves.urllib.parse import urlparse\n import json\n import numpy as np\n import os\n@@ -34,10 +35,24 @@\n                               ParquetSchema, ColumnSchema)\n from pyarrow.compat import guid\n from pyarrow.filesystem import (LocalFileSystem, _ensure_filesystem,\n-                                _get_fs_from_path)\n+                                get_filesystem_from_uri)\n from pyarrow.util import _is_path_like, _stringify_path\n \n \n+def _parse_uri(path):\n+    path = _stringify_path(path)\n+    return urlparse(path).path\n+\n+\n+def _get_filesystem_and_path(passed_filesystem, path):\n+    if passed_filesystem is None:\n+        return get_filesystem_from_uri(path)\n+    else:\n+        passed_filesystem = _ensure_filesystem(passed_filesystem)\n+        parsed_path = _parse_uri(path)\n+        return passed_filesystem, parsed_path\n+\n+\n def _check_contains_null(val):\n     if isinstance(val, six.binary_type):\n         for byte in val:\n@@ -316,7 +331,8 @@ def __init__(self, where, schema, flavor=None,\n                  version='1.0',\n                  use_dictionary=True,\n                  compression='snappy',\n-                 use_deprecated_int96_timestamps=None, **options):\n+                 use_deprecated_int96_timestamps=None,\n+                 filesystem=None, **options):\n         if use_deprecated_int96_timestamps is None:\n             # Use int96 timestamps for Spark\n             if flavor is not None and 'spark' in flavor:\n@@ -338,8 +354,8 @@ def __init__(self, where, schema, flavor=None,\n         self.file_handle = None\n \n         if _is_path_like(where):\n-            fs = _get_fs_from_path(where)\n-            sink = self.file_handle = fs.open(where, 'wb')\n+            fs, path = _get_filesystem_and_path(filesystem, where)\n+            sink = self.file_handle = fs.open(path, 'wb')\n         else:\n             sink = where\n \n@@ -681,7 +697,8 @@ class ParquetManifest(object):\n     \"\"\"\n     def __init__(self, dirpath, filesystem=None, pathsep='/',\n                  partition_scheme='hive', metadata_nthreads=1):\n-        self.filesystem = filesystem or _get_fs_from_path(dirpath)\n+        filesystem, dirpath = _get_filesystem_and_path(filesystem, dirpath)\n+        self.filesystem = filesystem\n         self.pathsep = pathsep\n         self.dirpath = _stringify_path(dirpath)\n         self.partition_scheme = partition_scheme\n@@ -845,15 +862,15 @@ class ParquetDataset(object):\n     def __init__(self, path_or_paths, filesystem=None, schema=None,\n                  metadata=None, split_row_groups=False, validate_schema=True,\n                  filters=None, metadata_nthreads=1):\n-        if filesystem is None:\n-            a_path = path_or_paths\n-            if isinstance(a_path, list):\n-                a_path = a_path[0]\n-            self.fs = _get_fs_from_path(a_path)\n-        else:\n-            self.fs = _ensure_filesystem(filesystem)\n+        a_path = path_or_paths\n+        if isinstance(a_path, list):\n+            a_path = a_path[0]\n \n-        self.paths = path_or_paths\n+        self.fs, _ = _get_filesystem_and_path(filesystem, a_path)\n+        if isinstance(path_or_paths, list):\n+            self.paths = [_parse_uri(path) for path in path_or_paths]\n+        else:\n+            self.paths = _parse_uri(path_or_paths)\n \n         (self.pieces,\n          self.partitions,\n@@ -1070,10 +1087,11 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1):\n \n \n def read_table(source, columns=None, use_threads=True, metadata=None,\n-               use_pandas_metadata=False, memory_map=True):\n+               use_pandas_metadata=False, memory_map=True,\n+               filesystem=None):\n     if _is_path_like(source):\n-        fs = _get_fs_from_path(source)\n-        return fs.read_parquet(source, columns=columns,\n+        fs, path = _get_filesystem_and_path(filesystem, source)\n+        return fs.read_parquet(path, columns=columns,\n                                use_threads=use_threads, metadata=metadata,\n                                use_pandas_metadata=use_pandas_metadata)\n \n@@ -1113,12 +1131,13 @@ def write_table(table, where, row_group_size=None, version='1.0',\n                 use_deprecated_int96_timestamps=None,\n                 coerce_timestamps=None,\n                 allow_truncated_timestamps=False,\n-                flavor=None, **kwargs):\n+                flavor=None, filesystem=None, **kwargs):\n     row_group_size = kwargs.pop('chunk_size', row_group_size)\n     use_int96 = use_deprecated_int96_timestamps\n     try:\n         with ParquetWriter(\n                 where, table.schema,\n+                filesystem=filesystem,\n                 version=version,\n                 flavor=flavor,\n                 use_dictionary=use_dictionary,\n@@ -1192,10 +1211,7 @@ def write_to_dataset(table, root_path, partition_cols=None,\n         Parameter for instantiating Table; preserve pandas index or not.\n     **kwargs : dict, kwargs for write_table function.\n     \"\"\"\n-    if filesystem is None:\n-        fs = _get_fs_from_path(root_path)\n-    else:\n-        fs = _ensure_filesystem(filesystem)\n+    fs, root_path = _get_filesystem_and_path(filesystem, root_path)\n \n     _mkdir_if_not_exists(fs, root_path)\n \ndiff --git a/python/pyarrow/tests/test_hdfs.py b/python/pyarrow/tests/test_hdfs.py\nindex f218a1604a..1af841f2ec 100644\n--- a/python/pyarrow/tests/test_hdfs.py\n+++ b/python/pyarrow/tests/test_hdfs.py\n@@ -216,7 +216,7 @@ def test_ls(self):\n         self.hdfs.mkdir(dir_path)\n \n         f = self.hdfs.open(f1_path, 'wb')\n-        f.write('a' * 10)\n+        f.write(b'a' * 10)\n \n         contents = sorted(self.hdfs.ls(base_path, False))\n         assert contents == [dir_path, f1_path]\n@@ -341,9 +341,9 @@ def test_read_write_parquet_files_with_uri(self):\n         df['uint32'] = df['uint32'].astype(np.int64)\n         table = pa.Table.from_pandas(df, preserve_index=False)\n \n-        pq.write_table(table, path)\n+        pq.write_table(table, path, filesystem=self.hdfs)\n \n-        result = pq.read_table(path).to_pandas()\n+        result = pq.read_table(path, filesystem=self.hdfs).to_pandas()\n \n         pdt.assert_frame_equal(result, df)\n \n@@ -380,7 +380,7 @@ def check_driver(cls):\n     def test_orphaned_file(self):\n         hdfs = hdfs_test_client()\n         file_path = self._make_test_file(hdfs, 'orphaned_file_test', 'fname',\n-                                         'foobarbaz')\n+                                         b'foobarbaz')\n \n         f = hdfs.open(file_path)\n         hdfs = None\n@@ -413,6 +413,11 @@ def _get_hdfs_uri(path):\n @pytest.mark.fastparquet\n @pytest.mark.parametrize('client', ['libhdfs', 'libhdfs3'])\n def test_fastparquet_read_with_hdfs(client):\n+    try:\n+        import snappy  # noqa\n+    except ImportError:\n+        pytest.skip('fastparquet test requires snappy')\n+\n     import pyarrow.parquet as pq\n     fastparquet = pytest.importorskip('fastparquet')\n \n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-18T18:24:49.401+0000",
                    "updated": "2018-12-18T18:24:49.401+0000",
                    "started": "2018-12-18T18:24:49.401+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "176655",
                    "issueId": "13174840"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 3000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@35ac69fb[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@47797882[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@72f1cfbc[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@7e400408[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@117a2143[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@11f5556b[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6d05e4c6[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@139bdd2a[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@532b9623[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@684edf20[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2aaf353b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@6710cfc9[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 3000,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Dec 18 18:24:37 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-12-18T18:24:37.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2919/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2018-07-26T13:29:17.000+0000",
        "updated": "2018-12-18T18:24:49.000+0000",
        "timeoriginalestimate": null,
        "description": "Currently, listing empty HDFS file\u00a0returns \"list directory failed\" which doesn't help much for users. An improvement would be like \"list $file_path failed: No such or file directory\", the error message that HDFS command \"hadoop fs -ls\" returns on empty file.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 3000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Improve error message when listing empty HDFS file",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/comment/16558413",
                    "id": "16558413",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kszucs",
                        "name": "kszucs",
                        "key": "kszucs",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Krisztian Szucs",
                        "active": true,
                        "timeZone": "Europe/Budapest"
                    },
                    "body": "Actually that has changed a bit recently, see https://github.com/apache/arrow/pull/1889\r\nBut still doesn't contain the path.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kszucs",
                        "name": "kszucs",
                        "key": "kszucs",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Krisztian Szucs",
                        "active": true,
                        "timeZone": "Europe/Budapest"
                    },
                    "created": "2018-07-26T15:18:17.891+0000",
                    "updated": "2018-07-26T15:18:17.891+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/comment/16616487",
                    "id": "16616487",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "This is a straightforward change. Contributions would be appreciated",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-09-15T19:39:32.538+0000",
                    "updated": "2018-09-15T19:39:32.538+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/comment/16616644",
                    "id": "16616644",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mauzhang",
                        "name": "mauzhang",
                        "key": "mauzhang",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Manu Zhang",
                        "active": true,
                        "timeZone": "Asia/Shanghai"
                    },
                    "body": "I'd love to work on this. Some questions here.\r\n\r\n1. Shall we check for file exists before list ?\r\n2. What to do with other errors ? ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mauzhang",
                        "name": "mauzhang",
                        "key": "mauzhang",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Manu Zhang",
                        "active": true,
                        "timeZone": "Asia/Shanghai"
                    },
                    "created": "2018-09-16T09:35:35.848+0000",
                    "updated": "2018-09-16T13:24:55.345+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/comment/16710398",
                    "id": "16710398",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Working on the libhdfs bindings can be a cumbersome due to long iteration cycles with the Dockerfile. In the past I have used the Apache Impala development environment to run a local mini-HDFS cluster on my host; it might be useful to write some instructions on the wiki about a minimal setup to run HDFS either in a Docker container or in normal user-space\r\n\r\nhttps://cwiki.apache.org//confluence/display/impala",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-12-05T17:43:42.132+0000",
                    "updated": "2018-12-05T17:43:42.132+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/comment/16723572",
                    "id": "16723572",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "cc [~kszucs] about documenting the developer workflow for working on the HDFS bindings",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-12-18T01:43:35.066+0000",
                    "updated": "2018-12-18T01:43:35.066+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13174840/comment/16724334",
                    "id": "16724334",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 3209\n[https://github.com/apache/arrow/pull/3209]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-12-18T18:24:37.274+0000",
                    "updated": "2018-12-18T18:24:37.274+0000"
                }
            ],
            "maxResults": 6,
            "total": 6,
            "startAt": 0
        },
        "customfield_12311820": "0|i3wcnj:",
        "customfield_12314139": null
    }
}