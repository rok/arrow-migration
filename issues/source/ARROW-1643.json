{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13107048",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048",
    "key": "ARROW-1643",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341707",
                "id": "12341707",
                "description": "",
                "name": "0.9.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-03-19"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ehsantn",
            "name": "ehsantn",
            "key": "ehsantn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Ehsan Totoni",
            "active": true,
            "timeZone": "America/Los_Angeles"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1643/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@d3bc25f[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@249196f1[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@761386f0[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@5e9da0dd[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@799df3cb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@10944d01[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7ada6de5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@49f2b12b[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5f670075[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@6d29b2dd[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@44355fd8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@1812c59c[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Mar 13 13:53:44 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-03-13T13:53:40.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1643/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2017-10-04T19:50:07.000+0000",
        "updated": "2018-03-13T13:53:44.000+0000",
        "timeoriginalestimate": null,
        "description": null,
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16377653",
                    "id": "16377653",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "ehsantn opened a new pull request #1668: ARROW-1643 [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668\n \n \n   This patch enables pq.read_table, pq.write_table, and pq.ParquetFile to accept HDFS URI and connect to HDFS.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-02-26T21:50:53.635+0000",
                    "updated": "2018-02-26T21:50:53.635+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16384082",
                    "id": "16384082",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643 [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-370035124\n \n \n   This is failing due to flakes. I want to make a couple tweaks to the patch, also, going to check it out locally and modify, in addition to fixing the flakes\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-02T19:56:03.372+0000",
                    "updated": "2018-03-02T19:56:03.372+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16384125",
                    "id": "16384125",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643 [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-370045951\n \n \n   This patch adds support for reading datasets (in addition to single files) that are located in HDFS, but this functionality is not tested, only reading single files. @ehsantn do you have time to add a unit test for reading a multi-file dataset from an HDFS uri?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-02T20:39:50.815+0000",
                    "updated": "2018-03-02T20:39:50.815+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16384128",
                    "id": "16384128",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-370046891\n \n \n   Note that the testing situation for HDFS right now is really not good (there is a Dockerfile and a test script, but it isn't being actively used and so likely to be bitrotting). I opened https://issues.apache.org/jira/browse/ARROW-2248 about doing something about this\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-02T20:43:38.948+0000",
                    "updated": "2018-03-02T20:43:38.948+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16384145",
                    "id": "16384145",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "ehsantn commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-370051214\n \n \n   Thanks @xhochy and @wesm for help. Sure, I'll add a unittest for a multi-file dataset.\r\n   \r\n   Yes, we need proper HDFS testing infrastructure. I test using a local HDFS setup.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-02T21:01:31.277+0000",
                    "updated": "2018-03-02T21:01:31.277+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16384146",
                    "id": "16384146",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-370051670\n \n \n   Looks like I missed a couple issues that Travis turned up (I was testing on Python 3.5), let me know if you need help getting the build passing\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-02T21:03:25.818+0000",
                    "updated": "2018-03-02T21:03:25.818+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16386876",
                    "id": "16386876",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-370592159\n \n \n   We should try to close this issue out this week -- if no one else can take a look I will find some time for it\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-05T22:35:23.935+0000",
                    "updated": "2018-03-05T22:35:23.935+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16387027",
                    "id": "16387027",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "ehsantn commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-370615960\n \n \n   Sorry @wesm, I was busy with unexpected tasks. Looking at it now; will hopefully finish tomorrow.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-06T00:21:56.283+0000",
                    "updated": "2018-03-06T00:21:56.283+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16389028",
                    "id": "16389028",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "ehsantn commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-371023197\n \n \n   Looks like the last travis config got stuck installing Lua, so maybe it just needs restarting. I don't have a Windows setup to look at the Windows error at the moment. There are two HDFS tests that are failing also but the errors seem unrelated to me. Can someone look at them?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-07T04:59:39.102+0000",
                    "updated": "2018-03-07T04:59:39.102+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16389033",
                    "id": "16389033",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-371023527\n \n \n   Restarted the build. Can you rebase? I think the appveyor build will pass then\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-07T05:02:05.746+0000",
                    "updated": "2018-03-07T05:02:05.746+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16390449",
                    "id": "16390449",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "ehsantn commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-371325413\n \n \n   Appveyor didn't pass after rebase.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-07T23:41:46.817+0000",
                    "updated": "2018-03-07T23:41:46.817+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16390885",
                    "id": "16390885",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-371409149\n \n \n   The error could be legitimate, someone with access to a Windows machine should have a look into it. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-08T07:57:06.448+0000",
                    "updated": "2018-03-08T07:57:06.448+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16395678",
                    "id": "16395678",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-372418909\n \n \n   I will take a look and see if we can get this into 0.9.0\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-12T18:39:01.530+0000",
                    "updated": "2018-03-12T18:39:01.530+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16396506",
                    "id": "16396506",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668#issuecomment-372538988\n \n \n   +1. I fixed the Windows problem. Let me see if the HDFS docker setup still works while the build is running\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-13T03:56:52.560+0000",
                    "updated": "2018-03-13T03:56:52.560+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16396961",
                    "id": "16396961",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 1668\n[https://github.com/apache/arrow/pull/1668]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-03-13T13:53:40.197+0000",
                    "updated": "2018-03-13T13:53:40.197+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13107048/comment/16396962",
                    "id": "16396962",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm closed pull request #1668: ARROW-1643: [Python] Accept hdfs:// prefixes in parquet.read_table and attempt to connect to HDFS\nURL: https://github.com/apache/arrow/pull/1668\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/python/pyarrow/parquet.py b/python/pyarrow/parquet.py\nindex 42c558b0b..fd9c740f1 100644\n--- a/python/pyarrow/parquet.py\n+++ b/python/pyarrow/parquet.py\n@@ -21,6 +21,13 @@\n import json\n import re\n import six\n+from six.moves.urllib.parse import urlparse\n+# pathlib might not be available in Python 2\n+try:\n+    import pathlib\n+    _has_pathlib = True\n+except ImportError:\n+    _has_pathlib = False\n \n import numpy as np\n \n@@ -53,6 +60,7 @@ class ParquetFile(object):\n     \"\"\"\n     def __init__(self, source, metadata=None, common_metadata=None):\n         self.reader = ParquetReader()\n+        source = _ensure_file(source)\n         self.reader.open(source, metadata=metadata)\n         self.common_metadata = common_metadata\n         self._nested_paths_by_prefix = self._build_nested_paths()\n@@ -279,8 +287,20 @@ def __init__(self, where, schema, flavor=None,\n             self.schema_changed = False\n \n         self.schema = schema\n+        self.where = where\n+\n+        # If we open a file using an implied filesystem, so it can be assured\n+        # to be closed\n+        self.file_handle = None\n+\n+        if is_path(where):\n+            fs = _get_fs_from_path(where)\n+            sink = self.file_handle = fs.open(where, 'wb')\n+        else:\n+            sink = where\n+\n         self.writer = _parquet.ParquetWriter(\n-            where, schema,\n+            sink, schema,\n             version=version,\n             compression=compression,\n             use_dictionary=use_dictionary,\n@@ -310,6 +330,8 @@ def close(self):\n         if self.is_open:\n             self.writer.close()\n             self.is_open = False\n+        if self.file_handle is not None:\n+            self.file_handle.close()\n \n \n def _get_pandas_index_columns(keyvalues):\n@@ -559,8 +581,9 @@ def get_index(self, level, name, key):\n         return self.levels[level].get_index(key)\n \n \n-def is_string(x):\n-    return isinstance(x, six.string_types)\n+def is_path(x):\n+    return (isinstance(x, six.string_types)\n+            or (_has_pathlib and isinstance(x, pathlib.Path)))\n \n \n class ParquetManifest(object):\n@@ -569,7 +592,7 @@ class ParquetManifest(object):\n     \"\"\"\n     def __init__(self, dirpath, filesystem=None, pathsep='/',\n                  partition_scheme='hive'):\n-        self.filesystem = filesystem or LocalFileSystem.get_instance()\n+        self.filesystem = filesystem or _get_fs_from_path(dirpath)\n         self.pathsep = pathsep\n         self.dirpath = dirpath\n         self.partition_scheme = partition_scheme\n@@ -692,7 +715,10 @@ class ParquetDataset(object):\n     def __init__(self, path_or_paths, filesystem=None, schema=None,\n                  metadata=None, split_row_groups=False, validate_schema=True):\n         if filesystem is None:\n-            self.fs = LocalFileSystem.get_instance()\n+            a_path = path_or_paths\n+            if isinstance(a_path, list):\n+                a_path = a_path[0]\n+            self.fs = _get_fs_from_path(a_path)\n         else:\n             self.fs = _ensure_filesystem(filesystem)\n \n@@ -851,7 +877,7 @@ def _make_manifest(path_or_paths, fs, pathsep='/'):\n         # Dask passes a directory as a list of length 1\n         path_or_paths = path_or_paths[0]\n \n-    if is_string(path_or_paths) and fs.isdir(path_or_paths):\n+    if is_path(path_or_paths) and fs.isdir(path_or_paths):\n         manifest = ParquetManifest(path_or_paths, filesystem=fs,\n                                    pathsep=fs.pathsep)\n         common_metadata_path = manifest.common_metadata_path\n@@ -904,11 +930,11 @@ def _make_manifest(path_or_paths, fs, pathsep='/'):\n \n def read_table(source, columns=None, nthreads=1, metadata=None,\n                use_pandas_metadata=False):\n-    if is_string(source):\n-        fs = LocalFileSystem.get_instance()\n+    if is_path(source):\n+        fs = _get_fs_from_path(source)\n+\n         if fs.isdir(source):\n-            return fs.read_parquet(source, columns=columns,\n-                                   metadata=metadata)\n+            return fs.read_parquet(source, columns=columns, metadata=metadata)\n \n     pf = ParquetFile(source, metadata=metadata)\n     return pf.read(columns=columns, nthreads=nthreads,\n@@ -957,7 +983,7 @@ def write_table(table, where, row_group_size=None, version='1.0',\n                 **kwargs) as writer:\n             writer.write_table(table, row_group_size=row_group_size)\n     except Exception:\n-        if isinstance(where, six.string_types):\n+        if is_path(where):\n             try:\n                 os.remove(where)\n             except os.error:\n@@ -1026,7 +1052,7 @@ def write_to_dataset(table, root_path, partition_cols=None,\n     )\n \n     if filesystem is None:\n-        fs = LocalFileSystem.get_instance()\n+        fs = _get_fs_from_path(root_path)\n     else:\n         fs = _ensure_filesystem(filesystem)\n \n@@ -1113,3 +1139,40 @@ def read_schema(where):\n     schema : pyarrow.Schema\n     \"\"\"\n     return ParquetFile(where).schema.to_arrow_schema()\n+\n+\n+def _ensure_file(source):\n+    if is_path(source):\n+        fs = _get_fs_from_path(source)\n+        try:\n+            return fs.open(source)\n+        except IOError as e:\n+            raise lib.ArrowIOError(\"failed to open file {}, {}\"\n+                                   .format(source, e))\n+    elif not hasattr(source, 'seek'):\n+        raise ValueError('Source does not appear file-like')\n+    else:\n+        return source\n+\n+\n+def _get_fs_from_path(path):\n+    \"\"\"\n+    return filesystem from path which could be an HDFS URI\n+    \"\"\"\n+    # input can be hdfs URI such as hdfs://host:port/myfile.parquet\n+    if _has_pathlib and isinstance(path, pathlib.Path):\n+        path = str(path)\n+    parsed_uri = urlparse(path)\n+    if parsed_uri.scheme == 'hdfs':\n+        netloc_split = parsed_uri.netloc.split(':')\n+        host = netloc_split[0]\n+        if host == '':\n+            host = 'default'\n+        port = 0\n+        if len(netloc_split) == 2 and netloc_split[1].isnumeric():\n+            port = int(netloc_split[1])\n+        fs = pa.hdfs.connect(host=host, port=port)\n+    else:\n+        fs = LocalFileSystem.get_instance()\n+\n+    return fs\ndiff --git a/python/pyarrow/tests/test_hdfs.py b/python/pyarrow/tests/test_hdfs.py\nindex 885272ba8..4840aee48 100644\n--- a/python/pyarrow/tests/test_hdfs.py\n+++ b/python/pyarrow/tests/test_hdfs.py\n@@ -272,19 +272,11 @@ def test_read_whole_file(self):\n \n         assert result == data\n \n-    @test_parquet.parquet\n-    def test_read_multiple_parquet_files(self):\n+    def _write_multiple_hdfs_pq_files(self, tmpdir):\n         import pyarrow.parquet as pq\n-\n         nfiles = 10\n         size = 5\n-\n-        tmpdir = pjoin(self.tmp_path, 'multi-parquet-' + guid())\n-\n-        self.hdfs.mkdir(tmpdir)\n-\n         test_data = []\n-        paths = []\n         for i in range(nfiles):\n             df = test_parquet._test_dataframe(size, seed=i)\n \n@@ -300,15 +292,60 @@ def test_read_multiple_parquet_files(self):\n                 pq.write_table(table, f)\n \n             test_data.append(table)\n-            paths.append(path)\n \n-        result = self.hdfs.read_parquet(tmpdir)\n         expected = pa.concat_tables(test_data)\n+        return expected\n+\n+    @test_parquet.parquet\n+    def test_read_multiple_parquet_files(self):\n+\n+        tmpdir = pjoin(self.tmp_path, 'multi-parquet-' + guid())\n+\n+        self.hdfs.mkdir(tmpdir)\n+\n+        expected = self._write_multiple_hdfs_pq_files(tmpdir)\n+        result = self.hdfs.read_parquet(tmpdir)\n \n         pdt.assert_frame_equal(result.to_pandas()\n                                .sort_values(by='index').reset_index(drop=True),\n                                expected.to_pandas())\n \n+    @test_parquet.parquet\n+    def test_read_multiple_parquet_files_with_uri(self):\n+        import pyarrow.parquet as pq\n+\n+        tmpdir = pjoin(self.tmp_path, 'multi-parquet-uri-' + guid())\n+\n+        self.hdfs.mkdir(tmpdir)\n+\n+        expected = self._write_multiple_hdfs_pq_files(tmpdir)\n+        path = _get_hdfs_uri(tmpdir)\n+        result = pq.read_table(path)\n+\n+        pdt.assert_frame_equal(result.to_pandas()\n+                               .sort_values(by='index').reset_index(drop=True),\n+                               expected.to_pandas())\n+\n+    @test_parquet.parquet\n+    def test_read_write_parquet_files_with_uri(self):\n+        import pyarrow.parquet as pq\n+\n+        tmpdir = pjoin(self.tmp_path, 'uri-parquet-' + guid())\n+        self.hdfs.mkdir(tmpdir)\n+        path = _get_hdfs_uri(pjoin(tmpdir, 'test.parquet'))\n+\n+        size = 5\n+        df = test_parquet._test_dataframe(size, seed=0)\n+        # Hack so that we don't have a dtype cast in v1 files\n+        df['uint32'] = df['uint32'].astype(np.int64)\n+        table = pa.Table.from_pandas(df, preserve_index=False)\n+\n+        pq.write_table(table, path)\n+\n+        result = pq.read_table(path).to_pandas()\n+\n+        pdt.assert_frame_equal(result, df)\n+\n     @test_parquet.parquet\n     def test_read_common_metadata_files(self):\n         tmpdir = pjoin(self.tmp_path, 'common-metadata-' + guid())\n@@ -357,3 +394,15 @@ class TestLibHdfs3(HdfsTestCases, unittest.TestCase):\n     def check_driver(cls):\n         if not pa.have_libhdfs3():\n             pytest.skip('No libhdfs3 available on system')\n+\n+\n+def _get_hdfs_uri(path):\n+    host = os.environ.get('ARROW_HDFS_TEST_HOST', 'localhost')\n+    try:\n+        port = int(os.environ.get('ARROW_HDFS_TEST_PORT', 0))\n+    except ValueError:\n+        raise ValueError('Env variable ARROW_HDFS_TEST_PORT was not '\n+                         'an integer')\n+    uri = \"hdfs://{}:{}{}\".format(host, port, path)\n+\n+    return uri\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-13T13:53:44.124+0000",
                    "updated": "2018-03-13T13:53:44.124+0000"
                }
            ],
            "maxResults": 16,
            "total": 16,
            "startAt": 0
        },
        "customfield_12311820": "0|i3kvvb:",
        "customfield_12314139": null
    }
}