{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13240309",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309",
    "key": "ARROW-5647",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12344925",
                "id": "12344925",
                "description": "",
                "name": "0.14.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-07-04"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/3",
            "id": "3",
            "description": "The problem is a duplicate of an existing issue.",
            "name": "Duplicate"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "1.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343937",
                "id": "12343937",
                "description": "",
                "name": "0.13.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-04-01"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": null,
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "name": "Closed",
            "id": "6",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=simonlid",
            "name": "simonlid",
            "key": "simonlid",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Simon Lidberg",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=simonlid",
            "name": "simonlid",
            "key": "simonlid",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Simon Lidberg",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-5647/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "id": "1",
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "name": "Bug",
            "subtask": false,
            "avatarId": 21133
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@1f0fde12[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2e78fa26[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@13ab3641[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@7aeb47d8[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@53cc5d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@5e72e2cd[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@14a1de7c[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@34548eb7[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2afb9d44[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@63d6665c[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@799e1664[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@692f1ed6[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Jul 04 10:31:36 UTC 2019",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2019-07-07T21:57:12.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-5647/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2019-06-18T22:30:50.000+0000",
        "updated": "2019-07-07T21:57:12.000+0000",
        "timeoriginalestimate": null,
        "description": "When trying to access a file using a mount point pointing to an Azure blob storage account the code fails with the following error:\r\n{color:#8b0000}OSError{color}: Passed non-file path: /mnt/aa/example.parquet\r\n{color:#8b0000}---------------------------------------------------------------------------{color} {color:#8b0000}OSError{color} Traceback (most recent call last) {color:#006400}<command-1848295812523966>{color} in {color:#4682b4}<module>{color}{color:#00008b}(){color} {color:#006400}----> 1{color} pddf2 {color:#AA4B00}={color} pd{color:#AA4B00}.{color}read_parquet{color:#AA4B00}({color}{color:#00008b}\"/mnt/aa/example.parquet\"{color}{color:#AA4B00},{color} engine{color:#AA4B00}={color}{color:#00008b}'pyarrow'{color}{color:#AA4B00}){color} {color:#006400} 2{color} display{color:#AA4B00}({color}pddf2{color:#AA4B00}){color} {color:#006400}/databricks/python/lib/python3.5/site-packages/pandas/io/parquet.py{color} in {color:#4682b4}read_parquet{color}{color:#00008b}(path, engine, columns, **kwargs){color} {color:#006400} 280{color} {color:#006400} 281{color} impl {color:#AA4B00}={color} get_engine{color:#AA4B00}({color}engine{color:#AA4B00}){color} {color:#006400}--> 282{color} {color:#006400}return{color} impl{color:#AA4B00}.{color}read{color:#AA4B00}({color}path{color:#AA4B00},{color} columns{color:#AA4B00}={color}columns{color:#AA4B00},{color} {color:#AA4B00}**{color}kwargs{color:#AA4B00}){color} {color:#006400}/databricks/python/lib/python3.5/site-packages/pandas/io/parquet.py{color} in {color:#4682b4}read{color}{color:#00008b}(self, path, columns, **kwargs){color} {color:#006400} 127{color} kwargs{color:#AA4B00}[{color}{color:#00008b}'use_pandas_metadata'{color}{color:#AA4B00}]{color} {color:#AA4B00}={color} {color:#006400}True{color} {color:#006400} 128{color} result = self.api.parquet.read_table(path, columns=columns, {color:#006400}--> 129{color}{color:#AA4B00} **kwargs).to_pandas() {color}{color:#006400} 130{color} {color:#006400}if{color} should_close{color:#AA4B00}:{color} {color:#006400} 131{color} {color:#006400}try{color}{color:#AA4B00}:{color} {color:#006400}/databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py{color} in {color:#4682b4}read_table{color}{color:#00008b}(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, filesystem){color} {color:#006400} 1150{color} return fs.read_parquet(path, columns=columns, {color:#006400} 1151{color} use_threads{color:#AA4B00}={color}use_threads{color:#AA4B00},{color} metadata{color:#AA4B00}={color}metadata{color:#AA4B00},{color} {color:#006400}-> 1152{color}{color:#AA4B00} use_pandas_metadata=use_pandas_metadata) {color}{color:#006400} 1153{color} {color:#006400} 1154{color} pf {color:#AA4B00}={color} ParquetFile{color:#AA4B00}({color}source{color:#AA4B00},{color} metadata{color:#AA4B00}={color}metadata{color:#AA4B00}){color} {color:#006400}/databricks/python/lib/python3.5/site-packages/pyarrow/filesystem.py{color} in {color:#4682b4}read_parquet{color}{color:#00008b}(self, path, columns, metadata, schema, use_threads, use_pandas_metadata){color} {color:#006400} 177{color} {color:#006400}from{color} pyarrow{color:#AA4B00}.{color}parquet {color:#006400}import{color} ParquetDataset {color:#006400} 178{color} dataset = ParquetDataset(path, schema=schema, metadata=metadata, {color:#006400}--> 179{color}{color:#AA4B00} filesystem=self) {color}{color:#006400} 180{color} return dataset.read(columns=columns, use_threads=use_threads, {color:#006400} 181{color} use_pandas_metadata=use_pandas_metadata) {color:#006400}/databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py{color} in {color:#4682b4}__init__{color}{color:#00008b}(self, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads, memory_map){color} {color:#006400} 933{color} self{color:#AA4B00}.{color}metadata_path{color:#AA4B00}){color} {color:#AA4B00}={color} _make_manifest{color:#AA4B00}({color} {color:#006400} 934{color} path_or_paths{color:#AA4B00},{color} self{color:#AA4B00}.{color}fs{color:#AA4B00},{color} metadata_nthreads{color:#AA4B00}={color}metadata_nthreads{color:#AA4B00},{color} {color:#006400}--> 935{color}{color:#AA4B00} open_file_func=self._open_file_func) {color}{color:#006400} 936{color} {color:#006400} 937{color} {color:#006400}if{color} self{color:#AA4B00}.{color}common_metadata_path {color:#006400}is{color} {color:#006400}not{color} {color:#006400}None{color}{color:#AA4B00}:{color} {color:#006400}/databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py{color} in {color:#4682b4}_make_manifest{color}{color:#00008b}(path_or_paths, fs, pathsep, metadata_nthreads, open_file_func){color} {color:#006400} 1108{color} {color:#006400}if{color} {color:#006400}not{color} fs{color:#AA4B00}.{color}isfile{color:#AA4B00}({color}path{color:#AA4B00}){color}{color:#AA4B00}:{color} {color:#006400} 1109{color} raise IOError('Passed non-file path: \\{0}' {color:#006400}-> 1110{color}{color:#AA4B00} .format(path)) {color}{color:#006400} 1111{color} piece {color:#AA4B00}={color} ParquetDatasetPiece{color:#AA4B00}({color}path{color:#AA4B00},{color} open_file_func{color:#AA4B00}={color}open_file_func{color:#AA4B00}){color} {color:#006400} 1112{color} pieces{color:#AA4B00}.{color}append{color:#AA4B00}({color}piece{color:#AA4B00}){color} {color:#8b0000}OSError{color}: Passed non-file path: /mnt/aa/example.parquet\r\n\u00a0\r\nI am using the following code from a Databricks notebook to reproduce the issue:\r\n{color:#005000}%sh \r\n{color}\r\n{color:#005000}sudo apt-get -y install python3-pip\r\n/databricks/python3/bin/pip3 uninstall pandas -y\r\n/databricks/python3/bin/pip3 uninstall numpy -y{color}\r\n{color:#005000}{color:#b08000}/databricks/python3/bin/pip3 uninstall pyarrow -y{color}{color}\r\n\u00a0\r\n\u00a0\r\n{color:#005000}{color:#b08000}{color:#b08000}%sh \r\n/databricks/python3/bin/pip3 install numpy==1.14.0\r\n/databricks/python3/bin/pip3 install pandas==0.24.1\r\n/databricks/python3/bin/pip3 install pyarrow==0.13.0{color}{color}{color}\r\n\u00a0\r\n{color:#005000}{color:#b08000}{color:#b08000}{color:#b08000}dbutils.fs.mount(\r\n\u00a0 source = \"wasbs://<mycontainer>@<mystorageaccount>.blob.core.windows.net\",\r\n\u00a0 mount_point = \"/mnt/aa\",\r\n\u00a0 extra_configs = \\{\"fs.azure.account.key.<mystorageaccount>.blob.core.windows.net\":dbutils.secrets.get(scope = \"storage\", key = \"blob_key\")}){color}{color}{color}{color}\r\n\u00a0\r\n{color:#005000}{color:#b08000}{color:#b08000}{color:#b08000}pddf2 = pd.read_parquet(\"/mnt/aa/example.parquet\", engine='pyarrow')\r\ndisplay(pddf2){color}{color}{color}{color}\r\n\u00a0",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/attachment/12972145",
                "id": "12972145",
                "filename": "arrow_error.txt",
                "author": {
                    "self": "https://issues.apache.org/jira/rest/api/2/user?username=simonlid",
                    "name": "simonlid",
                    "key": "simonlid",
                    "avatarUrls": {
                        "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                        "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                        "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                        "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                    },
                    "displayName": "Simon Lidberg",
                    "active": true,
                    "timeZone": "Etc/UTC"
                },
                "created": "2019-06-18T22:30:16.080+0000",
                "size": 3184,
                "mimeType": "text/plain",
                "content": "https://issues.apache.org/jira/secure/attachment/12972145/arrow_error.txt"
            }
        ],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Accessing a file from Databricks using pandas read_parquet using the pyarrow engine fails with : Passed non-file path: /mnt/aa/example.parquet ",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": "Azure Databricks",
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16867096",
                    "id": "16867096",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "What does {{os.path.isfile(\"/mnt/aa/example.parquet\")}} return? ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-06-18T22:32:55.114+0000",
                    "updated": "2019-06-18T22:32:55.114+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16867100",
                    "id": "16867100",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=simonlid",
                        "name": "simonlid",
                        "key": "simonlid",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Simon Lidberg",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "That actually do return false\r\n\r\n\u00a0\r\n\r\nI can however read the same path using\r\n\r\n\u00a0\r\n\r\ndf2 = spark.read.parquet(\"/mnt/aa/example.parquet\")",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=simonlid",
                        "name": "simonlid",
                        "key": "simonlid",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Simon Lidberg",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2019-06-18T22:40:07.261+0000",
                    "updated": "2019-06-18T22:40:07.261+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16869928",
                    "id": "16869928",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "body": "This is a curiousity with databricks file system (DBFS), actually. Spark on databricks will automatically access files over the {{dbfs:}} file system for you, without you even noticing. The native system calls for doing I/O don't do that. You should be able to open the file if you access it on {{/dbfs/mnt/aa/example.parquet}}. The\u00a0{{/dbfs}} on the local file system has the same contents as the\u00a0{{dbfs:}} file system that spark uses.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "created": "2019-06-21T22:43:12.646+0000",
                    "updated": "2019-06-21T22:43:12.646+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16869930",
                    "id": "16869930",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "body": "Note that the DBFS documentation has warnings for trying to read files that are larger than 2G using local file system I/O, so if you need to do that, you should probably split those files into smaller chunks using spark first.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "created": "2019-06-21T22:45:08.935+0000",
                    "updated": "2019-06-21T22:45:08.935+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16870857",
                    "id": "16870857",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=simonlid",
                        "name": "simonlid",
                        "key": "simonlid",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Simon Lidberg",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "I tested now with accessing the file using /dbfs/mnt/aa/example.parquet it fails but this time with another error:\r\n\r\nArrowIOError Traceback (most recent call last) <command-4042920808160098> in <module>() ----> 1 pddf2 = pd.read_parquet(\"/dbfs/mnt/aa/example2.parquet\", engine='pyarrow')  2 display(pddf2) /databricks/python/lib/python3.5/site-packages/pandas/io/parquet.py in read_parquet(path, engine, columns, **kwargs)  280  281 impl = get_engine(engine) --> 282 return impl.read(path, columns=columns, **kwargs) /databricks/python/lib/python3.5/site-packages/pandas/io/parquet.py in read(self, path, columns, **kwargs)  127 kwargs['use_pandas_metadata'] = True  128 result = self.api.parquet.read_table(path, columns=columns, --> 129 **kwargs).to_pandas()  130 if should_close:  131 try: /databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py in read_table(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, filesystem)  1150 return fs.read_parquet(path, columns=columns,  1151 use_threads=use_threads, metadata=metadata, -> 1152 use_pandas_metadata=use_pandas_metadata)  1153  1154 pf = ParquetFile(source, metadata=metadata) /databricks/python/lib/python3.5/site-packages/pyarrow/filesystem.py in read_parquet(self, path, columns, metadata, schema, use_threads, use_pandas_metadata)  177 from pyarrow.parquet import ParquetDataset  178 dataset = ParquetDataset(path, schema=schema, metadata=metadata, --> 179 filesystem=self)  180 return dataset.read(columns=columns, use_threads=use_threads,  181 use_pandas_metadata=use_pandas_metadata) /databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py in __init__(self, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads, memory_map)  956  957 if validate_schema: --> 958 self.validate_schemas()  959  960 if filters is not None: /databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py in validate_schemas(self)  967 self.schema = self.common_metadata.schema  968 else: --> 969 self.schema = self.pieces[0].get_metadata().schema  970 elif self.schema is None:  971 self.schema = self.metadata.schema /databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py in get_metadata(self, open_file_func)  500 f = self._open(open_file_func)  501 else: --> 502 f = self.open()  503 return f.metadata  504 /databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py in open(self)  518 Returns instance of ParquetFile  519 \"\"\" --> 520 reader = self.open_file_func(self.path)  521 if not isinstance(reader, ParquetFile):  522 reader = ParquetFile(reader) /databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py in open_file(path, meta)  1054 return ParquetFile(path, metadata=meta,  1055 memory_map=self.memory_map, -> 1056 common_metadata=self.common_metadata)  1057 else:  1058 def open_file(path, meta=None): /databricks/python/lib/python3.5/site-packages/pyarrow/parquet.py in __init__(self, source, metadata, common_metadata, memory_map)  128 memory_map=True):  129 self.reader = ParquetReader() --> 130 self.reader.open(source, use_memory_map=memory_map, metadata=metadata)  131 self.common_metadata = common_metadata  132 self._nested_paths_by_prefix = self._build_nested_paths() /databricks/python/lib/python3.5/site-packages/pyarrow/_parquet.cpython-35m-x86_64-linux-gnu.so in pyarrow._parquet.ParquetReader.open() /databricks/python/lib/python3.5/site-packages/pyarrow/lib.cpython-35m-x86_64-linux-gnu.so in pyarrow.lib.check_status() ArrowIOError: Invalid parquet file. Corrupt footer.\r\n\r\nMy entire test code is as follows:\r\n\r\nfrom pyspark.sql import *\r\n--Create test data\r\nrow1 = Row(id='1', name='Alpha')\r\nrow2 = Row(id='2', name='Beta')\r\nrow3 = Row(id='3', name='Gamma')\r\nrow4 = Row(id='4', name='Delta')\r\n\r\ndf = spark.createDataFrame([row1, row2, row3, row4])\r\ndisplay(df)\r\n\r\n--Write the data to the mount point\r\ndf.write.parquet(\"/mnt/aa/example2.parquet\")\r\n\r\n--Try reading using pandas read_parquet\r\npddf2 = pd.read_parquet(\"/dbfs/mnt/aa/example.parquet\", engine='pyarrow')\r\ndisplay(pddf2)\u00a0\r\n\r\nThe same file can be read using \r\ndf2 = spark.read.parquet(\"/mnt/aa/example.parquet\")\r\n\r\npddf = df2.toPandas()\r\ntype(pddf)\r\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=simonlid",
                        "name": "simonlid",
                        "key": "simonlid",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Simon Lidberg",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2019-06-24T06:55:51.082+0000",
                    "updated": "2019-06-24T06:57:47.178+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16870919",
                    "id": "16870919",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "body": "This error is a bit misleading from Arrow. I'm guessing you wrote this parquet file with spark?\r\n\r\n\u00a0\r\n\r\nSpark will tend to put non-parquet files in a parquet folder / dataset, files named things like {{_started}}, {{_comitted}}, {{_SUCCESS}} and so on. These aren't valid parquet files, spark uses them for book-keeping reasons. I think it has to do with writing datasets to blob storage, which doesn't support things like atomic directory renames.\r\n\r\nI'm not sure why arrow attempts to read them as parquet files, but you can easily work around this. Here are two things that I do to get around this issue:\r\n\r\n\u00a0\r\n{code:java}\r\nimport pyarrow.parquet as pq\r\nimport glob\r\n\r\nsegments = glob.glob('/dbfs/mnt/aa/example.parquet/*.parquet')\r\npdf = pq.ParquetDataset(segments).read().to_pandas(){code}\r\n\u00a0\r\n\r\nThis won't always work, eg. you may have a more deeply nested parquet dataset. In this case I've found no other way around this than deleting the offending files.\r\n\r\n\u00a0\r\n\r\nBut I bet, if you were to check, you'd find that your {{example.parquet}} is a folder that contains exactly 1 file that ends with {{.parquet}}, so you could just read that one out.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "created": "2019-06-24T08:24:11.317+0000",
                    "updated": "2019-06-24T08:24:11.317+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16870942",
                    "id": "16870942",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "body": "This is a pain point for me. I use spark a lot to join together and filter some pretty big parquet files (100GB etc), where I will end up with a much smaller one, of only 2-3GB in the end.\u00a0 I usually have to fight both spark and arrow for a little while before I can read the smaller file into pandas.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "created": "2019-06-24T08:27:31.465+0000",
                    "updated": "2019-06-24T08:27:31.465+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16871399",
                    "id": "16871399",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "The \"_started\" files will be excluded automatically in version 0.14.0. PRs to address other problems you're having would be welcome",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-06-24T15:18:17.731+0000",
                    "updated": "2019-06-24T15:18:17.731+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240309/comment/16878528",
                    "id": "16878528",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "body": "[~wesmckinn] \u2013 as far as I can tell, all my \"gripes\" are fixed on master. I think this issue could probably be closed [~simonlid] ?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kaaveland",
                        "name": "kaaveland",
                        "key": "kaaveland",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robin K\u00e5veland",
                        "active": true,
                        "timeZone": "Europe/Oslo"
                    },
                    "created": "2019-07-04T10:31:36.811+0000",
                    "updated": "2019-07-04T10:31:36.811+0000"
                }
            ],
            "maxResults": 9,
            "total": 9,
            "startAt": 0
        },
        "customfield_12311820": "0|z03vs0:",
        "customfield_12314139": null
    }
}