{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13406673",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673",
    "key": "ARROW-14330",
    "fields": {
        "parent": {
            "id": "13417100",
            "key": "ARROW-15079",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13417100",
            "fields": {
                "summary": "[C++] Add scheduler to constrain memory of exec plans",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                    "description": "The issue is open and ready for the assignee to start work on it.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                    "name": "Open",
                    "id": "1",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                        "id": 2,
                        "key": "new",
                        "colorName": "blue-gray",
                        "name": "To Do"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                    "id": "2",
                    "description": "A new feature of the product, which has yet to be developed.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                    "name": "New Feature",
                    "subtask": false,
                    "avatarId": 21141
                }
            }
        },
        "fixVersions": [],
        "resolution": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available",
            "query-engine"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": null,
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
            "description": "The issue is open and ready for the assignee to start work on it.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
            "name": "Open",
            "id": "1",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                "id": 2,
                "key": "new",
                "colorName": "blue-gray",
                "name": "To Do"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=aocsa",
            "name": "aocsa",
            "key": "aocsa",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=aocsa&avatarId=47387",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aocsa&avatarId=47387",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aocsa&avatarId=47387",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aocsa&avatarId=47387"
            },
            "displayName": "Alexander Ocsa",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=aocsa",
            "name": "aocsa",
            "key": "aocsa",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=aocsa&avatarId=47387",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=aocsa&avatarId=47387",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=aocsa&avatarId=47387",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=aocsa&avatarId=47387"
            },
            "displayName": "Alexander Ocsa",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 6600,
            "total": 6600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 6600,
            "total": 6600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-14330/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 11,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/672257",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r739573619\n\n\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n+ public:\n+  DiskDataHolder(const std::shared_ptr<RecordBatch>& record_batch,\n+                 MemoryPool* memory_pool)\n+      : DataHolder(MemoryLevel::kDiskLevel), memory_pool_(memory_pool) {\n+    std::string root_path;\n+    std::string file_name = \"data-holder-temp-\" + RandomString(64) + \".feather\";\n+\n+    filesystem_ =\n+        arrow::fs::FileSystemFromUri(cache_storage_root_path, &root_path).ValueOrDie();\n+\n+    file_path_ = root_path + file_name;\n+    status_ = StoreRecordBatch(record_batch, filesystem_, file_path_);\n+  }\n+\n+  Result<ExecBatch> Get() override {\n+    ARROW_RETURN_NOT_OK(status_);\n+    ARROW_ASSIGN_OR_RAISE(auto record_batch, RecoverRecordBatch(filesystem_, file_path_));\n+    return ExecBatch(*record_batch);\n+  }\n+\n+ private:\n+  std::string file_path_;\n+  Status status_;\n+  MemoryPool* memory_pool_;\n+  std::shared_ptr<arrow::fs::FileSystem> filesystem_;\n+  const std::string cache_storage_root_path = \"file:///tmp/\";\n+};\n+\n+class MemoryResources::MemoryResourcesImpl {\n+ public:\n+  Status AddMemoryResource(std::unique_ptr<MemoryResource> resource) {\n+    std::lock_guard<std::mutex> mutation_guard(lock_);\n\nReview comment:\n       This might be a bit of a premature optimization.  I don't think `AddMemoryResource` is going to be called a lot.  It might be simpler to do away with the locking (and the mutex) and then you could even get rid of the pimpl at that point.\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n+\n+      auto memory_resource_result = resources->memory_resource(id);\n+      if (memory_resource_result.ok()) {\n+        auto memory_resource = memory_resource_result.ValueOrDie();\n+        auto memory_to_use = memory_resource->memory_used();\n\nReview comment:\n       Nit: Name this variable `memory_used`?\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n\nReview comment:\n       Maybe it would make more sense for `MemoryResources` to return a vector of `MemoryResource` instances so you could iterate over that.\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node_test.cc\n##########\n@@ -0,0 +1,140 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+#include <random>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+\n+using testing::UnorderedElementsAreArray;\n+\n+namespace arrow {\n+namespace compute {\n+\n+struct TestDataHolderNode : public ::testing::Test {\n+  static constexpr int kNumBatches = 10;\n+\n+  TestDataHolderNode() : rng_(0) {}\n+\n+  std::shared_ptr<Schema> GenerateRandomSchema(size_t num_inputs) {\n+    static std::vector<std::shared_ptr<DataType>> some_arrow_types = {\n+        arrow::null(),    arrow::boolean(), arrow::int8(),    arrow::int16(),\n+        arrow::int32(),   arrow::int64(),   arrow::float16(), arrow::float32(),\n+        arrow::float64(), arrow::utf8(),    arrow::binary(),  arrow::date32()};\n+\n+    std::vector<std::shared_ptr<Field>> fields(num_inputs);\n+    std::default_random_engine gen(42);\n+    std::uniform_int_distribution<int> types_dist(\n+        0, static_cast<int>(some_arrow_types.size()) - 1);\n+    for (size_t i = 0; i < num_inputs; i++) {\n+      int random_index = types_dist(gen);\n+      auto col_type = some_arrow_types.at(random_index);\n+      fields[i] =\n+          field(\"column_\" + std::to_string(i) + \"_\" + col_type->ToString(), col_type);\n+    }\n+    return schema(fields);\n+  }\n+\n+  void GenerateBatchesFromSchema(const std::shared_ptr<Schema>& schema,\n+                                 size_t num_batches, BatchesWithSchema* out_batches,\n+                                 int multiplicity = 1, int64_t batch_size = 4) {\n+    if (num_batches == 0) {\n+      auto empty_record_batch = ExecBatch(*rng_.BatchOf(schema->fields(), 0));\n+      out_batches->batches.push_back(empty_record_batch);\n+    } else {\n+      for (size_t j = 0; j < num_batches; j++) {\n+        out_batches->batches.push_back(\n+            ExecBatch(*rng_.BatchOf(schema->fields(), batch_size)));\n+      }\n+    }\n+\n+    size_t batch_count = out_batches->batches.size();\n+    for (int repeat = 1; repeat < multiplicity; ++repeat) {\n+      for (size_t i = 0; i < batch_count; ++i) {\n+        out_batches->batches.push_back(out_batches->batches[i]);\n+      }\n+    }\n+    out_batches->schema = schema;\n+  }\n+\n+  void CheckRunOutput(const std::vector<BatchesWithSchema>& batches,\n+                      const BatchesWithSchema& exp_batches) {\n+    ExecContext exec_context(default_memory_pool(),\n+                             ::arrow::internal::GetCpuThreadPool());\n+\n+    ASSERT_OK_AND_ASSIGN(auto plan, ExecPlan::Make(&exec_context));\n+\n+    Declaration union_decl{\"union\", ExecNodeOptions{}};\n+\n+    for (const auto& batch : batches) {\n+      union_decl.inputs.emplace_back(Declaration{\n+          \"source\", SourceNodeOptions{batch.schema, batch.gen(/*parallel=*/true,\n+                                                              /*slow=*/false)}});\n+    }\n+    AsyncGenerator<util::optional<ExecBatch>> sink_gen;\n+\n+    if (batches.size() == 0) {\n+      ASSERT_RAISES(Invalid, Declaration::Sequence({union_decl,\n+                                                    {\"data_holder\", ExecNodeOptions{}},\n+                                                    {\"sink\", SinkNodeOptions{&sink_gen}}})\n+                                 .AddToPlan(plan.get()));\n+      return;\n+    } else {\n+      ASSERT_OK(Declaration::Sequence({union_decl,\n+                                       {\"data_holder\", ExecNodeOptions{}},\n+                                       {\"sink\", SinkNodeOptions{&sink_gen}}})\n+                    .AddToPlan(plan.get()));\n+    }\n+    Future<std::vector<ExecBatch>> actual = StartAndCollect(plan.get(), sink_gen);\n+\n+    auto expected_matcher =\n+        Finishes(ResultWith(UnorderedElementsAreArray(exp_batches.batches)));\n+    ASSERT_THAT(actual, expected_matcher);\n+  }\n+\n+  void CheckDataHolderExecNode(size_t num_input_nodes, size_t num_batches) {\n+    auto random_schema = GenerateRandomSchema(num_input_nodes);\n+\n+    std::vector<std::shared_ptr<RecordBatch>> all_record_batches;\n+    std::vector<BatchesWithSchema> input_batches(num_input_nodes);\n+    BatchesWithSchema exp_batches;\n+    exp_batches.schema = random_schema;\n+    for (size_t i = 0; i < num_input_nodes; i++) {\n+      GenerateBatchesFromSchema(random_schema, num_batches, &input_batches[i]);\n+      for (const auto& batch : input_batches[i].batches) {\n+        exp_batches.batches.push_back(batch);\n+      }\n+    }\n+    CheckRunOutput(input_batches, exp_batches);\n+  }\n+\n+  ::arrow::random::RandomArrayGenerator rng_;\n+};\n+\n+TEST_F(TestDataHolderNode, TestNonEmpty) {\n\nReview comment:\n       This will eventually need tests that cover the case where limits are hit and batches are actually persisted.\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n+\n+      auto memory_resource_result = resources->memory_resource(id);\n+      if (memory_resource_result.ok()) {\n+        auto memory_resource = memory_resource_result.ValueOrDie();\n+        auto memory_to_use = memory_resource->memory_used();\n+        if (memory_to_use < memory_resource->memory_limit()) {\n+          ARROW_ASSIGN_OR_RAISE(auto data_holder, memory_resource->GetDataHolder(batch));\n+          this->producer_.Push(std::move(data_holder));\n+          break;\n+        }\n+      }\n+    }\n+    return Status::OK();\n+  }\n+  AsyncGenerator<std::shared_ptr<DataHolder>> generator() { return gen_; }\n+\n+ public:\n+  ExecContext* context_;\n+  PushGenerator<std::shared_ptr<DataHolder>> gen_;\n+  PushGenerator<std::shared_ptr<DataHolder>>::Producer producer_;\n+};\n+\n+class DataHolderNode : public ExecNode {\n+ public:\n+  DataHolderNode(ExecPlan* plan, NodeVector inputs, std::vector<std::string> input_labels,\n+                 std::shared_ptr<Schema> output_schema, int num_outputs)\n+      : ExecNode(plan, std::move(inputs), input_labels, std::move(output_schema),\n+                 /*num_outputs=*/num_outputs) {\n+    executor_ = plan->exec_context()->executor();\n+\n+    data_holder_manager_ =\n+        ::arrow::internal::make_unique<DataHolderManager>(plan->exec_context());\n+\n+    auto status = task_group_.AddTask([this]() -> Result<Future<>> {\n+      ARROW_DCHECK(executor_ != nullptr);\n+      return executor_->Submit(this->stop_source_.token(), [this] {\n+        auto generator = this->data_holder_manager_->generator();\n+        auto iterator = MakeGeneratorIterator(std::move(generator));\n+        while (true) {\n+          ARROW_ASSIGN_OR_RAISE(auto result, iterator.Next());\n+          if (IsIterationEnd(result)) {\n+            break;\n+          }\n+          ARROW_ASSIGN_OR_RAISE(ExecBatch batch, result->Get());\n+          this->outputs_[0]->InputReceived(this, batch);\n+        }\n+        return Status::OK();\n+      });\n+    });\n+    if (!status.ok()) {\n+      if (input_counter_.Cancel()) {\n+        this->Finish(status);\n+      }\n+      inputs_[0]->StopProducing(this);\n+    }\n+  }\n+\n+  void ErrorReceived(ExecNode* input, Status error) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->ErrorReceived(this, std::move(error));\n+  }\n+\n+  void InputFinished(ExecNode* input, int total_batches) override {\n+    DCHECK_EQ(input, inputs_[0]);\n+    outputs_[0]->InputFinished(this, total_batches);\n+    if (input_counter_.SetTotal(total_batches)) {\n+      this->Finish();\n+    }\n+  }\n+\n+  static Result<ExecNode*> Make(ExecPlan* plan, std::vector<ExecNode*> inputs,\n+                                const ExecNodeOptions& options) {\n+    auto schema = inputs[0]->output_schema();\n+    return plan->EmplaceNode<DataHolderNode>(plan, std::move(inputs),\n+                                             std::vector<std::string>{\"target\"},\n+                                             std::move(schema), /*num_outputs=*/1);\n+  }\n+\n+  const char* kind_name() const override { return \"DataHolderNode\"; }\n+\n+  void InputReceived(ExecNode* input, ExecBatch batch) override {\n+    if (finished_.is_finished()) {\n+      return;\n+    }\n+    auto status = task_group_.AddTask([this, batch]() -> Result<Future<>> {\n+      return this->executor_->Submit(this->stop_source_.token(), [this, batch]() {\n+        auto pool = this->plan()->exec_context()->memory_pool();\n+        ARROW_ASSIGN_OR_RAISE(auto record_batch,\n+                              batch.ToRecordBatch(this->output_schema(), pool));\n\nReview comment:\n       Converting every `ExecBatch` to `RecordBatch` sort of defeats the purpose of having `ExecBatch` in the first place.  Ideally this would only have to happen if we needed to store to disk.\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.h\n##########\n@@ -0,0 +1,94 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/macros.h\"\n+\n+#include <iterator>\n+#include <memory>\n+#include <string>\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+struct ExecBatch;\n+\n+enum class MemoryLevel : int { kGPULevel, kCPULevel, kDiskLevel };\n\nReview comment:\n       I think these should be kGpuLevel and kCpuLevel according to the style guide (not that we are terribly consistent):\r\n   \r\n   https://google.github.io/styleguide/cppguide.html#General_Naming_Rules\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n+ public:\n+  DiskDataHolder(const std::shared_ptr<RecordBatch>& record_batch,\n+                 MemoryPool* memory_pool)\n+      : DataHolder(MemoryLevel::kDiskLevel), memory_pool_(memory_pool) {\n+    std::string root_path;\n+    std::string file_name = \"data-holder-temp-\" + RandomString(64) + \".feather\";\n+\n+    filesystem_ =\n+        arrow::fs::FileSystemFromUri(cache_storage_root_path, &root_path).ValueOrDie();\n+\n+    file_path_ = root_path + file_name;\n+    status_ = StoreRecordBatch(record_batch, filesystem_, file_path_);\n+  }\n+\n+  Result<ExecBatch> Get() override {\n+    ARROW_RETURN_NOT_OK(status_);\n+    ARROW_ASSIGN_OR_RAISE(auto record_batch, RecoverRecordBatch(filesystem_, file_path_));\n+    return ExecBatch(*record_batch);\n+  }\n+\n+ private:\n+  std::string file_path_;\n+  Status status_;\n+  MemoryPool* memory_pool_;\n+  std::shared_ptr<arrow::fs::FileSystem> filesystem_;\n+  const std::string cache_storage_root_path = \"file:///tmp/\";\n+};\n+\n+class MemoryResources::MemoryResourcesImpl {\n+ public:\n+  Status AddMemoryResource(std::unique_ptr<MemoryResource> resource) {\n+    std::lock_guard<std::mutex> mutation_guard(lock_);\n+    auto level = resource->memory_level();\n+    auto it = stats_.find(level);\n+    if (it != stats_.end()) {\n+      return Status::KeyError(\"Already have a resource type registered with name: \",\n+                              resource->ToString());\n+    }\n+    stats_[level] = std::move(resource);\n+    return Status::OK();\n+  }\n+\n+  size_t size() const { return stats_.size(); }\n+\n+  Result<int64_t> memory_limit(MemoryLevel level) const {\n+    auto it = stats_.find(level);\n+    if (it == stats_.end()) {\n+      return Status::KeyError(\"No memory resource registered with level: \",\n+                              MemoryLevelName(level));\n+    }\n+    return it->second->memory_limit();\n+  }\n+\n+  Result<int64_t> memory_used(MemoryLevel level) const {\n+    auto it = stats_.find(level);\n+    if (it == stats_.end()) {\n+      return Status::KeyError(\"No memory resource registered with level: \",\n+                              MemoryLevelName(level));\n+    }\n+    return it->second->memory_used();\n+  }\n+\n+  Result<MemoryResource*> memory_resource(MemoryLevel level) const {\n+    auto it = stats_.find(level);\n+    if (it == stats_.end()) {\n+      return Status::KeyError(\"No memory resource registered with level: \",\n+                              MemoryLevelName(level));\n+    }\n+    return it->second.get();\n+  }\n+\n+ private:\n+  std::mutex lock_;\n+\n+  std::unordered_map<MemoryLevel, std::unique_ptr<MemoryResource>> stats_;\n\nReview comment:\n       Given that `MemoryLevel` is an enum could this just be a fixed array?\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n+\n+      auto memory_resource_result = resources->memory_resource(id);\n+      if (memory_resource_result.ok()) {\n+        auto memory_resource = memory_resource_result.ValueOrDie();\n+        auto memory_to_use = memory_resource->memory_used();\n+        if (memory_to_use < memory_resource->memory_limit()) {\n\nReview comment:\n       What happens if this is false?  It seems to me the batch would be lost.\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n+\n+      auto memory_resource_result = resources->memory_resource(id);\n+      if (memory_resource_result.ok()) {\n+        auto memory_resource = memory_resource_result.ValueOrDie();\n+        auto memory_to_use = memory_resource->memory_used();\n+        if (memory_to_use < memory_resource->memory_limit()) {\n+          ARROW_ASSIGN_OR_RAISE(auto data_holder, memory_resource->GetDataHolder(batch));\n+          this->producer_.Push(std::move(data_holder));\n+          break;\n+        }\n+      }\n+    }\n+    return Status::OK();\n+  }\n+  AsyncGenerator<std::shared_ptr<DataHolder>> generator() { return gen_; }\n+\n+ public:\n+  ExecContext* context_;\n+  PushGenerator<std::shared_ptr<DataHolder>> gen_;\n+  PushGenerator<std::shared_ptr<DataHolder>>::Producer producer_;\n+};\n+\n+class DataHolderNode : public ExecNode {\n+ public:\n+  DataHolderNode(ExecPlan* plan, NodeVector inputs, std::vector<std::string> input_labels,\n+                 std::shared_ptr<Schema> output_schema, int num_outputs)\n+      : ExecNode(plan, std::move(inputs), input_labels, std::move(output_schema),\n+                 /*num_outputs=*/num_outputs) {\n+    executor_ = plan->exec_context()->executor();\n+\n+    data_holder_manager_ =\n+        ::arrow::internal::make_unique<DataHolderManager>(plan->exec_context());\n+\n+    auto status = task_group_.AddTask([this]() -> Result<Future<>> {\n+      ARROW_DCHECK(executor_ != nullptr);\n+      return executor_->Submit(this->stop_source_.token(), [this] {\n+        auto generator = this->data_holder_manager_->generator();\n+        auto iterator = MakeGeneratorIterator(std::move(generator));\n+        while (true) {\n+          ARROW_ASSIGN_OR_RAISE(auto result, iterator.Next());\n+          if (IsIterationEnd(result)) {\n+            break;\n+          }\n+          ARROW_ASSIGN_OR_RAISE(ExecBatch batch, result->Get());\n+          this->outputs_[0]->InputReceived(this, batch);\n+        }\n+        return Status::OK();\n+      });\n+    });\n+    if (!status.ok()) {\n+      if (input_counter_.Cancel()) {\n+        this->Finish(status);\n+      }\n+      inputs_[0]->StopProducing(this);\n+    }\n\nReview comment:\n       It's a bit odd to be calling these methods in the constructor.  Admittedly it's a rather odd error case (AddTask probably shouldn't fail unless maybe the underlying thread pool has been shutdown).  I'm not sure if this will work or if the next call to `StopProducing` will clear things out.\n\n##########\nFile path: cpp/src/arrow/compute/exec.h\n##########\n@@ -78,6 +80,11 @@ class ARROW_EXPORT ExecContext {\n   /// registry provided by GetFunctionRegistry.\n   FunctionRegistry* func_registry() const { return func_registry_; }\n \n+  /// \\brief The MemoryResources for looking up memory resources by memory level\n+  /// and getting data holders to enable out of core processing. Defaults to the\n+  /// library-global function registry provided by GetMemoryResources.\n\nReview comment:\n       ```suggestion\r\n     /// and getting data holders to enable out of core processing. Defaults to the\r\n     /// instance provided by GetMemoryResources.\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n\nReview comment:\n       This probably fits better in a utility class somewhere so it can be shared.  It's pretty similar to the existing function in `bloom_filter_test.cc`\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n+\n+      auto memory_resource_result = resources->memory_resource(id);\n+      if (memory_resource_result.ok()) {\n+        auto memory_resource = memory_resource_result.ValueOrDie();\n+        auto memory_to_use = memory_resource->memory_used();\n+        if (memory_to_use < memory_resource->memory_limit()) {\n+          ARROW_ASSIGN_OR_RAISE(auto data_holder, memory_resource->GetDataHolder(batch));\n+          this->producer_.Push(std::move(data_holder));\n+          break;\n+        }\n+      }\n+    }\n+    return Status::OK();\n+  }\n+  AsyncGenerator<std::shared_ptr<DataHolder>> generator() { return gen_; }\n+\n+ public:\n+  ExecContext* context_;\n+  PushGenerator<std::shared_ptr<DataHolder>> gen_;\n+  PushGenerator<std::shared_ptr<DataHolder>>::Producer producer_;\n+};\n+\n+class DataHolderNode : public ExecNode {\n+ public:\n+  DataHolderNode(ExecPlan* plan, NodeVector inputs, std::vector<std::string> input_labels,\n+                 std::shared_ptr<Schema> output_schema, int num_outputs)\n+      : ExecNode(plan, std::move(inputs), input_labels, std::move(output_schema),\n+                 /*num_outputs=*/num_outputs) {\n+    executor_ = plan->exec_context()->executor();\n+\n+    data_holder_manager_ =\n+        ::arrow::internal::make_unique<DataHolderManager>(plan->exec_context());\n+\n+    auto status = task_group_.AddTask([this]() -> Result<Future<>> {\n+      ARROW_DCHECK(executor_ != nullptr);\n+      return executor_->Submit(this->stop_source_.token(), [this] {\n+        auto generator = this->data_holder_manager_->generator();\n+        auto iterator = MakeGeneratorIterator(std::move(generator));\n\nReview comment:\n       This won't work.  You need to avoid blocking on the CPU thread pool.  This basically takes one of the CPU pool's threads and dedicates it to pulling from the data holder output.  If the data holder fills up then this thread will be a useless thread and since our thread pool is a fixed thread pool this is a bad thing.  Even if the data holder hasn't filled up this thread will spend a lot of time idle if the scanner is slow.\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n\nReview comment:\n       Nit: These `DataHolder` implementations might fit better elsewhere.  I'm not sure we want the `compute` module to depend on the `ipc` module.\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n+ public:\n+  DiskDataHolder(const std::shared_ptr<RecordBatch>& record_batch,\n+                 MemoryPool* memory_pool)\n+      : DataHolder(MemoryLevel::kDiskLevel), memory_pool_(memory_pool) {\n+    std::string root_path;\n+    std::string file_name = \"data-holder-temp-\" + RandomString(64) + \".feather\";\n+\n+    filesystem_ =\n+        arrow::fs::FileSystemFromUri(cache_storage_root_path, &root_path).ValueOrDie();\n+\n+    file_path_ = root_path + file_name;\n+    status_ = StoreRecordBatch(record_batch, filesystem_, file_path_);\n\nReview comment:\n       Complex logic shouldn't happen in constructors.  Maybe there needs to be a `Put` method or something.\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node_test.cc\n##########\n@@ -0,0 +1,140 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+#include <random>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+\n+using testing::UnorderedElementsAreArray;\n+\n+namespace arrow {\n+namespace compute {\n+\n+struct TestDataHolderNode : public ::testing::Test {\n+  static constexpr int kNumBatches = 10;\n+\n+  TestDataHolderNode() : rng_(0) {}\n+\n+  std::shared_ptr<Schema> GenerateRandomSchema(size_t num_inputs) {\n+    static std::vector<std::shared_ptr<DataType>> some_arrow_types = {\n+        arrow::null(),    arrow::boolean(), arrow::int8(),    arrow::int16(),\n+        arrow::int32(),   arrow::int64(),   arrow::float16(), arrow::float32(),\n+        arrow::float64(), arrow::utf8(),    arrow::binary(),  arrow::date32()};\n+\n+    std::vector<std::shared_ptr<Field>> fields(num_inputs);\n+    std::default_random_engine gen(42);\n+    std::uniform_int_distribution<int> types_dist(\n+        0, static_cast<int>(some_arrow_types.size()) - 1);\n+    for (size_t i = 0; i < num_inputs; i++) {\n+      int random_index = types_dist(gen);\n+      auto col_type = some_arrow_types.at(random_index);\n+      fields[i] =\n+          field(\"column_\" + std::to_string(i) + \"_\" + col_type->ToString(), col_type);\n+    }\n+    return schema(fields);\n+  }\n+\n+  void GenerateBatchesFromSchema(const std::shared_ptr<Schema>& schema,\n+                                 size_t num_batches, BatchesWithSchema* out_batches,\n+                                 int multiplicity = 1, int64_t batch_size = 4) {\n+    if (num_batches == 0) {\n+      auto empty_record_batch = ExecBatch(*rng_.BatchOf(schema->fields(), 0));\n+      out_batches->batches.push_back(empty_record_batch);\n+    } else {\n+      for (size_t j = 0; j < num_batches; j++) {\n+        out_batches->batches.push_back(\n+            ExecBatch(*rng_.BatchOf(schema->fields(), batch_size)));\n+      }\n+    }\n+\n+    size_t batch_count = out_batches->batches.size();\n+    for (int repeat = 1; repeat < multiplicity; ++repeat) {\n+      for (size_t i = 0; i < batch_count; ++i) {\n+        out_batches->batches.push_back(out_batches->batches[i]);\n+      }\n+    }\n+    out_batches->schema = schema;\n+  }\n\nReview comment:\n       While this is an interesting concept I don't see why we need random batches to test a data holder.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-10-29T23:49:37.972+0000",
                    "updated": "2021-10-29T23:49:37.972+0000",
                    "started": "2021-10-29T23:49:37.972+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "672257",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/672353",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "aocsa commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r739654690\n\n\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n+ public:\n+  DiskDataHolder(const std::shared_ptr<RecordBatch>& record_batch,\n+                 MemoryPool* memory_pool)\n+      : DataHolder(MemoryLevel::kDiskLevel), memory_pool_(memory_pool) {\n+    std::string root_path;\n+    std::string file_name = \"data-holder-temp-\" + RandomString(64) + \".feather\";\n+\n+    filesystem_ =\n+        arrow::fs::FileSystemFromUri(cache_storage_root_path, &root_path).ValueOrDie();\n+\n+    file_path_ = root_path + file_name;\n+    status_ = StoreRecordBatch(record_batch, filesystem_, file_path_);\n+  }\n+\n+  Result<ExecBatch> Get() override {\n+    ARROW_RETURN_NOT_OK(status_);\n+    ARROW_ASSIGN_OR_RAISE(auto record_batch, RecoverRecordBatch(filesystem_, file_path_));\n+    return ExecBatch(*record_batch);\n+  }\n+\n+ private:\n+  std::string file_path_;\n+  Status status_;\n+  MemoryPool* memory_pool_;\n+  std::shared_ptr<arrow::fs::FileSystem> filesystem_;\n+  const std::string cache_storage_root_path = \"file:///tmp/\";\n+};\n+\n+class MemoryResources::MemoryResourcesImpl {\n+ public:\n+  Status AddMemoryResource(std::unique_ptr<MemoryResource> resource) {\n+    std::lock_guard<std::mutex> mutation_guard(lock_);\n+    auto level = resource->memory_level();\n+    auto it = stats_.find(level);\n+    if (it != stats_.end()) {\n+      return Status::KeyError(\"Already have a resource type registered with name: \",\n+                              resource->ToString());\n+    }\n+    stats_[level] = std::move(resource);\n+    return Status::OK();\n+  }\n+\n+  size_t size() const { return stats_.size(); }\n+\n+  Result<int64_t> memory_limit(MemoryLevel level) const {\n+    auto it = stats_.find(level);\n+    if (it == stats_.end()) {\n+      return Status::KeyError(\"No memory resource registered with level: \",\n+                              MemoryLevelName(level));\n+    }\n+    return it->second->memory_limit();\n+  }\n+\n+  Result<int64_t> memory_used(MemoryLevel level) const {\n+    auto it = stats_.find(level);\n+    if (it == stats_.end()) {\n+      return Status::KeyError(\"No memory resource registered with level: \",\n+                              MemoryLevelName(level));\n+    }\n+    return it->second->memory_used();\n+  }\n+\n+  Result<MemoryResource*> memory_resource(MemoryLevel level) const {\n+    auto it = stats_.find(level);\n+    if (it == stats_.end()) {\n+      return Status::KeyError(\"No memory resource registered with level: \",\n+                              MemoryLevelName(level));\n+    }\n+    return it->second.get();\n+  }\n+\n+ private:\n+  std::mutex lock_;\n+\n+  std::unordered_map<MemoryLevel, std::unique_ptr<MemoryResource>> stats_;\n\nReview comment:\n       Sure \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-10-30T13:30:10.573+0000",
                    "updated": "2021-10-30T13:30:10.573+0000",
                    "started": "2021-10-30T13:30:10.572+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "672353",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/672354",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "aocsa commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r739654996\n\n\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n+ public:\n+  DiskDataHolder(const std::shared_ptr<RecordBatch>& record_batch,\n+                 MemoryPool* memory_pool)\n+      : DataHolder(MemoryLevel::kDiskLevel), memory_pool_(memory_pool) {\n+    std::string root_path;\n+    std::string file_name = \"data-holder-temp-\" + RandomString(64) + \".feather\";\n+\n+    filesystem_ =\n+        arrow::fs::FileSystemFromUri(cache_storage_root_path, &root_path).ValueOrDie();\n+\n+    file_path_ = root_path + file_name;\n+    status_ = StoreRecordBatch(record_batch, filesystem_, file_path_);\n+  }\n+\n+  Result<ExecBatch> Get() override {\n+    ARROW_RETURN_NOT_OK(status_);\n+    ARROW_ASSIGN_OR_RAISE(auto record_batch, RecoverRecordBatch(filesystem_, file_path_));\n+    return ExecBatch(*record_batch);\n+  }\n+\n+ private:\n+  std::string file_path_;\n+  Status status_;\n+  MemoryPool* memory_pool_;\n+  std::shared_ptr<arrow::fs::FileSystem> filesystem_;\n+  const std::string cache_storage_root_path = \"file:///tmp/\";\n+};\n+\n+class MemoryResources::MemoryResourcesImpl {\n+ public:\n+  Status AddMemoryResource(std::unique_ptr<MemoryResource> resource) {\n+    std::lock_guard<std::mutex> mutation_guard(lock_);\n\nReview comment:\n       Agree\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-10-30T13:33:47.005+0000",
                    "updated": "2021-10-30T13:33:47.005+0000",
                    "started": "2021-10-30T13:33:47.005+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "672354",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/672355",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "aocsa commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r739655556\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n\nReview comment:\n       Agree\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-10-30T13:39:45.055+0000",
                    "updated": "2021-10-30T13:39:45.055+0000",
                    "started": "2021-10-30T13:39:45.054+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "672355",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/672358",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "aocsa commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r739656281\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n+\n+      auto memory_resource_result = resources->memory_resource(id);\n+      if (memory_resource_result.ok()) {\n+        auto memory_resource = memory_resource_result.ValueOrDie();\n+        auto memory_to_use = memory_resource->memory_used();\n+        if (memory_to_use < memory_resource->memory_limit()) {\n\nReview comment:\n       Got it\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-10-30T13:48:02.138+0000",
                    "updated": "2021-10-30T13:48:02.138+0000",
                    "started": "2021-10-30T13:48:02.138+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "672358",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/672379",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "aocsa commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r739677271\n\n\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n\nReview comment:\n       I was wondering the same question.  Maybe the best place is `arrow/dataset/` like [DatasetWritingSinkNodeConsumer](https://github.com/westonpace/arrow/blob/97ed669a8d7589361f821a6e88935fe19fece54b/cpp/src/arrow/dataset/file_base.cc#L327). \r\n    \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-10-30T17:10:54.225+0000",
                    "updated": "2021-10-30T17:10:54.225+0000",
                    "started": "2021-10-30T17:10:54.225+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "672379",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/672814",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r740478913\n\n\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n\nReview comment:\n       Datasets also seems like an odd home.\r\n   \r\n   I asked on Zulip: https://ursalabs.zulipchat.com/#narrow/stream/180245-dev/topic/Compute.20module.20.2F.20IPC.20module.20dependency\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-01T19:39:19.975+0000",
                    "updated": "2021-11-01T19:39:19.975+0000",
                    "started": "2021-11-01T19:39:19.975+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "672814",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/673418",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r740478913\n\n\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n\nReview comment:\n       Datasets also seems like an odd home.\r\n   \r\n   I asked on Zulip: https://ursalabs.zulipchat.com/#narrow/stream/180245-dev/topic/Compute.20module.20.2F.20IPC.20module.20dependency\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-02T17:55:21.536+0000",
                    "updated": "2021-11-02T17:55:21.536+0000",
                    "started": "2021-11-02T17:55:21.536+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "673418",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/679117",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "felipeblazing commented on a change in pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#discussion_r745712534\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,220 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  explicit DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    bool pushed = false;\n+    auto resources = context_->memory_resources();\n+    for (auto memory_resource : resources->memory_resources()) {\n+      auto memory_used = memory_resource->memory_used();\n+      if (memory_used < memory_resource->memory_limit()) {\n+        ARROW_ASSIGN_OR_RAISE(auto data_holder, memory_resource->GetDataHolder(batch));\n+        this->producer_.Push(std::move(data_holder));\n+        pushed = true;\n+        break;\n+      }\n+    }\n+    if (!pushed) {\n+      return Status::Invalid(\"No memory resource registered at all in the exec_context\");\n+    }\n+    return Status::OK();\n+  }\n+  AsyncGenerator<std::shared_ptr<DataHolder>> generator() { return gen_; }\n+\n+ public:\n+  ExecContext* context_;\n+  PushGenerator<std::shared_ptr<DataHolder>> gen_;\n+  PushGenerator<std::shared_ptr<DataHolder>>::Producer producer_;\n+};\n+\n+class DataHolderNode : public ExecNode {\n+ public:\n+  DataHolderNode(ExecPlan* plan, NodeVector inputs, std::vector<std::string> input_labels,\n+                 std::shared_ptr<Schema> output_schema, int num_outputs)\n+      : ExecNode(plan, std::move(inputs), input_labels, std::move(output_schema),\n+                 /*num_outputs=*/num_outputs) {\n+    executor_ = plan->exec_context()->executor();\n+\n+    data_holder_manager_ =\n+        ::arrow::internal::make_unique<DataHolderManager>(plan->exec_context());\n+\n+    auto status = task_group_.AddTask([this]() -> Result<Future<>> {\n\nReview comment:\n       I don't think this is how we should push into the next node. We need for a way for a node to be able to request this data from the DataHolder. Setting up a task that basically loops through inputs to push them forward doesn't allow for intelligent scheduling of these things in the future. \r\n   \r\n   Two options I see are either\r\n   \r\n   1. Have the nodes that follow DataHolderManager pull from the DataHolderManager. This is relatively straight forward but lacks control.\r\n   2. Have some kind of Simple Scheduler which pulls from the DataHolderManager that have accumulated the most HeldData and pushes those tasks forward. This is a bit more work but provides more value in my opinion.\r\n   \r\n   \n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.cc\n##########\n@@ -0,0 +1,307 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include <memory>\n+#include <mutex>\n+#include <random>\n+#include <unordered_map>\n+\n+#include <arrow/filesystem/filesystem.h>\n+#include <arrow/ipc/feather.h>\n+#include <arrow/ipc/reader.h>\n+#include <arrow/ipc/writer.h>\n+#include \"arrow/io/file.h\"\n+\n+#ifdef __APPLE__\n+#include <sys/sysctl.h>\n+#include <sys/types.h>\n+#endif\n+\n+#ifdef __linux__\n+#include <sys/statvfs.h>\n+#include <sys/sysinfo.h>\n+#endif\n+\n+// Windows APIs\n+#include \"arrow/util/windows_compatibility.h\"\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+std::string MemoryLevelName(MemoryLevel memory_level) {\n+  static const char* MemoryLevelNames[] = {ARROW_STRINGIFY(MemoryLevel::kDiskLevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kCPULevel),\n+                                           ARROW_STRINGIFY(MemoryLevel::kGPULevel)};\n+\n+  return MemoryLevelNames[static_cast<int>(memory_level)];\n+}\n+\n+std::string MemoryResource::ToString() const { return MemoryLevelName(memory_level_); }\n+\n+class CPUDataHolder : public DataHolder {\n+ public:\n+  explicit CPUDataHolder(const std::shared_ptr<RecordBatch>& record_batch)\n+      : DataHolder(MemoryLevel::kCPULevel), record_batch_(std::move(record_batch)) {}\n+\n+  Result<ExecBatch> Get() override { return ExecBatch(*record_batch_); }\n+\n+ private:\n+  std::shared_ptr<RecordBatch> record_batch_;\n+};\n+\n+namespace {\n+\n+std::string RandomString(std::size_t length) {\n+  const std::string characters =\n+      \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\";\n+  std::random_device random_device;\n+  std::mt19937 generator(random_device());\n+  std::uniform_int_distribution<> distribution(0, characters.size() - 1);\n+  std::string random_string;\n+  for (std::size_t i = 0; i < length; ++i) {\n+    random_string += characters[distribution(generator)];\n+  }\n+  return random_string;\n+}\n+\n+}  // namespace\n+\n+Status StoreRecordBatch(const std::shared_ptr<RecordBatch>& record_batch,\n+                        const std::shared_ptr<fs::FileSystem>& filesystem,\n+                        const std::string& file_path) {\n+  auto output = filesystem->OpenOutputStream(file_path).ValueOrDie();\n+  auto writer =\n+      arrow::ipc::MakeFileWriter(output.get(), record_batch->schema()).ValueOrDie();\n+  ARROW_RETURN_NOT_OK(writer->WriteRecordBatch(*record_batch));\n+  return writer->Close();\n+}\n+Result<std::shared_ptr<RecordBatch>> RecoverRecordBatch(\n+    const std::shared_ptr<fs::FileSystem>& filesystem, const std::string& file_path) {\n+  ARROW_ASSIGN_OR_RAISE(auto input, filesystem->OpenInputFile(file_path));\n+  ARROW_ASSIGN_OR_RAISE(auto reader, arrow::ipc::feather::Reader::Open(input));\n+  std::shared_ptr<Table> table;\n+  ARROW_RETURN_NOT_OK(reader->Read(&table));\n+  TableBatchReader batch_iter(*table);\n+  ARROW_ASSIGN_OR_RAISE(auto batch, batch_iter.Next());\n+  return batch;\n+}\n+\n+class DiskDataHolder : public DataHolder {\n+ public:\n+  DiskDataHolder(const std::shared_ptr<RecordBatch>& record_batch,\n+                 MemoryPool* memory_pool)\n+      : DataHolder(MemoryLevel::kDiskLevel), memory_pool_(memory_pool) {\n+    std::string root_path;\n+    std::string file_name = \"data-holder-temp-\" + RandomString(64) + \".feather\";\n+\n+    filesystem_ =\n+        arrow::fs::FileSystemFromUri(cache_storage_root_path, &root_path).ValueOrDie();\n+\n+    file_path_ = root_path + file_name;\n+    status_ = StoreRecordBatch(record_batch, filesystem_, file_path_);\n\nReview comment:\n       So there are a few options here but what we are saying is that we have these different DataHolders that are created from record_batch. We could make a function which is like\r\n   \r\n   `template <typename DataHolderType> make_data_holder_from_batch(...)`\r\n   \r\n   And it would invoke the constructur with something like the filesystem and path pointing to a file that has already persisted the record batch. This would allow the constructor to be simpler while still being able to have a common api for creating the data_holders from a record_batch\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node_test.cc\n##########\n@@ -0,0 +1,140 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <gmock/gmock-matchers.h>\n+#include <random>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+\n+using testing::UnorderedElementsAreArray;\n+\n+namespace arrow {\n+namespace compute {\n+\n+struct TestDataHolderNode : public ::testing::Test {\n+  static constexpr int kNumBatches = 10;\n+\n+  TestDataHolderNode() : rng_(0) {}\n+\n+  std::shared_ptr<Schema> GenerateRandomSchema(size_t num_inputs) {\n+    static std::vector<std::shared_ptr<DataType>> some_arrow_types = {\n+        arrow::null(),    arrow::boolean(), arrow::int8(),    arrow::int16(),\n+        arrow::int32(),   arrow::int64(),   arrow::float16(), arrow::float32(),\n+        arrow::float64(), arrow::utf8(),    arrow::binary(),  arrow::date32()};\n+\n+    std::vector<std::shared_ptr<Field>> fields(num_inputs);\n+    std::default_random_engine gen(42);\n+    std::uniform_int_distribution<int> types_dist(\n+        0, static_cast<int>(some_arrow_types.size()) - 1);\n+    for (size_t i = 0; i < num_inputs; i++) {\n+      int random_index = types_dist(gen);\n+      auto col_type = some_arrow_types.at(random_index);\n+      fields[i] =\n+          field(\"column_\" + std::to_string(i) + \"_\" + col_type->ToString(), col_type);\n+    }\n+    return schema(fields);\n+  }\n+\n+  void GenerateBatchesFromSchema(const std::shared_ptr<Schema>& schema,\n+                                 size_t num_batches, BatchesWithSchema* out_batches,\n+                                 int multiplicity = 1, int64_t batch_size = 4) {\n+    if (num_batches == 0) {\n+      auto empty_record_batch = ExecBatch(*rng_.BatchOf(schema->fields(), 0));\n+      out_batches->batches.push_back(empty_record_batch);\n+    } else {\n+      for (size_t j = 0; j < num_batches; j++) {\n+        out_batches->batches.push_back(\n+            ExecBatch(*rng_.BatchOf(schema->fields(), batch_size)));\n+      }\n+    }\n+\n+    size_t batch_count = out_batches->batches.size();\n+    for (int repeat = 1; repeat < multiplicity; ++repeat) {\n+      for (size_t i = 0; i < batch_count; ++i) {\n+        out_batches->batches.push_back(out_batches->batches[i]);\n+      }\n+    }\n+    out_batches->schema = schema;\n+  }\n\nReview comment:\n       I guess intead of random we could just do comprehensive so that we cover all the types listed here every time.\n\n##########\nFile path: cpp/src/arrow/compute/memory_resources.h\n##########\n@@ -0,0 +1,98 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/macros.h\"\n+\n+#include <array>\n+#include <iterator>\n+#include <memory>\n+#include <string>\n+#include <vector>\n+\n+namespace arrow {\n+\n+namespace compute {\n+\n+struct ExecBatch;\n+\n+enum class MemoryLevel : int { kGpuLevel, kCpuLevel, kDiskLevel, kNumLevels };\n\nReview comment:\n       Do we want the memory levels to be more extensible than the ones that we staticlaly define? I think this would be fine for a first pass but we should think about later one when maybe the user wants to define their own memory levels.\n\n##########\nFile path: cpp/src/arrow/compute/exec/data_holder_node.cc\n##########\n@@ -0,0 +1,222 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <mutex>\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/api.h\"\n+\n+#include \"arrow/compute/memory_resources.h\"\n+#include \"arrow/util/async_generator.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/exec_plan.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/util/bitmap_ops.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/future.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+\n+class DataHolderManager {\n+ public:\n+  DataHolderManager(ExecContext* context)\n+      : context_(context), gen_(), producer_(gen_.producer()) {}\n+\n+  Status Push(const std::shared_ptr<RecordBatch>& batch) {\n+    static const MemoryLevel all_memory_levels[] = {\n+        MemoryLevel::kGPULevel, MemoryLevel::kCPULevel, MemoryLevel::kDiskLevel};\n+\n+    for (auto id : all_memory_levels) {\n+      auto resources = context_->memory_resources();\n+\n+      auto memory_resource_result = resources->memory_resource(id);\n+      if (memory_resource_result.ok()) {\n+        auto memory_resource = memory_resource_result.ValueOrDie();\n+        auto memory_to_use = memory_resource->memory_used();\n+        if (memory_to_use < memory_resource->memory_limit()) {\n+          ARROW_ASSIGN_OR_RAISE(auto data_holder, memory_resource->GetDataHolder(batch));\n+          this->producer_.Push(std::move(data_holder));\n+          break;\n+        }\n+      }\n+    }\n+    return Status::OK();\n+  }\n+  AsyncGenerator<std::shared_ptr<DataHolder>> generator() { return gen_; }\n+\n+ public:\n+  ExecContext* context_;\n+  PushGenerator<std::shared_ptr<DataHolder>> gen_;\n+  PushGenerator<std::shared_ptr<DataHolder>>::Producer producer_;\n+};\n+\n+class DataHolderNode : public ExecNode {\n+ public:\n+  DataHolderNode(ExecPlan* plan, NodeVector inputs, std::vector<std::string> input_labels,\n+                 std::shared_ptr<Schema> output_schema, int num_outputs)\n+      : ExecNode(plan, std::move(inputs), input_labels, std::move(output_schema),\n+                 /*num_outputs=*/num_outputs) {\n+    executor_ = plan->exec_context()->executor();\n+\n+    data_holder_manager_ =\n+        ::arrow::internal::make_unique<DataHolderManager>(plan->exec_context());\n+\n+    auto status = task_group_.AddTask([this]() -> Result<Future<>> {\n+      ARROW_DCHECK(executor_ != nullptr);\n+      return executor_->Submit(this->stop_source_.token(), [this] {\n+        auto generator = this->data_holder_manager_->generator();\n+        auto iterator = MakeGeneratorIterator(std::move(generator));\n\nReview comment:\n       Maybe we can use a condition variable that waits until there are things to iterate on. When a generator has something to push it can notify that cv.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-11-09T15:43:37.965+0000",
                    "updated": "2021-11-09T15:43:37.965+0000",
                    "started": "2021-11-09T15:43:37.965+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "679117",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/749716",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426#issuecomment-1082464057\n\n\n   I'm going to close this as I don't think it is being pursued any longer and we are implementing these features in other PRs.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-29T23:26:11.894+0000",
                    "updated": "2022-03-29T23:26:11.894+0000",
                    "started": "2022-03-29T23:26:11.894+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "749716",
                    "issueId": "13406673"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13406673/worklog/749717",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace closed pull request #11426:\nURL: https://github.com/apache/arrow/pull/11426\n\n\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-03-29T23:26:14.441+0000",
                    "updated": "2022-03-29T23:26:14.441+0000",
                    "started": "2022-03-29T23:26:14.441+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "749717",
                    "issueId": "13406673"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 6600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@40d7f3c2[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@193de0bc[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5c56056c[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@2a98365a[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@764de688[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@505262c3[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3cc360c0[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@5782abe4[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4e627e3a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@d65594f[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2a87ed43[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@6818ae7c[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 6600,
        "customfield_12312520": null,
        "customfield_12312521": "2021-10-15 01:02:04.0",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": null,
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-14330/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2021-10-15T01:02:04.000+0000",
        "updated": "2022-07-15T15:15:31.000+0000",
        "timeoriginalestimate": null,
        "description": "The purpose of this task is to make an ExecNode that can provide the following functionality.\r\n # Be able to obtain heuristics about our memory consumption and have a memory consumption threshold\r\n\r\n # Be able to write incoming ExecBatch to disk if memory consumption is above the threshold, stores either the ExecBatch or a handle to file in a queue.\r\n\r\n # Provide an api for pulling an ExecBatch from the queue. It should favor pulling all of the batches that are in memory first and then the ones that are handles to files.\r\n\r\n\u00a0\r\n\r\nPRs to reference\r\n\r\n[https://github.com/apache/arrow/pull/11017/]\r\n\r\n\u00a0",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "1h 50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 6600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Create DataHolder that can be used for caching during exec plans",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [],
            "maxResults": 0,
            "total": 0,
            "startAt": 0
        },
        "customfield_12311820": "0|z0vv4w:",
        "customfield_12314139": null
    }
}