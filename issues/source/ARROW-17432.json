{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13477074",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074",
    "key": "ARROW-17432",
    "fields": {
        "fixVersions": [],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351051",
                "id": "12351051",
                "description": "",
                "name": "8.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-05-06"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351550",
                "id": "12351550",
                "name": "9.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-08-03"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": null,
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "name": "Closed",
            "id": "6",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333008",
                "id": "12333008",
                "name": "R"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
            "name": "gds506",
            "key": "JIRAUSER294488",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Guillermo Duran",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
            "name": "gds506",
            "key": "JIRAUSER294488",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Guillermo Duran",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-17432/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "id": "1",
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "name": "Bug",
            "subtask": false,
            "avatarId": 21133
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@276086a8[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6e71dc65[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@46a7d676[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@2655b833[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2359ce6[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6dc6d9db[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@15aab673[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@1eb510d5[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@30496d49[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@6b9a629a[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2b4348b4[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@1dc6c6b1[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Oct 17 02:32:56 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-10-17T02:33:25.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-17432/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2022-08-16T14:01:07.000+0000",
        "updated": "2022-10-17T02:33:25.000+0000",
        "timeoriginalestimate": null,
        "description": "This is a weird issue that creates new rows when importing a large csv (56 GB) into parquet in R. It occurred with both R Arrow 8.0.0 and 9.0.0 BUT didn't occur with the Python Arrow library 9.0.0. Due to the large size of the original csv it's difficult to create a reproducible example, but I share the code and outputs.\r\n\r\nThe code I use in R to import the csv:\r\n{code:java}\r\nlibrary(arrow)\r\nlibrary(dplyr)\r\n \r\ncsv_file <- \"/ebird_erd2021/full/obs.csv\"\r\ndest <- \"/ebird_erd2021/full/obs_parquet/\" \r\n\r\nsch = arrow::schema(checklist_id = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 species_code = string(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 exotic_category = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 obs_count = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 only_presence_reported = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 only_slash_reported = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 valid = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 reviewed = float32(),\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 has_media = float32()\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )\r\n\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = sch, skip_rows = 1)\r\n\r\nwrite_dataset(csv_stream, dest, format = \"parquet\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 max_rows_per_file=1000000L,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 hive_style = TRUE,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 existing_data_behavior = \"overwrite\"){code}\r\nWhen I load the dataset and check one random _checklist_id_ I get rows that are not part of the _obs.csv_ file. There shouldn't be duplicated species in a checklist but there are ({_}amerob{_} for example)...\u00a0 also note that the duplicated species have different {_}obs_count{_}. 50 species in total in that specific {_}checklist_id{_}.\r\n{code:java}\r\nparquet_arrow <- open_dataset(dest, format = \"parquet\")\r\n\r\nparquet_arrow |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect() \r\n\r\n# A tibble: 50 \u00d7 3\r\n   checklist_id species_code obs_count\r\n          <dbl> <chr>            <dbl>\r\n 1     18543372 altori               3\r\n 2     18543372 amekes               1\r\n 3     18543372 amered              40\r\n 4     18543372 amerob              30\r\n 5     18543372 amerob               9\r\n 6     18543372 balori               9\r\n 7     18543372 blkter               9\r\n 8     18543372 blkvul              20\r\n 9     18543372 buggna               1\r\n10     18543372 buwwar               1\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows{code}\r\nIf I use awk to query the csv file with that same checklist id, I get something different:\r\n{code:java}\r\n$ awk -F \",\" '{ if ($1 == 18543372) { print } }' obs.csv\r\n\r\n18543372.0,rewbla,,60.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,amerob,,30.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,robgro,,2.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,eastow,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,sedwre1,,2.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,ovenbi1,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,buggna,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,reshaw,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,turvul,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,gowwar,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,balori,,9.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,buwwar,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,grycat,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,cangoo,,6.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,houwre,,1.0,0.0,0.0,1.0,0.0,0.0\r\n18543372.0,amered,,40.0,0.0,0.0,1.0,1.0,0.0\r\n18543372.0,norwat,,2.0,0.0,0.0,1.0,0.0,0.0{code}\r\n17 different species and no repetitions... Look _amerob_ on the 2nd line only, with 30 _obs_count_\r\n\r\n\u00a0\r\n\r\nIf I import the csv into parquet using the Python Arrow library as:\r\n{code:java}\r\nimport pyarrow as pa\r\nimport pyarrow.dataset as ds\r\nimport pyarrow.compute as pc\r\nimport pandas as pd \r\n\r\ntest_rows_csv = pd.read_csv(\"/ebird_erd2021/full/obs.csv\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nrows = 1000)\r\n\r\nsch = pa.Schema.from_pandas(test_rows_csv)\r\n\r\ncsv_file = ds.dataset(\"/ebird_erd2021/full/obs.csv\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 schema = sch,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 format = \"csv\")\r\n\r\nds.write_dataset(csv_file,\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"ebird_erd2021/full/obs_parquet_py/\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0format = \"parquet\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = sch,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0use_threads = True,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0max_rows_per_file = 1000000,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0max_rows_per_group = 1000000,\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0existing_data_behavior = \"error\"){code}\r\nAnd then load it in R doing the same checklist search:\r\n{code:java}\r\nparquet_py <- \"/ebird_erd2021/full/obs_parquet_py/\"\r\n\r\nparquet_arrow <- open_dataset(parquet_py, format = \"parquet\")\r\n\r\nparquet_arrow |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 select(checklist_id, species_code, obs_count) |>\u00a0\r\n\u00a0 collect()\r\n\r\n# A tibble: 17 \u00d7 3\r\n   checklist_id species_code obs_count\r\n          <dbl> <chr>            <dbl>\r\n 1     18543372 amered              40\r\n 2     18543372 amerob              30\r\n 3     18543372 balori               9\r\n 4     18543372 buggna               1\r\n 5     18543372 buwwar               1\r\n 6     18543372 cangoo               6\r\n 7     18543372 eastow               1\r\n 8     18543372 gowwar               1\r\n 9     18543372 grycat               1\r\n10     18543372 houwre               1\r\n11     18543372 norwat               2\r\n12     18543372 ovenbi1              1\r\n13     18543372 reshaw               1\r\n14     18543372 rewbla              60\r\n15     18543372 robgro               2\r\n16     18543372 sedwre1              2\r\n17     18543372 turvul               1{code}\r\nI get exactly what I should. No _species_code_ repeated and 17 different species.\r\n\r\n\u00a0\r\n\r\nDue to these differences I guess something weird must be happening in the R arrow library.",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[R] messed up rows when importing large csv into parquet",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": "R version 4.2.1\r\nRunning in Arch Linux - EndeavourOS\r\n\r\narrow_info()\r\nArrow package version: 9.0.0\r\n\r\nCapabilities:\r\n               \r\ndataset    TRUE\r\nsubstrait FALSE\r\nparquet    TRUE\r\njson       TRUE\r\ns3         TRUE\r\ngcs        TRUE\r\nutf8proc   TRUE\r\nre2        TRUE\r\nsnappy     TRUE\r\ngzip       TRUE\r\nbrotli     TRUE\r\nzstd       TRUE\r\nlz4        TRUE\r\nlz4_frame  TRUE\r\nlzo       FALSE\r\nbz2        TRUE\r\njemalloc   TRUE\r\nmimalloc   TRUE\r\n\r\nMemory:\r\n                  \r\nAllocator jemalloc\r\nCurrent   49.31 Kb\r\nMax        1.63 Mb\r\n\r\nRuntime:\r\n                        \r\nSIMD Level          avx2\r\nDetected SIMD Level avx2\r\n\r\nBuild:\r\n                          \r\nC++ Library Version  9.0.0\r\nC++ Compiler           GNU\r\nC++ Compiler Version 7.5.0\r\n\r\n####\r\nprint(pa.__version__)\r\n9.0.0\r\n",
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074/comment/17584903",
                    "id": "17584903",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=eitsupi",
                        "name": "eitsupi",
                        "key": "JIRAUSER280211",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
                        },
                        "displayName": "SHIMA Tatsuya",
                        "active": true,
                        "timeZone": "Asia/Tokyo"
                    },
                    "body": "Hi, how about passing the schema to the {{col_types}} argument?\r\n\r\n{code:r}\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\", \r\n                           col_types = sch)\r\n{code}\r\n\r\nOr, using {{readr::read_csv()}}?\r\n\r\nI also wonder if the number of rows in the dataset fetched is the same in all cases.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=eitsupi",
                        "name": "eitsupi",
                        "key": "JIRAUSER280211",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
                        },
                        "displayName": "SHIMA Tatsuya",
                        "active": true,
                        "timeZone": "Asia/Tokyo"
                    },
                    "created": "2022-08-25T15:32:22.859+0000",
                    "updated": "2022-08-25T15:32:22.859+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074/comment/17604804",
                    "id": "17604804",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Thanks for your comments [~eitsupi] .\r\n\r\nI tried using _col_types_ instead of _schema_ as arguments of the _open_dataset_ function but the issue is still present.\r\n\r\n\u00a0\r\n\r\nI also did the \"query\" straight with the _csv_stream_ object and got the same issue, so I guess the bug is in the *_open_dataset_* function. Take a look:\r\n{code:java}\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0col_types = sch)\r\n\r\ncsv_stream |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect()\r\n\r\n# A tibble: 50 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 altori                    NA         3                      0                   0     1        0         0\r\n 2     18543372 amekes                    NA         1                      0                   0     1        0         0\r\n 3     18543372 amered                    NA        40                      0                   0     1        1         0\r\n 4     18543372 amerob                    NA        30                      0                   0     1        0         0\r\n 5     18543372 amerob                    NA         9                      0                   0     1        0         0\r\n 6     18543372 balori                    NA         9                      0                   0     1        0         0\r\n 7     18543372 blkter                    NA         9                      0                   0     1        0         0\r\n 8     18543372 blkvul                    NA        20                      0                   0     1        0         0\r\n 9     18543372 buggna                    NA         1                      0                   0     1        0         0\r\n10     18543372 buwwar                    NA         1                      0                   0     1        0         0\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows{code}\r\n\u00a0\r\n\r\nIn regard to the number of rows, I check the csv file:\r\n{code:java}\r\n$ wc -l obs.csv\r\n\r\n739629150 obs.csv{code}\r\n\u00a0\r\n\r\nand the csv_stream read by arrow:\r\n{code:java}\r\n> csv_stream$num_rows\r\n[1] 739629149\r\n\r\n{code}\r\nI get them right (without taking into account the header).\r\n\r\n\u00a0\r\n\r\nSo it seems the open_dataset is reading the right number of rows, but making a mess with the information on each row.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-09-14T15:20:50.469+0000",
                    "updated": "2022-09-14T15:20:50.469+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074/comment/17617597",
                    "id": "17617597",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fmic",
                        "name": "fmic",
                        "key": "JIRAUSER294484",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Fran\u00e7ois Michonneau",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "I'm wondering if you have a floating point issue. Your checklist ID is being imported as double and you filter with `==`. Can you parse your checklist ID as int32 when importing in Arrow? (as a related question why do you have decimal notation for integers in your CSV file?)",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fmic",
                        "name": "fmic",
                        "key": "JIRAUSER294484",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Fran\u00e7ois Michonneau",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2022-10-14T09:30:39.082+0000",
                    "updated": "2022-10-14T09:30:39.082+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074/comment/17617742",
                    "id": "17617742",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Thanks for your suggestion [~fmic]\u00a0\r\n\r\nAs why we have a decimal notation on the checklists ID column... that's a good question, but basically that's how the data is exported from the eBird db.\r\n\r\n\u00a0\r\n{code:java}\r\n$ head obs.csv\r\nchecklist_id,species_code,exotic_category,obs_count,only_presence_reported,only_slash_reported,valid,reviewed,has_media\r\n771514.0,comgra,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,grycat,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,bkcchi,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,sonspa,,3.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,bnhcow,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,amegfi,,4.0,0.0,0.0,1.0,0.0,0.0\r\n771514.0,rewbla,,1.0,0.0,0.0,1.0,0.0,0.0\r\n771515.0,yelwar,,4.0,0.0,0.0,1.0,0.0,0.0\r\n771515.0,amecro,,1.0,0.0,0.0,1.0,0.0,0.0\r\n{code}\r\nI can do some regex trickery to remove the \".0\" from the csv before _open_dataset()_ but in any case it's weird that I have the issue only when importing the csv with the R Arrow library. If I change the type for that column to int32 on the _open_dataset()_ schema,\u00a0 I get a conversion error due to the mismatch.\r\n\r\n\u00a0\r\n\r\nIf I do the subset with the decimal I still get the same weird rows:\r\n\r\n\u00a0\r\n{code:java}\r\nsch = arrow::schema(checklist_id = float32(),\r\n                    species_code = string(),\r\n                    exotic_category = float32(),\r\n                    obs_count = float32(),\r\n                    only_presence_reported = float32(),\r\n                    only_slash_reported = float32(),\r\n                    valid = float32(),\r\n                    reviewed = float32(),\r\n                    has_media = float32()\r\n                    )\r\n\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\", \r\n                           col_types = sch)\r\n\r\ncsv_stream |> \r\n   filter(checklist_id == 18543372.0) |> \r\n   arrange(species_code) |> \r\n   collect()\r\n\r\n# A tibble: 50 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 altori                    NA         3                      0                   0     1        0         0\r\n 2     18543372 amekes                    NA         1                      0                   0     1        0         0\r\n 3     18543372 amered                    NA        40                      0                   0     1        1         0\r\n 4     18543372 amerob                    NA        30                      0                   0     1        0         0\r\n 5     18543372 amerob                    NA         9                      0                   0     1        0         0\r\n 6     18543372 balori                    NA         9                      0                   0     1        0         0\r\n 7     18543372 blkter                    NA         9                      0                   0     1        0         0\r\n 8     18543372 blkvul                    NA        20                      0                   0     1        0         0\r\n 9     18543372 buggna                    NA         1                      0                   0     1        0         0\r\n10     18543372 buwwar                    NA         1                      0                   0     1        0         0\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows{code}\r\n\u00a0\r\n\r\nEven if I filter by an interval, the result is the same:\r\n{code:java}\r\ncsv_stream |> \r\n  filter(checklist_id > 18543371 & checklist_id < 18543373) |> \r\n  arrange(species_code) |> \r\n  collect()\r\n\r\n# A tibble: 50 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 altori                    NA         3                      0                   0     1        0         0\r\n 2     18543372 amekes                    NA         1                      0                   0     1        0         0\r\n 3     18543372 amered                    NA        40                      0                   0     1        1         0\r\n 4     18543372 amerob                    NA        30                      0                   0     1        0         0\r\n 5     18543372 amerob                    NA         9                      0                   0     1        0         0\r\n 6     18543372 balori                    NA         9                      0                   0     1        0         0\r\n 7     18543372 blkter                    NA         9                      0                   0     1        0         0\r\n 8     18543372 blkvul                    NA        20                      0                   0     1        0         0\r\n 9     18543372 buggna                    NA         1                      0                   0     1        0         0\r\n10     18543372 buwwar                    NA         1                      0                   0     1        0         0\r\n# \u2026 with 40 more rows\r\n# \u2139 Use `print(n = ...)` to see more rows {code}\r\n\u00a0\r\n\r\nAlso, thinking about the possible differences between the schema used to import the csv in Arrow's Python vs R, it seems that both are the \"same\":\r\n{code:java}\r\nimport pyarrow as pa\r\nimport pyarrow.dataset as ds\r\nimport pyarrow.compute as pc\r\nimport pandas as pd\u00a0\r\n\r\ntest_rows_csv = pd.read_csv(\"/ebird_erd2021/full/obs.csv\",\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nrows = 1000)\r\n\r\nsch = pa.Schema.from_pandas(test_rows_csv)\r\n\r\nsch\r\n\r\nchecklist_id: double\r\nspecies_code: string\r\nexotic_category: double\r\nobs_count: double\r\nonly_presence_reported: double\r\nonly_slash_reported: double\r\nvalid: double\r\nreviewed: double\r\nhas_media: double\r\n-- schema metadata --\r\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 1391{code}",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-10-14T13:53:07.212+0000",
                    "updated": "2022-10-14T14:19:52.304+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074/comment/17617756",
                    "id": "17617756",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fmic",
                        "name": "fmic",
                        "key": "JIRAUSER294484",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Fran\u00e7ois Michonneau",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Could you use awk or python to see if there is a {{checklist_id}} associated with having 9 `{{{}obs_count{}}}` for `{{{}amerob{}}}`? and if there is one, you could create a small version of the CSV file with just these {{checklist_ids}} to see if you can reproduce this duplication.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fmic",
                        "name": "fmic",
                        "key": "JIRAUSER294484",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
                        },
                        "displayName": "Fran\u00e7ois Michonneau",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2022-10-14T14:17:11.841+0000",
                    "updated": "2022-10-14T14:17:11.841+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074/comment/17617907",
                    "id": "17617907",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "thanks again for your input [~fmic]\u00a0\r\n\r\nI selected all the rows with obs_count == 9 AND species_code == \"amerob\". The database/csv is quite big, so there are lots of these (a 7MB csv).\r\n\r\nInterestingly, when importing the csv with _open_dataset()_ I wasn't able to reproduce the issue. __ \r\n\r\nGenerating the \"test\" csv with awk:\r\n{code:java}\r\n$ head -n 1 obs.csv > test_amerob_9.csv && awk -F \",\" '{ if (($2 ~ /amerob/) && ($4 == 9)) { print } }' obs.csv >> test_amerob_9.csv \r\n\r\n$ head test_amerob_9.csv\r\nchecklist_id,species_code,exotic_category,obs_count,only_presence_reported,only_slash_reported,valid,reviewed,has_media\r\n892273.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n926762.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n927961.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n932031.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n932082.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n932713.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n933502.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n934156.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0\r\n935005.0,amerob,,9.0,0.0,0.0,1.0,0.0,0.0{code}\r\nLoading as Arrow and querying in R:\r\n{code:java}\r\ncsv_file <- \"test_amerob_9.csv\"\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = sch, skip_rows = 1)\r\n\r\ncsv_stream |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect()\r\n\r\n A tibble: 1 \u00d7 9\r\n  checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n         <dbl> <chr>                  <dbl>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n1     18543372 amerob                    NA         9                      0                   0     1        0         0{code}\r\n\u00a0\r\n\r\nI wonder if it has to be due to the large size of the csv and something internal of the \"csv importer/parser\" of the R Arrow library?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-10-14T18:19:42.902+0000",
                    "updated": "2022-10-14T18:19:42.902+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13477074/comment/17618380",
                    "id": "17618380",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "hey I tried with _schema = NULL_ to infer the schema from the csv and it worked!\r\n\r\n\u00a0\r\n{code:java}\r\ncsv_stream <- open_dataset(csv_file, format = \"csv\",\u00a0\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0schema = NULL)\r\n\r\ncsv_stream |>\u00a0\r\n\u00a0 filter(checklist_id == 18543372) |>\u00a0\r\n\u00a0 arrange(species_code) |>\u00a0\r\n\u00a0 collect()\r\n\r\n# A tibble: 17 \u00d7 9\r\n   checklist_id species_code exotic_category obs_count only_presence_reported only_slash_reported valid reviewed has_media\r\n          <dbl> <chr>                  <???>     <dbl>                  <dbl>               <dbl> <dbl>    <dbl>     <dbl>\r\n 1     18543372 amered                     .        40                      0                   0     1        1         0\r\n 2     18543372 amerob                     .        30                      0                   0     1        0         0\r\n 3     18543372 balori                     .         9                      0                   0     1        0         0\r\n 4     18543372 buggna                     .         1                      0                   0     1        0         0\r\n 5     18543372 buwwar                     .         1                      0                   0     1        0         0\r\n 6     18543372 cangoo                     .         6                      0                   0     1        0         0\r\n 7     18543372 eastow                     .         1                      0                   0     1        0         0\r\n 8     18543372 gowwar                     .         1                      0                   0     1        0         0\r\n 9     18543372 grycat                     .         1                      0                   0     1        0         0\r\n10     18543372 houwre                     .         1                      0                   0     1        0         0\r\n11     18543372 norwat                     .         2                      0                   0     1        0         0\r\n12     18543372 ovenbi1                    .         1                      0                   0     1        0         0\r\n13     18543372 reshaw                     .         1                      0                   0     1        0         0\r\n14     18543372 rewbla                     .        60                      0                   0     1        0         0\r\n15     18543372 robgro                     .         2                      0                   0     1        0         0\r\n16     18543372 sedwre1                    .         2                      0                   0     1        0         0\r\n17     18543372 turvul                     .         1                      0                   0     1        0         0 {code}\r\n\u00a0\r\n\r\n\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=gds506",
                        "name": "gds506",
                        "key": "JIRAUSER294488",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Guillermo Duran",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-10-17T02:32:56.035+0000",
                    "updated": "2022-10-17T02:32:56.035+0000"
                }
            ],
            "maxResults": 7,
            "total": 7,
            "startAt": 0
        },
        "customfield_12311820": "0|z17suo:",
        "customfield_12314139": null
    }
}