{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13124727",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727",
    "key": "ARROW-1920",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341707",
                "id": "12341707",
                "description": "",
                "name": "0.9.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-03-19"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jim.crist",
            "name": "jim.crist",
            "key": "jim.crist",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jim.crist&avatarId=33449",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jim.crist&avatarId=33449",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jim.crist&avatarId=33449",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jim.crist&avatarId=33449"
            },
            "displayName": "Jim Crist",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jim.crist",
            "name": "jim.crist",
            "key": "jim.crist",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jim.crist&avatarId=33449",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jim.crist&avatarId=33449",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jim.crist&avatarId=33449",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jim.crist&avatarId=33449"
            },
            "displayName": "Jim Crist",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jim.crist",
            "name": "jim.crist",
            "key": "jim.crist",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jim.crist&avatarId=33449",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jim.crist&avatarId=33449",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jim.crist&avatarId=33449",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jim.crist&avatarId=33449"
            },
            "displayName": "Jim Crist",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1920/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@4f045db3[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@375ef8fb[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5cbf6982[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@1c66dbce[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@69634d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6b271dc8[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4c738a57[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@66e190bc[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2d59e426[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@7e436518[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2eb279b5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@44bc78af[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Jan 04 15:12:10 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-01-04T15:11:21.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1920/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2017-12-13T16:29:34.000+0000",
        "updated": "2018-01-04T15:12:10.000+0000",
        "timeoriginalestimate": null,
        "description": "Would be nice to be able to read ORC files in pyarrow, similar to the already existing parquet support.",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "Add support for reading ORC files",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16289484",
                    "id": "16289484",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist opened a new pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418\n \n \n   This adds support for reading ORC files in the C++ library, as well as python bindings for this functionality.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-13T16:31:23.899+0000",
                    "updated": "2017-12-13T16:31:23.899+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16289496",
                    "id": "16289496",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-351447660\n \n \n   A few high level notes:\r\n   \r\n   - Following the example in #1026, I put the c++ code in `src/arrow/adapters/orc/*`. This is nice, as Arrow has a more active community than `apache/orc`. However, it does mean that the underlying classes in liborc (e.g. `ColumnStatistics`, `ReaderOptions`, etc...) can't be exposed as part of the api. An alternative version would add arrow support in `apache/orc`, and wrap that in `pyarrow`. My main goal is to add orc reading support to pyarrow, so whatever library structure best allows that is fine with me.\r\n   \r\n   - This is the first time I've written c++ in 10 years, I've probably made some naive mistakes. Criticism welcome :).\r\n   \r\n   - Since liborc and pyarrow share numerous dependencies, it's important that the versions of these dependencies match. As such, I haven't added a `FindORC.cmake` script - a custom build of `liborc.a` is required to ensure the dependencies match.\r\n   \r\n   - I'm not sure how to add tests here. There are numerous example files in `apache/orc` that I used to test locally, but I'm not sure if/how we can integrate those into the tests here.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-13T16:39:03.915+0000",
                    "updated": "2017-12-13T16:39:03.915+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16289504",
                    "id": "16289504",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-351448881\n \n \n   Demo:\r\n   \r\n   ```python\r\n   In [1]: from pyarrow import orc\r\n   \r\n   In [2]: f = orc.ORCFile('/Users/jcrist/Code/orc/examples/demo-11-none.orc')\r\n   \r\n   In [3]: f.nrows\r\n   Out[3]: 1920800\r\n   \r\n   In [4]: f.nstripes\r\n   Out[4]: 385\r\n   \r\n   In [5]: f.read_stripe(0).to_pandas().head()\r\n   Out[5]:\r\n      _col0 _col1 _col2    _col3  _col4 _col5  _col6  _col7  _col8\r\n   0      1     M     M  Primary    500  Good      0      0      0\r\n   1      2     F     M  Primary    500  Good      0      0      0\r\n   2      3     M     S  Primary    500  Good      0      0      0\r\n   3      4     F     S  Primary    500  Good      0      0      0\r\n   4      5     M     D  Primary    500  Good      0      0      0\r\n   \r\n   In [6]: f2 = orc.ORCFile('/Users/jcrist/Code/orc/examples/TestOrcFile.test1.orc')\r\n   \r\n   In [7]: f2.schema  # A nested schema\r\n   Out[7]:\r\n   boolean1: bool\r\n   byte1: int8\r\n   short1: int16\r\n   int1: int32\r\n   long1: int64\r\n   float1: float\r\n   double1: double\r\n   bytes1: binary\r\n   string1: string\r\n   middle: struct<list: list<item: struct<int1: int32, string1: string>>>\r\n     child 0, list: list<item: struct<int1: int32, string1: string>>\r\n         child 0, item: struct<int1: int32, string1: string>\r\n             child 0, int1: int32\r\n             child 1, string1: string\r\n   list: list<item: struct<int1: int32, string1: string>>\r\n     child 0, item: struct<int1: int32, string1: string>\r\n         child 0, int1: int32\r\n         child 1, string1: string\r\n   map: list<item: struct<key: string, value: struct<int1: int32, string1: string>>>\r\n     child 0, item: struct<key: string, value: struct<int1: int32, string1: string>>\r\n         child 0, key: string\r\n         child 1, value: struct<int1: int32, string1: string>\r\n             child 0, int1: int32\r\n             child 1, string1: string\r\n   \r\n   In [8]: f2.read(columns=['boolean1', 'middle.list.int1']).to_pydict()  # subselect nested fields\r\n   Out[8]:\r\n   OrderedDict([('boolean1', [False, True]),\r\n                ('middle',\r\n                 [{'list': [{'int1': 1}, {'int1': 2}]},\r\n                  {'list': [{'int1': 1}, {'int1': 2}]}])])\r\n   ```\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-13T16:42:57.439+0000",
                    "updated": "2017-12-13T16:42:57.439+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16289514",
                    "id": "16289514",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "cpcloud commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-351450726\n \n \n   @jcrist This looks pretty awesome. Looking forward to reviewing, I should have some time this weekend.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-13T16:48:35.401+0000",
                    "updated": "2017-12-13T16:48:35.401+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16289518",
                    "id": "16289518",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r156716704\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, uint64_t stripe) {\n+    if (stripe >= stripes_.size()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, uint64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, (uint64_t)1000));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    auto elements = batch->elements.get();\n+    auto elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    auto keys = batch->keys.get();\n+    auto vals = batch->elements.get();\n+    auto keytype = type->getSubtype(0);\n+    auto valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n \n Review comment:\n   `liborc` upcasts all numerics to `int64`, which means we need to downcast back into the arrow structure. This was the best pattern I found to support this, but it gets a bit into the internal details of the `ArrayBuilder`. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-13T16:52:01.089+0000",
                    "updated": "2017-12-13T16:52:01.089+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16289519",
                    "id": "16289519",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r156716294\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, uint64_t stripe) {\n+    if (stripe >= stripes_.size()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, uint64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, (uint64_t)1000));\n \n Review comment:\n   I'm not terribly happy with this magic number here. Since data has to be copied out of the orc reader and into the arrow structure, it doesn't make sense to allocate a batch the same size as the output (doubling memory usage), but you also don't want a really tiny batch. This could be configurable if needed, but I'd rather have users avoid this detail. `liborc` does expose a memory estimate for a read, so the fixed number of rows could be switched to a fixed memory size, and the batch size computed from there.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-13T16:52:01.163+0000",
                    "updated": "2017-12-13T16:52:01.163+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16289520",
                    "id": "16289520",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r156717022\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   This reads an entire file as a single `RecordBatch`. I'm not sure if this is best, or if it should allocate a bunch of smaller `RecordBatch`'s and return a `Table` composed of them.\r\n   \r\n   I'm also not sure if the api here should be working with `Table` instead of `RecordBatch`.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-13T16:52:01.177+0000",
                    "updated": "2017-12-13T16:52:01.177+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16292562",
                    "id": "16292562",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157200905\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   Reading the full file should go into a `Table` instance. If we are reading only chunks of a file, they should than go into a `RecordBatch` which then could be merged by the user into a `Table`.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-15T14:02:07.253+0000",
                    "updated": "2017-12-15T14:02:07.253+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16292563",
                    "id": "16292563",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157205268\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n \n Review comment:\n   Simply use `std::vector<std::shared_ptr<Field>> fields` here\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-15T14:02:07.262+0000",
                    "updated": "2017-12-15T14:02:07.262+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16292564",
                    "id": "16292564",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157205486\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n \n Review comment:\n   No need for `= nullptr` here, this is the default.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-15T14:02:07.263+0000",
                    "updated": "2017-12-15T14:02:07.263+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16292565",
                    "id": "16292565",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157206300\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, uint64_t stripe) {\n+    if (stripe >= stripes_.size()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, uint64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, (uint64_t)1000));\n \n Review comment:\n   It would be nice if you refactor this out as a constant declared somewhere, e.g. `constexpr uint64_t kReadRowsBatch = 1000`. One approach we used in parquet-cpp was to implement a specialization in the parquet-cpp code that could directly read into pre-allocated memory. I don't expect this to be implemented in this PR but it could be a worthwhile optimisation if this here proves to be too slow (we had a 30% performance improvement by that change in parquet_arrow).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-15T14:02:07.267+0000",
                    "updated": "2017-12-15T14:02:07.267+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16292566",
                    "id": "16292566",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157205182\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n \n Review comment:\n   Please only use `auto` if the actual type is already mentioned in the same line.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-15T14:02:07.268+0000",
                    "updated": "2017-12-15T14:02:07.268+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16292567",
                    "id": "16292567",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157205586\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n \n Review comment:\n   This is not needed, the value of metadata is already this.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-15T14:02:07.274+0000",
                    "updated": "2017-12-15T14:02:07.274+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295429",
                    "id": "16295429",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157567877\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n \n Review comment:\n   Are you sure about this? Removing this line leads to a segfault, as the `metadata->Append` line below dereferences a nullptr (IIUC, note that my c++ is rusty at best, so I may misunderstand here).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T18:48:15.938+0000",
                    "updated": "2017-12-18T18:48:15.938+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295442",
                    "id": "16295442",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157568522\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   Should the resulting table be composed of a single or multiple record batches? Either is doable, as we're having to copy data out of the orc reader in either case. Currently I read the whole table as a single large record batch, but there may be some benefit to breaking it into a collections of smaller blocks, not sure.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T18:51:01.892+0000",
                    "updated": "2017-12-18T18:51:01.892+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295455",
                    "id": "16295455",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-352523219\n \n \n   > These are probably due to liborc symbols not being hidden in the generated shared libraries. If you like I can make a PR to your PR to fix this.\r\n   \r\n   That'd be useful, I don't fully understand what the `symbols.map` file is doing.\r\n   \r\n   > In general, we follow the Google C++ styleguide in Arrow. One of the specialities of it is that unsigned integers are not used.\r\n   \r\n   I've removed the use of unsigned integers in several (but not all) places. These were used to match the api of `liborc`, which makes heavy use of them. I could remove them completely, but would need to explicitly check range and cast when interacting with `liborc` then.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T18:53:20.779+0000",
                    "updated": "2017-12-18T18:53:20.779+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295474",
                    "id": "16295474",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157570484\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, uint64_t stripe) {\n+    if (stripe >= stripes_.size()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, uint64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, (uint64_t)1000));\n \n Review comment:\n   > One approach we used in parquet-cpp was to implement a specialization in the parquet-cpp code that could directly read into pre-allocated memory.\r\n   \r\n   I'd also expect substantial performance improvements with this route (could avoid the extra allocations, all the casting, dropping of dictionary encoding, etc...). This would require the arrow implementation move to liborc instead (an option that I mentioned above), as none of the required interfaces are exposed in the `liborc` library. I don't think this would be a problem to do later, as the user-api exposed here shouldn't change, just the build process.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T18:58:59.802+0000",
                    "updated": "2017-12-18T18:58:59.802+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295482",
                    "id": "16295482",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "cpcloud commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157571817\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n \n Review comment:\n   @xhochy This is needed if you don't pass the keys and values to the metadata constructor, because a NULL pointer to `KeyValueMetadata` is different than an instance of `KeyValueMetadata` with no keys/values.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:04:23.420+0000",
                    "updated": "2017-12-18T19:04:23.420+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295490",
                    "id": "16295490",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "cpcloud commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157572947\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, uint64_t stripe) {\n+    if (stripe >= stripes_.size()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, uint64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, (uint64_t)1000));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    auto elements = batch->elements.get();\n+    auto elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    auto keys = batch->keys.get();\n+    auto vals = batch->elements.get();\n+    auto keytype = type->getSubtype(0);\n+    auto valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n \n Review comment:\n   could do this as `std::copy(source, source + length, target + start)` as well\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:09:21.273+0000",
                    "updated": "2017-12-18T19:09:21.273+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295562",
                    "id": "16295562",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157573769\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out);\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out);\n+  int64_t NumberOfStripes();\n+  int64_t NumberOfRows();\n+\n+ private:\n+  class Impl;\n+  std::unique_ptr<Impl> impl_;\n+  explicit ORCFileReader(std::unique_ptr<Impl> impl);\n \n Review comment:\n   We've been leaning toward creating the PIMPL in the private ctor (and having no arguments), but perhaps this is stylistic (see `ipc::RecordBatchStreamReader` as an example)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:33.295+0000",
                    "updated": "2017-12-18T19:51:33.295+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295563",
                    "id": "16295563",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157572468\n \n \n\n ##########\n File path: cpp/CMakeLists.txt\n ##########\n @@ -226,6 +230,17 @@ if(ARROW_BUILD_TESTS OR ARROW_BUILD_BENCHMARKS)\n   set(ARROW_WITH_ZSTD ON)\n endif()\n \n+if (WIN32)\n \n Review comment:\n   Maybe change this to `MSVC` since cygwin/mingw32/64 may behave differently\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:33.333+0000",
                    "updated": "2017-12-18T19:51:33.333+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295564",
                    "id": "16295564",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157572286\n \n \n\n ##########\n File path: cpp/CMakeLists.txt\n ##########\n @@ -226,6 +230,17 @@ if(ARROW_BUILD_TESTS OR ARROW_BUILD_BENCHMARKS)\n   set(ARROW_WITH_ZSTD ON)\n endif()\n \n+if (WIN32)\n+  # ORC doesn't build on windows\n \n Review comment:\n   Are there JIRAs open about this on the Apache ORC project? \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:33.454+0000",
                    "updated": "2017-12-18T19:51:33.454+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295565",
                    "id": "16295565",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157572657\n \n \n\n ##########\n File path: cpp/cmake_modules/ThirdpartyToolchain.cmake\n ##########\n @@ -29,7 +29,9 @@ set(SNAPPY_VERSION \"1.1.3\")\n set(BROTLI_VERSION \"v0.6.0\")\n set(LZ4_VERSION \"1.7.5\")\n set(ZSTD_VERSION \"1.2.0\")\n+set(PROTOBUF_VERSION \"2.6.0\")\n set(GRPC_VERSION \"94582910ad7f82ad447ecc72e6548cb669e4f7a9\") # v1.6.5\n+set(ORC_VERSION \"cf00b67795717ab3eb04e950780ed6d104109017\")\n \n Review comment:\n   Does this need a version of trunk, or can we use a released version of ORC?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:33.629+0000",
                    "updated": "2017-12-18T19:51:33.629+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295566",
                    "id": "16295566",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157574394\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n \n Review comment:\n   Since `ORC` is already in the name of the classes in question, it would be acceptable to drop the `orc` namespace and hiding any private names in anonymous namespaces or detail/internal namespaces\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:33.714+0000",
                    "updated": "2017-12-18T19:51:33.714+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295567",
                    "id": "16295567",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157574083\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n \n Review comment:\n   This should be the first include in the file -- I thought cpplint complained about this but perhaps not\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.159+0000",
                    "updated": "2017-12-18T19:51:34.159+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295568",
                    "id": "16295568",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157576157\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n \n Review comment:\n   possibly `GetArrowSchema`? \r\n   \r\n   This method and the one above should either be static or live in an anonymous namespace (we have started doing more of the latter since LLVM can do extra optimizations with anonymous NS)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.210+0000",
                    "updated": "2017-12-18T19:51:34.210+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295569",
                    "id": "16295569",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157575348\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n \n Review comment:\n   You can also `return (*impl)->Init();` here\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.336+0000",
                    "updated": "2017-12-18T19:51:34.336+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295570",
                    "id": "16295570",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157575047\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n \n Review comment:\n   Does ORC support any other timestamp resolutions?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.361+0000",
                    "updated": "2017-12-18T19:51:34.361+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295571",
                    "id": "16295571",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157578027\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n \n Review comment:\n   See above comments re: argument ordering\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.365+0000",
                    "updated": "2017-12-18T19:51:34.365+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295572",
                    "id": "16295572",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157574937\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n \n Review comment:\n   Is the expectation for both of these types to be ASCII or UTF-8?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.389+0000",
                    "updated": "2017-12-18T19:51:34.389+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295573",
                    "id": "16295573",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157576471\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n \n Review comment:\n   PascalCase here\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.393+0000",
                    "updated": "2017-12-18T19:51:34.393+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295574",
                    "id": "16295574",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157573219\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n \n Review comment:\n   Can you add a minimal set of doxygen comments to this class and its methods (for the API documentation)? Any details however minimal about the params would be helpful\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.414+0000",
                    "updated": "2017-12-18T19:51:34.414+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295575",
                    "id": "16295575",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157578269\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n \n Review comment:\n   OK to use `i < builder->num_fields()` here (and elsewhere)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.442+0000",
                    "updated": "2017-12-18T19:51:34.442+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295576",
                    "id": "16295576",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157575848\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n \n Review comment:\n   Would it be easier / make more sense to read the schema once upon opening the file (and store the schema as a member in this object)? \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.446+0000",
                    "updated": "2017-12-18T19:51:34.446+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295577",
                    "id": "16295577",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157574829\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n \n Review comment:\n   Maybe call this `GetArrowType`? \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.483+0000",
                    "updated": "2017-12-18T19:51:34.483+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295578",
                    "id": "16295578",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157575195\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n \n Review comment:\n   Use `static_cast` here\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.485+0000",
                    "updated": "2017-12-18T19:51:34.485+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295579",
                    "id": "16295579",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157579012\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n \n Review comment:\n   If you set `const bool nullable = batch->hasNulls` then some compilers may be able to unswitch this loop. Not sure it will matter much performancewise though\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.488+0000",
                    "updated": "2017-12-18T19:51:34.488+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295580",
                    "id": "16295580",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157576539\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n \n Review comment:\n   `ReadBatch`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.500+0000",
                    "updated": "2017-12-18T19:51:34.500+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295581",
                    "id": "16295581",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157581705\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_date_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<Date64Builder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = source[i] * 24 * 60 * 60 * 1000;\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type>\n+  Status append_binary_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                             int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i], batch->length[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_fixed_binary_batch(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<FixedSizeBinaryBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_decimal_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                              liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                              int64_t length) {\n+    auto builder = static_cast<Decimal128Builder*>(abuilder);\n+\n+    if (type->getPrecision() == 0 || type->getPrecision() > 18) {\n+      auto batch = static_cast<liborc::Decimal128VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x =\n+              Decimal128(batch->values[i].getHighBits(), batch->values[i].getLowBits());\n \n Review comment:\n   Confirming with `cpcloud` that this lines up with our little-endian decimal128 representation in Arrow\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.542+0000",
                    "updated": "2017-12-18T19:51:34.542+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295582",
                    "id": "16295582",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157579521\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n \n Review comment:\n   Using `typename` instead of `class` might be more conforming, but I don't have a strong opinion\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.552+0000",
                    "updated": "2017-12-18T19:51:34.552+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295583",
                    "id": "16295583",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157576992\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n \n Review comment:\n   I assume this is a contract of `createRowBatch`? Using `const auto& struct_batch = static_cast<const liborc::StructVectorBatch&>(*batch)` might be more consistent with other parts of the codebase\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.571+0000",
                    "updated": "2017-12-18T19:51:34.571+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295584",
                    "id": "16295584",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157582076\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_date_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<Date64Builder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = source[i] * 24 * 60 * 60 * 1000;\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type>\n+  Status append_binary_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                             int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i], batch->length[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_fixed_binary_batch(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<FixedSizeBinaryBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_decimal_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                              liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                              int64_t length) {\n+    auto builder = static_cast<Decimal128Builder*>(abuilder);\n+\n+    if (type->getPrecision() == 0 || type->getPrecision() > 18) {\n+      auto batch = static_cast<liborc::Decimal128VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x =\n+              Decimal128(batch->values[i].getHighBits(), batch->values[i].getLowBits());\n+          RETURN_NOT_OK(builder->Append(x));\n+        } else {\n+          RETURN_NOT_OK(builder->AppendNull());\n+        }\n+      }\n+    } else {\n+      auto batch = static_cast<liborc::Decimal64VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x = Decimal128(batch->values[i]);\n \n Review comment:\n   Could this yield undefined behavior? Here either `x` should be properly on the stack or passed as an rvalue to `Append` (`Append(Decimal128(...))`)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.575+0000",
                    "updated": "2017-12-18T19:51:34.575+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295585",
                    "id": "16295585",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157580801\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n \n Review comment:\n   Perhaps declare `constexpr int64_t kOneSecondNanos = 1000000000LL;`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.576+0000",
                    "updated": "2017-12-18T19:51:34.576+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295586",
                    "id": "16295586",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157579833\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, uint64_t stripe) {\n+    if (stripe >= stripes_.size()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, uint64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, (uint64_t)1000));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    auto elements = batch->elements.get();\n+    auto elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    auto keys = batch->keys.get();\n+    auto vals = batch->elements.get();\n+    auto keytype = type->getSubtype(0);\n+    auto valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n \n Review comment:\n   +1 (and if not using `std::copy`, should use `static_cast`)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.578+0000",
                    "updated": "2017-12-18T19:51:34.578+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295587",
                    "id": "16295587",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157580974\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n \n Review comment:\n   We might leave a TODO about boundschecking since ORC supports a longer range of timestamps for nano resolution\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.590+0000",
                    "updated": "2017-12-18T19:51:34.590+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295588",
                    "id": "16295588",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157581152\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_date_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<Date64Builder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = source[i] * 24 * 60 * 60 * 1000;\n \n Review comment:\n   Can you put this shift in a named constexpr variable (`kOneDayMillis`)?\r\n   \r\n   Any reason to use date64 here instead of date32? \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.621+0000",
                    "updated": "2017-12-18T19:51:34.621+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295589",
                    "id": "16295589",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157577876\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n \n Review comment:\n   PascalCase these append methods\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.640+0000",
                    "updated": "2017-12-18T19:51:34.640+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295590",
                    "id": "16295590",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157577719\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n \n Review comment:\n   Can this happen?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.657+0000",
                    "updated": "2017-12-18T19:51:34.657+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295591",
                    "id": "16295591",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157580486\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,698 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      auto fields = {field(\"key\", keytype), field(\"value\", valtype)};\n+      *out = list(struct_(fields));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      auto size = type->getSubtypeCount();\n+      auto fields = std::vector<std::shared_ptr<Field>>();\n+      std::vector<uint8_t> type_codes;\n+      for (uint64_t child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        auto f = field(\"_union_\" + std::to_string(child), elemtype);\n+        fields.push_back(f);\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  uint64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  uint64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    auto size = type.getSubtypeCount();\n+    auto fields = std::vector<std::shared_ptr<Field>>();\n+    for (uint64_t child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata = nullptr;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(uint64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, uint64_t stripe) {\n+    if (stripe >= stripes_.size()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, uint64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, (uint64_t)1000));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    auto elements = batch->elements.get();\n+    auto elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    auto keys = batch->keys.get();\n+    auto vals = batch->elements.get();\n+    auto keytype = type->getSubtype(0);\n+    auto valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n \n Review comment:\n   The pattern we used in parquet-cpp was to copy the values into a temporary buffer (that gets reused), but this is OK, too. However, we had not envisioned users directly writing into the internal builder buffer\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.669+0000",
                    "updated": "2017-12-18T19:51:34.669+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295592",
                    "id": "16295592",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157577282\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n \n Review comment:\n   `AppendBatch`. Also, can we change the argument orders and some refs/pointers here -- \"in\" arguments should come first, followed by the in-out argument `builder`. `batch` should be passed as const-ref (initially I thought that `type` should be too, but I see that the ORC API returns pointers to type objects)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T19:51:34.707+0000",
                    "updated": "2017-12-18T19:51:34.707+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295646",
                    "id": "16295646",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "cpcloud commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157597545\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_date_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<Date64Builder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = source[i] * 24 * 60 * 60 * 1000;\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type>\n+  Status append_binary_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                             int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i], batch->length[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_fixed_binary_batch(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<FixedSizeBinaryBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_decimal_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                              liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                              int64_t length) {\n+    auto builder = static_cast<Decimal128Builder*>(abuilder);\n+\n+    if (type->getPrecision() == 0 || type->getPrecision() > 18) {\n+      auto batch = static_cast<liborc::Decimal128VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x =\n+              Decimal128(batch->values[i].getHighBits(), batch->values[i].getLowBits());\n \n Review comment:\n   Yep, our `Decimal128` constructor is specified `high, low`.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T20:53:36.500+0000",
                    "updated": "2017-12-18T20:53:36.500+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295650",
                    "id": "16295650",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "cpcloud commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157598805\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_date_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<Date64Builder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = source[i] * 24 * 60 * 60 * 1000;\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type>\n+  Status append_binary_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                             int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i], batch->length[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_fixed_binary_batch(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<FixedSizeBinaryBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_decimal_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                              liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                              int64_t length) {\n+    auto builder = static_cast<Decimal128Builder*>(abuilder);\n+\n+    if (type->getPrecision() == 0 || type->getPrecision() > 18) {\n+      auto batch = static_cast<liborc::Decimal128VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x =\n+              Decimal128(batch->values[i].getHighBits(), batch->values[i].getLowBits());\n+          RETURN_NOT_OK(builder->Append(x));\n+        } else {\n+          RETURN_NOT_OK(builder->AppendNull());\n+        }\n+      }\n+    } else {\n+      auto batch = static_cast<liborc::Decimal64VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x = Decimal128(batch->values[i]);\n \n Review comment:\n   That's actually valid behavior per the standard, but I think it's more complicated than it needs to be. This should be a stack variable or temporary.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T20:58:53.832+0000",
                    "updated": "2017-12-18T20:58:53.832+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295651",
                    "id": "16295651",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "cpcloud commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157598805\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_date_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<Date64Builder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = source[i] * 24 * 60 * 60 * 1000;\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type>\n+  Status append_binary_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                             int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i], batch->length[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_fixed_binary_batch(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<FixedSizeBinaryBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_decimal_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                              liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                              int64_t length) {\n+    auto builder = static_cast<Decimal128Builder*>(abuilder);\n+\n+    if (type->getPrecision() == 0 || type->getPrecision() > 18) {\n+      auto batch = static_cast<liborc::Decimal128VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x =\n+              Decimal128(batch->values[i].getHighBits(), batch->values[i].getLowBits());\n+          RETURN_NOT_OK(builder->Append(x));\n+        } else {\n+          RETURN_NOT_OK(builder->AppendNull());\n+        }\n+      }\n+    } else {\n+      auto batch = static_cast<liborc::Decimal64VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!batch->hasNulls || batch->notNull[i]) {\n+          const Decimal128& x = Decimal128(batch->values[i]);\n \n Review comment:\n   That's actually defined behavior per the standard, but I think it's more complicated than it needs to be. This should be a stack variable or temporary.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T20:59:03.493+0000",
                    "updated": "2017-12-18T20:59:03.493+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295856",
                    "id": "16295856",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157629699\n \n \n\n ##########\n File path: cpp/CMakeLists.txt\n ##########\n @@ -226,6 +230,17 @@ if(ARROW_BUILD_TESTS OR ARROW_BUILD_BENCHMARKS)\n   set(ARROW_WITH_ZSTD ON)\n endif()\n \n+if (WIN32)\n+  # ORC doesn't build on windows\n \n Review comment:\n   https://issues.apache.org/jira/browse/ORC-34, but it's also an issue with the cmake build system assuming *nix in some places (e.g. calling `./configure` directly).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:32:42.682+0000",
                    "updated": "2017-12-18T23:32:42.682+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295859",
                    "id": "16295859",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157629876\n \n \n\n ##########\n File path: cpp/cmake_modules/ThirdpartyToolchain.cmake\n ##########\n @@ -29,7 +29,9 @@ set(SNAPPY_VERSION \"1.1.3\")\n set(BROTLI_VERSION \"v0.6.0\")\n set(LZ4_VERSION \"1.7.5\")\n set(ZSTD_VERSION \"1.2.0\")\n+set(PROTOBUF_VERSION \"2.6.0\")\n set(GRPC_VERSION \"94582910ad7f82ad447ecc72e6548cb669e4f7a9\") # v1.6.5\n+set(ORC_VERSION \"cf00b67795717ab3eb04e950780ed6d104109017\")\n \n Review comment:\n   Needs a version of trunk (needed a bunch of fixes to their build system). This was master when I started this PR, but could probably update to master again.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:33:59.666+0000",
                    "updated": "2017-12-18T23:33:59.666+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295860",
                    "id": "16295860",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157630068\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n \n Review comment:\n   In the future we might want to have other classes (column statistics, writer, etc...) as such, I think having an `orc` namespace would be nice to group things instead of just putting these in `adapters`. Could remove the `ORC` prefix from the classes though if you'd prefer.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:35:11.502+0000",
                    "updated": "2017-12-18T23:35:11.502+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295862",
                    "id": "16295862",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157630348\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n \n Review comment:\n   I think so? There isn't a good thorough document afaict describing the ORC format. From reading the code and the example files, it looks like utf8 is common. VARCHAR and STRING are human readable, just not sure about common codec.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:37:03.320+0000",
                    "updated": "2017-12-18T23:37:03.320+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295864",
                    "id": "16295864",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157630505\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n \n Review comment:\n   No, and the resolution is higher than that arrow supports (one int64 for seconds since the epoch, one for nanoseconds in that second).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:38:10.695+0000",
                    "updated": "2017-12-18T23:38:10.695+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295866",
                    "id": "16295866",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157630599\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n \n Review comment:\n   Maybe? A schema would need to be recreated on read if there are column filters, but for the top-level file this could be done once and cached.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:38:53.475+0000",
                    "updated": "2017-12-18T23:38:53.475+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295871",
                    "id": "16295871",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157630773\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n \n Review comment:\n   This method requires access to `reader_` (to get the metadata), so needs to be a method on the class and can't be a static method. I've left it as is, can you explain a bit more about why this should be in an anonymous namespace? Still trying to pick up good C++ practices.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:40:11.933+0000",
                    "updated": "2017-12-18T23:40:11.933+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295873",
                    "id": "16295873",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157630903\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n \n Review comment:\n   Yeah. When filtering columns `liborc` will leave non-read nodes as `nullptr` in the tree. I've added a comment making note of this.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:41:02.571+0000",
                    "updated": "2017-12-18T23:41:02.571+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295874",
                    "id": "16295874",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157630967\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n+                      liborc::ColumnVectorBatch* batch, int64_t offset, int64_t length) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return append_struct_batch(type, builder, batch, offset, length);\n+      case liborc::LIST:\n+        return append_list_batch(type, builder, batch, offset, length);\n+      case liborc::MAP:\n+        return append_map_batch(type, builder, batch, offset, length);\n+      case liborc::LONG:\n+        return append_numeric_batch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            builder, batch, offset, length);\n+      case liborc::INT:\n+        return append_numeric_batch_cast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::SHORT:\n+        return append_numeric_batch_cast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::BYTE:\n+        return append_numeric_batch_cast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                         int64_t>(builder, batch, offset, length);\n+      case liborc::DOUBLE:\n+        return append_numeric_batch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            builder, batch, offset, length);\n+      case liborc::FLOAT:\n+        return append_numeric_batch_cast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                         double>(builder, batch, offset, length);\n+      case liborc::BOOLEAN:\n+        return append_bool_batch(builder, batch, offset, length);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return append_binary_batch<StringBuilder>(builder, batch, offset, length);\n+      case liborc::BINARY:\n+        return append_binary_batch<BinaryBuilder>(builder, batch, offset, length);\n+      case liborc::CHAR:\n+        return append_fixed_binary_batch(builder, batch, offset, length);\n+      case liborc::DATE:\n+        return append_date_batch(builder, batch, offset, length);\n+      case liborc::TIMESTAMP:\n+        return append_timestamp_batch(builder, batch, offset, length);\n+      case liborc::DECIMAL:\n+        return append_decimal_batch(type, builder, batch, offset, length);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status append_struct_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                             liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                             int64_t length) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    int n_fields = builder->num_fields();\n+    for (int i = 0; i < n_fields; i++) {\n+      RETURN_NOT_OK(append_batch(type->getSubtype(i), builder->field_builder(i),\n+                                 batch->fields[i], offset, length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_list_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                           liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!batch->hasNulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(append_batch(elemtype, builder->value_builder(), elements, start,\n+                                   end - start));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_map_batch(const liborc::Type* type, ArrayBuilder* abuilder,\n+                          liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                          int64_t length) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!batch->hasNulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(append_batch(keytype, struct_builder->field_builder(0), keys, start,\n+                                   list_length));\n+        RETURN_NOT_OK(append_batch(valtype, struct_builder->field_builder(1), vals, start,\n+                                   list_length));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status append_numeric_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                              int64_t offset, int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status append_numeric_batch_cast(ArrayBuilder* abuilder,\n+                                   liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                   int64_t length) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = (target_type)source[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_bool_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_timestamp_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                                int64_t offset, int64_t length) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = seconds[i] * int64_t(1e9) + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status append_date_batch(ArrayBuilder* abuilder, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length) {\n+    auto builder = static_cast<Date64Builder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      target[start + i] = source[i] * 24 * 60 * 60 * 1000;\n \n Review comment:\n   Good point, switched to date32.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:41:21.903+0000",
                    "updated": "2017-12-18T23:41:21.903+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295880",
                    "id": "16295880",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-352593834\n \n \n   Thanks for the review. I believe all comments have been addressed/questioned.\r\n   \r\n   > It seems like a C++ ORC writer has been happening only recently in the apache/orc repo, what is the status of that?\r\n   \r\n   I'm not sure, haven't tried it. From looking at the code it looks like it wouldn't be too hard to implement. However, it can only write HIVE 0.11 format, which is rather old (2013!) and doesn't support decimals with precision/scale. As such, I think for now your second option might be better. Can you point me to an example using this style of test?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:44:39.681+0000",
                    "updated": "2017-12-18T23:44:39.681+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295885",
                    "id": "16295885",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157631664\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, NumberOfRows(), out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::list<uint64_t>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(select_stripe(&opts, stripe));\n+    opts.includeTypes(include_indices);\n+    return read_batch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status select_stripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status read_batch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(type_to_schema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    auto struct_batch = static_cast<liborc::StructVectorBatch*>(batch.get());\n+\n+    int n_fields = builder->num_fields();\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < n_fields; i++) {\n+        RETURN_NOT_OK(append_batch(type.getSubtype(i), builder->GetField(i),\n+                                   struct_batch->fields[i], 0, batch->numElements));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status append_batch(const liborc::Type* type, ArrayBuilder* builder,\n \n Review comment:\n   The ORC api also returns pointers for `ColumnVectorBatch` objects, so I've left those as pointers as well.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:45:59.146+0000",
                    "updated": "2017-12-18T23:45:59.146+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16295886",
                    "id": "16295886",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157631773\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   @wesm, @cpcloud any strong thoughts on this ^^?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-18T23:46:43.330+0000",
                    "updated": "2017-12-18T23:46:43.330+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16296110",
                    "id": "16296110",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157656729\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.cc\n ##########\n @@ -0,0 +1,699 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status get_dtype(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date64();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(get_dtype(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(get_dtype(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back((uint8_t)child);\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  explicit Impl(MemoryPool* pool, std::unique_ptr<liborc::Reader> reader)\n+      : pool_(pool), reader_(std::move(reader)) {}\n+\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<Impl>* impl) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    impl->reset(new Impl(pool, std::move(liborc_reader)));\n+    RETURN_NOT_OK((*impl)->Init());\n+\n+    return Status::OK();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return type_to_schema(type, out);\n+  }\n+\n+  Status type_to_schema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n \n Review comment:\n   Sorry, I missed that this was an instance method, so that's all good\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-19T03:21:02.524+0000",
                    "updated": "2017-12-19T03:21:02.524+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16296160",
                    "id": "16296160",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r157660029\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   The problem with this is that if there is a string column with a lot of very large strings, you could overrun the capacity of `arrow::BinaryArray` -- so it would be better to yield a Table even if all the columns are not chunked\r\n   \r\n   I missed this in my review, but it would be better to use `std::vector<int>` here, a bit more consistent with the Parquet reader\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-19T03:59:54.621+0000",
                    "updated": "2017-12-19T03:59:54.621+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16302663",
                    "id": "16302663",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r158593428\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   Ok, I've changed the `Read` method to return a table composed of one record batch per stripe. I'm not sure if this is the best api - could also see returning a table composed of fixed-length record batches given a user proved batch-size (which would be equally efficient, since we have to copy the data either way).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-24T04:35:09.621+0000",
                    "updated": "2017-12-24T04:35:09.621+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16302665",
                    "id": "16302665",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r158593446\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   > I missed this in my review, but it would be better to use std::vector<int> here, a bit more consistent with the Parquet reader\r\n   \r\n   Done. One question I have now is when to use `int64_t` and when to just use `int`. Right now the user facing api uses a mix, which seems off. Not sure what the best practice is here, I see both used in the arrow codebase.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-24T04:37:38.767+0000",
                    "updated": "2017-12-24T04:37:38.767+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16302666",
                    "id": "16302666",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-353765053\n \n \n   Right now I think the todo list is (minus more code quality review from others):\r\n   \r\n   - [ ] Figure out a testing strategy and add tests (ping @wesm for thoughts on this, see my comment above)\r\n   - [ ] Fix the `manylinux1` build (ping @xhochy for instructions/a PR here)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-24T04:39:55.751+0000",
                    "updated": "2017-12-24T04:39:55.751+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16306941",
                    "id": "16306941",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-354568148\n \n \n   Sorry for the delay. I think we can merge this without the manylinux1 build and without tests, so we can just disable in the manylinux1 build script for now.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-30T21:01:40.203+0000",
                    "updated": "2017-12-30T21:01:40.203+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16306967",
                    "id": "16306967",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-354570725\n \n \n   @wesm please wait. I hope to send the PR for the manylinux1 fix this year. Seems trivial but build is still running locally ;)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-30T21:59:34.828+0000",
                    "updated": "2017-12-30T21:59:34.828+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16306973",
                    "id": "16306973",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-354570998\n \n \n   Here it is: https://github.com/jcrist/arrow/pull/1\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-12-30T22:05:51.851+0000",
                    "updated": "2017-12-30T22:05:51.851+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16310212",
                    "id": "16310212",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-353765053\n \n \n   Right now I think the todo list is (minus more code quality review from others):\r\n   \r\n   - [ ] Figure out a testing strategy and add tests (ping @wesm for thoughts on this, see my comment above)\r\n   - [x] Fix the `manylinux1` build (ping @xhochy for instructions/a PR here)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-01-03T20:00:49.574+0000",
                    "updated": "2018-01-03T20:00:49.574+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16310310",
                    "id": "16310310",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on a change in pull request #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#discussion_r159533357\n \n \n\n ##########\n File path: cpp/src/arrow/adapters/orc/adapter.h\n ##########\n @@ -0,0 +1,65 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+  Status Read(std::shared_ptr<RecordBatch>* out);\n+  Status Read(const std::list<uint64_t>& include_indices,\n+              std::shared_ptr<RecordBatch>* out);\n \n Review comment:\n   ^^^ Any response to this?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-01-03T21:32:22.485+0000",
                    "updated": "2018-01-03T21:32:22.485+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16310314",
                    "id": "16310314",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jcrist commented on issue #1418: ARROW-1920 [C++/Python] Add ORC Reader\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-355133548\n \n \n   > Sorry for the delay. I think we can merge this without the manylinux1 build and without tests, so we can just disable in the manylinux1 build script for now.\r\n   \r\n   Besides an unrelated (I think?) failure, this now passes all tests.\r\n   \r\n   I'm a little worried about merging it without tests, but if you're fine with that I can make a subsequent PR once a testing strategy has been decided.\r\n   \r\n   Thanks all for the review here, this has been a good learning experience.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-01-03T21:33:31.988+0000",
                    "updated": "2018-01-03T21:33:31.988+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16311455",
                    "id": "16311455",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 1418\n[https://github.com/apache/arrow/pull/1418]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-01-04T15:11:21.448+0000",
                    "updated": "2018-01-04T15:11:21.448+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16311456",
                    "id": "16311456",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm closed pull request #1418: ARROW-1920 [C++/Python] Add experimental reader for Apache ORC files\nURL: https://github.com/apache/arrow/pull/1418\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/ci/travis_script_python.sh b/ci/travis_script_python.sh\nindex 5f7b0a9a1..444386fdf 100755\n--- a/ci/travis_script_python.sh\n+++ b/ci/travis_script_python.sh\n@@ -82,7 +82,7 @@ fi\n export PYARROW_BUILD_TYPE=$ARROW_BUILD_TYPE\n \n pip install -r requirements.txt\n-python setup.py build_ext --with-parquet --with-plasma \\\n+python setup.py build_ext --with-parquet --with-plasma --with-orc\\\n        install --single-version-externally-managed --record=record.text\n popd\n \ndiff --git a/cpp/CMakeLists.txt b/cpp/CMakeLists.txt\nindex dd159ced2..ede13af5d 100644\n--- a/cpp/CMakeLists.txt\n+++ b/cpp/CMakeLists.txt\n@@ -119,6 +119,10 @@ if(\"${CMAKE_SOURCE_DIR}\" STREQUAL \"${CMAKE_CURRENT_SOURCE_DIR}\")\n     \"Build the Arrow GPU extensions (requires CUDA installation)\"\n     OFF)\n \n+  option(ARROW_ORC\n+    \"Build the Arrow ORC adapter\"\n+    ON)\n+\n   option(ARROW_JEMALLOC\n     \"Build the Arrow jemalloc-based allocator\"\n     OFF)\n@@ -226,6 +230,17 @@ if(ARROW_BUILD_TESTS OR ARROW_BUILD_BENCHMARKS)\n   set(ARROW_WITH_ZSTD ON)\n endif()\n \n+if (MSVC)\n+  # ORC doesn't build on windows\n+  set(ARROW_ORC OFF)\n+endif()\n+\n+if(ARROW_ORC)\n+  set(ARROW_WITH_LZ4 ON)\n+  set(ARROW_WITH_SNAPPY ON)\n+  set(ARROW_WITH_ZLIB ON)\n+endif()\n+\n if(NOT ARROW_BUILD_TESTS)\n   set(NO_TESTS 1)\n endif()\n@@ -526,6 +541,13 @@ if (ARROW_WITH_GRPC)\n     ${ARROW_STATIC_LINK_LIBS})\n endif()\n \n+if (ARROW_ORC)\n+  SET(ARROW_STATIC_LINK_LIBS\n+    orc\n+    protobuf\n+    ${ARROW_STATIC_LINK_LIBS})\n+endif()\n+\n if (ARROW_STATIC_LINK_LIBS)\n   add_dependencies(arrow_dependencies ${ARROW_STATIC_LINK_LIBS})\n endif()\ndiff --git a/cpp/cmake_modules/FindProtobuf.cmake b/cpp/cmake_modules/FindProtobuf.cmake\nnew file mode 100644\nindex 000000000..a42f4493a\n--- /dev/null\n+++ b/cpp/cmake_modules/FindProtobuf.cmake\n@@ -0,0 +1,89 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# PROTOBUF_HOME environmental variable is used to check for Protobuf headers and static library\n+\n+# PROTOBUF_INCLUDE_DIR: directory containing headers\n+# PROTOBUF_LIBS: directory containing Protobuf libraries\n+# PROTOBUF_STATIC_LIB: location of protobuf.a\n+# PROTOC_STATIC_LIB: location of protoc.a\n+# PROTOBUF_EXECUTABLE: location of protoc\n+# PROTOBUF_FOUND is set if Protobuf is found\n+\n+\n+if( NOT \"${PROTOBUF_HOME}\" STREQUAL \"\")\n+    file (TO_CMAKE_PATH \"${PROTOBUF_HOME}\" _protobuf_path)\n+endif()\n+\n+message (STATUS \"PROTOBUF_HOME: ${PROTOBUF_HOME}\")\n+\n+find_path (PROTOBUF_INCLUDE_DIR google/protobuf/io/zero_copy_stream.h HINTS\n+  ${_protobuf_path}\n+  NO_DEFAULT_PATH\n+  PATH_SUFFIXES \"include\")\n+\n+find_path (PROTOBUF_INCLUDE_DIR google/protobuf/io/coded_stream.h HINTS\n+  ${_protobuf_path}\n+  NO_DEFAULT_PATH\n+  PATH_SUFFIXES \"include\")\n+\n+find_library (PROTOBUF_LIBRARY NAMES protobuf PATHS\n+  ${_protobuf_path}\n+  NO_DEFAULT_PATH\n+  PATH_SUFFIXES \"lib\")\n+\n+find_library (PROTOC_LIBRARY NAMES protoc PATHS\n+  ${_protobuf_path}\n+  NO_DEFAULT_PATH\n+  PATH_SUFFIXES \"lib\")\n+\n+find_program(PROTOBUF_EXECUTABLE protoc HINTS\n+  ${_protobuf_path}\n+  NO_DEFAULT_PATH\n+  PATH_SUFFIXES \"bin\")\n+\n+if (PROTOBUF_INCLUDE_DIR AND PROTOBUF_LIBRARY AND PROTOC_LIBRARY AND PROTOBUF_EXECUTABLE)\n+  set (PROTOBUF_FOUND TRUE)\n+  get_filename_component (PROTOBUF_LIBS ${PROTOBUF_LIBRARY} PATH)\n+  set (PROTOBUF_LIB_NAME protobuf)\n+  set (PROTOC_LIB_NAME protoc)\n+  set (PROTOBUF_STATIC_LIB ${PROTOBUF_LIBS}/${CMAKE_STATIC_LIBRARY_PREFIX}${PROTOBUF_LIB_NAME}${CMAKE_STATIC_LIBRARY_SUFFIX})\n+  set (PROTOC_STATIC_LIB ${PROTOBUF_LIBS}/${CMAKE_STATIC_LIBRARY_PREFIX}${PROTOC_LIB_NAME}${CMAKE_STATIC_LIBRARY_SUFFIX})\n+else ()\n+  set (PROTOBUF_FOUND FALSE)\n+endif ()\n+\n+if (PROTOBUF_FOUND)\n+  message (STATUS \"Found the Protobuf headers: ${PROTOBUF_INCLUDE_DIR}\")\n+  message (STATUS \"Found the Protobuf library: ${PROTOBUF_STATIC_LIB}\")\n+  message (STATUS \"Found the Protoc library: ${PROTOC_STATIC_LIB}\")\n+  message (STATUS \"Found the Protoc executable: ${PROTOBUF_EXECUTABLE}\")\n+else()\n+  if (_protobuf_path)\n+    set (PROTOBUF_ERR_MSG \"Could not find Protobuf. Looked in ${_protobuf_path}.\")\n+  else ()\n+    set (PROTOBUF_ERR_MSG \"Could not find Protobuf in system search paths.\")\n+  endif()\n+\n+  if (Protobuf_FIND_REQUIRED)\n+    message (FATAL_ERROR \"${PROTOBUF_ERR_MSG}\")\n+  else ()\n+    message (STATUS \"${PROTOBUF_ERR_MSG}\")\n+  endif ()\n+endif()\n+\n+mark_as_advanced (\n+  PROTOBUF_INCLUDE_DIR\n+  PROTOBUF_LIBS\n+  PROTOBUF_STATIC_LIB\n+  PROTOC_STATIC_LIB\n+)\ndiff --git a/cpp/cmake_modules/ThirdpartyToolchain.cmake b/cpp/cmake_modules/ThirdpartyToolchain.cmake\nindex b706aab45..4f6443417 100644\n--- a/cpp/cmake_modules/ThirdpartyToolchain.cmake\n+++ b/cpp/cmake_modules/ThirdpartyToolchain.cmake\n@@ -29,7 +29,9 @@ set(SNAPPY_VERSION \"1.1.3\")\n set(BROTLI_VERSION \"v0.6.0\")\n set(LZ4_VERSION \"1.7.5\")\n set(ZSTD_VERSION \"1.2.0\")\n+set(PROTOBUF_VERSION \"2.6.0\")\n set(GRPC_VERSION \"94582910ad7f82ad447ecc72e6548cb669e4f7a9\") # v1.6.5\n+set(ORC_VERSION \"cf00b67795717ab3eb04e950780ed6d104109017\")\n \n string(TOUPPER ${CMAKE_BUILD_TYPE} UPPERCASE_BUILD_TYPE)\n \n@@ -721,6 +723,7 @@ if (ARROW_WITH_LZ4)\n \n   if(\"${LZ4_HOME}\" STREQUAL \"\")\n     set(LZ4_BUILD_DIR \"${CMAKE_CURRENT_BINARY_DIR}/lz4_ep-prefix/src/lz4_ep\")\n+    set(LZ4_HOME \"${LZ4_BUILD_DIR}\")\n     set(LZ4_INCLUDE_DIR \"${LZ4_BUILD_DIR}/lib\")\n \n     if (MSVC)\n@@ -865,3 +868,73 @@ if (ARROW_WITH_GRPC)\n   endif()\n \n endif()\n+\n+if (ARROW_ORC)\n+  # protobuf\n+  if (\"${PROTOBUF_HOME}\" STREQUAL \"\")\n+    set (PROTOBUF_PREFIX \"${THIRDPARTY_DIR}/protobuf_ep-install\")\n+    set (PROTOBUF_HOME \"${PROTOBUF_PREFIX}\")\n+    set (PROTOBUF_INCLUDE_DIR \"${PROTOBUF_PREFIX}/include\")\n+    set (PROTOBUF_STATIC_LIB \"${PROTOBUF_PREFIX}/lib/${CMAKE_STATIC_LIBRARY_PREFIX}protobuf${CMAKE_STATIC_LIBRARY_SUFFIX}\")\n+    set (PROTOBUF_SRC_URL \"https://github.com/google/protobuf/releases/download/v${PROTOBUF_VERSION}/protobuf-${PROTOBUF_VERSION}.tar.gz\")\n+\n+    ExternalProject_Add(protobuf_ep\n+      CONFIGURE_COMMAND \"./configure\" \"--disable-shared\" \"--prefix=${PROTOBUF_PREFIX}\" \"CXXFLAGS=${EP_CXX_FLAGS}\"\n+      BUILD_IN_SOURCE 1\n+      URL ${PROTOBUF_SRC_URL}\n+      LOG_DOWNLOAD 1\n+      LOG_CONFIGURE 1\n+      LOG_BUILD 1\n+      LOG_INSTALL 1\n+      BUILD_BYPRODUCTS \"${PROTOBUF_STATIC_LIB}\")\n+\n+    set (PROTOBUF_VENDORED 1)\n+  else ()\n+    find_package (Protobuf REQUIRED)\n+    set (PROTOBUF_VENDORED 0)\n+  endif ()\n+\n+  include_directories (SYSTEM ${PROTOBUF_INCLUDE_DIR})\n+  ADD_THIRDPARTY_LIB(protobuf\n+    STATIC_LIB ${PROTOBUF_STATIC_LIB})\n+\n+  if (PROTOBUF_VENDORED)\n+    add_dependencies (protobuf protobuf_ep)\n+  endif ()\n+\n+  # orc\n+  set(ORC_PREFIX \"${CMAKE_CURRENT_BINARY_DIR}/orc_ep-install\")\n+  set(ORC_HOME \"${ORC_PREFIX}\")\n+  set(ORC_INCLUDE_DIR \"${ORC_PREFIX}/include\")\n+  set(ORC_STATIC_LIB \"${ORC_PREFIX}/lib/${CMAKE_STATIC_LIBRARY_PREFIX}orc${CMAKE_STATIC_LIBRARY_SUFFIX}\")\n+\n+  # Since LZ4 isn't installed, the header file is in ${LZ4_HOME}/lib instead of\n+  # ${LZ4_HOME}/include, which forces us to specify the include directory\n+  # manually as well.\n+  set (ORC_CMAKE_ARGS -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}\n+                      -DCMAKE_INSTALL_PREFIX=${ORC_PREFIX}\n+                      -DCMAKE_CXX_FLAGS=${EP_CXX_FLAGS}\n+                      -DBUILD_LIBHDFSPP=OFF\n+                      -DBUILD_JAVA=OFF\n+                      -DBUILD_TOOLS=OFF\n+                      -DBUILD_CPP_TESTS=OFF\n+                      -DINSTALL_VENDORED_LIBS=OFF\n+                      -DPROTOBUF_HOME=${PROTOBUF_HOME}\n+                      -DLZ4_HOME=${LZ4_HOME}\n+                      -DLZ4_INCLUDE_DIR=${LZ4_INCLUDE_DIR}\n+                      -DSNAPPY_HOME=${SNAPPY_HOME}\n+                      -DZLIB_HOME=${ZLIB_HOME})\n+\n+  ExternalProject_Add(orc_ep\n+    GIT_REPOSITORY \"https://github.com/apache/orc\"\n+    GIT_TAG ${ORC_VERSION}\n+    BUILD_BYPRODUCTS ${ORC_STATIC_LIB}\n+    CMAKE_ARGS ${ORC_CMAKE_ARGS})\n+\n+  include_directories(SYSTEM ${ORC_INCLUDE_DIR})\n+  ADD_THIRDPARTY_LIB(orc\n+    STATIC_LIB ${ORC_STATIC_LIB})\n+\n+  add_dependencies(orc_ep protobuf lz4_static snappy zlib)\n+  add_dependencies(orc orc_ep)\n+endif()\ndiff --git a/cpp/src/arrow/CMakeLists.txt b/cpp/src/arrow/CMakeLists.txt\nindex d645cca22..ad86256e0 100644\n--- a/cpp/src/arrow/CMakeLists.txt\n+++ b/cpp/src/arrow/CMakeLists.txt\n@@ -90,6 +90,11 @@ if (ARROW_WITH_ZSTD)\n   SET(ARROW_SRCS util/compression_zstd.cc ${ARROW_SRCS})\n endif()\n \n+if (ARROW_ORC)\n+  add_subdirectory(adapters/orc)\n+  SET(ARROW_SRCS adapters/orc/adapter.cc ${ARROW_SRCS})\n+endif()\n+\n if (NOT ARROW_BOOST_HEADER_ONLY)\n   set(ARROW_SRCS ${ARROW_SRCS}\n     io/hdfs.cc\ndiff --git a/cpp/src/arrow/adapters/orc/CMakeLists.txt b/cpp/src/arrow/adapters/orc/CMakeLists.txt\nnew file mode 100644\nindex 000000000..eb7194cd4\n--- /dev/null\n+++ b/cpp/src/arrow/adapters/orc/CMakeLists.txt\n@@ -0,0 +1,25 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+#######################################\n+# arrow_orc\n+#######################################\n+\n+# Headers: top level\n+install(FILES\n+        adapter.h\n+        DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/arrow/adapters/orc\")\ndiff --git a/cpp/src/arrow/adapters/orc/adapter.cc b/cpp/src/arrow/adapters/orc/adapter.cc\nnew file mode 100644\nindex 000000000..473c90f92\n--- /dev/null\n+++ b/cpp/src/arrow/adapters/orc/adapter.cc\n@@ -0,0 +1,697 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/adapters/orc/adapter.h\"\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <list>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/builder.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/table_builder.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit-util.h\"\n+#include \"arrow/util/decimal.h\"\n+#include \"arrow/util/macros.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+#include \"orc/OrcFile.hh\"\n+\n+// alias to not interfere with nested orc namespace\n+namespace liborc = orc;\n+\n+namespace arrow {\n+namespace adapters {\n+namespace orc {\n+\n+#define ORC_THROW_NOT_OK(s)                   \\\n+  do {                                        \\\n+    Status _s = (s);                          \\\n+    if (!_s.ok()) {                           \\\n+      std::stringstream ss;                   \\\n+      ss << \"Arrow error: \" << _s.ToString(); \\\n+      throw liborc::ParseError(ss.str());     \\\n+    }                                         \\\n+  } while (0)\n+\n+class ArrowInputFile : public liborc::InputStream {\n+ public:\n+  explicit ArrowInputFile(const std::shared_ptr<io::ReadableFileInterface>& file)\n+      : file_(file) {}\n+\n+  uint64_t getLength() const override {\n+    int64_t size;\n+    ORC_THROW_NOT_OK(file_->GetSize(&size));\n+    return static_cast<uint64_t>(size);\n+  }\n+\n+  uint64_t getNaturalReadSize() const override { return 128 * 1024; }\n+\n+  void read(void* buf, uint64_t length, uint64_t offset) override {\n+    int64_t bytes_read;\n+\n+    ORC_THROW_NOT_OK(file_->ReadAt(offset, length, &bytes_read, buf));\n+\n+    if (static_cast<uint64_t>(bytes_read) != length) {\n+      throw liborc::ParseError(\"Short read from arrow input file\");\n+    }\n+  }\n+\n+  const std::string& getName() const override {\n+    static const std::string filename(\"ArrowInputFile\");\n+    return filename;\n+  }\n+\n+ private:\n+  std::shared_ptr<io::ReadableFileInterface> file_;\n+};\n+\n+struct StripeInformation {\n+  uint64_t offset;\n+  uint64_t length;\n+  uint64_t num_rows;\n+};\n+\n+Status GetArrowType(const liborc::Type* type, std::shared_ptr<DataType>* out) {\n+  // When subselecting fields on read, liborc will set some nodes to nullptr,\n+  // so we need to check for nullptr before progressing\n+  if (type == nullptr) {\n+    *out = null();\n+    return Status::OK();\n+  }\n+  liborc::TypeKind kind = type->getKind();\n+  switch (kind) {\n+    case liborc::BOOLEAN:\n+      *out = boolean();\n+      break;\n+    case liborc::BYTE:\n+      *out = int8();\n+      break;\n+    case liborc::SHORT:\n+      *out = int16();\n+      break;\n+    case liborc::INT:\n+      *out = int32();\n+      break;\n+    case liborc::LONG:\n+      *out = int64();\n+      break;\n+    case liborc::FLOAT:\n+      *out = float32();\n+      break;\n+    case liborc::DOUBLE:\n+      *out = float64();\n+      break;\n+    case liborc::VARCHAR:\n+    case liborc::STRING:\n+      *out = utf8();\n+      break;\n+    case liborc::BINARY:\n+      *out = binary();\n+      break;\n+    case liborc::CHAR:\n+      *out = fixed_size_binary(type->getMaximumLength());\n+      break;\n+    case liborc::TIMESTAMP:\n+      *out = timestamp(TimeUnit::NANO);\n+      break;\n+    case liborc::DATE:\n+      *out = date32();\n+      break;\n+    case liborc::DECIMAL: {\n+      if (type->getPrecision() == 0) {\n+        // In HIVE 0.11/0.12 precision is set as 0, but means max precision\n+        *out = decimal(38, 6);\n+      } else {\n+        *out = decimal(type->getPrecision(), type->getScale());\n+      }\n+      break;\n+    }\n+    case liborc::LIST: {\n+      if (type->getSubtypeCount() != 1) {\n+        return Status::Invalid(\"Invalid Orc List type\");\n+      }\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(GetArrowType(type->getSubtype(0), &elemtype));\n+      *out = list(elemtype);\n+      break;\n+    }\n+    case liborc::MAP: {\n+      if (type->getSubtypeCount() != 2) {\n+        return Status::Invalid(\"Invalid Orc Map type\");\n+      }\n+      std::shared_ptr<DataType> keytype;\n+      std::shared_ptr<DataType> valtype;\n+      RETURN_NOT_OK(GetArrowType(type->getSubtype(0), &keytype));\n+      RETURN_NOT_OK(GetArrowType(type->getSubtype(1), &valtype));\n+      *out = list(struct_({field(\"key\", keytype), field(\"value\", valtype)}));\n+      break;\n+    }\n+    case liborc::STRUCT: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(GetArrowType(type->getSubtype(child), &elemtype));\n+        std::string name = type->getFieldName(child);\n+        fields.push_back(field(name, elemtype));\n+      }\n+      *out = struct_(fields);\n+      break;\n+    }\n+    case liborc::UNION: {\n+      int size = type->getSubtypeCount();\n+      std::vector<std::shared_ptr<Field>> fields;\n+      std::vector<uint8_t> type_codes;\n+      for (int child = 0; child < size; ++child) {\n+        std::shared_ptr<DataType> elemtype;\n+        RETURN_NOT_OK(GetArrowType(type->getSubtype(child), &elemtype));\n+        fields.push_back(field(\"_union_\" + std::to_string(child), elemtype));\n+        type_codes.push_back(static_cast<uint8_t>(child));\n+      }\n+      *out = union_(fields, type_codes);\n+      break;\n+    }\n+    default: {\n+      std::stringstream ss;\n+      ss << \"Unknown Orc type kind: \" << kind;\n+      return Status::Invalid(ss.str());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+// The number of rows to read in a ColumnVectorBatch\n+constexpr int64_t kReadRowsBatch = 1000;\n+\n+// The numer of nanoseconds in a second\n+constexpr int64_t kOneSecondNanos = 1000000000LL;\n+\n+class ORCFileReader::Impl {\n+ public:\n+  Impl() {}\n+  ~Impl() {}\n+\n+  Status Open(const std::shared_ptr<io::ReadableFileInterface>& file, MemoryPool* pool) {\n+    std::unique_ptr<ArrowInputFile> io_wrapper(new ArrowInputFile(file));\n+    liborc::ReaderOptions options;\n+    std::unique_ptr<liborc::Reader> liborc_reader;\n+    try {\n+      liborc_reader = createReader(std::move(io_wrapper), options);\n+    } catch (const liborc::ParseError& e) {\n+      return Status::IOError(e.what());\n+    }\n+    pool_ = pool;\n+    reader_ = std::move(liborc_reader);\n+\n+    return Init();\n+  }\n+\n+  Status Init() {\n+    int64_t nstripes = reader_->getNumberOfStripes();\n+    stripes_.resize(nstripes);\n+    std::unique_ptr<liborc::StripeInformation> stripe;\n+    for (int i = 0; i < nstripes; ++i) {\n+      stripe = reader_->getStripe(i);\n+      stripes_[i] = StripeInformation(\n+          {stripe->getOffset(), stripe->getLength(), stripe->getNumberOfRows()});\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t NumberOfStripes() { return stripes_.size(); }\n+\n+  int64_t NumberOfRows() { return reader_->getNumberOfRows(); }\n+\n+  Status ReadSchema(std::shared_ptr<Schema>* out) {\n+    const liborc::Type& type = reader_->getType();\n+    return GetArrowSchema(type, out);\n+  }\n+\n+  Status GetArrowSchema(const liborc::Type& type, std::shared_ptr<Schema>* out) {\n+    if (type.getKind() != liborc::STRUCT) {\n+      return Status::NotImplemented(\n+          \"Only ORC files with a top-level struct \"\n+          \"can be handled\");\n+    }\n+    int size = type.getSubtypeCount();\n+    std::vector<std::shared_ptr<Field>> fields;\n+    for (int child = 0; child < size; ++child) {\n+      std::shared_ptr<DataType> elemtype;\n+      RETURN_NOT_OK(GetArrowType(type.getSubtype(child), &elemtype));\n+      std::string name = type.getFieldName(child);\n+      fields.push_back(field(name, elemtype));\n+    }\n+    std::list<std::string> keys = reader_->getMetadataKeys();\n+    std::shared_ptr<KeyValueMetadata> metadata;\n+    if (!keys.empty()) {\n+      metadata = std::make_shared<KeyValueMetadata>();\n+      for (auto it = keys.begin(); it != keys.end(); ++it) {\n+        metadata->Append(*it, reader_->getMetadataValue(*it));\n+      }\n+    }\n+\n+    *out = std::make_shared<Schema>(fields, metadata);\n+    return Status::OK();\n+  }\n+\n+  Status Read(std::shared_ptr<Table>* out) {\n+    liborc::RowReaderOptions opts;\n+    return ReadTable(opts, out);\n+  }\n+\n+  Status Read(const std::vector<int>& include_indices, std::shared_ptr<Table>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(SelectIndices(&opts, include_indices));\n+    return ReadTable(opts, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(SelectStripe(&opts, stripe));\n+    return ReadBatch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status ReadStripe(int64_t stripe, const std::vector<int>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out) {\n+    liborc::RowReaderOptions opts;\n+    RETURN_NOT_OK(SelectIndices(&opts, include_indices));\n+    RETURN_NOT_OK(SelectStripe(&opts, stripe));\n+    return ReadBatch(opts, stripes_[stripe].num_rows, out);\n+  }\n+\n+  Status SelectStripe(liborc::RowReaderOptions* opts, int64_t stripe) {\n+    if (stripe < 0 || stripe >= NumberOfStripes()) {\n+      std::stringstream ss;\n+      ss << \"Out of bounds stripe: \" << stripe;\n+      return Status::Invalid(ss.str());\n+    }\n+    opts->range(stripes_[stripe].offset, stripes_[stripe].length);\n+    return Status::OK();\n+  }\n+\n+  Status SelectIndices(liborc::RowReaderOptions* opts,\n+                       const std::vector<int>& include_indices) {\n+    std::list<uint64_t> include_indices_list;\n+    for (auto it = include_indices.begin(); it != include_indices.end(); ++it) {\n+      if (*it < 0) {\n+        return Status::Invalid(\"Negative field index\");\n+      }\n+      include_indices_list.push_back(*it);\n+    }\n+    opts->includeTypes(include_indices_list);\n+    return Status::OK();\n+  }\n+\n+  Status ReadTable(const liborc::RowReaderOptions& row_opts,\n+                   std::shared_ptr<Table>* out) {\n+    liborc::RowReaderOptions opts(row_opts);\n+    std::vector<std::shared_ptr<RecordBatch>> batches(stripes_.size());\n+    for (size_t stripe = 0; stripe < stripes_.size(); stripe++) {\n+      opts.range(stripes_[stripe].offset, stripes_[stripe].length);\n+      RETURN_NOT_OK(ReadBatch(opts, stripes_[stripe].num_rows, &batches[stripe]));\n+    }\n+    return Table::FromRecordBatches(batches, out);\n+  }\n+\n+  Status ReadBatch(const liborc::RowReaderOptions& opts, int64_t nrows,\n+                   std::shared_ptr<RecordBatch>* out) {\n+    std::unique_ptr<liborc::RowReader> rowreader;\n+    std::unique_ptr<liborc::ColumnVectorBatch> batch;\n+    try {\n+      rowreader = reader_->createRowReader(opts);\n+      batch = rowreader->createRowBatch(std::min(nrows, kReadRowsBatch));\n+    } catch (const liborc::ParseError& e) {\n+      return Status::Invalid(e.what());\n+    }\n+    const liborc::Type& type = rowreader->getSelectedType();\n+    std::shared_ptr<Schema> schema;\n+    RETURN_NOT_OK(GetArrowSchema(type, &schema));\n+\n+    std::unique_ptr<RecordBatchBuilder> builder;\n+    RETURN_NOT_OK(RecordBatchBuilder::Make(schema, pool_, nrows, &builder));\n+\n+    // The top-level type must be a struct to read into an arrow table\n+    const auto& struct_batch = static_cast<liborc::StructVectorBatch&>(*batch);\n+\n+    while (rowreader->next(*batch)) {\n+      for (int i = 0; i < builder->num_fields(); i++) {\n+        RETURN_NOT_OK(AppendBatch(type.getSubtype(i), struct_batch.fields[i], 0,\n+                                  batch->numElements, builder->GetField(i)));\n+      }\n+    }\n+    RETURN_NOT_OK(builder->Flush(out));\n+    return Status::OK();\n+  }\n+\n+  Status AppendBatch(const liborc::Type* type, liborc::ColumnVectorBatch* batch,\n+                     int64_t offset, int64_t length, ArrayBuilder* builder) {\n+    if (type == nullptr) {\n+      return Status::OK();\n+    }\n+    liborc::TypeKind kind = type->getKind();\n+    switch (kind) {\n+      case liborc::STRUCT:\n+        return AppendStructBatch(type, batch, offset, length, builder);\n+      case liborc::LIST:\n+        return AppendListBatch(type, batch, offset, length, builder);\n+      case liborc::MAP:\n+        return AppendMapBatch(type, batch, offset, length, builder);\n+      case liborc::LONG:\n+        return AppendNumericBatch<Int64Builder, liborc::LongVectorBatch, int64_t>(\n+            batch, offset, length, builder);\n+      case liborc::INT:\n+        return AppendNumericBatchCast<Int32Builder, int32_t, liborc::LongVectorBatch,\n+                                      int64_t>(batch, offset, length, builder);\n+      case liborc::SHORT:\n+        return AppendNumericBatchCast<Int16Builder, int16_t, liborc::LongVectorBatch,\n+                                      int64_t>(batch, offset, length, builder);\n+      case liborc::BYTE:\n+        return AppendNumericBatchCast<Int8Builder, int8_t, liborc::LongVectorBatch,\n+                                      int64_t>(batch, offset, length, builder);\n+      case liborc::DOUBLE:\n+        return AppendNumericBatch<DoubleBuilder, liborc::DoubleVectorBatch, double>(\n+            batch, offset, length, builder);\n+      case liborc::FLOAT:\n+        return AppendNumericBatchCast<FloatBuilder, float, liborc::DoubleVectorBatch,\n+                                      double>(batch, offset, length, builder);\n+      case liborc::BOOLEAN:\n+        return AppendBoolBatch(batch, offset, length, builder);\n+      case liborc::VARCHAR:\n+      case liborc::STRING:\n+        return AppendBinaryBatch<StringBuilder>(batch, offset, length, builder);\n+      case liborc::BINARY:\n+        return AppendBinaryBatch<BinaryBuilder>(batch, offset, length, builder);\n+      case liborc::CHAR:\n+        return AppendFixedBinaryBatch(batch, offset, length, builder);\n+      case liborc::DATE:\n+        return AppendNumericBatchCast<Date32Builder, int32_t, liborc::LongVectorBatch,\n+                                      int64_t>(batch, offset, length, builder);\n+      case liborc::TIMESTAMP:\n+        return AppendTimestampBatch(batch, offset, length, builder);\n+      case liborc::DECIMAL:\n+        return AppendDecimalBatch(type, batch, offset, length, builder);\n+      default:\n+        std::stringstream ss;\n+        ss << \"Not implemented type kind: \" << kind;\n+        return Status::NotImplemented(ss.str());\n+    }\n+  }\n+\n+  Status AppendStructBatch(const liborc::Type* type, liborc::ColumnVectorBatch* cbatch,\n+                           int64_t offset, int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<StructBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StructVectorBatch*>(cbatch);\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->Append(length, valid_bytes));\n+\n+    for (int i = 0; i < builder->num_fields(); i++) {\n+      RETURN_NOT_OK(AppendBatch(type->getSubtype(i), batch->fields[i], offset, length,\n+                                builder->field_builder(i)));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status AppendListBatch(const liborc::Type* type, liborc::ColumnVectorBatch* cbatch,\n+                         int64_t offset, int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<ListBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::ListVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* elements = batch->elements.get();\n+    const liborc::Type* elemtype = type->getSubtype(0);\n+\n+    const bool has_nulls = batch->hasNulls;\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!has_nulls || batch->notNull[i]) {\n+        int64_t start = batch->offsets[i];\n+        int64_t end = batch->offsets[i + 1];\n+        RETURN_NOT_OK(builder->Append());\n+        RETURN_NOT_OK(AppendBatch(elemtype, elements, start, end - start,\n+                                  builder->value_builder()));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status AppendMapBatch(const liborc::Type* type, liborc::ColumnVectorBatch* cbatch,\n+                        int64_t offset, int64_t length, ArrayBuilder* abuilder) {\n+    auto list_builder = static_cast<ListBuilder*>(abuilder);\n+    auto struct_builder = static_cast<StructBuilder*>(list_builder->value_builder());\n+    auto batch = static_cast<liborc::MapVectorBatch*>(cbatch);\n+    liborc::ColumnVectorBatch* keys = batch->keys.get();\n+    liborc::ColumnVectorBatch* vals = batch->elements.get();\n+    const liborc::Type* keytype = type->getSubtype(0);\n+    const liborc::Type* valtype = type->getSubtype(1);\n+\n+    const bool has_nulls = batch->hasNulls;\n+    for (int i = offset; i < length + offset; i++) {\n+      RETURN_NOT_OK(list_builder->Append());\n+      int64_t start = batch->offsets[i];\n+      int64_t list_length = batch->offsets[i + 1] - start;\n+      if (list_length && (!has_nulls || batch->notNull[i])) {\n+        RETURN_NOT_OK(struct_builder->Append(list_length, nullptr));\n+        RETURN_NOT_OK(AppendBatch(keytype, keys, start, list_length,\n+                                  struct_builder->field_builder(0)));\n+        RETURN_NOT_OK(AppendBatch(valtype, vals, start, list_length,\n+                                  struct_builder->field_builder(1)));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class batch_type, class elem_type>\n+  Status AppendNumericBatch(liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                            int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    const elem_type* source = batch->data.data() + offset;\n+    RETURN_NOT_OK(builder->Append(source, length, valid_bytes));\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type, class target_type, class batch_type, class source_type>\n+  Status AppendNumericBatchCast(liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<batch_type*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const source_type* source = batch->data.data() + offset;\n+    target_type* target = reinterpret_cast<target_type*>(builder->data()->mutable_data());\n+\n+    std::copy(source, source + length, target + start);\n+\n+    return Status::OK();\n+  }\n+\n+  Status AppendBoolBatch(liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                         int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<BooleanBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::LongVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* source = batch->data.data() + offset;\n+    uint8_t* target = reinterpret_cast<uint8_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      if (source[i]) {\n+        BitUtil::SetBit(target, start + i);\n+      } else {\n+        BitUtil::ClearBit(target, start + i);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status AppendTimestampBatch(liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                              int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<TimestampBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::TimestampVectorBatch*>(cbatch);\n+\n+    if (length == 0) {\n+      return Status::OK();\n+    }\n+    int start = builder->length();\n+\n+    const uint8_t* valid_bytes = nullptr;\n+    if (batch->hasNulls) {\n+      valid_bytes = reinterpret_cast<const uint8_t*>(batch->notNull.data()) + offset;\n+    }\n+    RETURN_NOT_OK(builder->AppendNulls(valid_bytes, length));\n+\n+    const int64_t* seconds = batch->data.data() + offset;\n+    const int64_t* nanos = batch->nanoseconds.data() + offset;\n+    int64_t* target = reinterpret_cast<int64_t*>(builder->data()->mutable_data());\n+\n+    for (int i = 0; i < length; i++) {\n+      // TODO: boundscheck this, as ORC supports higher resolution timestamps\n+      // than arrow for nanosecond resolution\n+      target[start + i] = seconds[i] * kOneSecondNanos + nanos[i];\n+    }\n+    return Status::OK();\n+  }\n+\n+  template <class builder_type>\n+  Status AppendBinaryBatch(liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                           int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<builder_type*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    const bool has_nulls = batch->hasNulls;\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!has_nulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i], batch->length[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status AppendFixedBinaryBatch(liborc::ColumnVectorBatch* cbatch, int64_t offset,\n+                                int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<FixedSizeBinaryBuilder*>(abuilder);\n+    auto batch = static_cast<liborc::StringVectorBatch*>(cbatch);\n+\n+    const bool has_nulls = batch->hasNulls;\n+    for (int i = offset; i < length + offset; i++) {\n+      if (!has_nulls || batch->notNull[i]) {\n+        RETURN_NOT_OK(builder->Append(batch->data[i]));\n+      } else {\n+        RETURN_NOT_OK(builder->AppendNull());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status AppendDecimalBatch(const liborc::Type* type, liborc::ColumnVectorBatch* cbatch,\n+                            int64_t offset, int64_t length, ArrayBuilder* abuilder) {\n+    auto builder = static_cast<Decimal128Builder*>(abuilder);\n+\n+    const bool has_nulls = cbatch->hasNulls;\n+    if (type->getPrecision() == 0 || type->getPrecision() > 18) {\n+      auto batch = static_cast<liborc::Decimal128VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!has_nulls || batch->notNull[i]) {\n+          RETURN_NOT_OK(builder->Append(\n+              Decimal128(batch->values[i].getHighBits(), batch->values[i].getLowBits())));\n+        } else {\n+          RETURN_NOT_OK(builder->AppendNull());\n+        }\n+      }\n+    } else {\n+      auto batch = static_cast<liborc::Decimal64VectorBatch*>(cbatch);\n+      for (int i = offset; i < length + offset; i++) {\n+        if (!has_nulls || batch->notNull[i]) {\n+          RETURN_NOT_OK(builder->Append(Decimal128(batch->values[i])));\n+        } else {\n+          RETURN_NOT_OK(builder->AppendNull());\n+        }\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+ private:\n+  MemoryPool* pool_;\n+  std::unique_ptr<liborc::Reader> reader_;\n+  std::vector<StripeInformation> stripes_;\n+};\n+\n+ORCFileReader::ORCFileReader() { impl_.reset(new ORCFileReader::Impl()); }\n+\n+ORCFileReader::~ORCFileReader() {}\n+\n+Status ORCFileReader::Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                           MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader) {\n+  auto result = std::unique_ptr<ORCFileReader>(new ORCFileReader());\n+  RETURN_NOT_OK(result->impl_->Open(file, pool));\n+  *reader = std::move(result);\n+  return Status::OK();\n+}\n+\n+Status ORCFileReader::ReadSchema(std::shared_ptr<Schema>* out) {\n+  return impl_->ReadSchema(out);\n+}\n+\n+Status ORCFileReader::Read(std::shared_ptr<Table>* out) { return impl_->Read(out); }\n+\n+Status ORCFileReader::Read(const std::vector<int>& include_indices,\n+                           std::shared_ptr<Table>* out) {\n+  return impl_->Read(include_indices, out);\n+}\n+\n+Status ORCFileReader::ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out) {\n+  return impl_->ReadStripe(stripe, out);\n+}\n+\n+Status ORCFileReader::ReadStripe(int64_t stripe, const std::vector<int>& include_indices,\n+                                 std::shared_ptr<RecordBatch>* out) {\n+  return impl_->ReadStripe(stripe, include_indices, out);\n+}\n+\n+int64_t ORCFileReader::NumberOfStripes() { return impl_->NumberOfStripes(); }\n+\n+int64_t ORCFileReader::NumberOfRows() { return impl_->NumberOfRows(); }\n+\n+}  // namespace orc\n+}  // namespace adapters\n+}  // namespace arrow\ndiff --git a/cpp/src/arrow/adapters/orc/adapter.h b/cpp/src/arrow/adapters/orc/adapter.h\nnew file mode 100644\nindex 000000000..6438658fd\n--- /dev/null\n+++ b/cpp/src/arrow/adapters/orc/adapter.h\n@@ -0,0 +1,105 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#ifndef ARROW_ORC_CONVERTER_H\n+#define ARROW_ORC_CONVERTER_H\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+namespace adapters {\n+\n+namespace orc {\n+\n+/// \\class ORCFileReader\n+/// \\brief Read an Arrow Table or RecordBatch from an ORC file.\n+class ARROW_EXPORT ORCFileReader {\n+ public:\n+  ~ORCFileReader();\n+\n+  /// \\brief Create a new ORC reader\n+  ///\n+  /// \\param[in] file the data source\n+  /// \\param[in] pool a MemoryPool to use for buffer allocations\n+  /// \\param[out] reader the returned reader object\n+  /// \\return Status\n+  static Status Open(const std::shared_ptr<io::ReadableFileInterface>& file,\n+                     MemoryPool* pool, std::unique_ptr<ORCFileReader>* reader);\n+\n+  /// \\brief Return the schema read from the ORC file\n+  ///\n+  /// \\param[out] out the returned Schema object\n+  Status ReadSchema(std::shared_ptr<Schema>* out);\n+\n+  /// \\brief Read the file as a Table\n+  ///\n+  /// The table will be composed of one record batch per stripe.\n+  ///\n+  /// \\param[out] out the returned RecordBatch\n+  Status Read(std::shared_ptr<Table>* out);\n+\n+  /// \\brief Read the file as a Table\n+  ///\n+  /// The table will be composed of one record batch per stripe.\n+  ///\n+  /// \\param[in] include_indices the selected field indices to read\n+  /// \\param[out] out the returned RecordBatch\n+  Status Read(const std::vector<int>& include_indices, std::shared_ptr<Table>* out);\n+\n+  /// \\brief Read a single stripe as a RecordBatch\n+  ///\n+  /// \\param[in] stripe the stripe index\n+  /// \\param[out] out the returned RecordBatch\n+  Status ReadStripe(int64_t stripe, std::shared_ptr<RecordBatch>* out);\n+\n+  /// \\brief Read a single stripe as a RecordBatch\n+  ///\n+  /// \\param[in] stripe the stripe index\n+  /// \\param[in] include_indices the selected field indices to read\n+  /// \\param[out] out the returned RecordBatch\n+  Status ReadStripe(int64_t stripe, const std::vector<int>& include_indices,\n+                    std::shared_ptr<RecordBatch>* out);\n+\n+  /// \\brief The number of stripes in the file\n+  int64_t NumberOfStripes();\n+\n+  /// \\brief The number of rows in the file\n+  int64_t NumberOfRows();\n+\n+ private:\n+  class Impl;\n+  std::unique_ptr<Impl> impl_;\n+  ORCFileReader();\n+};\n+\n+}  // namespace orc\n+\n+}  // namespace adapters\n+\n+}  // namespace arrow\n+\n+#endif  // ARROW_ORC_CONVERTER_H\ndiff --git a/cpp/src/arrow/symbols.map b/cpp/src/arrow/symbols.map\nindex f216d8650..c5d23793c 100644\n--- a/cpp/src/arrow/symbols.map\n+++ b/cpp/src/arrow/symbols.map\n@@ -55,6 +55,8 @@\n     ERR_getErrorString;\n     # jemalloc\n     je_arrow_*;\n+    # ORC destructors\n+    _ZThn8_N3orc*;\n \n     extern \"C++\" {\n       # devtoolset or -static-libstdc++ - the Red Hat devtoolset statically\n@@ -65,6 +67,8 @@\n \n       # Statically linked C++ dependencies\n       boost::*;\n+      google::*;\n+      orc::*;\n       snappy::*;\n     };\n };\ndiff --git a/python/CMakeLists.txt b/python/CMakeLists.txt\nindex cbbb464d0..e9de08ba1 100644\n--- a/python/CMakeLists.txt\n+++ b/python/CMakeLists.txt\n@@ -70,6 +70,9 @@ if(\"${CMAKE_SOURCE_DIR}\" STREQUAL \"${CMAKE_CURRENT_SOURCE_DIR}\")\n   option(PYARROW_BUILD_PLASMA\n     \"Build the PyArrow Plasma integration\"\n     OFF)\n+  option(PYARROW_BUILD_ORC\n+    \"Build the PyArrow ORC integration\"\n+    OFF)\n   option(PYARROW_BUNDLE_ARROW_CPP\n     \"Bundle the Arrow C++ libraries\"\n     OFF)\n@@ -357,6 +360,14 @@ if (PYARROW_BUILD_PLASMA)\n   file(COPY ${PLASMA_EXECUTABLE} DESTINATION ${BUILD_OUTPUT_ROOT_DIRECTORY})\n endif()\n \n+\n+if (PYARROW_BUILD_ORC)\n+  ## ORC\n+  set(CYTHON_EXTENSIONS\n+      ${CYTHON_EXTENSIONS}\n+      _orc)\n+endif()\n+\n ############################################################\n # Setup and build Cython modules\n ############################################################\ndiff --git a/python/manylinux1/scripts/check_arrow_visibility.sh b/python/manylinux1/scripts/check_arrow_visibility.sh\nindex 27a30f747..bed357edf 100755\n--- a/python/manylinux1/scripts/check_arrow_visibility.sh\n+++ b/python/manylinux1/scripts/check_arrow_visibility.sh\n@@ -17,10 +17,13 @@\n # under the License.\n \n nm -D -C /arrow-dist/lib64/libarrow.so > nm_arrow.log\n+grep ' T ' nm_arrow.log | grep -v arrow > visible_symbols.log\n \n-if [[ `grep ' T ' nm_arrow.log | grep -v arrow | wc -l` -eq 2 ]]\n+if [[ `cat visible_symbols.log | wc -l` -eq 2 ]]\n then\n     exit 0\n fi\n \n+cat visible_symbols.log\n+\n exit 1\ndiff --git a/python/pyarrow/_orc.pxd b/python/pyarrow/_orc.pxd\nnew file mode 100644\nindex 000000000..411691510\n--- /dev/null\n+++ b/python/pyarrow/_orc.pxd\n@@ -0,0 +1,50 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+# distutils: language = c++\n+\n+from libc.string cimport const_char\n+from libcpp.vector cimport vector as std_vector\n+from pyarrow.includes.common cimport *\n+from pyarrow.includes.libarrow cimport (CArray, CSchema, CStatus,\n+                                        CTable, CMemoryPool,\n+                                        CKeyValueMetadata,\n+                                        CRecordBatch,\n+                                        CTable,\n+                                        RandomAccessFile, OutputStream,\n+                                        TimeUnit)\n+\n+\n+cdef extern from \"arrow/adapters/orc/adapter.h\" namespace \"arrow::adapters::orc\" nogil:\n+    cdef cppclass ORCFileReader:\n+\n+        @staticmethod\n+        CStatus Open(const shared_ptr[RandomAccessFile]& file,\n+                     CMemoryPool* pool,\n+                     unique_ptr[ORCFileReader]* reader)\n+\n+        CStatus ReadSchema(shared_ptr[CSchema]* out)\n+\n+        CStatus ReadStripe(int64_t stripe, shared_ptr[CRecordBatch]* out)\n+        CStatus ReadStripe(int64_t stripe, std_vector[int], shared_ptr[CRecordBatch]* out)\n+\n+        CStatus Read(shared_ptr[CTable]* out)\n+        CStatus Read(std_vector[int], shared_ptr[CTable]* out)\n+\n+        int64_t NumberOfStripes()\n+\n+        int64_t NumberOfRows()\ndiff --git a/python/pyarrow/_orc.pyx b/python/pyarrow/_orc.pyx\nnew file mode 100644\nindex 000000000..7ff4bac6d\n--- /dev/null\n+++ b/python/pyarrow/_orc.pyx\n@@ -0,0 +1,111 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+# cython: profile=False\n+# distutils: language = c++\n+# cython: embedsignature = True\n+\n+from cython.operator cimport dereference as deref\n+from libcpp.vector cimport vector as std_vector\n+from pyarrow.includes.common cimport *\n+from pyarrow.includes.libarrow cimport *\n+from pyarrow.lib cimport (check_status,\n+                          MemoryPool, maybe_unbox_memory_pool,\n+                          Schema, pyarrow_wrap_schema,\n+                          RecordBatch,\n+                          pyarrow_wrap_table,\n+                          get_reader)\n+import six\n+\n+\n+cdef class ORCReader:\n+    cdef:\n+        object source\n+        CMemoryPool* allocator\n+        unique_ptr[ORCFileReader] reader\n+\n+    def __cinit__(self, MemoryPool memory_pool=None):\n+        self.allocator = maybe_unbox_memory_pool(memory_pool)\n+\n+    def open(self, object source):\n+        cdef:\n+            shared_ptr[RandomAccessFile] rd_handle\n+\n+        self.source = source\n+\n+        get_reader(source, &rd_handle)\n+        with nogil:\n+            check_status(ORCFileReader.Open(rd_handle, self.allocator,\n+                                             &self.reader))\n+\n+    def schema(self):\n+        \"\"\"\n+        The arrow schema for this file.\n+\n+        Returns\n+        -------\n+        schema : pyarrow.Schema\n+        \"\"\"\n+        cdef:\n+            shared_ptr[CSchema] sp_arrow_schema\n+\n+        with nogil:\n+            check_status(deref(self.reader).ReadSchema(&sp_arrow_schema))\n+\n+        return pyarrow_wrap_schema(sp_arrow_schema)\n+\n+    def nrows(self):\n+        return deref(self.reader).NumberOfRows();\n+\n+    def nstripes(self):\n+        return deref(self.reader).NumberOfStripes();\n+\n+    def read_stripe(self, n, include_indices=None):\n+        cdef:\n+            shared_ptr[CRecordBatch] sp_record_batch\n+            RecordBatch batch\n+            int64_t stripe\n+            std_vector[int] indices\n+\n+        stripe = n\n+\n+        if include_indices is None:\n+            with nogil:\n+                check_status(deref(self.reader).ReadStripe(stripe, &sp_record_batch))\n+        else:\n+            indices = include_indices\n+            with nogil:\n+                check_status(deref(self.reader).ReadStripe(stripe, indices, &sp_record_batch))\n+\n+        batch = RecordBatch()\n+        batch.init(sp_record_batch)\n+        return batch\n+\n+    def read(self, include_indices=None):\n+        cdef:\n+            shared_ptr[CTable] sp_table\n+            std_vector[int] indices\n+\n+        if include_indices is None:\n+            with nogil:\n+                check_status(deref(self.reader).Read(&sp_table))\n+        else:\n+            indices = include_indices\n+            with nogil:\n+                check_status(deref(self.reader).Read(indices, &sp_table))\n+\n+        return pyarrow_wrap_table(sp_table)\ndiff --git a/python/pyarrow/orc.py b/python/pyarrow/orc.py\nnew file mode 100644\nindex 000000000..22451d521\n--- /dev/null\n+++ b/python/pyarrow/orc.py\n@@ -0,0 +1,149 @@\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+from itertools import count\n+from numbers import Integral\n+\n+from pyarrow import _orc\n+from pyarrow import types\n+from pyarrow.lib import Schema\n+\n+\n+def _is_map(typ):\n+    return (types.is_list(typ) and\n+            types.is_struct(typ.value_type) and\n+            typ.value_type.num_children == 2 and\n+            typ.value_type[0].name == 'key' and\n+            typ.value_type[1].name == 'value')\n+\n+\n+def _traverse(typ, counter):\n+    if isinstance(typ, Schema) or types.is_struct(typ):\n+        for field in typ:\n+            path = (field.name,)\n+            yield path, next(counter)\n+            for sub, c in _traverse(field.type, counter):\n+                yield path + sub, c\n+    elif _is_map(typ):\n+        for sub_c in _traverse(typ.value_type, counter):\n+            yield sub_c\n+    elif types.is_list(typ):\n+        # Skip one index for list type, since this can never be selected\n+        # directly\n+        next(counter)\n+        for sub_c in _traverse(typ.value_type, counter):\n+            yield sub_c\n+    elif types.is_union(typ):\n+        # Union types not supported, just skip the indexes\n+        for dtype in typ:\n+            next(counter)\n+            for sub_c in _traverse(dtype, counter):\n+                pass\n+\n+\n+def _schema_to_indices(schema):\n+    return {'.'.join(i): c for i, c in _traverse(schema, count(1))}\n+\n+\n+class ORCFile(object):\n+    \"\"\"\n+    Reader interface for a single ORC file\n+\n+    Parameters\n+    ----------\n+    source : str or pyarrow.io.NativeFile\n+        Readable source. For passing Python file objects or byte buffers,\n+        see pyarrow.io.PythonFileInterface or pyarrow.io.BufferReader.\n+    \"\"\"\n+    def __init__(self, source):\n+        self.reader = _orc.ORCReader()\n+        self.reader.open(source)\n+        self._column_index_lookup = _schema_to_indices(self.schema)\n+\n+    @property\n+    def schema(self):\n+        \"\"\"The file schema, as an arrow schema\"\"\"\n+        return self.reader.schema()\n+\n+    @property\n+    def nrows(self):\n+        \"\"\"The number of rows in the file\"\"\"\n+        return self.reader.nrows()\n+\n+    @property\n+    def nstripes(self):\n+        \"\"\"The number of stripes in the file\"\"\"\n+        return self.reader.nstripes()\n+\n+    def _select_indices(self, columns=None):\n+        if columns is None:\n+            return None\n+\n+        schema = self.schema\n+        indices = []\n+        for col in columns:\n+            if isinstance(col, Integral):\n+                col = int(col)\n+                if 0 <= col < len(schema):\n+                    col = schema[col].name\n+                else:\n+                    raise ValueError(\"Column indices must be in 0 <= ind < %d,\"\n+                                     \" got %d\" % (len(schema), col))\n+            if col in self._column_index_lookup:\n+                indices.append(self._column_index_lookup[col])\n+            else:\n+                raise ValueError(\"Unknown column name %r\" % col)\n+\n+        return indices\n+\n+    def read_stripe(self, n, columns=None):\n+        \"\"\"Read a single stripe from the file.\n+\n+        Parameters\n+        ----------\n+        n : int\n+            The stripe index\n+        columns : list\n+            If not None, only these columns will be read from the stripe. A\n+            column name may be a prefix of a nested field, e.g. 'a' will select\n+            'a.b', 'a.c', and 'a.d.e'\n+\n+        Returns\n+        -------\n+        pyarrow.lib.RecordBatch\n+            Content of the stripe as a RecordBatch.\n+        \"\"\"\n+        include_indices = self._select_indices(columns)\n+        return self.reader.read_stripe(n, include_indices=include_indices)\n+\n+    def read(self, columns=None):\n+        \"\"\"Read the whole file.\n+\n+        Parameters\n+        ----------\n+        columns : list\n+            If not None, only these columns will be read from the file. A\n+            column name may be a prefix of a nested field, e.g. 'a' will select\n+            'a.b', 'a.c', and 'a.d.e'\n+\n+        Returns\n+        -------\n+        pyarrow.lib.Table\n+            Content of the file as a Table.\n+        \"\"\"\n+        include_indices = self._select_indices(columns)\n+        return self.reader.read(include_indices=include_indices)\ndiff --git a/python/setup.py b/python/setup.py\nindex 32e76ab05..3d3831dc0 100644\n--- a/python/setup.py\n+++ b/python/setup.py\n@@ -84,6 +84,7 @@ def run(self):\n                      ('with-parquet', None, 'build the Parquet extension'),\n                      ('with-static-parquet', None, 'link parquet statically'),\n                      ('with-plasma', None, 'build the Plasma extension'),\n+                     ('with-orc', None, 'build the ORC extension'),\n                      ('bundle-arrow-cpp', None,\n                       'bundle the Arrow C++ libraries')] +\n                     _build_ext.user_options)\n@@ -109,12 +110,15 @@ def initialize_options(self):\n             os.environ.get('PYARROW_WITH_STATIC_BOOST', '1'))\n         self.with_plasma = strtobool(\n             os.environ.get('PYARROW_WITH_PLASMA', '0'))\n+        self.with_orc = strtobool(\n+            os.environ.get('PYARROW_WITH_ORC', '0'))\n         self.bundle_arrow_cpp = strtobool(\n             os.environ.get('PYARROW_BUNDLE_ARROW_CPP', '0'))\n \n     CYTHON_MODULE_NAMES = [\n         'lib',\n         '_parquet',\n+        '_orc',\n         'plasma']\n \n     def _run_cmake(self):\n@@ -157,6 +161,9 @@ def _run_cmake(self):\n         if self.with_plasma:\n             cmake_options.append('-DPYARROW_BUILD_PLASMA=on')\n \n+        if self.with_orc:\n+            cmake_options.append('-DPYARROW_BUILD_ORC=on')\n+\n         if len(self.cmake_cxxflags) > 0:\n             cmake_options.append('-DPYARROW_CXXFLAGS=\"{0}\"'\n                                  .format(self.cmake_cxxflags))\n@@ -284,6 +291,8 @@ def _failure_permitted(self, name):\n             return True\n         if name == 'plasma' and not self.with_plasma:\n             return True\n+        if name == '_orc' and not self.with_orc:\n+            return True\n         return False\n \n     def _get_inplace_dir(self):\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-01-04T15:11:22.994+0000",
                    "updated": "2018-01-04T15:11:22.994+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13124727/comment/16311457",
                    "id": "16311457",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1418: ARROW-1920 [C++/Python] Add experimental reader for Apache ORC files\nURL: https://github.com/apache/arrow/pull/1418#issuecomment-355307073\n \n \n   Thank you for your contribution! This is exciting stuff\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-01-04T15:12:10.614+0000",
                    "updated": "2018-01-04T15:12:10.614+0000"
                }
            ],
            "maxResults": 79,
            "total": 79,
            "startAt": 0
        },
        "customfield_12311820": "0|i3nv7b:",
        "customfield_12314139": null
    }
}