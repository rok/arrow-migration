{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13419803",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803",
    "key": "ARROW-15212",
    "fields": {
        "parent": {
            "id": "13411345",
            "key": "ARROW-14679",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13411345",
            "fields": {
                "summary": "[R] [C++] Handle suffix argument in joins",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                    "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                    "name": "Resolved",
                    "id": "5",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                        "id": 3,
                        "key": "done",
                        "colorName": "green",
                        "name": "Done"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "id": "4",
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                    "name": "Improvement",
                    "subtask": false,
                    "avatarId": 21140
                }
            }
        },
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351051",
                "id": "12351051",
                "description": "",
                "name": "8.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-05-06"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vibhatha",
            "name": "vibhatha",
            "key": "vibhatha",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
            },
            "displayName": "Vibhatha Lakmal Abeykoon",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vibhatha",
            "name": "vibhatha",
            "key": "vibhatha",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
            },
            "displayName": "Vibhatha Lakmal Abeykoon",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vibhatha",
            "name": "vibhatha",
            "key": "vibhatha",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
            },
            "displayName": "Vibhatha Lakmal Abeykoon",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 8400,
            "total": 8400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 8400,
            "total": 8400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15212/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 14,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/711168",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#issuecomment-1016201504\n\n\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-19T08:35:12.088+0000",
                    "updated": "2022-01-19T08:35:12.088+0000",
                    "started": "2022-01-19T08:35:12.087+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "711168",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/711602",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#discussion_r788045868\n\n\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n\nReview comment:\n       Nit: This might be slightly more readable if it were just two string constants.  For example:\r\n   \r\n   ```\r\n   const std::string kLeftRelationCsvData = R\"csv(lkey,shared,ldistinct\"\r\n   1,4,7\r\n   2,5,8\r\n   11,20,21\r\n   3,6,9)csv\";\r\n   ```\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n+\n+  // Read table from CSV file\n+  ARROW_ASSIGN_OR_RAISE(auto maybe_table, reader->Read());\n+  auto ds = std::make_shared<arrow::dataset::InMemoryDataset>(maybe_table);\n+  arrow::Result<std::shared_ptr<arrow::dataset::InMemoryDataset>> result(std::move(ds));\n+  return result;\n+}\n+\n+cp::Expression Materialize(std::vector<std::string> names) {\n+  std::vector<cp::Expression> exprs;\n+  for (const auto& name : names) {\n+    exprs.push_back(cp::field_ref(name));\n+  }\n+\n+  return cp::project(exprs, names);\n+}\n+\n+arrow::Status DoHashJoin() {\n+  cp::ExecContext exec_context(arrow::default_memory_pool(),\n+                               ::arrow::internal::GetCpuThreadPool());\n+\n+  arrow::dataset::internal::Initialize();\n+\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<cp::ExecPlan> plan,\n+                        cp::ExecPlan::Make(&exec_context));\n+\n+  arrow::AsyncGenerator<arrow::util::optional<cp::ExecBatch>> sink_gen;\n+\n+  cp::ExecNode* left_source;\n+  cp::ExecNode* right_source;\n+\n+  ARROW_ASSIGN_OR_RAISE(auto l_dataset, CreateDataSetFromCSVData(\"l\"));\n+  ARROW_ASSIGN_OR_RAISE(auto r_dataset, CreateDataSetFromCSVData(\"r\"));\n+\n+  auto l_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  l_options->projection = Materialize({});  // create empty projection\n+\n+  auto r_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  r_options->projection = Materialize({});  // create empty projection\n+\n+  // construct the scan node\n+  auto l_scan_node_options = arrow::dataset::ScanNodeOptions{l_dataset, l_options};\n+  auto r_scan_node_options = arrow::dataset::ScanNodeOptions{r_dataset, r_options};\n+\n+  ARROW_ASSIGN_OR_RAISE(left_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, l_scan_node_options));\n+  ARROW_ASSIGN_OR_RAISE(right_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, r_scan_node_options));\n+\n+  arrow::compute::HashJoinNodeOptions join_opts{\n+      arrow::compute::JoinType::INNER,\n+      /*left_keys=*/{\"lkey\"},\n+      /*right_keys=*/{\"rkey\"},         arrow::compute::literal(true), \"_l\", \"_r\"};\n+\n+  ARROW_ASSIGN_OR_RAISE(\n+      auto hashjoin,\n+      cp::MakeExecNode(\"hashjoin\", plan.get(), {left_source, right_source}, join_opts));\n+\n+  ARROW_ASSIGN_OR_RAISE(std::ignore, cp::MakeExecNode(\"sink\", plan.get(), {hashjoin},\n+                                                      cp::SinkNodeOptions{&sink_gen}));\n+  // expected columns l_a, l_b\n+  std::shared_ptr<arrow::RecordBatchReader> sink_reader = cp::MakeGeneratorReader(\n+      hashjoin->output_schema(), std::move(sink_gen), exec_context.memory_pool());\n+\n+  // // validate the ExecPlan\n+  ABORT_ON_FAILURE(plan->Validate());\n+  // // // start the ExecPlan\n\nReview comment:\n       ```suggestion\r\n     // start the ExecPlan\r\n   ```\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n+\n+  // Read table from CSV file\n+  ARROW_ASSIGN_OR_RAISE(auto maybe_table, reader->Read());\n+  auto ds = std::make_shared<arrow::dataset::InMemoryDataset>(maybe_table);\n+  arrow::Result<std::shared_ptr<arrow::dataset::InMemoryDataset>> result(std::move(ds));\n+  return result;\n+}\n+\n+cp::Expression Materialize(std::vector<std::string> names) {\n+  std::vector<cp::Expression> exprs;\n+  for (const auto& name : names) {\n+    exprs.push_back(cp::field_ref(name));\n+  }\n+\n+  return cp::project(exprs, names);\n+}\n+\n+arrow::Status DoHashJoin() {\n+  cp::ExecContext exec_context(arrow::default_memory_pool(),\n+                               ::arrow::internal::GetCpuThreadPool());\n+\n+  arrow::dataset::internal::Initialize();\n+\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<cp::ExecPlan> plan,\n+                        cp::ExecPlan::Make(&exec_context));\n+\n+  arrow::AsyncGenerator<arrow::util::optional<cp::ExecBatch>> sink_gen;\n+\n+  cp::ExecNode* left_source;\n+  cp::ExecNode* right_source;\n+\n+  ARROW_ASSIGN_OR_RAISE(auto l_dataset, CreateDataSetFromCSVData(\"l\"));\n+  ARROW_ASSIGN_OR_RAISE(auto r_dataset, CreateDataSetFromCSVData(\"r\"));\n+\n+  auto l_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  l_options->projection = Materialize({});  // create empty projection\n+\n+  auto r_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  r_options->projection = Materialize({});  // create empty projection\n+\n+  // construct the scan node\n+  auto l_scan_node_options = arrow::dataset::ScanNodeOptions{l_dataset, l_options};\n+  auto r_scan_node_options = arrow::dataset::ScanNodeOptions{r_dataset, r_options};\n+\n+  ARROW_ASSIGN_OR_RAISE(left_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, l_scan_node_options));\n+  ARROW_ASSIGN_OR_RAISE(right_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, r_scan_node_options));\n+\n+  arrow::compute::HashJoinNodeOptions join_opts{\n+      arrow::compute::JoinType::INNER,\n+      /*left_keys=*/{\"lkey\"},\n+      /*right_keys=*/{\"rkey\"},         arrow::compute::literal(true), \"_l\", \"_r\"};\n+\n+  ARROW_ASSIGN_OR_RAISE(\n+      auto hashjoin,\n+      cp::MakeExecNode(\"hashjoin\", plan.get(), {left_source, right_source}, join_opts));\n+\n+  ARROW_ASSIGN_OR_RAISE(std::ignore, cp::MakeExecNode(\"sink\", plan.get(), {hashjoin},\n+                                                      cp::SinkNodeOptions{&sink_gen}));\n+  // expected columns l_a, l_b\n+  std::shared_ptr<arrow::RecordBatchReader> sink_reader = cp::MakeGeneratorReader(\n+      hashjoin->output_schema(), std::move(sink_gen), exec_context.memory_pool());\n+\n+  // // validate the ExecPlan\n+  ABORT_ON_FAILURE(plan->Validate());\n+  // // // start the ExecPlan\n+  ABORT_ON_FAILURE(plan->StartProducing());\n+\n+  // // // collect sink_reader into a Table\n\nReview comment:\n       ```suggestion\r\n     // collect sink_reader into a Table\r\n   ```\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n\nReview comment:\n       ```suggestion\r\n   ```\r\n   \r\n   I don't think this method is used.\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n\nReview comment:\n       ```suggestion\r\n   std::string GetDataAsCsvString(const std::string& relation) {\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_node.cc\n##########\n@@ -275,30 +275,56 @@ Status HashJoinSchema::ValidateSchemas(JoinType join_type, const Schema& left_sc\n }\n \n std::shared_ptr<Schema> HashJoinSchema::MakeOutputSchema(\n-    const std::string& left_field_name_prefix,\n-    const std::string& right_field_name_prefix) {\n+    const std::string& left_field_name_suffix,\n+    const std::string& right_field_name_suffix) {\n   std::vector<std::shared_ptr<Field>> fields;\n   int left_size = proj_maps[0].num_cols(HashJoinProjection::OUTPUT);\n   int right_size = proj_maps[1].num_cols(HashJoinProjection::OUTPUT);\n   fields.resize(left_size + right_size);\n \n-  for (int i = 0; i < left_size + right_size; ++i) {\n-    bool is_left = (i < left_size);\n-    int side = (is_left ? 0 : 1);\n-    int input_field_id = proj_maps[side]\n-                             .map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT)\n-                             .get(is_left ? i : i - left_size);\n+  std::unordered_multimap<std::string, int> left_field_map;\n\nReview comment:\n       At first I was a little confused why you used a `multimap` instead of a `set`.  Then I remembered that we might have multiple columns with the same name.\r\n   \r\n   However, in order for that case to work, you would need to use `equal_range` instead of `find` down below when you actually search for the field.\r\n   \r\n   In fact, I don't think we have any test cases for this in the hash join tests (and I'm not 100% sure we'd completely support it elsewhere) but it might be an interesting test case.\r\n   \r\n   Either way, can you change the below \"finding\" code to use `equal_range` instead of `find`?\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n\nReview comment:\n       ```suggestion\r\n       const std::string& relation) {\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/options.h\n##########\n@@ -245,9 +245,9 @@ class ARROW_EXPORT HashJoinNodeOptions : public ExecNodeOptions {\n   // prefix added to names of output fields coming from left input (used to distinguish,\n   // if necessary, between fields of the same name in left and right input and can be left\n   // empty if there are no name collisions)\n-  std::string output_prefix_for_left;\n+  std::string output_suffix_for_left;\n   // prefix added to names of output fields coming from right input\n\nReview comment:\n       ```suggestion\r\n     // suffix added to names of output fields coming from right input\r\n   ```\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n\nReview comment:\n       ```suggestion\r\n     const std::shared_ptr<arrow::csv::TableReader>& reader = table_reader;\r\n   ```\r\n   \r\n   Do you need this alias?  It is only used in one spot below and `table_reader` is a pretty reasonable name already\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n+\n+  // Read table from CSV file\n+  ARROW_ASSIGN_OR_RAISE(auto maybe_table, reader->Read());\n+  auto ds = std::make_shared<arrow::dataset::InMemoryDataset>(maybe_table);\n+  arrow::Result<std::shared_ptr<arrow::dataset::InMemoryDataset>> result(std::move(ds));\n+  return result;\n+}\n+\n+cp::Expression Materialize(std::vector<std::string> names) {\n\nReview comment:\n       ```suggestion\r\n   cp::Expression Materialize(const std::vector<std::string>& names) {\r\n   ```\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n\nReview comment:\n       ```suggestion\r\n     const arrow::io::IOContext& io_context = arrow::io::default_io_context();\r\n   ```\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n+\n+  // Read table from CSV file\n+  ARROW_ASSIGN_OR_RAISE(auto maybe_table, reader->Read());\n+  auto ds = std::make_shared<arrow::dataset::InMemoryDataset>(maybe_table);\n+  arrow::Result<std::shared_ptr<arrow::dataset::InMemoryDataset>> result(std::move(ds));\n+  return result;\n+}\n+\n+cp::Expression Materialize(std::vector<std::string> names) {\n+  std::vector<cp::Expression> exprs;\n+  for (const auto& name : names) {\n+    exprs.push_back(cp::field_ref(name));\n+  }\n+\n+  return cp::project(exprs, names);\n+}\n+\n+arrow::Status DoHashJoin() {\n+  cp::ExecContext exec_context(arrow::default_memory_pool(),\n+                               ::arrow::internal::GetCpuThreadPool());\n+\n+  arrow::dataset::internal::Initialize();\n+\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<cp::ExecPlan> plan,\n+                        cp::ExecPlan::Make(&exec_context));\n+\n+  arrow::AsyncGenerator<arrow::util::optional<cp::ExecBatch>> sink_gen;\n+\n+  cp::ExecNode* left_source;\n+  cp::ExecNode* right_source;\n+\n+  ARROW_ASSIGN_OR_RAISE(auto l_dataset, CreateDataSetFromCSVData(\"l\"));\n+  ARROW_ASSIGN_OR_RAISE(auto r_dataset, CreateDataSetFromCSVData(\"r\"));\n+\n+  auto l_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  l_options->projection = Materialize({});  // create empty projection\n+\n+  auto r_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  r_options->projection = Materialize({});  // create empty projection\n+\n+  // construct the scan node\n+  auto l_scan_node_options = arrow::dataset::ScanNodeOptions{l_dataset, l_options};\n+  auto r_scan_node_options = arrow::dataset::ScanNodeOptions{r_dataset, r_options};\n+\n+  ARROW_ASSIGN_OR_RAISE(left_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, l_scan_node_options));\n+  ARROW_ASSIGN_OR_RAISE(right_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, r_scan_node_options));\n+\n+  arrow::compute::HashJoinNodeOptions join_opts{\n+      arrow::compute::JoinType::INNER,\n+      /*left_keys=*/{\"lkey\"},\n+      /*right_keys=*/{\"rkey\"},         arrow::compute::literal(true), \"_l\", \"_r\"};\n+\n+  ARROW_ASSIGN_OR_RAISE(\n+      auto hashjoin,\n+      cp::MakeExecNode(\"hashjoin\", plan.get(), {left_source, right_source}, join_opts));\n+\n+  ARROW_ASSIGN_OR_RAISE(std::ignore, cp::MakeExecNode(\"sink\", plan.get(), {hashjoin},\n+                                                      cp::SinkNodeOptions{&sink_gen}));\n+  // expected columns l_a, l_b\n+  std::shared_ptr<arrow::RecordBatchReader> sink_reader = cp::MakeGeneratorReader(\n+      hashjoin->output_schema(), std::move(sink_gen), exec_context.memory_pool());\n+\n+  // // validate the ExecPlan\n\nReview comment:\n       ```suggestion\r\n     // validate the ExecPlan\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/options.h\n##########\n@@ -245,9 +245,9 @@ class ARROW_EXPORT HashJoinNodeOptions : public ExecNodeOptions {\n   // prefix added to names of output fields coming from left input (used to distinguish,\n\nReview comment:\n       ```suggestion\r\n     // suffix added to names of output fields coming from left input (used to distinguish,\r\n   ```\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n+\n+  // Read table from CSV file\n+  ARROW_ASSIGN_OR_RAISE(auto maybe_table, reader->Read());\n+  auto ds = std::make_shared<arrow::dataset::InMemoryDataset>(maybe_table);\n+  arrow::Result<std::shared_ptr<arrow::dataset::InMemoryDataset>> result(std::move(ds));\n+  return result;\n+}\n+\n+cp::Expression Materialize(std::vector<std::string> names) {\n\nReview comment:\n       `Materialize` is a big of a confusing name.  Perhaps `MakeDefaultProjection` would be better?  Ideally this entire method will go away at some point in the future as the default projection shouldn't really need to be specified.\r\n   \r\n   Also, why take a vector of names as an argument when you only ever pass an empty vector?  It might be simpler to get rid of this function entirely and just call `cp::project({}, {})`\r\n   \r\n   Also, there should be a comment somewhere explaining that passing in an empty vector of names/expressions to `cp::project` will result in a \"default\" projection where each field is mapped to a field_ref.  That comment may belong on `cp::project`'s docs though.\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n+\n+  // Read table from CSV file\n+  ARROW_ASSIGN_OR_RAISE(auto maybe_table, reader->Read());\n+  auto ds = std::make_shared<arrow::dataset::InMemoryDataset>(maybe_table);\n+  arrow::Result<std::shared_ptr<arrow::dataset::InMemoryDataset>> result(std::move(ds));\n+  return result;\n+}\n+\n+cp::Expression Materialize(std::vector<std::string> names) {\n+  std::vector<cp::Expression> exprs;\n+  for (const auto& name : names) {\n+    exprs.push_back(cp::field_ref(name));\n+  }\n+\n+  return cp::project(exprs, names);\n+}\n+\n+arrow::Status DoHashJoin() {\n+  cp::ExecContext exec_context(arrow::default_memory_pool(),\n+                               ::arrow::internal::GetCpuThreadPool());\n+\n+  arrow::dataset::internal::Initialize();\n+\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<cp::ExecPlan> plan,\n+                        cp::ExecPlan::Make(&exec_context));\n+\n+  arrow::AsyncGenerator<arrow::util::optional<cp::ExecBatch>> sink_gen;\n+\n+  cp::ExecNode* left_source;\n+  cp::ExecNode* right_source;\n+\n+  ARROW_ASSIGN_OR_RAISE(auto l_dataset, CreateDataSetFromCSVData(\"l\"));\n+  ARROW_ASSIGN_OR_RAISE(auto r_dataset, CreateDataSetFromCSVData(\"r\"));\n+\n+  auto l_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  l_options->projection = Materialize({});  // create empty projection\n+\n+  auto r_options = std::make_shared<arrow::dataset::ScanOptions>();\n+  r_options->projection = Materialize({});  // create empty projection\n+\n+  // construct the scan node\n+  auto l_scan_node_options = arrow::dataset::ScanNodeOptions{l_dataset, l_options};\n+  auto r_scan_node_options = arrow::dataset::ScanNodeOptions{r_dataset, r_options};\n+\n+  ARROW_ASSIGN_OR_RAISE(left_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, l_scan_node_options));\n+  ARROW_ASSIGN_OR_RAISE(right_source,\n+                        cp::MakeExecNode(\"scan\", plan.get(), {}, r_scan_node_options));\n+\n+  arrow::compute::HashJoinNodeOptions join_opts{\n+      arrow::compute::JoinType::INNER,\n+      /*left_keys=*/{\"lkey\"},\n+      /*right_keys=*/{\"rkey\"},         arrow::compute::literal(true), \"_l\", \"_r\"};\n\nReview comment:\n       ```suggestion\r\n         /*in_left_keys=*/{\"lkey\"},\r\n         /*in_right_keys=*/{\"rkey\"},         arrow::compute::literal(true), \"_l\", \"_r\"};\r\n   ```\r\n   Also, if you're going to specify the names for these parameters you should probably specify the names for the rest.  None of them are intuitive.\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_node_test.cc\n##########\n@@ -937,6 +937,73 @@ void HashJoinWithExecPlan(Random64Bit& rng, bool parallel,\n   ASSERT_OK_AND_ASSIGN(*output, TableFromExecBatches(output_schema, res));\n }\n \n+TEST(HashJoin, Suffix) {\n+  BatchesWithSchema input_left;\n+  input_left.batches = {ExecBatchFromJSON({int32(), int32(), int32()}, R\"([\n+                   [1, 4, 7],\n+                   [2, 5, 8],\n+                   [3, 6, 9]\n+                 ])\")};\n+  input_left.schema = schema(\n+      {field(\"lkey\", int32()), field(\"shared\", int32()), field(\"ldistinct\", int32())});\n+\n+  BatchesWithSchema input_right;\n+  input_right.batches = {ExecBatchFromJSON({int32(), int32(), int32()}, R\"([\n+                   [1, 10, 13],\n+                   [2, 11, 14],\n+                   [3, 12, 15]\n+                 ])\")};\n+  input_right.schema = schema(\n+      {field(\"rkey\", int32()), field(\"shared\", int32()), field(\"rdistinct\", int32())});\n+\n+  BatchesWithSchema expected;\n+  expected.batches = {\n+      ExecBatchFromJSON({int32(), int32(), int32(), int32(), int32(), int32()}, R\"([\n+    [1, 4, 7, 1, 10, 13],\n+    [2, 5, 8, 2, 11, 14],\n+    [3, 6, 9, 3, 12, 15]\n+  ])\")};\n+\n+  expected.schema = schema({field(\"lkey\", int32()), field(\"shared_l\", int32()),\n+                            field(\"ldistinct\", int32()), field(\"rkey\", int32()),\n+                            field(\"shared_r\", int32()), field(\"rdistinct\", int32())});\n+\n+  ExecContext exec_ctx;\n+\n+  ASSERT_OK_AND_ASSIGN(auto plan, ExecPlan::Make(&exec_ctx));\n+  AsyncGenerator<util::optional<ExecBatch>> sink_gen;\n+\n+  ExecNode* left_source;\n+  ExecNode* right_source;\n+  ASSERT_OK_AND_ASSIGN(\n+      left_source,\n+      MakeExecNode(\"source\", plan.get(), {},\n+                   SourceNodeOptions{input_left.schema, input_left.gen(/*parallel=*/false,\n+                                                                       /*slow=*/false)}));\n+\n+  ASSERT_OK_AND_ASSIGN(right_source,\n+                       MakeExecNode(\"source\", plan.get(), {},\n+                                    SourceNodeOptions{input_right.schema,\n+                                                      input_right.gen(/*parallel=*/false,\n+                                                                      /*slow=*/false)}))\n+\n+  HashJoinNodeOptions join_opts{JoinType::INNER,\n+                                /*left_keys=*/{\"lkey\"},\n+                                /*right_keys=*/{\"rkey\"}, literal(true), \"_l\", \"_r\"};\n\nReview comment:\n       ```suggestion\r\n                                   /*in_left_keys=*/{\"lkey\"},\r\n                                   /*in_right_keys=*/{\"rkey\"}, literal(true), \"_l\", \"_r\"};\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-19T19:25:53.530+0000",
                    "updated": "2022-01-19T19:25:53.530+0000",
                    "started": "2022-01-19T19:25:53.529+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "711602",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/711848",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on a change in pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#discussion_r788317883\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_node.cc\n##########\n@@ -275,30 +275,56 @@ Status HashJoinSchema::ValidateSchemas(JoinType join_type, const Schema& left_sc\n }\n \n std::shared_ptr<Schema> HashJoinSchema::MakeOutputSchema(\n-    const std::string& left_field_name_prefix,\n-    const std::string& right_field_name_prefix) {\n+    const std::string& left_field_name_suffix,\n+    const std::string& right_field_name_suffix) {\n   std::vector<std::shared_ptr<Field>> fields;\n   int left_size = proj_maps[0].num_cols(HashJoinProjection::OUTPUT);\n   int right_size = proj_maps[1].num_cols(HashJoinProjection::OUTPUT);\n   fields.resize(left_size + right_size);\n \n-  for (int i = 0; i < left_size + right_size; ++i) {\n-    bool is_left = (i < left_size);\n-    int side = (is_left ? 0 : 1);\n-    int input_field_id = proj_maps[side]\n-                             .map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT)\n-                             .get(is_left ? i : i - left_size);\n+  std::unordered_multimap<std::string, int> left_field_map;\n\nReview comment:\n       You're making a very important point. One thing, I wanted to do was, to make sure I use the correct order, because I want to bind the column name with the corresponding iterator index. That's the main reason why I selected a `multimap` leaving space for multiple keys too. But again, thinking about this, do we allow duplicate column names in a schema? I might have missed this even though I wrote it like this. \r\n   \r\n   `equal_range` needs to be there and I will correct it. \r\n   \r\n   By the way, I also assumed O(m*n) must be heavy if we have columns with 1000s of columns, that's why the code required that map in the first place. Is there a better way to optimize it? \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-20T03:20:12.517+0000",
                    "updated": "2022-01-20T03:20:12.517+0000",
                    "started": "2022-01-20T03:20:12.517+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "711848",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/711880",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on a change in pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#discussion_r788380967\n\n\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n+\n+  // Read table from CSV file\n+  ARROW_ASSIGN_OR_RAISE(auto maybe_table, reader->Read());\n+  auto ds = std::make_shared<arrow::dataset::InMemoryDataset>(maybe_table);\n+  arrow::Result<std::shared_ptr<arrow::dataset::InMemoryDataset>> result(std::move(ds));\n+  return result;\n+}\n+\n+cp::Expression Materialize(std::vector<std::string> names) {\n\nReview comment:\n       absolutely, just the one liner makes more sense since we haven't used it with any args passed. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-20T06:20:24.698+0000",
                    "updated": "2022-01-20T06:20:24.698+0000",
                    "started": "2022-01-20T06:20:24.698+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "711880",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/711888",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on a change in pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#discussion_r788400686\n\n\n\n##########\nFile path: cpp/examples/arrow/join_example.cc\n##########\n@@ -0,0 +1,194 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements. See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership. The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License. You may obtain a copy of the License at\n+//\n+// http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied. See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// This example showcases various ways to work with Datasets. It's\n+// intended to be paired with the documentation.\n+\n+#include <arrow/api.h>\n+#include <arrow/compute/api.h>\n+#include <arrow/compute/exec/exec_plan.h>\n+#include <arrow/compute/exec/expression.h>\n+#include <arrow/csv/api.h>\n+\n+#include <arrow/dataset/dataset.h>\n+#include <arrow/dataset/plan.h>\n+#include <arrow/dataset/scanner.h>\n+\n+#include <arrow/io/interfaces.h>\n+#include <arrow/io/memory.h>\n+#include <arrow/io/stdio.h>\n+\n+#include <arrow/filesystem/filesystem.h>\n+\n+#include <arrow/result.h>\n+#include <arrow/status.h>\n+\n+#include <arrow/util/vector.h>\n+\n+#include <iostream>\n+#include <vector>\n+\n+namespace ds = arrow::dataset;\n+namespace cp = arrow::compute;\n+\n+#define ABORT_ON_FAILURE(expr)                     \\\n+  do {                                             \\\n+    arrow::Status status_ = (expr);                \\\n+    if (!status_.ok()) {                           \\\n+      std::cerr << status_.message() << std::endl; \\\n+      abort();                                     \\\n+    }                                              \\\n+  } while (0);\n+\n+std::string GetDataAsCsvString(std::string relation) {\n+  std::string data_str = \"\";\n+  if (relation == \"l\") {\n+    data_str = R\"csv(lkey,shared,ldistinct\n+1,4,7\n+2,5,8\n+11,20,21\n+3,6,9)csv\";\n+  } else if (relation == \"r\") {\n+    data_str = R\"csv(rkey,shared,rdistinct\n+1,10,13\n+124,10,11\n+2,11,14\n+3,12,15)csv\";\n+  } else {\n+    return data_str;\n+  }\n+  return data_str;\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::Table>> GetTableFromExecBatches(\n+    const std::shared_ptr<arrow::Schema>& schema,\n+    const std::vector<arrow::compute::ExecBatch>& exec_batches) {\n+  arrow::RecordBatchVector batches;\n+  for (const auto& batch : exec_batches) {\n+    ARROW_ASSIGN_OR_RAISE(auto rb, batch.ToRecordBatch(schema));\n+    batches.push_back(std::move(rb));\n+  }\n+  return arrow::Table::FromRecordBatches(schema, batches);\n+}\n+\n+arrow::Result<std::shared_ptr<arrow::dataset::Dataset>> CreateDataSetFromCSVData(\n+    std::string relation) {\n+  arrow::io::IOContext io_context = arrow::io::default_io_context();\n+  std::shared_ptr<arrow::io::InputStream> input;\n+  std::string csv_data = GetDataAsCsvString(relation);\n+  std::cout << \"CSV DATA : \" << relation << std::endl;\n+  std::cout << csv_data << std::endl;\n+  arrow::util::string_view sv = csv_data;\n+  input = std::make_shared<arrow::io::BufferReader>(sv);\n+  auto read_options = arrow::csv::ReadOptions::Defaults();\n+  auto parse_options = arrow::csv::ParseOptions::Defaults();\n+  auto convert_options = arrow::csv::ConvertOptions::Defaults();\n+\n+  // Instantiate TableReader from input stream and options\n+  ARROW_ASSIGN_OR_RAISE(std::shared_ptr<arrow::csv::TableReader> table_reader,\n+                        arrow::csv::TableReader::Make(io_context, input, read_options,\n+                                                      parse_options, convert_options));\n+\n+  std::shared_ptr<arrow::csv::TableReader> reader = table_reader;\n\nReview comment:\n       Yes, we can keep it `table_reader`, I agree with you. Probably a negligible naming by me :) \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-20T06:43:27.073+0000",
                    "updated": "2022-01-20T06:43:27.073+0000",
                    "started": "2022-01-20T06:43:27.072+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "711888",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/711895",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on a change in pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#discussion_r788416836\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_node.cc\n##########\n@@ -275,30 +275,56 @@ Status HashJoinSchema::ValidateSchemas(JoinType join_type, const Schema& left_sc\n }\n \n std::shared_ptr<Schema> HashJoinSchema::MakeOutputSchema(\n-    const std::string& left_field_name_prefix,\n-    const std::string& right_field_name_prefix) {\n+    const std::string& left_field_name_suffix,\n+    const std::string& right_field_name_suffix) {\n   std::vector<std::shared_ptr<Field>> fields;\n   int left_size = proj_maps[0].num_cols(HashJoinProjection::OUTPUT);\n   int right_size = proj_maps[1].num_cols(HashJoinProjection::OUTPUT);\n   fields.resize(left_size + right_size);\n \n-  for (int i = 0; i < left_size + right_size; ++i) {\n-    bool is_left = (i < left_size);\n-    int side = (is_left ? 0 : 1);\n-    int input_field_id = proj_maps[side]\n-                             .map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT)\n-                             .get(is_left ? i : i - left_size);\n+  std::unordered_multimap<std::string, int> left_field_map;\n\nReview comment:\n       Think my comment on multi-column is wrong: multi-columns are supported as I assumed. \n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_node.cc\n##########\n@@ -275,30 +275,56 @@ Status HashJoinSchema::ValidateSchemas(JoinType join_type, const Schema& left_sc\n }\n \n std::shared_ptr<Schema> HashJoinSchema::MakeOutputSchema(\n-    const std::string& left_field_name_prefix,\n-    const std::string& right_field_name_prefix) {\n+    const std::string& left_field_name_suffix,\n+    const std::string& right_field_name_suffix) {\n   std::vector<std::shared_ptr<Field>> fields;\n   int left_size = proj_maps[0].num_cols(HashJoinProjection::OUTPUT);\n   int right_size = proj_maps[1].num_cols(HashJoinProjection::OUTPUT);\n   fields.resize(left_size + right_size);\n \n-  for (int i = 0; i < left_size + right_size; ++i) {\n-    bool is_left = (i < left_size);\n-    int side = (is_left ? 0 : 1);\n-    int input_field_id = proj_maps[side]\n-                             .map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT)\n-                             .get(is_left ? i : i - left_size);\n+  std::unordered_multimap<std::string, int> left_field_map;\n\nReview comment:\n       Think my comment on multi-column is wrong: multi-columns with same name are supported as I assumed. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-20T07:01:55.138+0000",
                    "updated": "2022-01-20T07:01:55.138+0000",
                    "started": "2022-01-20T07:01:55.138+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "711895",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/711925",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on a change in pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#discussion_r788526908\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_node.cc\n##########\n@@ -275,30 +275,56 @@ Status HashJoinSchema::ValidateSchemas(JoinType join_type, const Schema& left_sc\n }\n \n std::shared_ptr<Schema> HashJoinSchema::MakeOutputSchema(\n-    const std::string& left_field_name_prefix,\n-    const std::string& right_field_name_prefix) {\n+    const std::string& left_field_name_suffix,\n+    const std::string& right_field_name_suffix) {\n   std::vector<std::shared_ptr<Field>> fields;\n   int left_size = proj_maps[0].num_cols(HashJoinProjection::OUTPUT);\n   int right_size = proj_maps[1].num_cols(HashJoinProjection::OUTPUT);\n   fields.resize(left_size + right_size);\n \n-  for (int i = 0; i < left_size + right_size; ++i) {\n-    bool is_left = (i < left_size);\n-    int side = (is_left ? 0 : 1);\n-    int input_field_id = proj_maps[side]\n-                             .map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT)\n-                             .get(is_left ? i : i - left_size);\n+  std::unordered_multimap<std::string, int> left_field_map;\n\nReview comment:\n       Updated the PR \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-01-20T08:53:41.959+0000",
                    "updated": "2022-01-20T08:53:41.959+0000",
                    "started": "2022-01-20T08:53:41.959+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "711925",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/723485",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#discussion_r802350610\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_node.cc\n##########\n@@ -275,30 +275,61 @@ Status HashJoinSchema::ValidateSchemas(JoinType join_type, const Schema& left_sc\n }\n \n std::shared_ptr<Schema> HashJoinSchema::MakeOutputSchema(\n-    const std::string& left_field_name_prefix,\n-    const std::string& right_field_name_prefix) {\n+    const std::string& left_field_name_suffix,\n+    const std::string& right_field_name_suffix) {\n   std::vector<std::shared_ptr<Field>> fields;\n   int left_size = proj_maps[0].num_cols(HashJoinProjection::OUTPUT);\n   int right_size = proj_maps[1].num_cols(HashJoinProjection::OUTPUT);\n   fields.resize(left_size + right_size);\n \n-  for (int i = 0; i < left_size + right_size; ++i) {\n-    bool is_left = (i < left_size);\n-    int side = (is_left ? 0 : 1);\n-    int input_field_id = proj_maps[side]\n-                             .map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT)\n-                             .get(is_left ? i : i - left_size);\n+  std::unordered_multimap<std::string, int> left_field_map;\n+  left_field_map.reserve(left_size);\n+  for (int i = 0; i < left_size; ++i) {\n+    int side = 0;  // left\n+    int input_field_id =\n+        proj_maps[side].map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT).get(i);\n     const std::string& input_field_name =\n         proj_maps[side].field_name(HashJoinProjection::INPUT, input_field_id);\n     const std::shared_ptr<DataType>& input_data_type =\n         proj_maps[side].data_type(HashJoinProjection::INPUT, input_field_id);\n+    left_field_map.insert({input_field_name, i});\n+    // insert left table field\n+    fields[i] =\n+        std::make_shared<Field>(input_field_name, input_data_type, true /*nullable*/);\n+  }\n \n-    std::string output_field_name =\n-        (is_left ? left_field_name_prefix : right_field_name_prefix) + input_field_name;\n+  for (int i = 0; i < right_size; ++i) {\n+    int side = 1;  // right\n+    int input_field_id =\n+        proj_maps[side].map(HashJoinProjection::OUTPUT, HashJoinProjection::INPUT).get(i);\n+    const std::string& input_field_name =\n+        proj_maps[side].field_name(HashJoinProjection::INPUT, input_field_id);\n+    const std::shared_ptr<DataType>& input_data_type =\n+        proj_maps[side].data_type(HashJoinProjection::INPUT, input_field_id);\n+    // search the map and add suffix to the elements which\n+    // are present both in left and right tables\n+    // auto search = left_field_map.find(input_field_name);\n\nReview comment:\n       ```suggestion\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-09T07:50:37.695+0000",
                    "updated": "2022-02-09T07:50:37.695+0000",
                    "started": "2022-02-09T07:50:37.694+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "723485",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/724216",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace closed pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110\n\n\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-10T01:25:57.846+0000",
                    "updated": "2022-02-10T01:25:57.846+0000",
                    "started": "2022-02-10T01:25:57.846+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "724216",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/724219",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "ursabot commented on pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#issuecomment-1034391503\n\n\n   Benchmark runs are scheduled for baseline = 2dfc60c1c921147d9032dd3694e256e1f20bfecd and contender = 401746bede014cf3d06a88930c282755f151a93b. 401746bede014cf3d06a88930c282755f151a93b is a master commit associated with this PR. Results will be available as each benchmark for each run completes.\n   Conbench compare runs links:\n   [Scheduled] [ec2-t3-xlarge-us-east-2](https://conbench.ursa.dev/compare/runs/af2f4533fc444e80acf5b192802bae61...8976ad62696e48ae9aa7157f22968ce6/)\n   [Scheduled] [test-mac-arm](https://conbench.ursa.dev/compare/runs/b0692c73cf8b4937a09a67a466fe786b...1dc37a2cf3fa4d47921635a05bf8231f/)\n   [Scheduled] [ursa-i9-9960x](https://conbench.ursa.dev/compare/runs/dfc2f247f0e14ec9ab955e86bfa493ca...b3907fcd83144ec98d45ab5d6ab1cb9d/)\n   [Scheduled] [ursa-thinkcentre-m75q](https://conbench.ursa.dev/compare/runs/7cc5a85edd6c4086ac1b344aeab573ba...9f0fb694951d401db480e4eb55beca93/)\n   Supported benchmarks:\n   ec2-t3-xlarge-us-east-2: Supported benchmark langs: Python. Runs only benchmarks with cloud = True\n   test-mac-arm: Supported benchmark langs: C++, Python, R\n   ursa-i9-9960x: Supported benchmark langs: Python, R, JavaScript\n   ursa-thinkcentre-m75q: Supported benchmark langs: C++, Java\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-10T01:31:28.949+0000",
                    "updated": "2022-02-10T01:31:28.949+0000",
                    "started": "2022-02-10T01:31:28.949+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "724219",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/724226",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "ursabot edited a comment on pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#issuecomment-1034391503\n\n\n   Benchmark runs are scheduled for baseline = 2dfc60c1c921147d9032dd3694e256e1f20bfecd and contender = 401746bede014cf3d06a88930c282755f151a93b. 401746bede014cf3d06a88930c282755f151a93b is a master commit associated with this PR. Results will be available as each benchmark for each run completes.\n   Conbench compare runs links:\n   [Finished :arrow_down:0.0% :arrow_up:0.0%] [ec2-t3-xlarge-us-east-2](https://conbench.ursa.dev/compare/runs/af2f4533fc444e80acf5b192802bae61...8976ad62696e48ae9aa7157f22968ce6/)\n   [Scheduled] [test-mac-arm](https://conbench.ursa.dev/compare/runs/b0692c73cf8b4937a09a67a466fe786b...1dc37a2cf3fa4d47921635a05bf8231f/)\n   [Scheduled] [ursa-i9-9960x](https://conbench.ursa.dev/compare/runs/dfc2f247f0e14ec9ab955e86bfa493ca...b3907fcd83144ec98d45ab5d6ab1cb9d/)\n   [Scheduled] [ursa-thinkcentre-m75q](https://conbench.ursa.dev/compare/runs/7cc5a85edd6c4086ac1b344aeab573ba...9f0fb694951d401db480e4eb55beca93/)\n   Supported benchmarks:\n   ec2-t3-xlarge-us-east-2: Supported benchmark langs: Python. Runs only benchmarks with cloud = True\n   test-mac-arm: Supported benchmark langs: C++, Python, R\n   ursa-i9-9960x: Supported benchmark langs: Python, R, JavaScript\n   ursa-thinkcentre-m75q: Supported benchmark langs: C++, Java\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-10T01:51:50.071+0000",
                    "updated": "2022-02-10T01:51:50.071+0000",
                    "started": "2022-02-10T01:51:50.070+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "724226",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/724697",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "ursabot edited a comment on pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#issuecomment-1034391503\n\n\n   Benchmark runs are scheduled for baseline = 2dfc60c1c921147d9032dd3694e256e1f20bfecd and contender = 401746bede014cf3d06a88930c282755f151a93b. 401746bede014cf3d06a88930c282755f151a93b is a master commit associated with this PR. Results will be available as each benchmark for each run completes.\n   Conbench compare runs links:\n   [Finished :arrow_down:0.0% :arrow_up:0.0%] [ec2-t3-xlarge-us-east-2](https://conbench.ursa.dev/compare/runs/af2f4533fc444e80acf5b192802bae61...8976ad62696e48ae9aa7157f22968ce6/)\n   [Scheduled] [test-mac-arm](https://conbench.ursa.dev/compare/runs/b0692c73cf8b4937a09a67a466fe786b...1dc37a2cf3fa4d47921635a05bf8231f/)\n   [Scheduled] [ursa-i9-9960x](https://conbench.ursa.dev/compare/runs/dfc2f247f0e14ec9ab955e86bfa493ca...b3907fcd83144ec98d45ab5d6ab1cb9d/)\n   [Finished :arrow_down:0.35% :arrow_up:0.04%] [ursa-thinkcentre-m75q](https://conbench.ursa.dev/compare/runs/7cc5a85edd6c4086ac1b344aeab573ba...9f0fb694951d401db480e4eb55beca93/)\n   Supported benchmarks:\n   ec2-t3-xlarge-us-east-2: Supported benchmark langs: Python. Runs only benchmarks with cloud = True\n   test-mac-arm: Supported benchmark langs: C++, Python, R\n   ursa-i9-9960x: Supported benchmark langs: Python, R, JavaScript\n   ursa-thinkcentre-m75q: Supported benchmark langs: C++, Java\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-10T19:12:27.804+0000",
                    "updated": "2022-02-10T19:12:27.804+0000",
                    "started": "2022-02-10T19:12:27.804+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "724697",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/724847",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "ursabot edited a comment on pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#issuecomment-1034391503\n\n\n   Benchmark runs are scheduled for baseline = 2dfc60c1c921147d9032dd3694e256e1f20bfecd and contender = 401746bede014cf3d06a88930c282755f151a93b. 401746bede014cf3d06a88930c282755f151a93b is a master commit associated with this PR. Results will be available as each benchmark for each run completes.\n   Conbench compare runs links:\n   [Finished :arrow_down:0.0% :arrow_up:0.0%] [ec2-t3-xlarge-us-east-2](https://conbench.ursa.dev/compare/runs/af2f4533fc444e80acf5b192802bae61...8976ad62696e48ae9aa7157f22968ce6/)\n   [Finished :arrow_down:0.55% :arrow_up:0.04%] [test-mac-arm](https://conbench.ursa.dev/compare/runs/b0692c73cf8b4937a09a67a466fe786b...1dc37a2cf3fa4d47921635a05bf8231f/)\n   [Scheduled] [ursa-i9-9960x](https://conbench.ursa.dev/compare/runs/dfc2f247f0e14ec9ab955e86bfa493ca...b3907fcd83144ec98d45ab5d6ab1cb9d/)\n   [Finished :arrow_down:0.35% :arrow_up:0.04%] [ursa-thinkcentre-m75q](https://conbench.ursa.dev/compare/runs/7cc5a85edd6c4086ac1b344aeab573ba...9f0fb694951d401db480e4eb55beca93/)\n   Supported benchmarks:\n   ec2-t3-xlarge-us-east-2: Supported benchmark langs: Python. Runs only benchmarks with cloud = True\n   test-mac-arm: Supported benchmark langs: C++, Python, R\n   ursa-i9-9960x: Supported benchmark langs: Python, R, JavaScript\n   ursa-thinkcentre-m75q: Supported benchmark langs: C++, Java\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-10T23:32:22.785+0000",
                    "updated": "2022-02-10T23:32:22.785+0000",
                    "started": "2022-02-10T23:32:22.785+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "724847",
                    "issueId": "13419803"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/worklog/725226",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "ursabot edited a comment on pull request #12110:\nURL: https://github.com/apache/arrow/pull/12110#issuecomment-1034391503\n\n\n   Benchmark runs are scheduled for baseline = 2dfc60c1c921147d9032dd3694e256e1f20bfecd and contender = 401746bede014cf3d06a88930c282755f151a93b. 401746bede014cf3d06a88930c282755f151a93b is a master commit associated with this PR. Results will be available as each benchmark for each run completes.\n   Conbench compare runs links:\n   [Finished :arrow_down:0.0% :arrow_up:0.0%] [ec2-t3-xlarge-us-east-2](https://conbench.ursa.dev/compare/runs/af2f4533fc444e80acf5b192802bae61...8976ad62696e48ae9aa7157f22968ce6/)\n   [Finished :arrow_down:0.55% :arrow_up:0.04%] [test-mac-arm](https://conbench.ursa.dev/compare/runs/b0692c73cf8b4937a09a67a466fe786b...1dc37a2cf3fa4d47921635a05bf8231f/)\n   [Finished :arrow_down:1.43% :arrow_up:0.0%] [ursa-i9-9960x](https://conbench.ursa.dev/compare/runs/dfc2f247f0e14ec9ab955e86bfa493ca...b3907fcd83144ec98d45ab5d6ab1cb9d/)\n   [Finished :arrow_down:0.35% :arrow_up:0.04%] [ursa-thinkcentre-m75q](https://conbench.ursa.dev/compare/runs/7cc5a85edd6c4086ac1b344aeab573ba...9f0fb694951d401db480e4eb55beca93/)\n   Supported benchmarks:\n   ec2-t3-xlarge-us-east-2: Supported benchmark langs: Python. Runs only benchmarks with cloud = True\n   test-mac-arm: Supported benchmark langs: C++, Python, R\n   ursa-i9-9960x: Supported benchmark langs: Python, R, JavaScript\n   ursa-thinkcentre-m75q: Supported benchmark langs: C++, Java\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2022-02-11T15:31:56.672+0000",
                    "updated": "2022-02-11T15:31:56.672+0000",
                    "started": "2022-02-11T15:31:56.672+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "725226",
                    "issueId": "13419803"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 8400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@6bae0c36[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@51749bce[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3aef0ada[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@4fb05ca2[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@d8a5a90[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@77a0ce83[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@35dbb377[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@7843ac22[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@27c23760[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@56e731cd[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3e4f606d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@5b88f93a[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 8400,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Feb 10 01:25:53 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-02-10T01:25:53.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15212/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2021-12-29T03:15:00.000+0000",
        "updated": "2022-02-11T15:31:57.000+0000",
        "timeoriginalestimate": null,
        "description": "Adding suffix options for C++ hash joins.\u00a0",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "2h 20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 8400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Handle suffix argument in joins",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13419803/comment/17489903",
                    "id": "17489903",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 12110\n[https://github.com/apache/arrow/pull/12110]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-02-10T01:25:53.589+0000",
                    "updated": "2022-02-10T01:25:53.589+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0y3go:",
        "customfield_12314139": null
    }
}