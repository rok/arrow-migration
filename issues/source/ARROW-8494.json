{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13298953",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953",
    "key": "ARROW-8494",
    "fields": {
        "parent": {
            "id": "13107102",
            "key": "ARROW-1644",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13107102",
            "fields": {
                "summary": "[C++][Parquet] Read and write nested Parquet data with a mix of struct and list nesting levels",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                    "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                    "name": "Resolved",
                    "id": "5",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                        "id": 3,
                        "key": "done",
                        "colorName": "green",
                        "name": "Done"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                    "id": "2",
                    "description": "A new feature of the product, which has yet to be developed.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                    "name": "New Feature",
                    "subtask": false,
                    "avatarId": 21141
                }
            }
        },
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12345977",
                "id": "12345977",
                "description": "",
                "name": "2.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2020-10-19"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=emkornfield%40gmail.com",
            "name": "emkornfield@gmail.com",
            "key": "emkornfield@gmail.com",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Micah Kornfield",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=emkornfield%40gmail.com",
            "name": "emkornfield@gmail.com",
            "key": "emkornfield@gmail.com",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Micah Kornfield",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=emkornfield%40gmail.com",
            "name": "emkornfield@gmail.com",
            "key": "emkornfield@gmail.com",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Micah Kornfield",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 35400,
            "total": 35400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 35400,
            "total": 35400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8494/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 59,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/483609",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield opened a new pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177\n\n\n   Also: ARROW-9810 (generalize rep/def level conversion to list lengths/bitmaps)\r\n   \r\n   This adds helper methods for reconstructing all necessary metadata\r\n   for arrow types.  For now this doesn't handle null_slot_usage (i.e.\r\n   children of FixedSizeList), it throws exceptions when nulls are\r\n   encountered in this case.  It uses there for generic reconstruction.\r\n   \r\n   The unit tests demonstrate how to use the helper methods in combination\r\n   with LevelInfo (generated from parquet/arrow/schema.h) to reconstruct\r\n   the metadata.  The arrow reader.cc is now rewritten to use these method.\r\n   \r\n   - Refactors necessary APIs to use LevelInfo and makes use of them in\r\n     column_reader\r\n   - Adds implementations for reconstructing list validity bitmaps\r\n     (uses rep/def levels)\r\n   - Adds implementations for reconstruction list lengths\r\n    (uses rep/def levels.).\r\n   - Adds dynamic dispatch for level comparison algorithms for AVX2\r\n     and BMI2.\r\n   - Adds a pextract alternative that uses BitRunReader that can be\r\n     used as a fallback.\r\n   - Fixes some bugs in detailed reconstruction to array tests.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-13T04:59:58.622+0000",
                    "updated": "2020-09-13T04:59:58.622+0000",
                    "started": "2020-09-13T04:59:58.622+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "483609",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/483612",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#issuecomment-691614256\n\n\n   https://issues.apache.org/jira/browse/ARROW-8494\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-13T05:05:31.991+0000",
                    "updated": "2020-09-13T05:05:31.991+0000",
                    "started": "2020-09-13T05:05:31.991+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "483612",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/483613",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r487483180\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,169 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n-\n-#if !defined(ARROW_HAVE_AVX512)\n \n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info, int64_t* values_read,\n+                                    int64_t* null_count, uint8_t* valid_bits,\n+                                    int64_t valid_bits_offset) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      valid_bits,\n+      /*start_offset=*/valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      *null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n   *values_read = valid_bits_writer.position();\n+  if (*null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n+  }\n }\n #endif\n \n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-}\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n+        *lengths += 1;\n+      }\n+    } else {\n+      // current_rep < list rep_level i.e. start of a list (ancenstor empty lists are\n+      // filtered out above).\n+      if (lengths != nullptr) {\n+        ++lengths;\n+        *lengths = (def_levels[x] >= level_info.def_level) ? 1 : 0;\n\nReview comment:\n       we should consider doing the sume of the previous element here.  Originally I did not because I thought at some point getting raw lengths would make it easier to handled chunked_arrays in reader.cc but I think that case is esoteric enough that removing the need to touch this data twice will be better.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-13T05:21:43.662+0000",
                    "updated": "2020-09-13T05:21:43.662+0000",
                    "started": "2020-09-13T05:21:43.662+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "483613",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/483812",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r487690672\n\n\n\n##########\nFile path: python/pyarrow/tests/test_parquet.py\n##########\n@@ -692,14 +692,6 @@ def test_pandas_can_write_nested_data(tempdir):\n     # This succeeds under V2\n     _write_table(arrow_table, imos)\n \n-    # Under V1 it fails.\n\nReview comment:\n       this was meant for my other PR< I willl revert it.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-14T06:59:51.658+0000",
                    "updated": "2020-09-14T06:59:51.658+0000",
                    "started": "2020-09-14T06:59:51.658+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "483812",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484118",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488023655\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n\nReview comment:\n       Please make `validity_output` a `uint8_t` or a `uint8_t[1]`. We don't want to encourage endianness issues (I realize this wouldn't happen here because we don't actually test the value of `validity_output`?).\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -45,25 +49,26 @@ TEST(TestColumnReader, DefinitionLevelsToBitmap) {\n \n   std::vector<uint8_t> valid_bits(2, 0);\n \n-  const int max_def_level = 3;\n-  const int max_rep_level = 1;\n+  LevelInfo level_info;\n+  level_info.def_level = 3;\n+  level_info.rep_level = 1;\n\nReview comment:\n       For the record, is `rep_level` useful in this test?\n\n##########\nFile path: cpp/src/parquet/arrow/reconstruct_internal_test.cc\n##########\n@@ -884,12 +875,12 @@ TEST_F(TestReconstructColumn, FAILING(TwoLevelListOptional)) {\n // List-in-struct\n //\n \n-TEST_F(TestReconstructColumn, FAILING(NestedList1)) {\n+TEST_F(TestReconstructColumn, NestedList1) {\n   // Arrow schema: struct(a: list(int32 not null) not null) not null\n   SetParquetSchema(GroupNode::Make(\n-      \"a\", Repetition::REQUIRED,\n+      \"a\", Repetition::REQUIRED,  // this\n\nReview comment:\n       Hmm... is the comment pointing to some particular detail? It seems a bit cryptic.\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n\nReview comment:\n       I would add:\r\n   ```c++\r\n   #ifndef BMI_RUNTIME_VERSION\r\n   #error expecting BMI_RUNTIME_VERSION to be set\r\n   #endif\r\n   ```\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n\nReview comment:\n       Using `util::variant` isn't customary at all in the codebase. Can you simply just expose two separate signatures?\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n+        if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+          throw ParquetException(\"List index overflow.\");\n+        }\n+        *lengths += 1;\n+      }\n+    } else {\n+      // current_rep < list rep_level i.e. start of a list (ancenstor empty lists are\n\nReview comment:\n       \"ancestor\". Do you have a buggy automatic spell checker? :-)\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n+\n+/// Reconstructs a validity bitmap for a struct that has nested children.\n+void PARQUET_EXPORT ConvertDefRepLevelsToBitmap(const int16_t* def_levels,\n+                                                const int16_t* rep_levels,\n+                                                int64_t num_def_levels,\n+                                                LevelInfo level_info,\n+                                                ValidityBitmapInputOutput* output);\n+\n+uint64_t PARQUET_EXPORT RunBasedExtract(uint64_t bitmap, uint64_t selection);\n+\n+#if defined(ARROW_HAVE_RUNTIME_BMI2)\n+void PARQUET_EXPORT DefinitionLevelsToBitmapBmi2WithRepeatedParent(\n\nReview comment:\n       Hmm... does this need to be exposed here? Again, it's a bit confusing to have instruction set specific implementation details at this place.\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n\nReview comment:\n       I was a bit miffed here. Can `lengths` be  renamed `offsets`?\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n\nReview comment:\n       Hmm... is this supposed to be `EXPECT_EQ`? I'm curious why/how this line works.\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n\nReview comment:\n       FTR, you might want to write a helper method to factor out those 5 lines :-)\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n\nReview comment:\n       You mean 6, right?\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n\nReview comment:\n       Why are you allocating one more than byte than what will actually be written? Does `ConvertDefRepLevelsToList` write to the following byte? \n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n\nReview comment:\n       Should we write some nested tests where some of the list nodes are non-nullable (so the def levels would have less possible values)? This would make sure we catch more cases. Perhaps some refactoring is also desired in order to make the tests easier to write :-)\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n+\n+/// Reconstructs a validity bitmap for a struct that has nested children.\n+void PARQUET_EXPORT ConvertDefRepLevelsToBitmap(const int16_t* def_levels,\n+                                                const int16_t* rep_levels,\n+                                                int64_t num_def_levels,\n+                                                LevelInfo level_info,\n+                                                ValidityBitmapInputOutput* output);\n+\n+uint64_t PARQUET_EXPORT RunBasedExtract(uint64_t bitmap, uint64_t selection);\n\nReview comment:\n       Is it useful to expose this (looks like an internal implementation detail)? Add a comment?\n\n##########\nFile path: cpp/src/parquet/level_comparison.h\n##########\n@@ -0,0 +1,93 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <algorithm>\n+#include <cstdint>\n+\n+#include \"arrow/util/bit_util.h\"\n+#include \"parquet/platform.h\"\n+\n+namespace parquet {\n+namespace internal {\n+\n+// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n\nReview comment:\n       ARROW-8494 is this issue. Is the comment up-to-date?\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+namespace BMI_RUNTIME_VERSION {\n+\n+using ::arrow::internal::BitRun;\n+using ::arrow::internal::BitRunReader;\n+\n+/// Algorithm to simulate pext using BitRunReader for cases where all bits\n+/// not set or set.\n+uint64_t RunBasedExtractMixed(uint64_t bitmap, uint64_t select_bitmap) {\n+  bitmap = arrow::BitUtil::FromLittleEndian(bitmap);\n+  uint64_t new_bitmap = 0;\n+  ::arrow::internal::BitRunReader selection(reinterpret_cast<uint8_t*>(&select_bitmap),\n+                                            /*start_offset=*/0, /*length=*/64);\n+  ::arrow::internal::BitRun run = selection.NextRun();\n+  int64_t selected_bits = 0;\n+  while (run.length != 0) {\n+    if (run.set) {\n+      new_bitmap |= (bitmap & ::arrow::BitUtil::LeastSignficantBitMask(run.length))\n\nReview comment:\n       Typo: \"Significant\"\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n\nReview comment:\n       \"ancestor\", \"further\"\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n+\n+TYPED_TEST(NestedListTest, SimpleLongList) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>(65 * 9, 2);\n+  this->test_data_.rep_levels_.clear();\n+  for (int x = 0; x < 65; x++) {\n+    this->test_data_.rep_levels_.push_back(0);\n+    this->test_data_.rep_levels_.insert(this->test_data_.rep_levels_.end(), 8,\n+                                        /*rep_level=*/1);\n+  }\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(66, 0);\n+  std::vector<typename TypeParam::ListLengthType> expected_lengths(66, 0);\n+  for (size_t x = 1; x < expected_lengths.size(); x++) {\n+    expected_lengths[x] = x * 9;\n+  }\n+  std::vector<uint8_t> validity_output(9, 0);\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 65;\n+  validity_io.valid_bits = validity_output.data();\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 65);\n+  EXPECT_THAT(lengths, testing::ElementsAreArray(expected_lengths));\n+\n+  EXPECT_EQ(validity_io.values_read, 65);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/65),\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"1\");\n+}\n+\n+TYPED_TEST(NestedListTest, TestOverflow) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>{2};\n+  this->test_data_.rep_levels_ = std::vector<int16_t>{0};\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(\n+      2, std::numeric_limits<typename TypeParam::ListLengthType>::max());\n\nReview comment:\n       Hmm... `lengths` is an output parameter, right? Why does it change something to initialize it at a large value?\n\n##########\nFile path: cpp/src/parquet/level_comparison.h\n##########\n@@ -0,0 +1,93 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <algorithm>\n+#include <cstdint>\n+\n+#include \"arrow/util/bit_util.h\"\n+#include \"parquet/platform.h\"\n+\n+namespace parquet {\n+namespace internal {\n+\n+// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n+// They currently represent minimal functionality for vectorized computation of definition\n+// levels.\n+\n+/// Builds a bitmap by applying predicate to the level vector provided.\n+///\n+/// \\param[in] levels Rep or def level array.\n+/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n+/// \\param[in] predicate The predicate to apply (must have the signature `bool\n+/// predicate(int16_t)`.\n+/// \\returns The bitmap using least significant \"bit\" ordering.\n+///\n+/// N.B. Correct byte ordering is dependent on little-endian architectures.\n+///\n+template <typename Predicate>\n+inline uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels,\n+                               Predicate predicate) {\n+  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n+  uint64_t mask = 0;\n+  for (int x = 0; x < num_levels; x++) {\n+    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n+  }\n+  return ::arrow::BitUtil::ToLittleEndian(mask);\n+}\n+\n+/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n+/// than rhs.\n+uint64_t PARQUET_EXPORT GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n+                                          int16_t rhs);\n+\n+#if defined(ARROW_HAVE_RUNTIME_AVX2)\n+uint64_t GreaterThanBitmapAvx2(const int16_t* levels, int64_t num_levels, int16_t rhs);\n+#endif\n+\n+struct MinMax {\n+  int16_t min;\n+  int16_t max;\n+};\n+\n+MinMax FindMinMax(const int16_t* levels, int64_t num_levels);\n+\n+#if defined(ARROW_HAVE_RUNTIME_AVX2)\n+MinMax FindMinMaxAvx2(const int16_t* levels, int64_t num_levels);\n+#endif\n+\n+// Used to make sure ODR rule isn't violated.\n+namespace IMPL_NAMESPACE {\n\nReview comment:\n       Hmm, can we normalize this? Elsewhere it's `BMI_RUNTIME_VERSION`. Also, make sure this macro is actually defined?\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n\nReview comment:\n       Please avoid triple-slash comments, they are for Doxygen docstrings.\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n\nReview comment:\n       Can you add this kind of boilerplate in `arrow/util/simd.h` instead?\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -19,6 +19,9 @@\n \n #include <cstdint>\n \n+#include \"arrow/util/bitmap.h\"\n+#include \"arrow/util/optional.h\"\n\nReview comment:\n       Is `optional` used here?\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+namespace BMI_RUNTIME_VERSION {\n+\n+using ::arrow::internal::BitRun;\n+using ::arrow::internal::BitRunReader;\n\nReview comment:\n       You're `using` them but still using the full qualified names below :-)\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n+\n+/// Reconstructs a validity bitmap for a struct that has nested children.\n\nReview comment:\n       Why \"that has nested children\"? The fact that it has nested children shouldn't make a difference, right?\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n+\n+TYPED_TEST(NestedListTest, SimpleLongList) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>(65 * 9, 2);\n+  this->test_data_.rep_levels_.clear();\n+  for (int x = 0; x < 65; x++) {\n+    this->test_data_.rep_levels_.push_back(0);\n+    this->test_data_.rep_levels_.insert(this->test_data_.rep_levels_.end(), 8,\n+                                        /*rep_level=*/1);\n+  }\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(66, 0);\n+  std::vector<typename TypeParam::ListLengthType> expected_lengths(66, 0);\n+  for (size_t x = 1; x < expected_lengths.size(); x++) {\n+    expected_lengths[x] = x * 9;\n+  }\n+  std::vector<uint8_t> validity_output(9, 0);\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 65;\n+  validity_io.valid_bits = validity_output.data();\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 65);\n+  EXPECT_THAT(lengths, testing::ElementsAreArray(expected_lengths));\n+\n+  EXPECT_EQ(validity_io.values_read, 65);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/65),\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"1\");\n+}\n+\n+TYPED_TEST(NestedListTest, TestOverflow) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>{2};\n+  this->test_data_.rep_levels_ = std::vector<int16_t>{0};\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(\n+      2, std::numeric_limits<typename TypeParam::ListLengthType>::max());\n+\n+  std::vector<uint8_t> validity_output(1, 0);\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 1;\n+  validity_io.valid_bits = validity_output.data();\n+  ASSERT_THROW(this->converter_.ComputeListInfo(this->test_data_, level_info,\n+                                                &validity_io, lengths.data()),\n+               ParquetException);\n+\n+  // Same thing should happen if the list already existed.\n+  this->test_data_.rep_levels_ = std::vector<int16_t>{1};\n+  ASSERT_THROW(this->converter_.ComputeListInfo(this->test_data_, level_info,\n+                                                &validity_io, lengths.data()),\n+               ParquetException);\n+\n+  // Should be OK because it shouldn't increment.\n+  this->test_data_.def_levels_ = std::vector<int16_t>{0};\n\nReview comment:\n       Is there any point in doing this at the end of the test?\n\n##########\nFile path: cpp/cmake_modules/SetupCxxFlags.cmake\n##########\n@@ -50,7 +50,7 @@ if(ARROW_CPU_FLAG STREQUAL \"x86\")\n     # skylake-avx512 consists of AVX512F,AVX512BW,AVX512VL,AVX512CD,AVX512DQ\n     set(ARROW_AVX512_FLAG \"-march=skylake-avx512 -mbmi2\")\n     # Append the avx2/avx512 subset option also, fix issue ARROW-9877 for homebrew-cpp\n-    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2\")\n+    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2 -mbmi2\")\n\nReview comment:\n       Isn't this risky? The compiler might select BMI2 instructions, even though the CPU may not actually support it?\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n\nReview comment:\n       Perhaps note that exceeding this number means the Parquet levels are corrupt?\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n\nReview comment:\n       The variations in terminology confuse me a lot. There's \"DefinitionLevelsToBitmap\" and \"ConvertDefRepLevelsToBitmap\". Can we settle on a clear naming scheme, so that it's apparent what the actual differences are?\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n\nReview comment:\n       Why `>` and not `>=`?\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n\nReview comment:\n       Input only?\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n\nReview comment:\n       Add a comment?\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n+        if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+          throw ParquetException(\"List index overflow.\");\n+        }\n+        *lengths += 1;\n+      }\n+    } else {\n+      // current_rep < list rep_level i.e. start of a list (ancenstor empty lists are\n+      // filtered out above).\n+      if (lengths != nullptr) {\n+        ++lengths;\n+        // Use cumulative lengths because this is what the more common\n+        // Arrow list types expect.\n+        *lengths = *(lengths - 1);\n+        if (def_levels[x] >= level_info.def_level) {\n+          if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+            throw ParquetException(\"List index overflow.\");\n+          }\n+          *lengths += 1;\n+        }\n+      }\n \n-  } else {\n-    // No BMI2 intsturctions are used for non-repeated case.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/false>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n+      if (valid_bits_writer != nullptr) {\n+        // the level_info def level for lists reflects element present level.\n+        // the prior level distinguishes between empty lists.\n+        if (def_levels[x] >= level_info.def_level - 1) {\n+          valid_bits_writer->Set();\n+        } else {\n+          output->null_count++;\n+          valid_bits_writer->Clear();\n+        }\n+        valid_bits_writer->Next();\n+      }\n+    }\n+  }\n+  if (valid_bits_writer != nullptr) {\n+    valid_bits_writer->Finish();\n+  }\n+  if (lengths != nullptr) {\n+    output->values_read = lengths - orig_pos;\n+  } else if (valid_bits_writer != nullptr) {\n+    output->values_read = valid_bits_writer->position();\n+  }\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported)\");\n   }\n }\n \n }  // namespace\n \n void DefinitionLevelsToBitmap(const int16_t* def_levels, int64_t num_def_levels,\n-                              const int16_t max_definition_level,\n-                              const int16_t max_repetition_level, int64_t* values_read,\n-                              int64_t* null_count, uint8_t* valid_bits,\n-                              int64_t valid_bits_offset) {\n-#if ARROW_LITTLE_ENDIAN\n-  DefinitionLevelsToBitmapLittleEndian(def_levels, num_def_levels, max_definition_level,\n-                                       max_repetition_level, values_read, null_count,\n-                                       valid_bits, valid_bits_offset);\n-\n+                              LevelInfo level_info, ValidityBitmapInputOutput* output) {\n+  if (level_info.rep_level > 0) {\n+#if defined(ARROW_HAVE_RUNTIME_BMI2)\n+    using FunctionType = decltype(&standard::DefinitionLevelsToBitmapSimd<true>);\n+    static FunctionType fn =\n+        CpuInfo::GetInstance()->HasEfficientBmi2()\n+            ? DefinitionLevelsToBitmapBmi2WithRepeatedParent\n+            : standard::DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>;\n+    fn(def_levels, num_def_levels, level_info, output);\n #else\n-  DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                 max_repetition_level, values_read, null_count,\n-                                 valid_bits, valid_bits_offset);\n+    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, level_info, output);\n\nReview comment:\n       Why isn't this calling `DefinitionLevelsToBitmapSimd<true>` as above instead?\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n\nReview comment:\n       Is there a reason we allow passing `nullptr` for `lengths` (which should be `offsets`?)\n\n##########\nFile path: cpp/src/parquet/CMakeLists.txt\n##########\n@@ -202,6 +203,19 @@ set(PARQUET_SRCS\n     stream_writer.cc\n     types.cc)\n \n+if(CXX_SUPPORTS_AVX2)\n+  # AVX2 is used as a proxy for BMI2.\n\nReview comment:\n       Does it cost much to add a separate `CXX_SUPPORTS_BMI2`?\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n+        if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+          throw ParquetException(\"List index overflow.\");\n+        }\n+        *lengths += 1;\n+      }\n+    } else {\n+      // current_rep < list rep_level i.e. start of a list (ancenstor empty lists are\n+      // filtered out above).\n+      if (lengths != nullptr) {\n+        ++lengths;\n+        // Use cumulative lengths because this is what the more common\n\nReview comment:\n       I don't understand the \"more common\" comment. Do some Arrow list types have non-cumulative lengths?\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+namespace BMI_RUNTIME_VERSION {\n+\n+using ::arrow::internal::BitRun;\n+using ::arrow::internal::BitRunReader;\n+\n+/// Algorithm to simulate pext using BitRunReader for cases where all bits\n+/// not set or set.\n+uint64_t RunBasedExtractMixed(uint64_t bitmap, uint64_t select_bitmap) {\n+  bitmap = arrow::BitUtil::FromLittleEndian(bitmap);\n+  uint64_t new_bitmap = 0;\n+  ::arrow::internal::BitRunReader selection(reinterpret_cast<uint8_t*>(&select_bitmap),\n+                                            /*start_offset=*/0, /*length=*/64);\n+  ::arrow::internal::BitRun run = selection.NextRun();\n+  int64_t selected_bits = 0;\n+  while (run.length != 0) {\n+    if (run.set) {\n+      new_bitmap |= (bitmap & ::arrow::BitUtil::LeastSignficantBitMask(run.length))\n+                    << selected_bits;\n+      selected_bits += run.length;\n+    }\n+    bitmap = bitmap >> run.length;\n+    run = selection.NextRun();\n+  }\n+  return arrow::BitUtil::ToLittleEndian(new_bitmap);\n+}\n+\n+inline uint64_t RunBasedExtractImpl(uint64_t bitmap, uint64_t select_bitmap) {\n+  /// These checks should be inline and are likely to be common cases.\n+  if (select_bitmap == ~uint64_t{0}) {\n+    return bitmap;\n+  } else if (select_bitmap == 0) {\n+    return 0;\n+  }\n+  /// Fallback to the slow method.\n+  return RunBasedExtractMixed(bitmap, select_bitmap);\n+}\n+\n+inline uint64_t ExtractBits(uint64_t bitmap, uint64_t select_bitmap) {\n+#if defined(ARROW_HAVE_BMI2) && !defined(__MINGW32__)\n+  return _pext_u64(bitmap, select_bitmap);\n+#else\n+  return RunBasedExtractImpl(bitmap, select_bitmap);\n+#endif\n+}\n+\n+template <bool has_repeated_parent>\n+int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n+                                      int64_t upper_bound_remaining, LevelInfo level_info,\n+                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n+  // Greater than level_info.def_level - 1 implies >= the def_level\n+  uint64_t defined_bitmap =\n+      internal::GreaterThanBitmap(def_levels, batch_size, level_info.def_level - 1);\n+\n+  DCHECK_LE(batch_size, 64);\n+  if (has_repeated_parent) {\n+    // Greater than level_info.repeated_ancestor_def_level - 1 implies >= the\n+    // repeated_ancenstor_def_level\n+    uint64_t present_bitmap = internal::GreaterThanBitmap(\n+        def_levels, batch_size, level_info.repeated_ancestor_def_level - 1);\n+    uint64_t selected_bits = ExtractBits(defined_bitmap, present_bitmap);\n\nReview comment:\n       FTR, I think that if BMI isn't available, you can still use a batch size of 5 or 6 bits and use a fast lookup table for ExtractBits (rather than the probably slow emulation code).\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n\nReview comment:\n       Also, call it `offsets` (do this everywhere it applies)\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n\nReview comment:\n       Also, perhaps \"empty or null\" rather than \"empty\"?\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n\nReview comment:\n       Also, in many cases `repeated_ancestor_def_level`, in which case we should simply use `GreaterThan`?\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n+\n+/// Reconstructs a validity bitmap for a struct that has nested children.\n\nReview comment:\n       Or you mean \"nested list children and/or ancestor lists\"? Nested struct children are indifferent, AFAICT.\n\n##########\nFile path: cpp/src/parquet/level_comparison.h\n##########\n@@ -0,0 +1,93 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <algorithm>\n+#include <cstdint>\n+\n+#include \"arrow/util/bit_util.h\"\n+#include \"parquet/platform.h\"\n+\n+namespace parquet {\n+namespace internal {\n+\n+// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n+// They currently represent minimal functionality for vectorized computation of definition\n+// levels.\n+\n+/// Builds a bitmap by applying predicate to the level vector provided.\n+///\n+/// \\param[in] levels Rep or def level array.\n+/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n+/// \\param[in] predicate The predicate to apply (must have the signature `bool\n+/// predicate(int16_t)`.\n+/// \\returns The bitmap using least significant \"bit\" ordering.\n+///\n+/// N.B. Correct byte ordering is dependent on little-endian architectures.\n+///\n+template <typename Predicate>\n+inline uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels,\n+                               Predicate predicate) {\n+  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n+  uint64_t mask = 0;\n+  for (int x = 0; x < num_levels; x++) {\n+    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n+  }\n+  return ::arrow::BitUtil::ToLittleEndian(mask);\n+}\n+\n+/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n+/// than rhs.\n+uint64_t PARQUET_EXPORT GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n+                                          int16_t rhs);\n+\n+#if defined(ARROW_HAVE_RUNTIME_AVX2)\n+uint64_t GreaterThanBitmapAvx2(const int16_t* levels, int64_t num_levels, int16_t rhs);\n+#endif\n+\n+struct MinMax {\n+  int16_t min;\n+  int16_t max;\n+};\n+\n+MinMax FindMinMax(const int16_t* levels, int64_t num_levels);\n+\n+#if defined(ARROW_HAVE_RUNTIME_AVX2)\n+MinMax FindMinMaxAvx2(const int16_t* levels, int64_t num_levels);\n+#endif\n+\n+// Used to make sure ODR rule isn't violated.\n+namespace IMPL_NAMESPACE {\n\nReview comment:\n       (perhaps `PARQUET_IMPL_NAMESPACE`)\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n\nReview comment:\n       Also, I suppose this wouldn't work if the ancestor list is a fixed size list, right?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-14T17:19:06.403+0000",
                    "updated": "2020-09-14T17:19:06.403+0000",
                    "started": "2020-09-14T17:19:06.403+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484118",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484119",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#issuecomment-692196443\n\n\n   Are there any benchmarks worth running here?\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-14T17:19:19.950+0000",
                    "updated": "2020-09-14T17:19:19.950+0000",
                    "started": "2020-09-14T17:19:19.950+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484119",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484127",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488084615\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n\nReview comment:\n       Also, in many cases `repeated_ancestor_def_level` would be 0, in which case we should simply use `GreaterThan`?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-14T17:28:07.318+0000",
                    "updated": "2020-09-14T17:28:07.318+0000",
                    "started": "2020-09-14T17:28:07.318+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484127",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484317",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#issuecomment-692494602\n\n\n   > Ok, thanks a lot for this PR. I think I am understanding the implementation (I skipped parquet/arrow/reader.cc for now, though). Some of the implementation details are still confusing me a bit. In any case, here are some comments.\r\n   \r\n   Please let me know if there is more confusion, I will attempt to add clarifying comments.  I think I addressed all your comments except for some in level_conversion_test.cc I'll address those tomorrow (I assume there will be more comments in reader.cc as well).\r\n   \r\n   > Are there any benchmarks worth running here?\r\n   \r\n   parquet-level-conversion-benchmark\r\n   parquet-arrow-reader-writer-benchmark (this won't cover the nested cases though)  There is an open JIRA under ARROW-1644 to add benchmarks for nested cases @npr mentioned there might be some example datasets that we wanted to try this on.\r\n   \r\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T06:25:42.089+0000",
                    "updated": "2020-09-15T06:25:42.089+0000",
                    "started": "2020-09-15T06:25:42.089+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484317",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484613",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488807129\n\n\n\n##########\nFile path: cpp/cmake_modules/SetupCxxFlags.cmake\n##########\n@@ -50,7 +50,7 @@ if(ARROW_CPU_FLAG STREQUAL \"x86\")\n     # skylake-avx512 consists of AVX512F,AVX512BW,AVX512VL,AVX512CD,AVX512DQ\n     set(ARROW_AVX512_FLAG \"-march=skylake-avx512 -mbmi2\")\n     # Append the avx2/avx512 subset option also, fix issue ARROW-9877 for homebrew-cpp\n-    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2\")\n+    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2 -mbmi2\")\n\nReview comment:\n       What is your opinion on this @emkornfield ?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:37:18.449+0000",
                    "updated": "2020-09-15T16:37:18.449+0000",
                    "started": "2020-09-15T16:37:18.449+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484613",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484617",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488809108\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n+\n+TYPED_TEST(NestedListTest, SimpleLongList) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>(65 * 9, 2);\n+  this->test_data_.rep_levels_.clear();\n+  for (int x = 0; x < 65; x++) {\n+    this->test_data_.rep_levels_.push_back(0);\n+    this->test_data_.rep_levels_.insert(this->test_data_.rep_levels_.end(), 8,\n+                                        /*rep_level=*/1);\n+  }\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(66, 0);\n+  std::vector<typename TypeParam::ListLengthType> expected_lengths(66, 0);\n+  for (size_t x = 1; x < expected_lengths.size(); x++) {\n+    expected_lengths[x] = x * 9;\n+  }\n+  std::vector<uint8_t> validity_output(9, 0);\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 65;\n+  validity_io.valid_bits = validity_output.data();\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 65);\n+  EXPECT_THAT(lengths, testing::ElementsAreArray(expected_lengths));\n+\n+  EXPECT_EQ(validity_io.values_read, 65);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/65),\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"1\");\n+}\n+\n+TYPED_TEST(NestedListTest, TestOverflow) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>{2};\n+  this->test_data_.rep_levels_ = std::vector<int16_t>{0};\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(\n+      2, std::numeric_limits<typename TypeParam::ListLengthType>::max());\n\nReview comment:\n       Ah, I understand, offsets will be computed by adding to the first one... can you add a comment?\r\n   \n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:40:37.888+0000",
                    "updated": "2020-09-15T16:40:37.888+0000",
                    "started": "2020-09-15T16:40:37.888+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484617",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484618",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488810069\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n\nReview comment:\n       Ping here.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:42:11.748+0000",
                    "updated": "2020-09-15T16:42:11.748+0000",
                    "started": "2020-09-15T16:42:11.748+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484618",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484620",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488810195\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n\nReview comment:\n       Not sure what you think about this?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:42:28.448+0000",
                    "updated": "2020-09-15T16:42:28.448+0000",
                    "started": "2020-09-15T16:42:28.448+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484620",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484621",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488810630\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+namespace BMI_RUNTIME_VERSION {\n+\n+using ::arrow::internal::BitRun;\n+using ::arrow::internal::BitRunReader;\n+\n+/// Algorithm to simulate pext using BitRunReader for cases where all bits\n+/// not set or set.\n+uint64_t RunBasedExtractMixed(uint64_t bitmap, uint64_t select_bitmap) {\n+  bitmap = arrow::BitUtil::FromLittleEndian(bitmap);\n+  uint64_t new_bitmap = 0;\n+  ::arrow::internal::BitRunReader selection(reinterpret_cast<uint8_t*>(&select_bitmap),\n+                                            /*start_offset=*/0, /*length=*/64);\n+  ::arrow::internal::BitRun run = selection.NextRun();\n+  int64_t selected_bits = 0;\n+  while (run.length != 0) {\n+    if (run.set) {\n+      new_bitmap |= (bitmap & ::arrow::BitUtil::LeastSignficantBitMask(run.length))\n\nReview comment:\n       Thanks for the JIRA.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:43:01.779+0000",
                    "updated": "2020-09-15T16:43:01.779+0000",
                    "started": "2020-09-15T16:43:01.779+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484621",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484622",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488810907\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/simd.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+#ifndef PARQUET_IMPL_NAMESPACE\n+#error \"PARQUET_IMPL_NAMESPACE must be defined\"\n+#endif\n+namespace PARQUET_IMPL_NAMESPACE {\n+\n+/// Algorithm to simulate pext using BitRunReader for cases where all bits\n+/// not set or set.\n+uint64_t RunBasedExtractMixed(uint64_t bitmap, uint64_t select_bitmap) {\n+  bitmap = arrow::BitUtil::FromLittleEndian(bitmap);\n+  uint64_t new_bitmap = 0;\n+  ::arrow::internal::BitRunReader selection(reinterpret_cast<uint8_t*>(&select_bitmap),\n+                                            /*start_offset=*/0, /*length=*/64);\n+  ::arrow::internal::BitRun run = selection.NextRun();\n+  int64_t selected_bits = 0;\n+  while (run.length != 0) {\n+    if (run.set) {\n+      new_bitmap |= (bitmap & ::arrow::BitUtil::LeastSignficantBitMask(run.length))\n+                    << selected_bits;\n+      selected_bits += run.length;\n+    }\n+    bitmap = bitmap >> run.length;\n+    run = selection.NextRun();\n+  }\n+  return arrow::BitUtil::ToLittleEndian(new_bitmap);\n+}\n+\n+inline uint64_t RunBasedExtractImpl(uint64_t bitmap, uint64_t select_bitmap) {\n+  /// These checks should be inline and are likely to be common cases.\n+  if (select_bitmap == ~uint64_t{0}) {\n+    return bitmap;\n+  } else if (select_bitmap == 0) {\n+    return 0;\n+  }\n+  /// Fallback to the slow method.\n+  return RunBasedExtractMixed(bitmap, select_bitmap);\n+}\n+\n+inline uint64_t ExtractBits(uint64_t bitmap, uint64_t select_bitmap) {\n+#if defined(ARROW_HAVE_BMI2) && !defined(__MINGW32__)\n\nReview comment:\n       Comment why mingw is left out?\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,139 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/simd.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+#ifndef PARQUET_IMPL_NAMESPACE\n+#error \"PARQUET_IMPL_NAMESPACE must be defined\"\n+#endif\n+namespace PARQUET_IMPL_NAMESPACE {\n+\n+/// Algorithm to simulate pext using BitRunReader for cases where all bits\n+/// not set or set.\n+uint64_t RunBasedExtractMixed(uint64_t bitmap, uint64_t select_bitmap) {\n+  bitmap = arrow::BitUtil::FromLittleEndian(bitmap);\n+  uint64_t new_bitmap = 0;\n+  ::arrow::internal::BitRunReader selection(reinterpret_cast<uint8_t*>(&select_bitmap),\n+                                            /*start_offset=*/0, /*length=*/64);\n+  ::arrow::internal::BitRun run = selection.NextRun();\n+  int64_t selected_bits = 0;\n+  while (run.length != 0) {\n+    if (run.set) {\n+      new_bitmap |= (bitmap & ::arrow::BitUtil::LeastSignficantBitMask(run.length))\n+                    << selected_bits;\n+      selected_bits += run.length;\n+    }\n+    bitmap = bitmap >> run.length;\n+    run = selection.NextRun();\n+  }\n+  return arrow::BitUtil::ToLittleEndian(new_bitmap);\n+}\n+\n+inline uint64_t RunBasedExtractImpl(uint64_t bitmap, uint64_t select_bitmap) {\n+  /// These checks should be inline and are likely to be common cases.\n+  if (select_bitmap == ~uint64_t{0}) {\n+    return bitmap;\n+  } else if (select_bitmap == 0) {\n+    return 0;\n+  }\n+  /// Fallback to the slow method.\n+  return RunBasedExtractMixed(bitmap, select_bitmap);\n+}\n+\n+inline uint64_t ExtractBits(uint64_t bitmap, uint64_t select_bitmap) {\n+#if defined(ARROW_HAVE_BMI2) && !defined(__MINGW32__)\n\nReview comment:\n       Comment why MinGW is left out?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:43:45.166+0000",
                    "updated": "2020-09-15T16:43:45.166+0000",
                    "started": "2020-09-15T16:43:45.166+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484622",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484623",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488812521\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,44 +135,65 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  // Input only.\n+  // The maximum number of values_read expected (actual\n+  // values read must be less than or equal to this value.\n+  // If this number is exceeded methods will throw a\n+  // ParquetException. Exceeding this limit indicates\n+  // either a corrupt or incorrectly written file.\n+  int64_t values_read_upper_bound = 0;\n+  // Output only. The number of values added to the encountered\n+  // (this is logicallyt he count of the number of elements\n+  // for an Arrow array).\n+  int64_t values_read = 0;\n+  // Input/Output. The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // Output only. The validity bitmap to populate. May be be null only\n+  // for DefRepLevelsToListInfo (if all that is needed is list offsets).\n+  uint8_t* valid_bits = NULLPTR;\n+  // Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n-#endif\n+//  Converts def_levels to validity bitmaps for non-list arrays and structs that have\n+//  at least one member that is not a list and has no list descendents.\n+//  For lists use DefRepLevelsToList and structs where all descendants contain\n+//  a list use DefRepLevelsToBitmap.\n\nReview comment:\n       Fun :-)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:46:08.896+0000",
                    "updated": "2020-09-15T16:46:08.896+0000",
                    "started": "2020-09-15T16:46:08.895+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484623",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484624",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488812914\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,44 +135,65 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  // Input only.\n+  // The maximum number of values_read expected (actual\n+  // values read must be less than or equal to this value.\n+  // If this number is exceeded methods will throw a\n+  // ParquetException. Exceeding this limit indicates\n+  // either a corrupt or incorrectly written file.\n+  int64_t values_read_upper_bound = 0;\n+  // Output only. The number of values added to the encountered\n+  // (this is logicallyt he count of the number of elements\n+  // for an Arrow array).\n+  int64_t values_read = 0;\n+  // Input/Output. The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // Output only. The validity bitmap to populate. May be be null only\n+  // for DefRepLevelsToListInfo (if all that is needed is list offsets).\n+  uint8_t* valid_bits = NULLPTR;\n+  // Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n-#endif\n+//  Converts def_levels to validity bitmaps for non-list arrays and structs that have\n+//  at least one member that is not a list and has no list descendents.\n+//  For lists use DefRepLevelsToList and structs where all descendants contain\n+//  a list use DefRepLevelsToBitmap.\n+void PARQUET_EXPORT DefLevelsToBitmap(const int16_t* def_levels, int64_t num_def_levels,\n+                                      LevelInfo level_info,\n+                                      ValidityBitmapInputOutput* output);\n+\n+// Reconstructs a validity bitmap and list offsets for a list arrays based on\n+// def/rep levels. The first element of offsets will not be modified if rep_levels\n+// starts with a new list.  The first element of offsets will be used when calculating\n+// the next offset.  See documentation onf DefLevelsToBitmap for when to use this\n+// method vs the other ones in this file for reconstruction.\n+//\n+// Offsets must be size to 1 + values_read_upper_bound.\n\nReview comment:\n       Great comments, thank you.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:46:52.172+0000",
                    "updated": "2020-09-15T16:46:52.172+0000",
                    "started": "2020-09-15T16:46:52.172+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484624",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484625",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488813253\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -19,6 +19,7 @@\n \n #include <cstdint>\n \n+#include \"arrow/util/bitmap.h\"\n\nReview comment:\n       Looks like this include is not used after all?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:47:25.456+0000",
                    "updated": "2020-09-15T16:47:25.456+0000",
                    "started": "2020-09-15T16:47:25.456+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484625",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484628",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488365834\n\n\n\n##########\nFile path: cpp/src/parquet/arrow/reconstruct_internal_test.cc\n##########\n@@ -884,12 +875,12 @@ TEST_F(TestReconstructColumn, FAILING(TwoLevelListOptional)) {\n // List-in-struct\n //\n \n-TEST_F(TestReconstructColumn, FAILING(NestedList1)) {\n+TEST_F(TestReconstructColumn, NestedList1) {\n   // Arrow schema: struct(a: list(int32 not null) not null) not null\n   SetParquetSchema(GroupNode::Make(\n-      \"a\", Repetition::REQUIRED,\n+      \"a\", Repetition::REQUIRED,  // this\n\nReview comment:\n       sorry. removed.\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -45,25 +49,26 @@ TEST(TestColumnReader, DefinitionLevelsToBitmap) {\n \n   std::vector<uint8_t> valid_bits(2, 0);\n \n-  const int max_def_level = 3;\n-  const int max_rep_level = 1;\n+  LevelInfo level_info;\n+  level_info.def_level = 3;\n+  level_info.rep_level = 1;\n\nReview comment:\n       Yes.  I added a comment about this in level_conversion.cc. \r\n   \r\n   > // It is simpler to rely on rep_level here until PARQUET-1899 is done and the code\r\n   172  is deleted in a follow-up release.\r\n   \r\n   Once this is cleaned up it is not required.\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n+\n+TYPED_TEST(NestedListTest, SimpleLongList) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>(65 * 9, 2);\n+  this->test_data_.rep_levels_.clear();\n+  for (int x = 0; x < 65; x++) {\n+    this->test_data_.rep_levels_.push_back(0);\n+    this->test_data_.rep_levels_.insert(this->test_data_.rep_levels_.end(), 8,\n+                                        /*rep_level=*/1);\n+  }\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(66, 0);\n+  std::vector<typename TypeParam::ListLengthType> expected_lengths(66, 0);\n+  for (size_t x = 1; x < expected_lengths.size(); x++) {\n+    expected_lengths[x] = x * 9;\n+  }\n+  std::vector<uint8_t> validity_output(9, 0);\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 65;\n+  validity_io.valid_bits = validity_output.data();\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 65);\n+  EXPECT_THAT(lengths, testing::ElementsAreArray(expected_lengths));\n+\n+  EXPECT_EQ(validity_io.values_read, 65);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/65),\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"1\");\n+}\n+\n+TYPED_TEST(NestedListTest, TestOverflow) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>{2};\n+  this->test_data_.rep_levels_ = std::vector<int16_t>{0};\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(\n+      2, std::numeric_limits<typename TypeParam::ListLengthType>::max());\n\nReview comment:\n       its input/output I clarified in the declaration.\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n+\n+TYPED_TEST(NestedListTest, SimpleLongList) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>(65 * 9, 2);\n+  this->test_data_.rep_levels_.clear();\n+  for (int x = 0; x < 65; x++) {\n+    this->test_data_.rep_levels_.push_back(0);\n+    this->test_data_.rep_levels_.insert(this->test_data_.rep_levels_.end(), 8,\n+                                        /*rep_level=*/1);\n+  }\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(66, 0);\n+  std::vector<typename TypeParam::ListLengthType> expected_lengths(66, 0);\n+  for (size_t x = 1; x < expected_lengths.size(); x++) {\n+    expected_lengths[x] = x * 9;\n+  }\n+  std::vector<uint8_t> validity_output(9, 0);\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 65;\n+  validity_io.valid_bits = validity_output.data();\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 65);\n+  EXPECT_THAT(lengths, testing::ElementsAreArray(expected_lengths));\n+\n+  EXPECT_EQ(validity_io.values_read, 65);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/65),\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"11111111 \"\n+            \"1\");\n+}\n+\n+TYPED_TEST(NestedListTest, TestOverflow) {\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+  level_info.repeated_ancestor_def_level = 0;\n+\n+  // No empty lists.\n+  this->test_data_.def_levels_ = std::vector<int16_t>{2};\n+  this->test_data_.rep_levels_ = std::vector<int16_t>{0};\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(\n+      2, std::numeric_limits<typename TypeParam::ListLengthType>::max());\n+\n+  std::vector<uint8_t> validity_output(1, 0);\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 1;\n+  validity_io.valid_bits = validity_output.data();\n+  ASSERT_THROW(this->converter_.ComputeListInfo(this->test_data_, level_info,\n+                                                &validity_io, lengths.data()),\n+               ParquetException);\n+\n+  // Same thing should happen if the list already existed.\n+  this->test_data_.rep_levels_ = std::vector<int16_t>{1};\n+  ASSERT_THROW(this->converter_.ComputeListInfo(this->test_data_, level_info,\n+                                                &validity_io, lengths.data()),\n+               ParquetException);\n+\n+  // Should be OK because it shouldn't increment.\n+  this->test_data_.def_levels_ = std::vector<int16_t>{0};\n\nReview comment:\n       I missed adding in the test to veriy this doesn't throw.\n\n##########\nFile path: cpp/src/parquet/CMakeLists.txt\n##########\n@@ -202,6 +203,19 @@ set(PARQUET_SRCS\n     stream_writer.cc\n     types.cc)\n \n+if(CXX_SUPPORTS_AVX2)\n+  # AVX2 is used as a proxy for BMI2.\n\nReview comment:\n       See above, it probably doesn't cost much but the two are essentially synonymous, I can try to separate if you would prefer.\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+namespace BMI_RUNTIME_VERSION {\n+\n+using ::arrow::internal::BitRun;\n+using ::arrow::internal::BitRunReader;\n+\n+/// Algorithm to simulate pext using BitRunReader for cases where all bits\n+/// not set or set.\n+uint64_t RunBasedExtractMixed(uint64_t bitmap, uint64_t select_bitmap) {\n+  bitmap = arrow::BitUtil::FromLittleEndian(bitmap);\n+  uint64_t new_bitmap = 0;\n+  ::arrow::internal::BitRunReader selection(reinterpret_cast<uint8_t*>(&select_bitmap),\n+                                            /*start_offset=*/0, /*length=*/64);\n+  ::arrow::internal::BitRun run = selection.NextRun();\n+  int64_t selected_bits = 0;\n+  while (run.length != 0) {\n+    if (run.set) {\n+      new_bitmap |= (bitmap & ::arrow::BitUtil::LeastSignficantBitMask(run.length))\n+                    << selected_bits;\n+      selected_bits += run.length;\n+    }\n+    bitmap = bitmap >> run.length;\n+    run = selection.NextRun();\n+  }\n+  return arrow::BitUtil::ToLittleEndian(new_bitmap);\n+}\n+\n+inline uint64_t RunBasedExtractImpl(uint64_t bitmap, uint64_t select_bitmap) {\n+  /// These checks should be inline and are likely to be common cases.\n+  if (select_bitmap == ~uint64_t{0}) {\n+    return bitmap;\n+  } else if (select_bitmap == 0) {\n+    return 0;\n+  }\n+  /// Fallback to the slow method.\n+  return RunBasedExtractMixed(bitmap, select_bitmap);\n+}\n+\n+inline uint64_t ExtractBits(uint64_t bitmap, uint64_t select_bitmap) {\n+#if defined(ARROW_HAVE_BMI2) && !defined(__MINGW32__)\n+  return _pext_u64(bitmap, select_bitmap);\n+#else\n+  return RunBasedExtractImpl(bitmap, select_bitmap);\n+#endif\n+}\n+\n+template <bool has_repeated_parent>\n+int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n+                                      int64_t upper_bound_remaining, LevelInfo level_info,\n+                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n+  // Greater than level_info.def_level - 1 implies >= the def_level\n+  uint64_t defined_bitmap =\n+      internal::GreaterThanBitmap(def_levels, batch_size, level_info.def_level - 1);\n+\n+  DCHECK_LE(batch_size, 64);\n+  if (has_repeated_parent) {\n+    // Greater than level_info.repeated_ancestor_def_level - 1 implies >= the\n+    // repeated_ancenstor_def_level\n+    uint64_t present_bitmap = internal::GreaterThanBitmap(\n+        def_levels, batch_size, level_info.repeated_ancestor_def_level - 1);\n+    uint64_t selected_bits = ExtractBits(defined_bitmap, present_bitmap);\n\nReview comment:\n       I would need to think about this algorithm a little bit more and my expectation is that we should still be seeing runs for 0s or 1s in most cases.  As noted before if this simulation doesn't work well on an AMD box we can revert to the scalar version\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n\nReview comment:\n       that is a good question maybe implicit EQ.  fixed.\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n\nReview comment:\n       yes.\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n\nReview comment:\n       yes, it should be.  sorry about that, I changed my mind on semantics late in this PR and didn't rename.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n\nReview comment:\n       done.  I thought this might get included in doxygen but i guess we somehow limit to only public APIs.\n\n##########\nFile path: cpp/src/parquet/level_comparison.h\n##########\n@@ -0,0 +1,93 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <algorithm>\n+#include <cstdint>\n+\n+#include \"arrow/util/bit_util.h\"\n+#include \"parquet/platform.h\"\n+\n+namespace parquet {\n+namespace internal {\n+\n+// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n+// They currently represent minimal functionality for vectorized computation of definition\n+// levels.\n+\n+/// Builds a bitmap by applying predicate to the level vector provided.\n+///\n+/// \\param[in] levels Rep or def level array.\n+/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n+/// \\param[in] predicate The predicate to apply (must have the signature `bool\n+/// predicate(int16_t)`.\n+/// \\returns The bitmap using least significant \"bit\" ordering.\n+///\n+/// N.B. Correct byte ordering is dependent on little-endian architectures.\n+///\n+template <typename Predicate>\n+inline uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels,\n+                               Predicate predicate) {\n+  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n+  uint64_t mask = 0;\n+  for (int x = 0; x < num_levels; x++) {\n+    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n+  }\n+  return ::arrow::BitUtil::ToLittleEndian(mask);\n+}\n+\n+/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n+/// than rhs.\n+uint64_t PARQUET_EXPORT GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n+                                          int16_t rhs);\n+\n+#if defined(ARROW_HAVE_RUNTIME_AVX2)\n+uint64_t GreaterThanBitmapAvx2(const int16_t* levels, int64_t num_levels, int16_t rhs);\n+#endif\n+\n+struct MinMax {\n+  int16_t min;\n+  int16_t max;\n+};\n+\n+MinMax FindMinMax(const int16_t* levels, int64_t num_levels);\n+\n+#if defined(ARROW_HAVE_RUNTIME_AVX2)\n+MinMax FindMinMaxAvx2(const int16_t* levels, int64_t num_levels);\n+#endif\n+\n+// Used to make sure ODR rule isn't violated.\n+namespace IMPL_NAMESPACE {\n\nReview comment:\n       went with PARQUET_IMPL_NAMESPACE\n\n##########\nFile path: cpp/src/parquet/level_comparison.h\n##########\n@@ -0,0 +1,93 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include <algorithm>\n+#include <cstdint>\n+\n+#include \"arrow/util/bit_util.h\"\n+#include \"parquet/platform.h\"\n+\n+namespace parquet {\n+namespace internal {\n+\n+// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n\nReview comment:\n       nope. removed.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n\nReview comment:\n       separated to two methods.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n+\n+/// Reconstructs a validity bitmap for a struct that has nested children.\n\nReview comment:\n       tried to clarify.  it is list/repeated children.\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+namespace BMI_RUNTIME_VERSION {\n+\n+using ::arrow::internal::BitRun;\n+using ::arrow::internal::BitRunReader;\n+\n+/// Algorithm to simulate pext using BitRunReader for cases where all bits\n+/// not set or set.\n+uint64_t RunBasedExtractMixed(uint64_t bitmap, uint64_t select_bitmap) {\n+  bitmap = arrow::BitUtil::FromLittleEndian(bitmap);\n+  uint64_t new_bitmap = 0;\n+  ::arrow::internal::BitRunReader selection(reinterpret_cast<uint8_t*>(&select_bitmap),\n+                                            /*start_offset=*/0, /*length=*/64);\n+  ::arrow::internal::BitRun run = selection.NextRun();\n+  int64_t selected_bits = 0;\n+  while (run.length != 0) {\n+    if (run.set) {\n+      new_bitmap |= (bitmap & ::arrow::BitUtil::LeastSignficantBitMask(run.length))\n\nReview comment:\n       already existing method.  filed https://issues.apache.org/jira/browse/ARROW-10009 to clean this up.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n\nReview comment:\n       done.\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n\nReview comment:\n       yes.  sorry forgot about this.\n\n##########\nFile path: cpp/cmake_modules/SetupCxxFlags.cmake\n##########\n@@ -50,7 +50,7 @@ if(ARROW_CPU_FLAG STREQUAL \"x86\")\n     # skylake-avx512 consists of AVX512F,AVX512BW,AVX512VL,AVX512CD,AVX512DQ\n     set(ARROW_AVX512_FLAG \"-march=skylake-avx512 -mbmi2\")\n     # Append the avx2/avx512 subset option also, fix issue ARROW-9877 for homebrew-cpp\n-    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2\")\n+    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2 -mbmi2\")\n\nReview comment:\n       It is no riskier than windows, which as far as I can tell does not have a separate flag for this.  From what I can tell there from [wikipedia](https://en.wikipedia.org/wiki/Bit_manipulation_instruction_set) only a small number of AVX2 processors don't support BMI2 (some variants pre Excavator) which support avx2 \n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+namespace parquet {\n+namespace internal {\n+namespace BMI_RUNTIME_VERSION {\n+\n+using ::arrow::internal::BitRun;\n+using ::arrow::internal::BitRunReader;\n\nReview comment:\n       removed these, I think I used them in the bitmap related code but there is less of a reason to use them here.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n+\n+/// Reconstructs a validity bitmap for a struct that has nested children.\n+void PARQUET_EXPORT ConvertDefRepLevelsToBitmap(const int16_t* def_levels,\n+                                                const int16_t* rep_levels,\n+                                                int64_t num_def_levels,\n+                                                LevelInfo level_info,\n+                                                ValidityBitmapInputOutput* output);\n+\n+uint64_t PARQUET_EXPORT RunBasedExtract(uint64_t bitmap, uint64_t selection);\n\nReview comment:\n       renamed to TestOnly and added a comment.  This is exposed to ensure we can get sufficient test coverage.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -19,6 +19,9 @@\n \n #include <cstdint>\n \n+#include \"arrow/util/bitmap.h\"\n+#include \"arrow/util/optional.h\"\n\nReview comment:\n       no it is left over from the bitmap code that I pulled out.\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n+        if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+          throw ParquetException(\"List index overflow.\");\n+        }\n+        *lengths += 1;\n+      }\n+    } else {\n+      // current_rep < list rep_level i.e. start of a list (ancenstor empty lists are\n+      // filtered out above).\n+      if (lengths != nullptr) {\n+        ++lengths;\n+        // Use cumulative lengths because this is what the more common\n+        // Arrow list types expect.\n+        *lengths = *(lengths - 1);\n+        if (def_levels[x] >= level_info.def_level) {\n+          if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+            throw ParquetException(\"List index overflow.\");\n+          }\n+          *lengths += 1;\n+        }\n+      }\n \n-  } else {\n-    // No BMI2 intsturctions are used for non-repeated case.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/false>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n+      if (valid_bits_writer != nullptr) {\n+        // the level_info def level for lists reflects element present level.\n+        // the prior level distinguishes between empty lists.\n+        if (def_levels[x] >= level_info.def_level - 1) {\n+          valid_bits_writer->Set();\n+        } else {\n+          output->null_count++;\n+          valid_bits_writer->Clear();\n+        }\n+        valid_bits_writer->Next();\n+      }\n+    }\n+  }\n+  if (valid_bits_writer != nullptr) {\n+    valid_bits_writer->Finish();\n+  }\n+  if (lengths != nullptr) {\n+    output->values_read = lengths - orig_pos;\n+  } else if (valid_bits_writer != nullptr) {\n+    output->values_read = valid_bits_writer->position();\n+  }\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported)\");\n   }\n }\n \n }  // namespace\n \n void DefinitionLevelsToBitmap(const int16_t* def_levels, int64_t num_def_levels,\n-                              const int16_t max_definition_level,\n-                              const int16_t max_repetition_level, int64_t* values_read,\n-                              int64_t* null_count, uint8_t* valid_bits,\n-                              int64_t valid_bits_offset) {\n-#if ARROW_LITTLE_ENDIAN\n-  DefinitionLevelsToBitmapLittleEndian(def_levels, num_def_levels, max_definition_level,\n-                                       max_repetition_level, values_read, null_count,\n-                                       valid_bits, valid_bits_offset);\n-\n+                              LevelInfo level_info, ValidityBitmapInputOutput* output) {\n+  if (level_info.rep_level > 0) {\n+#if defined(ARROW_HAVE_RUNTIME_BMI2)\n+    using FunctionType = decltype(&standard::DefinitionLevelsToBitmapSimd<true>);\n+    static FunctionType fn =\n+        CpuInfo::GetInstance()->HasEfficientBmi2()\n+            ? DefinitionLevelsToBitmapBmi2WithRepeatedParent\n+            : standard::DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>;\n+    fn(def_levels, num_def_levels, level_info, output);\n #else\n-  DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                 max_repetition_level, values_read, null_count,\n-                                 valid_bits, valid_bits_offset);\n+    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, level_info, output);\n\nReview comment:\n       Added a comment.  It is likely the best choice for big-endian platforms.  It might also be the best choice for AMD CPUs (if you could see the performance difference of this PR on your machine compared to the master it would help inform if this should be used above.\n\n##########\nFile path: cpp/cmake_modules/SetupCxxFlags.cmake\n##########\n@@ -50,7 +50,7 @@ if(ARROW_CPU_FLAG STREQUAL \"x86\")\n     # skylake-avx512 consists of AVX512F,AVX512BW,AVX512VL,AVX512CD,AVX512DQ\n     set(ARROW_AVX512_FLAG \"-march=skylake-avx512 -mbmi2\")\n     # Append the avx2/avx512 subset option also, fix issue ARROW-9877 for homebrew-cpp\n-    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2\")\n+    set(ARROW_AVX2_FLAG \"${ARROW_AVX2_FLAG} -mavx2 -mbmi2\")\n\nReview comment:\n       did you mean to tag someone else here?  Or do I get the final say :)\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n\nReview comment:\n       carelessness, also fixed bound to ToList.\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n+        if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+          throw ParquetException(\"List index overflow.\");\n+        }\n+        *lengths += 1;\n+      }\n+    } else {\n+      // current_rep < list rep_level i.e. start of a list (ancenstor empty lists are\n+      // filtered out above).\n+      if (lengths != nullptr) {\n+        ++lengths;\n+        // Use cumulative lengths because this is what the more common\n\nReview comment:\n       clarified this is fixed size list vs variable size list issue.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+\n+/// Reconstructs a validity bitmap and list lengths for a ListArray based on\n+/// def/rep levels.\n+void PARQUET_EXPORT ConvertDefRepLevelsToList(\n+    const int16_t* def_levels, const int16_t* rep_levels, int64_t num_def_levels,\n+    LevelInfo level_info, ValidityBitmapInputOutput* output,\n+    ::arrow::util::variant<int32_t*, int64_t*> lengths);\n+\n+/// Reconstructs a validity bitmap for a struct that has nested children.\n+void PARQUET_EXPORT ConvertDefRepLevelsToBitmap(const int16_t* def_levels,\n+                                                const int16_t* rep_levels,\n+                                                int64_t num_def_levels,\n+                                                LevelInfo level_info,\n+                                                ValidityBitmapInputOutput* output);\n+\n+uint64_t PARQUET_EXPORT RunBasedExtract(uint64_t bitmap, uint64_t selection);\n+\n+#if defined(ARROW_HAVE_RUNTIME_BMI2)\n+void PARQUET_EXPORT DefinitionLevelsToBitmapBmi2WithRepeatedParent(\n\nReview comment:\n       yeah, I didn't think this through.  moved declaration into .cc with documentation pointing to instruction set specific .cc  did this for comparison as well.\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n\nReview comment:\n       Added comment. Yes, that is controlled below (we always use SIMD when this isn't nested.\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n\nReview comment:\n       done.  for fixed size lists we will need to fix-up level info appropriately, so that this check doesn't get triggered.\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n\nReview comment:\n       sorry, for the naming confusion.  I started with lengths but then transition to offsets.  I think I've cleaned up references in this file now.  Yes, we reuse this function for nullable structs with that have repeated children.  I added a comment for both checks.\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,190 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n+#define BMI_RUNTIME_VERSION standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef BMI_RUNTIME_VERSION\n \n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefinitionLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                                    LevelInfo level_info,\n+                                    ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n-}\n-#endif\n-\n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n   }\n }\n+#endif\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n+template <typename LengthType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, LengthType* lengths) {\n+  LengthType* orig_pos = lengths;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty ancenstor lists and futher nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n-}\n+    if (ARROW_PREDICT_FALSE(\n+            (valid_bits_writer != nullptr &&\n+             valid_bits_writer->position() > output->values_read_upper_bound) ||\n+            (lengths - orig_pos) > output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      if (lengths != nullptr) {\n+        if (ARROW_PREDICT_FALSE(*lengths == std::numeric_limits<LengthType>::max())) {\n+          throw ParquetException(\"List index overflow.\");\n+        }\n+        *lengths += 1;\n+      }\n+    } else {\n+      // current_rep < list rep_level i.e. start of a list (ancenstor empty lists are\n\nReview comment:\n       yes, its called autocomplete.  Once I fat finger one place, I typically auto complete more then once.  \n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n\nReview comment:\n       No the bitmap is output only.  clarified each parameter here.\n\n##########\nFile path: cpp/src/parquet/level_conversion_inc.h\n##########\n@@ -0,0 +1,146 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+#pragma once\n+\n+#include \"parquet/level_conversion.h\"\n+\n+#include <algorithm>\n+#include <limits>\n+#if defined(ARROW_HAVE_BMI2)\n+#if defined(_MSC_VER)\n+#include <immintrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif  // _MSC_VER\n+#endif  // ARROW_HAVE_BMI2\n+\n+#include \"arrow/util/bit_run_reader.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"parquet/exception.h\"\n+#include \"parquet/level_comparison.h\"\n+\n\nReview comment:\n       done.\n\n##########\nFile path: cpp/src/parquet/level_conversion.h\n##########\n@@ -132,43 +137,49 @@ struct PARQUET_EXPORT LevelInfo {\n   }\n };\n \n-void PARQUET_EXPORT DefinitionLevelsToBitmap(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset);\n-\n-// These APIs are likely to be revised as part of ARROW-8494 to reduce duplicate code.\n-// They currently represent minimal functionality for vectorized computation of definition\n-// levels.\n-\n-#if defined(ARROW_LITTLE_ENDIAN)\n-/// Builds a bitmap by applying predicate to the level vector provided.\n-///\n-/// \\param[in] levels Rep or def level array.\n-/// \\param[in] num_levels The number of levels to process (must be [0, 64])\n-/// \\param[in] predicate The predicate to apply (must have the signature `bool\n-/// predicate(int16_t)`.\n-/// \\returns The bitmap using least significant \"bit\" ordering.\n-///\n-/// N.B. Correct byte ordering is dependent on little-endian architectures.\n-///\n-template <typename Predicate>\n-uint64_t LevelsToBitmap(const int16_t* levels, int64_t num_levels, Predicate predicate) {\n-  // Both clang and GCC can vectorize this automatically with SSE4/AVX2.\n-  uint64_t mask = 0;\n-  for (int x = 0; x < num_levels; x++) {\n-    mask |= static_cast<uint64_t>(predicate(levels[x]) ? 1 : 0) << x;\n-  }\n-  return mask;\n-}\n-\n-/// Builds a  bitmap where each set bit indicates the corresponding level is greater\n-/// than rhs.\n-static inline uint64_t GreaterThanBitmap(const int16_t* levels, int64_t num_levels,\n-                                         int16_t rhs) {\n-  return LevelsToBitmap(levels, num_levels, [rhs](int16_t value) { return value > rhs; });\n-}\n+/// Input/Output structure for reconstructed validity bitmaps.\n+struct PARQUET_EXPORT ValidityBitmapInputOutput {\n+  /// The maximum number of values_read expected (actual\n+  /// values read must be less than or equal to this value.\n+  /// If this number is exceeded methods will throw a\n+  /// ParquetException.\n+  int64_t values_read_upper_bound = 0;\n+  /// The number of values added to the bitmap.\n+  int64_t values_read = 0;\n+  /// The number of nulls encountered.\n+  int64_t null_count = 0;\n+  // The validity bitmp to populate. Can only be null\n+  // for DefRepLevelsToListInfo (if all that is needed is list lengths).\n+  uint8_t* valid_bits = NULLPTR;\n+  /// Input only, offset into valid_bits to start at.\n+  int64_t valid_bits_offset = 0;\n+};\n \n+/// Converts def_levels to validity bitmaps for non-list arrays.\n+void PARQUET_EXPORT DefinitionLevelsToBitmap(const int16_t* def_levels,\n\nReview comment:\n       I tried to consolidation on use shorting to def/rep level everyplace and removing convert.  Let me know if this clarifies things.  I also added more guidance on each method.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:49:53.817+0000",
                    "updated": "2020-09-15T16:49:53.817+0000",
                    "started": "2020-09-15T16:49:53.817+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484628",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484629",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488815019\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion.cc\n##########\n@@ -18,176 +18,205 @@\n \n #include <algorithm>\n #include <limits>\n-#if defined(ARROW_HAVE_BMI2)\n-#include <x86intrin.h>\n-#endif\n \n+#include \"arrow/util/bit_run_reader.h\"\n #include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/cpu_info.h\"\n #include \"arrow/util/logging.h\"\n #include \"parquet/exception.h\"\n \n+#include \"parquet/level_comparison.h\"\n+#define PARQUET_IMPL_NAMESPACE standard\n+#include \"parquet/level_conversion_inc.h\"\n+#undef PARQUET_IMPL_NAMESPACE\n+\n namespace parquet {\n namespace internal {\n namespace {\n-inline void CheckLevelRange(const int16_t* levels, int64_t num_levels,\n-                            const int16_t max_expected_level) {\n-  int16_t min_level = std::numeric_limits<int16_t>::max();\n-  int16_t max_level = std::numeric_limits<int16_t>::min();\n-  for (int x = 0; x < num_levels; x++) {\n-    min_level = std::min(levels[x], min_level);\n-    max_level = std::max(levels[x], max_level);\n-  }\n-  if (ARROW_PREDICT_FALSE(num_levels > 0 &&\n-                          (min_level < 0 || max_level > max_expected_level))) {\n-    throw ParquetException(\"definition level exceeds maximum\");\n-  }\n-}\n \n-#if !defined(ARROW_HAVE_AVX512)\n-\n-inline void DefinitionLevelsToBitmapScalar(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  // We assume here that valid_bits is large enough to accommodate the\n-  // additional definition levels and the ones that have already been written\n-  ::arrow::internal::BitmapWriter valid_bits_writer(valid_bits, valid_bits_offset,\n-                                                    num_def_levels);\n-\n-  // TODO(itaiin): As an interim solution we are splitting the code path here\n-  // between repeated+flat column reads, and non-repeated+nested reads.\n-  // Those paths need to be merged in the future\n-  for (int i = 0; i < num_def_levels; ++i) {\n-    if (def_levels[i] == max_definition_level) {\n+using ::arrow::internal::CpuInfo;\n+\n+#if !defined(ARROW_HAVE_RUNTIME_BMI2)\n+void DefLevelsToBitmapScalar(const int16_t* def_levels, int64_t num_def_levels,\n+                             LevelInfo level_info, ValidityBitmapInputOutput* output) {\n+  ::arrow::internal::FirstTimeBitmapWriter valid_bits_writer(\n+      output->valid_bits,\n+      /*start_offset=*/output->valid_bits_offset,\n+      /*length=*/num_def_levels);\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // This indicates that a parent repeated element has zero\n+    // length so the def level is not applicable to this column.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level) {\n+      continue;\n+    }\n+    if (ARROW_PREDICT_FALSE(valid_bits_writer.position() >=\n+                            output->values_read_upper_bound)) {\n+      std::stringstream ss;\n+      ss << \"Definition levels exceeded upper bound: \" << output->values_read_upper_bound;\n+      throw ParquetException(ss.str());\n+    }\n+    if (def_levels[x] >= level_info.def_level) {\n       valid_bits_writer.Set();\n-    } else if (max_repetition_level > 0) {\n-      // repetition+flat case\n-      if (def_levels[i] == (max_definition_level - 1)) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        continue;\n-      }\n     } else {\n-      // non-repeated+nested case\n-      if (def_levels[i] < max_definition_level) {\n-        valid_bits_writer.Clear();\n-        *null_count += 1;\n-      } else {\n-        throw ParquetException(\"definition level exceeds maximum\");\n-      }\n+      valid_bits_writer.Clear();\n+      output->null_count += 1;\n     }\n-\n     valid_bits_writer.Next();\n   }\n   valid_bits_writer.Finish();\n-  *values_read = valid_bits_writer.position();\n+  output->values_read = valid_bits_writer.position();\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported\");\n+  }\n }\n #endif\n \n-template <bool has_repeated_parent>\n-int64_t DefinitionLevelsBatchToBitmap(const int16_t* def_levels, const int64_t batch_size,\n-                                      const int16_t required_definition_level,\n-                                      ::arrow::internal::FirstTimeBitmapWriter* writer) {\n-  CheckLevelRange(def_levels, batch_size, required_definition_level);\n-  uint64_t defined_bitmap =\n-      internal::GreaterThanBitmap(def_levels, batch_size, required_definition_level - 1);\n-\n-  DCHECK_LE(batch_size, 64);\n-  if (has_repeated_parent) {\n-#if defined(ARROW_HAVE_BMI2)\n-    // This is currently a specialized code path assuming only (nested) lists\n-    // present through the leaf (i.e. no structs). Upper level code only calls\n-    // this method when the leaf-values are nullable (otherwise no spacing is needed),\n-    // Because only nested lists exists it is sufficient to know that the field\n-    // was either null or included it (i.e. definition level > max_definitation_level\n-    // -2) If there where structs mixed in, we need to know the def_level of the\n-    // repeated parent so we can check for def_level > \"def level of repeated parent\".\n-    uint64_t present_bitmap = internal::GreaterThanBitmap(def_levels, batch_size,\n-                                                          required_definition_level - 2);\n-    uint64_t selected_bits = _pext_u64(defined_bitmap, present_bitmap);\n-    writer->AppendWord(selected_bits, ::arrow::BitUtil::PopCount(present_bitmap));\n-    return ::arrow::BitUtil::PopCount(selected_bits);\n-#else\n-    assert(false && \"must not execute this without BMI2\");\n-#endif\n-  } else {\n-    writer->AppendWord(defined_bitmap, batch_size);\n-    return ::arrow::BitUtil::PopCount(defined_bitmap);\n+template <typename OffsetType>\n+void DefRepLevelsToListInfo(const int16_t* def_levels, const int16_t* rep_levels,\n+                            int64_t num_def_levels, LevelInfo level_info,\n+                            ValidityBitmapInputOutput* output, OffsetType* offsets) {\n+  OffsetType* orig_pos = offsets;\n+  std::unique_ptr<::arrow::internal::FirstTimeBitmapWriter> valid_bits_writer;\n+  if (output->valid_bits) {\n+    valid_bits_writer.reset(new ::arrow::internal::FirstTimeBitmapWriter(\n+        output->valid_bits, output->valid_bits_offset, num_def_levels));\n   }\n-}\n+  for (int x = 0; x < num_def_levels; x++) {\n+    // Skip items that belong to empty or null ancestor lists and further nested lists.\n+    if (def_levels[x] < level_info.repeated_ancestor_def_level ||\n+        rep_levels[x] > level_info.rep_level) {\n+      continue;\n+    }\n \n-template <bool has_repeated_parent>\n-void DefinitionLevelsToBitmapSimd(const int16_t* def_levels, int64_t num_def_levels,\n-                                  const int16_t required_definition_level,\n-                                  int64_t* values_read, int64_t* null_count,\n-                                  uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  constexpr int64_t kBitMaskSize = 64;\n-  ::arrow::internal::FirstTimeBitmapWriter writer(valid_bits,\n-                                                  /*start_offset=*/valid_bits_offset,\n-                                                  /*length=*/num_def_levels);\n-  int64_t set_count = 0;\n-  *values_read = 0;\n-  while (num_def_levels > kBitMaskSize) {\n-    set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-        def_levels, kBitMaskSize, required_definition_level, &writer);\n-    def_levels += kBitMaskSize;\n-    num_def_levels -= kBitMaskSize;\n-  }\n-  set_count += DefinitionLevelsBatchToBitmap<has_repeated_parent>(\n-      def_levels, num_def_levels, required_definition_level, &writer);\n+    if (rep_levels[x] == level_info.rep_level) {\n+      // A continuation of an existing list.\n+      // offsets can be null for structs with repeated children (we don't need to know\n+      // offsets until we get to the children).\n+      if (offsets != nullptr) {\n+        if (ARROW_PREDICT_FALSE(*offsets == std::numeric_limits<OffsetType>::max())) {\n+          throw ParquetException(\"List index overflow.\");\n+        }\n+        *offsets += 1;\n+      }\n+    } else {\n+      if (ARROW_PREDICT_FALSE(\n+              (valid_bits_writer != nullptr &&\n+               valid_bits_writer->position() >= output->values_read_upper_bound) ||\n+              (offsets - orig_pos) >= output->values_read_upper_bound)) {\n+        std::stringstream ss;\n+        ss << \"Definition levels exceeded upper bound: \"\n+           << output->values_read_upper_bound;\n+        throw ParquetException(ss.str());\n+      }\n \n-  *values_read = writer.position();\n-  *null_count += *values_read - set_count;\n-  writer.Finish();\n+      // current_rep < list rep_level i.e. start of a list (ancestor empty lists are\n+      // filtered out above).\n+      // offsets can be null for structs with repeated children (we don't need to know\n+      // offsets until we get to the children).\n+      if (offsets != nullptr) {\n+        ++offsets;\n+        // Use cumulative offsets because variable size lists are more common then\n+        // fixed size lists so it should be cheaper to make these cumulative and\n+        // subtract when validating fixed size lists.\n+        *offsets = *(offsets - 1);\n+        if (def_levels[x] >= level_info.def_level) {\n+          if (ARROW_PREDICT_FALSE(*offsets == std::numeric_limits<OffsetType>::max())) {\n+            throw ParquetException(\"List index overflow.\");\n+          }\n+          *offsets += 1;\n+        }\n+      }\n+\n+      if (valid_bits_writer != nullptr) {\n+        // the level_info def level for lists reflects element present level.\n+        // the prior level distinguishes between empty lists.\n+        if (def_levels[x] >= level_info.def_level - 1) {\n+          valid_bits_writer->Set();\n+        } else {\n+          output->null_count++;\n+          valid_bits_writer->Clear();\n+        }\n+        valid_bits_writer->Next();\n+      }\n+    }\n+  }\n+  if (valid_bits_writer != nullptr) {\n+    valid_bits_writer->Finish();\n+  }\n+  if (offsets != nullptr) {\n+    output->values_read = offsets - orig_pos;\n+  } else if (valid_bits_writer != nullptr) {\n+    output->values_read = valid_bits_writer->position();\n+  }\n+  if (output->null_count > 0 && level_info.null_slot_usage > 1) {\n+    throw ParquetException(\n+        \"Null values with null_slot_usage > 1 not supported.\"\n+        \"(i.e. FixedSizeLists with null values are not supported)\");\n+  }\n }\n \n-void DefinitionLevelsToBitmapLittleEndian(\n-    const int16_t* def_levels, int64_t num_def_levels, const int16_t max_definition_level,\n-    const int16_t max_repetition_level, int64_t* values_read, int64_t* null_count,\n-    uint8_t* valid_bits, int64_t valid_bits_offset) {\n-  if (max_repetition_level > 0) {\n-// This is a short term hack to prevent using the pext BMI2 instructions\n-// on non-intel platforms where performance is subpar.\n-// In the medium term we will hopefully be able to runtime dispatch\n-// to use this on intel only platforms that support pext.\n-#if defined(ARROW_HAVE_AVX512)\n-    // BMI2 is required for efficient bit extraction.\n-    DefinitionLevelsToBitmapSimd</*has_repeated_parent=*/true>(\n-        def_levels, num_def_levels, max_definition_level, values_read, null_count,\n-        valid_bits, valid_bits_offset);\n-#else\n-    DefinitionLevelsToBitmapScalar(def_levels, num_def_levels, max_definition_level,\n-                                   max_repetition_level, values_read, null_count,\n-                                   valid_bits, valid_bits_offset);\n-#endif  // ARROW_HAVE_BMI2\n+}  // namespace\n \n+#if defined(ARROW_HAVE_RUNTIME_BMI2)\n+// defined in level_conversion_bmi2.cc for dynamic dispatch.\n+void DefLevelsToBitmapBmi2WithRepeatedParent(const int16_t* def_levels,\n+                                             int64_t num_def_levels, LevelInfo level_info,\n+                                             ValidityBitmapInputOutput* output);\n+#endif\n+\n+void DefLevelsToBitmap(const int16_t* def_levels, int64_t num_def_levels,\n+                       LevelInfo level_info, ValidityBitmapInputOutput* output) {\n+  // It is simpler to rely on rep_level here until PARQUET-1899 is done and the code\n+  // is deleted in a follow-up release.\n+  if (level_info.rep_level > 0) {\n+#if defined(ARROW_HAVE_RUNTIME_BMI2)\n+    using FunctionType = decltype(&standard::DefLevelsToBitmapSimd<true>);\n+    static FunctionType fn =\n+        CpuInfo::GetInstance()->HasEfficientBmi2()\n+            ? DefLevelsToBitmapBmi2WithRepeatedParent\n+            : standard::DefLevelsToBitmapSimd</*has_repeated_parent=*/true>;\n+    fn(def_levels, num_def_levels, level_info, output);\n+#else\n+    // This indicates we are likely on a big-endian platformat which don't have a\n\nReview comment:\n       \"platform\"\r\n   \r\n   But the comment is mistaken: ARM is little-endian most of the time (technically it supports both, but Linux runs it in little-endian mode AFAIK).\r\n   \r\n   Also, I don't understand why `DefLevelsToBitmapScalar` is preferred here but `DefLevelsToBitmapSimd` is preferred below? Don't the same arguments apply?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:50:17.360+0000",
                    "updated": "2020-09-15T16:50:17.360+0000",
                    "started": "2020-09-15T16:50:17.360+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484629",
                    "issueId": "13298953"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/worklog/484631",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #8177:\nURL: https://github.com/apache/arrow/pull/8177#discussion_r488815645\n\n\n\n##########\nFile path: cpp/src/parquet/level_conversion_test.cc\n##########\n@@ -108,22 +114,245 @@ TEST(GreaterThanBitmap, GeneratesExpectedBitmasks) {\n \n TEST(DefinitionLevelsToBitmap, WithRepetitionLevelFiltersOutEmptyListValues) {\n   std::vector<uint8_t> validity_bitmap(/*count*/ 8, 0);\n-  int64_t null_count = 5;\n-  int64_t values_read = 1;\n \n+  ValidityBitmapInputOutput io;\n+  io.values_read_upper_bound = 64;\n+  io.values_read = 1;\n+  io.null_count = 5;\n+  io.valid_bits = validity_bitmap.data();\n+  io.valid_bits_offset = 1;\n+\n+  LevelInfo level_info;\n+  level_info.repeated_ancestor_def_level = 1;\n+  level_info.def_level = 2;\n+  level_info.rep_level = 1;\n   // All zeros should be ignored, ones should be unset in the bitmp and 2 should be set.\n   std::vector<int16_t> def_levels = {0, 0, 0, 2, 2, 1, 0, 2};\n-  DefinitionLevelsToBitmap(\n-      def_levels.data(), def_levels.size(), /*max_definition_level=*/2,\n-      /*max_repetition_level=*/1, &values_read, &null_count, validity_bitmap.data(),\n-      /*valid_bits_offset=*/1);\n+  DefinitionLevelsToBitmap(def_levels.data(), def_levels.size(), level_info, &io);\n \n   EXPECT_EQ(BitmapToString(validity_bitmap, /*bit_count=*/8), \"01101000\");\n   for (size_t x = 1; x < validity_bitmap.size(); x++) {\n     EXPECT_EQ(validity_bitmap[x], 0) << \"index: \" << x;\n   }\n-  EXPECT_EQ(null_count, /*5 + 1 =*/6);\n-  EXPECT_EQ(values_read, 4);  // value should get overwritten.\n+  EXPECT_EQ(io.null_count, /*5 + 1 =*/6);\n+  EXPECT_EQ(io.values_read, 4);  // value should get overwritten.\n+}\n+\n+class MultiLevelTestData {\n+ public:\n+  // Triply nested list values borrow from write_path\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  std::vector<int16_t> def_levels_{2, 7, 6, 7, 5, 3,  // first row\n+                                   5, 5, 7, 7, 2, 7,  // second row\n+                                   0,                 // third row\n+                                   1};\n+  std::vector<int16_t> rep_levels_{0, 1, 3, 3, 2, 1,  // first row\n+                                   0, 1, 2, 3, 1, 1,  // second row\n+                                   0, 0};\n+};\n+\n+template <typename ConverterType>\n+class NestedListTest : public testing::Test {\n+ public:\n+  MultiLevelTestData test_data_;\n+  ConverterType converter_;\n+};\n+\n+template <typename ListType>\n+struct RepDefLevelConverter {\n+  using ListLengthType = ListType;\n+  ListLengthType* ComputeListInfo(const MultiLevelTestData& test_data,\n+                                  LevelInfo level_info, ValidityBitmapInputOutput* output,\n+                                  ListType* lengths) {\n+    ConvertDefRepLevelsToList(test_data.def_levels_.data(), test_data.rep_levels_.data(),\n+                              test_data.def_levels_.size(), level_info, output, lengths);\n+    return lengths + output->values_read;\n+  }\n+};\n+\n+using ConverterTypes =\n+    ::testing::Types<RepDefLevelConverter</*list_length_type=*/int32_t>,\n+                     RepDefLevelConverter</*list_length_type=*/int64_t>>;\n+TYPED_TEST_CASE(NestedListTest, ConverterTypes);\n+\n+TYPED_TEST(NestedListTest, OuterMostTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 outer most lists (len(3), len(4), null, len(0))\n+  LevelInfo level_info;\n+  level_info.rep_level = 1;\n+  level_info.def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(5, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 4;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 4);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 7, 7, 7));\n+\n+  EXPECT_EQ(validity_io.values_read, 4);\n+  EXPECT_EQ(validity_io.null_count, 1);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/4), \"1101\");\n+}\n+\n+TYPED_TEST(NestedListTest, MiddleListTest) {\n+  // [null, [[1 , null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> middle lists (null, len(2), len(0),\n+  //                  len(1), len(2), null, len(1),\n+  //                  N/A,\n+  //                  N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 2;\n+  level_info.def_level = 4;\n+  level_info.repeated_ancestor_def_level = 2;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(8, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 7;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 7);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 0, 2, 2, 3, 5, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 7);\n+  EXPECT_EQ(validity_io.null_count, 2);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/7), \"0111101\");\n+}\n+\n+TYPED_TEST(NestedListTest, InnerMostListTest) {\n+  // [null, [[1, null, 3], []], []],\n+  // [[[]], [[], [1, 2]], null, [[3]]],\n+  // null,\n+  // []\n+  // -> 4 inner lists (N/A, [len(3), len(0)], N/A\n+  //                        len(0), [len(0), len(2)], N/A, len(1),\n+  //                        N/A,\n+  //                        N/A\n+  LevelInfo level_info;\n+  level_info.rep_level = 3;\n+  level_info.def_level = 6;\n+  level_info.repeated_ancestor_def_level = 4;\n+\n+  std::vector<typename TypeParam::ListLengthType> lengths(7, 0);\n+  uint64_t validity_output;\n+  ValidityBitmapInputOutput validity_io;\n+  validity_io.values_read_upper_bound = 6;\n+  validity_io.valid_bits = reinterpret_cast<uint8_t*>(&validity_output);\n+  typename TypeParam::ListLengthType* next_position = this->converter_.ComputeListInfo(\n+      this->test_data_, level_info, &validity_io, lengths.data());\n+\n+  EXPECT_THAT(next_position, lengths.data() + 6);\n+  EXPECT_THAT(lengths, testing::ElementsAre(0, 3, 3, 3, 3, 5, 6));\n+\n+  EXPECT_EQ(validity_io.values_read, 6);\n+  EXPECT_EQ(validity_io.null_count, 0);\n+  EXPECT_EQ(BitmapToString(validity_io.valid_bits, /*length=*/6), \"111111\");\n+}\n\nReview comment:\n       sorry, I didn't respond directly here.  I'll refactor the tests tonight.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-15T16:51:23.143+0000",
                    "updated": "2020-09-15T16:51:23.143+0000",
                    "started": "2020-09-15T16:51:23.143+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "484631",
                    "issueId": "13298953"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 35400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@72fbe3c2[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@21de6e94[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5f87ba7[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@57800f42[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2b7125e2[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@ae3ce4[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@46cd4a15[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@1160b791[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@331cce6a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@42a48df1[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6e95fa52[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@7add042e[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 35400,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Sep 21 18:45:47 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-09-21T18:45:47.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8494/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2020-04-17T04:13:13.000+0000",
        "updated": "2020-09-22T03:44:32.000+0000",
        "timeoriginalestimate": null,
        "description": "This logic would attempt to create the data necessary for each field by passing through the levels once for each field.\u00a0 it is expected that due to once we can put SIMD/bitmap code in place this will perform better for nested data with shallow nesting, but due to repetitive computation might perform worse for deep nested that include List-types.\u00a0 The SIMD/bitmap enhancements are covered in:\u00a0ARROW-9985\r\n\r\n\u00a0\r\n\r\nAt a high level the logic would be structured as:\r\n\r\n{{for each field:}}\r\n\r\n{{\u00a0 \u00a0for each rep/def level entry:}}\r\n\r\n{{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0update null bitmask and offsets.}}",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "9h 50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 35400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Implement basic array-by-array  reassembly logic",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/comment/17185332",
                    "id": "17185332",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "If I understand correctly, for a non-list nullable field, we only need to update the null bitmap:\r\n* if def level >= field's def level, append non-null\r\n* otherwise, append null\r\n\r\nFor a non-nullable list field, we must update the offsets:\r\n* if rep level < field's rep level and def level < field's def level , append current_offset (empty list)\r\n* if rep level < field's rep level and def level >= field's def level , append current_offset++ (first item in new list)\r\n* otherwise, just current_offset++ (next item in same list)\r\n\r\nFor a nullable list field, the ancestor_def_level must also be taken into account?\r\n\r\nSo non-list fields are easy, list fields have more sophisticated logic that might be less easy to do efficiently.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2020-08-26T17:00:42.637+0000",
                    "updated": "2020-08-26T17:00:42.637+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/comment/17185583",
                    "id": "17185583",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=emkornfield%40gmail.com",
                        "name": "emkornfield@gmail.com",
                        "key": "emkornfield@gmail.com",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Micah Kornfield",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Yes [~apitrou]\u00a0that matches my understanding, I have an algorithm that I think might work fairly well for the more complicated\u00a0 list cases but probably has diminishing returns as the level of nesting grows.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=emkornfield%40gmail.com",
                        "name": "emkornfield@gmail.com",
                        "key": "emkornfield@gmail.com",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Micah Kornfield",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2020-08-27T03:25:10.097+0000",
                    "updated": "2020-08-27T03:25:10.097+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13298953/comment/17199587",
                    "id": "17199587",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Issue resolved by pull request 8177\n[https://github.com/apache/arrow/pull/8177]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2020-09-21T18:45:47.432+0000",
                    "updated": "2020-09-21T18:45:47.432+0000"
                }
            ],
            "maxResults": 3,
            "total": 3,
            "startAt": 0
        },
        "customfield_12311820": "0|z0dqco:",
        "customfield_12314139": null
    }
}