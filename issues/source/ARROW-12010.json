{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13365951",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951",
    "key": "ARROW-12010",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12349983",
                "id": "12349983",
                "description": "",
                "name": "5.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-07-28"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12348823",
                "id": "12348823",
                "description": "",
                "name": "3.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-01-25"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12615164",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12615164",
                "type": {
                    "id": "12310460",
                    "name": "Child-Issue",
                    "inward": "is a child of",
                    "outward": "is a parent of",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310460"
                },
                "inwardIssue": {
                    "id": "13376404",
                    "key": "ARROW-12633",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13376404",
                    "fields": {
                        "summary": "[C++] Query engine umbrella issue",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
            "name": "michalno",
            "key": "michalno",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Michal Nowakiewicz",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 6000,
            "total": 6000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 6000,
            "total": 6000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12010/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 10,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/570237",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768#issuecomment-804622859\n\n\n   https://issues.apache.org/jira/browse/ARROW-12010\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-03-23T05:15:00.628+0000",
                    "updated": "2021-03-23T05:15:00.628+0000",
                    "started": "2021-03-23T05:15:00.628+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "570237",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/585997",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768#discussion_r616784836\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -182,10 +182,62 @@ struct TestGrouper {\n     ExpectConsume(*ExecBatch::Make(key_batch), expected);\n   }\n \n+  void AssertEquivalentIds(const Datum& expected, const Datum& actual) {\n\nReview comment:\n       Please include a comment describing what this does compared to AssertDatumsEqual\n\n##########\nFile path: cpp/src/arrow/compute/kernels/hash_aggregate_test.cc\n##########\n@@ -182,10 +182,62 @@ struct TestGrouper {\n     ExpectConsume(*ExecBatch::Make(key_batch), expected);\n   }\n \n+  void AssertEquivalentIds(const Datum& expected, const Datum& actual) {\n+    auto left = expected.make_array();\n+    auto right = actual.make_array();\n+    ASSERT_EQ(left->length(), right->length()) << \"#ids unequal\";\n+    int64_t num_ids = left->length();\n+    auto left_data = left->data();\n+    auto right_data = right->data();\n+    const uint32_t* left_ids =\n+        reinterpret_cast<const uint32_t*>(left_data->buffers[1]->data());\n+    const uint32_t* right_ids =\n+        reinterpret_cast<const uint32_t*>(right_data->buffers[1]->data());\n+    uint32_t max_left_id = 0;\n+    uint32_t max_right_id = 0;\n+    for (int64_t i = 0; i < num_ids; ++i) {\n+      if (left_ids[i] > max_left_id) {\n+        max_left_id = left_ids[i];\n+      }\n+      if (right_ids[i] > max_right_id) {\n+        max_right_id = right_ids[i];\n+      }\n+    }\n+    std::vector<bool> right_to_left_present;\n\nReview comment:\n       std::vector can be sized and initialized on construction\r\n   ```suggestion\r\n       std::vector<bool> right_to_left_present(max_right_id + 1, false);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/CMakeLists.txt\n##########\n@@ -392,14 +392,45 @@ if(ARROW_COMPUTE)\n               compute/kernels/vector_hash.cc\n               compute/kernels/vector_nested.cc\n               compute/kernels/vector_selection.cc\n-              compute/kernels/vector_sort.cc)\n+              compute/kernels/vector_sort.cc\n+              engine/key_hash.cc\n+              engine/key_map.cc\n+              engine/key_compare.cc\n+              engine/key_encode.cc              \n+              engine/groupby.cc\n+              engine/util.cc)\n \n   if(ARROW_HAVE_RUNTIME_AVX2)\n     list(APPEND ARROW_SRCS compute/kernels/aggregate_basic_avx2.cc)\n     set_source_files_properties(compute/kernels/aggregate_basic_avx2.cc PROPERTIES\n                                 SKIP_PRECOMPILE_HEADERS ON)\n     set_source_files_properties(compute/kernels/aggregate_basic_avx2.cc PROPERTIES\n                                 COMPILE_FLAGS ${ARROW_AVX2_FLAG})\n+    list(APPEND ARROW_SRCS engine/key_hash_avx2.cc)\n+    set_source_files_properties(engine/key_hash_avx2.cc PROPERTIES\n+                                SKIP_PRECOMPILE_HEADERS ON)\n+    set_source_files_properties(engine/key_hash_avx2.cc PROPERTIES\n+                                COMPILE_FLAGS ${ARROW_AVX2_FLAG})\n\nReview comment:\n       Let's extract this to a macro,\r\n   ```cmake\r\n   macro(append_avx2_src SRC)\r\n     if(ARROW_HAVE_RUNTIME_AVX2)\r\n       list(APPEND ARROW_SRCS ${SRC})\r\n       set_source_files_properties(${SRC} PROPERTIES\r\n                                   SKIP_PRECOMPILE_HEADERS ON)\r\n       set_source_files_properties(${SRC} PROPERTIES\r\n                                   COMPILE_FLAGS ${ARROW_AVX2_FLAG})\r\n     endif()\r\n   endmacro()\r\n   ```\n\n##########\nFile path: cpp/src/arrow/engine/key_encode.h\n##########\n@@ -0,0 +1,544 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/engine/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+/// Converts between key representation as a collection of arrays for\n+/// individual columns and another representation as a single array of rows\n+/// combining data from all columns into one value.\n+/// This conversion is reversible.\n+/// Row-oriented storage is beneficial when there is a need for random access\n+/// of individual rows and at the same time all included columns are likely to\n+/// be accessed together, as in the case of hash table key.\n+class KeyEncoder {\n+ public:\n+  struct KeyEncoderContext {\n+    bool has_avx2() const { return instr == util::CPUInstructionSet::avx2; }\n+    util::CPUInstructionSet instr;\n+    util::TempVectorStack* stack;\n+  };\n+\n+  /// Description of a storage format for rows produced by encoder.\n+  struct KeyRowMetadata {\n+    uint32_t get_num_varbinary_cols() const {\n+      return cumulative_lengths_length / sizeof(uint32_t);\n+    }\n+    /// Is row a varying-length binary, using offsets array to find a beginning of a row,\n+    /// or is it a fixed-length binary.\n+    bool is_fixed_length;\n+    /// For a fixed-length binary row, common size of rows in bytes.\n+    /// For a varying-length binary, size of all encoded fixed-length key columns.\n+    /// Encoded fixed-length key columns in that case prefix the information\n+    /// about all varying-length key columns.\n+    uint32_t fixed_length;\n+    /// Size in bytes of optional cumulative lengths of varying-length key columns,\n+    /// used when the row is not fixed length.\n+    /// Zero for fixed-length row.\n+    /// This number is equal to the number of varying-length key columns multiplied\n+    /// by sizeof(uint32_t), which is the size of a single cumulative length.\n+    uint32_t cumulative_lengths_length;\n+    /// Fixed number of bytes per row that are used to encode null masks.\n+    /// Null masks indicate for a single row which of its key columns are null.\n+    /// Nth bit in the sequence of bytes assigned to a row represents null\n+    /// information for Nth key column.\n+    int null_masks_bytes_per_row;\n+  };\n+\n+  class KeyRowArray {\n+   public:\n+    KeyRowArray();\n+    Status Init(MemoryPool* pool, const KeyRowMetadata& metadata);\n+    void Clean();\n+    Status AppendEmpty(uint32_t num_rows_to_append, uint32_t num_extra_bytes_to_append);\n+    Status AppendSelectionFrom(const KeyRowArray& from, uint32_t num_rows_to_append,\n+                               const uint16_t* source_row_ids);\n+    const KeyRowMetadata& get_metadata() const { return metadata_; }\n+    int64_t get_length() const { return num_rows_; }\n+    const uint8_t* data(int i) const {\n+      ARROW_DCHECK(i >= 0 && i <= max_buffers_);\n+      return buffers_[i];\n+    }\n+    uint8_t* mutable_data(int i) {\n+      ARROW_DCHECK(i >= 0 && i <= max_buffers_);\n+      return mutable_buffers_[i];\n+    }\n+    const uint32_t* get_offsets() const {\n\nReview comment:\n       For simple accessors, please name functions in snake_case and without prefixes like `get_`\r\n   ```suggestion\r\n       const uint32_t* offsets() const {\r\n   ```\n\n##########\nFile path: cpp/src/arrow/engine/util.h\n##########\n@@ -0,0 +1,167 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#if defined(__clang__) || defined(__GNUC__)\n+#define BYTESWAP(x) __builtin_bswap64(x)\n+#define ROTL(x, n) (((x) << (n)) | ((x) >> (32 - (n))))\n+#elif defined(_MSC_VER)\n+#include <intrin.h>\n+#define BYTESWAP(x) _byteswap_uint64(x)\n+#define ROTL(x, n) _rotl((x), (n))\n+#endif\n+\n+namespace arrow {\n+namespace util {\n+\n+enum class CPUInstructionSet {\n+  scalar,\n+  avx2,   // All of: AVX2, BMI2\n+  avx512  // In addition to avx2, all of: AVX512-F, AVX512-BW, AVX512-DQ, AVX512-CD\n+};\n+\n+/// Storage used to allocate temporary vectors of a batch size.\n+/// Temporary vectors should resemble allocating temporary variables on the stack\n+/// but in the context of vectorized processing where we need to store a vector of\n+/// temporaries instead of a single value.\n+class TempVectorStack {\n+  template <typename>\n+  friend class TempVectorHolder;\n+\n+ public:\n+  Status Init(MemoryPool* pool, int64_t size) {\n+    pool_ = pool;\n+    num_vectors_ = 0;\n+    top_ = 0;\n+    buffer_size_ = size;\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, AllocateResizableBuffer(size, pool_));\n+    buffer_ = std::move(buffer);\n+    return Status::OK();\n+  }\n+\n+ private:\n+  void alloc(uint32_t num_bytes, uint8_t*& data, int& id) {\n+    int64_t old_top = top_;\n+    top_ += num_bytes + padding;\n+    // Stack overflow check\n+    ARROW_DCHECK(top_ <= buffer_size_);\n+    data = buffer_->mutable_data() + old_top;\n+    id = num_vectors_++;\n+  }\n+  void release(int id, uint32_t num_bytes) {\n+    ARROW_DCHECK(num_vectors_ == id + 1);\n+    int64_t size = num_bytes + padding;\n+    ARROW_DCHECK(top_ >= size);\n+    top_ -= size;\n+    --num_vectors_;\n+  }\n+  static constexpr int64_t padding = 64;\n+  MemoryPool* pool_;\n+  int num_vectors_;\n+  int64_t top_;\n+  std::unique_ptr<ResizableBuffer> buffer_;\n+  int64_t buffer_size_;\n+};\n+\n+template <typename T>\n+class TempVectorHolder {\n+  friend class TempVectorStack;\n+\n+ public:\n+  ~TempVectorHolder() { stack_->release(id_, num_elements_ * sizeof(T)); }\n+  T* mutable_data() { return reinterpret_cast<T*>(data_); }\n+  TempVectorHolder(TempVectorStack* stack, uint32_t num_elements) {\n+    stack_ = stack;\n+    num_elements_ = num_elements;\n+    stack_->alloc(num_elements * sizeof(T), data_, id_);\n+  }\n+\n+ private:\n+  TempVectorStack* stack_;\n+  uint8_t* data_;\n+  int id_;\n+  uint32_t num_elements_;\n+};\n+\n+class BitUtil {\n+ public:\n+  template <int bit_to_search = 1>\n\nReview comment:\n       To avoid counterintuitive instantiation/linkage, please don't declare templates in headers then instantiate them in source files. Templates should either be publicly defined or confined to a single translation unit (declared only in a source file).\n\n##########\nFile path: cpp/src/arrow/engine/util.h\n##########\n@@ -0,0 +1,167 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#if defined(__clang__) || defined(__GNUC__)\n+#define BYTESWAP(x) __builtin_bswap64(x)\n+#define ROTL(x, n) (((x) << (n)) | ((x) >> (32 - (n))))\n+#elif defined(_MSC_VER)\n+#include <intrin.h>\n+#define BYTESWAP(x) _byteswap_uint64(x)\n+#define ROTL(x, n) _rotl((x), (n))\n+#endif\n+\n+namespace arrow {\n+namespace util {\n+\n+enum class CPUInstructionSet {\n+  scalar,\n+  avx2,   // All of: AVX2, BMI2\n+  avx512  // In addition to avx2, all of: AVX512-F, AVX512-BW, AVX512-DQ, AVX512-CD\n+};\n+\n+/// Storage used to allocate temporary vectors of a batch size.\n+/// Temporary vectors should resemble allocating temporary variables on the stack\n+/// but in the context of vectorized processing where we need to store a vector of\n+/// temporaries instead of a single value.\n+class TempVectorStack {\n+  template <typename>\n+  friend class TempVectorHolder;\n+\n+ public:\n+  Status Init(MemoryPool* pool, int64_t size) {\n+    pool_ = pool;\n+    num_vectors_ = 0;\n+    top_ = 0;\n+    buffer_size_ = size;\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, AllocateResizableBuffer(size, pool_));\n+    buffer_ = std::move(buffer);\n+    return Status::OK();\n+  }\n+\n+ private:\n+  void alloc(uint32_t num_bytes, uint8_t*& data, int& id) {\n+    int64_t old_top = top_;\n+    top_ += num_bytes + padding;\n+    // Stack overflow check\n+    ARROW_DCHECK(top_ <= buffer_size_);\n+    data = buffer_->mutable_data() + old_top;\n+    id = num_vectors_++;\n+  }\n+  void release(int id, uint32_t num_bytes) {\n+    ARROW_DCHECK(num_vectors_ == id + 1);\n+    int64_t size = num_bytes + padding;\n+    ARROW_DCHECK(top_ >= size);\n+    top_ -= size;\n+    --num_vectors_;\n+  }\n+  static constexpr int64_t padding = 64;\n+  MemoryPool* pool_;\n+  int num_vectors_;\n+  int64_t top_;\n+  std::unique_ptr<ResizableBuffer> buffer_;\n\nReview comment:\n       ```suggestion\r\n     std::unique_ptr<Buffer> buffer_;\r\n   ```\n\n##########\nFile path: cpp/src/arrow/engine/util.h\n##########\n@@ -0,0 +1,167 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#if defined(__clang__) || defined(__GNUC__)\n+#define BYTESWAP(x) __builtin_bswap64(x)\n+#define ROTL(x, n) (((x) << (n)) | ((x) >> (32 - (n))))\n+#elif defined(_MSC_VER)\n+#include <intrin.h>\n+#define BYTESWAP(x) _byteswap_uint64(x)\n+#define ROTL(x, n) _rotl((x), (n))\n+#endif\n+\n+namespace arrow {\n+namespace util {\n+\n+enum class CPUInstructionSet {\n+  scalar,\n+  avx2,   // All of: AVX2, BMI2\n+  avx512  // In addition to avx2, all of: AVX512-F, AVX512-BW, AVX512-DQ, AVX512-CD\n+};\n+\n+/// Storage used to allocate temporary vectors of a batch size.\n+/// Temporary vectors should resemble allocating temporary variables on the stack\n+/// but in the context of vectorized processing where we need to store a vector of\n+/// temporaries instead of a single value.\n+class TempVectorStack {\n+  template <typename>\n+  friend class TempVectorHolder;\n+\n+ public:\n+  Status Init(MemoryPool* pool, int64_t size) {\n+    pool_ = pool;\n+    num_vectors_ = 0;\n+    top_ = 0;\n+    buffer_size_ = size;\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, AllocateResizableBuffer(size, pool_));\n+    buffer_ = std::move(buffer);\n+    return Status::OK();\n+  }\n+\n+ private:\n+  void alloc(uint32_t num_bytes, uint8_t*& data, int& id) {\n+    int64_t old_top = top_;\n+    top_ += num_bytes + padding;\n+    // Stack overflow check\n+    ARROW_DCHECK(top_ <= buffer_size_);\n+    data = buffer_->mutable_data() + old_top;\n+    id = num_vectors_++;\n+  }\n+  void release(int id, uint32_t num_bytes) {\n+    ARROW_DCHECK(num_vectors_ == id + 1);\n+    int64_t size = num_bytes + padding;\n+    ARROW_DCHECK(top_ >= size);\n+    top_ -= size;\n+    --num_vectors_;\n+  }\n+  static constexpr int64_t padding = 64;\n+  MemoryPool* pool_;\n\nReview comment:\n       TempVectorStack doesn't seem to use this MemoryPool outside of init(), could you remove it and add a comment describing the use of this class?\n\n##########\nFile path: cpp/src/arrow/engine/key_encode.h\n##########\n@@ -0,0 +1,544 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/engine/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+/// Converts between key representation as a collection of arrays for\n+/// individual columns and another representation as a single array of rows\n+/// combining data from all columns into one value.\n+/// This conversion is reversible.\n+/// Row-oriented storage is beneficial when there is a need for random access\n+/// of individual rows and at the same time all included columns are likely to\n+/// be accessed together, as in the case of hash table key.\n+class KeyEncoder {\n+ public:\n+  struct KeyEncoderContext {\n+    bool has_avx2() const { return instr == util::CPUInstructionSet::avx2; }\n+    util::CPUInstructionSet instr;\n+    util::TempVectorStack* stack;\n+  };\n+\n+  /// Description of a storage format for rows produced by encoder.\n+  struct KeyRowMetadata {\n+    uint32_t get_num_varbinary_cols() const {\n+      return cumulative_lengths_length / sizeof(uint32_t);\n+    }\n+    /// Is row a varying-length binary, using offsets array to find a beginning of a row,\n+    /// or is it a fixed-length binary.\n+    bool is_fixed_length;\n+    /// For a fixed-length binary row, common size of rows in bytes.\n+    /// For a varying-length binary, size of all encoded fixed-length key columns.\n+    /// Encoded fixed-length key columns in that case prefix the information\n+    /// about all varying-length key columns.\n+    uint32_t fixed_length;\n+    /// Size in bytes of optional cumulative lengths of varying-length key columns,\n+    /// used when the row is not fixed length.\n+    /// Zero for fixed-length row.\n+    /// This number is equal to the number of varying-length key columns multiplied\n+    /// by sizeof(uint32_t), which is the size of a single cumulative length.\n+    uint32_t cumulative_lengths_length;\n+    /// Fixed number of bytes per row that are used to encode null masks.\n+    /// Null masks indicate for a single row which of its key columns are null.\n+    /// Nth bit in the sequence of bytes assigned to a row represents null\n+    /// information for Nth key column.\n+    int null_masks_bytes_per_row;\n+  };\n+\n+  class KeyRowArray {\n+   public:\n+    KeyRowArray();\n+    Status Init(MemoryPool* pool, const KeyRowMetadata& metadata);\n+    void Clean();\n+    Status AppendEmpty(uint32_t num_rows_to_append, uint32_t num_extra_bytes_to_append);\n+    Status AppendSelectionFrom(const KeyRowArray& from, uint32_t num_rows_to_append,\n+                               const uint16_t* source_row_ids);\n+    const KeyRowMetadata& get_metadata() const { return metadata_; }\n+    int64_t get_length() const { return num_rows_; }\n+    const uint8_t* data(int i) const {\n+      ARROW_DCHECK(i >= 0 && i <= max_buffers_);\n+      return buffers_[i];\n+    }\n+    uint8_t* mutable_data(int i) {\n+      ARROW_DCHECK(i >= 0 && i <= max_buffers_);\n+      return mutable_buffers_[i];\n+    }\n+    const uint32_t* get_offsets() const {\n+      return reinterpret_cast<const uint32_t*>(data(1));\n+    }\n+    uint32_t* get_mutable_offsets() {\n+      return reinterpret_cast<uint32_t*>(mutable_data(1));\n+    }\n+    const uint8_t* get_null_masks() const { return null_masks_->data(); }\n+    uint8_t* get_null_masks() { return null_masks_->mutable_data(); }\n+\n+    bool has_any_nulls(const KeyEncoderContext* ctx) const;\n+\n+   private:\n+    Status ResizeFixedLengthBuffers(int64_t num_extra_rows);\n+    Status ResizeOptionalVaryingLengthBuffer(int64_t num_extra_bytes);\n+\n+    int64_t size_null_masks(int64_t num_rows);\n+    int64_t size_offsets(int64_t num_rows);\n+    int64_t size_rows_fixed_length(int64_t num_rows);\n+    int64_t size_rows_varying_length(int64_t num_bytes);\n+    void update_buffer_pointers();\n+\n+    static constexpr int64_t padding_for_vectors = 64;\n+    MemoryPool* pool_;\n+    KeyRowMetadata metadata_;\n+    /// Buffers can only expand during lifetime and never shrink.\n+    std::unique_ptr<ResizableBuffer> null_masks_;\n+    std::unique_ptr<ResizableBuffer> offsets_;\n+    std::unique_ptr<ResizableBuffer> rows_;\n+    static constexpr int max_buffers_ = 3;\n+    const uint8_t* buffers_[max_buffers_];\n+    uint8_t* mutable_buffers_[max_buffers_];\n+    int64_t num_rows_;\n+    int64_t rows_capacity_;\n+    int64_t bytes_capacity_;\n+\n+    // Mutable to allow lazy evaluation\n+    mutable int64_t num_rows_for_has_any_nulls_;\n+    mutable bool has_any_nulls_;\n+  };\n+\n+  /// Description of a storage format of a single key column as needed\n+  /// for the purpose of row encoding.\n+  struct KeyColumnMetadata {\n+    KeyColumnMetadata() {}\n+    KeyColumnMetadata(bool is_fixed_length_in, uint32_t fixed_length_in)\n+        : is_fixed_length(is_fixed_length_in), fixed_length(fixed_length_in) {}\n+    /// Is column storing a varying-length binary, using offsets array\n+    /// to find a beginning of a value, or is it a fixed-length binary.\n+    bool is_fixed_length;\n+    /// For a fixed-length binary column: number of bytes per value.\n+    /// Zero has a special meaning, indicating a bit vector with one bit per value.\n+    /// For a varying-length binary column: number of bytes per offset.\n+    uint32_t fixed_length;\n+  };\n+\n+  /// A lightweight description of an array representing one of key columns.\n+  class KeyColumnArray {\n+   public:\n+    KeyColumnArray() {}\n+    /// Create as a mix of buffers according to the mask from two descriptions\n+    /// (Nth bit is set to 0 if Nth buffer from the first input\n+    /// should be used and is set to 1 otherwise).\n+    /// Metadata is inherited from the first input.\n+    KeyColumnArray(const KeyColumnMetadata& metadata, const KeyColumnArray& left,\n+                   const KeyColumnArray& right, int buffer_id_to_replace);\n+    /// Create for reading\n+    KeyColumnArray(const KeyColumnMetadata& metadata, int64_t length,\n+                   const uint8_t* buffer0, const uint8_t* buffer1,\n+                   const uint8_t* buffer2);\n+    /// Create for writing\n+    KeyColumnArray(const KeyColumnMetadata& metadata, int64_t length, uint8_t* buffer0,\n+                   uint8_t* buffer1, uint8_t* buffer2);\n+    /// Create as a window view of original description that is offset\n+    /// by a given number of rows.\n+    /// The number of rows used in offset must be divisible by 8\n+    /// in order to not split bit vectors within a single byte.\n+    KeyColumnArray(const KeyColumnArray& from, int64_t start, int64_t length);\n+    uint8_t* mutable_data(int i) {\n+      ARROW_DCHECK(i >= 0 && i <= max_buffers_);\n+      return mutable_buffers_[i];\n+    }\n+    const uint8_t* data(int i) const {\n+      ARROW_DCHECK(i >= 0 && i <= max_buffers_);\n+      return buffers_[i];\n+    }\n+    uint32_t* get_mutable_offsets() {\n+      return reinterpret_cast<uint32_t*>(mutable_data(1));\n+    }\n+    const uint32_t* get_offsets() const {\n+      return reinterpret_cast<const uint32_t*>(data(1));\n+    }\n+    const KeyColumnMetadata& get_metadata() const { return metadata_; }\n+    int64_t get_length() const { return length_; }\n+\n+   private:\n+    static constexpr int max_buffers_ = 3;\n+    const uint8_t* buffers_[max_buffers_];\n+    uint8_t* mutable_buffers_[max_buffers_];\n+    KeyColumnMetadata metadata_;\n+    int64_t length_;\n+  };\n+\n+  void Init(const std::vector<KeyColumnMetadata>& cols, KeyEncoderContext* ctx);\n+\n+  const KeyRowMetadata& get_row_metadata() { return row_metadata_; }\n+\n+  /// Find out the required sizes of all buffers output buffers for encoding\n+  /// (including varying-length buffers).\n+  /// Use that information to resize provided row array so that it can fit\n+  /// encoded data.\n+  Status PrepareOutputForEncode(int64_t start_input_row, int64_t num_input_rows,\n+                                KeyRowArray& rows,\n+                                const std::vector<KeyColumnArray>& all_cols);\n+\n+  /// Encode a window of column oriented data into the entire output\n+  /// row oriented storage.\n+  /// The output buffers for encoding need to be correctly sized before\n+  /// starting encoding.\n+  void Encode(int64_t start_input_row, int64_t num_input_rows, KeyRowArray& rows,\n+              const std::vector<KeyColumnArray>& cols);\n+\n+  /// Decode a window of row oriented data into a corresponding\n+  /// window of column oriented storage.\n+  /// The output buffers need to be correctly allocated and sized before\n+  /// calling each method.\n+  /// For that reason decoding is split into two functions.\n+  /// The output of the first one, that processes everything except for\n+  /// varying length buffers, can be used to find out required varying\n+  /// length buffers sizes.\n+  void DecodeFixedLengthBuffers(int64_t start_row_input, int64_t start_row_output,\n+                                int64_t num_rows, const KeyRowArray& rows,\n+                                std::vector<KeyColumnArray>& cols);\n+\n+  void DecodeVaryingLengthBuffers(int64_t start_row_input, int64_t start_row_output,\n+                                  int64_t num_rows, const KeyRowArray& rows,\n+                                  std::vector<KeyColumnArray>& cols);\n+\n+ private:\n+  void PrepareMetadata(const std::vector<KeyColumnMetadata>& col_metadata,\n+                       KeyRowMetadata* out_row_metadata);\n+\n+  /// Prepare column array vectors.\n+  /// Output column arrays represent a range of input column arrays\n+  /// specified by starting row and number of rows.\n+  /// Three vectors are generated:\n+  /// - all columns\n+  /// - fixed-length columns only\n+  /// - varying-length columns only\n+  void PrepareKeyColumnArrays(int64_t start_row, int64_t num_rows,\n+                              const std::vector<KeyColumnArray>& cols_in,\n+                              std::vector<KeyColumnArray>* out_all_cols,\n+                              std::vector<KeyColumnArray>* out_fixedbinary_cols,\n+                              std::vector<KeyColumnArray>* out_varbinary_cols,\n+                              std::vector<uint32_t>* batch_varbinary_cols_base_offsets);\n+\n+  void GetOutputBufferSizeForEncode(int64_t start_row, int64_t num_rows,\n+                                    const KeyRowMetadata& row_metadata,\n+                                    const std::vector<KeyColumnArray>& all_cols,\n+                                    int64_t* out_num_bytes_required);\n+\n+  class TransformBoolean {\n+   public:\n+    static KeyColumnArray ArrayReplace(const KeyColumnArray& column,\n+                                       const KeyColumnArray& temp);\n+    static void PreEncode(const KeyColumnArray& input, KeyColumnArray& output,\n+                          KeyEncoderContext* ctx);\n+    static void PostDecode(const KeyColumnArray& input, KeyColumnArray& output,\n+                           KeyEncoderContext* ctx);\n+  };\n+\n+  class EncoderInteger {\n+   public:\n+    static void Encode(uint32_t* offset_within_row, KeyRowArray& rows,\n+                       const KeyColumnArray& col, KeyEncoderContext* ctx,\n+                       KeyColumnArray& temp);\n+    static void Decode(uint32_t start_row, uint32_t num_rows, uint32_t* offset_within_row,\n+                       const KeyRowArray& rows, KeyColumnArray& col,\n+                       KeyEncoderContext* ctx, KeyColumnArray& temp);\n+    static bool UsesTransform(const KeyColumnArray& column);\n+    static KeyColumnArray ArrayReplace(const KeyColumnArray& column,\n+                                       KeyColumnArray& temp);\n+    static void PreEncode(const KeyColumnArray& input, KeyColumnArray& output,\n+                          KeyEncoderContext* ctx);\n+    static void PostDecode(const KeyColumnArray& input, KeyColumnArray& output,\n+                           KeyEncoderContext* ctx);\n+\n+   private:\n+    static bool IsBoolean(const KeyColumnMetadata& metadata);\n+  };\n+\n+  class EncoderBinary {\n+   public:\n+    static void Encode(uint32_t* offset_within_row, KeyRowArray& rows,\n+                       const KeyColumnArray& col, KeyEncoderContext* ctx,\n+                       KeyColumnArray& temp);\n+    static void Decode(uint32_t start_row, uint32_t num_rows, uint32_t* offset_within_row,\n+                       const KeyRowArray& rows, KeyColumnArray& col,\n+                       KeyEncoderContext* ctx, KeyColumnArray& temp);\n+    static bool IsInteger(const KeyColumnMetadata& metadata);\n+\n+   private:\n+    template <bool is_row_fixed_length, bool is_encoding, class COPY_FN>\n+    static inline void EncodeDecodeHelper(uint32_t start_row, uint32_t num_rows,\n+                                          uint32_t offset_within_row,\n+                                          const KeyRowArray* rows_const,\n+                                          KeyRowArray* rows_mutable_maybe_null,\n+                                          const KeyColumnArray* col_const,\n+                                          KeyColumnArray* col_mutable_maybe_null,\n+                                          COPY_FN copy_fn);\n+    template <bool is_row_fixed_length>\n+    static void EncodeImp(uint32_t offset_within_row, KeyRowArray& rows,\n+                          const KeyColumnArray& col);\n+    template <bool is_row_fixed_length>\n+    static void DecodeImp(uint32_t start_row, uint32_t num_rows,\n+                          uint32_t offset_within_row, const KeyRowArray& rows,\n+                          KeyColumnArray& col);\n+#if defined(ARROW_HAVE_AVX2)\n+    template <bool is_row_fixed_length>\n+    static void EncodeImp_avx2(uint32_t offset_within_row, KeyRowArray& rows,\n+                               const KeyColumnArray& col);\n+    template <bool is_row_fixed_length>\n+    static void DecodeImp_avx2(uint32_t start_row, uint32_t num_rows,\n+                               uint32_t offset_within_row, const KeyRowArray& rows,\n+                               KeyColumnArray& col);\n+#endif\n+    static void ColumnMemsetNulls(uint32_t offset_within_row, KeyRowArray& rows,\n+                                  const KeyColumnArray& col, KeyEncoderContext* ctx,\n+                                  KeyColumnArray& temp_vector_16bit, uint8_t byte_value);\n+    template <bool is_row_fixed_length, uint32_t col_width>\n+    static void ColumnMemsetNullsImp(uint32_t offset_within_row, KeyRowArray& rows,\n+                                     const KeyColumnArray& col, KeyEncoderContext* ctx,\n+                                     KeyColumnArray& temp_vector_16bit,\n+                                     uint8_t byte_value);\n+  };\n+\n+  class EncoderBinaryPair {\n+   public:\n+    static bool CanProcessPair(const KeyColumnMetadata& col1,\n+                               const KeyColumnMetadata& col2) {\n+      return EncoderBinary::IsInteger(col1) && EncoderBinary::IsInteger(col2);\n+    }\n+    static void Encode(uint32_t* offset_within_row, KeyRowArray& rows,\n+                       const KeyColumnArray& col1, const KeyColumnArray& col2,\n+                       KeyEncoderContext* ctx, KeyColumnArray& temp1,\n+                       KeyColumnArray& temp2);\n+    static void Decode(uint32_t start_row, uint32_t num_rows, uint32_t* offset_within_row,\n+                       const KeyRowArray& rows, KeyColumnArray& col1,\n+                       KeyColumnArray& col2, KeyEncoderContext* ctx,\n+                       KeyColumnArray& temp1, KeyColumnArray& temp2);\n+\n+   private:\n+    template <bool is_row_fixed_length, typename col1_type, typename col2_type>\n+    static void EncodeImp(uint32_t num_rows_to_skip, uint32_t offset_within_row,\n+                          KeyRowArray& rows, const KeyColumnArray& col1,\n+                          const KeyColumnArray& col2);\n+    template <bool is_row_fixed_length, typename col1_type, typename col2_type>\n+    static void DecodeImp(uint32_t num_rows_to_skip, uint32_t start_row,\n+                          uint32_t num_rows, uint32_t offset_within_row,\n+                          const KeyRowArray& rows, KeyColumnArray& col1,\n+                          KeyColumnArray& col2);\n+#if defined(ARROW_HAVE_AVX2)\n+    template <bool is_row_fixed_length, uint32_t col_width>\n+    static uint32_t EncodeImp_avx2(uint32_t offset_within_row, KeyRowArray& rows,\n+                                   const KeyColumnArray& col1,\n+                                   const KeyColumnArray& col2);\n+    template <bool is_row_fixed_length, uint32_t col_width>\n+    static uint32_t DecodeImp_avx2(uint32_t start_row, uint32_t num_rows,\n+                                   uint32_t offset_within_row, const KeyRowArray& rows,\n+                                   KeyColumnArray& col1, KeyColumnArray& col2);\n+#endif\n+  };\n+\n+  class EncoderOffsets {\n+   public:\n+    // In order not to repeat work twice,\n+    // encoding combines in a single pass computing of:\n+    // a) row offsets for varying-length rows\n+    // b) within each new row, the cumulative length array\n+    // of varying-length values within a row.\n+    static void Encode(KeyRowArray& rows,\n+                       const std::vector<KeyColumnArray>& varbinary_cols,\n+                       KeyEncoderContext* ctx);\n+    static void Decode(uint32_t start_row, uint32_t num_rows, const KeyRowArray& rows,\n+                       std::vector<KeyColumnArray>& varbinary_cols,\n+                       std::vector<uint32_t>& varbinary_cols_base_offset,\n+                       KeyEncoderContext* ctx);\n+\n+   private:\n+    static void EncodeImp(uint32_t num_rows_already_processed, KeyRowArray& rows,\n+                          const std::vector<KeyColumnArray>& varbinary_cols);\n+#if defined(ARROW_HAVE_AVX2)\n+    static uint32_t EncodeImp_avx2(KeyRowArray& rows,\n+                                   const std::vector<KeyColumnArray>& varbinary_cols,\n+                                   KeyColumnArray& temp_buffer_32B_per_col);\n+#endif\n+  };\n+\n+  class EncoderVarBinary {\n+   public:\n+    static void Encode(uint32_t varbinary_col_id, KeyRowArray& rows,\n+                       const KeyColumnArray& col, KeyEncoderContext* ctx);\n+    static void Decode(uint32_t start_row, uint32_t num_rows, uint32_t varbinary_col_id,\n+                       const KeyRowArray& rows, KeyColumnArray& col,\n+                       KeyEncoderContext* ctx);\n+\n+   private:\n+    template <bool first_varbinary_col, bool is_encoding, class COPY_FN>\n+    static inline void EncodeDecodeHelper(uint32_t start_row, uint32_t num_rows,\n+                                          uint32_t varbinary_col_id,\n+                                          const KeyRowArray* rows_const,\n+                                          KeyRowArray* rows_mutable_maybe_null,\n+                                          const KeyColumnArray* col_const,\n+                                          KeyColumnArray* col_mutable_maybe_null,\n+                                          COPY_FN copy_fn);\n+    template <bool first_varbinary_col>\n+    static void EncodeImp(uint32_t varbinary_col_id, KeyRowArray& rows,\n+                          const KeyColumnArray& col);\n+    template <bool first_varbinary_col>\n+    static void DecodeImp(uint32_t start_row, uint32_t num_rows,\n+                          uint32_t varbinary_col_id, const KeyRowArray& rows,\n+                          KeyColumnArray& col);\n+#if defined(ARROW_HAVE_AVX2)\n+    template <bool first_varbinary_col>\n+    static void EncodeImp_avx2(uint32_t varbinary_col_id, KeyRowArray& rows,\n+                               const KeyColumnArray& col);\n+    template <bool first_varbinary_col>\n+    static void DecodeImp_avx2(uint32_t start_row, uint32_t num_rows,\n+                               uint32_t varbinary_col_id, const KeyRowArray& rows,\n+                               KeyColumnArray& col);\n+#endif\n+  };\n+\n+  class EncoderNulls {\n+   public:\n+    static void Encode(KeyRowArray& rows, const std::vector<KeyColumnArray>& cols,\n\nReview comment:\n       Please avoid mutable references. For out arguments, please use a mutable pointer\r\n   ```suggestion\r\n       static void Encode(KeyRowArray* rows, const std::vector<KeyColumnArray>& cols,\r\n   ```\n\n##########\nFile path: cpp/src/arrow/engine/util_avx2.cc\n##########\n@@ -0,0 +1,183 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <immintrin.h>\n+\n+#include \"arrow/engine/util.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace util {\n+\n+#if defined(ARROW_HAVE_AVX2)\n+\n+template <int bit_to_search>\n+void BitUtil::bits_to_indexes_avx2(const int num_bits, const uint8_t* bits,\n+                                   int& num_indexes, uint16_t* indexes) {\n+  // 64 bits at a time\n+  constexpr int unroll = 64;\n+\n+  // The caller takes care of processing the remaining bits at the end outside of the\n+  // multiples of 64\n+  ARROW_DCHECK(num_bits % unroll == 0);\n+\n+  uint8_t byte_indexes[64];\n+  const uint64_t incr = 0x0808080808080808ULL;\n+  const uint64_t mask = 0x0706050403020100ULL;\n+  num_indexes = 0;\n+  for (int i = 0; i < num_bits / unroll; ++i) {\n+    uint64_t word = reinterpret_cast<const uint64_t*>(bits)[i];\n+    if (bit_to_search == 0) {\n+      word = ~word;\n+    }\n+    uint64_t base = 0;\n+    int num_indexes_loop = 0;\n+    while (word) {\n+      uint64_t byte_indexes_next =\n+          _pext_u64(mask, _pdep_u64(word, UINT64_C(0X0101010101010101)) * 0xff) + base;\n+      *reinterpret_cast<uint64_t*>(byte_indexes + num_indexes_loop) = byte_indexes_next;\n+      base += incr;\n+      num_indexes_loop += static_cast<int>(arrow::BitUtil::PopCount(word & 0xff));\n+      word >>= 8;\n+    }\n+    // Unpack indexes to 16-bits and either add the base of i * 64 or shuffle input\n+    // indexes\n+    for (int j = 0; j < (num_indexes_loop + 15) / 16; ++j) {\n+      __m256i output = _mm256_cvtepi8_epi16(\n+          _mm_loadu_si128(reinterpret_cast<const __m128i*>(byte_indexes) + j));\n+      output = _mm256_add_epi16(output, _mm256_set1_epi16(i * 64));\n+      _mm256_storeu_si256(((__m256i*)(indexes + num_indexes)) + j, output);\n+    }\n+    num_indexes += num_indexes_loop;\n+  }\n+}\n+template void BitUtil::bits_to_indexes_avx2<0>(const int num_bits, const uint8_t* bits,\n+                                               int& num_indexes, uint16_t* indexes);\n+template void BitUtil::bits_to_indexes_avx2<1>(const int num_bits, const uint8_t* bits,\n+                                               int& num_indexes, uint16_t* indexes);\n+\n+template <int bit_to_search>\n+void BitUtil::bits_filter_indexes_avx2(const int num_bits, const uint8_t* bits,\n+                                       const uint16_t* input_indexes, int& num_indexes,\n+                                       uint16_t* indexes) {\n+  // 64 bits at a time\n+  constexpr int unroll = 64;\n+\n+  // The caller takes care of processing the remaining bits at the end outside of the\n+  // multiples of 64\n+  ARROW_DCHECK(num_bits % unroll == 0);\n+\n+  const uint64_t mask = 0xfedcba9876543210ULL;\n+  num_indexes = 0;\n+  for (int i = 0; i < num_bits / unroll; ++i) {\n+    uint64_t word = reinterpret_cast<const uint64_t*>(bits)[i];\n+    if (bit_to_search == 0) {\n+      word = ~word;\n+    }\n+\n+    int loop_id = 0;\n+    while (word) {\n+      uint64_t indexes_4bit =\n+          _pext_u64(mask, _pdep_u64(word, UINT64_C(0x1111111111111111)) * 0xf);\n+      // Unpack 4 bit indexes to 8 bits\n+      __m256i indexes_8bit = _mm256_set1_epi64x(indexes_4bit);\n+      indexes_8bit = _mm256_shuffle_epi8(\n+          indexes_8bit, _mm256_setr_epi64x(0x0303020201010000ULL, 0x0707060605050404ULL,\n+                                           0x0303020201010000ULL, 0x0707060605050404ULL));\n+      indexes_8bit = _mm256_blendv_epi8(\n+          _mm256_and_si256(indexes_8bit, _mm256_set1_epi8(0x0f)),\n+          _mm256_and_si256(_mm256_srli_epi32(indexes_8bit, 4), _mm256_set1_epi8(0x0f)),\n+          _mm256_set1_epi16(static_cast<uint16_t>(0xff00)));\n+      __m256i input =\n+          _mm256_loadu_si256(((const __m256i*)input_indexes) + 4 * i + loop_id);\n+      // Shuffle bytes to get low bytes in the first 128-bit lane and high bytes in the\n+      // second\n+      input = _mm256_shuffle_epi8(\n+          input, _mm256_setr_epi64x(0x0e0c0a0806040200ULL, 0x0f0d0b0907050301ULL,\n+                                    0x0e0c0a0806040200ULL, 0x0f0d0b0907050301ULL));\n\nReview comment:\n       Please create `constexpr` variables for any magic numbers\n\n##########\nFile path: cpp/src/arrow/engine/groupby.h\n##########\n@@ -0,0 +1,84 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"arrow/engine/key_compare.h\"\n+#include \"arrow/engine/key_encode.h\"\n+#include \"arrow/engine/key_hash.h\"\n+#include \"arrow/engine/key_map.h\"\n+#include \"arrow/engine/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+class GroupMap {\n\nReview comment:\n       GroupMap seems to be a pure implementation detail of GrouperFastImpl. If there isn't a reason to keep the two classes distinct, could we consolidate them into GrouperFastImpl\n\n##########\nFile path: cpp/src/arrow/engine/key_encode.h\n##########\n@@ -0,0 +1,544 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/engine/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+/// Converts between key representation as a collection of arrays for\n+/// individual columns and another representation as a single array of rows\n+/// combining data from all columns into one value.\n+/// This conversion is reversible.\n+/// Row-oriented storage is beneficial when there is a need for random access\n+/// of individual rows and at the same time all included columns are likely to\n+/// be accessed together, as in the case of hash table key.\n+class KeyEncoder {\n+ public:\n+  struct KeyEncoderContext {\n+    bool has_avx2() const { return instr == util::CPUInstructionSet::avx2; }\n+    util::CPUInstructionSet instr;\n+    util::TempVectorStack* stack;\n+  };\n+\n+  /// Description of a storage format for rows produced by encoder.\n+  struct KeyRowMetadata {\n+    uint32_t get_num_varbinary_cols() const {\n\nReview comment:\n       For member functions, please use CamelCase\r\n   ```suggestion\r\n       uint32_t GetNumVarBinaryCols() const {\r\n   ```\n\n##########\nFile path: cpp/src/arrow/engine/util.h\n##########\n@@ -0,0 +1,167 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#if defined(__clang__) || defined(__GNUC__)\n+#define BYTESWAP(x) __builtin_bswap64(x)\n+#define ROTL(x, n) (((x) << (n)) | ((x) >> (32 - (n))))\n+#elif defined(_MSC_VER)\n+#include <intrin.h>\n+#define BYTESWAP(x) _byteswap_uint64(x)\n+#define ROTL(x, n) _rotl((x), (n))\n+#endif\n+\n+namespace arrow {\n+namespace util {\n+\n+enum class CPUInstructionSet {\n+  scalar,\n+  avx2,   // All of: AVX2, BMI2\n+  avx512  // In addition to avx2, all of: AVX512-F, AVX512-BW, AVX512-DQ, AVX512-CD\n+};\n+\n+/// Storage used to allocate temporary vectors of a batch size.\n+/// Temporary vectors should resemble allocating temporary variables on the stack\n+/// but in the context of vectorized processing where we need to store a vector of\n+/// temporaries instead of a single value.\n+class TempVectorStack {\n+  template <typename>\n+  friend class TempVectorHolder;\n+\n+ public:\n+  Status Init(MemoryPool* pool, int64_t size) {\n+    pool_ = pool;\n+    num_vectors_ = 0;\n+    top_ = 0;\n+    buffer_size_ = size;\n+    ARROW_ASSIGN_OR_RAISE(auto buffer, AllocateResizableBuffer(size, pool_));\n+    buffer_ = std::move(buffer);\n+    return Status::OK();\n+  }\n+\n+ private:\n+  void alloc(uint32_t num_bytes, uint8_t*& data, int& id) {\n+    int64_t old_top = top_;\n+    top_ += num_bytes + padding;\n+    // Stack overflow check\n+    ARROW_DCHECK(top_ <= buffer_size_);\n+    data = buffer_->mutable_data() + old_top;\n+    id = num_vectors_++;\n+  }\n+  void release(int id, uint32_t num_bytes) {\n+    ARROW_DCHECK(num_vectors_ == id + 1);\n+    int64_t size = num_bytes + padding;\n+    ARROW_DCHECK(top_ >= size);\n+    top_ -= size;\n+    --num_vectors_;\n+  }\n+  static constexpr int64_t padding = 64;\n+  MemoryPool* pool_;\n+  int num_vectors_;\n+  int64_t top_;\n+  std::unique_ptr<ResizableBuffer> buffer_;\n+  int64_t buffer_size_;\n+};\n+\n+template <typename T>\n+class TempVectorHolder {\n+  friend class TempVectorStack;\n+\n+ public:\n+  ~TempVectorHolder() { stack_->release(id_, num_elements_ * sizeof(T)); }\n+  T* mutable_data() { return reinterpret_cast<T*>(data_); }\n+  TempVectorHolder(TempVectorStack* stack, uint32_t num_elements) {\n+    stack_ = stack;\n+    num_elements_ = num_elements;\n+    stack_->alloc(num_elements * sizeof(T), data_, id_);\n+  }\n+\n+ private:\n+  TempVectorStack* stack_;\n+  uint8_t* data_;\n+  int id_;\n+  uint32_t num_elements_;\n+};\n+\n+class BitUtil {\n+ public:\n+  template <int bit_to_search = 1>\n+  static void bits_to_indexes(CPUInstructionSet instruction_set, const int num_bits,\n+                              const uint8_t* bits, int& num_indexes, uint16_t* indexes);\n+\n+  template <int bit_to_search = 1>\n+  static void bits_filter_indexes(CPUInstructionSet instruction_set, const int num_bits,\n+                                  const uint8_t* bits, const uint16_t* input_indexes,\n+                                  int& num_indexes, uint16_t* indexes);\n+\n+  // Input and output indexes may be pointing to the same data (in-place filtering).\n+  static void bits_split_indexes(CPUInstructionSet instruction_set, const int num_bits,\n+                                 const uint8_t* bits, int& num_indexes_bit0,\n+                                 uint16_t* indexes_bit0, uint16_t* indexes_bit1);\n+\n+  // Bit 1 is replaced with byte 0xFF.\n+  static void bits_to_bytes(CPUInstructionSet instruction_set, const int num_bits,\n+                            const uint8_t* bits, uint8_t* bytes);\n\nReview comment:\n       These bit utilities are generally useful, please put them into a header so others could take advantage of them. For example cpp/src/arrow/util/bitmap_builders.h has BytesToBits, for which this should become an overload.\n\n##########\nFile path: cpp/src/arrow/engine/key_map.h\n##########\n@@ -0,0 +1,167 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <functional>\n+\n+#include \"arrow/engine/util.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+//\n+// 0 byte - 7 bucket | 1. byte - 6 bucket | ...\n+// ---------------------------------------------------\n+// |     Empty bit*   |    Empty bit       |\n+// ---------------------------------------------------\n+// |   7-bit hash    |    7-bit hash      |\n+// ---------------------------------------------------\n+// * Empty bucket has value 0x80. Non-empty bucket has highest bit set to 0.\n+// ** The order of bytes is reversed - highest byte represents 0th bucket.\n+// No other part of data structure uses this reversed order.\n+//\n+class SwissTable {\n\nReview comment:\n       Please add a higher level doc comment describing this class and it's utility. Specifically: describe how equality comparison and appending/storage of new entries are deferred to callbacks.\r\n   \r\n   Separately, add a comment detailing its implementation and usage of stamps for vectorized probing.\n\n##########\nFile path: cpp/src/arrow/engine/util.h\n##########\n@@ -0,0 +1,167 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#if defined(__clang__) || defined(__GNUC__)\n+#define BYTESWAP(x) __builtin_bswap64(x)\n+#define ROTL(x, n) (((x) << (n)) | ((x) >> (32 - (n))))\n+#elif defined(_MSC_VER)\n+#include <intrin.h>\n+#define BYTESWAP(x) _byteswap_uint64(x)\n+#define ROTL(x, n) _rotl((x), (n))\n+#endif\n+\n+namespace arrow {\n+namespace util {\n+\n+enum class CPUInstructionSet {\n+  scalar,\n+  avx2,   // All of: AVX2, BMI2\n+  avx512  // In addition to avx2, all of: AVX512-F, AVX512-BW, AVX512-DQ, AVX512-CD\n+};\n\nReview comment:\n       Instead of this, please use `arrow::internal::CpuInfo::{AVX2, AVX512}` or `arrow::compute::SimdLevel::{NONE, AVX2, AVX512}`\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-20T16:45:38.195+0000",
                    "updated": "2021-04-20T16:45:38.195+0000",
                    "started": "2021-04-20T16:45:38.195+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "585997",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/586000",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768#discussion_r616869161\n\n\n\n##########\nFile path: cpp/src/arrow/engine/key_encode.cc\n##########\n@@ -0,0 +1,1604 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/engine/key_encode.h\"\n+\n+#include <memory.h>\n+#include <algorithm>\n+\n+#include \"arrow/engine/util.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+KeyEncoder::KeyRowArray::KeyRowArray()\n+    : pool_(nullptr), rows_capacity_(0), bytes_capacity_(0) {}\n+\n+Status KeyEncoder::KeyRowArray::Init(MemoryPool* pool, const KeyRowMetadata& metadata) {\n+  pool_ = pool;\n+  metadata_ = metadata;\n+\n+  ARROW_DCHECK(!null_masks_ && !offsets_ && !rows_);\n+\n+  constexpr int64_t rows_capacity = 8;\n+  constexpr int64_t bytes_capacity = 1024;\n+\n+  // Null masks\n+  ARROW_ASSIGN_OR_RAISE(auto null_masks,\n+                        AllocateResizableBuffer(size_null_masks(rows_capacity), pool_));\n+  null_masks_ = std::move(null_masks);\n+  memset(null_masks_->mutable_data(), 0, size_null_masks(rows_capacity));\n+\n+  // Offsets and rows\n+  if (!metadata.is_fixed_length) {\n+    ARROW_ASSIGN_OR_RAISE(auto offsets,\n+                          AllocateResizableBuffer(size_offsets(rows_capacity), pool_));\n+    offsets_ = std::move(offsets);\n+    memset(offsets_->mutable_data(), 0, size_offsets(rows_capacity));\n+    reinterpret_cast<uint32_t*>(offsets_->mutable_data())[0] = 0;\n+\n+    ARROW_ASSIGN_OR_RAISE(\n+        auto rows,\n+        AllocateResizableBuffer(size_rows_varying_length(bytes_capacity), pool_));\n+    rows_ = std::move(rows);\n+    memset(rows_->mutable_data(), 0, size_rows_varying_length(bytes_capacity));\n+    bytes_capacity_ = size_rows_varying_length(bytes_capacity) - padding_for_vectors;\n+  } else {\n+    ARROW_ASSIGN_OR_RAISE(\n+        auto rows, AllocateResizableBuffer(size_rows_fixed_length(rows_capacity), pool_));\n+    rows_ = std::move(rows);\n+    memset(rows_->mutable_data(), 0, size_rows_fixed_length(rows_capacity));\n+    bytes_capacity_ = size_rows_fixed_length(rows_capacity) - padding_for_vectors;\n+  }\n+\n+  update_buffer_pointers();\n+\n+  rows_capacity_ = rows_capacity;\n+\n+  num_rows_ = 0;\n+  num_rows_for_has_any_nulls_ = 0;\n+  has_any_nulls_ = false;\n+\n+  return Status::OK();\n+}\n+\n+void KeyEncoder::KeyRowArray::Clean() {\n+  num_rows_ = 0;\n+  num_rows_for_has_any_nulls_ = 0;\n+  has_any_nulls_ = false;\n+\n+  if (!metadata_.is_fixed_length) {\n+    reinterpret_cast<uint32_t*>(offsets_->mutable_data())[0] = 0;\n+  }\n+}\n+\n+int64_t KeyEncoder::KeyRowArray::size_null_masks(int64_t num_rows) {\n+  return num_rows * metadata_.null_masks_bytes_per_row + padding_for_vectors;\n+}\n+\n+int64_t KeyEncoder::KeyRowArray::size_offsets(int64_t num_rows) {\n+  return (num_rows + 1) * sizeof(uint32_t) + padding_for_vectors;\n+}\n+\n+int64_t KeyEncoder::KeyRowArray::size_rows_fixed_length(int64_t num_rows) {\n+  return num_rows * metadata_.fixed_length + padding_for_vectors;\n+}\n+\n+int64_t KeyEncoder::KeyRowArray::size_rows_varying_length(int64_t num_bytes) {\n+  return num_bytes + padding_for_vectors;\n+}\n+\n+void KeyEncoder::KeyRowArray::update_buffer_pointers() {\n+  buffers_[0] = mutable_buffers_[0] = null_masks_->mutable_data();\n+  if (metadata_.is_fixed_length) {\n+    buffers_[1] = mutable_buffers_[1] = rows_->mutable_data();\n+    buffers_[2] = mutable_buffers_[2] = nullptr;\n+  } else {\n+    buffers_[1] = mutable_buffers_[1] = offsets_->mutable_data();\n+    buffers_[2] = mutable_buffers_[2] = rows_->mutable_data();\n+  }\n+}\n+\n+Status KeyEncoder::KeyRowArray::ResizeFixedLengthBuffers(int64_t num_extra_rows) {\n+  if (rows_capacity_ >= num_rows_ + num_extra_rows) {\n+    return Status::OK();\n+  }\n+\n+  int64_t rows_capacity_new = std::max(static_cast<int64_t>(1), 2 * rows_capacity_);\n+  while (rows_capacity_new < num_rows_ + num_extra_rows) {\n+    rows_capacity_new *= 2;\n+  }\n+\n+  // Null masks\n+  RETURN_NOT_OK(null_masks_->Resize(size_null_masks(rows_capacity_new), false));\n+  memset(null_masks_->mutable_data() + size_null_masks(rows_capacity_), 0,\n+         size_null_masks(rows_capacity_new) - size_null_masks(rows_capacity_));\n+\n+  // Either offsets or rows\n+  if (!metadata_.is_fixed_length) {\n+    RETURN_NOT_OK(offsets_->Resize(size_offsets(rows_capacity_new), false));\n+    memset(offsets_->mutable_data() + size_offsets(rows_capacity_), 0,\n+           size_offsets(rows_capacity_new) - size_offsets(rows_capacity_));\n+  } else {\n+    RETURN_NOT_OK(rows_->Resize(size_rows_fixed_length(rows_capacity_new), false));\n+    memset(rows_->mutable_data() + size_rows_fixed_length(rows_capacity_), 0,\n+           size_rows_fixed_length(rows_capacity_new) -\n+               size_rows_fixed_length(rows_capacity_));\n+    bytes_capacity_ = size_rows_fixed_length(rows_capacity_new) - padding_for_vectors;\n+  }\n+\n+  update_buffer_pointers();\n+\n+  rows_capacity_ = rows_capacity_new;\n+\n+  return Status::OK();\n+}\n+\n+Status KeyEncoder::KeyRowArray::ResizeOptionalVaryingLengthBuffer(\n+    int64_t num_extra_bytes) {\n+  int64_t num_bytes = get_offsets()[num_rows_];\n+  if (bytes_capacity_ >= num_bytes + num_extra_bytes || metadata_.is_fixed_length) {\n+    return Status::OK();\n+  }\n+\n+  int64_t bytes_capacity_new = std::max(static_cast<int64_t>(1), 2 * bytes_capacity_);\n+  while (bytes_capacity_new < num_bytes + num_extra_bytes) {\n+    bytes_capacity_new *= 2;\n+  }\n+\n+  RETURN_NOT_OK(rows_->Resize(size_rows_varying_length(bytes_capacity_new), false));\n+  memset(rows_->mutable_data() + size_rows_varying_length(bytes_capacity_), 0,\n+         size_rows_varying_length(bytes_capacity_new) -\n+             size_rows_varying_length(bytes_capacity_));\n+\n+  update_buffer_pointers();\n+\n+  bytes_capacity_ = bytes_capacity_new;\n+\n+  return Status::OK();\n+}\n+\n+Status KeyEncoder::KeyRowArray::AppendSelectionFrom(const KeyRowArray& from,\n+                                                    uint32_t num_rows_to_append,\n+                                                    const uint16_t* source_row_ids) {\n+  ARROW_DCHECK(metadata_.is_fixed_length == from.get_metadata().is_fixed_length &&\n+               metadata_.fixed_length == from.get_metadata().fixed_length &&\n+               metadata_.cumulative_lengths_length ==\n+                   from.get_metadata().cumulative_lengths_length &&\n+               metadata_.null_masks_bytes_per_row ==\n+                   from.get_metadata().null_masks_bytes_per_row);\n+\n+  RETURN_NOT_OK(ResizeFixedLengthBuffers(num_rows_to_append));\n+\n+  if (!metadata_.is_fixed_length) {\n+    // Varying-length rows\n+    const uint32_t* from_offsets =\n+        reinterpret_cast<const uint32_t*>(from.offsets_->data());\n+    uint32_t* to_offsets = reinterpret_cast<uint32_t*>(offsets_->mutable_data());\n+    uint32_t total_length = to_offsets[num_rows_];\n+    uint32_t total_length_to_append = 0;\n+    for (uint32_t i = 0; i < num_rows_to_append; ++i) {\n+      uint16_t row_id = source_row_ids[i];\n+      uint32_t length = from_offsets[row_id + 1] - from_offsets[row_id];\n+      total_length_to_append += length;\n+      to_offsets[num_rows_ + i + 1] = total_length + total_length_to_append;\n+    }\n+\n+    RETURN_NOT_OK(ResizeOptionalVaryingLengthBuffer(total_length_to_append));\n+\n+    const uint8_t* src = from.rows_->data();\n+    uint8_t* dst = rows_->mutable_data() + total_length;\n+    for (uint32_t i = 0; i < num_rows_to_append; ++i) {\n+      uint16_t row_id = source_row_ids[i];\n+      uint32_t length = from_offsets[row_id + 1] - from_offsets[row_id];\n+      const uint64_t* src64 =\n+          reinterpret_cast<const uint64_t*>(src + from_offsets[row_id]);\n+      uint64_t* dst64 = reinterpret_cast<uint64_t*>(dst);\n+      for (uint32_t j = 0; j < (length + 7) / 8; ++j) {\n+        dst64[j] = src64[j];\n+      }\n+      dst += length;\n+    }\n+  } else {\n+    // Fixed-length rows\n+    const uint8_t* src = from.rows_->data();\n+    uint8_t* dst = rows_->mutable_data() + num_rows_ * metadata_.fixed_length;\n+    for (uint32_t i = 0; i < num_rows_to_append; ++i) {\n+      uint16_t row_id = source_row_ids[i];\n+      uint32_t length = metadata_.fixed_length;\n+      const uint64_t* src64 = reinterpret_cast<const uint64_t*>(src + length * row_id);\n+      uint64_t* dst64 = reinterpret_cast<uint64_t*>(dst);\n+      for (uint32_t j = 0; j < (length + 7) / 8; ++j) {\n+        dst64[j] = src64[j];\n+      }\n+      dst += length;\n+    }\n+  }\n+\n+  // Null masks\n+  uint32_t byte_length = metadata_.null_masks_bytes_per_row;\n+  uint64_t dst_byte_offset = num_rows_ * byte_length;\n+  const uint8_t* src_base = from.null_masks_->data();\n+  uint8_t* dst_base = null_masks_->mutable_data();\n+  for (uint32_t i = 0; i < num_rows_to_append; ++i) {\n+    uint32_t row_id = source_row_ids[i];\n+    int64_t src_byte_offset = row_id * byte_length;\n+    const uint8_t* src = src_base + src_byte_offset;\n+    uint8_t* dst = dst_base + dst_byte_offset;\n+    for (uint32_t ibyte = 0; ibyte < byte_length; ++ibyte) {\n+      dst[ibyte] = src[ibyte];\n+    }\n+    dst_byte_offset += byte_length;\n+  }\n+\n+  num_rows_ += num_rows_to_append;\n+\n+  return Status::OK();\n+}\n+\n+Status KeyEncoder::KeyRowArray::AppendEmpty(uint32_t num_rows_to_append,\n+                                            uint32_t num_extra_bytes_to_append) {\n+  RETURN_NOT_OK(ResizeFixedLengthBuffers(num_rows_to_append));\n+  RETURN_NOT_OK(ResizeOptionalVaryingLengthBuffer(num_extra_bytes_to_append));\n+  num_rows_ += num_rows_to_append;\n+  return Status::OK();\n+}\n+\n+bool KeyEncoder::KeyRowArray::has_any_nulls(const KeyEncoderContext* ctx) const {\n+  if (has_any_nulls_) {\n+    return true;\n+  }\n+  if (num_rows_for_has_any_nulls_ < num_rows_) {\n+    auto size_per_row = get_metadata().null_masks_bytes_per_row;\n+    has_any_nulls_ = !util::BitUtil::are_all_bytes_zero(\n+        ctx->instr, get_null_masks() + size_per_row * num_rows_for_has_any_nulls_,\n+        static_cast<uint32_t>(size_per_row * (num_rows_ - num_rows_for_has_any_nulls_)));\n+    num_rows_for_has_any_nulls_ = num_rows_;\n+  }\n+  return has_any_nulls_;\n+}\n+\n+KeyEncoder::KeyColumnArray::KeyColumnArray(const KeyColumnMetadata& metadata,\n+                                           const KeyColumnArray& left,\n+                                           const KeyColumnArray& right,\n+                                           int buffer_id_to_replace) {\n+  metadata_ = metadata;\n+  length_ = left.get_length();\n+  for (int i = 0; i < max_buffers_; ++i) {\n+    buffers_[i] = left.buffers_[i];\n+    mutable_buffers_[i] = left.mutable_buffers_[i];\n+  }\n+  buffers_[buffer_id_to_replace] = right.buffers_[buffer_id_to_replace];\n+  mutable_buffers_[buffer_id_to_replace] = right.mutable_buffers_[buffer_id_to_replace];\n+}\n+\n+KeyEncoder::KeyColumnArray::KeyColumnArray(const KeyColumnMetadata& metadata,\n+                                           int64_t length, const uint8_t* buffer0,\n+                                           const uint8_t* buffer1,\n+                                           const uint8_t* buffer2) {\n+  metadata_ = metadata;\n+  length_ = length;\n+  buffers_[0] = buffer0;\n+  buffers_[1] = buffer1;\n+  buffers_[2] = buffer2;\n+  mutable_buffers_[0] = mutable_buffers_[1] = mutable_buffers_[2] = nullptr;\n+}\n+\n+KeyEncoder::KeyColumnArray::KeyColumnArray(const KeyColumnMetadata& metadata,\n+                                           int64_t length, uint8_t* buffer0,\n+                                           uint8_t* buffer1, uint8_t* buffer2) {\n+  metadata_ = metadata;\n+  length_ = length;\n+  buffers_[0] = mutable_buffers_[0] = buffer0;\n+  buffers_[1] = mutable_buffers_[1] = buffer1;\n+  buffers_[2] = mutable_buffers_[2] = buffer2;\n+}\n+\n+KeyEncoder::KeyColumnArray::KeyColumnArray(const KeyColumnArray& from, int64_t start,\n+                                           int64_t length) {\n+  ARROW_DCHECK((start % 8) == 0);\n+  metadata_ = from.metadata_;\n+  length_ = length;\n+  uint32_t fixed_size =\n+      !metadata_.is_fixed_length ? sizeof(uint32_t) : metadata_.fixed_length;\n+\n+  buffers_[0] = from.buffers_[0] ? from.buffers_[0] + start / 8 : nullptr;\n+  mutable_buffers_[0] =\n+      from.mutable_buffers_[0] ? from.mutable_buffers_[0] + start / 8 : nullptr;\n+\n+  if (fixed_size == 0) {\n+    buffers_[1] = from.buffers_[1] ? from.buffers_[1] + start / 8 : nullptr;\n+    mutable_buffers_[1] =\n+        from.mutable_buffers_[1] ? from.mutable_buffers_[1] + start / 8 : nullptr;\n+  } else {\n+    buffers_[1] = from.buffers_[1] ? from.buffers_[1] + start * fixed_size : nullptr;\n+    mutable_buffers_[1] = from.mutable_buffers_[1]\n+                              ? from.mutable_buffers_[1] + start * fixed_size\n+                              : nullptr;\n+  }\n+\n+  buffers_[2] = from.buffers_[2];\n+  mutable_buffers_[2] = from.mutable_buffers_[2];\n+}\n+\n+KeyEncoder::KeyColumnArray KeyEncoder::TransformBoolean::ArrayReplace(\n+    const KeyColumnArray& column, const KeyColumnArray& temp) {\n+  // Make sure that the temp buffer is large enough\n+  ARROW_DCHECK(temp.get_length() >= column.get_length() &&\n+               temp.get_metadata().is_fixed_length &&\n+               temp.get_metadata().fixed_length >= sizeof(uint8_t));\n+  KeyColumnMetadata metadata;\n+  metadata.is_fixed_length = true;\n+  metadata.fixed_length = sizeof(uint8_t);\n+  constexpr int buffer_index = 1;\n+  KeyColumnArray result = KeyColumnArray(metadata, column, temp, buffer_index);\n+  return result;\n+}\n+\n+void KeyEncoder::TransformBoolean::PreEncode(const KeyColumnArray& input,\n+                                             KeyColumnArray& output,\n+                                             KeyEncoderContext* ctx) {\n+  // Make sure that metadata and lengths are compatible.\n+  ARROW_DCHECK(output.get_metadata().is_fixed_length ==\n+               input.get_metadata().is_fixed_length);\n+  ARROW_DCHECK(output.get_metadata().fixed_length == 1 &&\n+               input.get_metadata().fixed_length == 0);\n+  ARROW_DCHECK(output.get_length() == input.get_length());\n+  constexpr int buffer_index = 1;\n+  ARROW_DCHECK(input.data(buffer_index) != nullptr);\n+  ARROW_DCHECK(output.mutable_data(buffer_index) != nullptr);\n+  util::BitUtil::bits_to_bytes(ctx->instr, static_cast<int>(input.get_length()),\n+                               input.data(buffer_index),\n+                               output.mutable_data(buffer_index));\n+}\n+\n+void KeyEncoder::TransformBoolean::PostDecode(const KeyColumnArray& input,\n+                                              KeyColumnArray& output,\n+                                              KeyEncoderContext* ctx) {\n+  // Make sure that metadata and lengths are compatible.\n+  ARROW_DCHECK(output.get_metadata().is_fixed_length ==\n+               input.get_metadata().is_fixed_length);\n+  ARROW_DCHECK(output.get_metadata().fixed_length == 0 &&\n+               input.get_metadata().fixed_length == 1);\n+  ARROW_DCHECK(output.get_length() == input.get_length());\n+  constexpr int buffer_index = 1;\n+  ARROW_DCHECK(input.data(buffer_index) != nullptr);\n+  ARROW_DCHECK(output.mutable_data(buffer_index) != nullptr);\n+\n+  util::BitUtil::bytes_to_bits(ctx->instr, static_cast<int>(input.get_length()),\n+                               input.data(buffer_index),\n+                               output.mutable_data(buffer_index));\n+}\n+\n+bool KeyEncoder::EncoderInteger::IsBoolean(const KeyColumnMetadata& metadata) {\n+  return metadata.is_fixed_length && metadata.fixed_length == 0;\n+}\n+\n+bool KeyEncoder::EncoderInteger::UsesTransform(const KeyColumnArray& column) {\n+  return IsBoolean(column.get_metadata());\n+}\n+\n+KeyEncoder::KeyColumnArray KeyEncoder::EncoderInteger::ArrayReplace(\n+    const KeyColumnArray& column, KeyColumnArray& temp) {\n+  if (IsBoolean(column.get_metadata())) {\n+    return TransformBoolean::ArrayReplace(column, temp);\n+  }\n+  return column;\n+}\n+\n+void KeyEncoder::EncoderInteger::PreEncode(const KeyColumnArray& input,\n+                                           KeyColumnArray& output,\n+                                           KeyEncoderContext* ctx) {\n+  if (IsBoolean(input.get_metadata())) {\n+    TransformBoolean::PreEncode(input, output, ctx);\n+  }\n+}\n+\n+void KeyEncoder::EncoderInteger::PostDecode(const KeyColumnArray& input,\n+                                            KeyColumnArray& output,\n+                                            KeyEncoderContext* ctx) {\n+  if (IsBoolean(output.get_metadata())) {\n+    TransformBoolean::PostDecode(input, output, ctx);\n+  }\n+}\n+\n+void KeyEncoder::EncoderInteger::Encode(uint32_t* offset_within_row, KeyRowArray& rows,\n+                                        const KeyColumnArray& col, KeyEncoderContext* ctx,\n+                                        KeyColumnArray& temp) {\n+  KeyColumnArray col_prep;\n+  if (UsesTransform(col)) {\n+    col_prep = ArrayReplace(col, temp);\n+    PreEncode(col, col_prep, ctx);\n+  } else {\n+    col_prep = col;\n+  }\n+\n+  uint32_t num_rows = static_cast<uint32_t>(col.get_length());\n+\n+  // When we have a single fixed length column we can just do memcpy\n+  if (rows.get_metadata().is_fixed_length &&\n+      rows.get_metadata().fixed_length == col.get_metadata().fixed_length) {\n+    ARROW_DCHECK(*offset_within_row == 0);\n+    uint32_t row_size = col.get_metadata().fixed_length;\n+    memcpy(rows.mutable_data(1), col.data(1), num_rows * row_size);\n+  } else if (rows.get_metadata().is_fixed_length) {\n+    uint32_t row_size = rows.get_metadata().fixed_length;\n+    uint8_t* row_base = rows.mutable_data(1) + *offset_within_row;\n+    const uint8_t* col_base = col_prep.data(1);\n+    switch (col_prep.get_metadata().fixed_length) {\n+      case 1:\n+        for (uint32_t i = 0; i < num_rows; ++i) {\n+          row_base[i * row_size] = col_base[i];\n+        }\n+        break;\n+      case 2:\n+        for (uint32_t i = 0; i < num_rows; ++i) {\n+          *reinterpret_cast<uint16_t*>(row_base + i * row_size) =\n+              reinterpret_cast<const uint16_t*>(col_base)[i];\n+        }\n\nReview comment:\n       There's a lot of unaligned accesses like this one. This is undefined behavior in C++ and it's not supported on all platforms. Could we use SafeLoadAs and SafeStore? If those produce a performance regression, can we optimize them?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-20T16:51:38.221+0000",
                    "updated": "2021-04-20T16:51:38.221+0000",
                    "started": "2021-04-20T16:51:38.221+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "586000",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/594191",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa opened a new pull request #10290:\nURL: https://github.com/apache/arrow/pull/10290\n\n\n   This change is based on top of pull request:\r\n   https://github.com/apache/arrow/pull/9768\r\n   \r\n   Previous implementation of hash group by converts input ExecBatches to row-oriented format,\r\n   then hashes and compares rows as if they were a single column. \r\n   \r\n   It is more efficient (especially for small number of key columns) to avoid relatively costly encoding and instead compute hashes of individual columns in column-oriented format mixing them together, and similarly comparing column-oriented data to row-oriented data in the hash table without converting. \r\n   \r\n   Encoding only happens for a subset of input rows that are inserted into the hash table - they introduce new groups. \r\n   Keys in hash table remain stored as row-oriented.\r\n   \r\n   There are 3 main new components:\r\n   - key_compare_single.cc - contains implementation of one column at a time comparison between column-oriented and row-oriented data\r\n   - key_hash_multi.cc - implements hashing individual columns of column-oriented key data and mixing the individual results together for a final multi-column hash\r\n   - key_encode_selected.cc - implements encoding in row-format only a selection of input rows; previously all input rows were encoded without support for selective encoding\r\n   \r\n   Currently only AVX2 implementation is present. Scalar version still needs to be added, together with code dispatching to appropriate implementation that is missing.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-05-10T19:22:41.096+0000",
                    "updated": "2021-05-10T19:22:41.096+0000",
                    "started": "2021-05-10T19:22:41.096+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "594191",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/594192",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #10290:\nURL: https://github.com/apache/arrow/pull/10290#issuecomment-837189752\n\n\n   https://issues.apache.org/jira/browse/ARROW-12010\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-05-10T19:23:04.244+0000",
                    "updated": "2021-05-10T19:23:04.244+0000",
                    "started": "2021-05-10T19:23:04.244+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "594192",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/594657",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768#discussion_r630404567\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/key_hash.cc\n##########\n@@ -0,0 +1,247 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec/key_hash.h\"\n+\n+#include <memory.h>\n+\n+#include <cstdint>\n+\n+#include \"arrow/compute/exec/util.h\"\n+\n+#ifdef _MSC_VER\n+#include <intrin.h>\n+#else\n+#include <x86intrin.h>\n+#endif\n+#include <immintrin.h>\n+\n+#include <algorithm>\n+\n+namespace arrow {\n+namespace compute {\n+\n+inline uint32_t Hashing::avalanche_helper(uint32_t acc) {\n+  acc ^= (acc >> 15);\n+  acc *= PRIME32_2;\n+  acc ^= (acc >> 13);\n+  acc *= PRIME32_3;\n+  acc ^= (acc >> 16);\n+  return acc;\n+}\n+\n+void Hashing::avalanche(const arrow::internal::CpuInfo* cpu_info, uint32_t num_keys,\n\nReview comment:\n       If the intent is to allow functions to be called with any hardware flags independent of any other calls, it's worth noting that CpuInfo is a singleton. So for example disabling AVX2 for Hashing::avalanche will prevent it from being used in any other functions as well. I think what you want is to pass an `int64_t hardware_flags` which can be acquired with `CpuInfo::GetInstance()->hardware_flags()` or explicitly specified\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-05-11T17:56:27.389+0000",
                    "updated": "2021-05-11T17:56:27.389+0000",
                    "started": "2021-05-11T17:56:27.389+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "594657",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/599265",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768#issuecomment-844149763\n\n\n   @michalursa looks like tests are hanging on our [bigendian CI](https://travis-ci.com/github/apache/arrow/jobs/506281680#L2907). Is this quick to address or should we leave this for follow up\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-05-19T14:17:54.166+0000",
                    "updated": "2021-05-19T14:17:54.166+0000",
                    "started": "2021-05-19T14:17:54.166+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "599265",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/599444",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nealrichardson commented on pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768#issuecomment-844456233\n\n\n   > @michalursa looks like tests are hanging on our [bigendian CI](https://travis-ci.com/github/apache/arrow/jobs/506281680#L2907). Is this quick to address or should we leave this for follow up\r\n   \r\n   cc @kiszk \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-05-19T20:41:01.665+0000",
                    "updated": "2021-05-19T20:41:01.665+0000",
                    "started": "2021-05-19T20:41:01.665+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "599444",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/599496",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "michalursa commented on pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768#issuecomment-844533147\n\n\n   > > @michalursa looks like tests are hanging on our [bigendian CI](https://travis-ci.com/github/apache/arrow/jobs/506281680#L2907). Is this quick to address or should we leave this for follow up\r\n   > \r\n   > cc @kiszk\r\n   \r\n   It requires a bit of thinking (or debugging) to make the code work with big endian. But since we still have the other group by implementation, for now I am disabling new one on big endian architectures, and will move this issue to a separate jira. \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-05-19T22:14:04.449+0000",
                    "updated": "2021-05-19T22:14:04.449+0000",
                    "started": "2021-05-19T22:14:04.448+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "599496",
                    "issueId": "13365951"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/worklog/600070",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz closed pull request #9768:\nURL: https://github.com/apache/arrow/pull/9768\n\n\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-05-20T21:42:47.322+0000",
                    "updated": "2021-05-20T21:42:47.322+0000",
                    "started": "2021-05-20T21:42:47.321+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "600070",
                    "issueId": "13365951"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 6000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@6c58a77e[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@574e1285[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3d8eb4c2[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@1af343cc[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@773def51[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@475a2c4f[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@fbaa8c2[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@fd777da[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@17085616[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@1a628ec[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5b006ca2[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@6fdda9bf[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 6000,
        "customfield_12312520": null,
        "customfield_12312521": "Thu May 20 21:42:44 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-05-20T21:42:44.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12010/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2021-03-17T21:47:11.000+0000",
        "updated": "2021-05-20T21:42:48.000+0000",
        "timeoriginalestimate": null,
        "description": "ARROW-11591 adds support for grouped aggregation with a very basic hash table.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "1h 40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 6000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Compute] Improve performance of the hash table used in GroupIdentifier",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/comment/17347980",
                    "id": "17347980",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
                        "name": "michalno",
                        "key": "michalno",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Michal Nowakiewicz",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Support for big endian architecture is missing and has been moved to a separate task: https://issues.apache.org/jira/browse/ARROW-12830\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
                        "name": "michalno",
                        "key": "michalno",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Michal Nowakiewicz",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2021-05-19T23:37:03.313+0000",
                    "updated": "2021-05-19T23:37:03.313+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13365951/comment/17348814",
                    "id": "17348814",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 9768\n[https://github.com/apache/arrow/pull/9768]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-05-20T21:42:44.345+0000",
                    "updated": "2021-05-20T21:42:44.345+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z0owug:",
        "customfield_12314139": null
    }
}