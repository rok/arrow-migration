{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13146580",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580",
    "key": "ARROW-2330",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12342562",
                "id": "12342562",
                "description": "",
                "name": "0.10.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-08-06"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341352",
                "id": "12341352",
                "name": "0.8.0",
                "archived": false,
                "released": true,
                "releaseDate": "2017-12-18"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=alendit",
            "name": "alendit",
            "key": "alendit",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Dimitri Vorona",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=alendit",
            "name": "alendit",
            "key": "alendit",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Dimitri Vorona",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=alendit",
            "name": "alendit",
            "key": "alendit",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Dimitri Vorona",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2330/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@1ba66e2e[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5de2255d[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@499766e7[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@5136a45[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@51d47cc4[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@7507f2f7[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@75502ee[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@198a1103[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6bca7caa[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@2110ab6e[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@e7d9fd0[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@47369515[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Jun 12 21:38:55 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-06-12T21:38:55.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2330/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2018-03-20T15:44:14.000+0000",
        "updated": "2018-06-12T21:38:55.000+0000",
        "timeoriginalestimate": null,
        "description": "The main aim of this change is to optimize the building of delta dictionaries. In the current version delta dictionaries are built using an additional \"overflow\" buffer which leads to complicated and potentially error-prone code and subpar performance by doubling the number of lookups.\r\n\r\nI solve this problem by introducing the notion of partially finishable array builders, i.e. builder which are able to retain the state on calling Finish. The interface is based on RecordBatchBuilder::Flush, i.e. Finish is overloaded with additional signature Finish(bool reset_builder, std::shared_ptr<Array>* out). The resulting Arrays point to the same data buffer with different offsets.\r\n\r\nI'm aware that the change is kind of biggish, but I'd like to discuss it here. The solution makes the code more straight forward, doesn't bloat the code base too much and leaves the API more or less untouched. Additionally, the new way to make delta dictionaries by using a different call signature to Finish feel cleaner to me.\r\n\r\nI'm looking forward to your critic and improvement ideas.\r\n\r\nThe pull request is available at:\u00a0https://github.com/apache/arrow/pull/1769",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Optimize delta buffer creation with partially finishable array builders",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": "https://github.com/apache/arrow/pull/1769",
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16406530",
                    "id": "16406530",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "alendit opened a new pull request #1769: https://issues.apache.org/jira/browse/ARROW-2330\nURL: https://github.com/apache/arrow/pull/1769\n \n \n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-20T15:45:08.284+0000",
                    "updated": "2018-03-20T15:45:08.284+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16417644",
                    "id": "16417644",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on issue #1769: ARROW-2330: [C++] Optimize delta buffer creation with partially finishable array builders\nURL: https://github.com/apache/arrow/pull/1769#issuecomment-376942167\n \n \n   What is the benefit of having ArrayBuilders that partly reset them versus just instantiating a new ArrayBuilder? I get it for the Dictionary case where keep state but for FixedSizeBinary I don't see the need to add such complexity.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-28T16:05:25.447+0000",
                    "updated": "2018-03-28T16:05:25.447+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16417967",
                    "id": "16417967",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "alendit commented on issue #1769: ARROW-2330: [C++] Optimize delta buffer creation with partially finishable array builders\nURL: https://github.com/apache/arrow/pull/1769#issuecomment-377005372\n \n \n   Hi Uwe,\r\n   \r\n   i was actually wondering the same thing myself. The reason I've implemented partial finishers for `FixedSizeBinaryBuilder` etc is that they are used by the `DictionaryBuilder` internally. I've tried to come up with a use case for the partial finishing for other builders, but, as you said, you can almost always simply instantiate a new one. Do you know why the `RecordBatchBuilder` has a partial `Flush` method? Is it because its instantion is more cumbersome compared to array builders?\r\n   \r\n   That being said, I don't think that it adds that much complexity, compared to the previous implementation. Most of the changes are in the testing code, and builder files themselves have around 30 additional LOC. At the same time, it makes the `DictionaryBuilder` quite straight forward.\r\n   \r\n   Maybe a compromise would be to hide the partial \u00b4Finish\u00b4 methods for other classes besides `DictionaryBuilder` and make them friends with it? I'm not a big friend of `friend`, though.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-03-28T19:22:14.085+0000",
                    "updated": "2018-03-28T19:22:14.085+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16431822",
                    "id": "16431822",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "alendit commented on issue #1769: ARROW-2330: [C++] Optimize delta buffer creation with partially finishable array builders\nURL: https://github.com/apache/arrow/pull/1769#issuecomment-379997360\n \n \n   Hi Uwe,\r\n   \r\n   did you come to any conclusion as to if this PR is a go? I could either adjust it or we can scrap it all together and then I'll look into getting delta dicts into `Readers` and `Writers`.\r\n   \r\n   Note: the test failure is unrelated to my changes, the cause was mentioned on the mailing list.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-10T07:09:24.896+0000",
                    "updated": "2018-04-10T07:09:24.896+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16432390",
                    "id": "16432390",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on issue #1769: ARROW-2330: [C++] Optimize delta buffer creation with partially finishable array builders\nURL: https://github.com/apache/arrow/pull/1769#issuecomment-380127439\n \n \n   Hello Dimitri,\r\n   \r\n   I forgot to reply to you. This got drowned in all the other Arrow activity in the last days. Sorry about that.\r\n   \r\n   > Do you know why the RecordBatchBuilder has a partial Flush method? Is it because its instantion is more cumbersome compared to array builders?\r\n   \r\n   The `RecordBatchBuilder` is different to the other builders as it does not generate a Arrays but should be used for a more streaming-like output. In it, all builders are resetted on Flush. This is also the behaviour I would expect in the dictionary builder.\r\n    \r\n   > That being said, I don't think that it adds that much complexity, compared to the previous implementation. Most of the changes are in the testing code, and builder files themselves have around 30 additional LOC. At the same time, it makes the DictionaryBuilder quite straight forward.\r\n   \r\n   The added complexity is the thing that scares me most at the moment. The Builders are built with the intention that they complety own their buffers and can modify them as they like internally. You can ask them for snapshot access to elements to inspect them but we don't provide any guarantees that the memory addresses that were returned from them are still valid once you can a method on the builder again.\r\n   \r\n   As far as I understand the current implementation in some cases we return the current buffer pointer as new `Buffer` object in the BufferBuilder. Once we do expand it though later on, we may free this memory address and thus the `Buffer` object point to unreachable memory. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-10T14:45:29.663+0000",
                    "updated": "2018-04-10T14:45:29.663+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16432556",
                    "id": "16432556",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "alendit commented on issue #1769: ARROW-2330: [C++] Optimize delta buffer creation with partially finishable array builders\nURL: https://github.com/apache/arrow/pull/1769#issuecomment-380165985\n \n \n   Hi Uwe,\r\n   \r\n   I see what you mean. Now that I've looked more carefully into `BufferSlices`, I see how much danger they can bear. Something like [this](https://gist.github.com/alendit/f759bc12e03d9dd9d72cac90a6334cc5) would cause a read-after-free. \r\n   \r\n   The problem, as I see it, is, that the SliceBuffer user has no way to ensure its validity. So even if we skip this PR, the problems with slices might happen in the future. I think some lean solution, like adding a `shared_ptr<Buffer> parent` to the slice and referencing its data instead, will increase the memory safety and might benefit this PR, too.\r\n   \r\n   Do you think we should discuss it on the mailing list?\r\n   \r\n   Cheers,\r\n   Dimitri.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-10T16:34:21.358+0000",
                    "updated": "2018-04-10T16:34:21.358+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16433764",
                    "id": "16433764",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "alendit commented on issue #1769: ARROW-2330: [C++] Optimize delta buffer creation with partially finishable array builders\nURL: https://github.com/apache/arrow/pull/1769#issuecomment-380419676\n \n \n   Hi Uwe,\r\n   \r\n   I've decided to close this PR until I have a better understanding of the possible issues with slices.\r\n   \r\n   Cheers!\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-11T11:30:27.850+0000",
                    "updated": "2018-04-11T11:30:27.850+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16433765",
                    "id": "16433765",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "alendit closed pull request #1769: ARROW-2330: [C++] Optimize delta buffer creation with partially finishable array builders\nURL: https://github.com/apache/arrow/pull/1769\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/cpp/src/arrow/array-test.cc b/cpp/src/arrow/array-test.cc\nindex fb1bebfca..7f7666bb3 100644\n--- a/cpp/src/arrow/array-test.cc\n+++ b/cpp/src/arrow/array-test.cc\n@@ -536,6 +536,44 @@ TYPED_TEST(TestPrimitiveBuilder, SliceEquality) {\n   ASSERT_TRUE(array->RangeEquals(5, 15, 0, slice));\n }\n \n+TYPED_TEST(TestPrimitiveBuilder, TestPartialFinish) {\n+  const int64_t size = 1000;\n+  this->RandomData(size * 2);\n+\n+  // build an array of all values\n+  std::shared_ptr<Array> all_values_array;\n+  ASSERT_OK(MakeArray(this->valid_bytes_, this->draws_, size * 2, this->builder_.get(),\n+                      &all_values_array));\n+\n+  for (uint64_t idx = 0; idx < size; ++idx) {\n+    if (this->valid_bytes_[idx] > 0) {\n+      ASSERT_OK(this->builder_->Append(this->draws_[idx]));\n+    } else {\n+      ASSERT_OK(this->builder_->AppendNull());\n+    }\n+  }\n+\n+  std::shared_ptr<Array> result1;\n+  ASSERT_OK(this->builder_->Finish(false, &result1));\n+\n+  ASSERT_EQ(size, result1->length());\n+  ASSERT_TRUE(all_values_array->RangeEquals(0, size, 0, result1));\n+\n+  for (uint64_t idx = size; idx < size * 2; ++idx) {\n+    if (this->valid_bytes_[idx] > 0) {\n+      ASSERT_OK(this->builder_->Append(this->draws_[idx]));\n+    } else {\n+      ASSERT_OK(this->builder_->AppendNull());\n+    }\n+  }\n+\n+  std::shared_ptr<Array> result2;\n+  ASSERT_OK(this->builder_->Finish(true, &result2));\n+\n+  ASSERT_EQ(size, result2->length());\n+  ASSERT_TRUE(all_values_array->RangeEquals(size, size * 2, 0, result2));\n+}\n+\n TYPED_TEST(TestPrimitiveBuilder, TestAppendScalar) {\n   DECL_T();\n \n@@ -1027,6 +1065,27 @@ TEST_F(TestStringBuilder, TestZeroLength) {\n   Done();\n }\n \n+TEST_F(TestStringBuilder, TestPartialFinish) {\n+  StringBuilder builder, builder_expected;\n+  ASSERT_OK(builder.Append(\"foo\"));\n+  ASSERT_OK(builder_expected.Append(\"foo\"));\n+\n+  std::shared_ptr<Array> result1, expected1;\n+  ASSERT_OK(builder.Finish(false, &result1));\n+  ASSERT_OK(builder_expected.Finish(&expected1));\n+  ASSERT_EQ(1, result1->length());\n+  ASSERT_TRUE(result1->Equals(expected1));\n+\n+  ASSERT_OK(builder.Append(\"foo\"));\n+  ASSERT_OK(builder_expected.Append(\"foo\"));\n+  std::shared_ptr<Array> result2, expected2;\n+  ASSERT_OK(builder.Finish(false, &result2));\n+  ASSERT_OK(builder_expected.Finish(&expected2));\n+  ASSERT_EQ(1, result2->length());\n+  ASSERT_EQ(1, result2->offset());\n+  ASSERT_TRUE(result2->Equals(expected2));\n+}\n+\n // Binary container type\n // TODO(emkornfield) there should be some way to refactor these to avoid code duplicating\n // with String\n@@ -1239,6 +1298,27 @@ TEST_F(TestBinaryBuilder, TestZeroLength) {\n   Done();\n }\n \n+TEST_F(TestBinaryBuilder, TestPartialFinish) {\n+  BinaryBuilder builder, builder_expected;\n+  ASSERT_OK(builder.Append(\"foo\"));\n+  ASSERT_OK(builder_expected.Append(\"foo\"));\n+\n+  std::shared_ptr<Array> result1, expected1;\n+  ASSERT_OK(builder.Finish(false, &result1));\n+  ASSERT_OK(builder_expected.Finish(&expected1));\n+  ASSERT_EQ(1, result1->length());\n+  ASSERT_TRUE(result1->Equals(expected1));\n+\n+  ASSERT_OK(builder.Append(\"foo\"));\n+  ASSERT_OK(builder_expected.Append(\"foo\"));\n+  std::shared_ptr<Array> result2, expected2;\n+  ASSERT_OK(builder.Finish(false, &result2));\n+  ASSERT_OK(builder_expected.Finish(&expected2));\n+  ASSERT_EQ(1, result2->length());\n+  ASSERT_EQ(1, result2->offset());\n+  ASSERT_TRUE(result2->Equals(expected2));\n+}\n+\n // ----------------------------------------------------------------------\n // Slice tests\n \n@@ -1472,6 +1552,26 @@ TEST_F(TestFWBinaryArray, Slice) {\n   ASSERT_TRUE(array->RangeEquals(1, 3, 0, slice));\n }\n \n+TEST_F(TestFWBinaryArray, TestPartialFinish) {\n+  auto type = fixed_size_binary(4);\n+  FixedSizeBinaryBuilder builder(type);\n+\n+  ASSERT_OK(builder.Append(\"foo\"));\n+  std::shared_ptr<Array> result1;\n+  ASSERT_OK(builder.Finish(false, &result1));\n+  ASSERT_EQ(1, result1->length());\n+  ASSERT_STREQ(\"foo\", reinterpret_cast<const char*>(\n+                          static_cast<const FixedSizeBinaryArray&>(*result1).Value(0)));\n+\n+  ASSERT_OK(builder.Append(\"bar\"));\n+  std::shared_ptr<Array> result2;\n+  ASSERT_OK(builder.Finish(&result2));\n+  ASSERT_EQ(1, result2->length());\n+  ASSERT_EQ(1, result2->offset());\n+  ASSERT_STREQ(\"bar\", reinterpret_cast<const char*>(\n+                          static_cast<const FixedSizeBinaryArray&>(*result2).Value(0)));\n+}\n+\n // ----------------------------------------------------------------------\n // AdaptiveInt tests\n \n@@ -1603,6 +1703,31 @@ TEST_F(TestAdaptiveIntBuilder, TestAppendVector) {\n   ASSERT_TRUE(expected_->Equals(result_));\n }\n \n+TEST_F(TestAdaptiveIntBuilder, TestPartialFinish) {\n+  ASSERT_OK(builder_->Append(0));\n+  ASSERT_OK(\n+      builder_->Append(static_cast<int64_t>(std::numeric_limits<int32_t>::max()) + 1));\n+\n+  std::shared_ptr<Array> result1, expected1;\n+  ASSERT_OK(builder_->Finish(false, &result1));\n+\n+  std::vector<int64_t> expected_values1(\n+      {0, static_cast<int64_t>(std::numeric_limits<int32_t>::max()) + 1});\n+\n+  ArrayFromVector<Int64Type, int64_t>(expected_values1, &expected1);\n+  ASSERT_TRUE(expected1->Equals(result1));\n+\n+  ASSERT_OK(builder_->Append(65536));\n+  ASSERT_OK(builder_->Append(1024));\n+\n+  std::shared_ptr<Array> result2, expected2;\n+  ASSERT_OK(builder_->Finish(false, &result2));\n+\n+  std::vector<int64_t> expected_values2({65536, 1024});\n+  ArrayFromVector<Int64Type, int64_t>(expected_values2, &expected_);\n+  ASSERT_TRUE(expected_->Equals(result2));\n+}\n+\n class TestAdaptiveUIntBuilder : public TestBuilder {\n  public:\n   void SetUp() {\n@@ -1698,6 +1823,31 @@ TEST_F(TestAdaptiveUIntBuilder, TestAppendVector) {\n   ASSERT_TRUE(expected_->Equals(result_));\n }\n \n+TEST_F(TestAdaptiveUIntBuilder, TestPartialFinish) {\n+  ASSERT_OK(builder_->Append(0));\n+  ASSERT_OK(\n+      builder_->Append(static_cast<uint64_t>(std::numeric_limits<uint32_t>::max()) + 1));\n+\n+  std::shared_ptr<Array> result1, expected1;\n+  ASSERT_OK(builder_->Finish(false, &result1));\n+\n+  std::vector<uint64_t> expected_values1(\n+      {0, static_cast<uint64_t>(std::numeric_limits<uint32_t>::max()) + 1});\n+\n+  ArrayFromVector<UInt64Type, uint64_t>(expected_values1, &expected1);\n+  ASSERT_TRUE(expected1->Equals(result1));\n+\n+  ASSERT_OK(builder_->Append(65536));\n+  ASSERT_OK(builder_->Append(1024));\n+\n+  std::shared_ptr<Array> result2, expected2;\n+  ASSERT_OK(builder_->Finish(false, &result2));\n+\n+  std::vector<uint64_t> expected_values2({65536, 1024});\n+  ArrayFromVector<UInt64Type, uint64_t>(expected_values2, &expected_);\n+  ASSERT_TRUE(expected_->Equals(result2));\n+}\n+\n // ----------------------------------------------------------------------\n // Dictionary tests\n \n@@ -1817,7 +1967,7 @@ TYPED_TEST(TestDictionaryBuilder, DeltaDictionary) {\n   ASSERT_OK(builder.Append(static_cast<typename TypeParam::c_type>(1)));\n   ASSERT_OK(builder.Append(static_cast<typename TypeParam::c_type>(2)));\n   std::shared_ptr<Array> result;\n-  ASSERT_OK(builder.Finish(&result));\n+  ASSERT_OK(builder.Finish(false, &result));\n \n   // Build expected data for the initial dictionary\n   NumericBuilder<TypeParam> dict_builder1;\n@@ -1876,7 +2026,7 @@ TYPED_TEST(TestDictionaryBuilder, DoubleDeltaDictionary) {\n   ASSERT_OK(builder.Append(static_cast<typename TypeParam::c_type>(1)));\n   ASSERT_OK(builder.Append(static_cast<typename TypeParam::c_type>(2)));\n   std::shared_ptr<Array> result;\n-  ASSERT_OK(builder.Finish(&result));\n+  ASSERT_OK(builder.Finish(false, &result));\n \n   // Build expected data for the initial dictionary\n   NumericBuilder<TypeParam> dict_builder1;\n@@ -1905,7 +2055,7 @@ TYPED_TEST(TestDictionaryBuilder, DoubleDeltaDictionary) {\n   ASSERT_OK(builder.Append(static_cast<typename TypeParam::c_type>(3)));\n \n   std::shared_ptr<Array> result_delta1;\n-  ASSERT_OK(builder.Finish(&result_delta1));\n+  ASSERT_OK(builder.Finish(false, &result_delta1));\n \n   // Build expected data for the delta dictionary\n   NumericBuilder<TypeParam> dict_builder2;\n@@ -1934,7 +2084,7 @@ TYPED_TEST(TestDictionaryBuilder, DoubleDeltaDictionary) {\n   ASSERT_OK(builder.Append(static_cast<typename TypeParam::c_type>(5)));\n \n   std::shared_ptr<Array> result_delta2;\n-  ASSERT_OK(builder.Finish(&result_delta2));\n+  ASSERT_OK(builder.Finish(false, &result_delta2));\n \n   // Build expected data for the delta dictionary again\n   NumericBuilder<TypeParam> dict_builder3;\n@@ -2030,7 +2180,7 @@ TEST(TestStringDictionaryBuilder, DeltaDictionary) {\n   ASSERT_OK(builder.Append(\"test\"));\n \n   std::shared_ptr<Array> result;\n-  ASSERT_OK(builder.Finish(&result));\n+  ASSERT_OK(builder.Finish(false, &result));\n \n   // Build expected data\n   StringBuilder str_builder1;\n@@ -2056,7 +2206,7 @@ TEST(TestStringDictionaryBuilder, DeltaDictionary) {\n   ASSERT_OK(builder.Append(\"test2\"));\n \n   std::shared_ptr<Array> result_delta;\n-  ASSERT_OK(builder.Finish(&result_delta));\n+  ASSERT_OK(builder.Finish(false, &result_delta));\n \n   // Build expected data\n   StringBuilder str_builder2;\n@@ -2093,7 +2243,7 @@ TEST(TestStringDictionaryBuilder, BigDeltaDictionary) {\n   }\n \n   std::shared_ptr<Array> result;\n-  ASSERT_OK(builder.Finish(&result));\n+  ASSERT_OK(builder.Finish(false, &result));\n \n   std::shared_ptr<Array> str_array1;\n   ASSERT_OK(str_builder1.Finish(&str_array1));\n@@ -2121,7 +2271,7 @@ TEST(TestStringDictionaryBuilder, BigDeltaDictionary) {\n   ASSERT_OK(str_builder2.Append(\"test_new_value1\"));\n \n   std::shared_ptr<Array> result2;\n-  ASSERT_OK(builder.Finish(&result2));\n+  ASSERT_OK(builder.Finish(false, &result2));\n \n   std::shared_ptr<Array> str_array2;\n   ASSERT_OK(str_builder2.Finish(&str_array2));\n@@ -2149,7 +2299,7 @@ TEST(TestStringDictionaryBuilder, BigDeltaDictionary) {\n   ASSERT_OK(str_builder3.Append(\"test_new_value2\"));\n \n   std::shared_ptr<Array> result3;\n-  ASSERT_OK(builder.Finish(&result3));\n+  ASSERT_OK(builder.Finish(false, &result3));\n \n   std::shared_ptr<Array> str_array3;\n   ASSERT_OK(str_builder3.Finish(&str_array3));\n@@ -2207,7 +2357,7 @@ TEST(TestFixedSizeBinaryDictionaryBuilder, DeltaDictionary) {\n   ASSERT_OK(builder.Append(test.data()));\n \n   std::shared_ptr<Array> result1;\n-  ASSERT_OK(builder.Finish(&result1));\n+  ASSERT_OK(builder.Finish(false, &result1));\n \n   // Build expected data\n   FixedSizeBinaryBuilder fsb_builder1(arrow::fixed_size_binary(4));\n@@ -2233,7 +2383,7 @@ TEST(TestFixedSizeBinaryDictionaryBuilder, DeltaDictionary) {\n   ASSERT_OK(builder.Append(test3.data()));\n \n   std::shared_ptr<Array> result2;\n-  ASSERT_OK(builder.Finish(&result2));\n+  ASSERT_OK(builder.Finish(false, &result2));\n \n   // Build expected data\n   FixedSizeBinaryBuilder fsb_builder2(arrow::fixed_size_binary(4));\ndiff --git a/cpp/src/arrow/buffer-test.cc b/cpp/src/arrow/buffer-test.cc\nindex a24384a38..229737723 100644\n--- a/cpp/src/arrow/buffer-test.cc\n+++ b/cpp/src/arrow/buffer-test.cc\n@@ -20,6 +20,7 @@\n #include <limits>\n #include <memory>\n #include <string>\n+#include <vector>\n \n #include <gtest/gtest.h>\n \n@@ -181,7 +182,7 @@ TEST(TestBuffer, Copy) {\n }\n \n TEST(TestBuffer, SliceBuffer) {\n-  std::string data_str = \"some data to slice\";\n+  std::string data_str = \"some data toxo slice\";\n \n   auto data = reinterpret_cast<const uint8_t*>(data_str.c_str());\n \n@@ -236,4 +237,102 @@ TEST(TestBufferBuilder, ResizeReserve) {\n   ASSERT_EQ(128, builder.capacity());\n }\n \n+TEST(TestBufferBuilder, ReuseBuilder) {\n+  const std::string data1 = \"foo\";\n+  const std::string data2 = \"bar\";\n+\n+  BufferBuilder builder;\n+\n+  ASSERT_OK(builder.Append(data1.c_str(), data1.length()));\n+\n+  std::shared_ptr<Buffer> out1;\n+  ASSERT_OK(builder.FinishSlice(&out1, 0, data1.length(), false));\n+\n+  ASSERT_EQ(3, out1->size());\n+  ASSERT_STREQ(data1.c_str(), reinterpret_cast<const char*>(out1->data()));\n+\n+  ASSERT_OK(builder.Append(data2.c_str(), data2.length()));\n+\n+  std::shared_ptr<Buffer> out2;\n+  ASSERT_OK(builder.FinishSlice(&out2, data1.length(), data2.length(), true));\n+\n+  ASSERT_EQ(3, out2->size());\n+  ASSERT_STREQ(data2.c_str(), reinterpret_cast<const char*>(out2->data()));\n+}\n+\n+TEST(TestBufferBuilder, FinishSlice) {\n+  const std::string data = \"foo_bar\";\n+  auto data_ptr = data.c_str();\n+\n+  BufferBuilder builder;\n+\n+  ASSERT_OK(builder.Append(data_ptr, data.length()));\n+  ASSERT_EQ(data.length(), builder.length());\n+\n+  // Partially finish\n+  std::shared_ptr<Buffer> out;\n+  ASSERT_OK(builder.FinishSlice(&out, 4, 3, true));\n+\n+  ASSERT_EQ(3, out->size());\n+  ASSERT_STREQ(\"bar\", reinterpret_cast<const char*>(out->data()));\n+}\n+\n+template <typename T>\n+class TestTypedBufferBuilder : public testing::Test {};\n+\n+typedef ::testing::Types<int8_t, uint8_t, int16_t, uint16_t, int32_t, uint32_t, int64_t,\n+                         uint64_t, float, double>\n+    PrimitiveTypes;\n+\n+TYPED_TEST_CASE(TestTypedBufferBuilder, PrimitiveTypes);\n+\n+TYPED_TEST(TestTypedBufferBuilder, ReuseBuilder) {\n+  std::vector<TypeParam> values1 = {1, 2, 3, 4};\n+  std::vector<TypeParam> values2 = {5, 6, 7, 8};\n+\n+  TypedBufferBuilder<TypeParam> builder;\n+\n+  ASSERT_OK(builder.Append(values1.data(), values1.size()));\n+\n+  std::shared_ptr<Buffer> out1;\n+  ASSERT_OK(builder.FinishSlice(&out1, 0, values1.size() * sizeof(TypeParam),\n+                                /* reset */ false));\n+\n+  ASSERT_EQ(values1.size() * sizeof(TypeParam), out1->size());\n+  ASSERT_EQ(0, memcmp(values1.data(), out1->data(), values1.size() * sizeof(TypeParam)));\n+\n+  ASSERT_OK(builder.Append(values2.data(), values2.size()));\n+\n+  std::shared_ptr<Buffer> out2;\n+  ASSERT_OK(builder.FinishSlice(&out2, values1.size() * sizeof(TypeParam),\n+                                values2.size() * sizeof(TypeParam), /* reset */ true));\n+\n+  ASSERT_EQ(values2.size() * sizeof(TypeParam), out2->size());\n+  ASSERT_EQ(0, memcmp(values2.data(), out2->data(), values2.size() * sizeof(TypeParam)));\n+}\n+\n+TYPED_TEST(TestTypedBufferBuilder, FinishSliceByItem) {\n+  std::vector<TypeParam> values1 = {1, 2, 3, 4};\n+  std::vector<TypeParam> values2 = {5, 6, 7, 8};\n+\n+  TypedBufferBuilder<TypeParam> builder;\n+\n+  ASSERT_OK(builder.Append(values1.data(), values1.size()));\n+\n+  std::shared_ptr<Buffer> out1;\n+  ASSERT_OK(builder.FinishSliceByItem(&out1, 0, values1.size(), /* reset */ false));\n+\n+  ASSERT_EQ(values1.size() * sizeof(TypeParam), out1->size());\n+  ASSERT_EQ(0, memcmp(values1.data(), out1->data(), values1.size() * sizeof(TypeParam)));\n+\n+  ASSERT_OK(builder.Append(values2.data(), values2.size()));\n+\n+  std::shared_ptr<Buffer> out2;\n+  ASSERT_OK(\n+      builder.FinishSliceByItem(&out2, values1.size(), values2.size(), /* reset */ true));\n+\n+  ASSERT_EQ(values2.size() * sizeof(TypeParam), out2->size());\n+  ASSERT_EQ(0, memcmp(values2.data(), out2->data(), values2.size() * sizeof(TypeParam)));\n+}\n+\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/buffer.h b/cpp/src/arrow/buffer.h\nindex 06160d7d4..fe7a0f398 100644\n--- a/cpp/src/arrow/buffer.h\n+++ b/cpp/src/arrow/buffer.h\n@@ -53,12 +53,15 @@ class ARROW_EXPORT Buffer {\n   /// \\param[in] size buffer size\n   ///\n   /// \\note The passed memory must be kept alive through some other means\n-  Buffer(const uint8_t* data, int64_t size)\n+  Buffer(const uint8_t* data, int64_t size, int64_t capacity)\n       : is_mutable_(false),\n         data_(data),\n         mutable_data_(NULLPTR),\n         size_(size),\n-        capacity_(size) {}\n+        capacity_(capacity) {}\n+\n+  /// Initialize with known capacity\n+  Buffer(const uint8_t* data, int64_t size) : Buffer(data, size, size) {}\n \n   /// \\brief Construct from std::string without copying memory\n   ///\n@@ -80,7 +83,7 @@ class ARROW_EXPORT Buffer {\n   /// in general we expected buffers to be aligned and padded to 64 bytes.  In the future\n   /// we might add utility methods to help determine if a buffer satisfies this contract.\n   Buffer(const std::shared_ptr<Buffer>& parent, const int64_t offset, const int64_t size)\n-      : Buffer(parent->data() + offset, size) {\n+      : Buffer(parent->data() + offset, size, parent->capacity()) {\n     parent_ = parent;\n   }\n \n@@ -300,11 +303,25 @@ class ARROW_EXPORT BufferBuilder {\n \n   Status Finish(std::shared_ptr<Buffer>* out) {\n     // Do not shrink to fit to avoid unneeded realloc\n+    return FinishSlice(out, 0, size_, true);\n+  }\n+\n+  Status FinishSlice(std::shared_ptr<Buffer>* out, const int64_t offset,\n+                     const int64_t length, const bool reset = true) {\n+    // Do not shrink to fit to avoid unneeded realloc\n     if (size_ > 0) {\n       RETURN_NOT_OK(buffer_->Resize(size_, false));\n     }\n-    *out = buffer_;\n-    Reset();\n+    if (size_ == 0 || (offset == 0 && length == size_)) {\n+      // no need for slices for trivial cases\n+      *out = buffer_;\n+    } else {\n+      *out = std::make_shared<Buffer>(buffer_, offset, length);\n+    }\n+\n+    if (reset) {\n+      Reset();\n+    }\n     return Status::OK();\n   }\n \n@@ -328,7 +345,8 @@ class ARROW_EXPORT BufferBuilder {\n template <typename T>\n class ARROW_EXPORT TypedBufferBuilder : public BufferBuilder {\n  public:\n-  explicit TypedBufferBuilder(MemoryPool* pool) : BufferBuilder(pool) {}\n+  explicit TypedBufferBuilder(MemoryPool* pool ARROW_MEMORY_POOL_DEFAULT)\n+      : BufferBuilder(pool) {}\n \n   Status Append(T arithmetic_value) {\n     static_assert(std::is_arithmetic<T>::value,\n@@ -357,6 +375,26 @@ class ARROW_EXPORT TypedBufferBuilder : public BufferBuilder {\n                                 num_elements * sizeof(T));\n   }\n \n+  /// Same as FinishSlice but uses typed item counts as offsets and length,\n+  /// i.e. with TypedBufferBuilder<uint32_t> offset of 4 means that the\n+  /// offset is 12 bytese or 4 uints\n+  Status FinishSliceByItem(std::shared_ptr<Buffer>* out, const int64_t offset,\n+                           const int64_t length, const bool reset = true) {\n+    // Do not shrink to fit to avoid unneeded realloc\n+    if (size_ > 0) {\n+      RETURN_NOT_OK(buffer_->Resize(size_, false));\n+    }\n+    if (size_ == 0) {\n+      *out = buffer_;\n+    } else {\n+      *out = std::make_shared<Buffer>(buffer_, offset * sizeof(T), length * sizeof(T));\n+    }\n+    if (reset) {\n+      Reset();\n+    }\n+    return Status::OK();\n+  }\n+\n   const T* data() const { return reinterpret_cast<const T*>(data_); }\n   int64_t length() const { return size_ / sizeof(T); }\n   int64_t capacity() const { return capacity_ / sizeof(T); }\ndiff --git a/cpp/src/arrow/builder.cc b/cpp/src/arrow/builder.cc\nindex c97253e64..9874e0fd7 100644\n--- a/cpp/src/arrow/builder.cc\n+++ b/cpp/src/arrow/builder.cc\n@@ -220,9 +220,11 @@ void ArrayBuilder::UnsafeSetNotNull(int64_t length) {\n // ----------------------------------------------------------------------\n // Null builder\n \n-Status NullBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n+Status NullBuilder::FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) {\n   *out = ArrayData::Make(null(), length_, {nullptr}, length_);\n-  length_ = null_count_ = 0;\n+  if (reset_builder) {\n+    length_ = null_count_ = 0;\n+  }\n   return Status::OK();\n }\n \n@@ -309,16 +311,25 @@ Status PrimitiveBuilder<T>::Append(const std::vector<value_type>& values) {\n }\n \n template <typename T>\n-Status PrimitiveBuilder<T>::FinishInternal(std::shared_ptr<ArrayData>* out) {\n+Status PrimitiveBuilder<T>::FinishInternal(bool reset_builder,\n+                                           std::shared_ptr<ArrayData>* out) {\n+  auto length = length_ - elements_offset_;\n   const int64_t bytes_required = TypeTraits<T>::bytes_required(length_);\n-  if (bytes_required > 0 && bytes_required < data_->size()) {\n+  if (bytes_required > 0 && bytes_required < data_->size() && reset_builder) {\n     // Trim buffers\n     RETURN_NOT_OK(data_->Resize(bytes_required));\n+    // reset raw_data_ pointer and capacity\n+    raw_data_ = reinterpret_cast<value_type*>(data_->mutable_data());\n+    capacity_ = data()->capacity();\n+  }\n+  *out = ArrayData::Make(type_, length, {null_bitmap_, data_}, null_count_,\n+                         elements_offset_);\n+\n+  if (reset_builder) {\n+    data_ = null_bitmap_ = nullptr;\n+    capacity_ = length_ = null_count_ = 0;\n   }\n-  *out = ArrayData::Make(type_, length_, {null_bitmap_, data_}, null_count_);\n \n-  data_ = null_bitmap_ = nullptr;\n-  capacity_ = length_ = null_count_ = 0;\n   return Status::OK();\n }\n \n@@ -340,7 +351,10 @@ template class PrimitiveBuilder<FloatType>;\n template class PrimitiveBuilder<DoubleType>;\n \n AdaptiveIntBuilderBase::AdaptiveIntBuilderBase(MemoryPool* pool)\n-    : ArrayBuilder(int64(), pool), data_(nullptr), raw_data_(nullptr), int_size_(1) {}\n+    : PartiallyFinishableArrayBuilder(int64(), pool),\n+      data_(nullptr),\n+      raw_data_(nullptr),\n+      int_size_(1) {}\n \n Status AdaptiveIntBuilderBase::Init(int64_t capacity) {\n   RETURN_NOT_OK(ArrayBuilder::Init(capacity));\n@@ -378,11 +392,16 @@ Status AdaptiveIntBuilderBase::Resize(int64_t capacity) {\n \n AdaptiveIntBuilder::AdaptiveIntBuilder(MemoryPool* pool) : AdaptiveIntBuilderBase(pool) {}\n \n-Status AdaptiveIntBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n+Status AdaptiveIntBuilder::FinishInternal(bool reset_builder,\n+                                          std::shared_ptr<ArrayData>* out) {\n+  auto length = length_ - elements_offset_;\n   const int64_t bytes_required = length_ * int_size_;\n-  if (bytes_required > 0 && bytes_required < data_->size()) {\n-    // Trim buffers\n+  if (bytes_required > 0 && bytes_required < data_->size() && reset_builder) {\n+    // only shrink the buffer\n     RETURN_NOT_OK(data_->Resize(bytes_required));\n+    // adjust raw_data_ pointer\n+    raw_data_ = data_->mutable_data();\n+    capacity_ = data_->capacity() / int_size_;\n   }\n \n   std::shared_ptr<DataType> output_type;\n@@ -404,10 +423,13 @@ Status AdaptiveIntBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n       return Status::NotImplemented(\"Only ints of size 1,2,4,8 are supported\");\n   }\n \n-  *out = ArrayData::Make(output_type, length_, {null_bitmap_, data_}, null_count_);\n+  *out = ArrayData::Make(output_type, length, {null_bitmap_, data_}, null_count_,\n+                         elements_offset_);\n \n-  data_ = null_bitmap_ = nullptr;\n-  capacity_ = length_ = null_count_ = 0;\n+  if (reset_builder) {\n+    data_ = null_bitmap_ = nullptr;\n+    capacity_ = length_ = null_count_ = 0;\n+  }\n   return Status::OK();\n }\n \n@@ -535,12 +557,17 @@ Status AdaptiveIntBuilder::ExpandIntSize(uint8_t new_int_size) {\n AdaptiveUIntBuilder::AdaptiveUIntBuilder(MemoryPool* pool)\n     : AdaptiveIntBuilderBase(pool) {}\n \n-Status AdaptiveUIntBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n+Status AdaptiveUIntBuilder::FinishInternal(bool reset_builder,\n+                                           std::shared_ptr<ArrayData>* out) {\n+  auto length = length_ - elements_offset_;\n   const int64_t bytes_required = length_ * int_size_;\n-  if (bytes_required > 0 && bytes_required < data_->size()) {\n-    // Trim buffers\n+  if (bytes_required > 0 && bytes_required < data_->size() && reset_builder) {\n     RETURN_NOT_OK(data_->Resize(bytes_required));\n+    // adjust raw_data_ pointer and capacity\n+    raw_data_ = data_->mutable_data();\n+    capacity_ = data_->capacity() / int_size_;\n   }\n+\n   std::shared_ptr<DataType> output_type;\n   switch (int_size_) {\n     case 1:\n@@ -560,10 +587,13 @@ Status AdaptiveUIntBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n       return Status::NotImplemented(\"Only ints of size 1,2,4,8 are supported\");\n   }\n \n-  *out = ArrayData::Make(output_type, length_, {null_bitmap_, data_}, null_count_);\n+  *out = ArrayData::Make(output_type, length, {null_bitmap_, data_}, null_count_,\n+                         elements_offset_);\n \n-  data_ = null_bitmap_ = nullptr;\n-  capacity_ = length_ = null_count_ = 0;\n+  if (reset_builder) {\n+    data_ = null_bitmap_ = nullptr;\n+    capacity_ = length_ = null_count_ = 0;\n+  }\n   return Status::OK();\n }\n \n@@ -689,7 +719,9 @@ Status AdaptiveUIntBuilder::ExpandIntSize(uint8_t new_int_size) {\n }\n \n BooleanBuilder::BooleanBuilder(MemoryPool* pool)\n-    : ArrayBuilder(boolean(), pool), data_(nullptr), raw_data_(nullptr) {}\n+    : PartiallyFinishableArrayBuilder(boolean(), pool),\n+      data_(nullptr),\n+      raw_data_(nullptr) {}\n \n BooleanBuilder::BooleanBuilder(const std::shared_ptr<DataType>& type, MemoryPool* pool)\n     : BooleanBuilder(pool) {\n@@ -730,17 +762,26 @@ Status BooleanBuilder::Resize(int64_t capacity) {\n   return Status::OK();\n }\n \n-Status BooleanBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n+Status BooleanBuilder::FinishInternal(bool reset_builder,\n+                                      std::shared_ptr<ArrayData>* out) {\n+  auto length = length_ - elements_offset_;\n   const int64_t bytes_required = BitUtil::BytesForBits(length_);\n \n-  if (bytes_required > 0 && bytes_required < data_->size()) {\n-    // Trim buffers\n+  if (bytes_required > 0 && bytes_required < data_->size() && reset_builder) {\n+    // Trim buffers only if buffer is reset afterwards\n     RETURN_NOT_OK(data_->Resize(bytes_required));\n+    // reset raw_data_ pointer and capacity_\n+    raw_data_ = data_->mutable_data();\n+    capacity_ = data_->capacity();\n+  }\n+  *out = ArrayData::Make(boolean(), length, {null_bitmap_, data_}, null_count_,\n+                         elements_offset_);\n+\n+  if (reset_builder) {\n+    data_ = null_bitmap_ = nullptr;\n+    capacity_ = length_ = null_count_ = 0;\n   }\n-  *out = ArrayData::Make(boolean(), length_, {null_bitmap_, data_}, null_count_);\n \n-  data_ = null_bitmap_ = nullptr;\n-  capacity_ = length_ = null_count_ = 0;\n   return Status::OK();\n }\n \n@@ -809,13 +850,12 @@ Status BooleanBuilder::Append(const std::vector<bool>& values) {\n \n // ----------------------------------------------------------------------\n // DictionaryBuilder\n-\n using internal::WrappedBinary;\n \n template <typename T>\n DictionaryBuilder<T>::DictionaryBuilder(const std::shared_ptr<DataType>& type,\n                                         MemoryPool* pool)\n-    : ArrayBuilder(type, pool),\n+    : PartiallyFinishableArrayBuilder(type, pool),\n       hash_slots_(nullptr),\n       dict_builder_(type, pool),\n       overflow_dict_builder_(type, pool),\n@@ -828,7 +868,7 @@ DictionaryBuilder<T>::DictionaryBuilder(const std::shared_ptr<DataType>& type,\n \n DictionaryBuilder<NullType>::DictionaryBuilder(const std::shared_ptr<DataType>& type,\n                                                MemoryPool* pool)\n-    : ArrayBuilder(type, pool), values_builder_(pool) {\n+    : PartiallyFinishableArrayBuilder(type, pool), values_builder_(pool) {\n   if (!::arrow::CpuInfo::initialized()) {\n     ::arrow::CpuInfo::Init();\n   }\n@@ -839,7 +879,7 @@ DictionaryBuilder<NullType>::~DictionaryBuilder() {}\n template <>\n DictionaryBuilder<FixedSizeBinaryType>::DictionaryBuilder(\n     const std::shared_ptr<DataType>& type, MemoryPool* pool)\n-    : ArrayBuilder(type, pool),\n+    : PartiallyFinishableArrayBuilder(type, pool),\n       hash_slots_(nullptr),\n       dict_builder_(type, pool),\n       overflow_dict_builder_(type, pool),\n@@ -858,11 +898,10 @@ Status DictionaryBuilder<T>::Init(int64_t elements) {\n   RETURN_NOT_OK(internal::NewHashTable(kInitialHashTableSize, pool_, &hash_table_));\n   hash_slots_ = reinterpret_cast<int32_t*>(hash_table_->mutable_data());\n   hash_table_size_ = kInitialHashTableSize;\n-  entry_id_offset_ = 0;\n   mod_bitmask_ = kInitialHashTableSize - 1;\n   hash_table_load_threshold_ =\n       static_cast<int64_t>(static_cast<double>(elements) * kMaxHashTableLoad);\n-\n+  RETURN_NOT_OK(dict_builder_.Init(elements));\n   return values_builder_.Init(elements);\n }\n \n@@ -915,7 +954,7 @@ Status DictionaryBuilder<T>::Append(const Scalar& value) {\n \n   if (index == kHashSlotEmpty) {\n     // Not in the hash table, so we insert it now\n-    index = static_cast<hash_slot_t>(dict_builder_.length() + entry_id_offset_);\n+    index = static_cast<hash_slot_t>(dict_builder_.length());\n     hash_slots_[j] = index;\n     RETURN_NOT_OK(AppendDictionary(value));\n \n@@ -992,58 +1031,49 @@ typename DictionaryBuilder<T>::Scalar DictionaryBuilder<T>::GetDictionaryValue(\n   return data[index];\n }\n \n-template <typename T>\n-Status DictionaryBuilder<T>::FinishInternal(std::shared_ptr<ArrayData>* out) {\n-  entry_id_offset_ += dict_builder_.length();\n-  RETURN_NOT_OK(overflow_dict_builder_.Append(\n-      reinterpret_cast<const DictionaryBuilder<T>::Scalar*>(dict_builder_.data()->data()),\n-      dict_builder_.length(), nullptr));\n+template <>\n+const uint8_t* DictionaryBuilder<FixedSizeBinaryType>::GetDictionaryValue(\n+    typename TypeTraits<FixedSizeBinaryType>::BuilderType& dictionary_builder,\n+    int64_t index) {\n+  return dictionary_builder.GetValue(index);\n+}\n \n-  std::shared_ptr<Array> dictionary;\n-  RETURN_NOT_OK(dict_builder_.Finish(&dictionary));\n+template <typename T>\n+Status DictionaryBuilder<T>::FinishInternal(bool reset_builder,\n+                                            std::shared_ptr<ArrayData>* out) {\n+  std::shared_ptr<Array> dictionary, values;\n+  RETURN_NOT_OK(dict_builder_.Finish(reset_builder, &dictionary));\n+  RETURN_NOT_OK(values_builder_.Finish(reset_builder, &values));\n+  *out = values->data();\n \n-  RETURN_NOT_OK(values_builder_.FinishInternal(out));\n   (*out)->type = std::make_shared<DictionaryType>((*out)->type, dictionary);\n \n-  RETURN_NOT_OK(dict_builder_.Init(capacity_));\n-  RETURN_NOT_OK(values_builder_.Init(capacity_));\n+  if (reset_builder) {\n+    capacity_ = 0;\n+  }\n+\n   return Status::OK();\n }\n \n-Status DictionaryBuilder<NullType>::FinishInternal(std::shared_ptr<ArrayData>* out) {\n+Status DictionaryBuilder<NullType>::FinishInternal(bool reset_builder,\n+                                                   std::shared_ptr<ArrayData>* out) {\n   std::shared_ptr<Array> dictionary = std::make_shared<NullArray>(0);\n \n-  RETURN_NOT_OK(values_builder_.FinishInternal(out));\n+  RETURN_NOT_OK(values_builder_.FinishInternal(reset_builder, out));\n   (*out)->type = std::make_shared<DictionaryType>((*out)->type, dictionary);\n   return Status::OK();\n }\n \n-template <>\n-const uint8_t* DictionaryBuilder<FixedSizeBinaryType>::GetDictionaryValue(\n-    typename TypeTraits<FixedSizeBinaryType>::BuilderType& dictionary_builder,\n-    int64_t index) {\n-  return dictionary_builder.GetValue(index);\n-}\n-\n template <>\n Status DictionaryBuilder<FixedSizeBinaryType>::FinishInternal(\n-    std::shared_ptr<ArrayData>* out) {\n-  entry_id_offset_ += dict_builder_.length();\n-\n-  for (uint64_t index = 0, limit = dict_builder_.length(); index < limit; ++index) {\n-    const Scalar value = GetDictionaryValue(dict_builder_, index);\n-    RETURN_NOT_OK(overflow_dict_builder_.Append(value));\n-  }\n-\n-  std::shared_ptr<Array> dictionary;\n-  RETURN_NOT_OK(dict_builder_.Finish(&dictionary));\n+    bool reset_builder, std::shared_ptr<ArrayData>* out) {\n+  std::shared_ptr<Array> dictionary, values;\n+  RETURN_NOT_OK(dict_builder_.Finish(reset_builder, &dictionary));\n+  RETURN_NOT_OK(values_builder_.Finish(reset_builder, &values));\n+  *out = values->data();\n \n-  RETURN_NOT_OK(values_builder_.FinishInternal(out));\n   (*out)->type = std::make_shared<DictionaryType>((*out)->type, dictionary);\n \n-  RETURN_NOT_OK(dict_builder_.Init(capacity_));\n-  RETURN_NOT_OK(values_builder_.Init(capacity_));\n-\n   return Status::OK();\n }\n \n@@ -1060,33 +1090,17 @@ int64_t DictionaryBuilder<FixedSizeBinaryType>::HashValue(const Scalar& value) {\n template <typename T>\n bool DictionaryBuilder<T>::SlotDifferent(hash_slot_t index, const Scalar& value) {\n   const bool value_found =\n-      index >= entry_id_offset_ &&\n-      GetDictionaryValue(dict_builder_, static_cast<int64_t>(index - entry_id_offset_)) ==\n-          value;\n-  const bool value_found_overflow =\n-      entry_id_offset_ > 0 &&\n-      GetDictionaryValue(overflow_dict_builder_, static_cast<int64_t>(index)) == value;\n-  return !(value_found || value_found_overflow);\n+      GetDictionaryValue(dict_builder_, static_cast<int64_t>(index)) == value;\n+  return !value_found;\n }\n \n template <>\n bool DictionaryBuilder<FixedSizeBinaryType>::SlotDifferent(hash_slot_t index,\n                                                            const Scalar& value) {\n   int32_t width = static_cast<const FixedSizeBinaryType&>(*type_).byte_width();\n-  bool value_found = false;\n-  if (index >= entry_id_offset_) {\n-    const Scalar other =\n-        GetDictionaryValue(dict_builder_, static_cast<int64_t>(index - entry_id_offset_));\n-    value_found = memcmp(other, value, width) == 0;\n-  }\n-\n-  bool value_found_overflow = false;\n-  if (entry_id_offset_ > 0) {\n-    const Scalar other_overflow =\n-        GetDictionaryValue(overflow_dict_builder_, static_cast<int64_t>(index));\n-    value_found_overflow = memcmp(other_overflow, value, width) == 0;\n-  }\n-  return !(value_found || value_found_overflow);\n+  const Scalar other = GetDictionaryValue(dict_builder_, static_cast<int64_t>(index));\n+  bool value_found = memcmp(other, value, width) == 0;\n+  return !value_found;\n }\n \n template <typename T>\n@@ -1094,82 +1108,63 @@ Status DictionaryBuilder<T>::AppendDictionary(const Scalar& value) {\n   return dict_builder_.Append(value);\n }\n \n-#define BINARY_DICTIONARY_SPECIALIZATIONS(Type)                                        \\\n-  template <>                                                                          \\\n-  WrappedBinary DictionaryBuilder<Type>::GetDictionaryValue(                           \\\n-      typename TypeTraits<Type>::BuilderType& dictionary_builder, int64_t index) {     \\\n-    int32_t v_len;                                                                     \\\n-    const uint8_t* v = dictionary_builder.GetValue(                                    \\\n-        static_cast<int64_t>(index - entry_id_offset_), &v_len);                       \\\n-    return WrappedBinary(v, v_len);                                                    \\\n-  }                                                                                    \\\n-                                                                                       \\\n-  template <>                                                                          \\\n-  Status DictionaryBuilder<Type>::AppendDictionary(const WrappedBinary& value) {       \\\n-    return dict_builder_.Append(value.ptr_, value.length_);                            \\\n-  }                                                                                    \\\n-                                                                                       \\\n-  template <>                                                                          \\\n-  Status DictionaryBuilder<Type>::AppendArray(const Array& array) {                    \\\n-    const BinaryArray& binary_array = static_cast<const BinaryArray&>(array);          \\\n-    WrappedBinary value(nullptr, 0);                                                   \\\n-    for (int64_t i = 0; i < array.length(); i++) {                                     \\\n-      if (array.IsNull(i)) {                                                           \\\n-        RETURN_NOT_OK(AppendNull());                                                   \\\n-      } else {                                                                         \\\n-        value.ptr_ = binary_array.GetValue(i, &value.length_);                         \\\n-        RETURN_NOT_OK(Append(value));                                                  \\\n-      }                                                                                \\\n-    }                                                                                  \\\n-    return Status::OK();                                                               \\\n-  }                                                                                    \\\n-                                                                                       \\\n-  template <>                                                                          \\\n-  int64_t DictionaryBuilder<Type>::HashValue(const WrappedBinary& value) {             \\\n-    return HashUtil::Hash(value.ptr_, value.length_, 0);                               \\\n-  }                                                                                    \\\n-                                                                                       \\\n-  template <>                                                                          \\\n-  bool DictionaryBuilder<Type>::SlotDifferent(hash_slot_t index,                       \\\n-                                              const WrappedBinary& value) {            \\\n-    int32_t other_length;                                                              \\\n-    bool value_found = false;                                                          \\\n-    if (index >= entry_id_offset_) {                                                   \\\n-      const uint8_t* other_value = dict_builder_.GetValue(                             \\\n-          static_cast<int64_t>(index - entry_id_offset_), &other_length);              \\\n-      value_found = other_length == value.length_ &&                                   \\\n-                    memcmp(other_value, value.ptr_, value.length_) == 0;               \\\n-    }                                                                                  \\\n-                                                                                       \\\n-    bool value_found_overflow = false;                                                 \\\n-    if (entry_id_offset_ > 0) {                                                        \\\n-      const uint8_t* other_value_overflow =                                            \\\n-          overflow_dict_builder_.GetValue(static_cast<int64_t>(index), &other_length); \\\n-      value_found_overflow =                                                           \\\n-          other_length == value.length_ &&                                             \\\n-          memcmp(other_value_overflow, value.ptr_, value.length_) == 0;                \\\n-    }                                                                                  \\\n-    return !(value_found || value_found_overflow);                                     \\\n-  }                                                                                    \\\n-                                                                                       \\\n-  template <>                                                                          \\\n-  Status DictionaryBuilder<Type>::FinishInternal(std::shared_ptr<ArrayData>* out) {    \\\n-    entry_id_offset_ += dict_builder_.length();                                        \\\n-    for (uint64_t index = 0, limit = dict_builder_.length(); index < limit; ++index) { \\\n-      int32_t out_length;                                                              \\\n-      const uint8_t* value = dict_builder_.GetValue(index, &out_length);               \\\n-      RETURN_NOT_OK(overflow_dict_builder_.Append(value, out_length));                 \\\n-    }                                                                                  \\\n-                                                                                       \\\n-    std::shared_ptr<Array> dictionary;                                                 \\\n-    RETURN_NOT_OK(dict_builder_.Finish(&dictionary));                                  \\\n-                                                                                       \\\n-    RETURN_NOT_OK(values_builder_.FinishInternal(out));                                \\\n-    (*out)->type = std::make_shared<DictionaryType>((*out)->type, dictionary);         \\\n-                                                                                       \\\n-    RETURN_NOT_OK(dict_builder_.Init(capacity_));                                      \\\n-    RETURN_NOT_OK(values_builder_.Init(capacity_));                                    \\\n-    return Status::OK();                                                               \\\n+#define BINARY_DICTIONARY_SPECIALIZATIONS(Type)                                          \\\n+  template <>                                                                            \\\n+  WrappedBinary DictionaryBuilder<Type>::GetDictionaryValue(                             \\\n+      typename TypeTraits<Type>::BuilderType& dictionary_builder, int64_t index) {       \\\n+    int32_t v_len;                                                                       \\\n+    const uint8_t* v = dictionary_builder.GetValue(static_cast<int64_t>(index), &v_len); \\\n+    return WrappedBinary(v, v_len);                                                      \\\n+  }                                                                                      \\\n+                                                                                         \\\n+  template <>                                                                            \\\n+  Status DictionaryBuilder<Type>::AppendDictionary(const WrappedBinary& value) {         \\\n+    return dict_builder_.Append(value.ptr_, value.length_);                              \\\n+  }                                                                                      \\\n+                                                                                         \\\n+  template <>                                                                            \\\n+  Status DictionaryBuilder<Type>::AppendArray(const Array& array) {                      \\\n+    const BinaryArray& binary_array = static_cast<const BinaryArray&>(array);            \\\n+    WrappedBinary value(nullptr, 0);                                                     \\\n+    for (int64_t i = 0; i < array.length(); i++) {                                       \\\n+      if (array.IsNull(i)) {                                                             \\\n+        RETURN_NOT_OK(AppendNull());                                                     \\\n+      } else {                                                                           \\\n+        value.ptr_ = binary_array.GetValue(i, &value.length_);                           \\\n+        RETURN_NOT_OK(Append(value));                                                    \\\n+      }                                                                                  \\\n+    }                                                                                    \\\n+    return Status::OK();                                                                 \\\n+  }                                                                                      \\\n+                                                                                         \\\n+  template <>                                                                            \\\n+  int64_t DictionaryBuilder<Type>::HashValue(const WrappedBinary& value) {               \\\n+    return HashUtil::Hash(value.ptr_, value.length_, 0);                                 \\\n+  }                                                                                      \\\n+                                                                                         \\\n+  template <>                                                                            \\\n+  bool DictionaryBuilder<Type>::SlotDifferent(hash_slot_t index,                         \\\n+                                              const WrappedBinary& value) {              \\\n+    int32_t other_length;                                                                \\\n+    bool value_found = false;                                                            \\\n+    const uint8_t* other_value =                                                         \\\n+        dict_builder_.GetValue(static_cast<int64_t>(index), &other_length);              \\\n+    value_found = other_length == value.length_ &&                                       \\\n+                  memcmp(other_value, value.ptr_, value.length_) == 0;                   \\\n+    return !value_found;                                                                 \\\n+  }                                                                                      \\\n+                                                                                         \\\n+  template <>                                                                            \\\n+  Status DictionaryBuilder<Type>::FinishInternal(bool reset_builder,                     \\\n+                                                 std::shared_ptr<ArrayData>* out) {      \\\n+    std::shared_ptr<Array> dictionary, values;                                           \\\n+    RETURN_NOT_OK(dict_builder_.Finish(reset_builder, &dictionary));                     \\\n+                                                                                         \\\n+    RETURN_NOT_OK(values_builder_.Finish(reset_builder, &values));                       \\\n+    *out = values->data();                                                               \\\n+    (*out)->type = std::make_shared<DictionaryType>((*out)->type, dictionary);           \\\n+                                                                                         \\\n+    return Status::OK();                                                                 \\\n   }\n \n BINARY_DICTIONARY_SPECIALIZATIONS(StringType);\n@@ -1206,14 +1201,6 @@ Status Decimal128Builder::Append(const Decimal128& value) {\n   return FixedSizeBinaryBuilder::Append(value.ToBytes());\n }\n \n-Status Decimal128Builder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n-  std::shared_ptr<Buffer> data;\n-  RETURN_NOT_OK(byte_builder_.Finish(&data));\n-\n-  *out = ArrayData::Make(type_, length_, {null_bitmap_, data}, null_count_);\n-  return Status::OK();\n-}\n-\n // ----------------------------------------------------------------------\n // ListBuilder\n \n@@ -1298,13 +1285,16 @@ ArrayBuilder* ListBuilder::value_builder() const {\n // String and binary\n \n BinaryBuilder::BinaryBuilder(const std::shared_ptr<DataType>& type, MemoryPool* pool)\n-    : ArrayBuilder(type, pool), offsets_builder_(pool), value_data_builder_(pool) {}\n+    : PartiallyFinishableArrayBuilder(type, pool),\n+      offsets_builder_(pool),\n+      value_data_builder_(pool) {}\n \n BinaryBuilder::BinaryBuilder(MemoryPool* pool) : BinaryBuilder(binary(), pool) {}\n \n Status BinaryBuilder::Init(int64_t elements) {\n   DCHECK_LE(elements, kListMaximumElements);\n   RETURN_NOT_OK(ArrayBuilder::Init(elements));\n+  is_final_offset_written_ = false;\n   // one more then requested for offsets\n   return offsets_builder_.Resize((elements + 1) * sizeof(int32_t));\n }\n@@ -1327,6 +1317,12 @@ Status BinaryBuilder::ReserveData(int64_t elements) {\n }\n \n Status BinaryBuilder::AppendNextOffset() {\n+  if (is_final_offset_written_) {\n+    // the final (closing) offset was written, just set the\n+    // flag to false\n+    is_final_offset_written_ = false;\n+    return Status::OK();\n+  }\n   const int64_t num_bytes = value_data_builder_.length();\n   if (ARROW_PREDICT_FALSE(num_bytes > kBinaryMemoryLimit)) {\n     std::stringstream ss;\n@@ -1337,6 +1333,16 @@ Status BinaryBuilder::AppendNextOffset() {\n   return offsets_builder_.Append(static_cast<int32_t>(num_bytes));\n }\n \n+// write final offset\n+Status BinaryBuilder::AppendFinalOffset() {\n+  if (ARROW_PREDICT_FALSE(is_final_offset_written_)) {\n+    return Status::Invalid(\"Final offset allready added\");\n+  }\n+  RETURN_NOT_OK(AppendNextOffset());\n+  is_final_offset_written_ = true;\n+  return Status::OK();\n+}\n+\n Status BinaryBuilder::Append(const uint8_t* value, int32_t length) {\n   RETURN_NOT_OK(Reserve(1));\n   RETURN_NOT_OK(AppendNextOffset());\n@@ -1352,17 +1358,23 @@ Status BinaryBuilder::AppendNull() {\n   return Status::OK();\n }\n \n-Status BinaryBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n-  // Write final offset (values length)\n-  RETURN_NOT_OK(AppendNextOffset());\n+Status BinaryBuilder::FinishInternal(bool reset_builder,\n+                                     std::shared_ptr<ArrayData>* out) {\n+  auto slice_length = length_ - elements_offset_;\n+  RETURN_NOT_OK(AppendFinalOffset());\n   std::shared_ptr<Buffer> offsets, value_data;\n \n-  RETURN_NOT_OK(offsets_builder_.Finish(&offsets));\n-  RETURN_NOT_OK(value_data_builder_.Finish(&value_data));\n+  RETURN_NOT_OK(\n+      offsets_builder_.FinishSliceByItem(&offsets, 0, slice_length + 1, reset_builder));\n+  auto last_offset = offsets_builder_.data()[elements_offset_ + slice_length];\n+  RETURN_NOT_OK(\n+      value_data_builder_.FinishSliceByItem(&value_data, 0, last_offset, reset_builder));\n \n-  *out = ArrayData::Make(type_, length_, {null_bitmap_, offsets, value_data}, null_count_,\n-                         0);\n-  Reset();\n+  *out = ArrayData::Make(type_, slice_length, {null_bitmap_, offsets, value_data},\n+                         null_count_, elements_offset_);\n+  if (reset_builder) {\n+    Reset();\n+  }\n   return Status::OK();\n }\n \n@@ -1418,7 +1430,7 @@ Status StringBuilder::Append(const std::vector<std::string>& values,\n \n FixedSizeBinaryBuilder::FixedSizeBinaryBuilder(const std::shared_ptr<DataType>& type,\n                                                MemoryPool* pool)\n-    : ArrayBuilder(type, pool),\n+    : PartiallyFinishableArrayBuilder(type, pool),\n       byte_width_(static_cast<const FixedSizeBinaryType&>(*type).byte_width()),\n       byte_builder_(pool) {}\n \n@@ -1449,14 +1461,19 @@ Status FixedSizeBinaryBuilder::Resize(int64_t capacity) {\n   return ArrayBuilder::Resize(capacity);\n }\n \n-Status FixedSizeBinaryBuilder::FinishInternal(std::shared_ptr<ArrayData>* out) {\n+Status FixedSizeBinaryBuilder::FinishInternal(bool reset_builder,\n+                                              std::shared_ptr<ArrayData>* out) {\n+  auto slice_length = length_ - elements_offset_;\n   std::shared_ptr<Buffer> data;\n-  RETURN_NOT_OK(byte_builder_.Finish(&data));\n+  RETURN_NOT_OK(byte_builder_.FinishSlice(&data, 0, slice_length * byte_width_, false));\n \n-  *out = ArrayData::Make(type_, length_, {null_bitmap_, data}, null_count_);\n+  *out = ArrayData::Make(type_, slice_length, {null_bitmap_, data}, null_count_,\n+                         elements_offset_);\n \n-  null_bitmap_ = nullptr;\n-  capacity_ = length_ = null_count_ = 0;\n+  if (reset_builder) {\n+    null_bitmap_ = nullptr;\n+    capacity_ = length_ = null_count_ = 0;\n+  }\n   return Status::OK();\n }\n \ndiff --git a/cpp/src/arrow/builder.h b/cpp/src/arrow/builder.h\nindex b0f77bd98..6a4919153 100644\n--- a/cpp/src/arrow/builder.h\n+++ b/cpp/src/arrow/builder.h\n@@ -26,6 +26,7 @@\n #include <string>\n #include <vector>\n \n+#include \"arrow/array.h\"\n #include \"arrow/buffer.h\"\n #include \"arrow/memory_pool.h\"\n #include \"arrow/status.h\"\n@@ -112,14 +113,14 @@ class ARROW_EXPORT ArrayBuilder {\n   std::shared_ptr<PoolBuffer> null_bitmap() const { return null_bitmap_; }\n \n   /// \\brief Return result of builder as an internal generic ArrayData\n-  /// object. Resets builder except for dictionary builder\n+  /// object.\n   ///\n   /// \\param[out] out the finalized ArrayData object\n   /// \\return Status\n   virtual Status FinishInternal(std::shared_ptr<ArrayData>* out) = 0;\n \n   /// \\brief Return result of builder as an Array object.\n-  ///        Resets the builder except for DictionaryBuilder\n+  ///        Resets the builder.\n   ///\n   /// \\param[out] out the finalized Array object\n   /// \\return Status\n@@ -172,10 +173,47 @@ class ARROW_EXPORT ArrayBuilder {\n   ARROW_DISALLOW_COPY_AND_ASSIGN(ArrayBuilder);\n };\n \n-class ARROW_EXPORT NullBuilder : public ArrayBuilder {\n+// An array build which supports partial finishes\n+//\n+// After a partial finish the state of the array builder\n+// is not reset and additional elements are appended to the\n+// previous state instead. Subsequent finishes will yield\n+// results which represent the elements added since the last\n+// finish, i.e. SliceBuffers or delta dictionaries\n+class ARROW_EXPORT PartiallyFinishableArrayBuilder : public ArrayBuilder {\n+ public:\n+  using ArrayBuilder::ArrayBuilder;\n+\n+  // Finishes the builder into out without resetting the builder if reset_builder\n+  // is false. Use with caution, it doesn't set elements_offset.\n+  virtual Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) = 0;\n+  Status FinishInternal(std::shared_ptr<ArrayData>* out) override {\n+    return FinishInternal(true, out);\n+  }\n+  Status Finish(std::shared_ptr<Array>* out) { return Finish(true, out); }\n+\n+  /// \\brief Return result of builder as a SliceArray object.\n+  ///\n+  /// \\param[in] reset_builder reset the state of the builder\n+  /// \\param[out] out the finalized Array object\n+  /// \\return Status\n+  Status Finish(bool reset_builder, std::shared_ptr<Array>* out) {\n+    std::shared_ptr<ArrayData> internal_data;\n+    RETURN_NOT_OK(FinishInternal(reset_builder, &internal_data));\n+    *out = MakeArray(internal_data);\n+    elements_offset_ = reset_builder ? 0 : length_;\n+    return Status::OK();\n+  }\n+  int64_t elements_offset() { return elements_offset_; }\n+\n+ protected:\n+  int64_t elements_offset_ = 0;\n+};\n+\n+class ARROW_EXPORT NullBuilder : public PartiallyFinishableArrayBuilder {\n  public:\n   explicit NullBuilder(MemoryPool* pool ARROW_MEMORY_POOL_DEFAULT)\n-      : ArrayBuilder(null(), pool) {}\n+      : PartiallyFinishableArrayBuilder(null(), pool) {}\n \n   Status AppendNull() {\n     ++null_count_;\n@@ -183,16 +221,17 @@ class ARROW_EXPORT NullBuilder : public ArrayBuilder {\n     return Status::OK();\n   }\n \n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n };\n \n template <typename Type>\n-class ARROW_EXPORT PrimitiveBuilder : public ArrayBuilder {\n+class ARROW_EXPORT PrimitiveBuilder : public PartiallyFinishableArrayBuilder {\n  public:\n   using value_type = typename Type::c_type;\n \n   explicit PrimitiveBuilder(const std::shared_ptr<DataType>& type, MemoryPool* pool)\n-      : ArrayBuilder(type, pool), data_(NULLPTR), raw_data_(NULLPTR) {}\n+      : PartiallyFinishableArrayBuilder(type, pool), data_(NULLPTR), raw_data_(NULLPTR) {}\n \n   using ArrayBuilder::Advance;\n \n@@ -241,7 +280,9 @@ class ARROW_EXPORT PrimitiveBuilder : public ArrayBuilder {\n   /// \\return Status\n   Status Append(const std::vector<value_type>& values);\n \n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n+\n   Status Init(int64_t capacity) override;\n \n   /// Increase the capacity of the builder to accommodate at least the indicated\n@@ -288,6 +329,15 @@ class ARROW_EXPORT NumericBuilder : public PrimitiveBuilder<T> {\n     raw_data_[length_++] = val;\n   }\n \n+  /// Append an array of scalar elements without capacity check\n+  ///\n+  /// Same warning as with UnsafeAppend with a single element\n+  void UnsafeAppend(const value_type* val, int64_t num_elements) {\n+    std::memcpy(raw_data_, val, num_elements);\n+    // length is updated here\n+    ArrayBuilder::UnsafeSetNotNull(num_elements);\n+  }\n+\n  protected:\n   using PrimitiveBuilder<T>::length_;\n   using PrimitiveBuilder<T>::null_bitmap_data_;\n@@ -317,7 +367,7 @@ using DoubleBuilder = NumericBuilder<DoubleType>;\n \n namespace internal {\n \n-class ARROW_EXPORT AdaptiveIntBuilderBase : public ArrayBuilder {\n+class ARROW_EXPORT AdaptiveIntBuilderBase : public PartiallyFinishableArrayBuilder {\n  public:\n   explicit AdaptiveIntBuilderBase(MemoryPool* pool);\n \n@@ -436,7 +486,8 @@ class ARROW_EXPORT AdaptiveUIntBuilder : public internal::AdaptiveIntBuilderBase\n   Status Append(const uint64_t* values, int64_t length,\n                 const uint8_t* valid_bytes = NULLPTR);\n \n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n \n  protected:\n   Status ExpandIntSize(uint8_t new_int_size);\n@@ -498,7 +549,8 @@ class ARROW_EXPORT AdaptiveIntBuilder : public internal::AdaptiveIntBuilderBase\n   Status Append(const int64_t* values, int64_t length,\n                 const uint8_t* valid_bytes = NULLPTR);\n \n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n \n  protected:\n   Status ExpandIntSize(uint8_t new_int_size);\n@@ -516,7 +568,7 @@ class ARROW_EXPORT AdaptiveIntBuilder : public internal::AdaptiveIntBuilderBase\n   Status ExpandIntSizeN();\n };\n \n-class ARROW_EXPORT BooleanBuilder : public ArrayBuilder {\n+class ARROW_EXPORT BooleanBuilder : public PartiallyFinishableArrayBuilder {\n  public:\n   explicit BooleanBuilder(MemoryPool* pool ARROW_MEMORY_POOL_DEFAULT);\n \n@@ -595,7 +647,8 @@ class ARROW_EXPORT BooleanBuilder : public ArrayBuilder {\n   /// \\return Status\n   Status Append(const std::vector<bool>& values);\n \n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n   Status Init(int64_t capacity) override;\n \n   /// Increase the capacity of the builder to accommodate at least the indicated\n@@ -666,7 +719,7 @@ class ARROW_EXPORT ListBuilder : public ArrayBuilder {\n \n /// \\class BinaryBuilder\n /// \\brief Builder class for variable-length binary data\n-class ARROW_EXPORT BinaryBuilder : public ArrayBuilder {\n+class ARROW_EXPORT BinaryBuilder : public PartiallyFinishableArrayBuilder {\n  public:\n   explicit BinaryBuilder(MemoryPool* pool ARROW_MEMORY_POOL_DEFAULT);\n \n@@ -689,7 +742,8 @@ class ARROW_EXPORT BinaryBuilder : public ArrayBuilder {\n   /// \\brief Ensures there is enough allocated capacity to append the indicated\n   /// number of bytes to the value data buffer without additional allocations\n   Status ReserveData(int64_t elements);\n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n \n   /// \\return size of values buffer so far\n   int64_t value_data_length() const { return value_data_builder_.length(); }\n@@ -706,7 +760,10 @@ class ARROW_EXPORT BinaryBuilder : public ArrayBuilder {\n   TypedBufferBuilder<uint8_t> value_data_builder_;\n \n   Status AppendNextOffset();\n+  Status AppendFinalOffset();\n   void Reset();\n+  // used to decide if we should write the next offset\n+  bool is_final_offset_written_ = false;\n };\n \n /// \\class StringBuilder\n@@ -725,7 +782,7 @@ class ARROW_EXPORT StringBuilder : public BinaryBuilder {\n // ----------------------------------------------------------------------\n // FixedSizeBinaryBuilder\n \n-class ARROW_EXPORT FixedSizeBinaryBuilder : public ArrayBuilder {\n+class ARROW_EXPORT FixedSizeBinaryBuilder : public PartiallyFinishableArrayBuilder {\n  public:\n   FixedSizeBinaryBuilder(const std::shared_ptr<DataType>& type,\n                          MemoryPool* pool ARROW_MEMORY_POOL_DEFAULT);\n@@ -753,7 +810,8 @@ class ARROW_EXPORT FixedSizeBinaryBuilder : public ArrayBuilder {\n \n   Status Init(int64_t elements) override;\n   Status Resize(int64_t capacity) override;\n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builders, std::shared_ptr<ArrayData>* out) override;\n \n   /// \\return size of values buffer so far\n   int64_t value_data_length() const { return byte_builder_.length(); }\n@@ -776,8 +834,6 @@ class ARROW_EXPORT Decimal128Builder : public FixedSizeBinaryBuilder {\n   using FixedSizeBinaryBuilder::Append;\n \n   Status Append(const Decimal128& val);\n-\n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n };\n \n using DecimalBuilder = Decimal128Builder;\n@@ -869,7 +925,7 @@ struct DictionaryScalar<FixedSizeBinaryType> {\n ///\n /// data\n template <typename T>\n-class ARROW_EXPORT DictionaryBuilder : public ArrayBuilder {\n+class ARROW_EXPORT DictionaryBuilder : public PartiallyFinishableArrayBuilder {\n  public:\n   using Scalar = typename internal::DictionaryScalar<T>::type;\n \n@@ -893,10 +949,11 @@ class ARROW_EXPORT DictionaryBuilder : public ArrayBuilder {\n \n   Status Init(int64_t elements) override;\n   Status Resize(int64_t capacity) override;\n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n \n   /// is the dictionary builder in the delta building mode\n-  bool is_building_delta() { return entry_id_offset_ > 0; }\n+  bool is_building_delta() { return dict_builder_.elements_offset() > 0; }\n \n  protected:\n   Status DoubleTableSize();\n@@ -912,11 +969,6 @@ class ARROW_EXPORT DictionaryBuilder : public ArrayBuilder {\n   /// Size of the table. Must be a power of 2.\n   int64_t hash_table_size_;\n \n-  // offset for the entry ids. Used to build delta dictionaries,\n-  // increased on every InternalFinish by the number of current entries\n-  // in the dictionary\n-  int64_t entry_id_offset_;\n-\n   // Store hash_table_size_ - 1, so that j & mod_bitmask_ is equivalent to j %\n   // hash_table_size_, but uses far fewer CPU cycles\n   int64_t mod_bitmask_;\n@@ -932,7 +984,7 @@ class ARROW_EXPORT DictionaryBuilder : public ArrayBuilder {\n };\n \n template <>\n-class ARROW_EXPORT DictionaryBuilder<NullType> : public ArrayBuilder {\n+class ARROW_EXPORT DictionaryBuilder<NullType> : public PartiallyFinishableArrayBuilder {\n  public:\n   ~DictionaryBuilder() override;\n \n@@ -947,7 +999,8 @@ class ARROW_EXPORT DictionaryBuilder<NullType> : public ArrayBuilder {\n \n   Status Init(int64_t elements) override;\n   Status Resize(int64_t capacity) override;\n-  Status FinishInternal(std::shared_ptr<ArrayData>* out) override;\n+  using PartiallyFinishableArrayBuilder::FinishInternal;\n+  Status FinishInternal(bool reset_builder, std::shared_ptr<ArrayData>* out) override;\n \n  protected:\n   AdaptiveIntBuilder values_builder_;\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-11T11:30:28.404+0000",
                    "updated": "2018-04-11T11:30:28.404+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13146580/comment/16510244",
                    "id": "16510244",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Resolved in PR\u00a0https://github.com/apache/arrow/pull/1769",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-06-12T21:38:55.700+0000",
                    "updated": "2018-06-12T21:38:55.700+0000"
                }
            ],
            "maxResults": 9,
            "total": 9,
            "startAt": 0
        },
        "customfield_12311820": "0|i3rjvb:",
        "customfield_12314139": null
    }
}