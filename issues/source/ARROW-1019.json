{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13071629",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629",
    "key": "ARROW-1019",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343858",
                "id": "12343858",
                "description": "",
                "name": "0.12.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-01-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "csv",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12544638",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12544638",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "outwardIssue": {
                    "id": "13188941",
                    "key": "ARROW-3409",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188941",
                    "fields": {
                        "summary": "[C++] Add streaming compression interfaces",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 10800,
            "total": 10800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 10800,
            "total": 10800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1019/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 23,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/154900",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou opened a new pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777\n \n \n   Implement `CompressedInputStream` and `CompressedOutputStream` C++ classes. Tested with gzip, brotli and zstd codecs.\r\n   \r\n   I initially intended to expose the functionality in Python, but `NativeFile` expects a `RandomAccessFile` in read mode (rather than a mere `InputStream`).\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-16T14:41:50.308+0000",
                    "updated": "2018-10-16T14:41:50.308+0000",
                    "started": "2018-10-16T14:41:50.308+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "154900",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155911",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#issuecomment-431023877\n \n \n   Will review this today\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T14:10:24.085+0000",
                    "updated": "2018-10-18T14:10:24.085+0000",
                    "started": "2018-10-18T14:10:24.085+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155911",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155971",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226360402\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.h\n ##########\n @@ -0,0 +1,113 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// Compressed stream implementations\n+\n+#ifndef ARROW_IO_COMPRESSED_H\n+#define ARROW_IO_COMPRESSED_H\n+\n+#include <memory>\n+#include <string>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class MemoryPool;\n+class Status;\n+\n+namespace util {\n+\n+class Codec;\n+\n+}  // namespace util\n+\n+namespace io {\n+\n+class ARROW_EXPORT CompressedOutputStream : public OutputStream {\n+ public:\n+  ~CompressedOutputStream() override;\n+\n+  /// \\brief Create a compressed output stream wrapping the given output stream.\n+  static Status Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                     std::shared_ptr<CompressedOutputStream>* out);\n+  static Status Make(MemoryPool* pool, util::Codec* codec,\n+                     std::shared_ptr<OutputStream> raw,\n+                     std::shared_ptr<CompressedOutputStream>* out);\n \n Review comment:\n   Maybe use `const std::shared_ptr<T>&` here and elsewhere in the public APIs for consistency\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.431+0000",
                    "updated": "2018-10-18T16:07:30.431+0000",
                    "started": "2018-10-18T16:07:30.430+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155971",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155972",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226344336\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                          &bytes_read, &bytes_written));\n+      compressed_pos_ += bytes_written;\n+\n+      if (bytes_read == 0) {\n+        // Not enough output, try to flush it and retry\n+        if (compressed_pos_ > 0) {\n+          RETURN_NOT_OK(FlushCompressed());\n+          output_len = compressed_->size() - compressed_pos_;\n+          output = compressed_->mutable_data() + compressed_pos_;\n+          RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written));\n+          compressed_pos_ += bytes_written;\n+        }\n+      }\n+      input += bytes_read;\n+      nbytes -= bytes_read;\n+      if (compressed_pos_ == compressed_->size()) {\n+        // Output buffer full, flush it\n+        RETURN_NOT_OK(FlushCompressed());\n+      }\n+      if (bytes_read == 0) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    while (true) {\n+      // Flush compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(\n+          compressor_->Flush(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FinalizeCompression() {\n+    while (true) {\n+      // Try to end compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->End(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        // Done\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    if (is_open_) {\n+      is_open_ = false;\n+      RETURN_NOT_OK(FinalizeCompression());\n+      return raw_->Close();\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+ private:\n+  // Write 64 KB compressed data at a time\n+  static const int64_t CHUNK_SIZE = 64 * 1024;\n \n Review comment:\n   `kChunkSize`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.432+0000",
                    "updated": "2018-10-18T16:07:30.432+0000",
                    "started": "2018-10-18T16:07:30.431+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155972",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155973",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226344284\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                          &bytes_read, &bytes_written));\n+      compressed_pos_ += bytes_written;\n+\n+      if (bytes_read == 0) {\n+        // Not enough output, try to flush it and retry\n+        if (compressed_pos_ > 0) {\n+          RETURN_NOT_OK(FlushCompressed());\n+          output_len = compressed_->size() - compressed_pos_;\n+          output = compressed_->mutable_data() + compressed_pos_;\n+          RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written));\n+          compressed_pos_ += bytes_written;\n+        }\n+      }\n+      input += bytes_read;\n+      nbytes -= bytes_read;\n+      if (compressed_pos_ == compressed_->size()) {\n+        // Output buffer full, flush it\n+        RETURN_NOT_OK(FlushCompressed());\n+      }\n+      if (bytes_read == 0) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    while (true) {\n+      // Flush compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(\n+          compressor_->Flush(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FinalizeCompression() {\n+    while (true) {\n+      // Try to end compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->End(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        // Done\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    if (is_open_) {\n+      is_open_ = false;\n+      RETURN_NOT_OK(FinalizeCompression());\n+      return raw_->Close();\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+ private:\n+  // Write 64 KB compressed data at a time\n+  static const int64_t CHUNK_SIZE = 64 * 1024;\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<OutputStream> raw_;\n+  Codec* codec_;\n+  bool is_open_;\n+  std::shared_ptr<Compressor> compressor_;\n+  std::shared_ptr<ResizableBuffer> compressed_;\n+  int64_t compressed_pos_;\n+\n+  mutable std::mutex lock_;\n+};\n+\n+Status CompressedOutputStream::Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                                    std::shared_ptr<CompressedOutputStream>* out) {\n+  return Make(default_memory_pool(), codec, raw, out);\n+}\n+\n+Status CompressedOutputStream::Make(MemoryPool* pool, util::Codec* codec,\n+                                    std::shared_ptr<OutputStream> raw,\n+                                    std::shared_ptr<CompressedOutputStream>* out) {\n+  std::shared_ptr<CompressedOutputStream> res(new CompressedOutputStream);\n+  res->impl_ = std::unique_ptr<Impl>(new Impl(pool, codec, std::move(raw)));\n+  RETURN_NOT_OK(res->impl_->Init());\n+  *out = res;\n+  return Status::OK();\n+}\n+\n+CompressedOutputStream::~CompressedOutputStream() {}\n+\n+Status CompressedOutputStream::Close() { return impl_->Close(); }\n+\n+Status CompressedOutputStream::Tell(int64_t* position) const {\n+  return impl_->Tell(position);\n+}\n+\n+Status CompressedOutputStream::Write(const void* data, int64_t nbytes) {\n+  return impl_->Write(data, nbytes);\n+}\n+\n+Status CompressedOutputStream::Flush() { return impl_->Flush(); }\n+\n+// ----------------------------------------------------------------------\n+// CompressedInputStream implementation\n+\n+class CompressedInputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<InputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeDecompressor(&decompressor_));\n+    return Status::OK();\n+  }\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+    if (is_open_) {\n+      is_open_ = false;\n+      return raw_->Close();\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  // Read compressed data if necessary\n+  Status EnsureCompressedData() {\n+    int64_t compressed_avail = compressed_ ? compressed_->size() - compressed_pos_ : 0;\n+    if (compressed_avail == 0) {\n+      // No compressed data available, read a full chunk\n+      RETURN_NOT_OK(raw_->Read(CHUNK_SIZE, &compressed_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status DecompressData() {\n+    int64_t decompress_size = DECOMPRESS_SIZE;\n+\n+    while (true) {\n+      RETURN_NOT_OK(AllocateResizableBuffer(pool_, decompress_size, &decompressed_));\n+      decompressed_pos_ = 0;\n+\n+      bool need_more_output;\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = compressed_->size() - compressed_pos_;\n+      const uint8_t* input = compressed_->data() + compressed_pos_;\n+      int64_t output_len = decompressed_->size();\n+      uint8_t* output = decompressed_->mutable_data();\n+\n+      RETURN_NOT_OK(decompressor_->Decompress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written,\n+                                              &need_more_output));\n+      compressed_pos_ += bytes_read;\n+      if (bytes_written > 0 || !need_more_output || input_len == 0) {\n+        RETURN_NOT_OK(decompressed_->Resize(bytes_written));\n+        break;\n+      }\n+      DCHECK_EQ(bytes_written, 0);\n+      // Need to enlarge output buffer\n+      decompress_size *= 2;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* out) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    *bytes_read = 0;\n+    auto out_data = reinterpret_cast<uint8_t*>(out);\n+\n+    while (nbytes > 0) {\n+      int64_t avail = decompressed_ ? (decompressed_->size() - decompressed_pos_) : 0;\n+      if (avail > 0) {\n+        // Pending decompressed data is available, use it\n+        avail = std::min(avail, nbytes);\n+        memcpy(out_data, decompressed_->data() + decompressed_pos_, avail);\n+        decompressed_pos_ += avail;\n+        out_data += avail;\n+        *bytes_read += avail;\n+        nbytes -= avail;\n+        if (decompressed_pos_ == decompressed_->size()) {\n+          // Decompressed data is exhausted, release buffer\n+          decompressed_.reset();\n+        }\n+        if (nbytes == 0) {\n+          // We're done\n+          break;\n+        }\n+      }\n+\n+      // At this point, no more decompressed data remains,\n+      // so we need to decompress more\n+      if (decompressor_->IsFinished()) {\n+        break;\n+      }\n+      // First try to read data from the decompressor\n+      if (compressed_) {\n+        RETURN_NOT_OK(DecompressData());\n+      }\n+      if (!decompressed_ || decompressed_->size() == 0) {\n+        // Got nothing, need to read more compressed data\n+        RETURN_NOT_OK(EnsureCompressedData());\n+        if (compressed_pos_ == compressed_->size()) {\n+          // Compressed stream unexpectedly exhausted\n+          return Status::IOError(\"Truncated compressed stream\");\n+        }\n+        RETURN_NOT_OK(DecompressData());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) {\n+    std::shared_ptr<ResizableBuffer> buf;\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, nbytes, &buf));\n+    int64_t bytes_read;\n+    RETURN_NOT_OK(Read(nbytes, &bytes_read, buf->mutable_data()));\n+    RETURN_NOT_OK(buf->Resize(bytes_read));\n+    *out = buf;\n+    return Status::OK();\n+  }\n+\n+  std::shared_ptr<InputStream> raw() const { return raw_; }\n+\n+ private:\n+  // Read 64 KB compressed data at a time\n+  static const int64_t CHUNK_SIZE = 64 * 1024;\n+  // Decompress 1 MB at a time\n+  static const int64_t DECOMPRESS_SIZE = 1024 * 1024;\n \n Review comment:\n   `kDecompressSize`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.436+0000",
                    "updated": "2018-10-18T16:07:30.436+0000",
                    "started": "2018-10-18T16:07:30.436+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155973",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155974",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226342211\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n \n Review comment:\n   I wonder if there might be a use for an intermediate abstraction \"CompressionBuffer\" that encapsulates some of this book-keeping that shows up in many places (unit tests and implementations). This could be passed into the stream compressor functions instead of raw pointers, allowing the compressor to request that the buffer be enlarged, etc. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.443+0000",
                    "updated": "2018-10-18T16:07:30.443+0000",
                    "started": "2018-10-18T16:07:30.442+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155974",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155975",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226339963\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n \n Review comment:\n   Could do `const std::shared_ptr<T>&` to possibly avoid extra copy\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.474+0000",
                    "updated": "2018-10-18T16:07:30.474+0000",
                    "started": "2018-10-18T16:07:30.473+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155975",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155976",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226339749\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n \n Review comment:\n   Include ordering https://google.github.io/styleguide/cppguide.html#Names_and_Order_of_Includes\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.484+0000",
                    "updated": "2018-10-18T16:07:30.484+0000",
                    "started": "2018-10-18T16:07:30.484+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155976",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155977",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226343770\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                          &bytes_read, &bytes_written));\n+      compressed_pos_ += bytes_written;\n+\n+      if (bytes_read == 0) {\n+        // Not enough output, try to flush it and retry\n+        if (compressed_pos_ > 0) {\n+          RETURN_NOT_OK(FlushCompressed());\n+          output_len = compressed_->size() - compressed_pos_;\n+          output = compressed_->mutable_data() + compressed_pos_;\n+          RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written));\n+          compressed_pos_ += bytes_written;\n+        }\n+      }\n+      input += bytes_read;\n+      nbytes -= bytes_read;\n+      if (compressed_pos_ == compressed_->size()) {\n+        // Output buffer full, flush it\n+        RETURN_NOT_OK(FlushCompressed());\n+      }\n+      if (bytes_read == 0) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    while (true) {\n+      // Flush compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(\n+          compressor_->Flush(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FinalizeCompression() {\n+    while (true) {\n+      // Try to end compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->End(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        // Done\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    if (is_open_) {\n+      is_open_ = false;\n+      RETURN_NOT_OK(FinalizeCompression());\n+      return raw_->Close();\n \n Review comment:\n   Do we definitely want to close the passed output stream? I'm trying to think if there are scenarios where we would not want to\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.487+0000",
                    "updated": "2018-10-18T16:07:30.487+0000",
                    "started": "2018-10-18T16:07:30.486+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155977",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155978",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226344057\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                          &bytes_read, &bytes_written));\n+      compressed_pos_ += bytes_written;\n+\n+      if (bytes_read == 0) {\n+        // Not enough output, try to flush it and retry\n+        if (compressed_pos_ > 0) {\n+          RETURN_NOT_OK(FlushCompressed());\n+          output_len = compressed_->size() - compressed_pos_;\n+          output = compressed_->mutable_data() + compressed_pos_;\n+          RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written));\n+          compressed_pos_ += bytes_written;\n+        }\n+      }\n+      input += bytes_read;\n+      nbytes -= bytes_read;\n+      if (compressed_pos_ == compressed_->size()) {\n+        // Output buffer full, flush it\n+        RETURN_NOT_OK(FlushCompressed());\n+      }\n+      if (bytes_read == 0) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    while (true) {\n+      // Flush compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(\n+          compressor_->Flush(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FinalizeCompression() {\n+    while (true) {\n+      // Try to end compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->End(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        // Done\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    if (is_open_) {\n+      is_open_ = false;\n+      RETURN_NOT_OK(FinalizeCompression());\n+      return raw_->Close();\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+ private:\n+  // Write 64 KB compressed data at a time\n+  static const int64_t CHUNK_SIZE = 64 * 1024;\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<OutputStream> raw_;\n+  Codec* codec_;\n+  bool is_open_;\n+  std::shared_ptr<Compressor> compressor_;\n+  std::shared_ptr<ResizableBuffer> compressed_;\n+  int64_t compressed_pos_;\n+\n+  mutable std::mutex lock_;\n+};\n+\n+Status CompressedOutputStream::Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                                    std::shared_ptr<CompressedOutputStream>* out) {\n+  return Make(default_memory_pool(), codec, raw, out);\n+}\n+\n+Status CompressedOutputStream::Make(MemoryPool* pool, util::Codec* codec,\n+                                    std::shared_ptr<OutputStream> raw,\n+                                    std::shared_ptr<CompressedOutputStream>* out) {\n+  std::shared_ptr<CompressedOutputStream> res(new CompressedOutputStream);\n+  res->impl_ = std::unique_ptr<Impl>(new Impl(pool, codec, std::move(raw)));\n+  RETURN_NOT_OK(res->impl_->Init());\n+  *out = res;\n+  return Status::OK();\n+}\n+\n+CompressedOutputStream::~CompressedOutputStream() {}\n+\n+Status CompressedOutputStream::Close() { return impl_->Close(); }\n+\n+Status CompressedOutputStream::Tell(int64_t* position) const {\n+  return impl_->Tell(position);\n+}\n+\n+Status CompressedOutputStream::Write(const void* data, int64_t nbytes) {\n+  return impl_->Write(data, nbytes);\n+}\n+\n+Status CompressedOutputStream::Flush() { return impl_->Flush(); }\n+\n+// ----------------------------------------------------------------------\n+// CompressedInputStream implementation\n+\n+class CompressedInputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<InputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeDecompressor(&decompressor_));\n+    return Status::OK();\n+  }\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+    if (is_open_) {\n+      is_open_ = false;\n+      return raw_->Close();\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  // Read compressed data if necessary\n+  Status EnsureCompressedData() {\n+    int64_t compressed_avail = compressed_ ? compressed_->size() - compressed_pos_ : 0;\n+    if (compressed_avail == 0) {\n+      // No compressed data available, read a full chunk\n+      RETURN_NOT_OK(raw_->Read(CHUNK_SIZE, &compressed_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status DecompressData() {\n+    int64_t decompress_size = DECOMPRESS_SIZE;\n+\n+    while (true) {\n+      RETURN_NOT_OK(AllocateResizableBuffer(pool_, decompress_size, &decompressed_));\n+      decompressed_pos_ = 0;\n+\n+      bool need_more_output;\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = compressed_->size() - compressed_pos_;\n+      const uint8_t* input = compressed_->data() + compressed_pos_;\n \n Review comment:\n   Same question here re: output buffer bookkeeping\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.506+0000",
                    "updated": "2018-10-18T16:07:30.506+0000",
                    "started": "2018-10-18T16:07:30.506+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155978",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155979",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226344239\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                          &bytes_read, &bytes_written));\n+      compressed_pos_ += bytes_written;\n+\n+      if (bytes_read == 0) {\n+        // Not enough output, try to flush it and retry\n+        if (compressed_pos_ > 0) {\n+          RETURN_NOT_OK(FlushCompressed());\n+          output_len = compressed_->size() - compressed_pos_;\n+          output = compressed_->mutable_data() + compressed_pos_;\n+          RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written));\n+          compressed_pos_ += bytes_written;\n+        }\n+      }\n+      input += bytes_read;\n+      nbytes -= bytes_read;\n+      if (compressed_pos_ == compressed_->size()) {\n+        // Output buffer full, flush it\n+        RETURN_NOT_OK(FlushCompressed());\n+      }\n+      if (bytes_read == 0) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    while (true) {\n+      // Flush compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(\n+          compressor_->Flush(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FinalizeCompression() {\n+    while (true) {\n+      // Try to end compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->End(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        // Done\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    if (is_open_) {\n+      is_open_ = false;\n+      RETURN_NOT_OK(FinalizeCompression());\n+      return raw_->Close();\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+ private:\n+  // Write 64 KB compressed data at a time\n+  static const int64_t CHUNK_SIZE = 64 * 1024;\n+\n+  MemoryPool* pool_;\n+  std::shared_ptr<OutputStream> raw_;\n+  Codec* codec_;\n+  bool is_open_;\n+  std::shared_ptr<Compressor> compressor_;\n+  std::shared_ptr<ResizableBuffer> compressed_;\n+  int64_t compressed_pos_;\n+\n+  mutable std::mutex lock_;\n+};\n+\n+Status CompressedOutputStream::Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                                    std::shared_ptr<CompressedOutputStream>* out) {\n+  return Make(default_memory_pool(), codec, raw, out);\n+}\n+\n+Status CompressedOutputStream::Make(MemoryPool* pool, util::Codec* codec,\n+                                    std::shared_ptr<OutputStream> raw,\n+                                    std::shared_ptr<CompressedOutputStream>* out) {\n+  std::shared_ptr<CompressedOutputStream> res(new CompressedOutputStream);\n+  res->impl_ = std::unique_ptr<Impl>(new Impl(pool, codec, std::move(raw)));\n+  RETURN_NOT_OK(res->impl_->Init());\n+  *out = res;\n+  return Status::OK();\n+}\n+\n+CompressedOutputStream::~CompressedOutputStream() {}\n+\n+Status CompressedOutputStream::Close() { return impl_->Close(); }\n+\n+Status CompressedOutputStream::Tell(int64_t* position) const {\n+  return impl_->Tell(position);\n+}\n+\n+Status CompressedOutputStream::Write(const void* data, int64_t nbytes) {\n+  return impl_->Write(data, nbytes);\n+}\n+\n+Status CompressedOutputStream::Flush() { return impl_->Flush(); }\n+\n+// ----------------------------------------------------------------------\n+// CompressedInputStream implementation\n+\n+class CompressedInputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<InputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeDecompressor(&decompressor_));\n+    return Status::OK();\n+  }\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+    if (is_open_) {\n+      is_open_ = false;\n+      return raw_->Close();\n+    } else {\n+      return Status::OK();\n+    }\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  // Read compressed data if necessary\n+  Status EnsureCompressedData() {\n+    int64_t compressed_avail = compressed_ ? compressed_->size() - compressed_pos_ : 0;\n+    if (compressed_avail == 0) {\n+      // No compressed data available, read a full chunk\n+      RETURN_NOT_OK(raw_->Read(CHUNK_SIZE, &compressed_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status DecompressData() {\n+    int64_t decompress_size = DECOMPRESS_SIZE;\n+\n+    while (true) {\n+      RETURN_NOT_OK(AllocateResizableBuffer(pool_, decompress_size, &decompressed_));\n+      decompressed_pos_ = 0;\n+\n+      bool need_more_output;\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = compressed_->size() - compressed_pos_;\n+      const uint8_t* input = compressed_->data() + compressed_pos_;\n+      int64_t output_len = decompressed_->size();\n+      uint8_t* output = decompressed_->mutable_data();\n+\n+      RETURN_NOT_OK(decompressor_->Decompress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written,\n+                                              &need_more_output));\n+      compressed_pos_ += bytes_read;\n+      if (bytes_written > 0 || !need_more_output || input_len == 0) {\n+        RETURN_NOT_OK(decompressed_->Resize(bytes_written));\n+        break;\n+      }\n+      DCHECK_EQ(bytes_written, 0);\n+      // Need to enlarge output buffer\n+      decompress_size *= 2;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Read(int64_t nbytes, int64_t* bytes_read, void* out) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    *bytes_read = 0;\n+    auto out_data = reinterpret_cast<uint8_t*>(out);\n+\n+    while (nbytes > 0) {\n+      int64_t avail = decompressed_ ? (decompressed_->size() - decompressed_pos_) : 0;\n+      if (avail > 0) {\n+        // Pending decompressed data is available, use it\n+        avail = std::min(avail, nbytes);\n+        memcpy(out_data, decompressed_->data() + decompressed_pos_, avail);\n+        decompressed_pos_ += avail;\n+        out_data += avail;\n+        *bytes_read += avail;\n+        nbytes -= avail;\n+        if (decompressed_pos_ == decompressed_->size()) {\n+          // Decompressed data is exhausted, release buffer\n+          decompressed_.reset();\n+        }\n+        if (nbytes == 0) {\n+          // We're done\n+          break;\n+        }\n+      }\n+\n+      // At this point, no more decompressed data remains,\n+      // so we need to decompress more\n+      if (decompressor_->IsFinished()) {\n+        break;\n+      }\n+      // First try to read data from the decompressor\n+      if (compressed_) {\n+        RETURN_NOT_OK(DecompressData());\n+      }\n+      if (!decompressed_ || decompressed_->size() == 0) {\n+        // Got nothing, need to read more compressed data\n+        RETURN_NOT_OK(EnsureCompressedData());\n+        if (compressed_pos_ == compressed_->size()) {\n+          // Compressed stream unexpectedly exhausted\n+          return Status::IOError(\"Truncated compressed stream\");\n+        }\n+        RETURN_NOT_OK(DecompressData());\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Read(int64_t nbytes, std::shared_ptr<Buffer>* out) {\n+    std::shared_ptr<ResizableBuffer> buf;\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, nbytes, &buf));\n+    int64_t bytes_read;\n+    RETURN_NOT_OK(Read(nbytes, &bytes_read, buf->mutable_data()));\n+    RETURN_NOT_OK(buf->Resize(bytes_read));\n+    *out = buf;\n+    return Status::OK();\n+  }\n+\n+  std::shared_ptr<InputStream> raw() const { return raw_; }\n+\n+ private:\n+  // Read 64 KB compressed data at a time\n+  static const int64_t CHUNK_SIZE = 64 * 1024;\n \n Review comment:\n   `kChunkSize`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.507+0000",
                    "updated": "2018-10-18T16:07:30.507+0000",
                    "started": "2018-10-18T16:07:30.507+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155979",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155980",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226369093\n \n \n\n ##########\n File path: cpp/src/arrow/io/io-compressed-test.cc\n ##########\n @@ -0,0 +1,243 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <memory>\n+#include <random>\n+#include <string>\n+#include <vector>\n+\n+#include <gtest/gtest.h>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/io/memory.h\"\n+#include \"arrow/io/test-common.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/test-util.h\"\n+#include \"arrow/util/compression.h\"\n+\n+namespace arrow {\n+namespace io {\n+\n+using ::arrow::util::Codec;\n+\n+#ifdef ARROW_VALGRIND\n+// Avoid slowing down tests too much with Valgrind\n+static constexpr int64_t RANDOM_DATA_SIZE = 50 * 1024;\n+static constexpr int64_t COMPRESSIBLE_DATA_SIZE = 120 * 1024;\n+#else\n+// The data should be large enough to exercise internal buffers\n+static constexpr int64_t RANDOM_DATA_SIZE = 3 * 1024 * 1024;\n+static constexpr int64_t COMPRESSIBLE_DATA_SIZE = 8 * 1024 * 1024;\n+#endif\n+\n+std::vector<uint8_t> MakeRandomData(int data_size) {\n+  std::vector<uint8_t> data(data_size);\n+  random_bytes(data_size, 1234, data.data());\n+  return data;\n+}\n+\n+std::vector<uint8_t> MakeCompressibleData(int data_size) {\n+  std::string base_data =\n+      \"Apache Arrow is a cross-language development platform for in-memory data\";\n+  int nrepeats = static_cast<int>(1 + data_size / base_data.size());\n+\n+  std::vector<uint8_t> data(base_data.size() * nrepeats);\n+  for (int i = 0; i < nrepeats; ++i) {\n+    std::memcpy(data.data() + i * base_data.size(), base_data.data(), base_data.size());\n+  }\n+  data.resize(data_size);\n+  return data;\n+}\n+\n+std::shared_ptr<Buffer> CompressDataOneShot(Codec* codec,\n+                                            const std::vector<uint8_t>& data) {\n+  int64_t max_compressed_len, compressed_len;\n+  max_compressed_len = codec->MaxCompressedLen(data.size(), data.data());\n+  std::shared_ptr<ResizableBuffer> compressed;\n+  ABORT_NOT_OK(AllocateResizableBuffer(max_compressed_len, &compressed));\n+  ABORT_NOT_OK(codec->Compress(data.size(), data.data(), max_compressed_len,\n+                               compressed->mutable_data(), &compressed_len));\n+  ABORT_NOT_OK(compressed->Resize(compressed_len));\n+  return compressed;\n+}\n+\n+Status RunCompressedInputStream(Codec* codec, std::shared_ptr<Buffer> compressed,\n+                                std::vector<uint8_t>* out) {\n+  // Create compressed input stream\n+  auto buffer_reader = std::make_shared<BufferReader>(compressed);\n+  std::shared_ptr<CompressedInputStream> stream;\n+  RETURN_NOT_OK(CompressedInputStream::Make(codec, buffer_reader, &stream));\n+\n+  std::vector<uint8_t> decompressed;\n+  int64_t decompressed_size = 0;\n+  const int64_t chunk_size = 1111;\n+  while (true) {\n+    std::shared_ptr<Buffer> buf;\n+    RETURN_NOT_OK(stream->Read(chunk_size, &buf));\n+    if (buf->size() == 0) {\n+      // EOF\n+      break;\n+    }\n+    decompressed.resize(decompressed_size + buf->size());\n+    memcpy(decompressed.data() + decompressed_size, buf->data(), buf->size());\n+    decompressed_size += buf->size();\n+  }\n+  *out = std::move(decompressed);\n+  return Status::OK();\n+}\n+\n+void CheckCompressedInputStream(Codec* codec, const std::vector<uint8_t>& data) {\n+  // Create compressed data\n+  auto compressed = CompressDataOneShot(codec, data);\n+\n+  std::vector<uint8_t> decompressed;\n+  ASSERT_OK(RunCompressedInputStream(codec, compressed, &decompressed));\n+\n+  ASSERT_EQ(decompressed.size(), data.size());\n+  ASSERT_EQ(decompressed, data);\n+}\n+\n+void CheckCompressedOutputStream(Codec* codec, const std::vector<uint8_t>& data,\n+                                 bool do_flush) {\n+  // Create compressed output stream\n+  std::shared_ptr<BufferOutputStream> buffer_writer;\n+  ASSERT_OK(BufferOutputStream::Create(1024, default_memory_pool(), &buffer_writer));\n+  std::shared_ptr<CompressedOutputStream> stream;\n+  ASSERT_OK(CompressedOutputStream::Make(codec, buffer_writer, &stream));\n+\n+  const uint8_t* input = data.data();\n+  int64_t input_len = data.size();\n+  const int64_t chunk_size = 1111;\n+  while (input_len > 0) {\n+    int64_t nbytes = std::min(chunk_size, input_len);\n+    ASSERT_OK(stream->Write(input, nbytes));\n+    input += nbytes;\n+    input_len -= nbytes;\n+    if (do_flush) {\n+      ASSERT_OK(stream->Flush());\n+    }\n+  }\n+  ASSERT_OK(stream->Close());\n+\n+  // Get compressed data and decompress it\n+  std::shared_ptr<Buffer> compressed;\n+  ASSERT_OK(buffer_writer->Finish(&compressed));\n+  std::vector<uint8_t> decompressed(data.size());\n+  ASSERT_OK(codec->Decompress(compressed->size(), compressed->data(), decompressed.size(),\n+                              decompressed.data()));\n+  ASSERT_EQ(decompressed, data);\n+}\n+\n+class CompressedInputStreamTest : public ::testing::TestWithParam<Compression::type> {\n+ protected:\n+  Compression::type GetCompression() { return GetParam(); }\n+\n+  std::unique_ptr<Codec> MakeCodec() {\n+    std::unique_ptr<Codec> codec;\n+    ABORT_NOT_OK(Codec::Create(GetCompression(), &codec));\n+    return codec;\n+  }\n+};\n+\n+TEST_P(CompressedInputStreamTest, CompressibleData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeCompressibleData(COMPRESSIBLE_DATA_SIZE);\n+\n+  CheckCompressedInputStream(codec.get(), data);\n+}\n+\n+TEST_P(CompressedInputStreamTest, RandomData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeRandomData(RANDOM_DATA_SIZE);\n+\n+  CheckCompressedInputStream(codec.get(), data);\n+}\n+\n+TEST_P(CompressedInputStreamTest, TruncatedData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeRandomData(10000);\n+  auto compressed = CompressDataOneShot(codec.get(), data);\n+  auto truncated = SliceBuffer(compressed, 0, compressed->size() - 3);\n+\n+  std::vector<uint8_t> decompressed;\n+  ASSERT_RAISES(IOError, RunCompressedInputStream(codec.get(), truncated, &decompressed));\n+}\n+\n+TEST_P(CompressedInputStreamTest, InvalidData) {\n+  auto codec = MakeCodec();\n+  auto compressed_data = MakeRandomData(10000);\n+\n+  auto buffer_reader = std::make_shared<BufferReader>(Buffer::Wrap(compressed_data));\n+  std::shared_ptr<CompressedInputStream> stream;\n+  ASSERT_OK(CompressedInputStream::Make(codec.get(), buffer_reader, &stream));\n+  std::shared_ptr<Buffer> out_buf;\n+  ASSERT_RAISES(IOError, stream->Read(1024, &out_buf));\n+}\n+\n+// NOTE: Snappy doesn't support streaming decompression\n \n Review comment:\n   We could (should?) define a framed format of our own devising\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.543+0000",
                    "updated": "2018-10-18T16:07:30.543+0000",
                    "started": "2018-10-18T16:07:30.541+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155980",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155981",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226360884\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.h\n ##########\n @@ -0,0 +1,113 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// Compressed stream implementations\n+\n+#ifndef ARROW_IO_COMPRESSED_H\n+#define ARROW_IO_COMPRESSED_H\n+\n+#include <memory>\n+#include <string>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class MemoryPool;\n+class Status;\n+\n+namespace util {\n+\n+class Codec;\n+\n+}  // namespace util\n+\n+namespace io {\n+\n+class ARROW_EXPORT CompressedOutputStream : public OutputStream {\n+ public:\n+  ~CompressedOutputStream() override;\n+\n+  /// \\brief Create a compressed output stream wrapping the given output stream.\n+  static Status Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                     std::shared_ptr<CompressedOutputStream>* out);\n+  static Status Make(MemoryPool* pool, util::Codec* codec,\n+                     std::shared_ptr<OutputStream> raw,\n+                     std::shared_ptr<CompressedOutputStream>* out);\n+\n+  // OutputStream interface\n+\n+  /// \\brief Close the compressed output stream.  This implicitly closes the\n+  /// underlying raw output stream.\n+  Status Close() override;\n+\n+  Status Tell(int64_t* position) const override;\n+\n+  Status Write(const void* data, int64_t nbytes) override;\n+  Status Flush() override;\n+\n+  /// \\brief Return the underlying raw output stream.\n+  std::shared_ptr<OutputStream> raw() const;\n+\n+ private:\n+  ARROW_DISALLOW_COPY_AND_ASSIGN(CompressedOutputStream);\n+\n+  CompressedOutputStream() = default;\n+\n+  class ARROW_NO_EXPORT Impl;\n+  std::unique_ptr<Impl> impl_;\n+};\n+\n+class ARROW_EXPORT CompressedInputStream : public InputStream {\n+ public:\n+  ~CompressedInputStream() override;\n+\n+  /// \\brief Create a compressed input stream wrapping the given input stream.\n+  static Status Make(util::Codec* codec, std::shared_ptr<InputStream> raw,\n+                     std::shared_ptr<CompressedInputStream>* out);\n+  static Status Make(MemoryPool* pool, util::Codec* codec,\n+                     std::shared_ptr<InputStream> raw,\n+                     std::shared_ptr<CompressedInputStream>* out);\n \n Review comment:\n   Same here\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.577+0000",
                    "updated": "2018-10-18T16:07:30.577+0000",
                    "started": "2018-10-18T16:07:30.576+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155981",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/155982",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226360536\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.h\n ##########\n @@ -0,0 +1,113 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// Compressed stream implementations\n+\n+#ifndef ARROW_IO_COMPRESSED_H\n+#define ARROW_IO_COMPRESSED_H\n+\n+#include <memory>\n+#include <string>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class MemoryPool;\n+class Status;\n+\n+namespace util {\n+\n+class Codec;\n+\n+}  // namespace util\n+\n+namespace io {\n+\n+class ARROW_EXPORT CompressedOutputStream : public OutputStream {\n+ public:\n+  ~CompressedOutputStream() override;\n+\n+  /// \\brief Create a compressed output stream wrapping the given output stream.\n+  static Status Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                     std::shared_ptr<CompressedOutputStream>* out);\n+  static Status Make(MemoryPool* pool, util::Codec* codec,\n \n Review comment:\n   Can `codec` be const? Also, can it by `const Codec&`?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:07:30.733+0000",
                    "updated": "2018-10-18T16:07:30.733+0000",
                    "started": "2018-10-18T16:07:30.733+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "155982",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/156003",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226374799\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n \n Review comment:\n   I don't know how it would look like, though.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:22:29.249+0000",
                    "updated": "2018-10-18T16:22:29.249+0000",
                    "started": "2018-10-18T16:22:29.248+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "156003",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/156004",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226375214\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.cc\n ##########\n @@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/memory_pool.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/compression.h\"\n+#include \"arrow/util/logging.h\"\n+\n+#include <algorithm>\n+#include <cstring>\n+#include <memory>\n+#include <mutex>\n+#include <string>\n+#include <utility>\n+\n+namespace arrow {\n+\n+using util::Codec;\n+using util::Compressor;\n+using util::Decompressor;\n+\n+namespace io {\n+\n+// ----------------------------------------------------------------------\n+// CompressedOutputStream implementation\n+\n+class CompressedOutputStream::Impl {\n+ public:\n+  Impl(MemoryPool* pool, Codec* codec, std::shared_ptr<OutputStream> raw)\n+      : pool_(pool), raw_(raw), codec_(codec), is_open_(true) {}\n+\n+  ~Impl() { DCHECK(Close().ok()); }\n+\n+  Status Init() {\n+    RETURN_NOT_OK(codec_->MakeCompressor(&compressor_));\n+    RETURN_NOT_OK(AllocateResizableBuffer(pool_, CHUNK_SIZE, &compressed_));\n+    compressed_pos_ = 0;\n+    return Status::OK();\n+  }\n+\n+  Status Tell(int64_t* position) const {\n+    return Status::NotImplemented(\"Cannot tell() a compressed stream\");\n+  }\n+\n+  std::shared_ptr<OutputStream> raw() const { return raw_; }\n+\n+  Status FlushCompressed() {\n+    if (compressed_pos_ > 0) {\n+      RETURN_NOT_OK(raw_->Write(compressed_->data(), compressed_pos_));\n+      compressed_pos_ = 0;\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Write(const void* data, int64_t nbytes) {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    auto input = reinterpret_cast<const uint8_t*>(data);\n+    while (nbytes > 0) {\n+      int64_t bytes_read, bytes_written;\n+      int64_t input_len = nbytes;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                          &bytes_read, &bytes_written));\n+      compressed_pos_ += bytes_written;\n+\n+      if (bytes_read == 0) {\n+        // Not enough output, try to flush it and retry\n+        if (compressed_pos_ > 0) {\n+          RETURN_NOT_OK(FlushCompressed());\n+          output_len = compressed_->size() - compressed_pos_;\n+          output = compressed_->mutable_data() + compressed_pos_;\n+          RETURN_NOT_OK(compressor_->Compress(input_len, input, output_len, output,\n+                                              &bytes_read, &bytes_written));\n+          compressed_pos_ += bytes_written;\n+        }\n+      }\n+      input += bytes_read;\n+      nbytes -= bytes_read;\n+      if (compressed_pos_ == compressed_->size()) {\n+        // Output buffer full, flush it\n+        RETURN_NOT_OK(FlushCompressed());\n+      }\n+      if (bytes_read == 0) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Flush() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    while (true) {\n+      // Flush compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(\n+          compressor_->Flush(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status FinalizeCompression() {\n+    while (true) {\n+      // Try to end compressor\n+      int64_t bytes_written;\n+      bool should_retry;\n+      int64_t output_len = compressed_->size() - compressed_pos_;\n+      uint8_t* output = compressed_->mutable_data() + compressed_pos_;\n+      RETURN_NOT_OK(compressor_->End(output_len, output, &bytes_written, &should_retry));\n+      compressed_pos_ += bytes_written;\n+\n+      // Flush compressed output\n+      RETURN_NOT_OK(FlushCompressed());\n+\n+      if (should_retry) {\n+        // Need to enlarge output buffer\n+        RETURN_NOT_OK(compressed_->Resize(compressed_->size() * 2));\n+      } else {\n+        // Done\n+        break;\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Close() {\n+    std::lock_guard<std::mutex> guard(lock_);\n+\n+    if (is_open_) {\n+      is_open_ = false;\n+      RETURN_NOT_OK(FinalizeCompression());\n+      return raw_->Close();\n \n Review comment:\n   I think by default, yes. We could add a constructor argument if we need to keep the underlying file alive in some cases.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:23:37.018+0000",
                    "updated": "2018-10-18T16:23:37.018+0000",
                    "started": "2018-10-18T16:23:37.018+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "156004",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/156008",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226376565\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.h\n ##########\n @@ -0,0 +1,113 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// Compressed stream implementations\n+\n+#ifndef ARROW_IO_COMPRESSED_H\n+#define ARROW_IO_COMPRESSED_H\n+\n+#include <memory>\n+#include <string>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class MemoryPool;\n+class Status;\n+\n+namespace util {\n+\n+class Codec;\n+\n+}  // namespace util\n+\n+namespace io {\n+\n+class ARROW_EXPORT CompressedOutputStream : public OutputStream {\n+ public:\n+  ~CompressedOutputStream() override;\n+\n+  /// \\brief Create a compressed output stream wrapping the given output stream.\n+  static Status Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                     std::shared_ptr<CompressedOutputStream>* out);\n+  static Status Make(MemoryPool* pool, util::Codec* codec,\n \n Review comment:\n   Currently, `Codec::MakeCompressor` and `Codec::MakeDecompressor` are non-const methods. IMHO it doesn't mean much to have a const Codec.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:27:27.591+0000",
                    "updated": "2018-10-18T16:27:27.591+0000",
                    "started": "2018-10-18T16:27:27.591+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "156008",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/156009",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226376987\n \n \n\n ##########\n File path: cpp/src/arrow/io/io-compressed-test.cc\n ##########\n @@ -0,0 +1,243 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <memory>\n+#include <random>\n+#include <string>\n+#include <vector>\n+\n+#include <gtest/gtest.h>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/io/memory.h\"\n+#include \"arrow/io/test-common.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/test-util.h\"\n+#include \"arrow/util/compression.h\"\n+\n+namespace arrow {\n+namespace io {\n+\n+using ::arrow::util::Codec;\n+\n+#ifdef ARROW_VALGRIND\n+// Avoid slowing down tests too much with Valgrind\n+static constexpr int64_t RANDOM_DATA_SIZE = 50 * 1024;\n+static constexpr int64_t COMPRESSIBLE_DATA_SIZE = 120 * 1024;\n+#else\n+// The data should be large enough to exercise internal buffers\n+static constexpr int64_t RANDOM_DATA_SIZE = 3 * 1024 * 1024;\n+static constexpr int64_t COMPRESSIBLE_DATA_SIZE = 8 * 1024 * 1024;\n+#endif\n+\n+std::vector<uint8_t> MakeRandomData(int data_size) {\n+  std::vector<uint8_t> data(data_size);\n+  random_bytes(data_size, 1234, data.data());\n+  return data;\n+}\n+\n+std::vector<uint8_t> MakeCompressibleData(int data_size) {\n+  std::string base_data =\n+      \"Apache Arrow is a cross-language development platform for in-memory data\";\n+  int nrepeats = static_cast<int>(1 + data_size / base_data.size());\n+\n+  std::vector<uint8_t> data(base_data.size() * nrepeats);\n+  for (int i = 0; i < nrepeats; ++i) {\n+    std::memcpy(data.data() + i * base_data.size(), base_data.data(), base_data.size());\n+  }\n+  data.resize(data_size);\n+  return data;\n+}\n+\n+std::shared_ptr<Buffer> CompressDataOneShot(Codec* codec,\n+                                            const std::vector<uint8_t>& data) {\n+  int64_t max_compressed_len, compressed_len;\n+  max_compressed_len = codec->MaxCompressedLen(data.size(), data.data());\n+  std::shared_ptr<ResizableBuffer> compressed;\n+  ABORT_NOT_OK(AllocateResizableBuffer(max_compressed_len, &compressed));\n+  ABORT_NOT_OK(codec->Compress(data.size(), data.data(), max_compressed_len,\n+                               compressed->mutable_data(), &compressed_len));\n+  ABORT_NOT_OK(compressed->Resize(compressed_len));\n+  return compressed;\n+}\n+\n+Status RunCompressedInputStream(Codec* codec, std::shared_ptr<Buffer> compressed,\n+                                std::vector<uint8_t>* out) {\n+  // Create compressed input stream\n+  auto buffer_reader = std::make_shared<BufferReader>(compressed);\n+  std::shared_ptr<CompressedInputStream> stream;\n+  RETURN_NOT_OK(CompressedInputStream::Make(codec, buffer_reader, &stream));\n+\n+  std::vector<uint8_t> decompressed;\n+  int64_t decompressed_size = 0;\n+  const int64_t chunk_size = 1111;\n+  while (true) {\n+    std::shared_ptr<Buffer> buf;\n+    RETURN_NOT_OK(stream->Read(chunk_size, &buf));\n+    if (buf->size() == 0) {\n+      // EOF\n+      break;\n+    }\n+    decompressed.resize(decompressed_size + buf->size());\n+    memcpy(decompressed.data() + decompressed_size, buf->data(), buf->size());\n+    decompressed_size += buf->size();\n+  }\n+  *out = std::move(decompressed);\n+  return Status::OK();\n+}\n+\n+void CheckCompressedInputStream(Codec* codec, const std::vector<uint8_t>& data) {\n+  // Create compressed data\n+  auto compressed = CompressDataOneShot(codec, data);\n+\n+  std::vector<uint8_t> decompressed;\n+  ASSERT_OK(RunCompressedInputStream(codec, compressed, &decompressed));\n+\n+  ASSERT_EQ(decompressed.size(), data.size());\n+  ASSERT_EQ(decompressed, data);\n+}\n+\n+void CheckCompressedOutputStream(Codec* codec, const std::vector<uint8_t>& data,\n+                                 bool do_flush) {\n+  // Create compressed output stream\n+  std::shared_ptr<BufferOutputStream> buffer_writer;\n+  ASSERT_OK(BufferOutputStream::Create(1024, default_memory_pool(), &buffer_writer));\n+  std::shared_ptr<CompressedOutputStream> stream;\n+  ASSERT_OK(CompressedOutputStream::Make(codec, buffer_writer, &stream));\n+\n+  const uint8_t* input = data.data();\n+  int64_t input_len = data.size();\n+  const int64_t chunk_size = 1111;\n+  while (input_len > 0) {\n+    int64_t nbytes = std::min(chunk_size, input_len);\n+    ASSERT_OK(stream->Write(input, nbytes));\n+    input += nbytes;\n+    input_len -= nbytes;\n+    if (do_flush) {\n+      ASSERT_OK(stream->Flush());\n+    }\n+  }\n+  ASSERT_OK(stream->Close());\n+\n+  // Get compressed data and decompress it\n+  std::shared_ptr<Buffer> compressed;\n+  ASSERT_OK(buffer_writer->Finish(&compressed));\n+  std::vector<uint8_t> decompressed(data.size());\n+  ASSERT_OK(codec->Decompress(compressed->size(), compressed->data(), decompressed.size(),\n+                              decompressed.data()));\n+  ASSERT_EQ(decompressed, data);\n+}\n+\n+class CompressedInputStreamTest : public ::testing::TestWithParam<Compression::type> {\n+ protected:\n+  Compression::type GetCompression() { return GetParam(); }\n+\n+  std::unique_ptr<Codec> MakeCodec() {\n+    std::unique_ptr<Codec> codec;\n+    ABORT_NOT_OK(Codec::Create(GetCompression(), &codec));\n+    return codec;\n+  }\n+};\n+\n+TEST_P(CompressedInputStreamTest, CompressibleData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeCompressibleData(COMPRESSIBLE_DATA_SIZE);\n+\n+  CheckCompressedInputStream(codec.get(), data);\n+}\n+\n+TEST_P(CompressedInputStreamTest, RandomData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeRandomData(RANDOM_DATA_SIZE);\n+\n+  CheckCompressedInputStream(codec.get(), data);\n+}\n+\n+TEST_P(CompressedInputStreamTest, TruncatedData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeRandomData(10000);\n+  auto compressed = CompressDataOneShot(codec.get(), data);\n+  auto truncated = SliceBuffer(compressed, 0, compressed->size() - 3);\n+\n+  std::vector<uint8_t> decompressed;\n+  ASSERT_RAISES(IOError, RunCompressedInputStream(codec.get(), truncated, &decompressed));\n+}\n+\n+TEST_P(CompressedInputStreamTest, InvalidData) {\n+  auto codec = MakeCodec();\n+  auto compressed_data = MakeRandomData(10000);\n+\n+  auto buffer_reader = std::make_shared<BufferReader>(Buffer::Wrap(compressed_data));\n+  std::shared_ptr<CompressedInputStream> stream;\n+  ASSERT_OK(CompressedInputStream::Make(codec.get(), buffer_reader, &stream));\n+  std::shared_ptr<Buffer> out_buf;\n+  ASSERT_RAISES(IOError, stream->Read(1024, &out_buf));\n+}\n+\n+// NOTE: Snappy doesn't support streaming decompression\n \n Review comment:\n   But is it useful? The main point here is to interact with existing files.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T16:28:44.114+0000",
                    "updated": "2018-10-18T16:28:44.114+0000",
                    "started": "2018-10-18T16:28:44.113+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "156009",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/156074",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226416101\n \n \n\n ##########\n File path: cpp/src/arrow/io/io-compressed-test.cc\n ##########\n @@ -0,0 +1,243 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <memory>\n+#include <random>\n+#include <string>\n+#include <vector>\n+\n+#include <gtest/gtest.h>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/io/compressed.h\"\n+#include \"arrow/io/memory.h\"\n+#include \"arrow/io/test-common.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/test-util.h\"\n+#include \"arrow/util/compression.h\"\n+\n+namespace arrow {\n+namespace io {\n+\n+using ::arrow::util::Codec;\n+\n+#ifdef ARROW_VALGRIND\n+// Avoid slowing down tests too much with Valgrind\n+static constexpr int64_t RANDOM_DATA_SIZE = 50 * 1024;\n+static constexpr int64_t COMPRESSIBLE_DATA_SIZE = 120 * 1024;\n+#else\n+// The data should be large enough to exercise internal buffers\n+static constexpr int64_t RANDOM_DATA_SIZE = 3 * 1024 * 1024;\n+static constexpr int64_t COMPRESSIBLE_DATA_SIZE = 8 * 1024 * 1024;\n+#endif\n+\n+std::vector<uint8_t> MakeRandomData(int data_size) {\n+  std::vector<uint8_t> data(data_size);\n+  random_bytes(data_size, 1234, data.data());\n+  return data;\n+}\n+\n+std::vector<uint8_t> MakeCompressibleData(int data_size) {\n+  std::string base_data =\n+      \"Apache Arrow is a cross-language development platform for in-memory data\";\n+  int nrepeats = static_cast<int>(1 + data_size / base_data.size());\n+\n+  std::vector<uint8_t> data(base_data.size() * nrepeats);\n+  for (int i = 0; i < nrepeats; ++i) {\n+    std::memcpy(data.data() + i * base_data.size(), base_data.data(), base_data.size());\n+  }\n+  data.resize(data_size);\n+  return data;\n+}\n+\n+std::shared_ptr<Buffer> CompressDataOneShot(Codec* codec,\n+                                            const std::vector<uint8_t>& data) {\n+  int64_t max_compressed_len, compressed_len;\n+  max_compressed_len = codec->MaxCompressedLen(data.size(), data.data());\n+  std::shared_ptr<ResizableBuffer> compressed;\n+  ABORT_NOT_OK(AllocateResizableBuffer(max_compressed_len, &compressed));\n+  ABORT_NOT_OK(codec->Compress(data.size(), data.data(), max_compressed_len,\n+                               compressed->mutable_data(), &compressed_len));\n+  ABORT_NOT_OK(compressed->Resize(compressed_len));\n+  return compressed;\n+}\n+\n+Status RunCompressedInputStream(Codec* codec, std::shared_ptr<Buffer> compressed,\n+                                std::vector<uint8_t>* out) {\n+  // Create compressed input stream\n+  auto buffer_reader = std::make_shared<BufferReader>(compressed);\n+  std::shared_ptr<CompressedInputStream> stream;\n+  RETURN_NOT_OK(CompressedInputStream::Make(codec, buffer_reader, &stream));\n+\n+  std::vector<uint8_t> decompressed;\n+  int64_t decompressed_size = 0;\n+  const int64_t chunk_size = 1111;\n+  while (true) {\n+    std::shared_ptr<Buffer> buf;\n+    RETURN_NOT_OK(stream->Read(chunk_size, &buf));\n+    if (buf->size() == 0) {\n+      // EOF\n+      break;\n+    }\n+    decompressed.resize(decompressed_size + buf->size());\n+    memcpy(decompressed.data() + decompressed_size, buf->data(), buf->size());\n+    decompressed_size += buf->size();\n+  }\n+  *out = std::move(decompressed);\n+  return Status::OK();\n+}\n+\n+void CheckCompressedInputStream(Codec* codec, const std::vector<uint8_t>& data) {\n+  // Create compressed data\n+  auto compressed = CompressDataOneShot(codec, data);\n+\n+  std::vector<uint8_t> decompressed;\n+  ASSERT_OK(RunCompressedInputStream(codec, compressed, &decompressed));\n+\n+  ASSERT_EQ(decompressed.size(), data.size());\n+  ASSERT_EQ(decompressed, data);\n+}\n+\n+void CheckCompressedOutputStream(Codec* codec, const std::vector<uint8_t>& data,\n+                                 bool do_flush) {\n+  // Create compressed output stream\n+  std::shared_ptr<BufferOutputStream> buffer_writer;\n+  ASSERT_OK(BufferOutputStream::Create(1024, default_memory_pool(), &buffer_writer));\n+  std::shared_ptr<CompressedOutputStream> stream;\n+  ASSERT_OK(CompressedOutputStream::Make(codec, buffer_writer, &stream));\n+\n+  const uint8_t* input = data.data();\n+  int64_t input_len = data.size();\n+  const int64_t chunk_size = 1111;\n+  while (input_len > 0) {\n+    int64_t nbytes = std::min(chunk_size, input_len);\n+    ASSERT_OK(stream->Write(input, nbytes));\n+    input += nbytes;\n+    input_len -= nbytes;\n+    if (do_flush) {\n+      ASSERT_OK(stream->Flush());\n+    }\n+  }\n+  ASSERT_OK(stream->Close());\n+\n+  // Get compressed data and decompress it\n+  std::shared_ptr<Buffer> compressed;\n+  ASSERT_OK(buffer_writer->Finish(&compressed));\n+  std::vector<uint8_t> decompressed(data.size());\n+  ASSERT_OK(codec->Decompress(compressed->size(), compressed->data(), decompressed.size(),\n+                              decompressed.data()));\n+  ASSERT_EQ(decompressed, data);\n+}\n+\n+class CompressedInputStreamTest : public ::testing::TestWithParam<Compression::type> {\n+ protected:\n+  Compression::type GetCompression() { return GetParam(); }\n+\n+  std::unique_ptr<Codec> MakeCodec() {\n+    std::unique_ptr<Codec> codec;\n+    ABORT_NOT_OK(Codec::Create(GetCompression(), &codec));\n+    return codec;\n+  }\n+};\n+\n+TEST_P(CompressedInputStreamTest, CompressibleData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeCompressibleData(COMPRESSIBLE_DATA_SIZE);\n+\n+  CheckCompressedInputStream(codec.get(), data);\n+}\n+\n+TEST_P(CompressedInputStreamTest, RandomData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeRandomData(RANDOM_DATA_SIZE);\n+\n+  CheckCompressedInputStream(codec.get(), data);\n+}\n+\n+TEST_P(CompressedInputStreamTest, TruncatedData) {\n+  auto codec = MakeCodec();\n+  auto data = MakeRandomData(10000);\n+  auto compressed = CompressDataOneShot(codec.get(), data);\n+  auto truncated = SliceBuffer(compressed, 0, compressed->size() - 3);\n+\n+  std::vector<uint8_t> decompressed;\n+  ASSERT_RAISES(IOError, RunCompressedInputStream(codec.get(), truncated, &decompressed));\n+}\n+\n+TEST_P(CompressedInputStreamTest, InvalidData) {\n+  auto codec = MakeCodec();\n+  auto compressed_data = MakeRandomData(10000);\n+\n+  auto buffer_reader = std::make_shared<BufferReader>(Buffer::Wrap(compressed_data));\n+  std::shared_ptr<CompressedInputStream> stream;\n+  ASSERT_OK(CompressedInputStream::Make(codec.get(), buffer_reader, &stream));\n+  std::shared_ptr<Buffer> out_buf;\n+  ASSERT_RAISES(IOError, stream->Read(1024, &out_buf));\n+}\n+\n+// NOTE: Snappy doesn't support streaming decompression\n \n Review comment:\n   Probably not. I will say YAGNI for now ;)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T18:25:05.121+0000",
                    "updated": "2018-10-18T18:25:05.121+0000",
                    "started": "2018-10-18T18:25:05.121+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "156074",
                    "issueId": "13071629"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/worklog/156077",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2777: ARROW-1019: [C++] Implement compressed streams\nURL: https://github.com/apache/arrow/pull/2777#discussion_r226417531\n \n \n\n ##########\n File path: cpp/src/arrow/io/compressed.h\n ##########\n @@ -0,0 +1,113 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// Compressed stream implementations\n+\n+#ifndef ARROW_IO_COMPRESSED_H\n+#define ARROW_IO_COMPRESSED_H\n+\n+#include <memory>\n+#include <string>\n+\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class MemoryPool;\n+class Status;\n+\n+namespace util {\n+\n+class Codec;\n+\n+}  // namespace util\n+\n+namespace io {\n+\n+class ARROW_EXPORT CompressedOutputStream : public OutputStream {\n+ public:\n+  ~CompressedOutputStream() override;\n+\n+  /// \\brief Create a compressed output stream wrapping the given output stream.\n+  static Status Make(util::Codec* codec, std::shared_ptr<OutputStream> raw,\n+                     std::shared_ptr<CompressedOutputStream>* out);\n+  static Status Make(MemoryPool* pool, util::Codec* codec,\n \n Review comment:\n   It's more of an argument passing consistency. We generally use `const T&` for immutable arguments, `T*` for mutable arguments, and `const T*` in the rarer case when the input may be null\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-18T18:29:18.435+0000",
                    "updated": "2018-10-18T18:29:18.435+0000",
                    "started": "2018-10-18T18:29:18.434+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "156077",
                    "issueId": "13071629"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": 10800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2a213ef[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2d69d730[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@12494d4a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@717ad864[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4e975098[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@7e1f6a93[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@26e45b07[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@1fa0e47[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@759d8d70[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@70533aa2[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@74eb7bcc[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@25b2cb20[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 10800,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Oct 18 19:34:49 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-10-18T19:34:49.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1019/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2017-05-12T18:43:38.000+0000",
        "updated": "2018-10-18T19:34:59.000+0000",
        "timeoriginalestimate": null,
        "description": "After incorporating the compression code and toolchain from parquet-cpp, we should be able to add a codec layer for on-the-fly compression and decompression",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "3h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 10800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Implement input stream and output stream with Gzip codec",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/comment/16593029",
                    "id": "16593029",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "We need this (+ async reading, see ARROW-500) eventually for the CSV reader project. cc [~pitrou]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-08-26T21:05:35.737+0000",
                    "updated": "2018-08-26T21:05:35.737+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13071629/comment/16655795",
                    "id": "16655795",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 2777\n[https://github.com/apache/arrow/pull/2777]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-10-18T19:34:49.727+0000",
                    "updated": "2018-10-18T19:34:49.727+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|i3ewxz:",
        "customfield_12314139": null
    }
}