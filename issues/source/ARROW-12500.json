{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13374245",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245",
    "key": "ARROW-12500",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12349983",
                "id": "12349983",
                "description": "",
                "name": "5.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-07-28"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "dataset",
            "datasets",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12615032",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12615032",
                "type": {
                    "id": "12310000",
                    "name": "Duplicate",
                    "inward": "is duplicated by",
                    "outward": "duplicates",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310000"
                },
                "inwardIssue": {
                    "id": "13375883",
                    "key": "ARROW-12603",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13375883",
                    "fields": {
                        "summary": "[R] open_dataset ignoring provided schema when using select",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
            "name": "lidavidm",
            "key": "lidavidm",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "David Li",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
            "name": "lidavidm",
            "key": "lidavidm",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "David Li",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
            "name": "lidavidm",
            "key": "lidavidm",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "David Li",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 8400,
            "total": 8400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 8400,
            "total": 8400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12500/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 14,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587406",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm opened a new pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134\n\n\n   This unifies (most of) the tests across Parquet, Feather, and CSV (with carve-outs for particular cases). In particular, this means all formats are now tested in conjunction with async/sync and serial/threaded scanners. Also, a set of common file format tests were refactored out of the individual tests and centralized.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T17:56:28.924+0000",
                    "updated": "2021-04-22T17:56:28.924+0000",
                    "started": "2021-04-22T17:56:28.923+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587406",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587407",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618624665\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_csv.cc\n##########\n@@ -90,9 +90,9 @@ static inline Result<csv::ConvertOptions> GetConvertOptions(\n       GetFragmentScanOptions<CsvFragmentScanOptions>(\n           kCsvTypeName, scan_options.get(), format.default_fragment_scan_options));\n   auto convert_options = csv_scan_options->convert_options;\n-  for (FieldRef ref : scan_options->MaterializedFields()) {\n-    ARROW_ASSIGN_OR_RAISE(auto field, ref.GetOne(*scan_options->dataset_schema));\n-\n+  // Properly set conversion types even for non-materialized fields\n+  // (since we're reading all of them anyways)\n+  for (auto field : scan_options->dataset_schema->fields()) {\n\nReview comment:\n       Unifying the tests led me to discover this, which I think inadvertently fixes a bug I ran into in ARROW-9697 that I hadn't figured out before. There, I found that for CSV fragments `to_table(schema=..., columns=[])` would fail when `to_table(schema=...)` did not fail, because in the former case, the CSV reader would complain about an invalid cast, seemingly ignoring the schema set. \r\n   \r\n   I think this isn't the best solution, however; we should actually be deriving `include_columns`. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T17:58:54.294+0000",
                    "updated": "2021-04-22T17:58:54.294+0000",
                    "started": "2021-04-22T17:58:54.293+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587407",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587409",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#issuecomment-825068972\n\n\n   https://issues.apache.org/jira/browse/ARROW-12500\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T18:03:23.056+0000",
                    "updated": "2021-04-22T18:03:23.056+0000",
                    "started": "2021-04-22T18:03:23.055+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587409",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587475",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618665298\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_csv_test.cc\n##########\n@@ -36,7 +37,21 @@\n namespace arrow {\n namespace dataset {\n \n-class TestCsvFileFormat : public testing::TestWithParam<Compression::type> {\n+class ArrowCsvWriterMixin {\n\nReview comment:\n       Naming nit: Not sure `mixin` is the right term here.  When I think `mixin` I think multiple inheritance.  Maybe `Strategy`?  Also, why \"ArrowCsv\".  Are there other CSV writers?  Also, maybe there is a way to use composition here?  Have an abstract method in `FileFormatFixtureMixin` that returns a `FormatStrategy` or something?  I know \"prefer composition over inheritance\" but I don't know if there is a similar \"prefer composition over template\" guideline :laughing: \n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n\nReview comment:\n       Rename to `TestInspectFailureWithRelevantError`?  There is no method named `Open` on `FileFormat`.\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n\nReview comment:\n       Nit: Maybe move this into a constructor to make it easier to modify options in the future?  Or you could change the method name to `Initialize` so it is more clear this must be called first?\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n\nReview comment:\n       These `ok` checks seem redundant given we are not testing `Result`/`Status` here and you test the `code` on the next line.\n\n##########\nFile path: cpp/src/arrow/dataset/file_csv_test.cc\n##########\n@@ -199,18 +210,11 @@ TEST_P(TestCsvFileFormat, OpenFailureWithRelevantError) {\n   if (GetCompression() != Compression::type::UNCOMPRESSED) {\n     GTEST_SKIP() << \"File source name is different with compression\";\n\nReview comment:\n       Is this really a problem?  Compression is just adding to the filename and we are testing with `HasSubstr`.\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n\nReview comment:\n       Nit: This is more helper function than test.  Perhaps rename to `WriteToBuffer`?  Also, we could create a `TestWrite` here that does...\r\n   \r\n   ```\r\n     auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\r\n     auto source = GetFileSource(reader.get());\r\n     auto written = WriteToBuffer(format_.get(), reader->schema());\r\n     AssertBufferEqual(*written, *source->buffer());\r\n   ```\r\n   \r\n   ...that should be universally applicable.\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n\nReview comment:\n       Not for this PR but I feel like there are a number of places where we have to do something like this to maintain implicit invariants.  It might be nice to have a `ScanOptions` cleanup at some point.  Change the name so it isn't `Options`, hide it from the public API, give it more methods (like `SetFilter`) and private state.\n\n##########\nFile path: cpp/src/arrow/dataset/file_csv.cc\n##########\n@@ -90,11 +90,16 @@ static inline Result<csv::ConvertOptions> GetConvertOptions(\n       GetFragmentScanOptions<CsvFragmentScanOptions>(\n           kCsvTypeName, scan_options.get(), format.default_fragment_scan_options));\n   auto convert_options = csv_scan_options->convert_options;\n-  for (FieldRef ref : scan_options->MaterializedFields()) {\n-    ARROW_ASSIGN_OR_RAISE(auto field, ref.GetOne(*scan_options->dataset_schema));\n-\n+  auto materialized = scan_options->MaterializedFields();\n+  std::unordered_set<std::string> materialized_fields(materialized.begin(),\n+                                                      materialized.end());\n+  for (auto field : scan_options->dataset_schema->fields()) {\n+    // Properly set conversion types for all fields\n     if (column_names.find(field->name()) == column_names.end()) continue;\n     convert_options.column_types[field->name()] = field->type();\n+    // Only read the requested columns\n+    if (materialized_fields.find(field->name()) == materialized_fields.end()) continue;\n\nReview comment:\n       Pretty minor nit but maybe move this above `convert_options.column_types...` so that `convert_options.column_types` doesn't include columns that are not in `convert_options.include_columns`.\n\n##########\nFile path: cpp/src/arrow/dataset/file_csv_test.cc\n##########\n@@ -199,18 +210,11 @@ TEST_P(TestCsvFileFormat, OpenFailureWithRelevantError) {\n   if (GetCompression() != Compression::type::UNCOMPRESSED) {\n     GTEST_SKIP() << \"File source name is different with compression\";\n   }\n-  auto source = GetFileSource(\"\");\n-  EXPECT_RAISES_WITH_MESSAGE_THAT(Invalid, testing::HasSubstr(\"<Buffer>\"),\n-                                  format_->Inspect(*source).status());\n-\n-  constexpr auto file_name = \"herp/derp\";\n-  ASSERT_OK_AND_ASSIGN(\n-      auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n-  EXPECT_RAISES_WITH_MESSAGE_THAT(Invalid, testing::HasSubstr(file_name),\n-                                  format_->Inspect({file_name, fs}).status());\n+  TestOpenFailureWithRelevantError(format_.get(), StatusCode::Invalid);\n\nReview comment:\n       If you add a `GetFormat` to the `WriterMixin` you could probably save a lot of `format_.get()` arguments.\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n+                                    std::shared_ptr<FileWriteOptions> options = nullptr) {\n+    SetSchema(schema->fields());\n+    EXPECT_OK_AND_ASSIGN(auto sink, GetFileSink());\n+\n+    if (!options) options = format->DefaultWriteOptions();\n+    EXPECT_OK_AND_ASSIGN(auto writer, format->MakeWriter(sink, schema, options));\n+    ARROW_EXPECT_OK(writer->Write(GetRecordBatchReader(schema).get()));\n+    ARROW_EXPECT_OK(writer->Finish());\n+    EXPECT_OK_AND_ASSIGN(auto written, sink->Finish());\n+    return written;\n+  }\n+\n+ protected:\n+  std::shared_ptr<ScanOptions> opts_ = std::make_shared<ScanOptions>();\n+};\n+\n+template <typename Writer>\n+class FileFormatScanMixin : public FileFormatFixtureMixin<Writer>,\n+                            public ::testing::WithParamInterface<TestScannerParams> {\n+ public:\n+  int64_t expected_batches() const { return GetParam().total_batches(); }\n+  int64_t expected_rows() const { return GetParam().expected_rows(); }\n+\n+  std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) override {\n+    return MakeGeneratedRecordBatch(schema, GetParam().items_per_batch,\n+                                    GetParam().total_batches());\n+  }\n+\n+  // Scan the fragment through the scanner.\n+  RecordBatchIterator Batches(std::shared_ptr<Fragment> fragment) {\n+    EXPECT_OK_AND_ASSIGN(auto schema, fragment->ReadPhysicalSchema());\n+    auto dataset = std::make_shared<FragmentDataset>(schema, FragmentVector{fragment});\n+    ScannerBuilder builder(dataset, opts_);\n+    ARROW_EXPECT_OK(builder.UseAsync(GetParam().use_async));\n+    ARROW_EXPECT_OK(builder.UseThreads(GetParam().use_threads));\n+    EXPECT_OK_AND_ASSIGN(auto scanner, builder.Finish());\n+    EXPECT_OK_AND_ASSIGN(auto batch_it, scanner->ScanBatches());\n+    return MakeMapIterator([](TaggedRecordBatch tagged) { return tagged.record_batch; },\n+                           std::move(batch_it));\n+  }\n+\n+  // Scan the fragment directly, without using the scanner.\n+  RecordBatchIterator PhysicalBatches(std::shared_ptr<Fragment> fragment) {\n+    if (GetParam().use_async) {\n+      EXPECT_OK_AND_ASSIGN(auto batch_gen, fragment->ScanBatchesAsync(opts_));\n+      EXPECT_OK_AND_ASSIGN(auto batch_it, MakeGeneratorIterator(std::move(batch_gen)));\n+      return batch_it;\n+    }\n+    EXPECT_OK_AND_ASSIGN(auto scan_task_it, fragment->Scan(opts_));\n+    return MakeFlattenIterator(MakeMaybeMapIterator(\n+        [](std::shared_ptr<ScanTask> scan_task) { return scan_task->Execute(); },\n+        std::move(scan_task_it)));\n+  }\n+\n+  // Shared test cases\n+  void TestScan(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = this->GetFileSource(reader.get());\n+\n+    this->SetSchema(reader->schema()->fields());\n+    ASSERT_OK_AND_ASSIGN(auto fragment, format->MakeFragment(*source));\n+\n+    int64_t row_count = 0;\n+    for (auto maybe_batch : Batches(fragment)) {\n+      ASSERT_OK_AND_ASSIGN(auto batch, maybe_batch);\n+      row_count += batch->num_rows();\n+    }\n+    ASSERT_EQ(row_count, GetParam().expected_rows());\n+  }\n+\n+  void TestScanProjected(FileFormat* format) {\n\nReview comment:\n       If projection is applied by the scanner why are we testing it here?\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n+                                    std::shared_ptr<FileWriteOptions> options = nullptr) {\n+    SetSchema(schema->fields());\n+    EXPECT_OK_AND_ASSIGN(auto sink, GetFileSink());\n+\n+    if (!options) options = format->DefaultWriteOptions();\n+    EXPECT_OK_AND_ASSIGN(auto writer, format->MakeWriter(sink, schema, options));\n+    ARROW_EXPECT_OK(writer->Write(GetRecordBatchReader(schema).get()));\n+    ARROW_EXPECT_OK(writer->Finish());\n+    EXPECT_OK_AND_ASSIGN(auto written, sink->Finish());\n+    return written;\n+  }\n+\n+ protected:\n+  std::shared_ptr<ScanOptions> opts_ = std::make_shared<ScanOptions>();\n+};\n+\n+template <typename Writer>\n+class FileFormatScanMixin : public FileFormatFixtureMixin<Writer>,\n+                            public ::testing::WithParamInterface<TestScannerParams> {\n+ public:\n+  int64_t expected_batches() const { return GetParam().total_batches(); }\n+  int64_t expected_rows() const { return GetParam().expected_rows(); }\n+\n+  std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) override {\n+    return MakeGeneratedRecordBatch(schema, GetParam().items_per_batch,\n+                                    GetParam().total_batches());\n+  }\n+\n+  // Scan the fragment through the scanner.\n+  RecordBatchIterator Batches(std::shared_ptr<Fragment> fragment) {\n+    EXPECT_OK_AND_ASSIGN(auto schema, fragment->ReadPhysicalSchema());\n+    auto dataset = std::make_shared<FragmentDataset>(schema, FragmentVector{fragment});\n+    ScannerBuilder builder(dataset, opts_);\n+    ARROW_EXPECT_OK(builder.UseAsync(GetParam().use_async));\n+    ARROW_EXPECT_OK(builder.UseThreads(GetParam().use_threads));\n\nReview comment:\n       Probably no need to set `UseThreads` here, that will not affect how the `FileFormat` is interacted with.\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n+                                    std::shared_ptr<FileWriteOptions> options = nullptr) {\n+    SetSchema(schema->fields());\n+    EXPECT_OK_AND_ASSIGN(auto sink, GetFileSink());\n+\n+    if (!options) options = format->DefaultWriteOptions();\n+    EXPECT_OK_AND_ASSIGN(auto writer, format->MakeWriter(sink, schema, options));\n+    ARROW_EXPECT_OK(writer->Write(GetRecordBatchReader(schema).get()));\n+    ARROW_EXPECT_OK(writer->Finish());\n+    EXPECT_OK_AND_ASSIGN(auto written, sink->Finish());\n+    return written;\n+  }\n+\n+ protected:\n+  std::shared_ptr<ScanOptions> opts_ = std::make_shared<ScanOptions>();\n+};\n+\n+template <typename Writer>\n+class FileFormatScanMixin : public FileFormatFixtureMixin<Writer>,\n+                            public ::testing::WithParamInterface<TestScannerParams> {\n+ public:\n+  int64_t expected_batches() const { return GetParam().total_batches(); }\n+  int64_t expected_rows() const { return GetParam().expected_rows(); }\n+\n+  std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) override {\n+    return MakeGeneratedRecordBatch(schema, GetParam().items_per_batch,\n+                                    GetParam().total_batches());\n+  }\n+\n+  // Scan the fragment through the scanner.\n+  RecordBatchIterator Batches(std::shared_ptr<Fragment> fragment) {\n\nReview comment:\n       What does this add to `FileFormat` testing above and beyond `ScanBatches`?  One could argue that `PhysicalBatches` is all you need.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T19:53:14.646+0000",
                    "updated": "2021-04-22T19:53:14.646+0000",
                    "started": "2021-04-22T19:53:14.646+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587475",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587489",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618708458\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n+                                    std::shared_ptr<FileWriteOptions> options = nullptr) {\n+    SetSchema(schema->fields());\n+    EXPECT_OK_AND_ASSIGN(auto sink, GetFileSink());\n+\n+    if (!options) options = format->DefaultWriteOptions();\n+    EXPECT_OK_AND_ASSIGN(auto writer, format->MakeWriter(sink, schema, options));\n+    ARROW_EXPECT_OK(writer->Write(GetRecordBatchReader(schema).get()));\n+    ARROW_EXPECT_OK(writer->Finish());\n+    EXPECT_OK_AND_ASSIGN(auto written, sink->Finish());\n+    return written;\n+  }\n+\n+ protected:\n+  std::shared_ptr<ScanOptions> opts_ = std::make_shared<ScanOptions>();\n+};\n+\n+template <typename Writer>\n+class FileFormatScanMixin : public FileFormatFixtureMixin<Writer>,\n+                            public ::testing::WithParamInterface<TestScannerParams> {\n+ public:\n+  int64_t expected_batches() const { return GetParam().total_batches(); }\n+  int64_t expected_rows() const { return GetParam().expected_rows(); }\n+\n+  std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) override {\n+    return MakeGeneratedRecordBatch(schema, GetParam().items_per_batch,\n+                                    GetParam().total_batches());\n+  }\n+\n+  // Scan the fragment through the scanner.\n+  RecordBatchIterator Batches(std::shared_ptr<Fragment> fragment) {\n\nReview comment:\n       Originally I wanted to have coverage of each file type with the actual scanner (right now we test each format in isolation + the scanner in isolation). But that is overkill as you point out.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T20:14:16.850+0000",
                    "updated": "2021-04-22T20:14:16.850+0000",
                    "started": "2021-04-22T20:14:16.849+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587489",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587491",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618709167\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n+                                    std::shared_ptr<FileWriteOptions> options = nullptr) {\n+    SetSchema(schema->fields());\n+    EXPECT_OK_AND_ASSIGN(auto sink, GetFileSink());\n+\n+    if (!options) options = format->DefaultWriteOptions();\n+    EXPECT_OK_AND_ASSIGN(auto writer, format->MakeWriter(sink, schema, options));\n+    ARROW_EXPECT_OK(writer->Write(GetRecordBatchReader(schema).get()));\n+    ARROW_EXPECT_OK(writer->Finish());\n+    EXPECT_OK_AND_ASSIGN(auto written, sink->Finish());\n+    return written;\n+  }\n+\n+ protected:\n+  std::shared_ptr<ScanOptions> opts_ = std::make_shared<ScanOptions>();\n+};\n+\n+template <typename Writer>\n+class FileFormatScanMixin : public FileFormatFixtureMixin<Writer>,\n+                            public ::testing::WithParamInterface<TestScannerParams> {\n+ public:\n+  int64_t expected_batches() const { return GetParam().total_batches(); }\n+  int64_t expected_rows() const { return GetParam().expected_rows(); }\n+\n+  std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) override {\n+    return MakeGeneratedRecordBatch(schema, GetParam().items_per_batch,\n+                                    GetParam().total_batches());\n+  }\n+\n+  // Scan the fragment through the scanner.\n+  RecordBatchIterator Batches(std::shared_ptr<Fragment> fragment) {\n+    EXPECT_OK_AND_ASSIGN(auto schema, fragment->ReadPhysicalSchema());\n+    auto dataset = std::make_shared<FragmentDataset>(schema, FragmentVector{fragment});\n+    ScannerBuilder builder(dataset, opts_);\n+    ARROW_EXPECT_OK(builder.UseAsync(GetParam().use_async));\n+    ARROW_EXPECT_OK(builder.UseThreads(GetParam().use_threads));\n+    EXPECT_OK_AND_ASSIGN(auto scanner, builder.Finish());\n+    EXPECT_OK_AND_ASSIGN(auto batch_it, scanner->ScanBatches());\n+    return MakeMapIterator([](TaggedRecordBatch tagged) { return tagged.record_batch; },\n+                           std::move(batch_it));\n+  }\n+\n+  // Scan the fragment directly, without using the scanner.\n+  RecordBatchIterator PhysicalBatches(std::shared_ptr<Fragment> fragment) {\n+    if (GetParam().use_async) {\n+      EXPECT_OK_AND_ASSIGN(auto batch_gen, fragment->ScanBatchesAsync(opts_));\n+      EXPECT_OK_AND_ASSIGN(auto batch_it, MakeGeneratorIterator(std::move(batch_gen)));\n+      return batch_it;\n+    }\n+    EXPECT_OK_AND_ASSIGN(auto scan_task_it, fragment->Scan(opts_));\n+    return MakeFlattenIterator(MakeMaybeMapIterator(\n+        [](std::shared_ptr<ScanTask> scan_task) { return scan_task->Execute(); },\n+        std::move(scan_task_it)));\n+  }\n+\n+  // Shared test cases\n+  void TestScan(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = this->GetFileSource(reader.get());\n+\n+    this->SetSchema(reader->schema()->fields());\n+    ASSERT_OK_AND_ASSIGN(auto fragment, format->MakeFragment(*source));\n+\n+    int64_t row_count = 0;\n+    for (auto maybe_batch : Batches(fragment)) {\n+      ASSERT_OK_AND_ASSIGN(auto batch, maybe_batch);\n+      row_count += batch->num_rows();\n+    }\n+    ASSERT_EQ(row_count, GetParam().expected_rows());\n+  }\n+\n+  void TestScanProjected(FileFormat* format) {\n\nReview comment:\n       This is testing whether each format will look at the projection in the ScanOptions and only return the necessary columns to fulfill the projection + filter later on. Notably, CSV didn't properly do that before.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T20:15:23.602+0000",
                    "updated": "2021-04-22T20:15:23.602+0000",
                    "started": "2021-04-22T20:15:23.602+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587491",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587494",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#issuecomment-825160462\n\n\n   Ah, despite all the diffs, no tests should have been removed - only shuffled around or consolidated when they were the same exact test.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T20:24:29.956+0000",
                    "updated": "2021-04-22T20:24:29.956+0000",
                    "started": "2021-04-22T20:24:29.956+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587494",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587522",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618731254\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_parquet_test.cc\n##########\n@@ -56,9 +52,25 @@ using testing::Pointee;\n \n using internal::checked_pointer_cast;\n \n-class ArrowParquetWriterMixin : public ::testing::Test {\n+class ArrowParquetWriterMixin {\n  public:\n-  Status WriteRecordBatch(const RecordBatch& batch, parquet::arrow::FileWriter* writer) {\n+  static std::shared_ptr<Buffer> Write(RecordBatchReader* reader) {\n+    auto pool = ::arrow::default_memory_pool();\n+\n+    std::shared_ptr<Buffer> out;\n+\n+    auto sink = CreateOutputStream(pool);\n+\n+    ARROW_EXPECT_OK(WriteRecordBatchReader(reader, pool, sink));\n+    // XXX the rest of the test may crash if this fails, since out will be nullptr\n\nReview comment:\n       Minor but could the method be changed to return `Result` so this comment can go away?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T21:04:54.602+0000",
                    "updated": "2021-04-22T21:04:54.602+0000",
                    "started": "2021-04-22T21:04:54.602+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587522",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587523",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618738629\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n+                                    std::shared_ptr<FileWriteOptions> options = nullptr) {\n+    SetSchema(schema->fields());\n+    EXPECT_OK_AND_ASSIGN(auto sink, GetFileSink());\n+\n+    if (!options) options = format->DefaultWriteOptions();\n+    EXPECT_OK_AND_ASSIGN(auto writer, format->MakeWriter(sink, schema, options));\n+    ARROW_EXPECT_OK(writer->Write(GetRecordBatchReader(schema).get()));\n+    ARROW_EXPECT_OK(writer->Finish());\n+    EXPECT_OK_AND_ASSIGN(auto written, sink->Finish());\n+    return written;\n+  }\n+\n+ protected:\n+  std::shared_ptr<ScanOptions> opts_ = std::make_shared<ScanOptions>();\n+};\n+\n+template <typename Writer>\n+class FileFormatScanMixin : public FileFormatFixtureMixin<Writer>,\n+                            public ::testing::WithParamInterface<TestScannerParams> {\n+ public:\n+  int64_t expected_batches() const { return GetParam().total_batches(); }\n+  int64_t expected_rows() const { return GetParam().expected_rows(); }\n+\n+  std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) override {\n+    return MakeGeneratedRecordBatch(schema, GetParam().items_per_batch,\n+                                    GetParam().total_batches());\n+  }\n+\n+  // Scan the fragment through the scanner.\n+  RecordBatchIterator Batches(std::shared_ptr<Fragment> fragment) {\n\nReview comment:\n       I could be easily convinced either way.  I think it's also good to detect potential interaction bugs.  I suppose the scanner could do various things with scan options (like the projection issue you mentioned) that aren't so easily exhaustively tested in formats.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T21:06:48.129+0000",
                    "updated": "2021-04-22T21:06:48.129+0000",
                    "started": "2021-04-22T21:06:48.128+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587523",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587528",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618743453\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n\nReview comment:\n       Added to ARROW-12311. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T21:15:45.631+0000",
                    "updated": "2021-04-22T21:15:45.631+0000",
                    "started": "2021-04-22T21:15:45.630+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587528",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587530",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r618744791\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_csv_test.cc\n##########\n@@ -36,7 +37,21 @@\n namespace arrow {\n namespace dataset {\n \n-class TestCsvFileFormat : public testing::TestWithParam<Compression::type> {\n+class ArrowCsvWriterMixin {\n\nReview comment:\n       I originally tried with abstract methods, but then because of the inheritance tree, you'd have to re-implement them in the AbcFileFormatTest and in the AbcFileFormatScanTest fixtures (I had issues when trying to just have the latter inherit the former). Probably there is some combination of superclasses and interfaces that'll make it work but at that point I decided a template was the lesser evil.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-22T21:18:15.384+0000",
                    "updated": "2021-04-22T21:18:15.384+0000",
                    "started": "2021-04-22T21:18:15.384+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587530",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587806",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on a change in pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#discussion_r619174208\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/test_util.h\n##########\n@@ -303,6 +304,316 @@ template <typename P>\n class DatasetFixtureMixinWithParam : public DatasetFixtureMixin,\n                                      public ::testing::WithParamInterface<P> {};\n \n+struct TestScannerParams {\n+  bool use_async;\n+  bool use_threads;\n+  int num_child_datasets;\n+  int num_batches;\n+  int items_per_batch;\n+\n+  int64_t total_batches() const { return num_child_datasets * num_batches; }\n+\n+  int64_t expected_rows() const { return total_batches() * items_per_batch; }\n+\n+  std::string ToString() const {\n+    // GTest requires this to be alphanumeric\n+    std::stringstream ss;\n+    ss << (use_async ? \"Async\" : \"Sync\") << (use_threads ? \"Threaded\" : \"Serial\")\n+       << num_child_datasets << \"d\" << num_batches << \"b\" << items_per_batch << \"r\";\n+    return ss.str();\n+  }\n+\n+  static std::string ToTestNameString(\n+      const ::testing::TestParamInfo<TestScannerParams>& info) {\n+    return std::to_string(info.index) + info.param.ToString();\n+  }\n+\n+  static std::vector<TestScannerParams> Values() {\n+    std::vector<TestScannerParams> values;\n+    for (int sync = 0; sync < 2; sync++) {\n+      for (int use_threads = 0; use_threads < 2; use_threads++) {\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 1, 1, 1024});\n+        values.push_back(\n+            {static_cast<bool>(sync), static_cast<bool>(use_threads), 2, 16, 1024});\n+      }\n+    }\n+    return values;\n+  }\n+};\n+\n+std::ostream& operator<<(std::ostream& out, const TestScannerParams& params) {\n+  out << (params.use_async ? \"async-\" : \"sync-\")\n+      << (params.use_threads ? \"threaded-\" : \"serial-\") << params.num_child_datasets\n+      << \"d-\" << params.num_batches << \"b-\" << params.items_per_batch << \"i\";\n+  return out;\n+}\n+\n+class FileFormatWriterMixin {\n+  virtual std::shared_ptr<Buffer> Write(RecordBatchReader* reader) = 0;\n+  virtual std::shared_ptr<Buffer> Write(const Table& table) = 0;\n+};\n+\n+/// WriterMixin should be a class with these static methods:\n+/// std::shared_ptr<Buffer> Write(RecordBatchReader* reader);\n+template <typename WriterMixin>\n+class FileFormatFixtureMixin : public ::testing::Test {\n+ public:\n+  constexpr static int64_t kBatchSize = 1UL << 12;\n+  constexpr static int64_t kBatchRepetitions = 1 << 5;\n+\n+  int64_t expected_batches() const { return kBatchRepetitions; }\n+  int64_t expected_rows() const { return kBatchSize * kBatchRepetitions; }\n+\n+  std::shared_ptr<FileSource> GetFileSource(RecordBatchReader* reader) {\n+    auto buffer = WriterMixin::Write(reader);\n+    return std::make_shared<FileSource>(std::move(buffer));\n+  }\n+\n+  virtual std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) {\n+    return MakeGeneratedRecordBatch(schema, kBatchSize, kBatchRepetitions);\n+  }\n+\n+  Result<std::shared_ptr<io::BufferOutputStream>> GetFileSink() {\n+    ARROW_ASSIGN_OR_RAISE(std::shared_ptr<ResizableBuffer> buffer,\n+                          AllocateResizableBuffer(0));\n+    return std::make_shared<io::BufferOutputStream>(buffer);\n+  }\n+\n+  void SetSchema(std::vector<std::shared_ptr<Field>> fields) {\n+    opts_ = std::make_shared<ScanOptions>();\n+    opts_->dataset_schema = schema(std::move(fields));\n+    ASSERT_OK(SetProjection(opts_.get(), opts_->dataset_schema->field_names()));\n+  }\n+\n+  void SetFilter(Expression filter) {\n+    ASSERT_OK_AND_ASSIGN(opts_->filter, filter.Bind(*opts_->dataset_schema));\n+  }\n+\n+  void Project(std::vector<std::string> names) {\n+    ASSERT_OK(SetProjection(opts_.get(), std::move(names)));\n+  }\n+\n+  // Shared test cases\n+  void TestOpenFailureWithRelevantError(FileFormat* format, StatusCode code) {\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    auto result = format->Inspect(FileSource(buf));\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(\"<Buffer>\"));\n+\n+    constexpr auto file_name = \"herp/derp\";\n+    ASSERT_OK_AND_ASSIGN(\n+        auto fs, fs::internal::MockFileSystem::Make(fs::kNoTime, {fs::File(file_name)}));\n+    result = format->Inspect({file_name, fs});\n+    EXPECT_FALSE(result.ok());\n+    EXPECT_EQ(code, result.status().code());\n+    EXPECT_THAT(result.status().ToString(), testing::HasSubstr(file_name));\n+  }\n+  void TestInspect(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    ASSERT_OK_AND_ASSIGN(auto actual, format->Inspect(*source.get()));\n+    AssertSchemaEqual(*actual, *reader->schema(), /*check_metadata=*/false);\n+  }\n+  void TestIsSupported(FileFormat* format) {\n+    auto reader = GetRecordBatchReader(schema({field(\"f64\", float64())}));\n+    auto source = GetFileSource(reader.get());\n+\n+    bool supported = false;\n+\n+    std::shared_ptr<Buffer> buf = std::make_shared<Buffer>(util::string_view(\"\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    buf = std::make_shared<Buffer>(util::string_view(\"corrupted\"));\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(FileSource(buf)));\n+    ASSERT_EQ(supported, false);\n+\n+    ASSERT_OK_AND_ASSIGN(supported, format->IsSupported(*source));\n+    EXPECT_EQ(supported, true);\n+  }\n+  std::shared_ptr<Buffer> TestWrite(FileFormat* format, std::shared_ptr<Schema> schema,\n+                                    std::shared_ptr<FileWriteOptions> options = nullptr) {\n+    SetSchema(schema->fields());\n+    EXPECT_OK_AND_ASSIGN(auto sink, GetFileSink());\n+\n+    if (!options) options = format->DefaultWriteOptions();\n+    EXPECT_OK_AND_ASSIGN(auto writer, format->MakeWriter(sink, schema, options));\n+    ARROW_EXPECT_OK(writer->Write(GetRecordBatchReader(schema).get()));\n+    ARROW_EXPECT_OK(writer->Finish());\n+    EXPECT_OK_AND_ASSIGN(auto written, sink->Finish());\n+    return written;\n+  }\n+\n+ protected:\n+  std::shared_ptr<ScanOptions> opts_ = std::make_shared<ScanOptions>();\n+};\n+\n+template <typename Writer>\n+class FileFormatScanMixin : public FileFormatFixtureMixin<Writer>,\n+                            public ::testing::WithParamInterface<TestScannerParams> {\n+ public:\n+  int64_t expected_batches() const { return GetParam().total_batches(); }\n+  int64_t expected_rows() const { return GetParam().expected_rows(); }\n+\n+  std::shared_ptr<RecordBatchReader> GetRecordBatchReader(\n+      std::shared_ptr<Schema> schema) override {\n+    return MakeGeneratedRecordBatch(schema, GetParam().items_per_batch,\n+                                    GetParam().total_batches());\n+  }\n+\n+  // Scan the fragment through the scanner.\n+  RecordBatchIterator Batches(std::shared_ptr<Fragment> fragment) {\n\nReview comment:\n       On balance I think I'll refactor this since you plan to add fuller integration tests for datasets which is a better spot to catch more involved things. The test cases here I'll keep, but only to directly test Scan/ScanBatches.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T12:19:13.023+0000",
                    "updated": "2021-04-23T12:19:13.023+0000",
                    "started": "2021-04-23T12:19:13.023+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587806",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/587811",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm commented on pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134#issuecomment-825622315\n\n\n   Thanks for the quick review. I think everything's been addressed.\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-23T12:25:50.530+0000",
                    "updated": "2021-04-23T12:25:50.530+0000",
                    "started": "2021-04-23T12:25:50.530+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "587811",
                    "issueId": "13374245"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/worklog/589288",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "lidavidm closed pull request #10134:\nURL: https://github.com/apache/arrow/pull/10134\n\n\n   \n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-04-26T15:07:49.001+0000",
                    "updated": "2021-04-26T15:07:49.001+0000",
                    "started": "2021-04-26T15:07:49.001+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "589288",
                    "issueId": "13374245"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 8400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@48b2ea91[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6458339f[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@55be0420[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@70df01c3[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5df25934[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6b4fd080[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4e7556cd[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@46ac97d9[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@9585dc1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@1c0657ba[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7821a9c9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@5a11fb4b[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 8400,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Apr 26 15:07:42 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-04-26T15:07:42.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-12500/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2021-04-21T21:43:16.000+0000",
        "updated": "2021-05-03T16:19:22.000+0000",
        "timeoriginalestimate": null,
        "description": "Between CSV/Parquet/IPC we have a number of very similar or in some cases essentially identical tests. As we're doing more refactoring and development it would be nice to consolidate these tests so that we can ensure all formats behave consistently and get the same level of testing. For instance, ARROW-11772 now adds more comprehensive tests for scanning IPC which don't yet apply to Parquet/CSV.\r\n\r\nThis sort of consolidation may also be nice to do in Python.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "2h 20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 8400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Dataset] Consolidate similar tests for file formats",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13374245/comment/17332481",
                    "id": "17332481",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 10134\n[https://github.com/apache/arrow/pull/10134]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=lidavidm",
                        "name": "lidavidm",
                        "key": "lidavidm",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "David Li",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2021-04-26T15:07:42.460+0000",
                    "updated": "2021-04-26T15:07:42.460+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0qbag:",
        "customfield_12314139": null
    }
}