{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13408535",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535",
    "key": "ARROW-14479",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350591",
                "id": "12350591",
                "description": "",
                "name": "7.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-02-03"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350591",
                "id": "12350591",
                "description": "",
                "name": "7.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-02-03"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12625254",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12625254",
                "type": {
                    "id": "12310460",
                    "name": "Child-Issue",
                    "inward": "is a child of",
                    "outward": "is a parent of",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/12310460"
                },
                "inwardIssue": {
                    "id": "13404218",
                    "key": "ARROW-14182",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13404218",
                    "fields": {
                        "summary": "[C++][Compute] Hash Join performance improvement",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=sakras",
            "name": "sakras",
            "key": "sakras",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Sasha Krassovsky",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
            "name": "michalno",
            "key": "michalno",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Michal Nowakiewicz",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
            "name": "michalno",
            "key": "michalno",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
            },
            "displayName": "Michal Nowakiewicz",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 34200,
            "total": 34200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 34200,
            "total": 34200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-14479/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 57,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/691464",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer opened a new pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876\n\n\n   Added microbenchmarks for Hash Join (using OpenMP for parallelism for now). Also added a python script that analyzes the benchmark file and makes a lot of pretty graphs!\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-07T03:34:31.664+0000",
                    "updated": "2021-12-07T03:34:31.664+0000",
                    "started": "2021-12-07T03:34:31.664+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "691464",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/691465",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#issuecomment-987537874\n\n\n   https://issues.apache.org/jira/browse/ARROW-14479\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-07T03:34:54.525+0000",
                    "updated": "2021-12-07T03:34:54.525+0000",
                    "started": "2021-12-07T03:34:54.524+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "691465",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/691466",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "edponce commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r763605558\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/CMakeLists.txt\n##########\n@@ -32,6 +32,9 @@ add_arrow_compute_test(util_test PREFIX \"arrow-compute\")\n \n add_arrow_benchmark(expression_benchmark PREFIX \"arrow-compute\")\n \n+find_package(OpenMP)\n+add_arrow_benchmark(hash_join_benchmark PREFIX \"arrow-compute\" EXTRA_LINK_LIBS OpenMP::OpenMP_CXX)\n\nReview comment:\n       If OpenMP is not available, would benchmark still compile?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-07T03:44:24.853+0000",
                    "updated": "2021-12-07T03:44:24.853+0000",
                    "started": "2021-12-07T03:44:24.852+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "691466",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/691467",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r763609273\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/CMakeLists.txt\n##########\n@@ -32,6 +32,9 @@ add_arrow_compute_test(util_test PREFIX \"arrow-compute\")\n \n add_arrow_benchmark(expression_benchmark PREFIX \"arrow-compute\")\n \n+find_package(OpenMP)\n+add_arrow_benchmark(hash_join_benchmark PREFIX \"arrow-compute\" EXTRA_LINK_LIBS OpenMP::OpenMP_CXX)\n\nReview comment:\n       No, probably not. I believe the goal is to be able to also compare the overheads of our executor framework vs OpenMP at some point\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-07T03:56:11.050+0000",
                    "updated": "2021-12-07T03:56:11.050+0000",
                    "started": "2021-12-07T03:56:11.050+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "691467",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/692066",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r764366267\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/CMakeLists.txt\n##########\n@@ -32,6 +32,9 @@ add_arrow_compute_test(util_test PREFIX \"arrow-compute\")\n \n add_arrow_benchmark(expression_benchmark PREFIX \"arrow-compute\")\n \n+find_package(OpenMP)\n+add_arrow_benchmark(hash_join_benchmark PREFIX \"arrow-compute\" EXTRA_LINK_LIBS OpenMP::OpenMP_CXX)\n\nReview comment:\n       I changed it so that it won't break compilation - it'll just not build this particular target in the absence of OpenMP. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-07T21:13:56.585+0000",
                    "updated": "2021-12-07T21:13:56.585+0000",
                    "started": "2021-12-07T21:13:56.585+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "692066",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694355",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r766078283\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/CMakeLists.txt\n##########\n@@ -32,6 +32,19 @@ add_arrow_compute_test(util_test PREFIX \"arrow-compute\")\n \n add_arrow_benchmark(expression_benchmark PREFIX \"arrow-compute\")\n \n+find_package(OpenMP)\n+if(OpenMP_CXX_FOUND)\n+  add_arrow_benchmark(hash_join_benchmark\n+                      PREFIX\n+                      \"arrow-compute\"\n+                      EXTRA_LINK_LIBS\n+                      OpenMP::OpenMP_CXX)\n+  if(MSVC)\n+    target_compile_options(arrow-compute-hash-join-benchmark\n+                           PRIVATE \"-openmp:experimental -openmp:llvm\")\n+  endif()\n+endif()\n+\n\nReview comment:\n       So I think traditionally we might expose this via a cmake option `ARROW_BUILD_OPENMP_BENCHMARKS`.  I think that has slightly more visibility.  Otherwise it would be very easy for this benchmark to get missed and not included in whatever regression we have.\r\n   \r\n   That being said, since it is just one benchmark, I don't feel too strongly about it and I'd be happy either way.\r\n   \r\n   @kou any opinion?\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n\nReview comment:\n       Minor nit: these names are a bit misleading for me.\r\n   \r\n   When I see `cardinality` I think `size` and not \"num distinct\".\r\n   Selectivity is maybe a bit closer but I've only ever heard the term in relation to filtering.\r\n   \r\n   If these are standard terms in the literature then I won't argue but if they aren't maybe something like `num_unique_build_keys` (admittedly a bit long) and `match_rate`?\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n\nReview comment:\n       I'm not sure if it was my version of OpenMP (8.0.1 via conda) or not but it didn't like the range based for loops. I  had to change it to a traditional for loop to get this to compile.  Otherwise I got an error:\r\n   \r\n   `statement after '#pragma omp for' must be a for loop`\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n\nReview comment:\n       Can you drop the curly braces?  They seem to trigger quoting by google benchmark and the string is already encased in `/` delimters:\r\n   \r\n   e.g. instead of:\r\n   \r\n   ```\r\n   BM_HashJoinBasic_KeyTypes/\"{int32}\"/Hashtable krows:1\r\n   ```\r\n   \r\n   the following is a touch more compact:\r\n   \r\n   ```\r\n   BM_HashJoinBasic_KeyTypes/int32/Hashtable krows:1\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64}\", {int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64}\", {int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64}\",\n+                  {int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64,int64}\",\n+                  {int64(), int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{utf8}\", {utf8()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 256);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(4)}\",\n+                  {fixed_size_binary(4)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(8)}\",\n+                  {fixed_size_binary(8)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(16)}\",\n+                  {fixed_size_binary(16)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(24)}\",\n+                  {fixed_size_binary(24)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(32)}\",\n+                  {fixed_size_binary(32)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+\n+std::vector<std::string> selectivity_argnames = {\"Selectivity\", \"HashTable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int32}\", {int32()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int64}\", {int64()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+\n+// Joins on UTF8 are currently really slow, so anything above 512 doesn't finished within\n+// a reasonable amount of time.\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{utf8}\", {utf8()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n\nReview comment:\n       4 or 5 choices for selectivity is probably enough to show any trends?  It would cut the runtime for the benchmark in half.\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n\nReview comment:\n       ```suggestion\r\n         DCHECK_OK(l_schema_builder.AddField(l_field));\r\n         DCHECK_OK(r_schema_builder.AddField(r_field));\r\n   ```\r\n   AddField takes a const reference.\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n\nReview comment:\n       There should be no need for you to do this math yourself:\r\n   \r\n   ```\r\n   st.counters[\"rows\"] = Counter(total_rows, benchmark::Counter::kIsRate);\r\n   ```\r\n   \r\n   Then google benchmark will show the result as rows per second.  Traditionally our benchmarks are bytes per second so I think it will make it easier for any automated tooling consuming these benchmarks if we always use rates or counters (e.g. that way bigger is always better for custom counters).\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n\nReview comment:\n       ```suggestion\r\n     settings.key_types = std::move(key_types);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n\nReview comment:\n       Is this needed?\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n\nReview comment:\n       ```suggestion\r\n     settings.key_types = std::move(key_types);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64}\", {int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64}\", {int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64}\",\n+                  {int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64,int64}\",\n+                  {int64(), int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{utf8}\", {utf8()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 256);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(4)}\",\n+                  {fixed_size_binary(4)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(8)}\",\n+                  {fixed_size_binary(8)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(16)}\",\n+                  {fixed_size_binary(16)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(24)}\",\n+                  {fixed_size_binary(24)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(32)}\",\n+                  {fixed_size_binary(32)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+\n+std::vector<std::string> selectivity_argnames = {\"Selectivity\", \"HashTable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int32}\", {int32()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int64}\", {int64()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+\n+// Joins on UTF8 are currently really slow, so anything above 512 doesn't finished within\n+// a reasonable amount of time.\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{utf8}\", {utf8()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 512, 8)});\n\nReview comment:\n       Some of the UTF8 benchmarks are unbearable slow (60 seconds for a single iteration * 10 selectivities).  Are we really learning new information by running above 64krows?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-11T02:42:58.242+0000",
                    "updated": "2021-12-11T02:42:58.242+0000",
                    "started": "2021-12-11T02:42:58.242+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694355",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694356",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767078622\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n\nReview comment:\n       ```suggestion\r\n   #include \"arrow/compute/kernels/test_util.h\"\r\n   #include \"arrow/testing/gtest_util.h\"\r\n   #include \"arrow/testing/matchers.h\"\r\n   ```\r\n   \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-11T02:44:52.142+0000",
                    "updated": "2021-12-11T02:44:52.142+0000",
                    "started": "2021-12-11T02:44:52.141+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694356",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694357",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767078640\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n\nReview comment:\n       ```suggestion\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-11T02:45:05.039+0000",
                    "updated": "2021-12-11T02:45:05.039+0000",
                    "started": "2021-12-11T02:45:05.039+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694357",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694358",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767078622\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n\nReview comment:\n       ```suggestion\r\n   ```\r\n   \n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n\nReview comment:\n       ```suggestion\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-11T02:45:28.754+0000",
                    "updated": "2021-12-11T02:45:28.754+0000",
                    "started": "2021-12-11T02:45:28.753+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694358",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694360",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767079743\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/CMakeLists.txt\n##########\n@@ -32,6 +32,19 @@ add_arrow_compute_test(util_test PREFIX \"arrow-compute\")\n \n add_arrow_benchmark(expression_benchmark PREFIX \"arrow-compute\")\n \n+find_package(OpenMP)\n+if(OpenMP_CXX_FOUND)\n+  add_arrow_benchmark(hash_join_benchmark\n+                      PREFIX\n+                      \"arrow-compute\"\n+                      EXTRA_LINK_LIBS\n+                      OpenMP::OpenMP_CXX)\n+  if(MSVC)\n+    target_compile_options(arrow-compute-hash-join-benchmark\n+                           PRIVATE \"-openmp:experimental -openmp:llvm\")\n+  endif()\n+endif()\n+\n\nReview comment:\n       You're thinking like the following implementation, right?\r\n   \r\n   ```cmake\r\n   if(ARROW_BUILD_OPENMP_BENCHMARKS)\r\n     find_package(OpenMP REQUIRED)\r\n     add_arrow_benchmark(hash_join_benchmark\r\n                         PREFIX\r\n                         \"arrow-compute\"\r\n                         EXTRA_LINK_LIBS\r\n                         OpenMP::OpenMP_CXX)\r\n     if(MSVC)\r\n       target_compile_options(arrow-compute-hash-join-benchmark\r\n                              PRIVATE \"-openmp:experimental -openmp:llvm\")\r\n     endif()\r\n   endif()\r\n   ```\r\n   \r\n   I think that it's a good idea. Developers can disable OpenMP related (heavy?) benchmarks explicitly with this approach.\r\n   \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-11T02:57:10.434+0000",
                    "updated": "2021-12-11T02:57:10.434+0000",
                    "started": "2021-12-11T02:57:10.434+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694360",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694538",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r766078283\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/CMakeLists.txt\n##########\n@@ -32,6 +32,19 @@ add_arrow_compute_test(util_test PREFIX \"arrow-compute\")\n \n add_arrow_benchmark(expression_benchmark PREFIX \"arrow-compute\")\n \n+find_package(OpenMP)\n+if(OpenMP_CXX_FOUND)\n+  add_arrow_benchmark(hash_join_benchmark\n+                      PREFIX\n+                      \"arrow-compute\"\n+                      EXTRA_LINK_LIBS\n+                      OpenMP::OpenMP_CXX)\n+  if(MSVC)\n+    target_compile_options(arrow-compute-hash-join-benchmark\n+                           PRIVATE \"-openmp:experimental -openmp:llvm\")\n+  endif()\n+endif()\n+\n\nReview comment:\n       So I think traditionally we might expose this via a cmake option `ARROW_BUILD_OPENMP_BENCHMARKS`.  I think that has slightly more visibility.  Otherwise it would be very easy for this benchmark to get missed and not included in whatever regression we have.\r\n   \r\n   That being said, since it is just one benchmark, I don't feel too strongly about it and I'd be happy either way.\r\n   \r\n   @kou any opinion?\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n\nReview comment:\n       Minor nit: these names are a bit misleading for me.\r\n   \r\n   When I see `cardinality` I think `size` and not \"num distinct\".\r\n   Selectivity is maybe a bit closer but I've only ever heard the term in relation to filtering.\r\n   \r\n   If these are standard terms in the literature then I won't argue but if they aren't maybe something like `num_unique_build_keys` (admittedly a bit long) and `match_rate`?\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n\nReview comment:\n       I'm not sure if it was my version of OpenMP (8.0.1 via conda) or not but it didn't like the range based for loops. I  had to change it to a traditional for loop to get this to compile.  Otherwise I got an error:\r\n   \r\n   `statement after '#pragma omp for' must be a for loop`\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n\nReview comment:\n       Can you drop the curly braces?  They seem to trigger quoting by google benchmark and the string is already encased in `/` delimters:\r\n   \r\n   e.g. instead of:\r\n   \r\n   ```\r\n   BM_HashJoinBasic_KeyTypes/\"{int32}\"/Hashtable krows:1\r\n   ```\r\n   \r\n   the following is a touch more compact:\r\n   \r\n   ```\r\n   BM_HashJoinBasic_KeyTypes/int32/Hashtable krows:1\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64}\", {int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64}\", {int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64}\",\n+                  {int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64,int64}\",\n+                  {int64(), int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{utf8}\", {utf8()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 256);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(4)}\",\n+                  {fixed_size_binary(4)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(8)}\",\n+                  {fixed_size_binary(8)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(16)}\",\n+                  {fixed_size_binary(16)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(24)}\",\n+                  {fixed_size_binary(24)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(32)}\",\n+                  {fixed_size_binary(32)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+\n+std::vector<std::string> selectivity_argnames = {\"Selectivity\", \"HashTable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int32}\", {int32()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int64}\", {int64()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+\n+// Joins on UTF8 are currently really slow, so anything above 512 doesn't finished within\n+// a reasonable amount of time.\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{utf8}\", {utf8()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n\nReview comment:\n       4 or 5 choices for selectivity is probably enough to show any trends?  It would cut the runtime for the benchmark in half.\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n\nReview comment:\n       ```suggestion\r\n         DCHECK_OK(l_schema_builder.AddField(l_field));\r\n         DCHECK_OK(r_schema_builder.AddField(r_field));\r\n   ```\r\n   AddField takes a const reference.\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n\nReview comment:\n       There should be no need for you to do this math yourself:\r\n   \r\n   ```\r\n   st.counters[\"rows\"] = Counter(total_rows, benchmark::Counter::kIsRate);\r\n   ```\r\n   \r\n   Then google benchmark will show the result as rows per second.  Traditionally our benchmarks are bytes per second so I think it will make it easier for any automated tooling consuming these benchmarks if we always use rates or counters (e.g. that way bigger is always better for custom counters).\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n\nReview comment:\n       ```suggestion\r\n     settings.key_types = std::move(key_types);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n\nReview comment:\n       Is this needed?\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n\nReview comment:\n       ```suggestion\r\n     settings.key_types = std::move(key_types);\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64}\", {int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64}\", {int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64}\",\n+                  {int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64,int64}\",\n+                  {int64(), int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{utf8}\", {utf8()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 256);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(4)}\",\n+                  {fixed_size_binary(4)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(8)}\",\n+                  {fixed_size_binary(8)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(16)}\",\n+                  {fixed_size_binary(16)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(24)}\",\n+                  {fixed_size_binary(24)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(32)}\",\n+                  {fixed_size_binary(32)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+\n+std::vector<std::string> selectivity_argnames = {\"Selectivity\", \"HashTable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int32}\", {int32()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int64}\", {int64()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+\n+// Joins on UTF8 are currently really slow, so anything above 512 doesn't finished within\n+// a reasonable amount of time.\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{utf8}\", {utf8()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 512, 8)});\n\nReview comment:\n       Some of the UTF8 benchmarks are unbearable slow (60 seconds for a single iteration * 10 selectivities).  Are we really learning new information by running above 64krows?\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n\nReview comment:\n       ```suggestion\r\n   #include \"arrow/compute/kernels/test_util.h\"\r\n   #include \"arrow/testing/gtest_util.h\"\r\n   #include \"arrow/testing/matchers.h\"\r\n   ```\r\n   \n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n\nReview comment:\n       ```suggestion\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n\nReview comment:\n       ```suggestion\r\n   ```\r\n   \n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n\nReview comment:\n       ```suggestion\r\n   ```\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T05:56:32.963+0000",
                    "updated": "2021-12-12T05:56:32.963+0000",
                    "started": "2021-12-12T05:56:32.963+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694538",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694579",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767079743\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/CMakeLists.txt\n##########\n@@ -32,6 +32,19 @@ add_arrow_compute_test(util_test PREFIX \"arrow-compute\")\n \n add_arrow_benchmark(expression_benchmark PREFIX \"arrow-compute\")\n \n+find_package(OpenMP)\n+if(OpenMP_CXX_FOUND)\n+  add_arrow_benchmark(hash_join_benchmark\n+                      PREFIX\n+                      \"arrow-compute\"\n+                      EXTRA_LINK_LIBS\n+                      OpenMP::OpenMP_CXX)\n+  if(MSVC)\n+    target_compile_options(arrow-compute-hash-join-benchmark\n+                           PRIVATE \"-openmp:experimental -openmp:llvm\")\n+  endif()\n+endif()\n+\n\nReview comment:\n       You're thinking like the following implementation, right?\r\n   \r\n   ```cmake\r\n   if(ARROW_BUILD_OPENMP_BENCHMARKS)\r\n     find_package(OpenMP REQUIRED)\r\n     add_arrow_benchmark(hash_join_benchmark\r\n                         PREFIX\r\n                         \"arrow-compute\"\r\n                         EXTRA_LINK_LIBS\r\n                         OpenMP::OpenMP_CXX)\r\n     if(MSVC)\r\n       target_compile_options(arrow-compute-hash-join-benchmark\r\n                              PRIVATE \"-openmp:experimental -openmp:llvm\")\r\n     endif()\r\n   endif()\r\n   ```\r\n   \r\n   I think that it's a good idea. Developers can disable OpenMP related (heavy?) benchmarks explicitly with this approach.\r\n   \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T06:00:33.687+0000",
                    "updated": "2021-12-12T06:00:33.687+0000",
                    "started": "2021-12-12T06:00:33.686+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694579",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694781",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767345286\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n\nReview comment:\n       Looks like that was added in OpenMP version 5.0 (https://stackoverflow.com/questions/64239850/clang-10-openmp-on-range-based-for-error-docs-say-should-be-ok). I'll change it to be a for loop using iterators. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T23:34:23.629+0000",
                    "updated": "2021-12-12T23:34:23.629+0000",
                    "started": "2021-12-12T23:34:23.629+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694781",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694782",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767345588\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n\nReview comment:\n       Well I wanted it to be consistent with the multikey ones. Should I drop the braces on those? Or are braces ok with those and keep single-key tests without them? \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T23:37:36.673+0000",
                    "updated": "2021-12-12T23:37:36.673+0000",
                    "started": "2021-12-12T23:37:36.672+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694782",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694783",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767346867\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n\nReview comment:\n       The thing is we're summing the time across all of the threads. I think settings it as a Rate will only do the total time. We actually want some measure of \"efficiency\". Multithreading is the primary such case, where we measure something like 70 ns/row for single-threaded but something like 120ns/row or more for higher numbers of threads. We want a way to see this overhead, which an overall rate wouldn't capture as well. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T23:47:30.838+0000",
                    "updated": "2021-12-12T23:47:30.838+0000",
                    "started": "2021-12-12T23:47:30.838+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694783",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694784",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767348040\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n\nReview comment:\n       Cardinality is always the number of distinct values. Cardinality is actually a huge field in query optimization - clever streaming algorithms like HyperLogLog have been developed to approximate it. It's used in query optimization for determining the best join strategy. \r\n   \r\n   Selectivity is generally a filtering term, but a Join is a type of filter. If you think about it, join is a combination of group by, project, and filter, so selectivity is also used when talking about joins. The most common way selectivity is defined for a join is as the ratio between number of output rows and the size of the cross product of its input relations (i.e. |R\u2a1dS|/|R\u2a2fS|), but my definition is similar. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T23:56:35.306+0000",
                    "updated": "2021-12-12T23:56:35.306+0000",
                    "started": "2021-12-12T23:56:35.306+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694784",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694785",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767348124\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n\nReview comment:\n       Good catch! Don't think so. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-12T23:57:18.079+0000",
                    "updated": "2021-12-12T23:57:18.079+0000",
                    "started": "2021-12-12T23:57:18.079+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694785",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/694865",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "save-buffer commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r767454648\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_KeyTypes(benchmark::State& st,\n+                                      std::vector<std::shared_ptr<DataType>> key_types,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.num_build_batches = static_cast<int>(st.range(0));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_Selectivity(benchmark::State& st,\n+                                         std::vector<std::shared_ptr<DataType>> key_types,\n+                                         Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.key_types = key_types;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+template <typename... Args>\n+static void BM_HashJoinBasic_JoinType(benchmark::State& st, JoinType join_type,\n+                                      Args&&...) {\n+  BenchmarkSettings settings;\n+  settings.selectivity = static_cast<double>(st.range(0)) / 100.0;\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches;\n+  settings.join_type = join_type;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_MatchesPerRow(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(0));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_PayloadSize(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  int32_t payload_size = static_cast<int32_t>(st.range(0));\n+  settings.probe_payload_types = {fixed_size_binary(payload_size)};\n+  settings.cardinality = 1.0 / static_cast<double>(st.range(1));\n+\n+  settings.num_build_batches = static_cast<int>(st.range(2));\n+  settings.num_probe_batches = settings.num_probe_batches;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_ProbeParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_build_batches * 8;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_BuildParallelism(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.num_threads = static_cast<int>(st.range(0));\n+  settings.num_build_batches = static_cast<int>(st.range(1));\n+  settings.num_probe_batches = settings.num_threads;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+static void BM_HashJoinBasic_NullPercentage(benchmark::State& st) {\n+  BenchmarkSettings settings;\n+  settings.null_percentage = static_cast<double>(st.range(0)) / 100.0;\n+\n+  HashJoinBasicBenchmarkImpl(st, settings);\n+}\n+\n+std::vector<std::string> keytypes_argnames = {\"Hashtable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int32}\", {int32()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64}\", {int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64}\", {int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64}\",\n+                  {int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{int64,int64,int64,int64}\",\n+                  {int64(), int64(), int64(), int64()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{utf8}\", {utf8()})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 256);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(4)}\",\n+                  {fixed_size_binary(4)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(8)}\",\n+                  {fixed_size_binary(8)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(16)}\",\n+                  {fixed_size_binary(16)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(24)}\",\n+                  {fixed_size_binary(24)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_KeyTypes, \"{fixed_size_binary(32)}\",\n+                  {fixed_size_binary(32)})\n+    ->ArgNames(keytypes_argnames)\n+    ->RangeMultiplier(4)\n+    ->Range(1, 4 * 1024);\n+\n+std::vector<std::string> selectivity_argnames = {\"Selectivity\", \"HashTable krows\"};\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int32}\", {int32()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{int64}\", {int64()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 4 * 1024, 8)});\n+\n+// Joins on UTF8 are currently really slow, so anything above 512 doesn't finished within\n+// a reasonable amount of time.\n+BENCHMARK_CAPTURE(BM_HashJoinBasic_Selectivity, \"{utf8}\", {utf8()})\n+    ->ArgNames(selectivity_argnames)\n+    ->ArgsProduct({benchmark::CreateDenseRange(0, 100, 10),\n+                   benchmark::CreateRange(1, 512, 8)});\n\nReview comment:\n       I turned it down to never be above 64k rows for utf8\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-13T07:02:44.292+0000",
                    "updated": "2021-12-13T07:02:44.292+0000",
                    "started": "2021-12-13T07:02:44.292+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "694865",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/695363",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r768130340\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n+};\n+\n+class JoinBenchmark {\n+ public:\n+  explicit JoinBenchmark(BenchmarkSettings& settings) {\n+    bool is_parallel = settings.num_threads != 1;\n+\n+    SchemaBuilder l_schema_builder, r_schema_builder;\n+    std::vector<FieldRef> left_keys, right_keys;\n+    for (size_t i = 0; i < settings.key_types.size(); i++) {\n+      std::string l_name = \"lk\" + std::to_string(i);\n+      std::string r_name = \"rk\" + std::to_string(i);\n+\n+      // For integers, selectivity is the proportion of the build interval that overlaps\n+      // with the probe interval\n+      uint64_t num_build_rows = settings.num_build_batches * settings.batch_size;\n+\n+      uint64_t min_build_value = 0;\n+      uint64_t max_build_value =\n+          static_cast<uint64_t>(num_build_rows * settings.cardinality);\n+\n+      uint64_t min_probe_value =\n+          static_cast<uint64_t>((1.0 - settings.selectivity) * max_build_value);\n+      uint64_t max_probe_value = min_probe_value + max_build_value;\n+\n+      std::unordered_map<std::string, std::string> build_metadata;\n+      build_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      build_metadata[\"min\"] = std::to_string(min_build_value);\n+      build_metadata[\"max\"] = std::to_string(max_build_value);\n+\n+      std::unordered_map<std::string, std::string> probe_metadata;\n+      probe_metadata[\"null_probability\"] = std::to_string(settings.null_percentage);\n+      probe_metadata[\"min\"] = std::to_string(min_probe_value);\n+      probe_metadata[\"max\"] = std::to_string(max_probe_value);\n+\n+      auto l_field =\n+          field(l_name, settings.key_types[i], key_value_metadata(probe_metadata));\n+      auto r_field =\n+          field(r_name, settings.key_types[i], key_value_metadata(build_metadata));\n+\n+      DCHECK_OK(l_schema_builder.AddField(std::move(l_field)));\n+      DCHECK_OK(r_schema_builder.AddField(std::move(r_field)));\n+\n+      left_keys.push_back(FieldRef(l_name));\n+      right_keys.push_back(FieldRef(r_name));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"lp\" + std::to_string(i);\n+      DCHECK_OK(l_schema_builder.AddField(field(name, settings.probe_payload_types[i])));\n+    }\n+\n+    for (size_t i = 0; i < settings.build_payload_types.size(); i++) {\n+      std::string name = \"rp\" + std::to_string(i);\n+      DCHECK_OK(r_schema_builder.AddField(field(name, settings.build_payload_types[i])));\n+    }\n+\n+    auto l_schema = *l_schema_builder.Finish();\n+    auto r_schema = *r_schema_builder.Finish();\n+\n+    l_batches_ =\n+        MakeRandomBatches(l_schema, settings.num_probe_batches, settings.batch_size);\n+    r_batches_ =\n+        MakeRandomBatches(r_schema, settings.num_build_batches, settings.batch_size);\n+\n+    stats_.num_probe_rows = settings.num_probe_batches * settings.batch_size;\n+\n+    ctx_ = arrow::internal::make_unique<ExecContext>(\n+        default_memory_pool(),\n+        is_parallel ? arrow::internal::GetCpuThreadPool() : nullptr);\n+\n+    schema_mgr_ = arrow::internal::make_unique<HashJoinSchema>();\n+    Expression filter = literal(true);\n+    DCHECK_OK(schema_mgr_->Init(settings.join_type, *l_batches_.schema, left_keys,\n+                                *r_batches_.schema, right_keys, filter, \"l_\", \"r_\"));\n+\n+    join_ = *HashJoinImpl::MakeBasic();\n+\n+    omp_set_num_threads(settings.num_threads);\n+    auto schedule_callback = [](std::function<Status(size_t)> func) -> Status {\n+#pragma omp task\n+      { DCHECK_OK(func(omp_get_thread_num())); }\n+      return Status::OK();\n+    };\n+\n+    DCHECK_OK(join_->Init(\n+        ctx_.get(), settings.join_type, !is_parallel /* use_sync_execution*/,\n+        settings.num_threads, schema_mgr_.get(), {JoinKeyCmp::EQ}, std::move(filter),\n+        [](ExecBatch) {}, [](int64_t x) {}, schedule_callback));\n+  }\n+\n+  void RunJoin() {\n+    double nanos = 0;\n+#pragma omp parallel reduction(+ : nanos)\n+    {\n+      auto start = std::chrono::high_resolution_clock::now();\n+      int tid = omp_get_thread_num();\n+#pragma omp for nowait\n+      for (auto batch : r_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 1 /* side */, batch));\n+#pragma omp for nowait\n+      for (auto batch : l_batches_.batches)\n+        DCHECK_OK(join_->InputReceived(tid, 0 /* side */, batch));\n+\n+#pragma omp barrier\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 1)); }\n+\n+#pragma omp single nowait\n+      { DCHECK_OK(join_->InputFinished(tid, /* side */ 0)); }\n+      std::chrono::duration<double, std::nano> elapsed =\n+          std::chrono::high_resolution_clock::now() - start;\n+      nanos += elapsed.count();\n+    }\n+    stats_.total_nanoseconds = nanos;\n+  }\n+\n+  ThreadIndexer thread_indexer_;\n+  BatchesWithSchema l_batches_;\n+  BatchesWithSchema r_batches_;\n+  std::unique_ptr<HashJoinSchema> schema_mgr_;\n+  std::unique_ptr<HashJoinImpl> join_;\n+  std::unique_ptr<ExecContext> ctx_;\n+\n+  struct {\n+    double total_nanoseconds;\n+    uint64_t num_probe_rows;\n+  } stats_;\n+};\n+\n+static void HashJoinBasicBenchmarkImpl(benchmark::State& st,\n+                                       BenchmarkSettings& settings) {\n+  JoinBenchmark bm(settings);\n+  double total_nanos = 0;\n+  uint64_t total_rows = 0;\n+  for (auto _ : st) {\n+    bm.RunJoin();\n+    total_nanos += bm.stats_.total_nanoseconds;\n+    total_rows += bm.stats_.num_probe_rows;\n+  }\n+  st.counters[\"ns/row\"] = total_nanos / total_rows;\n\nReview comment:\n       I agree you'd want a cost that is summed across all threads.  [`MeasureProcessCPUTime`](https://github.com/google/benchmark/blob/main/docs/user_guide.md#cpu-timers) should address that.  However, if that doesn't play nicely with OpenMP for some reason then this approach is fine.\r\n   \r\n   I don't see why this requires a time instead of a rate.  8.3M rows/s is still clearly worse than 14.3M rows/s\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-13T21:20:21.066+0000",
                    "updated": "2021-12-13T21:20:21.066+0000",
                    "started": "2021-12-13T21:20:21.066+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "695363",
                    "issueId": "13408535"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/worklog/695365",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11876:\nURL: https://github.com/apache/arrow/pull/11876#discussion_r768131154\n\n\n\n##########\nFile path: cpp/src/arrow/compute/exec/hash_join_benchmark.cc\n##########\n@@ -0,0 +1,425 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/api.h\"\n+#include \"arrow/compute/exec/hash_join.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/compute/exec/util.h\"\n+#include \"arrow/compute/kernels/row_encoder.h\"\n+#include \"arrow/compute/kernels/test_util.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/testing/matchers.h\"\n+#include \"arrow/testing/random.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/make_unique.h\"\n+#include \"arrow/util/pcg_random.h\"\n+#include \"arrow/util/thread_pool.h\"\n+\n+#include <cstdint>\n+#include <cstdio>\n+#include <memory>\n+\n+#include <omp.h>\n+\n+namespace arrow {\n+namespace compute {\n+struct BenchmarkSettings {\n+  int num_threads = 1;\n+  JoinType join_type = JoinType::INNER;\n+  int batch_size = 1024;\n+  int num_build_batches = 32;\n+  int num_probe_batches = 32 * 16;\n+  std::vector<std::shared_ptr<DataType>> key_types = {int32()};\n+  std::vector<std::shared_ptr<DataType>> build_payload_types = {};\n+  std::vector<std::shared_ptr<DataType>> probe_payload_types = {};\n+\n+  double null_percentage = 0.0;\n+  double cardinality = 1.0;  // Proportion of distinct keys in build side\n+  double selectivity = 1.0;  // Probability of a match for a given row\n\nReview comment:\n       Thank you for the explanation.  I'll withdraw this point :+1: \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-12-13T21:21:36.734+0000",
                    "updated": "2021-12-13T21:21:36.734+0000",
                    "started": "2021-12-13T21:21:36.734+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "695365",
                    "issueId": "13408535"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 34200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@379facf9[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1040651a[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7511d620[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@66ea152d[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@45985382[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6074076d[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1baf6d95[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@2dda40b0[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2a5912ca[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@6a563783[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@a753c99[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@75d532a7[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 34200,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Jan 13 02:36:09 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-01-13T02:36:09.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-14479/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2021-10-26T19:01:48.000+0000",
        "updated": "2022-01-14T04:11:16.000+0000",
        "timeoriginalestimate": null,
        "description": "Implement a series of microbenchmarks giving a good picture of the performance of hash join implemented in Arrow across different set of dimensions.\r\nCompare the performance against some other product(s).\r\nAdd scripts for generating useful visual reports giving a good picture of the costs of hash join.\r\n\r\nExamples of dimensions to explore in microbenchmarks:\r\n * number of duplicate keys on build side\r\n * relative size of build side to probe side\r\n * selectivity of the join\r\n * number of key columns\r\n * number of payload columns\r\n * filtering performance for semi- and anti- joins\r\n * dense integer key vs sparse integer key vs string key\r\n * build size\r\n * scaling of build, filtering, probe\r\n * inner vs left outer, inner vs right outer\r\n * left semi vs right semi, left anti vs right anti, left outer vs right outer\r\n * non-uniform key distribution\r\n * monotonic key values in input, partitioned key values in input (with and without per batch min-max metadata)\r\n * chain of multiple hash joins\r\n * overhead of Bloom filter for non-selective Bloom filter",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "9.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 34200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Compute] Hash Join microbenchmarks",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/comment/17451018",
                    "id": "17451018",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
                        "name": "michalno",
                        "key": "michalno",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Michal Nowakiewicz",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "h1. Dimensions\r\n\r\nBelow is the list of useful dimensions for hash join performance testing.\r\n\r\nWe would like to have one test specifically targeting each of these dimensions. At the end of the description of each of the dimensions below there may be a note suggesting how to combine this dimension with other related dimensions for multi-dimensional performance analysis. We can roughly assume that exploration of multi-dimensional space with up to 3 dimensions would mean producing one graph for each value of the dimension with the smallest cardinality, with one curve for each value of the second smallest cardinality dimension, using the highest cardinality dimension as x axis.\r\nh2. 1. Size of the hash table\r\n\r\nSize of the hash table can be measured in bytes or in the number of inserted elements (either rows or unique keys on build side). Different implementations can use different organization of data in hash tables and related data structures and because of that produce different sizes of these data structures for the same set of input rows. It seems reasonable to use the number of inserted rows as the input parameter for benchmarks and size of memory used as the output of measurement.\r\n\r\nMeasuring performance for varying size of the hash table is the fundamental test of the core hash table implementation. Going from tens to millions of inserted items in the hash table, we can observe the impact of various types of CPU cache misses on the performance. The graph should show performance dropping at the points where each type of CPU cache becomes smaller than what is required for hash table data. The exact input value point where it happens depends on the organization of data in the hash table and may vary from one implementation to another (some implementations may for instance use light-weight compression of data in the hash table to move these points further to the right on the graph).\u00a0\r\n\r\nThe extremes on both sides of this graph are of particular interest. Testing with hash tables fitting into CPU L1 cache takes away the cost of memory access and verifies the implementation of things like: hashing, traversing hash table, fetching, transforming and moving data from hash table. Testing with a hash table filling a significant chunk of all available memory verifies the scenario when the main bottleneck by far is loading a cache line from main memory. In this case, techniques like using large/huge pages, memory prefetching, partitioning before accessing hash tables, play a significant role in achieving good performance despite the fact that the same techniques would hurt the performance on small hash tables. Another interesting data point is the throughput in terms of bytes per second output by hash join in that scenario. What makes it interesting is that this number can often be similar or even worse (at least for a single-threaded hash join) than the SSD storage read/write bandwidth. What it means is that for the largest hash table, the implementation that uses spill-over to disk storage may not be much worse than in-memory processing and there may be a point where the two performance lines meet (a point defined by the hash table size combined with the number of processing threads, at which there is no benefit to fully in-memory processing in terms of execution time).\r\nh2. 2. Data types\r\n\r\nAnother interesting dimension is data types and number of key columns. Hashing, storing of keys in a hash table, looking up keys in the hash table is typically much different between fixed-length data types (e.g. integer keys) and varying-length data types (e.g. string keys). There are optimizations available uniquely for integer keys from a dense domain (range of key values comparable to number of distinct keys).\u00a0\r\n\r\nTypically the number of key columns is small (single digit). There are some interesting performance questions related to the number of keys. An example would be comparing performance on 4x int64_t columns to performance on a 1x 32B binary column. Since there is an easy way to transform data from the first case to the second case, a large difference in performance could be a sign of a problem with implementation for one of these cases. Similar scenario for strings could involve comparing 4x strings having from 0 to 16 characters each to a 1x string having from 0 to 64 characters.\r\n\r\nCombine with 1.\r\nh2. 3. Selectivity\r\n\r\nOne of the functions of the hash join (for semi or inner join) is to remove rows on the probe side with no matches on the build side. Hash join may choose for instance to build a Bloom filter for keys on the build side to quickly eliminate such rows on the probe side, providing a fast membership test but with a small probability of false positives. It may also be interesting to compare the filtering performance of semi hash join to that of in-list filter, since both implement roughly the same functionality.\r\n\r\nFiltering performance of hash join mostly depends on two factors:\r\n\r\na) number of distinct keys on build side (or number of inserted rows on build side for some implementations, which may be different in case of duplicate keys);\r\n\r\nb) probability of accepting a key on probe side (selectivity).\r\n\r\nThe first factor affects the cost of a single filter query, while the second affects the relative portion of processing time spent doing post-filter tasks, like hash table lookups and materialization of matching rows from build side.\r\n\r\nIncluded in the join filtering performance test should be a comparison of semi-join to anti-semi-join. Side by side view of the results obtained for both these join types when the selectivities are the same is interesting. On one hand, it seems that anti-join could be implemented just the same way as semi-join just with filter results negated. On the other hand, there are some important differences between these two cases, e.g. semi-join can use Bloom filters (with false positives) for fast elimination of rows, while anti-join cannot (Bloom filter would provide false negatives in such a case).\u00a0\r\n\r\nCombine with 1. and 2.\r\nh2. 4. Join types\r\n\r\nThere are 8 basic types of join: left/right semi, left/right anti, inner, left/right outer and full outer. The processing pipeline for each of them is slightly different with a different subset of required steps. Join filtering tests will cover evaluation of semi and anti variants, basic tests will be based on inner join, which leaves outer joins as missing area for performance evaluation. Full outer join combines the unique steps of left and right outer joins, so it should be enough to test left and right outer joins separately to get a good picture of performance of hash join steps unique for outer joins.\r\n\r\n\u00a0\r\n\r\nCombine with 1. and 3.\r\nh2. 5. Number of matches\r\n\r\nThe work required to process many-to-many joins may present unique challenges that are not present in case of many-to-one joins. For instance, the possibility of having multiple matches for an input row on the probe side means that we may need to produce multiple copies of that row - one for each match in the hash table. We may also need to traverse chains of rows stored in the hash table for a specific single key in order to retrieve payloads from the build side of the join for all matching rows.\u00a0\r\n\r\n\u00a0\r\n\r\nOf particular interest is looking at the average number of matches in the context of inequality joins. Hash join can perform a join operation with a predicate that mixes key equalities with key inequalities. The simplest implementation uses a hash table for equalities and then traverses potentially many matches coming from it, evaluating inequalities for each of them. The usefulness of such an implementation depends on the cost of traversal of chains of matches for a given key and materialization of their data for the purpose of residual predicate evaluation. It may be acceptable for high selectivity residual predicates (high percentage of candidate matching rows pass the predicate) but not for low selectivity ones (most of the matching rows are false positives rejected by subsequent inequality tests).\r\n\r\n\u00a0\r\n\r\nCombine with 1.\r\nh2. 6. Payload size\r\n\r\nSize of payload columns affects the cost of data movement when partitioning, copying or fetching rows from a hash table. It seems reasonable to look at varying payload sizes in the range of perhaps 0 to 100 bytes.\u00a0\r\n\r\n\u00a0\r\n\r\nCombine with 1. and 5.\r\nh2. 7. Degree of parallelism\r\n\r\nProbe side should scale very well with increasing number of executing threads, since (almost) all data structures, including the hash table, are read-only during probe side processing and do not require any synchronization between the threads. Also, all threads share the same read-only copy of data, which means that they use CPU cache during probe side processing in an efficient way (without competing needs across threads executing hash join together).\u00a0\r\n\r\n\u00a0\r\n\r\nBuild side is of particular interest with respect to degree of parallelism, since the hash table build process is not trivially parallelizable.\r\n\r\n\u00a0\r\n\r\nCombine with: 1. and 2.\r\nh2. 8. Dictionaries\r\n\r\nArrow data format supports dictionary encoded values (there is an array of values called a dictionary and another array storing only integer ids pointing to values in the dictionary). There is an opportunity to process data faster in hash join in the presence of dictionary encoded key columns, since a dictionary already accomplishes some of the work that hash join needs to do when mapping duplicate keys to the same hash table entry. The most meaningful scenario for hash join involves normalized dictionaries - dictionaries with only unique values. It is interesting to compare hash join performance with the same key column when using a normalized dictionary and when not using it. There are 4 interesting cases: no dictionaries, dictionary on build side but not on probe side, dictionary on probe side but not on build side, (different) dictionaries on both sides.\r\n\r\n\u00a0\r\n\r\nCombine with 1. and 2.\r\nh2. 9. [Optional] Distribution of key frequencies\r\n\r\nTests involving dimensions above should be performed on key columns with uniform distribution for most meaningful results. Despite that, the real-world data often does not follow a uniform distribution and is closer to some form of exponential distribution function. Although it is not a common thing to be implemented, it is possible to add to hash join performance optimizations specifically related to different keys having much different frequencies on the probe side. Keeping most frequent keys and their payloads together in memory should change the cache hit ratios in case of hash tables larger than the CPU cache.\r\n\r\n\u00a0\r\n\r\nCombine with 1.\r\nh1. Separating build side and probe side costs\r\n\r\nIn the course of hash join processing, typically processing of build side and probe side of the join happens in separate phases, e.g. join starts with hash table build operation that involves only the build side, then switches to hash table lookups for all rows on the probe side, and then finally optionally scans the hash table (outputting either hash table rows with any matches or with no matches). Most dimensions of hash join performance testing mentioned in this document affect both sides of the join, but the challenges for build side and probe side can be much different. When testing, it is easy to vary the relative size (in number of rows) of build side vs probe side. Generating 10x more rows on the probe side will make almost all of build side processing overshadowed by the probe side processing cost. Symmetrically, testing with 10x less rows on the probe side will mostly show only the build side processing costs. There is no need for varying relative sizes of both sides of the hash join between two extremes, since the costs in between should with high probability just follow a linear combination of the costs for the extremes.\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=michalno",
                        "name": "michalno",
                        "key": "michalno",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Michal Nowakiewicz",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2021-11-30T10:17:56.878+0000",
                    "updated": "2021-11-30T10:17:56.878+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13408535/comment/17475062",
                    "id": "17475062",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 11876\n[https://github.com/apache/arrow/pull/11876]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-01-13T02:36:09.969+0000",
                    "updated": "2022-01-13T02:36:09.969+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z0w6mg:",
        "customfield_12314139": null
    }
}