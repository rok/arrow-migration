{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13141283",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283",
    "key": "ARROW-2229",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12349493",
                "id": "12349493",
                "description": "",
                "name": "4.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-04-26"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12613734",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12613734",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13361039",
                    "key": "ARROW-11787",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13361039",
                    "fields": {
                        "summary": "[R] Implement write csv",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=emkornfield",
            "name": "emkornfield",
            "key": "emkornfield",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Micah Kornfield",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=fangandma",
            "name": "fangandma",
            "key": "fangandma",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Jun",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=fangandma",
            "name": "fangandma",
            "key": "fangandma",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Jun",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 28800,
            "total": 28800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 28800,
            "total": 28800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2229/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 48,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/552839",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield opened a new pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504\n\n\n   This offers possibly performance naive CSV writer with\r\n   limited options to keep the initial PR down.\r\n   \r\n   Obvious potential improvements to this approach\r\n   are:\r\n   \r\n   - Smarter casts for dictionaries\r\n   - Arena allocation for intermediate cast results\r\n   \r\n   The implementation also means that for all primitive type\r\n   support we might have to fill in gaps in our cast function.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-16T07:36:54.799+0000",
                    "updated": "2021-02-16T07:36:54.799+0000",
                    "started": "2021-02-16T07:36:54.799+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "552839",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/552840",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#issuecomment-779647673\n\n\n   https://issues.apache.org/jira/browse/ARROW-2229\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-16T07:37:08.281+0000",
                    "updated": "2021-02-16T07:37:08.281+0000",
                    "started": "2021-02-16T07:37:08.281+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "552840",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/552841",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r576604027\n\n\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,397 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine how the size its contents will take in the CSV. For\n\nReview comment:\n       ```suggestion\r\n   // scanning each column to determine the size of its contents when rendered as a string in CSV. For\r\n   ```\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-16T07:38:11.369+0000",
                    "updated": "2021-02-16T07:38:11.369+0000",
                    "started": "2021-02-16T07:38:11.369+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "552841",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/552843",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#issuecomment-779650118\n\n\n    @jorisvandenbossche @pitrou would one or both of you mind reviewing?\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-16T07:42:47.884+0000",
                    "updated": "2021-02-16T07:42:47.884+0000",
                    "started": "2021-02-16T07:42:47.883+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "552843",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/552847",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield edited a comment on pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#issuecomment-779650118\n\n\n    @jorisvandenbossche @pitrou would one or both of you mind reviewing?  It appears CSV is part of the minimal build but compute (casts are not).  I was thinking of doing an ifdef and raise not implemented in that case.  Does that seem like a reasonable approach?\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-16T07:57:05.464+0000",
                    "updated": "2021-02-16T07:57:05.464+0000",
                    "started": "2021-02-16T07:57:05.463+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "552847",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553122",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577008765\n\n\n\n##########\nFile path: python/pyarrow/_csv.pyx\n##########\n@@ -762,3 +764,53 @@ def open_csv(input_file, read_options=None, parse_options=None,\n                  move(c_convert_options),\n                  maybe_unbox_memory_pool(memory_pool))\n     return reader\n+\n+\n+def write_csv(output_file, data, include_header=True,\n+              MemoryPool memory_pool=None):\n+    \"\"\"\n+\n+    Parameters\n+    ----------\n+    output_file: string, path, pyarrow.OutputStream or file-like object\n+        The location of CSV data.\n+    data: The data to write.\n+        Either a pyarrow.RecordBatch or a pyarrow.Table\n+    include_header: bool, optional\n+        Include header based on schema field names when writing out\n+        (defaults to true).\n+    memory_pool: MemoryPool, optional\n+        Pool to allocate Table memory from\n\nReview comment:\n       Hmm... which table memory?\n\n##########\nFile path: cpp/src/arrow/csv/writer.h\n##########\n@@ -0,0 +1,47 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"arrow/csv/options.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// Functionality for converting Arrow data to Comma separated value text.\n+// This library supports all primitive types that can be cast to a StringArrays.\n+// It applies to following formatting rules:\n+//  - For non-binary types no quotes surround values.  Nulls are represented as the empty\n+//  string.\n+//  - For binary types all non-null data is quoted (and quotes within data are escaped\n+//  with an additional quote).\n+//    Null values are empty and unquoted.\n+//  - LF (\\n) is always used as a line ending.\n+\n+/// \\brief Converts table to a CSV and writes the results to output.\n+/// Experimental\n+ARROW_EXPORT Status WriteCsv(const Table& table, const WriteOptions& options,\n+                             MemoryPool* pool, arrow::io::OutputStream* output);\n+/// \\brief Converts batch to CSV and writes the results to output.\n+/// Experimental\n+ARROW_EXPORT Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                             MemoryPool* pool, arrow::io::OutputStream* output);\n\nReview comment:\n       API-wise, it would sound more logical to expose a `CSVWriter` that takes a schema and then allows to write tables and batches in an interative fashion, no?\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n\nReview comment:\n       Can you put all member declarations next to each other?\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n+  }\n+\n+  Status WriteHeader(io::OutputStream* out) {\n+    RETURN_NOT_OK(data_buffer_->Resize(CalculateHeaderSize(), /*shrink_to_fit=*/false));\n+    char* next = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      *next++ = '\"';\n+      next = Escape(schema_->field(col)->name(), next);\n+      *next++ = '\"';\n+      *next++ = ',';\n+    }\n+    next--;\n+    *next = '\\n';\n+    return out->Write(data_buffer_);\n+  }\n+\n+  Status TranslateMininalBatch(const RecordBatch& batch) {\n+    if (batch.num_rows() == 0) {\n+      return Status::OK();\n+    }\n+    std::vector<int32_t, arrow::stl::allocator<int32_t>> offsets(\n+        batch.num_rows(), 0, arrow::stl::allocator<int32_t>(pool_));\n+\n+    // Calculate relative offsets for each row (excluding delimiters)\n+    for (size_t col = 0; col < column_populators_.size(); col++) {\n+      RETURN_NOT_OK(\n+          column_populators_[col]->UpdateRowLengths(*batch.column(col), offsets.data()));\n+    }\n+    // Calculate cumulalative offsets for each row (including delimiters).\n+    offsets[0] += batch.num_columns();\n+    for (int64_t row = 1; row < batch.num_rows(); row++) {\n+      offsets[row] += offsets[row - 1] + /*delimiter lengths*/ batch.num_columns();\n+    }\n+    // Resize the target buffer to required size. We assume batch to batch sizes\n+    // should be pretty close so don't shrink the buffer to avoid allocation churn.\n+    RETURN_NOT_OK(data_buffer_->Resize(offsets.back(), /*shrink_to_fit=*/false));\n+\n+    // Calculate pointers to the start of each row.\n+    row_positions_.resize(batch.num_rows());\n+    row_positions_[0] = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (size_t row = 1; row < row_positions_.size(); row++) {\n+      row_positions_[row] =\n+          reinterpret_cast<char*>(data_buffer_->mutable_data()) + offsets[row - 1];\n\nReview comment:\n       I'm curious: is it useful to compute a vector of `char*` positions rather than reuse the offsets array?\n\n##########\nFile path: python/pyarrow/_csv.pyx\n##########\n@@ -762,3 +764,53 @@ def open_csv(input_file, read_options=None, parse_options=None,\n                  move(c_convert_options),\n                  maybe_unbox_memory_pool(memory_pool))\n     return reader\n+\n+\n+def write_csv(output_file, data, include_header=True,\n+              MemoryPool memory_pool=None):\n+    \"\"\"\n+\n+    Parameters\n+    ----------\n+    output_file: string, path, pyarrow.OutputStream or file-like object\n+        The location of CSV data.\n+    data: The data to write.\n+        Either a pyarrow.RecordBatch or a pyarrow.Table\n+    include_header: bool, optional\n+        Include header based on schema field names when writing out\n+        (defaults to true).\n\nReview comment:\n       I would rather make the API more consistent and have the user pass a `WriteOptions` instance here.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n\nReview comment:\n       Nit, but I think we spell \"CSV\" everywhere currently.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n\nReview comment:\n       Looks like `extra_chars` could be replaced with a `vector<bool>` indicated whether a given value requires quoting?\r\n   Then `Escape` can tell you the ending out pointer.\n\n##########\nFile path: cpp/src/arrow/record_batch.h\n##########\n@@ -163,6 +164,10 @@ class ARROW_EXPORT RecordBatch {\n   /// \\return new record batch\n   virtual std::shared_ptr<RecordBatch> Slice(int64_t offset, int64_t length) const = 0;\n \n+  // Returns an iterator for maximum slice size over this record batch.  The Iterator\n+  // Becomes invalid when this object goes out of scope.\n+  RecordBatchIterator SliceIterator(int64_t slice_size) const;\n\nReview comment:\n       Wouldn't it be more consistent with the rest of the RecordBatch API to use `RecordBatchReader`?\n\n##########\nFile path: cpp/src/arrow/record_batch.cc\n##########\n@@ -37,6 +37,26 @@\n \n namespace arrow {\n \n+namespace {\n+// If there will only be one slice returned it is cheaper to just return the original\n+// RecordBatch (no overhead from vector and std::shared_ptr copying on underlying arrays).\n+\n+struct SliceIteratorFunctor {\n+  Result<std::shared_ptr<RecordBatch>> Next() {\n+    if (current_offset < batch->num_rows()) {\n+      std::shared_ptr<RecordBatch> next = batch->Slice(current_offset, slice_size);\n+      current_offset += slice_size;\n+      return next;\n+    }\n+    return IterationTraits<std::shared_ptr<RecordBatch>>::End();\n+  }\n+  const RecordBatch* const batch;\n\nReview comment:\n       Hmm... this means the iterator will fail if the user doesn't keep the original batch alive. Do we really gain anything by not taking a `shared_ptr` here?\n\n##########\nFile path: cpp/src/arrow/csv/writer.h\n##########\n@@ -0,0 +1,47 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include \"arrow/csv/options.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/table.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// Functionality for converting Arrow data to Comma separated value text.\n+// This library supports all primitive types that can be cast to a StringArrays.\n+// It applies to following formatting rules:\n+//  - For non-binary types no quotes surround values.  Nulls are represented as the empty\n+//  string.\n\nReview comment:\n       I think that very quickly people will ask for the null string to be configurable.\n\n##########\nFile path: cpp/src/arrow/csv/writer_test.cc\n##########\n@@ -0,0 +1,119 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/io/memory.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_fwd.h\"\n+\n+namespace arrow {\n+namespace csv {\n+\n+struct TestParams {\n+  std::shared_ptr<RecordBatch> record_batch;\n+  WriteOptions options;\n+  std::string expected_output;\n+};\n+\n+WriteOptions DefaultTestOptions(bool include_header) {\n+  WriteOptions options;\n+  options.batch_size = 5;\n+  options.include_header = include_header;\n+  return options;\n+}\n+\n+std::vector<TestParams> GenerateTestCases() {\n\nReview comment:\n       I think this approach won't scale when we'll want to test additional datatypes. I would suggest testing the different types explicitly in separate methods.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n\nReview comment:\n       Can you add newlines around method definitions?\n\n##########\nFile path: cpp/src/arrow/csv/writer_test.cc\n##########\n@@ -0,0 +1,119 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/io/memory.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+#include \"arrow/type_fwd.h\"\n+\n+namespace arrow {\n+namespace csv {\n+\n+struct TestParams {\n+  std::shared_ptr<RecordBatch> record_batch;\n+  WriteOptions options;\n+  std::string expected_output;\n+};\n+\n+WriteOptions DefaultTestOptions(bool include_header) {\n+  WriteOptions options;\n+  options.batch_size = 5;\n+  options.include_header = include_header;\n+  return options;\n+}\n+\n+std::vector<TestParams> GenerateTestCases() {\n+  auto abc_schema = schema({\n+      {field(\"a\", uint64())},\n+      {field(\"b\\\"\", utf8())},\n+      {field(\"c \", int32())},\n+  });\n+  auto empty_batch =\n+      RecordBatch::Make(abc_schema, /*num_rows=*/0,\n+                        {\n+                            ArrayFromJSON(abc_schema->field(0)->type(), \"[]\"),\n+                            ArrayFromJSON(abc_schema->field(1)->type(), \"[]\"),\n+                            ArrayFromJSON(abc_schema->field(2)->type(), \"[]\"),\n+                        });\n+  auto populated_batch = RecordBatchFromJSON(abc_schema, R\"([{\"a\": 1, \"c \": -1},\n+                                                         { \"a\": 1, \"b\\\"\": \"abc\\\"efg\", \"c \": 2324},\n+                                                         { \"b\\\"\": \"abcd\", \"c \": 5467},\n+                                                         { },\n+                                                         { \"a\": 546, \"b\\\"\": \"\", \"c \": 517 },\n+                                                         { \"a\": 124, \"b\\\"\": \"a\\\"\\\"b\\\"\" }])\");\n+  std::string expected_without_header = std::string(\"1,,-1\") + \"\\n\" +     // line 1\n+                                        +R\"(1,\"abc\"\"efg\",2324)\" + \"\\n\" +  // line 2\n+                                        R\"(,\"abcd\",5467)\" + \"\\n\" +        // line 3\n+                                        R\"(,,)\" + \"\\n\" +                  // line 4\n+                                        R\"(546,\"\",517)\" + \"\\n\" +          // line 5\n+                                        R\"(124,\"a\"\"\"\"b\"\"\",)\" + \"\\n\";      // line 6\n+  std::string expected_header = std::string(R\"(\"a\",\"b\"\"\",\"c \")\") + \"\\n\";\n+\n+  return std::vector<TestParams>{\n+      {empty_batch, DefaultTestOptions(/*header=*/false), \"\"},\n+      {empty_batch, DefaultTestOptions(/*header=*/true), expected_header},\n+      {populated_batch, DefaultTestOptions(/*header=*/false), expected_without_header},\n+      {populated_batch, DefaultTestOptions(/*header=*/true),\n+       expected_header + expected_without_header}};\n+}\n+\n+class TestWriteCsv : public ::testing::TestWithParam<TestParams> {};\n+\n+TEST_P(TestWriteCsv, TestWrite) {\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<io::BufferOutputStream> out,\n+                       io::BufferOutputStream::Create());\n+  WriteOptions options = GetParam().options;\n+\n+  ASSERT_OK(\n+      WriteCsv(*GetParam().record_batch, options, default_memory_pool(), out.get()));\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<Buffer> buffer, out->Finish());\n+  EXPECT_EQ(std::string(reinterpret_cast<const char*>(buffer->data()), buffer->size()),\n+            GetParam().expected_output);\n+  ASSERT_OK(out->Reset());\n+\n+  // Batch size shouldn't matter.\n+  options.batch_size /= 2;\n+  ASSERT_OK(\n+      WriteCsv(*GetParam().record_batch, options, default_memory_pool(), out.get()));\n+  ASSERT_OK_AND_ASSIGN(buffer, out->Finish());\n+  EXPECT_EQ(std::string(reinterpret_cast<const char*>(buffer->data()), buffer->size()),\n+            GetParam().expected_output);\n+  ASSERT_OK(out->Reset());\n+\n+  // Table and Record batch should work identically.\n+  ASSERT_OK_AND_ASSIGN(std::shared_ptr<Table> table,\n+                       Table::FromRecordBatches({GetParam().record_batch}));\n+  ASSERT_OK(WriteCsv(*table, options, default_memory_pool(), out.get()));\n+  ASSERT_OK_AND_ASSIGN(buffer, out->Finish());\n+  EXPECT_EQ(std::string(reinterpret_cast<const char*>(buffer->data()), buffer->size()),\n+            GetParam().expected_output);\n+  ASSERT_OK(out->Reset());\n\nReview comment:\n       You probably want to avoid copy/paste and factor out the boilerplate in dedicated test functions/methods.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n\nReview comment:\n       \"Minimal\"?\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n\nReview comment:\n       You can probably use a fallback `Visit` method instead of spelling out the type condition above.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n\nReview comment:\n       `3` is because of quoting and delimiters?\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n+  }\n+\n+  Status WriteHeader(io::OutputStream* out) {\n+    RETURN_NOT_OK(data_buffer_->Resize(CalculateHeaderSize(), /*shrink_to_fit=*/false));\n+    char* next = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      *next++ = '\"';\n+      next = Escape(schema_->field(col)->name(), next);\n+      *next++ = '\"';\n+      *next++ = ',';\n+    }\n+    next--;\n+    *next = '\\n';\n+    return out->Write(data_buffer_);\n\nReview comment:\n       `DCHECK` that `next` corresponds to the buffer end?\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n\nReview comment:\n       Interesting approach. It may also allow parallelizing conversion if we want to go that way.\n\n##########\nFile path: cpp/src/arrow/record_batch.cc\n##########\n@@ -37,6 +37,26 @@\n \n namespace arrow {\n \n+namespace {\n+// If there will only be one slice returned it is cheaper to just return the original\n+// RecordBatch (no overhead from vector and std::shared_ptr copying on underlying arrays).\n\nReview comment:\n       I don't understand this comment: where is the optimization which just returns the original RecordBatch?\n\n##########\nFile path: cpp/src/arrow/csv/options.h\n##########\n@@ -137,5 +137,13 @@ struct ARROW_EXPORT ReadOptions {\n   static ReadOptions Defaults();\n };\n \n+/// Experimental\n+struct WriteOptions {\n+  bool include_header = true;\n+  // The writer processes batches of rows together.  This is the\n+  // maximum number of rows processed at a time.\n+  int32_t batch_size = 1024;\n\nReview comment:\n       Intuitively, this seems a bit low, but we can tune it later.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n\nReview comment:\n       `kQuoteCount` is `int64_t` apparently.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n+  }\n+\n+  Status WriteHeader(io::OutputStream* out) {\n+    RETURN_NOT_OK(data_buffer_->Resize(CalculateHeaderSize(), /*shrink_to_fit=*/false));\n+    char* next = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      *next++ = '\"';\n+      next = Escape(schema_->field(col)->name(), next);\n+      *next++ = '\"';\n+      *next++ = ',';\n+    }\n+    next--;\n+    *next = '\\n';\n+    return out->Write(data_buffer_);\n+  }\n+\n+  Status TranslateMininalBatch(const RecordBatch& batch) {\n+    if (batch.num_rows() == 0) {\n+      return Status::OK();\n+    }\n+    std::vector<int32_t, arrow::stl::allocator<int32_t>> offsets(\n+        batch.num_rows(), 0, arrow::stl::allocator<int32_t>(pool_));\n+\n+    // Calculate relative offsets for each row (excluding delimiters)\n+    for (size_t col = 0; col < column_populators_.size(); col++) {\n+      RETURN_NOT_OK(\n+          column_populators_[col]->UpdateRowLengths(*batch.column(col), offsets.data()));\n+    }\n+    // Calculate cumulalative offsets for each row (including delimiters).\n+    offsets[0] += batch.num_columns();\n+    for (int64_t row = 1; row < batch.num_rows(); row++) {\n+      offsets[row] += offsets[row - 1] + /*delimiter lengths*/ batch.num_columns();\n+    }\n+    // Resize the target buffer to required size. We assume batch to batch sizes\n+    // should be pretty close so don't shrink the buffer to avoid allocation churn.\n+    RETURN_NOT_OK(data_buffer_->Resize(offsets.back(), /*shrink_to_fit=*/false));\n+\n+    // Calculate pointers to the start of each row.\n+    row_positions_.resize(batch.num_rows());\n+    row_positions_[0] = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (size_t row = 1; row < row_positions_.size(); row++) {\n+      row_positions_[row] =\n+          reinterpret_cast<char*>(data_buffer_->mutable_data()) + offsets[row - 1];\n+    }\n+    // Use the pointers to populate all of the data.\n+    for (const auto& populator : column_populators_) {\n+      populator->PopulateColumns(row_positions_.data());\n+    }\n\nReview comment:\n       `DCHECK` that `row_positions_.back()` corresponds to the end of the buffer?\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n+  }\n+\n+  Status WriteHeader(io::OutputStream* out) {\n+    RETURN_NOT_OK(data_buffer_->Resize(CalculateHeaderSize(), /*shrink_to_fit=*/false));\n+    char* next = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      *next++ = '\"';\n+      next = Escape(schema_->field(col)->name(), next);\n+      *next++ = '\"';\n+      *next++ = ',';\n+    }\n+    next--;\n+    *next = '\\n';\n+    return out->Write(data_buffer_);\n+  }\n+\n+  Status TranslateMininalBatch(const RecordBatch& batch) {\n+    if (batch.num_rows() == 0) {\n+      return Status::OK();\n+    }\n+    std::vector<int32_t, arrow::stl::allocator<int32_t>> offsets(\n+        batch.num_rows(), 0, arrow::stl::allocator<int32_t>(pool_));\n+\n+    // Calculate relative offsets for each row (excluding delimiters)\n+    for (size_t col = 0; col < column_populators_.size(); col++) {\n+      RETURN_NOT_OK(\n+          column_populators_[col]->UpdateRowLengths(*batch.column(col), offsets.data()));\n+    }\n+    // Calculate cumulalative offsets for each row (including delimiters).\n+    offsets[0] += batch.num_columns();\n+    for (int64_t row = 1; row < batch.num_rows(); row++) {\n+      offsets[row] += offsets[row - 1] + /*delimiter lengths*/ batch.num_columns();\n+    }\n+    // Resize the target buffer to required size. We assume batch to batch sizes\n+    // should be pretty close so don't shrink the buffer to avoid allocation churn.\n+    RETURN_NOT_OK(data_buffer_->Resize(offsets.back(), /*shrink_to_fit=*/false));\n+\n+    // Calculate pointers to the start of each row.\n+    row_positions_.resize(batch.num_rows());\n+    row_positions_[0] = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (size_t row = 1; row < row_positions_.size(); row++) {\n+      row_positions_[row] =\n+          reinterpret_cast<char*>(data_buffer_->mutable_data()) + offsets[row - 1];\n+    }\n+    // Use the pointers to populate all of the data.\n+    for (const auto& populator : column_populators_) {\n+      populator->PopulateColumns(row_positions_.data());\n+    }\n\nReview comment:\n       (even better would be to `DCHECK` that each row position is consistent with the corresponding pre-computed row length)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-16T18:31:05.434+0000",
                    "updated": "2021-02-16T18:31:05.434+0000",
                    "started": "2021-02-16T18:31:05.433+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553122",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553374",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577320416\n\n\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n\nReview comment:\n       yep :)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T04:39:25.391+0000",
                    "updated": "2021-02-17T04:39:25.391+0000",
                    "started": "2021-02-17T04:39:25.391+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553374",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553377",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577320791\n\n\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n\nReview comment:\n       included in the cast.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T04:40:44.405+0000",
                    "updated": "2021-02-17T04:40:44.405+0000",
                    "started": "2021-02-17T04:40:44.405+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553377",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553382",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577324567\n\n\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n\nReview comment:\n       yes, that is potentially simpler.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T04:53:15.847+0000",
                    "updated": "2021-02-17T04:53:15.847+0000",
                    "started": "2021-02-17T04:53:15.846+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553382",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553412",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577324654\n\n\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n\nReview comment:\n       replacing.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n+  }\n+\n+  Status WriteHeader(io::OutputStream* out) {\n+    RETURN_NOT_OK(data_buffer_->Resize(CalculateHeaderSize(), /*shrink_to_fit=*/false));\n+    char* next = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      *next++ = '\"';\n+      next = Escape(schema_->field(col)->name(), next);\n+      *next++ = '\"';\n+      *next++ = ',';\n+    }\n+    next--;\n+    *next = '\\n';\n+    return out->Write(data_buffer_);\n\nReview comment:\n       done.\n\n##########\nFile path: python/pyarrow/_csv.pyx\n##########\n@@ -762,3 +764,53 @@ def open_csv(input_file, read_options=None, parse_options=None,\n                  move(c_convert_options),\n                  maybe_unbox_memory_pool(memory_pool))\n     return reader\n+\n+\n+def write_csv(output_file, data, include_header=True,\n+              MemoryPool memory_pool=None):\n+    \"\"\"\n+\n+    Parameters\n+    ----------\n+    output_file: string, path, pyarrow.OutputStream or file-like object\n+        The location of CSV data.\n+    data: The data to write.\n+        Either a pyarrow.RecordBatch or a pyarrow.Table\n+    include_header: bool, optional\n+        Include header based on schema field names when writing out\n+        (defaults to true).\n+    memory_pool: MemoryPool, optional\n+        Pool to allocate Table memory from\n\nReview comment:\n       copy and paste bug.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n+  }\n+\n+  Status WriteHeader(io::OutputStream* out) {\n+    RETURN_NOT_OK(data_buffer_->Resize(CalculateHeaderSize(), /*shrink_to_fit=*/false));\n+    char* next = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      *next++ = '\"';\n+      next = Escape(schema_->field(col)->name(), next);\n+      *next++ = '\"';\n+      *next++ = ',';\n+    }\n+    next--;\n+    *next = '\\n';\n+    return out->Write(data_buffer_);\n+  }\n+\n+  Status TranslateMininalBatch(const RecordBatch& batch) {\n+    if (batch.num_rows() == 0) {\n+      return Status::OK();\n+    }\n+    std::vector<int32_t, arrow::stl::allocator<int32_t>> offsets(\n+        batch.num_rows(), 0, arrow::stl::allocator<int32_t>(pool_));\n+\n+    // Calculate relative offsets for each row (excluding delimiters)\n+    for (size_t col = 0; col < column_populators_.size(); col++) {\n+      RETURN_NOT_OK(\n+          column_populators_[col]->UpdateRowLengths(*batch.column(col), offsets.data()));\n+    }\n+    // Calculate cumulalative offsets for each row (including delimiters).\n+    offsets[0] += batch.num_columns();\n+    for (int64_t row = 1; row < batch.num_rows(); row++) {\n+      offsets[row] += offsets[row - 1] + /*delimiter lengths*/ batch.num_columns();\n+    }\n+    // Resize the target buffer to required size. We assume batch to batch sizes\n+    // should be pretty close so don't shrink the buffer to avoid allocation churn.\n+    RETURN_NOT_OK(data_buffer_->Resize(offsets.back(), /*shrink_to_fit=*/false));\n+\n+    // Calculate pointers to the start of each row.\n+    row_positions_.resize(batch.num_rows());\n+    row_positions_[0] = reinterpret_cast<char*>(data_buffer_->mutable_data());\n+    for (size_t row = 1; row < row_positions_.size(); row++) {\n+      row_positions_[row] =\n+          reinterpret_cast<char*>(data_buffer_->mutable_data()) + offsets[row - 1];\n\nReview comment:\n       probably not (or at least we would need profiling to say for sure): This is mostly left over from when I was thinking we might want to return Array<Utf8> in which case.  I've changed to use the offsets.\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+      RETURN_NOT_OK(reader.ReadNext(&batch));\n+    }\n+\n+    return Status::OK();\n+  }\n+\n+ private:\n+  CsvConverter(std::shared_ptr<Schema> schema,\n+               std::vector<std::unique_ptr<ColumnPopulator>> populators, MemoryPool* pool)\n+      : schema_(std::move(schema)),\n+        column_populators_(std::move(populators)),\n+        row_positions_(1024, nullptr, arrow::stl::allocator<char*>(pool)),\n+        pool_(pool) {}\n+\n+  const std::shared_ptr<Schema> schema_;\n+\n+  Status PrepareForContentsWrite(const WriteOptions& options, io::OutputStream* out) {\n+    if (data_buffer_ == nullptr) {\n+      ASSIGN_OR_RAISE(\n+          data_buffer_,\n+          AllocateResizableBuffer(\n+              options.batch_size * schema_->num_fields() * kColumnSizeGuess, pool_));\n+    }\n+    if (options.include_header) {\n+      RETURN_NOT_OK(WriteHeader(out));\n+    }\n+    return Status::OK();\n+  }\n+\n+  int64_t CalculateHeaderSize() const {\n+    int64_t header_length = 0;\n+    for (int col = 0; col < schema_->num_fields(); col++) {\n+      const std::string& col_name = schema_->field(col)->name();\n+      header_length += col_name.size();\n+      header_length += CountEscapes(col_name);\n+    }\n+    return header_length + (3 * schema_->num_fields());\n\nReview comment:\n       yes, replaced with a constexpr\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n\nReview comment:\n       yes. sorry.\n\n##########\nFile path: python/pyarrow/_csv.pyx\n##########\n@@ -762,3 +764,53 @@ def open_csv(input_file, read_options=None, parse_options=None,\n                  move(c_convert_options),\n                  maybe_unbox_memory_pool(memory_pool))\n     return reader\n+\n+\n+def write_csv(output_file, data, include_header=True,\n+              MemoryPool memory_pool=None):\n+    \"\"\"\n+\n+    Parameters\n+    ----------\n+    output_file: string, path, pyarrow.OutputStream or file-like object\n+        The location of CSV data.\n+    data: The data to write.\n+        Either a pyarrow.RecordBatch or a pyarrow.Table\n+    include_header: bool, optional\n+        Include header based on schema field names when writing out\n+        (defaults to true).\n\nReview comment:\n       done.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T06:38:38.282+0000",
                    "updated": "2021-02-17T06:38:38.282+0000",
                    "started": "2021-02-17T06:38:38.282+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553412",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553413",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577359507\n\n\n\n##########\nFile path: cpp/src/arrow/record_batch.cc\n##########\n@@ -37,6 +37,26 @@\n \n namespace arrow {\n \n+namespace {\n+// If there will only be one slice returned it is cheaper to just return the original\n+// RecordBatch (no overhead from vector and std::shared_ptr copying on underlying arrays).\n\nReview comment:\n       left over comment from when I was going to down the rabbit whole.  I've moved all this code into the writer.cc to avoid debating the best way to expose this publicly.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T06:39:21.866+0000",
                    "updated": "2021-02-17T06:39:21.866+0000",
                    "started": "2021-02-17T06:39:21.866+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553413",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553414",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577359813\n\n\n\n##########\nFile path: cpp/src/arrow/record_batch.cc\n##########\n@@ -37,6 +37,26 @@\n \n namespace arrow {\n \n+namespace {\n+// If there will only be one slice returned it is cheaper to just return the original\n+// RecordBatch (no overhead from vector and std::shared_ptr copying on underlying arrays).\n+\n+struct SliceIteratorFunctor {\n+  Result<std::shared_ptr<RecordBatch>> Next() {\n+    if (current_offset < batch->num_rows()) {\n+      std::shared_ptr<RecordBatch> next = batch->Slice(current_offset, slice_size);\n+      current_offset += slice_size;\n+      return next;\n+    }\n+    return IterationTraits<std::shared_ptr<RecordBatch>>::End();\n+  }\n+  const RecordBatch* const batch;\n\nReview comment:\n       yes, it would.  The tricky part is we can't get a shared_ptr to record batch if this is a member method.  (unless we add enable_shared_from_this).\r\n   \r\n   To avoid any contention here for now I've moved this to be an implementation detail.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T06:40:15.263+0000",
                    "updated": "2021-02-17T06:40:15.263+0000",
                    "started": "2021-02-17T06:40:15.263+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553414",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553415",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577360041\n\n\n\n##########\nFile path: cpp/src/arrow/record_batch.h\n##########\n@@ -163,6 +164,10 @@ class ARROW_EXPORT RecordBatch {\n   /// \\return new record batch\n   virtual std::shared_ptr<RecordBatch> Slice(int64_t offset, int64_t length) const = 0;\n \n+  // Returns an iterator for maximum slice size over this record batch.  The Iterator\n+  // Becomes invalid when this object goes out of scope.\n+  RecordBatchIterator SliceIterator(int64_t slice_size) const;\n\nReview comment:\n       I was guessing iterators were now preferred?  I haven't been keeping up.  But as noted above the point is moot now.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T06:40:48.273+0000",
                    "updated": "2021-02-17T06:40:48.273+0000",
                    "started": "2021-02-17T06:40:48.272+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553415",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553416",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577360104\n\n\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n\nReview comment:\n       replaced.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T06:41:01.502+0000",
                    "updated": "2021-02-17T06:41:01.502+0000",
                    "started": "2021-02-17T06:41:01.502+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553416",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553417",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#issuecomment-780342208\n\n\n   @pitrou thank you for all the comment still working through addressing them (I'll ping you again for review when it is ready).  Could you chime in if using you think the ifdef approach mentioned above to return not implemented when compute isn't available seems reasonable to you?\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T06:42:44.774+0000",
                    "updated": "2021-02-17T06:42:44.774+0000",
                    "started": "2021-02-17T06:42:44.774+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553417",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553655",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#issuecomment-780616970\n\n\n   Sorry, I hadn't seen that question. Yes, I think that raising `NotImplemented` is fine for now.\r\n   \r\n   In the future, we may want to always enable `Cast` (it's also used in `stl.h`), if that doesn't add too much to the binary sizes.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T15:03:33.235+0000",
                    "updated": "2021-02-17T15:03:33.235+0000",
                    "started": "2021-02-17T15:03:33.235+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553655",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553899",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#issuecomment-780876347\n\n\n   Cool! \r\n   \r\n   I don't have time right now to give it a more detailed review, but I quickly fetched the branch, and even for a not yet optimized first version, this is already *much* faster as the pure python pandas `to_csv` writer (in pandas only the csv reader is optimized, not the writer). \r\n   With a small example (50,000 rows, 5 columns, with floats/int/string), I get 140ms with pandas, and 20ms with this branch (in release build) which even included the conversion pandas->arrow (but that's only 2-3ms in this case). \r\n   \r\n   Few things I noticed / random thoughts:\r\n   \r\n   * When writing a column of floats that don't have decimals, no decimal point is included in the output, so it looks like an int (so eg `1` instead of `1.0`, pandas writes the latter). Not sure if we want to preserve this \"type information\" in this case.\r\n   * Pandas doesn't use quoting by default, also for string columns. I am not fully sure what makes the most sense as default option, but disabling quoting can be a follow-up enhancement. \r\n   * We don't support casting timestamps to strings (yet), so that will be a useful addition to casting to be used here\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T21:48:09.330+0000",
                    "updated": "2021-02-17T21:48:09.330+0000",
                    "started": "2021-02-17T21:48:09.329+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553899",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553900",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#issuecomment-780876754\n\n\n   > Pandas doesn't use quoting by default, also for string columns. I am not fully sure what makes the most sense as default option, but disabling quoting can be a follow-up enhancement.\r\n   \r\n   Quoting by default ensures that we can distinguish missing values and empty strings, I suppose?\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T21:48:53.378+0000",
                    "updated": "2021-02-17T21:48:53.378+0000",
                    "started": "2021-02-17T21:48:53.378+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553900",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/553904",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r577969326\n\n\n\n##########\nFile path: python/pyarrow/_csv.pyx\n##########\n@@ -762,3 +764,53 @@ def open_csv(input_file, read_options=None, parse_options=None,\n                  move(c_convert_options),\n                  maybe_unbox_memory_pool(memory_pool))\n     return reader\n+\n+\n+def write_csv(output_file, data, include_header=True,\n\nReview comment:\n       In the parquet and feather api, it's first the data and then the file name\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-17T21:50:12.991+0000",
                    "updated": "2021-02-17T21:50:12.991+0000",
                    "started": "2021-02-17T21:50:12.990+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "553904",
                    "issueId": "13141283"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/worklog/554057",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #9504:\nURL: https://github.com/apache/arrow/pull/9504#discussion_r578128924\n\n\n\n##########\nFile path: cpp/src/arrow/csv/writer.cc\n##########\n@@ -0,0 +1,398 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/csv/writer.h\"\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/io/interfaces.h\"\n+#include \"arrow/record_batch.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/result_internal.h\"\n+#include \"arrow/stl_allocator.h\"\n+#include \"arrow/util/make_unique.h\"\n+\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+namespace csv {\n+// This implementation is intentionally light on configurability to minimize the size of\n+// the initial PR. Aditional features can be added as there is demand and interest to\n+// implement them.\n+//\n+// The algorithm used here at a high level is to break RecordBatches/Tables into slices\n+// and convert each slice independently.  A slice is then converted to CSV by first\n+// scanning each column to determine the size of its contents when rendered as a string in\n+// CSV. For non-string types this requires casting the value to string (which is cached).\n+// This data is used to understand the precise length of each row and a single allocation\n+// for the final CSV data buffer. Once the final size is known each column is then\n+// iterated over again to place its contents into the CSV data buffer. The rationale for\n+// choosing this approach is it allows for reuse of the cast functionality in the compute\n+// module // and inline data visiting functionality in the core library. A performance\n+// comparison has not been done using a naive single-pass approach. This approach might\n+// still be competitive due to reduction in the number of per row branches necessary with\n+// a single pass approach. Profiling would likely yield further opportunities for\n+// optimization with this approach.\n+\n+namespace {\n+\n+// Counts the number of characters that need escaping in s.\n+int64_t CountEscapes(util::string_view s) {\n+  return static_cast<int64_t>(std::count(s.begin(), s.end(), '\"'));\n+}\n+\n+// Matching quote pair character length.\n+constexpr int64_t kQuoteCount = 2;\n+\n+// Interface for generating CSV data per column.\n+// The intended usage is to iteratively call UpdateRowLengths for a column and\n+// then PopulateColumns.\n+class ColumnPopulator {\n+ public:\n+  ColumnPopulator(MemoryPool* pool, char end_char) : end_char_(end_char), pool_(pool) {}\n+  virtual ~ColumnPopulator() = default;\n+  // Adds the number of characters each entry in data will add to to elements\n+  // in row_lengths.\n+  Status UpdateRowLengths(const Array& data, int32_t* row_lengths) {\n+    compute::ExecContext ctx(pool_);\n+    // Populators are intented to be applied to reasonably small data.  In most cases\n+    // threading overhead would not be justified.\n+    ctx.set_use_threads(false);\n+    ASSIGN_OR_RAISE(\n+        std::shared_ptr<Array> casted,\n+        compute::Cast(data, /*to_type=*/utf8(), compute::CastOptions(), &ctx));\n+    casted_array_ = internal::checked_pointer_cast<StringArray>(casted);\n+    return UpdateRowLengths(row_lengths);\n+  }\n+\n+  // Places string data onto each row in output and updates the corresponding row\n+  // row pointers in preparation for calls to other ColumnPopulators.\n+  virtual void PopulateColumns(char** output) const = 0;\n+\n+ protected:\n+  virtual Status UpdateRowLengths(int32_t* row_lengths) = 0;\n+  std::shared_ptr<StringArray> casted_array_;\n+  const char end_char_;\n+\n+ private:\n+  MemoryPool* const pool_;\n+};\n+\n+// Copies the contents of to out properly escaping any necessary charaters.\n+char* Escape(arrow::util::string_view s, char* out) {\n+  for (const char* val = s.data(); val < s.data() + s.length(); val++, out++) {\n+    if (*val == '\"') {\n+      *out = *val;\n+      out++;\n+    }\n+    *out = *val;\n+  }\n+  return out;\n+}\n+\n+// Populator for non-string types.  This populator relies on compute Cast functionality to\n+// String if it doesn't exist it will be an error.  it also assumes the resulting string\n+// from a cast does not require quoting or escaping.\n+class UnquotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  explicit UnquotedColumnPopulator(MemoryPool* memory_pool, char end_char)\n+      : ColumnPopulator(memory_pool, end_char) {}\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    for (int x = 0; x < casted_array_->length(); x++) {\n+      row_lengths[x] += casted_array_->value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    VisitArrayDataInline<StringType>(\n+        *casted_array_->data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = s.length() + /*end_char*/ 1;\n+          memcpy(*rows, s.data(), s.length());\n+          *(*rows + s.length()) = end_char_;\n+          *rows += next_column_offset;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+        });\n+  }\n+};\n+\n+// Strings need special handling to ensure they are escaped properly.\n+// This class handles escaping assuming that all strings will be quoted\n+// and that the only character within the string that needs to escaped is\n+// a quote character (\") and escaping is done my adding another quote.\n+class QuotedColumnPopulator : public ColumnPopulator {\n+ public:\n+  QuotedColumnPopulator(MemoryPool* pool, char end_char)\n+      : ColumnPopulator(pool, end_char) {}\n+\n+  Status UpdateRowLengths(int32_t* row_lengths) override {\n+    const StringArray& input = *casted_array_;\n+    extra_chars_count_.resize(input.length());\n+    auto extra_chars = extra_chars_count_.begin();\n+    VisitArrayDataInline<StringType>(\n+        *input.data(),\n+        [&](arrow::util::string_view s) {\n+          int64_t escaped_count = CountEscapes(s);\n+          // TODO: Maybe use 64 bit row lengths or safe cast?\n+          *extra_chars = static_cast<int>(escaped_count) + kQuoteCount;\n+          extra_chars++;\n+        },\n+        [&]() {\n+          *extra_chars = 0;\n+          extra_chars++;\n+        });\n+\n+    for (int x = 0; x < input.length(); x++) {\n+      row_lengths[x] += extra_chars_count_[x] + input.value_length(x);\n+    }\n+    return Status::OK();\n+  }\n+\n+  void PopulateColumns(char** rows) const override {\n+    const int32_t* extra_chars = extra_chars_count_.data();\n+    VisitArrayDataInline<StringType>(\n+        *(casted_array_->data()),\n+        [&](arrow::util::string_view s) {\n+          int64_t next_column_offset = *extra_chars + s.length() + /*end_char*/ 1;\n+          **rows = '\"';\n+          if (*extra_chars == kQuoteCount) {\n+            memcpy((*rows + 1), s.data(), s.length());\n+          } else {\n+            Escape(s, (*rows + 1));\n+          }\n+          *(*rows + next_column_offset - 2) = '\"';\n+          *(*rows + next_column_offset - 1) = end_char_;\n+          *rows += next_column_offset;\n+          extra_chars++;\n+          rows++;\n+        },\n+        [&]() {\n+          // Nulls are empty (unquoted) to distinguish with empty string.\n+          **rows = end_char_;\n+          *rows += 1;\n+          rows++;\n+          extra_chars++;\n+        });\n+  }\n+\n+ private:\n+  std::vector<int32_t, std::allocator<int32_t>> extra_chars_count_;\n+};\n+\n+struct PopulatorFactory {\n+  template <typename TypeClass>\n+  enable_if_t<is_base_binary_type<TypeClass>::value ||\n+                  std::is_same<FixedSizeBinaryType, TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new QuotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_dictionary<TypeClass, Status> Visit(const TypeClass& type) {\n+    return VisitTypeInline(*type.value_type(), this);\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_nested_type<TypeClass>::value || is_extension_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    return Status::Invalid(\"Nested and extension types not supported\");\n+  }\n+\n+  template <typename TypeClass>\n+  enable_if_t<is_primitive_ctype<TypeClass>::value || is_decimal_type<TypeClass>::value ||\n+                  is_null_type<TypeClass>::value || is_temporal_type<TypeClass>::value,\n+              Status>\n+  Visit(const TypeClass& type) {\n+    populator = new UnquotedColumnPopulator(pool, end_char);\n+    return Status::OK();\n+  }\n+\n+  char end_char;\n+  MemoryPool* pool;\n+  ColumnPopulator* populator;\n+};\n+\n+Result<std::unique_ptr<ColumnPopulator>> MakePopulator(const Field& field, char end_char,\n+                                                       MemoryPool* pool) {\n+  PopulatorFactory factory{end_char, pool, nullptr};\n+  RETURN_NOT_OK(VisitTypeInline(*field.type(), &factory));\n+  return std::unique_ptr<ColumnPopulator>(factory.populator);\n+}\n+\n+class CsvConverter {\n+ public:\n+  static Result<std::unique_ptr<CsvConverter>> Make(std::shared_ptr<Schema> schema,\n+                                                    MemoryPool* pool) {\n+    std::vector<std::unique_ptr<ColumnPopulator>> populators(schema->num_fields());\n+    for (int col = 0; col < schema->num_fields(); col++) {\n+      char end_char = col < schema->num_fields() - 1 ? ',' : '\\n';\n+      ASSIGN_OR_RAISE(populators[col],\n+                      MakePopulator(*schema->field(col), end_char, pool));\n+    }\n+    return std::unique_ptr<CsvConverter>(\n+        new CsvConverter(std::move(schema), std::move(populators), pool));\n+  }\n+  static constexpr int64_t kColumnSizeGuess = 8;\n+  Status WriteCsv(const RecordBatch& batch, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    RecordBatchIterator iterator = batch.SliceIterator(options.batch_size);\n+    for (auto maybe_slice : iterator) {\n+      ASSIGN_OR_RAISE(std::shared_ptr<RecordBatch> slice, maybe_slice);\n+      RETURN_NOT_OK(TranslateMininalBatch(*slice));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status WriteCsv(const Table& table, const WriteOptions& options,\n+                  io::OutputStream* out) {\n+    TableBatchReader reader(table);\n+    reader.set_chunksize(options.batch_size);\n+    RETURN_NOT_OK(PrepareForContentsWrite(options, out));\n+    std::shared_ptr<RecordBatch> batch;\n+    RETURN_NOT_OK(reader.ReadNext(&batch));\n+    while (batch != nullptr) {\n+      RETURN_NOT_OK(TranslateMininalBatch(*batch));\n+      RETURN_NOT_OK(out->Write(data_buffer_));\n\nReview comment:\n       Another easy optimization is to move the writes to a dedicated background thread.  I'll add this to my list of \"to asyncerize\" which will include this optimization by necessity.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-02-18T04:42:48.741+0000",
                    "updated": "2021-02-18T04:42:48.741+0000",
                    "started": "2021-02-18T04:42:48.740+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "554057",
                    "issueId": "13141283"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": 28800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@1239c58d[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@135ca1ad[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4ae2b45a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@3cc52562[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7b9b96dd[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@358ba1f7[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6a949378[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@7f6f557d[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@58e51933[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@30898fc1[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7ec8c5fb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@7b89a3e2[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 28800,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Feb 25 19:16:07 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-02-25T19:16:07.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2229/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2018-02-27T16:26:15.000+0000",
        "updated": "2021-04-15T17:24:21.000+0000",
        "timeoriginalestimate": null,
        "description": "I did a search through JIRA and didn't find this. Is there a support for CSV file reading/writing in arrow available?\r\nI can go through pandas.read_csv and then convert to arrow table of course, but I would also like to use a native arrow api that's schema-driven CSV reading/writing.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "8h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 28800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Write CSV files from RecordBatch, Table",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/comment/16379439",
                    "id": "16379439",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "It's ARROW-25. Definitely want to be able to read CSV files natively into Arrow format. I will change this JIRA to be a CSV writer",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-02-27T23:01:33.176+0000",
                    "updated": "2018-02-27T23:01:33.176+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13141283/comment/17291158",
                    "id": "17291158",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Issue resolved by pull request 9504\n[https://github.com/apache/arrow/pull/9504]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2021-02-25T19:16:07.328+0000",
                    "updated": "2021-02-25T19:16:07.328+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|i3qnnb:",
        "customfield_12314139": null
    }
}