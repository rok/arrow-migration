{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13117343",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117343",
    "key": "ARROW-1782",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341352",
                "id": "12341352",
                "name": "0.8.0",
                "archived": false,
                "released": true,
                "releaseDate": "2017-12-18"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1782/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@469f84e0[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2c4cbb40[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3cb733ac[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@75e819c1[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@33a456ab[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@1dc7f22e[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@18688869[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@2dfbacb4[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3cfbb6ae[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@1e8f659d[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@42788de5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@32160712[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Nov 23 14:48:12 UTC 2017",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2017-11-23T14:48:12.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1782/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2017-11-09T17:27:08.000+0000",
        "updated": "2017-11-23T14:48:12.000+0000",
        "timeoriginalestimate": null,
        "description": "These should release the GIL, and serve as an alternative to the various compressor wrapper libraries out there. They should have the ability to work with {{pyarrow.Buffer}} or {{PyBytes}} as the user prefers",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Expose compressors as pyarrow.compress, pyarrow.decompress",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117343/comment/16261684",
                    "id": "16261684",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm opened a new pull request #1345: ARROW-1782: [Python] Add pyarrow.compress, decompress APIs\nURL: https://github.com/apache/arrow/pull/1345\n \n \n   This enables bytes, Buffer, or buffer-like objects to be compressed either to PyBytes or `pyarrow.Buffer`. Wanted some feedback on the API (argument names, etc.). The compression API in Arrow in general requires knowing the size of the decompressed data, but some compressors (like Snappy) are able to tell you how big the result will be based only on the input buffer\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-21T23:43:51.473+0000",
                    "updated": "2017-11-21T23:43:51.473+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117343/comment/16261685",
                    "id": "16261685",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1345: ARROW-1782: [Python] Add pyarrow.compress, decompress APIs\nURL: https://github.com/apache/arrow/pull/1345#discussion_r152433696\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression.h\n ##########\n @@ -27,7 +27,7 @@\n namespace arrow {\n \n struct Compression {\n-  enum type { UNCOMPRESSED, SNAPPY, GZIP, LZO, BROTLI, ZSTD, LZ4 };\n+  enum type { UNCOMPRESSED, SNAPPY, GZIP, BROTLI, ZSTD, LZ4, LZO };\n \n Review comment:\n   We should probably remove LZO, but I think this is exposed in parquet-cpp right now\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-21T23:44:20.641+0000",
                    "updated": "2017-11-21T23:44:20.641+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117343/comment/16262504",
                    "id": "16262504",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on a change in pull request #1345: ARROW-1782: [Python] Add pyarrow.compress, decompress APIs\nURL: https://github.com/apache/arrow/pull/1345#discussion_r152561225\n \n \n\n ##########\n File path: cpp/src/arrow/util/compression.h\n ##########\n @@ -27,7 +27,7 @@\n namespace arrow {\n \n struct Compression {\n-  enum type { UNCOMPRESSED, SNAPPY, GZIP, LZO, BROTLI, ZSTD, LZ4 };\n+  enum type { UNCOMPRESSED, SNAPPY, GZIP, BROTLI, ZSTD, LZ4, LZO };\n \n Review comment:\n   It is part of the Parquet standard, so Parquet will need it (altough we don't support it at the moment). I'm not aware how widly it is used, yet no user complained.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-22T13:20:32.669+0000",
                    "updated": "2017-11-22T13:20:32.669+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117343/comment/16264422",
                    "id": "16264422",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm closed pull request #1345: ARROW-1782: [Python] Add pyarrow.compress, decompress APIs\nURL: https://github.com/apache/arrow/pull/1345\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/cpp/src/arrow/util/compression.h b/cpp/src/arrow/util/compression.h\nindex ae187a7fc..de3837ec7 100644\n--- a/cpp/src/arrow/util/compression.h\n+++ b/cpp/src/arrow/util/compression.h\n@@ -27,7 +27,7 @@\n namespace arrow {\n \n struct Compression {\n-  enum type { UNCOMPRESSED, SNAPPY, GZIP, LZO, BROTLI, ZSTD, LZ4 };\n+  enum type { UNCOMPRESSED, SNAPPY, GZIP, BROTLI, ZSTD, LZ4, LZO };\n };\n \n class ARROW_EXPORT Codec {\ndiff --git a/python/doc/source/api.rst b/python/doc/source/api.rst\nindex fb2a28677..bb2a0420b 100644\n--- a/python/doc/source/api.rst\n+++ b/python/doc/source/api.rst\n@@ -195,7 +195,11 @@ Input / Output and Shared Memory\n    :toctree: generated/\n \n    allocate_buffer\n+   compress\n+   decompress\n+   frombuffer\n    Buffer\n+   ResizableBuffer\n    BufferReader\n    BufferOutputStream\n    NativeFile\ndiff --git a/python/pyarrow/__init__.py b/python/pyarrow/__init__.py\nindex c4db36e55..0456a658f 100644\n--- a/python/pyarrow/__init__.py\n+++ b/python/pyarrow/__init__.py\n@@ -71,18 +71,21 @@\n # ARROW-1683: Remove after 0.8.0?\n from pyarrow.lib import TimestampType\n \n-from pyarrow.lib import (HdfsFile, NativeFile, PythonFile,\n-                         FixedSizeBufferWriter,\n-                         Buffer, BufferReader, BufferOutputStream,\n-                         OSFile, MemoryMappedFile, memory_map,\n-                         allocate_buffer, frombuffer,\n-                         memory_map, create_memory_map,\n-                         have_libhdfs, have_libhdfs3, MockOutputStream)\n+# Buffers, allocation\n+from pyarrow.lib import (Buffer, ResizableBuffer, compress, decompress,\n+                         allocate_buffer, frombuffer)\n \n from pyarrow.lib import (MemoryPool, total_allocated_bytes,\n                          set_memory_pool, default_memory_pool,\n                          log_memory_allocations)\n \n+from pyarrow.lib import (HdfsFile, NativeFile, PythonFile,\n+                         FixedSizeBufferWriter,\n+                         BufferReader, BufferOutputStream,\n+                         OSFile, MemoryMappedFile, memory_map,\n+                         create_memory_map, have_libhdfs, have_libhdfs3,\n+                         MockOutputStream)\n+\n from pyarrow.lib import (ChunkedArray, Column, RecordBatch, Table,\n                          concat_tables)\n \ndiff --git a/python/pyarrow/includes/libarrow.pxd b/python/pyarrow/includes/libarrow.pxd\nindex 324648178..5d68607ef 100644\n--- a/python/pyarrow/includes/libarrow.pxd\n+++ b/python/pyarrow/includes/libarrow.pxd\n@@ -169,26 +169,27 @@ cdef extern from \"arrow/api.h\" namespace \"arrow\" nogil:\n \n     cdef cppclass CBuffer\" arrow::Buffer\":\n         CBuffer(const uint8_t* data, int64_t size)\n-        uint8_t* data()\n+        const uint8_t* data()\n+        uint8_t* mutable_data()\n         int64_t size()\n         shared_ptr[CBuffer] parent()\n         c_bool is_mutable() const\n+        c_bool Equals(const CBuffer& other)\n \n     cdef cppclass CMutableBuffer\" arrow::MutableBuffer\"(CBuffer):\n         CMutableBuffer(const uint8_t* data, int64_t size)\n-        uint8_t* mutable_data()\n+\n+    cdef cppclass CResizableBuffer\" arrow::ResizableBuffer\"(CMutableBuffer):\n+        CStatus Resize(const int64_t new_size, c_bool shrink_to_fit)\n+        CStatus Reserve(const int64_t new_size)\n \n     CStatus AllocateBuffer(CMemoryPool* pool, const int64_t size,\n                            shared_ptr[CBuffer]* out)\n \n     CStatus AllocateResizableBuffer(CMemoryPool* pool, const int64_t size,\n-                                    shared_ptr[ResizableBuffer]* out)\n+                                    shared_ptr[CResizableBuffer]* out)\n \n-    cdef cppclass ResizableBuffer(CBuffer):\n-        CStatus Resize(int64_t nbytes)\n-        CStatus Reserve(int64_t nbytes)\n-\n-    cdef cppclass PoolBuffer(ResizableBuffer):\n+    cdef cppclass PoolBuffer(CResizableBuffer):\n         PoolBuffer()\n         PoolBuffer(CMemoryPool*)\n \n@@ -635,7 +636,7 @@ cdef extern from \"arrow/io/api.h\" namespace \"arrow::io\" nogil:\n \n     cdef cppclass CBufferOutputStream \\\n             \" arrow::io::BufferOutputStream\"(OutputStream):\n-        CBufferOutputStream(const shared_ptr[ResizableBuffer]& buffer)\n+        CBufferOutputStream(const shared_ptr[CResizableBuffer]& buffer)\n \n     cdef cppclass CMockOutputStream \\\n             \" arrow::io::MockOutputStream\"(OutputStream):\n@@ -661,6 +662,7 @@ cdef extern from \"arrow/ipc/api.h\" namespace \"arrow::ipc\" nogil:\n         MessageType_V1\" arrow::ipc::MetadataVersion::V1\"\n         MessageType_V2\" arrow::ipc::MetadataVersion::V2\"\n         MessageType_V3\" arrow::ipc::MetadataVersion::V3\"\n+        MessageType_V4\" arrow::ipc::MetadataVersion::V4\"\n \n     cdef cppclass CMessage\" arrow::ipc::Message\":\n         CStatus Open(const shared_ptr[CBuffer]& metadata,\n@@ -926,3 +928,26 @@ cdef extern from 'arrow/python/init.h':\n \n cdef extern from 'arrow/python/config.h' namespace 'arrow::py':\n     void set_numpy_nan(object o)\n+\n+\n+cdef extern from 'arrow/util/compression.h' namespace 'arrow' nogil:\n+    enum CompressionType\" arrow::Compression::type\":\n+        CompressionType_UNCOMPRESSED\" arrow::Compression::UNCOMPRESSED\"\n+        CompressionType_SNAPPY\" arrow::Compression::SNAPPY\"\n+        CompressionType_GZIP\" arrow::Compression::GZIP\"\n+        CompressionType_BROTLI\" arrow::Compression::BROTLI\"\n+        CompressionType_ZSTD\" arrow::Compression::ZSTD\"\n+        CompressionType_LZ4\" arrow::Compression::LZ4\"\n+\n+    cdef cppclass CCodec\" arrow::Codec\":\n+        @staticmethod\n+        CStatus Create(CompressionType codec, unique_ptr[CCodec]* out)\n+\n+        CStatus Decompress(int64_t input_len, const uint8_t* input,\n+                           int64_t output_len, uint8_t* output_buffer)\n+\n+        CStatus Compress(int64_t input_len, const uint8_t* input,\n+                         int64_t output_buffer_len, uint8_t* output_buffer,\n+                         int64_t* output_length)\n+\n+        int64_t MaxCompressedLen(int64_t input_len, const uint8_t* input)\ndiff --git a/python/pyarrow/io.pxi b/python/pyarrow/io.pxi\nindex 495e31b5a..619ba365c 100644\n--- a/python/pyarrow/io.pxi\n+++ b/python/pyarrow/io.pxi\n@@ -600,6 +600,23 @@ cdef class Buffer:\n         # TODO(wesm): buffer slicing\n         raise NotImplementedError\n \n+    def equals(self, Buffer other):\n+        \"\"\"\n+        Determine if two buffers contain exactly the same data\n+\n+        Parameters\n+        ----------\n+        other : Buffer\n+\n+        Returns\n+        -------\n+        are_equal : True if buffer contents and size are equal\n+        \"\"\"\n+        cdef c_bool result = False\n+        with nogil:\n+            result = self.buffer.get().Equals(deref(other.buffer.get()))\n+        return result\n+\n     def to_pybytes(self):\n         return cp.PyBytes_FromStringAndSize(\n             <const char*>self.buffer.get().data(),\n@@ -644,13 +661,37 @@ cdef class Buffer:\n         return self.size\n \n \n+cdef class ResizableBuffer(Buffer):\n+\n+    cdef void init_rz(self, const shared_ptr[CResizableBuffer]& buffer):\n+        self.init(<shared_ptr[CBuffer]> buffer)\n+\n+    def resize(self, int64_t new_size, shrink_to_fit=False):\n+        \"\"\"\n+        Resize buffer to indicated size\n+\n+        Parameters\n+        ----------\n+        new_size : int64_t\n+            New size of buffer (padding may be added internally)\n+        shrink_to_fit : boolean, default False\n+            If new_size is less than the current size, shrink internal\n+            capacity, otherwise leave at current capacity\n+        \"\"\"\n+        cdef c_bool c_shrink_to_fit = shrink_to_fit\n+        with nogil:\n+            check_status((<CResizableBuffer*> self.buffer.get())\n+                         .Resize(new_size, c_shrink_to_fit))\n+\n+\n cdef shared_ptr[PoolBuffer] _allocate_buffer(CMemoryPool* pool):\n     cdef shared_ptr[PoolBuffer] result\n     result.reset(new PoolBuffer(pool))\n     return result\n \n \n-def allocate_buffer(int64_t size, MemoryPool pool=None):\n+def allocate_buffer(int64_t size, MemoryPool memory_pool=None,\n+                    resizable=False):\n     \"\"\"\n     Allocate mutable fixed-size buffer\n \n@@ -658,17 +699,27 @@ def allocate_buffer(int64_t size, MemoryPool pool=None):\n     ----------\n     size : int\n         Number of bytes to allocate (plus internal padding)\n-    pool : MemoryPool, optional\n+    memory_pool : MemoryPool, optional\n         Uses default memory pool if not provided\n+    resizable : boolean, default False\n+\n+    Returns\n+    -------\n+    buffer : Buffer or ResizableBuffer\n     \"\"\"\n     cdef:\n         shared_ptr[CBuffer] buffer\n-        CMemoryPool* cpool = maybe_unbox_memory_pool(pool)\n+        shared_ptr[CResizableBuffer] rz_buffer\n+        CMemoryPool* cpool = maybe_unbox_memory_pool(memory_pool)\n \n-    with nogil:\n-        check_status(AllocateBuffer(cpool, size, &buffer))\n-\n-    return pyarrow_wrap_buffer(buffer)\n+    if resizable:\n+        with nogil:\n+            check_status(AllocateResizableBuffer(cpool, size, &rz_buffer))\n+        return pyarrow_wrap_resizable_buffer(rz_buffer)\n+    else:\n+        with nogil:\n+            check_status(AllocateBuffer(cpool, size, &buffer))\n+        return pyarrow_wrap_buffer(buffer)\n \n \n cdef class BufferOutputStream(NativeFile):\n@@ -679,7 +730,7 @@ cdef class BufferOutputStream(NativeFile):\n     def __cinit__(self, MemoryPool memory_pool=None):\n         self.buffer = _allocate_buffer(maybe_unbox_memory_pool(memory_pool))\n         self.wr_file.reset(new CBufferOutputStream(\n-            <shared_ptr[ResizableBuffer]> self.buffer))\n+            <shared_ptr[CResizableBuffer]> self.buffer))\n         self.is_readable = 0\n         self.is_writeable = 1\n         self.is_open = True\n@@ -783,3 +834,145 @@ cdef get_writer(object source, shared_ptr[OutputStream]* writer):\n     else:\n         raise TypeError('Unable to read from object of type: {0}'\n                         .format(type(source)))\n+\n+\n+# ---------------------------------------------------------------------\n+\n+cdef CompressionType _get_compression_type(object name):\n+    if name is None or name == 'uncompressed':\n+        return CompressionType_UNCOMPRESSED\n+    elif name == 'snappy':\n+        return CompressionType_SNAPPY\n+    elif name == 'gzip':\n+        return CompressionType_GZIP\n+    elif name == 'brotli':\n+        return CompressionType_BROTLI\n+    elif name == 'zstd':\n+        return CompressionType_ZSTD\n+    elif name == 'lz4':\n+        return CompressionType_LZ4\n+    else:\n+        raise ValueError(\"Unrecognized compression type: {0}\"\n+                         .format(str(name)))\n+\n+\n+def compress(object buf, codec='lz4', asbytes=False, memory_pool=None):\n+    \"\"\"\n+    Compress pyarrow.Buffer or Python object supporting the buffer (memoryview)\n+    protocol\n+\n+    Parameters\n+    ----------\n+    buf : pyarrow.Buffer, bytes, or other object supporting buffer protocol\n+    codec : string, default 'lz4'\n+        Compression codec.\n+        Supported types: {'brotli, 'gzip', 'lz4', 'snappy', 'zstd'}\n+    asbytes : boolean, default False\n+        Return result as Python bytes object, otherwise Buffer\n+    memory_pool : MemoryPool, default None\n+        Memory pool to use for buffer allocations, if any\n+\n+    Returns\n+    -------\n+    compressed : pyarrow.Buffer or bytes (if asbytes=True)\n+    \"\"\"\n+    cdef:\n+        CompressionType c_codec = _get_compression_type(codec)\n+        unique_ptr[CCodec] compressor\n+        cdef CBuffer* c_buf\n+        cdef PyObject* pyobj\n+        cdef ResizableBuffer out_buf\n+\n+    with nogil:\n+        check_status(CCodec.Create(c_codec, &compressor))\n+\n+    if not isinstance(buf, Buffer):\n+        buf = frombuffer(buf)\n+\n+    c_buf = (<Buffer> buf).buffer.get()\n+\n+    cdef int64_t max_output_size = (compressor.get()\n+                                    .MaxCompressedLen(c_buf.size(),\n+                                                      c_buf.data()))\n+    cdef uint8_t* output_buffer = NULL\n+\n+    if asbytes:\n+        pyobj = PyBytes_FromStringAndSizeNative(NULL, max_output_size)\n+        output_buffer = <uint8_t*> cp.PyBytes_AS_STRING(<object> pyobj)\n+    else:\n+        out_buf = allocate_buffer(max_output_size, memory_pool=memory_pool,\n+                                  resizable=True)\n+        output_buffer = out_buf.buffer.get().mutable_data()\n+\n+    cdef int64_t output_length = 0\n+    with nogil:\n+        check_status(compressor.get()\n+                     .Compress(c_buf.size(), c_buf.data(),\n+                               max_output_size, output_buffer,\n+                               &output_length))\n+\n+    if asbytes:\n+        cp._PyBytes_Resize(&pyobj, <Py_ssize_t> output_length)\n+        return PyObject_to_object(pyobj)\n+    else:\n+        out_buf.resize(output_length)\n+        return out_buf\n+\n+\n+def decompress(object buf, decompressed_size=None, codec='lz4',\n+               asbytes=False, memory_pool=None):\n+    \"\"\"\n+    Decompress data from buffer-like object\n+\n+    Parameters\n+    ----------\n+    buf : pyarrow.Buffer, bytes, or memoryview-compatible object\n+    decompressed_size : int64_t, default None\n+        If not specified, will be computed if the codec is able to determine\n+        the uncompressed buffer size\n+    codec : string, default 'lz4'\n+        Compression codec.\n+        Supported types: {'brotli, 'gzip', 'lz4', 'snappy', 'zstd'}\n+    asbytes : boolean, default False\n+        Return result as Python bytes object, otherwise Buffer\n+    memory_pool : MemoryPool, default None\n+        Memory pool to use for buffer allocations, if any\n+\n+    Returns\n+    -------\n+    uncompressed : pyarrow.Buffer or bytes (if asbytes=True)\n+    \"\"\"\n+    cdef:\n+        CompressionType c_codec = _get_compression_type(codec)\n+        unique_ptr[CCodec] compressor\n+        cdef CBuffer* c_buf\n+        cdef Buffer out_buf\n+\n+    with nogil:\n+        check_status(CCodec.Create(c_codec, &compressor))\n+\n+    if not isinstance(buf, Buffer):\n+        buf = frombuffer(buf)\n+\n+    c_buf = (<Buffer> buf).buffer.get()\n+\n+    if decompressed_size is None:\n+        raise ValueError(\"Must pass decompressed_size for {0} codec\"\n+                         .format(codec))\n+\n+    cdef int64_t output_size = decompressed_size\n+    cdef uint8_t* output_buffer = NULL\n+\n+    if asbytes:\n+        pybuf = cp.PyBytes_FromStringAndSize(NULL, output_size)\n+        output_buffer = <uint8_t*> cp.PyBytes_AS_STRING(pybuf)\n+    else:\n+        out_buf = allocate_buffer(output_size, memory_pool=memory_pool)\n+        output_buffer = out_buf.buffer.get().mutable_data()\n+\n+    with nogil:\n+        check_status(compressor.get()\n+                     .Decompress(c_buf.size(), c_buf.data(),\n+                                 output_size, output_buffer))\n+\n+    return pybuf if asbytes else out_buf\ndiff --git a/python/pyarrow/lib.pxd b/python/pyarrow/lib.pxd\nindex 5abb72ba4..90f749d6d 100644\n--- a/python/pyarrow/lib.pxd\n+++ b/python/pyarrow/lib.pxd\n@@ -323,6 +323,11 @@ cdef class Buffer:\n     cdef void init(self, const shared_ptr[CBuffer]& buffer)\n \n \n+cdef class ResizableBuffer(Buffer):\n+\n+    cdef void init_rz(self, const shared_ptr[CResizableBuffer]& buffer)\n+\n+\n cdef class NativeFile:\n     cdef:\n         shared_ptr[RandomAccessFile] rd_file\n@@ -343,6 +348,8 @@ cdef get_reader(object source, shared_ptr[RandomAccessFile]* reader)\n cdef get_writer(object source, shared_ptr[OutputStream]* writer)\n \n cdef public object pyarrow_wrap_buffer(const shared_ptr[CBuffer]& buf)\n+cdef public object pyarrow_wrap_resizable_buffer(\n+    const shared_ptr[CResizableBuffer]& buf)\n cdef public object pyarrow_wrap_data_type(const shared_ptr[CDataType]& type)\n cdef public object pyarrow_wrap_field(const shared_ptr[CField]& field)\n cdef public object pyarrow_wrap_schema(const shared_ptr[CSchema]& type)\ndiff --git a/python/pyarrow/plasma.pyx b/python/pyarrow/plasma.pyx\nindex bc0e94e64..f2e8653d8 100644\n--- a/python/pyarrow/plasma.pyx\n+++ b/python/pyarrow/plasma.pyx\n@@ -30,7 +30,7 @@ import collections\n import pyarrow\n \n from pyarrow.lib cimport Buffer, NativeFile, check_status\n-from pyarrow.includes.libarrow cimport (CMutableBuffer, CBuffer,\n+from pyarrow.includes.libarrow cimport (CBuffer, CMutableBuffer,\n                                         CFixedSizeBufferWriter, CStatus)\n \n \ndiff --git a/python/pyarrow/public-api.pxi b/python/pyarrow/public-api.pxi\nindex bf670c5c4..9776f2ad7 100644\n--- a/python/pyarrow/public-api.pxi\n+++ b/python/pyarrow/public-api.pxi\n@@ -43,6 +43,13 @@ cdef public api object pyarrow_wrap_buffer(const shared_ptr[CBuffer]& buf):\n     return result\n \n \n+cdef public api object pyarrow_wrap_resizable_buffer(\n+    const shared_ptr[CResizableBuffer]& buf):\n+    cdef ResizableBuffer result = ResizableBuffer()\n+    result.init_rz(buf)\n+    return result\n+\n+\n cdef public api bint pyarrow_is_data_type(object type_):\n     return isinstance(type_, DataType)\n \ndiff --git a/python/pyarrow/tests/test_io.py b/python/pyarrow/tests/test_io.py\nindex 98c465adc..e60dd35de 100644\n--- a/python/pyarrow/tests/test_io.py\n+++ b/python/pyarrow/tests/test_io.py\n@@ -182,6 +182,42 @@ def test_allocate_buffer():\n     assert buf.to_pybytes()[:5] == bit\n \n \n+def test_allocate_buffer_resizable():\n+    buf = pa.allocate_buffer(100, resizable=True)\n+    assert isinstance(buf, pa.ResizableBuffer)\n+\n+    buf.resize(200)\n+    assert buf.size == 200\n+\n+\n+def test_compress_decompress():\n+    INPUT_SIZE = 10000\n+    test_data = (np.random.randint(0, 255, size=INPUT_SIZE)\n+                 .astype(np.uint8)\n+                 .tostring())\n+    test_buf = pa.frombuffer(test_data)\n+\n+    codecs = ['lz4', 'snappy', 'gzip', 'zstd', 'brotli']\n+    for codec in codecs:\n+        compressed_buf = pa.compress(test_buf, codec=codec)\n+        compressed_bytes = pa.compress(test_data, codec=codec, asbytes=True)\n+\n+        assert isinstance(compressed_bytes, bytes)\n+\n+        decompressed_buf = pa.decompress(compressed_buf, INPUT_SIZE,\n+                                         codec=codec)\n+        decompressed_bytes = pa.decompress(compressed_bytes, INPUT_SIZE,\n+                                           codec=codec, asbytes=True)\n+\n+        assert isinstance(decompressed_bytes, bytes)\n+\n+        assert decompressed_buf.equals(test_buf)\n+        assert decompressed_bytes == test_data\n+\n+        with pytest.raises(ValueError):\n+            pa.decompress(compressed_bytes, codec=codec)\n+\n+\n def test_buffer_memoryview_is_immutable():\n     val = b'some data'\n \n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-23T14:48:12.263+0000",
                    "updated": "2017-11-23T14:48:12.263+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117343/comment/16264423",
                    "id": "16264423",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 1345\n[https://github.com/apache/arrow/pull/1345]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-11-23T14:48:12.666+0000",
                    "updated": "2017-11-23T14:48:12.666+0000"
                }
            ],
            "maxResults": 5,
            "total": 5,
            "startAt": 0
        },
        "customfield_12311820": "0|i3mltb:",
        "customfield_12314139": null
    }
}