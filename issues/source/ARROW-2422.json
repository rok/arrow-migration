{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13151030",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030",
    "key": "ARROW-2422",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12342562",
                "id": "12342562",
                "description": "",
                "name": "0.10.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-08-06"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
            "name": "Minor",
            "id": "4"
        },
        "labels": [
            "features",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jneuffer",
            "name": "jneuffer",
            "key": "jneuffer",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34043",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34043",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34043",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34043"
            },
            "displayName": "Julius Neuffer",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jneuff",
            "name": "jneuff",
            "key": "jneuff",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Julius Neuffer",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jneuff",
            "name": "jneuff",
            "key": "jneuff",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Julius Neuffer",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 2400,
            "total": 2400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 2400,
            "total": 2400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2422/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 4,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/worklog/95087",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "xhochy commented on a change in pull request #1861: ARROW-2422: Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#discussion_r184125374\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -997,40 +997,162 @@ def test_read_partitioned_directory(tmpdir):\n \n \n @parquet\n-def test_read_partitioned_directory_filtered(tmpdir):\n-    fs = LocalFileSystem.get_instance()\n-    base_path = str(tmpdir)\n-\n-    import pyarrow.parquet as pq\n-\n-    foo_keys = [0, 1]\n-    bar_keys = ['a', 'b', 'c']\n-    partition_spec = [\n-        ['foo', foo_keys],\n-        ['bar', bar_keys]\n-    ]\n-    N = 30\n-\n-    df = pd.DataFrame({\n-        'index': np.arange(N),\n-        'foo': np.array(foo_keys, dtype='i4').repeat(15),\n-        'bar': np.tile(np.tile(np.array(bar_keys, dtype=object), 5), 2),\n-        'values': np.random.randn(N)\n-    }, columns=['index', 'foo', 'bar', 'values'])\n-\n-    _generate_partition_directories(fs, base_path, partition_spec, df)\n-\n-    dataset = pq.ParquetDataset(\n-        base_path, filesystem=fs,\n-        filters=[('foo', '=', 1), ('bar', '!=', 'b')]\n+class TestParquetFilter:\n \n Review comment:\n   I'm +0 on using classes for indentation but please use new-style classes that inherit from `object`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-04-25T16:28:32.814+0000",
                    "updated": "2018-04-25T16:28:32.814+0000",
                    "started": "2018-04-25T16:28:32.814+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "95087",
                    "issueId": "13151030"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/worklog/95467",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "crepererum commented on a change in pull request #1861: ARROW-2422: Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#discussion_r184275149\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -997,40 +997,162 @@ def test_read_partitioned_directory(tmpdir):\n \n \n @parquet\n-def test_read_partitioned_directory_filtered(tmpdir):\n-    fs = LocalFileSystem.get_instance()\n-    base_path = str(tmpdir)\n-\n-    import pyarrow.parquet as pq\n-\n-    foo_keys = [0, 1]\n-    bar_keys = ['a', 'b', 'c']\n-    partition_spec = [\n-        ['foo', foo_keys],\n-        ['bar', bar_keys]\n-    ]\n-    N = 30\n-\n-    df = pd.DataFrame({\n-        'index': np.arange(N),\n-        'foo': np.array(foo_keys, dtype='i4').repeat(15),\n-        'bar': np.tile(np.tile(np.array(bar_keys, dtype=object), 5), 2),\n-        'values': np.random.randn(N)\n-    }, columns=['index', 'foo', 'bar', 'values'])\n-\n-    _generate_partition_directories(fs, base_path, partition_spec, df)\n-\n-    dataset = pq.ParquetDataset(\n-        base_path, filesystem=fs,\n-        filters=[('foo', '=', 1), ('bar', '!=', 'b')]\n+class TestParquetFilter:\n+\n+    def test_equivalency(tmpdir):\n+        fs = LocalFileSystem.get_instance()\n+        base_path = str(tmpdir)\n+\n+        import pyarrow.parquet as pq\n+\n+        integer_keys = [0, 1]\n+        string_keys = ['a', 'b', 'c']\n+        boolean_keys = [True, False]\n+        partition_spec = [\n+            ['integer', integer_keys],\n+            ['string', string_keys],\n+            ['boolean', boolean_keys]\n+        ]\n+\n+        df = pd.DataFrame({\n+            'integer': np.array(integer_keys, dtype='i4').repeat(15),\n+            'string': np.tile(np.tile(np.array(string_keys,\n+                                               dtype=object\n+                                               ), 5), 2),\n+            'boolean': np.tile(np.tile(np.array(boolean_keys,\n+                                                dtype='bool'\n+                                                ), 5), 3),\n+        }, columns=['integer', 'string', 'boolean'])\n+\n+        _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+        dataset = pq.ParquetDataset(\n+            base_path, filesystem=fs,\n+            filters=[('integer', '=', 1), ('string', '!=', 'b'),\n+                     ('boolean', '==', True)]\n+        )\n+        table = dataset.read()\n+        result_df = (table.to_pandas()\n+                     .reset_index(drop=True))\n+\n+        assert 0 not in result_df['integer'].values\n+        assert 'b' not in result_df['string'].values\n+        assert False not in result_df['boolean'].values\n+\n+    def test_cutoff_exclusive_integer(tmpdir):\n+        fs = LocalFileSystem.get_instance()\n+        base_path = str(tmpdir)\n+\n+        import pyarrow.parquet as pq\n+\n+        integer_keys = [0, 1, 2, 3, 4]\n+        partition_spec = [\n+            ['integers', integer_keys],\n+        ]\n+        N = 5\n+\n+        df = pd.DataFrame({\n+            'index': np.arange(N),\n+            'integers': np.array(integer_keys, dtype='i4'),\n+        }, columns=['index', 'integers'])\n+\n+        _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+        dataset = pq.ParquetDataset(\n+            base_path, filesystem=fs,\n+            filters=[\n+                ('integers', '<', 4),\n+                ('integers', '>', 1),\n+            ]\n+        )\n+        table = dataset.read()\n+        result_df = (table.to_pandas()\n+                     .sort_values(by='index')\n+                     .reset_index(drop=True))\n+\n+        result_list = [x for x in map(int, result_df['integers'].values)]\n+        assert result_list == [2, 3]\n+\n+    @pytest.mark.xfail(\n+        raises=TypeError,\n+        reason='Loss of type information in creation of categoricals.'\n     )\n-    table = dataset.read()\n-    result_df = (table.to_pandas()\n-                 .sort_values(by='index')\n-                 .reset_index(drop=True))\n-\n-    assert 0 not in result_df['foo'].values\n-    assert 'b' not in result_df['bar'].values\n+    def test_cutoff_exclusive_datetime(tmpdir):\n+        fs = LocalFileSystem.get_instance()\n+        base_path = str(tmpdir)\n+\n+        import pyarrow.parquet as pq\n+\n+        date_keys = [\n+            datetime.date(2018, 4, 9),\n+            datetime.date(2018, 4, 10),\n+            datetime.date(2018, 4, 11),\n+            datetime.date(2018, 4, 12),\n+            datetime.date(2018, 4, 13)\n+        ]\n+        partition_spec = [\n+            ['dates', date_keys]\n+        ]\n+        N = 5\n+\n+        df = pd.DataFrame({\n+            'index': np.arange(N),\n+            'dates': np.array(date_keys, dtype='datetime64'),\n+        }, columns=['index', 'dates'])\n+\n+        _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+        dataset = pq.ParquetDataset(\n+            base_path, filesystem=fs,\n+            filters=[\n+                ('dates', '<', \"2018-04-12\"),\n+                ('dates', '>', \"2018-04-10\")\n+            ]\n+        )\n+        table = dataset.read()\n+        result_df = (table.to_pandas()\n+                     .sort_values(by='index')\n+                     .reset_index(drop=True))\n+\n+        expected = pd.Categorical(\n+            np.array([datetime.date(2018, 4, 11)], dtype='datetime64'),\n+            categories=np.array(date_keys, dtype='datetime64'))\n+\n+        assert result_df['dates'].values == expected\n+\n+    def test_inclusive_integer(tmpdir):\n+        fs = LocalFileSystem.get_instance()\n+        base_path = str(tmpdir)\n+\n+        import pyarrow.parquet as pq\n+\n+        integer_keys = [0, 1, 2, 3, 4]\n+        partition_spec = [\n+            ['integers', integer_keys],\n+        ]\n+        N = 5\n+\n+        df = pd.DataFrame({\n+            'index': np.arange(N),\n+            'integers': np.array(integer_keys, dtype='i4'),\n+        }, columns=['index', 'integers'])\n+\n+        _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+        dataset = pq.ParquetDataset(\n+            base_path, filesystem=fs,\n+            filters=[\n+                ('integers', '<=', 3),\n+                ('integers', '>=', 2),\n+            ]\n+        )\n+        table = dataset.read()\n+        result_df = (table.to_pandas()\n+                     .sort_values(by='index')\n+                     .reset_index(drop=True))\n+\n+        result_list = [int(x) for x in map(int, result_df['integers'].values)]\n+        assert result_list == [2, 3]\n \n \n Review comment:\n   Test with `pytest.raises` and an unimplemented operator is missing that also checks the exception message, see comment on that above \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-04-26T12:05:18.119+0000",
                    "updated": "2018-04-26T12:05:18.119+0000",
                    "started": "2018-04-26T12:05:18.118+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "95467",
                    "issueId": "13151030"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/worklog/95468",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "crepererum commented on a change in pull request #1861: ARROW-2422: Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#discussion_r184274869\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -859,19 +859,32 @@ def open_file(path, meta=None):\n \n     def _filter(self, filters):\n         def filter_accepts_partition(part_key, filter, level):\n+\n             p_column, p_value_index = part_key\n             f_column, op, f_value = filter\n             if p_column != f_column:\n                 return True\n \n-            f_value_index = self.partitions.get_index(level, p_column,\n-                                                      str(f_value))\n-            if op == \"=\":\n-                return f_value_index == p_value_index\n+            f_type = type(f_value)\n+            p_value = f_type((self.partitions\n+                                  .levels[level]\n+                                  .dictionary[p_value_index]\n+                                  .as_py()))\n+\n+            if op == \"=\" or op == \"==\":\n+                return p_value == f_value\n             elif op == \"!=\":\n-                return f_value_index != p_value_index\n+                return p_value != f_value\n+            elif op == '<':\n+                return p_value < f_value\n+            elif op == '>':\n+                return p_value > f_value\n+            elif op == '<=':\n+                return p_value <= f_value\n+            elif op == '>=':\n+                return p_value >= f_value\n             else:\n-                return True\n+                raise ValueError(\"'%s' is not a valid operator in predicates.\")\n \n Review comment:\n   %s should also be filled in here. A test would have caught this bug. \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-04-26T12:05:18.223+0000",
                    "updated": "2018-04-26T12:05:18.223+0000",
                    "started": "2018-04-26T12:05:18.222+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "95468",
                    "issueId": "13151030"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/worklog/97030",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "xhochy closed pull request #1861: ARROW-2422: Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/python/pyarrow/parquet.py b/python/pyarrow/parquet.py\nindex 34aa55a9c..18f329ea4 100644\n--- a/python/pyarrow/parquet.py\n+++ b/python/pyarrow/parquet.py\n@@ -858,19 +858,33 @@ def open_file(path, meta=None):\n \n     def _filter(self, filters):\n         def filter_accepts_partition(part_key, filter, level):\n+\n             p_column, p_value_index = part_key\n             f_column, op, f_value = filter\n             if p_column != f_column:\n                 return True\n \n-            f_value_index = self.partitions.get_index(level, p_column,\n-                                                      str(f_value))\n-            if op == \"=\":\n-                return f_value_index == p_value_index\n+            f_type = type(f_value)\n+            p_value = f_type((self.partitions\n+                                  .levels[level]\n+                                  .dictionary[p_value_index]\n+                                  .as_py()))\n+\n+            if op == \"=\" or op == \"==\":\n+                return p_value == f_value\n             elif op == \"!=\":\n-                return f_value_index != p_value_index\n+                return p_value != f_value\n+            elif op == '<':\n+                return p_value < f_value\n+            elif op == '>':\n+                return p_value > f_value\n+            elif op == '<=':\n+                return p_value <= f_value\n+            elif op == '>=':\n+                return p_value >= f_value\n             else:\n-                return True\n+                raise ValueError(\"'%s' is not a valid operator in predicates.\",\n+                                 filter[1])\n \n         def one_filter_accepts(piece, filter):\n             return all(filter_accepts_partition(part_key, filter, level)\ndiff --git a/python/pyarrow/tests/test_parquet.py b/python/pyarrow/tests/test_parquet.py\nindex 3fec0f7c4..86cf417d9 100644\n--- a/python/pyarrow/tests/test_parquet.py\n+++ b/python/pyarrow/tests/test_parquet.py\n@@ -1022,40 +1022,189 @@ def test_read_partitioned_directory(tmpdir):\n \n \n @parquet\n-def test_read_partitioned_directory_filtered(tmpdir):\n+def test_equivalency(tmpdir):\n     fs = LocalFileSystem.get_instance()\n     base_path = str(tmpdir)\n \n     import pyarrow.parquet as pq\n \n-    foo_keys = [0, 1]\n-    bar_keys = ['a', 'b', 'c']\n+    integer_keys = [0, 1]\n+    string_keys = ['a', 'b', 'c']\n+    boolean_keys = [True, False]\n     partition_spec = [\n-        ['foo', foo_keys],\n-        ['bar', bar_keys]\n+        ['integer', integer_keys],\n+        ['string', string_keys],\n+        ['boolean', boolean_keys]\n     ]\n-    N = 30\n+\n+    df = pd.DataFrame({\n+        'integer': np.array(integer_keys, dtype='i4').repeat(15),\n+        'string': np.tile(np.tile(np.array(string_keys, dtype=object), 5), 2),\n+        'boolean': np.tile(np.tile(np.array(boolean_keys, dtype='bool'), 5),\n+                           3),\n+    }, columns=['integer', 'string', 'boolean'])\n+\n+    _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+    dataset = pq.ParquetDataset(\n+        base_path, filesystem=fs,\n+        filters=[('integer', '=', 1), ('string', '!=', 'b'),\n+                 ('boolean', '==', True)]\n+    )\n+    table = dataset.read()\n+    result_df = (table.to_pandas().reset_index(drop=True))\n+\n+    assert 0 not in result_df['integer'].values\n+    assert 'b' not in result_df['string'].values\n+    assert False not in result_df['boolean'].values\n+\n+    @parquet\n+    def test_cutoff_exclusive_integer(tmpdir):\n+        fs = LocalFileSystem.get_instance()\n+        base_path = str(tmpdir)\n+\n+        import pyarrow.parquet as pq\n+\n+        integer_keys = [0, 1, 2, 3, 4]\n+        partition_spec = [\n+            ['integers', integer_keys],\n+        ]\n+        N = 5\n+\n+        df = pd.DataFrame({\n+            'index': np.arange(N),\n+            'integers': np.array(integer_keys, dtype='i4'),\n+        }, columns=['index', 'integers'])\n+\n+        _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+        dataset = pq.ParquetDataset(\n+            base_path, filesystem=fs,\n+            filters=[\n+                ('integers', '<', 4),\n+                ('integers', '>', 1),\n+            ]\n+        )\n+        table = dataset.read()\n+        result_df = (table.to_pandas()\n+                          .sort_values(by='index')\n+                          .reset_index(drop=True))\n+\n+        result_list = [x for x in map(int, result_df['integers'].values)]\n+        assert result_list == [2, 3]\n+\n+\n+@parquet\n+@pytest.mark.xfail(\n+    raises=TypeError,\n+    reason='Loss of type information in creation of categoricals.'\n+)\n+def test_cutoff_exclusive_datetime(tmpdir):\n+    fs = LocalFileSystem.get_instance()\n+    base_path = str(tmpdir)\n+\n+    import pyarrow.parquet as pq\n+\n+    date_keys = [\n+        datetime.date(2018, 4, 9),\n+        datetime.date(2018, 4, 10),\n+        datetime.date(2018, 4, 11),\n+        datetime.date(2018, 4, 12),\n+        datetime.date(2018, 4, 13)\n+    ]\n+    partition_spec = [\n+        ['dates', date_keys]\n+    ]\n+    N = 5\n \n     df = pd.DataFrame({\n         'index': np.arange(N),\n-        'foo': np.array(foo_keys, dtype='i4').repeat(15),\n-        'bar': np.tile(np.tile(np.array(bar_keys, dtype=object), 5), 2),\n-        'values': np.random.randn(N)\n-    }, columns=['index', 'foo', 'bar', 'values'])\n+        'dates': np.array(date_keys, dtype='datetime64'),\n+    }, columns=['index', 'dates'])\n \n     _generate_partition_directories(fs, base_path, partition_spec, df)\n \n     dataset = pq.ParquetDataset(\n         base_path, filesystem=fs,\n-        filters=[('foo', '=', 1), ('bar', '!=', 'b')]\n+        filters=[\n+            ('dates', '<', \"2018-04-12\"),\n+            ('dates', '>', \"2018-04-10\")\n+        ]\n     )\n     table = dataset.read()\n     result_df = (table.to_pandas()\n-                 .sort_values(by='index')\n-                 .reset_index(drop=True))\n+                      .sort_values(by='index')\n+                      .reset_index(drop=True))\n \n-    assert 0 not in result_df['foo'].values\n-    assert 'b' not in result_df['bar'].values\n+    expected = pd.Categorical(\n+        np.array([datetime.date(2018, 4, 11)], dtype='datetime64'),\n+        categories=np.array(date_keys, dtype='datetime64'))\n+\n+    assert result_df['dates'].values == expected\n+\n+\n+@parquet\n+def test_inclusive_integer(tmpdir):\n+    fs = LocalFileSystem.get_instance()\n+    base_path = str(tmpdir)\n+\n+    import pyarrow.parquet as pq\n+\n+    integer_keys = [0, 1, 2, 3, 4]\n+    partition_spec = [\n+        ['integers', integer_keys],\n+    ]\n+    N = 5\n+\n+    df = pd.DataFrame({\n+        'index': np.arange(N),\n+        'integers': np.array(integer_keys, dtype='i4'),\n+    }, columns=['index', 'integers'])\n+\n+    _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+    dataset = pq.ParquetDataset(\n+        base_path, filesystem=fs,\n+        filters=[\n+            ('integers', '<=', 3),\n+            ('integers', '>=', 2),\n+        ]\n+    )\n+    table = dataset.read()\n+    result_df = (table.to_pandas()\n+                      .sort_values(by='index')\n+                      .reset_index(drop=True))\n+\n+    result_list = [int(x) for x in map(int, result_df['integers'].values)]\n+    assert result_list == [2, 3]\n+\n+\n+@parquet\n+def test_invalid_pred_op(tmpdir):\n+    fs = LocalFileSystem.get_instance()\n+    base_path = str(tmpdir)\n+\n+    import pyarrow.parquet as pq\n+\n+    integer_keys = [0, 1, 2, 3, 4]\n+    partition_spec = [\n+        ['integers', integer_keys],\n+    ]\n+    N = 5\n+\n+    df = pd.DataFrame({\n+        'index': np.arange(N),\n+        'integers': np.array(integer_keys, dtype='i4'),\n+    }, columns=['index', 'integers'])\n+\n+    _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+    with pytest.raises(ValueError):\n+        pq.ParquetDataset(base_path,\n+                          filesystem=fs,\n+                          filters=[\n+                            ('integers', '=<', 3),\n+                          ])\n \n \n @pytest.yield_fixture\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-05-01T10:21:05.948+0000",
                    "updated": "2018-05-01T10:21:05.948+0000",
                    "started": "2018-05-01T10:21:05.948+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "97030",
                    "issueId": "13151030"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 2400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@4a4611dc[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5beb505f[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@50c12846[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@5129e3a9[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@66d39430[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@54b366f3[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@d69f73b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@13c36994[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@69cb1dc8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@26807afc[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@64128138[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@6c15cbe7[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 2400,
        "customfield_12312520": null,
        "customfield_12312521": "Tue May 01 10:21:22 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-05-01T10:21:22.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-2422/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2018-04-09T12:32:17.000+0000",
        "updated": "2018-07-27T15:26:34.000+0000",
        "timeoriginalestimate": null,
        "description": "After implementing basic filters ('=', '!=') on Hive partitioned Parquet files (ARROW-2401), I'll extend them ('>', '<', '<=', '>=') with a new PR on Github.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 2400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Support more filter operators on Hive partitioned Parquet files",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16430459",
                    "id": "16430459",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jneuff opened a new pull request #1861: ARROW-2422 Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861\n \n \n   This extends the functionality of https://github.com/apache/arrow/pull/1840, by adding support for '<', '>', '<=', '>=' comparison operators in filters.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-09T12:36:25.631+0000",
                    "updated": "2018-04-09T12:36:25.631+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16430493",
                    "id": "16430493",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jneuff commented on issue #1861: ARROW-2422 Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#issuecomment-379742811\n \n \n   @pacman82\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-09T12:58:50.757+0000",
                    "updated": "2018-04-09T12:58:50.757+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16430628",
                    "id": "16430628",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "xhochy commented on issue #1861: ARROW-2422 Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#issuecomment-379777120\n \n \n   Can you add unit tests for more than just integer as a type?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-09T14:44:39.379+0000",
                    "updated": "2018-04-09T14:44:39.379+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16439186",
                    "id": "16439186",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jneuff commented on a change in pull request #1861: ARROW-2422 Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#discussion_r181675580\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -997,40 +997,159 @@ def test_read_partitioned_directory(tmpdir):\n \n \n @parquet\n-def test_read_partitioned_directory_filtered(tmpdir):\n-    fs = LocalFileSystem.get_instance()\n-    base_path = str(tmpdir)\n-\n-    import pyarrow.parquet as pq\n-\n-    foo_keys = [0, 1]\n-    bar_keys = ['a', 'b', 'c']\n-    partition_spec = [\n-        ['foo', foo_keys],\n-        ['bar', bar_keys]\n-    ]\n-    N = 30\n-\n-    df = pd.DataFrame({\n-        'index': np.arange(N),\n-        'foo': np.array(foo_keys, dtype='i4').repeat(15),\n-        'bar': np.tile(np.tile(np.array(bar_keys, dtype=object), 5), 2),\n-        'values': np.random.randn(N)\n-    }, columns=['index', 'foo', 'bar', 'values'])\n-\n-    _generate_partition_directories(fs, base_path, partition_spec, df)\n-\n-    dataset = pq.ParquetDataset(\n-        base_path, filesystem=fs,\n-        filters=[('foo', '=', 1), ('bar', '!=', 'b')]\n+class TestParquetFilter:\n+\n+    def test_equivalency(tmpdir):\n+        fs = LocalFileSystem.get_instance()\n+        base_path = str(tmpdir)\n+\n+        import pyarrow.parquet as pq\n+\n+        integer_keys = [0, 1]\n+        string_keys = ['a', 'b', 'c']\n+        boolean_keys = [True, False]\n+        partition_spec = [\n+            ['integer', integer_keys],\n+            ['string', string_keys],\n+            ['boolean', boolean_keys]\n+        ]\n+        N = 30\n+\n+        df = pd.DataFrame({\n+            'index': np.arange(N),\n+            'integer': np.array(integer_keys, dtype='i4').repeat(15),\n+            'string': np.tile(np.tile(np.array(string_keys, dtype=object), 5), 2),\n+            'boolean': np.tile(np.tile(np.array(boolean_keys, dtype='bool'), 5), 3),\n+        }, columns=['index', 'integer', 'string', 'boolean'])\n+\n+        _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+        dataset = pq.ParquetDataset(\n+            base_path, filesystem=fs,\n+            filters=[('integer', '=', 1), ('string', '!=', 'b'), ('boolean', '==', True)]\n+        )\n+        table = dataset.read()\n+        result_df = (table.to_pandas()\n+                     .sort_values(by='index')\n+                     .reset_index(drop=True))\n+\n+        assert 0 not in result_df['integer'].values\n+        assert 'b' not in result_df['string'].values\n+        assert False not in result_df['boolean'].values\n+\n+    def test_cutoff_exclusive_integer(tmpdir):\n+        fs = LocalFileSystem.get_instance()\n+        base_path = str(tmpdir)\n+\n+        import pyarrow.parquet as pq\n+\n+        integer_keys = [0, 1, 2, 3, 4]\n+        partition_spec = [\n+            ['integers', integer_keys],\n+        ]\n+        N = 5\n+\n+        df = pd.DataFrame({\n+            'index': np.arange(N),\n+            'integers': np.array(integer_keys, dtype='i4'),\n+        }, columns=['index', 'integers'])\n+\n+        _generate_partition_directories(fs, base_path, partition_spec, df)\n+\n+        dataset = pq.ParquetDataset(\n+            base_path, filesystem=fs,\n+            filters=[\n+                ('integers', '<', 4),\n+                ('integers', '>', 1),\n+            ]\n+        )\n+        table = dataset.read()\n+        result_df = (table.to_pandas()\n+                     .sort_values(by='index')\n+                     .reset_index(drop=True))\n+\n+        result_list = [x for x in map(int, result_df['integers'].values)]\n+        assert result_list == [2, 3]\n+\n+    @pytest.mark.xfail(\n+        raises=TypeError, reason='We suspect loss of type information in creation of categoricals.'\n     )\n \n Review comment:\n   @xhochy This is the behavior we just told you about offline. `result_df['dates'].values` seems to be of type `object` instead of `datetime64`.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-16T09:38:20.083+0000",
                    "updated": "2018-04-16T09:38:20.083+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16445569",
                    "id": "16445569",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "crepererum commented on a change in pull request #1861: ARROW-2422: Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#discussion_r183004838\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -864,12 +864,23 @@ def filter_accepts_partition(part_key, filter, level):\n             if p_column != f_column:\n                 return True\n \n-            f_value_index = self.partitions.get_index(level, p_column,\n-                                                      str(f_value))\n+            p_value = (self.partitions\n+                       .levels[level]\n+                       .dictionary[p_value_index]\n+                       .as_py())\n+\n             if op == \"=\":\n-                return f_value_index == p_value_index\n+                return p_value == f_value\n             elif op == \"!=\":\n-                return f_value_index != p_value_index\n+                return p_value != f_value\n+            elif op == '<':\n+                return p_value < f_value\n+            elif op == '>':\n+                return p_value > f_value\n+            elif op == '<=':\n+                return p_value <= f_value\n+            elif op == '>=':\n+                return p_value >= f_value\n             else:\n                 return True\n \n Review comment:\n   Should a unknown op not raise instead of just being ignored?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-20T10:05:31.680+0000",
                    "updated": "2018-04-20T10:05:31.680+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16447953",
                    "id": "16447953",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jneuff commented on a change in pull request #1861: ARROW-2422: Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#discussion_r183354699\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -864,12 +864,23 @@ def filter_accepts_partition(part_key, filter, level):\n             if p_column != f_column:\n                 return True\n \n-            f_value_index = self.partitions.get_index(level, p_column,\n-                                                      str(f_value))\n+            p_value = (self.partitions\n+                       .levels[level]\n+                       .dictionary[p_value_index]\n+                       .as_py())\n+\n             if op == \"=\":\n \n Review comment:\n   Should we replace `\"=\"` with `\"==\"`?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-23T11:01:57.468+0000",
                    "updated": "2018-04-23T11:01:57.468+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16447956",
                    "id": "16447956",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "jneuff commented on a change in pull request #1861: ARROW-2422: Support more operators for partition filtering\nURL: https://github.com/apache/arrow/pull/1861#discussion_r183355089\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -864,12 +864,23 @@ def filter_accepts_partition(part_key, filter, level):\n             if p_column != f_column:\n                 return True\n \n-            f_value_index = self.partitions.get_index(level, p_column,\n-                                                      str(f_value))\n+            p_value = (self.partitions\n+                       .levels[level]\n+                       .dictionary[p_value_index]\n+                       .as_py())\n+\n             if op == \"=\":\n-                return f_value_index == p_value_index\n+                return p_value == f_value\n             elif op == \"!=\":\n-                return f_value_index != p_value_index\n+                return p_value != f_value\n+            elif op == '<':\n+                return p_value < f_value\n+            elif op == '>':\n+                return p_value > f_value\n+            elif op == '<=':\n+                return p_value <= f_value\n+            elif op == '>=':\n+                return p_value >= f_value\n             else:\n                 return True\n \n Review comment:\n   I take that as a yes.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-04-23T11:03:29.570+0000",
                    "updated": "2018-04-23T11:03:29.570+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13151030/comment/16459586",
                    "id": "16459586",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=uwe",
                        "name": "uwe",
                        "key": "xhochy",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=xhochy&avatarId=30652",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xhochy&avatarId=30652",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xhochy&avatarId=30652",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xhochy&avatarId=30652"
                        },
                        "displayName": "Uwe Korn",
                        "active": true,
                        "timeZone": "Europe/Berlin"
                    },
                    "body": "Issue resolved by pull request 1861\n[https://github.com/apache/arrow/pull/1861]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=uwe",
                        "name": "uwe",
                        "key": "xhochy",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=xhochy&avatarId=30652",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=xhochy&avatarId=30652",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=xhochy&avatarId=30652",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=xhochy&avatarId=30652"
                        },
                        "displayName": "Uwe Korn",
                        "active": true,
                        "timeZone": "Europe/Berlin"
                    },
                    "created": "2018-05-01T10:21:22.653+0000",
                    "updated": "2018-05-01T10:21:22.653+0000"
                }
            ],
            "maxResults": 8,
            "total": 8,
            "startAt": 0
        },
        "customfield_12311820": "0|i3sb73:",
        "customfield_12314139": null
    }
}