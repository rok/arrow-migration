{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13346100",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100",
    "key": "ARROW-10918",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12348823",
                "id": "12348823",
                "description": "",
                "name": "3.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-01-25"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12620617",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12620617",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13258848",
                    "key": "ARROW-6699",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13258848",
                    "fields": {
                        "summary": "[C++] Add Parquet docs",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12605005",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12605005",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13346379",
                    "key": "ARROW-10941",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346379",
                    "fields": {
                        "summary": "[Doc][C++] Document supported Parquet encryption features",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
                            "id": "3",
                            "description": "A task that needs to be done.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
                            "name": "Task",
                            "subtask": false,
                            "avatarId": 21148
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12332532",
                "id": "12332532",
                "name": "Documentation"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "aggregateprogress": {
            "progress": 10200,
            "total": 10200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 10200,
            "total": 10200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-10918/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 17,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524540",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou opened a new pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928\n\n\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T16:33:48.846+0000",
                    "updated": "2020-12-15T16:33:48.846+0000",
                    "started": "2020-12-15T16:33:48.846+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524540",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524544",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#issuecomment-745411030\n\n\n   @emkornfield I'm not sure everything is covered adequately. I would welcome your validation on this.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T16:37:33.528+0000",
                    "updated": "2020-12-15T16:37:33.528+0000",
                    "started": "2020-12-15T16:37:33.527+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524544",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524551",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nevi-me commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543504470\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n\nReview comment:\n       Is it not better to map it to a Parquet timestamp? I'm assuming that some resolution is lost if mapping to int32\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n\nReview comment:\n       Do you support `LargeUtf8`?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T16:44:00.278+0000",
                    "updated": "2020-12-15T16:44:00.278+0000",
                    "started": "2020-12-15T16:44:00.278+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524551",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524554",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#issuecomment-745420463\n\n\n   https://issues.apache.org/jira/browse/ARROW-10918\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T16:51:12.420+0000",
                    "updated": "2020-12-15T16:51:12.420+0000",
                    "started": "2020-12-15T16:51:12.420+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524554",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524556",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543514265\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n\nReview comment:\n       Yes, it is. So is `LargeBinary`. I'll add a note, thanks.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T16:53:08.731+0000",
                    "updated": "2020-12-15T16:53:08.731+0000",
                    "started": "2020-12-15T16:53:08.731+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524556",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524560",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543516189\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n\nReview comment:\n       While Arrow Date64 is represented as a number of milliseconds since the Unix epoch, it logically only represents entire days. From the Schema flatbuffers file:\r\n   ```\r\n   /// Date is either a 32-bit or 64-bit type representing elapsed time since UNIX\r\n   /// epoch (1970-01-01), stored in either of two units:\r\n   ///\r\n   /// * Milliseconds (64 bits) indicating UNIX time elapsed since the epoch (no\r\n   ///   leap seconds), where the values are evenly divisible by 86400000\r\n   /// * Days (32 bits) since the UNIX epoch\r\n   table Date {\r\n     unit: DateUnit = MILLISECOND;\r\n   }\r\n   ```\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T16:55:30.356+0000",
                    "updated": "2020-12-15T16:55:30.356+0000",
                    "started": "2020-12-15T16:55:30.355+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524560",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524565",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nevi-me commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543521956\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n\nReview comment:\n       Ah, I read that today, but it went over my head. I'll change #8926. Do/should we enforce this when creating a Date64 array, by checking if the value is divisible by 86400000?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T17:02:16.528+0000",
                    "updated": "2020-12-15T17:02:16.528+0000",
                    "started": "2020-12-15T17:02:16.528+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524565",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524566",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nevi-me commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543521956\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n\nReview comment:\n       Ah, I read that today, but it went over my head. I'll change #8926. Should we enforce this in Rust when creating a Date64 array, by checking if the value is divisible by 86400000?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T17:02:29.577+0000",
                    "updated": "2020-12-15T17:02:29.577+0000",
                    "started": "2020-12-15T17:02:29.576+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524566",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524571",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543532965\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n\nReview comment:\n       You could have an option to check that. I don't think it's mandatory to do it by default.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T17:16:57.714+0000",
                    "updated": "2020-12-15T17:16:57.714+0000",
                    "started": "2020-12-15T17:16:57.714+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524571",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524574",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543535005\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n\nReview comment:\n       (related: ARROW-10924)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T17:19:41.540+0000",
                    "updated": "2020-12-15T17:19:41.540+0000",
                    "started": "2020-12-15T17:19:41.540+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524574",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524579",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nevi-me commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r543539734\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,203 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+---------+\n+| Physical type            | Mapped Arrow type       | Notes   |\n++==========================+=========================+=========+\n+| BOOLEAN                  | Boolean                 |         |\n++--------------------------+-------------------------+---------+\n+| INT32                    | Int32 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT64                    | Int64 / other           | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)    |\n++--------------------------+-------------------------+---------+\n+| FLOAT                    | Float32                 |         |\n++--------------------------+-------------------------+---------+\n+| DOUBLE                   | Float64                 |         |\n++--------------------------+-------------------------+---------+\n+| BYTE_ARRAY               | Binary / other          | \\(1)    |\n++--------------------------+-------------------------+---------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)    |\n++--------------------------+-------------------------+---------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n\nReview comment:\n       Thanks, also opened ARROW-10925\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-15T17:26:42.818+0000",
                    "updated": "2020-12-15T17:26:42.818+0000",
                    "started": "2020-12-15T17:26:42.817+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524579",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524863",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r544071122\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,207 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n\nReview comment:\n       Would it make sense (to the extent we know), to also list the features we do not support (not in the table, but eg in a sentence after the table)?\r\n   \r\n   For example for the encodings there are ones we do not support?\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,207 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+------------+\n+| Physical type            | Mapped Arrow type       | Notes      |\n++==========================+=========================+============+\n+| BOOLEAN                  | Boolean                 |            |\n++--------------------------+-------------------------+------------+\n+| INT32                    | Int32 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT64                    | Int64 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)       |\n++--------------------------+-------------------------+------------+\n+| FLOAT                    | Float32                 |            |\n++--------------------------+-------------------------+------------+\n+| DOUBLE                   | Float64                 |            |\n++--------------------------+-------------------------+------------+\n+| BYTE_ARRAY               | Binary / other          | \\(1) \\(3)  |\n++--------------------------+-------------------------+------------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)       |\n++--------------------------+-------------------------+------------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+* \\(3) On the write side, an Arrow LargeBinary can also mapped to BYTE_ARRAY.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n\nReview comment:\n       An example of this is JSON/BSON ?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-16T07:34:48.853+0000",
                    "updated": "2020-12-16T07:34:48.853+0000",
                    "started": "2020-12-16T07:34:48.853+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524863",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524866",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r544081105\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,207 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+------------+\n+| Physical type            | Mapped Arrow type       | Notes      |\n++==========================+=========================+============+\n+| BOOLEAN                  | Boolean                 |            |\n++--------------------------+-------------------------+------------+\n+| INT32                    | Int32 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT64                    | Int64 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)       |\n++--------------------------+-------------------------+------------+\n+| FLOAT                    | Float32                 |            |\n++--------------------------+-------------------------+------------+\n+| DOUBLE                   | Float64                 |            |\n++--------------------------+-------------------------+------------+\n+| BYTE_ARRAY               | Binary / other          | \\(1) \\(3)  |\n++--------------------------+-------------------------+------------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)       |\n++--------------------------+-------------------------+------------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+* \\(3) On the write side, an Arrow LargeBinary can also mapped to BYTE_ARRAY.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(4)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        |         |\n\nReview comment:\n       the read side doesn't conform to the parquet specification because repeated elements are not deduplicated.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-16T07:49:15.761+0000",
                    "updated": "2020-12-16T07:49:15.761+0000",
                    "started": "2020-12-16T07:49:15.761+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524866",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524867",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r544081781\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,207 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+------------+\n+| Physical type            | Mapped Arrow type       | Notes      |\n++==========================+=========================+============+\n+| BOOLEAN                  | Boolean                 |            |\n++--------------------------+-------------------------+------------+\n+| INT32                    | Int32 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT64                    | Int64 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)       |\n++--------------------------+-------------------------+------------+\n+| FLOAT                    | Float32                 |            |\n++--------------------------+-------------------------+------------+\n+| DOUBLE                   | Float64                 |            |\n++--------------------------+-------------------------+------------+\n+| BYTE_ARRAY               | Binary / other          | \\(1) \\(3)  |\n++--------------------------+-------------------------+------------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)       |\n++--------------------------+-------------------------+------------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+* \\(3) On the write side, an Arrow LargeBinary can also mapped to BYTE_ARRAY.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n\nReview comment:\n       decimal256 is only used if the original type written from arrow is decimal256 or the precision exceeds decimal 128.  Arrow only writes FLBA for decimals.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-16T07:50:21.982+0000",
                    "updated": "2020-12-16T07:50:21.982+0000",
                    "started": "2020-12-16T07:50:21.982+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524867",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524868",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "emkornfield commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r544082188\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,207 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+------------+\n+| Physical type            | Mapped Arrow type       | Notes      |\n++==========================+=========================+============+\n+| BOOLEAN                  | Boolean                 |            |\n++--------------------------+-------------------------+------------+\n+| INT32                    | Int32 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT64                    | Int64 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)       |\n++--------------------------+-------------------------+------------+\n+| FLOAT                    | Float32                 |            |\n++--------------------------+-------------------------+------------+\n+| DOUBLE                   | Float64                 |            |\n++--------------------------+-------------------------+------------+\n+| BYTE_ARRAY               | Binary / other          | \\(1) \\(3)  |\n++--------------------------+-------------------------+------------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)       |\n++--------------------------+-------------------------+------------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+* \\(3) On the write side, an Arrow LargeBinary can also mapped to BYTE_ARRAY.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n+\n++-------------------+-----------------------------+----------------------------+---------+\n+| Logical type      | Physical type               | Mapped Arrow type          | Notes   |\n++===================+=============================+============================+=========+\n+| NULL              | Any                         | Null                       | \\(1)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT32                       | Int8 / UInt8 / Int16 /     |         |\n+|                   |                             | UInt16 / Int32 / UInt32    |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| INT               | INT64                       | Int64 / UInt64             |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DECIMAL           | INT32 / INT64 / BYTE_ARRAY  | Decimal128 / Decimal256    |         |\n+|                   | / FIXED_LENGTH_BYTE_ARRAY   |                            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| DATE              | INT32                       | Date32                     | \\(2)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT32                       | Time32 (milliseconds)      |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIME              | INT64                       | Time64 (micro- or          |         |\n+|                   |                             | nanoseconds)               |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| TIMESTAMP         | INT64                       | Timestamp (milli-, micro-  |         |\n+|                   |                             | or nanoseconds)            |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+| STRING            | BYTE_ARRAY                  | Utf8                       | \\(3)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| LIST              | Any                         | List                       | \\(4)    |\n++-------------------+-----------------------------+----------------------------+---------+\n+| MAP               | Any                         | Map                        |         |\n++-------------------+-----------------------------+----------------------------+---------+\n+\n+* \\(1) On the write side, the Parquet physical type INT32 is generated.\n+\n+* \\(2) On the write side, an Arrow Date64 is also mapped to a Parquet DATE INT32.\n+\n+* \\(3) On the write side, an Arrow LargeUtf8 is also mapped to a Parquet STRING.\n+\n+* \\(4) On the write side, an Arrow LargeList or FixedSizedList is also mapped to\n\nReview comment:\n       it might be worth noting that unless the file was written with arrow metadata Arrow will not handle converting to Large types.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-16T07:51:06.272+0000",
                    "updated": "2020-12-16T07:51:06.272+0000",
                    "started": "2020-12-16T07:51:06.272+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524868",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/524949",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928#discussion_r544184629\n\n\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,207 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n\nReview comment:\n       Yep, it could.\n\n##########\nFile path: docs/source/cpp/parquet.rst\n##########\n@@ -27,15 +27,207 @@ Reading and writing Parquet files\n .. seealso::\n    :ref:`Parquet reader and writer API reference <cpp-api-parquet>`.\n \n-The Parquet C++ library is part of the Apache Arrow project and benefits\n-from tight integration with Arrow C++.\n+The `Parquet format <https://parquet.apache.org/documentation/latest/>`__\n+is a space-efficient columnar storage format for complex data.  The Parquet\n+C++ implementation is part of the Apache Arrow project and benefits\n+from tight integration with the Arrow C++ classes and facilities.\n+\n+Supported Parquet features\n+==========================\n+\n+The Parquet format has many features, and Parquet C++ supports a subset of them.\n+\n+Page types\n+----------\n+\n++-------------------+---------+\n+| Page type         | Notes   |\n++===================+=========+\n+| DATA_PAGE         |         |\n++-------------------+---------+\n+| DATA_PAGE_V2      |         |\n++-------------------+---------+\n+| DICTIONARY_PAGE   |         |\n++-------------------+---------+\n+\n+Compression\n+-----------\n+\n++-------------------+---------+\n+| Compression codec | Notes   |\n++===================+=========+\n+| SNAPPY            |         |\n++-------------------+---------+\n+| GZIP              |         |\n++-------------------+---------+\n+| BROTLI            |         |\n++-------------------+---------+\n+| LZ4               | \\(1)    |\n++-------------------+---------+\n+| ZSTD              |         |\n++-------------------+---------+\n+\n+* \\(1) On the read side, Parquet C++ is able to decompress both the regular\n+  LZ4 block format and the ad-hoc Hadoop LZ4 format used by the\n+  `reference Parquet implementation <https://github.com/apache/parquet-mr>`__.\n+  On the write side, Parquet C++ always generates the ad-hoc Hadoop LZ4 format.\n+\n+Encodings\n+---------\n+\n++--------------------------+---------+\n+| Encoding                 | Notes   |\n++==========================+=========+\n+| PLAIN                    |         |\n++--------------------------+---------+\n+| PLAIN_DICTIONARY         |         |\n++--------------------------+---------+\n+| BIT_PACKED               |         |\n++--------------------------+---------+\n+| RLE                      | \\(1)    |\n++--------------------------+---------+\n+| RLE_DICTIONARY           | \\(2)    |\n++--------------------------+---------+\n+| BYTE_STREAM_SPLIT        |         |\n++--------------------------+---------+\n+\n+* \\(1) Only supported for encoding definition and repetition levels, not values.\n+\n+* \\(2) On the write path, RLE_DICTIONARY is only enabled if Parquet format version\n+  2.0 (or potentially greater) is selected in :func:`WriterProperties::version`.\n+\n+Types\n+-----\n+\n+Physical types\n+~~~~~~~~~~~~~~\n+\n++--------------------------+-------------------------+------------+\n+| Physical type            | Mapped Arrow type       | Notes      |\n++==========================+=========================+============+\n+| BOOLEAN                  | Boolean                 |            |\n++--------------------------+-------------------------+------------+\n+| INT32                    | Int32 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT64                    | Int64 / other           | \\(1)       |\n++--------------------------+-------------------------+------------+\n+| INT96                    | Timestamp (nanoseconds) | \\(2)       |\n++--------------------------+-------------------------+------------+\n+| FLOAT                    | Float32                 |            |\n++--------------------------+-------------------------+------------+\n+| DOUBLE                   | Float64                 |            |\n++--------------------------+-------------------------+------------+\n+| BYTE_ARRAY               | Binary / other          | \\(1) \\(3)  |\n++--------------------------+-------------------------+------------+\n+| FIXED_LENGTH_BYTE_ARRAY  | FixedSizeBinary / other | \\(1)       |\n++--------------------------+-------------------------+------------+\n+\n+* \\(1) Can be mapped to other Arrow types, depending on the logical type\n+  (see below).\n+\n+* \\(2) On the write side, :func:`ArrowWriterProperties::support_deprecated_int96_timestamps`\n+  must be enabled.\n+\n+* \\(3) On the write side, an Arrow LargeBinary can also mapped to BYTE_ARRAY.\n+\n+Logical types\n+~~~~~~~~~~~~~\n+\n+Specific logical types can override the default Arrow type mapping for a given\n+physical type.  If the Parquet file contains an unrecognized logical type,\n+the default physical type mapping is used.\n\nReview comment:\n       Right.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-16T10:29:13.938+0000",
                    "updated": "2020-12-16T10:29:13.938+0000",
                    "started": "2020-12-16T10:29:13.937+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "524949",
                    "issueId": "13346100"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/worklog/525046",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou closed pull request #8928:\nURL: https://github.com/apache/arrow/pull/8928\n\n\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-12-16T14:38:50.887+0000",
                    "updated": "2020-12-16T14:38:50.887+0000",
                    "started": "2020-12-16T14:38:50.887+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "525046",
                    "issueId": "13346100"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
            "id": "3",
            "description": "A task that needs to be done.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
            "name": "Task",
            "subtask": false,
            "avatarId": 21148
        },
        "timespent": 10200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2c2e6992[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2d8578e8[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3c5a447f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@3a9e3924[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@704dcb08[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@2dec3a6a[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@437bea14[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@867ac46[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@16ec33c9[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@5a1f7414[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@46a81e09[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@73989f06[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 10200,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Dec 16 14:38:45 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-12-16T14:38:45.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-10918/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2020-12-15T12:35:11.000+0000",
        "updated": "2021-08-05T15:33:24.000+0000",
        "timeoriginalestimate": null,
        "description": "We should document the Parquet features supported by our C++ implementation.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "2h 50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 10200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Doc] Document supported Parquet features",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13346100/comment/17250353",
                    "id": "17250353",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Issue resolved by pull request 8928\n[https://github.com/apache/arrow/pull/8928]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2020-12-16T14:38:45.701+0000",
                    "updated": "2020-12-16T14:38:45.701+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0lizs:",
        "customfield_12314139": null
    }
}