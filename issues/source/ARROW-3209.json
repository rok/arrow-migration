{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13184141",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141",
    "key": "ARROW-3209",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343858",
                "id": "12343858",
                "description": "",
                "name": "0.12.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-01-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 8400,
            "total": 8400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 8400,
            "total": 8400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3209/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 14,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/171955",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou opened a new pull request #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088\n \n \n   Also rename the arrow::gpu namespace to arrow::cuda.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-04T17:16:12.413+0000",
                    "updated": "2018-12-04T17:16:12.413+0000",
                    "started": "2018-12-04T17:16:12.413+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "171955",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/171956",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444181229\n \n \n   I think the C glib side needs to be fixed, but I'm not sure how. @kou would you like to push something to this PR?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-04T17:16:40.908+0000",
                    "updated": "2018-12-04T17:16:40.908+0000",
                    "started": "2018-12-04T17:16:40.908+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "171956",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/171973",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444193328\n \n \n   Ah, I forgot about the disruption that this would cause to the glib side, where there are also Linux packages. I think it's a good idea to leave open the possibility of GPU computing outside of CUDA\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-04T17:50:58.055+0000",
                    "updated": "2018-12-04T17:50:58.055+0000",
                    "started": "2018-12-04T17:50:58.054+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "171973",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172165",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444371650\n \n \n   I'll add some commits for C GLib, Ruby and Linux packages to this PR.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-05T06:14:40.635+0000",
                    "updated": "2018-12-05T06:14:40.635+0000",
                    "started": "2018-12-05T06:14:40.634+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172165",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172187",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444402421\n \n \n   It seems that `Cuda` in `arrow::cuda::Cuda*` is redundant.\r\n   Should we keep `Cuda` or remove `Cuda`?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-05T08:35:41.547+0000",
                    "updated": "2018-12-05T08:35:41.547+0000",
                    "started": "2018-12-05T08:35:41.546+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172187",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172193",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444406491\n \n \n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=h1) Report\n   > Merging [#3088](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=desc) into [master](https://codecov.io/gh/apache/arrow/commit/4ac4eb569978b214e41c9d4254533b4b2ac09875?src=pr&el=desc) will **increase** coverage by `1.03%`.\n   > The diff coverage is `n/a`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/3088/graphs/tree.svg?width=650&token=LpTCFbqVT1&height=150&src=pr)](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #3088      +/-   ##\n   ==========================================\n   + Coverage   87.12%   88.15%   +1.03%     \n   ==========================================\n     Files         492      434      -58     \n     Lines       69104    65339    -3765     \n   ==========================================\n   - Hits        60204    57601    -2603     \n   + Misses       8801     7738    -1063     \n   + Partials       99        0      -99\n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [cpp/src/plasma/client.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvY2xpZW50LmNj) | `84.68% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/protocol.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvcHJvdG9jb2wuY2M=) | `95.62% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/plasma.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvcGxhc21hLmg=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/store.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvc3RvcmUuaA==) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/store.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvc3RvcmUuY2M=) | `92.42% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/common.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvY29tbW9uLmg=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/test/client\\_tests.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvdGVzdC9jbGllbnRfdGVzdHMuY2M=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [go/arrow/array/table.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvYXJyYXkvdGFibGUuZ28=) | | |\n   | [go/arrow/math/uint64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC91aW50NjRfYW1kNjQuZ28=) | | |\n   | [go/arrow/internal/testing/tools/bool.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvaW50ZXJuYWwvdGVzdGluZy90b29scy9ib29sLmdv) | | |\n   | ... and [55 more](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree-more) | |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=footer). Last update [4ac4eb5...f8683ca](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-05T08:49:59.493+0000",
                    "updated": "2018-12-05T08:49:59.493+0000",
                    "started": "2018-12-05T08:49:59.492+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172193",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172197",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io edited a comment on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444406491\n \n \n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=h1) Report\n   > Merging [#3088](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=desc) into [master](https://codecov.io/gh/apache/arrow/commit/4ac4eb569978b214e41c9d4254533b4b2ac09875?src=pr&el=desc) will **increase** coverage by `1.03%`.\n   > The diff coverage is `n/a`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/3088/graphs/tree.svg?width=650&token=LpTCFbqVT1&height=150&src=pr)](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #3088      +/-   ##\n   ==========================================\n   + Coverage   87.12%   88.15%   +1.03%     \n   ==========================================\n     Files         492      434      -58     \n     Lines       69104    65339    -3765     \n   ==========================================\n   - Hits        60204    57600    -2604     \n   + Misses       8801     7739    -1062     \n   + Partials       99        0      -99\n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [cpp/src/plasma/client.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvY2xpZW50LmNj) | `84.68% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/protocol.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvcHJvdG9jb2wuY2M=) | `95.62% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/plasma.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvcGxhc21hLmg=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/store.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvc3RvcmUuaA==) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/store.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvc3RvcmUuY2M=) | `92.42% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/common.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvY29tbW9uLmg=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/test/client\\_tests.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvdGVzdC9jbGllbnRfdGVzdHMuY2M=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/arrow/csv/column-builder.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9hcnJvdy9jc3YvY29sdW1uLWJ1aWxkZXIuY2M=) | `95.45% <0%> (-1.95%)` | :arrow_down: |\n   | [go/arrow/array/table.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvYXJyYXkvdGFibGUuZ28=) | | |\n   | [go/arrow/math/uint64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC91aW50NjRfYW1kNjQuZ28=) | | |\n   | ... and [58 more](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree-more) | |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=footer). Last update [4ac4eb5...219ffa2](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-05T09:17:40.446+0000",
                    "updated": "2018-12-05T09:17:40.446+0000",
                    "started": "2018-12-05T09:17:40.445+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172197",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172203",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444424909\n \n \n   > It seems that Cuda in `arrow::cuda::Cuda*` is redundant. Should we keep Cuda or remove Cuda?\r\n   \r\n   I'd keep it.\r\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-05T09:50:36.744+0000",
                    "updated": "2018-12-05T09:50:36.744+0000",
                    "started": "2018-12-05T09:50:36.743+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172203",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172211",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "codecov-io edited a comment on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444406491\n \n \n   # [Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=h1) Report\n   > Merging [#3088](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=desc) into [master](https://codecov.io/gh/apache/arrow/commit/4ac4eb569978b214e41c9d4254533b4b2ac09875?src=pr&el=desc) will **increase** coverage by `1.03%`.\n   > The diff coverage is `n/a`.\n   \n   [![Impacted file tree graph](https://codecov.io/gh/apache/arrow/pull/3088/graphs/tree.svg?width=650&token=LpTCFbqVT1&height=150&src=pr)](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=tree)\n   \n   ```diff\n   @@            Coverage Diff             @@\n   ##           master    #3088      +/-   ##\n   ==========================================\n   + Coverage   87.12%   88.15%   +1.03%     \n   ==========================================\n     Files         492      434      -58     \n     Lines       69104    65339    -3765     \n   ==========================================\n   - Hits        60204    57601    -2603     \n   + Misses       8801     7738    -1063     \n   + Partials       99        0      -99\n   ```\n   \n   \n   | [Impacted Files](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=tree) | Coverage \u0394 | |\n   |---|---|---|\n   | [cpp/src/plasma/client.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvY2xpZW50LmNj) | `84.68% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/protocol.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvcHJvdG9jb2wuY2M=) | `95.62% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/plasma.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvcGxhc21hLmg=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/store.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvc3RvcmUuaA==) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/store.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvc3RvcmUuY2M=) | `92.42% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/common.h](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvY29tbW9uLmg=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [cpp/src/plasma/test/client\\_tests.cc](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Y3BwL3NyYy9wbGFzbWEvdGVzdC9jbGllbnRfdGVzdHMuY2M=) | `100% <\u00f8> (\u00f8)` | :arrow_up: |\n   | [go/arrow/array/table.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvYXJyYXkvdGFibGUuZ28=) | | |\n   | [go/arrow/math/uint64\\_amd64.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvbWF0aC91aW50NjRfYW1kNjQuZ28=) | | |\n   | [go/arrow/internal/testing/tools/bool.go](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree#diff-Z28vYXJyb3cvaW50ZXJuYWwvdGVzdGluZy90b29scy9ib29sLmdv) | | |\n   | ... and [55 more](https://codecov.io/gh/apache/arrow/pull/3088/diff?src=pr&el=tree-more) | |\n   \n   ------\n   \n   [Continue to review full report at Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=continue).\n   > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)\n   > `\u0394 = absolute <relative> (impact)`, `\u00f8 = not affected`, `? = missing data`\n   > Powered by [Codecov](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=footer). Last update [4ac4eb5...219ffa2](https://codecov.io/gh/apache/arrow/pull/3088?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-05T09:56:30.011+0000",
                    "updated": "2018-12-05T09:56:30.011+0000",
                    "started": "2018-12-05T09:56:30.010+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172211",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172396",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444565002\n \n \n   Some of the Linux packages failed\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-05T17:10:40.143+0000",
                    "updated": "2018-12-05T17:10:40.143+0000",
                    "started": "2018-12-05T17:10:40.142+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172396",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172562",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444730433\n \n \n   Linux package builds are fixed: https://github.com/kou/crossbow/branches/all?utf8=%E2%9C%93&query=build-54\r\n   \r\n   I'll merge this when CI is passed.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-06T02:55:08.148+0000",
                    "updated": "2018-12-06T02:55:08.148+0000",
                    "started": "2018-12-06T02:55:08.147+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172562",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172563",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444731857\n \n \n   Great, thanks @kou!\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-06T03:03:07.611+0000",
                    "updated": "2018-12-06T03:03:07.611+0000",
                    "started": "2018-12-06T03:03:07.610+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172563",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172564",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou commented on issue #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088#issuecomment-444735536\n \n \n   CI is green. I'll merge this.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-06T03:25:31.224+0000",
                    "updated": "2018-12-06T03:25:31.224+0000",
                    "started": "2018-12-06T03:25:31.223+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172564",
                    "issueId": "13184141"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/worklog/172565",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "kou closed pull request #3088: ARROW-3209: [C++] Rename libarrow_gpu to libarrow_cuda\nURL: https://github.com/apache/arrow/pull/3088\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/c_glib/.gitignore b/c_glib/.gitignore\nindex cc7a19348a..18f952e0b3 100644\n--- a/c_glib/.gitignore\n+++ b/c_glib/.gitignore\n@@ -51,12 +51,12 @@ Makefile.in\n /libtool\n /m4/\n /stamp-h1\n+/arrow-cuda-glib/*.pc\n /arrow-glib/enums.c\n /arrow-glib/enums.h\n /arrow-glib/stamp-*\n /arrow-glib/version.h\n /arrow-glib/*.pc\n-/arrow-gpu-glib/*.pc\n /gandiva-glib/*.pc\n /parquet-glib/*.pc\n /plasma-glib/*.pc\ndiff --git a/c_glib/Makefile.am b/c_glib/Makefile.am\nindex d21555e12b..149894c824 100644\n--- a/c_glib/Makefile.am\n+++ b/c_glib/Makefile.am\n@@ -19,7 +19,7 @@ ACLOCAL_AMFLAGS = -I m4 ${ACLOCAL_FLAGS}\n \n SUBDIRS =\t\t\t\t\t\\\n \tarrow-glib\t\t\t\t\\\n-\tarrow-gpu-glib\t\t\t\t\\\n+\tarrow-cuda-glib\t\t\t\t\\\n \tgandiva-glib\t\t\t\t\\\n \tparquet-glib\t\t\t\t\\\n \tplasma-glib\t\t\t\t\\\ndiff --git a/c_glib/arrow-gpu-glib/Makefile.am b/c_glib/arrow-cuda-glib/Makefile.am\nsimilarity index 64%\nrename from c_glib/arrow-gpu-glib/Makefile.am\nrename to c_glib/arrow-cuda-glib/Makefile.am\nindex a1249035a5..2e3848d2a0 100644\n--- a/c_glib/arrow-gpu-glib/Makefile.am\n+++ b/c_glib/arrow-cuda-glib/Makefile.am\n@@ -24,51 +24,51 @@ AM_CPPFLAGS =\t\t\t\t\t\\\n \t-I$(top_builddir)\t\t\t\\\n \t-I$(top_srcdir)\n \n-if HAVE_ARROW_GPU\n+if HAVE_ARROW_CUDA\n lib_LTLIBRARIES =\t\t\t\t\\\n-\tlibarrow-gpu-glib.la\n+\tlibarrow-cuda-glib.la\n \n-libarrow_gpu_glib_la_CXXFLAGS =\t\t\t\\\n+libarrow_cuda_glib_la_CXXFLAGS =\t\t\\\n \t$(GLIB_CFLAGS)\t\t\t\t\\\n \t$(ARROW_CFLAGS)\t\t\t\t\\\n-\t$(ARROW_GPU_CFLAGS)\t\t\t\\\n+\t$(ARROW_CUDA_CFLAGS)\t\t\t\\\n \t$(GARROW_CXXFLAGS)\n \n-libarrow_gpu_glib_la_LDFLAGS =\t\t\t\\\n+libarrow_cuda_glib_la_LDFLAGS =\t\t\t\\\n \t-version-info $(LT_VERSION_INFO)\t\\\n \t-no-undefined\n \n-libarrow_gpu_glib_la_LIBADD =\t\t\t\\\n+libarrow_cuda_glib_la_LIBADD =\t\t\t\\\n \t$(GLIB_LIBS)\t\t\t\t\\\n \t$(ARROW_LIBS)\t\t\t\t\\\n-\t$(ARROW_GPU_LIBS)\t\t\t\\\n+\t$(ARROW_CUDA_LIBS)\t\t\t\\\n \t../arrow-glib/libarrow-glib.la\n \n-libarrow_gpu_glib_la_headers =\t\t\t\\\n-\tarrow-gpu-glib.h\t\t\t\\\n+libarrow_cuda_glib_la_headers =\t\t\t\\\n+\tarrow-cuda-glib.h\t\t\t\\\n \tcuda.h\n \n-libarrow_gpu_glib_la_sources =\t\t\t\\\n+libarrow_cuda_glib_la_sources =\t\t\t\\\n \tcuda.cpp\t\t\t\t\\\n-\t$(libarrow_gpu_glib_la_headers)\n+\t$(libarrow_cuda_glib_la_headers)\n \n-libarrow_gpu_glib_la_cpp_headers =\t\t\\\n-\tarrow-gpu-glib.hpp\t\t\t\\\n+libarrow_cuda_glib_la_cpp_headers =\t\t\\\n+\tarrow-cuda-glib.hpp\t\t\t\\\n \tcuda.hpp\n \n-libarrow_gpu_glib_la_SOURCES =\t\t\t\\\n-\t$(libarrow_gpu_glib_la_sources)\t\t\\\n-\t$(libarrow_gpu_glib_la_cpp_headers)\n+libarrow_cuda_glib_la_SOURCES =\t\t\t\\\n+\t$(libarrow_cuda_glib_la_sources)\t\\\n+\t$(libarrow_cuda_glib_la_cpp_headers)\n \n-arrow_gpu_glib_includedir =\t\t\t\\\n-\t$(includedir)/arrow-gpu-glib\n-arrow_gpu_glib_include_HEADERS =\t\t\\\n-\t$(libarrow_gpu_glib_la_headers)\t\t\\\n-\t$(libarrow_gpu_glib_la_cpp_headers)\n+arrow_cuda_glib_includedir =\t\t\t\\\n+\t$(includedir)/arrow-cuda-glib\n+arrow_cuda_glib_include_HEADERS =\t\t\\\n+\t$(libarrow_cuda_glib_la_headers)\t\\\n+\t$(libarrow_cuda_glib_la_cpp_headers)\n \n pkgconfigdir = $(libdir)/pkgconfig\n pkgconfig_DATA =\t\t\t\t\\\n-\tarrow-gpu-glib.pc\n+\tarrow-cuda-glib.pc\n \n if HAVE_INTROSPECTION\n -include $(INTROSPECTION_MAKEFILE)\n@@ -85,39 +85,39 @@ endif\n INTROSPECTION_COMPILER_ARGS =\t\t\t\\\n \t--includedir=$(abs_builddir)/../arrow-glib\n \n-ArrowGPU-1.0.gir: libarrow-gpu-glib.la\n-ArrowGPU_1_0_gir_PACKAGES =\t\t\t\\\n+ArrowCUDA-1.0.gir: libarrow-cuda-glib.la\n+ArrowCUDA_1_0_gir_PACKAGES =\t\t\t\\\n \tarrow-glib\n-ArrowGPU_1_0_gir_EXPORT_PACKAGES =\t\t\\\n-\tarrow-gpu-glib\n-ArrowGPU_1_0_gir_INCLUDES =\t\t\t\\\n+ArrowCUDA_1_0_gir_EXPORT_PACKAGES =\t\t\\\n+\tarrow-cuda-glib\n+ArrowCUDA_1_0_gir_INCLUDES =\t\t\t\\\n \tArrow-1.0\n-ArrowGPU_1_0_gir_CFLAGS =\t\t\t\\\n+ArrowCUDA_1_0_gir_CFLAGS =\t\t\t\\\n \t$(AM_CPPFLAGS)\n-ArrowGPU_1_0_gir_LIBS =\n-ArrowGPU_1_0_gir_FILES =\t\t\t\\\n-\t$(libarrow_gpu_glib_la_sources)\n-ArrowGPU_1_0_gir_SCANNERFLAGS =\t\t\t\t\t\\\n+ArrowCUDA_1_0_gir_LIBS =\n+ArrowCUDA_1_0_gir_FILES =\t\t\t\\\n+\t$(libarrow_cuda_glib_la_sources)\n+ArrowCUDA_1_0_gir_SCANNERFLAGS =\t\t\t\t\\\n \t--library-path=$(ARROW_LIB_DIR)\t\t\t\t\\\n \t--warn-all\t\t\t\t\t\t\\\n \t--add-include-path=$(abs_builddir)/../arrow-glib\t\\\n-\t--identifier-prefix=GArrowGPU\t\t\t\t\\\n-\t--symbol-prefix=garrow_gpu\n+\t--identifier-prefix=GArrowCUDA\t\t\t\t\\\n+\t--symbol-prefix=garrow_cuda\n if OS_MACOS\n-ArrowGPU_1_0_gir_LIBS +=\t\t\t\\\n+ArrowCUDA_1_0_gir_LIBS +=\t\t\t\\\n \t arrow-glib\t\t\t\t\\\n-\t arrow-gpu-glib\n-ArrowGPU_1_0_gir_SCANNERFLAGS +=\t\t\t\t\\\n+\t arrow-cuda-glib\n+ArrowCUDA_1_0_gir_SCANNERFLAGS +=\t\t\t\t\\\n \t--no-libtool\t\t\t\t\t\t\\\n \t--library-path=$(abs_builddir)/../arrow-glib/.libs\t\\\n \t--library-path=$(abs_builddir)/.libs\n else\n-ArrowGPU_1_0_gir_LIBS +=\t\t\t\t\\\n+ArrowCUDA_1_0_gir_LIBS +=\t\t\t\t\\\n \t$(abs_builddir)/../arrow-glib/libarrow-glib.la\t\\\n-\tlibarrow-gpu-glib.la\n+\tlibarrow-cuda-glib.la\n endif\n \n-INTROSPECTION_GIRS += ArrowGPU-1.0.gir\n+INTROSPECTION_GIRS += ArrowCUDA-1.0.gir\n \n girdir = $(datadir)/gir-1.0\n gir_DATA = $(INTROSPECTION_GIRS)\ndiff --git a/c_glib/arrow-gpu-glib/arrow-gpu-glib.h b/c_glib/arrow-cuda-glib/arrow-cuda-glib.h\nsimilarity index 96%\nrename from c_glib/arrow-gpu-glib/arrow-gpu-glib.h\nrename to c_glib/arrow-cuda-glib/arrow-cuda-glib.h\nindex 1538c9a186..b3c7f21087 100644\n--- a/c_glib/arrow-gpu-glib/arrow-gpu-glib.h\n+++ b/c_glib/arrow-cuda-glib/arrow-cuda-glib.h\n@@ -21,4 +21,4 @@\n \n #include <arrow-glib/arrow-glib.h>\n \n-#include <arrow-gpu-glib/cuda.h>\n+#include <arrow-cuda-glib/cuda.h>\ndiff --git a/c_glib/arrow-gpu-glib/arrow-gpu-glib.hpp b/c_glib/arrow-cuda-glib/arrow-cuda-glib.hpp\nsimilarity index 95%\nrename from c_glib/arrow-gpu-glib/arrow-gpu-glib.hpp\nrename to c_glib/arrow-cuda-glib/arrow-cuda-glib.hpp\nindex 92017d8b67..e79b43ae07 100644\n--- a/c_glib/arrow-gpu-glib/arrow-gpu-glib.hpp\n+++ b/c_glib/arrow-cuda-glib/arrow-cuda-glib.hpp\n@@ -21,4 +21,4 @@\n \n #include <arrow-glib/arrow-glib.hpp>\n \n-#include <arrow-gpu-glib/cuda.hpp>\n+#include <arrow-cuda-glib/cuda.hpp>\ndiff --git a/c_glib/arrow-gpu-glib/arrow-gpu-glib.pc.in b/c_glib/arrow-cuda-glib/arrow-cuda-glib.pc.in\nsimilarity index 85%\nrename from c_glib/arrow-gpu-glib/arrow-gpu-glib.pc.in\nrename to c_glib/arrow-cuda-glib/arrow-cuda-glib.pc.in\nindex 38a6bae1a1..de0ce974c7 100644\n--- a/c_glib/arrow-gpu-glib/arrow-gpu-glib.pc.in\n+++ b/c_glib/arrow-cuda-glib/arrow-cuda-glib.pc.in\n@@ -20,9 +20,9 @@ exec_prefix=@exec_prefix@\n libdir=@libdir@\n includedir=@includedir@\n \n-Name: Apache Arrow GPU GLib\n-Description: C API for Apache Arrow GPU based on GLib\n+Name: Apache Arrow CUDA GLib\n+Description: C API for Apache Arrow CUDA based on GLib\n Version: @VERSION@\n-Libs: -L${libdir} -larrow-gpu-glib\n+Libs: -L${libdir} -larrow-cuda-glib\n Cflags: -I${includedir}\n-Requires: arrow-glib\n+Requires: arrow-glib arrow-cuda\ndiff --git a/c_glib/arrow-cuda-glib/cuda.cpp b/c_glib/arrow-cuda-glib/cuda.cpp\nnew file mode 100644\nindex 0000000000..3f82f8fa80\n--- /dev/null\n+++ b/c_glib/arrow-cuda-glib/cuda.cpp\n@@ -0,0 +1,942 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#ifdef HAVE_CONFIG_H\n+#  include <config.h>\n+#endif\n+\n+#include <arrow-glib/buffer.hpp>\n+#include <arrow-glib/error.hpp>\n+#include <arrow-glib/input-stream.hpp>\n+#include <arrow-glib/output-stream.hpp>\n+#include <arrow-glib/readable.hpp>\n+#include <arrow-glib/record-batch.hpp>\n+#include <arrow-glib/schema.hpp>\n+\n+#include <arrow-cuda-glib/cuda.hpp>\n+\n+G_BEGIN_DECLS\n+\n+/**\n+ * SECTION: cuda\n+ * @section_id: cuda-classes\n+ * @title: CUDA related classes\n+ * @include: arrow-cuda-glib/arrow-cuda-glib.h\n+ *\n+ * The following classes provide CUDA support for Apache Arrow data.\n+ *\n+ * #GArrowCUDADeviceManager is the starting point. You need at\n+ * least one #GArrowCUDAContext to process Apache Arrow data on\n+ * NVIDIA GPU.\n+ *\n+ * #GArrowCUDAContext is a class to keep context for one GPU. You\n+ * need to create #GArrowCUDAContext for each GPU that you want to\n+ * use. You can create #GArrowCUDAContext by\n+ * garrow_cuda_device_manager_get_context().\n+ *\n+ * #GArrowCUDABuffer is a class for data on GPU. You can copy data\n+ * on GPU to/from CPU by garrow_cuda_buffer_copy_to_host() and\n+ * garrow_cuda_buffer_copy_from_host(). You can share data on GPU\n+ * with other processes by garrow_cuda_buffer_export() and\n+ * garrow_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowCUDAHostBuffer is a class for data on CPU that is\n+ * directly accessible from GPU.\n+ *\n+ * #GArrowCUDAIPCMemoryHandle is a class to share data on GPU with\n+ * other processes. You can export your data on GPU to other processes\n+ * by garrow_cuda_buffer_export() and\n+ * garrow_cuda_ipc_memory_handle_new(). You can import other\n+ * process data on GPU by garrow_cuda_ipc_memory_handle_new() and\n+ * garrow_cuda_buffer_new_ipc().\n+ *\n+ * #GArrowCUDABufferInputStream is a class to read data in\n+ * #GArrowCUDABuffer.\n+ *\n+ * #GArrowCUDABufferOutputStream is a class to write data into\n+ * #GArrowCUDABuffer.\n+ */\n+\n+G_DEFINE_TYPE(GArrowCUDADeviceManager,\n+              garrow_cuda_device_manager,\n+              G_TYPE_OBJECT)\n+\n+static void\n+garrow_cuda_device_manager_init(GArrowCUDADeviceManager *object)\n+{\n+}\n+\n+static void\n+garrow_cuda_device_manager_class_init(GArrowCUDADeviceManagerClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_cuda_device_manager_new:\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowCUDADeviceManager on success,\n+ *   %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDADeviceManager *\n+garrow_cuda_device_manager_new(GError **error)\n+{\n+  arrow::cuda::CudaDeviceManager *manager;\n+  auto status = arrow::cuda::CudaDeviceManager::GetInstance(&manager);\n+  if (garrow_error_check(error, status, \"[cuda][device-manager][new]\")) {\n+    auto manager = g_object_new(GARROW_CUDA_TYPE_DEVICE_MANAGER,\n+                                NULL);\n+    return GARROW_CUDA_DEVICE_MANAGER(manager);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_device_manager_get_context:\n+ * @manager: A #GArrowCUDADeviceManager.\n+ * @gpu_number: A GPU device number for the target context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowCUDAContext on\n+ *   success, %NULL on error. Contexts for the same GPU device number\n+ *   share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDAContext *\n+garrow_cuda_device_manager_get_context(GArrowCUDADeviceManager *manager,\n+                                       gint gpu_number,\n+                                       GError **error)\n+{\n+  arrow::cuda::CudaDeviceManager *arrow_manager;\n+  arrow::cuda::CudaDeviceManager::GetInstance(&arrow_manager);\n+  std::shared_ptr<arrow::cuda::CudaContext> context;\n+  auto status = arrow_manager->GetContext(gpu_number, &context);\n+  if (garrow_error_check(error, status,\n+                         \"[cuda][device-manager][get-context]]\")) {\n+    return garrow_cuda_context_new_raw(&context);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_device_manager_get_n_devices:\n+ * @manager: A #GArrowCUDADeviceManager.\n+ *\n+ * Returns: The number of GPU devices.\n+ *\n+ * Since: 0.8.0\n+ */\n+gsize\n+garrow_cuda_device_manager_get_n_devices(GArrowCUDADeviceManager *manager)\n+{\n+  arrow::cuda::CudaDeviceManager *arrow_manager;\n+  arrow::cuda::CudaDeviceManager::GetInstance(&arrow_manager);\n+  return arrow_manager->num_devices();\n+}\n+\n+\n+typedef struct GArrowCUDAContextPrivate_ {\n+  std::shared_ptr<arrow::cuda::CudaContext> context;\n+} GArrowCUDAContextPrivate;\n+\n+enum {\n+  PROP_CONTEXT = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowCUDAContext,\n+                           garrow_cuda_context,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_CUDA_CONTEXT_GET_PRIVATE(object) \\\n+  static_cast<GArrowCUDAContextPrivate *>(      \\\n+    garrow_cuda_context_get_instance_private(   \\\n+      GARROW_CUDA_CONTEXT(object)))\n+\n+static void\n+garrow_cuda_context_finalize(GObject *object)\n+{\n+  auto priv = GARROW_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  priv->context = nullptr;\n+\n+  G_OBJECT_CLASS(garrow_cuda_context_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_cuda_context_set_property(GObject *object,\n+                                 guint prop_id,\n+                                 const GValue *value,\n+                                 GParamSpec *pspec)\n+{\n+  auto priv = GARROW_CUDA_CONTEXT_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_CONTEXT:\n+    priv->context =\n+      *static_cast<std::shared_ptr<arrow::cuda::CudaContext> *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_cuda_context_get_property(GObject *object,\n+                                 guint prop_id,\n+                                 GValue *value,\n+                                 GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_cuda_context_init(GArrowCUDAContext *object)\n+{\n+}\n+\n+static void\n+garrow_cuda_context_class_init(GArrowCUDAContextClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_cuda_context_finalize;\n+  gobject_class->set_property = garrow_cuda_context_set_property;\n+  gobject_class->get_property = garrow_cuda_context_get_property;\n+\n+  /**\n+   * GArrowCUDAContext:context:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"context\",\n+                              \"Context\",\n+                              \"The raw std::shared_ptr<arrow::cuda::CudaContext>\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_CONTEXT, spec);\n+}\n+\n+/**\n+ * garrow_cuda_context_get_allocated_size:\n+ * @context: A #GArrowCUDAContext.\n+ *\n+ * Returns: The allocated memory by this context in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_cuda_context_get_allocated_size(GArrowCUDAContext *context)\n+{\n+  auto arrow_context = garrow_cuda_context_get_raw(context);\n+  return arrow_context->bytes_allocated();\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowCUDABuffer,\n+              garrow_cuda_buffer,\n+              GARROW_TYPE_BUFFER)\n+\n+static void\n+garrow_cuda_buffer_init(GArrowCUDABuffer *object)\n+{\n+}\n+\n+static void\n+garrow_cuda_buffer_class_init(GArrowCUDABufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_cuda_buffer_new:\n+ * @context: A #GArrowCUDAContext.\n+ * @size: The number of bytes to be allocated on GPU device for this context.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowCUDABuffer on\n+ *   success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new(GArrowCUDAContext *context,\n+                       gint64 size,\n+                       GError **error)\n+{\n+  auto arrow_context = garrow_cuda_context_get_raw(context);\n+  std::shared_ptr<arrow::cuda::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->Allocate(size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[cuda][buffer][new]\")) {\n+    return garrow_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_buffer_new_ipc:\n+ * @context: A #GArrowCUDAContext.\n+ * @handle: A #GArrowCUDAIPCMemoryHandle to be communicated.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowCUDABuffer on\n+ *   success, %NULL on error. The buffer has data from the IPC target.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new_ipc(GArrowCUDAContext *context,\n+                           GArrowCUDAIPCMemoryHandle *handle,\n+                           GError **error)\n+{\n+  auto arrow_context = garrow_cuda_context_get_raw(context);\n+  auto arrow_handle = garrow_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::cuda::CudaBuffer> arrow_buffer;\n+  auto status = arrow_context->OpenIpcBuffer(*arrow_handle, &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[cuda][buffer][new-ipc]\")) {\n+    return garrow_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_buffer_new_record_batch:\n+ * @context: A #GArrowCUDAContext.\n+ * @record_batch: A #GArrowRecordBatch to be serialized.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowCUDABuffer on\n+ *   success, %NULL on error. The buffer has serialized record batch\n+ *   data.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new_record_batch(GArrowCUDAContext *context,\n+                                    GArrowRecordBatch *record_batch,\n+                                    GError **error)\n+{\n+  auto arrow_context = garrow_cuda_context_get_raw(context);\n+  auto arrow_record_batch = garrow_record_batch_get_raw(record_batch);\n+  std::shared_ptr<arrow::cuda::CudaBuffer> arrow_buffer;\n+  auto status = arrow::cuda::SerializeRecordBatch(*arrow_record_batch,\n+                                                  arrow_context.get(),\n+                                                  &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[cuda][buffer][new-record-batch]\")) {\n+    return garrow_cuda_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_buffer_copy_to_host:\n+ * @buffer: A #GArrowCUDABuffer.\n+ * @position: The offset of memory on GPU device to be copied.\n+ * @size: The size of memory on GPU device to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A #GBytes that have copied memory on CPU\n+ *   host on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GBytes *\n+garrow_cuda_buffer_copy_to_host(GArrowCUDABuffer *buffer,\n+                                gint64 position,\n+                                gint64 size,\n+                                GError **error)\n+{\n+  auto arrow_buffer = garrow_cuda_buffer_get_raw(buffer);\n+  auto data = static_cast<uint8_t *>(g_malloc(size));\n+  auto status = arrow_buffer->CopyToHost(position, size, data);\n+  if (garrow_error_check(error, status, \"[cuda][buffer][copy-to-host]\")) {\n+    return g_bytes_new_take(data, size);\n+  } else {\n+    g_free(data);\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_buffer_copy_from_host:\n+ * @buffer: A #GArrowCUDABuffer.\n+ * @data: (array length=size): Data on CPU host to be copied.\n+ * @size: The size of data on CPU host to be copied in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_cuda_buffer_copy_from_host(GArrowCUDABuffer *buffer,\n+                                  const guint8 *data,\n+                                  gint64 size,\n+                                  GError **error)\n+{\n+  auto arrow_buffer = garrow_cuda_buffer_get_raw(buffer);\n+  auto status = arrow_buffer->CopyFromHost(0, data, size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[cuda][buffer][copy-from-host]\");\n+}\n+\n+/**\n+ * garrow_cuda_buffer_export:\n+ * @buffer: A #GArrowCUDABuffer.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowCUDAIPCMemoryHandle to handle the exported buffer on\n+ *   success, %NULL on error\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDAIPCMemoryHandle *\n+garrow_cuda_buffer_export(GArrowCUDABuffer *buffer, GError **error)\n+{\n+  auto arrow_buffer = garrow_cuda_buffer_get_raw(buffer);\n+  std::shared_ptr<arrow::cuda::CudaIpcMemHandle> arrow_handle;\n+  auto status = arrow_buffer->ExportForIpc(&arrow_handle);\n+  if (garrow_error_check(error, status, \"[cuda][buffer][export-for-ipc]\")) {\n+    return garrow_cuda_ipc_memory_handle_new_raw(&arrow_handle);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_buffer_get_context:\n+ * @buffer: A #GArrowCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowCUDAContext for the\n+ *   buffer. Contexts for the same buffer share the same data internally.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDAContext *\n+garrow_cuda_buffer_get_context(GArrowCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_cuda_buffer_get_raw(buffer);\n+  auto arrow_context = arrow_buffer->context();\n+  return garrow_cuda_context_new_raw(&arrow_context);\n+}\n+\n+/**\n+ * garrow_cuda_buffer_read_record_batch:\n+ * @buffer: A #GArrowCUDABuffer.\n+ * @schema: A #GArrowSchema for record batch.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowRecordBatch on\n+ *   success, %NULL on error. The record batch data is located on GPU.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowRecordBatch *\n+garrow_cuda_buffer_read_record_batch(GArrowCUDABuffer *buffer,\n+                                     GArrowSchema *schema,\n+                                     GError **error)\n+{\n+  auto arrow_buffer = garrow_cuda_buffer_get_raw(buffer);\n+  auto arrow_schema = garrow_schema_get_raw(schema);\n+  auto pool = arrow::default_memory_pool();\n+  std::shared_ptr<arrow::RecordBatch> arrow_record_batch;\n+  auto status = arrow::cuda::ReadRecordBatch(arrow_schema,\n+                                             arrow_buffer,\n+                                             pool,\n+                                             &arrow_record_batch);\n+  if (garrow_error_check(error, status,\n+                         \"[cuda][buffer][read-record-batch]\")) {\n+    return garrow_record_batch_new_raw(&arrow_record_batch);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowCUDAHostBuffer,\n+              garrow_cuda_host_buffer,\n+              GARROW_TYPE_MUTABLE_BUFFER)\n+\n+static void\n+garrow_cuda_host_buffer_init(GArrowCUDAHostBuffer *object)\n+{\n+}\n+\n+static void\n+garrow_cuda_host_buffer_class_init(GArrowCUDAHostBufferClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_cuda_host_buffer_new:\n+ * @gpu_number: A GPU device number for the target context.\n+ * @size: The number of bytes to be allocated on CPU host.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: A newly created #GArrowCUDAHostBuffer on success,\n+ *   %NULL on error. The allocated memory is accessible from GPU\n+ *   device for the @context.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDAHostBuffer *\n+garrow_cuda_host_buffer_new(gint gpu_number, gint64 size, GError **error)\n+{\n+  arrow::cuda::CudaDeviceManager *manager;\n+  auto status = arrow::cuda::CudaDeviceManager::GetInstance(&manager);\n+  std::shared_ptr<arrow::cuda::CudaHostBuffer> arrow_buffer;\n+  status = manager->AllocateHost(gpu_number, size, &arrow_buffer);\n+  if (garrow_error_check(error, status, \"[cuda][host-buffer][new]\")) {\n+    return garrow_cuda_host_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+\n+typedef struct GArrowCUDAIPCMemoryHandlePrivate_ {\n+  std::shared_ptr<arrow::cuda::CudaIpcMemHandle> ipc_memory_handle;\n+} GArrowCUDAIPCMemoryHandlePrivate;\n+\n+enum {\n+  PROP_IPC_MEMORY_HANDLE = 1\n+};\n+\n+G_DEFINE_TYPE_WITH_PRIVATE(GArrowCUDAIPCMemoryHandle,\n+                           garrow_cuda_ipc_memory_handle,\n+                           G_TYPE_OBJECT)\n+\n+#define GARROW_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object)       \\\n+  static_cast<GArrowCUDAIPCMemoryHandlePrivate *>(              \\\n+    garrow_cuda_ipc_memory_handle_get_instance_private(         \\\n+      GARROW_CUDA_IPC_MEMORY_HANDLE(object)))\n+\n+static void\n+garrow_cuda_ipc_memory_handle_finalize(GObject *object)\n+{\n+  auto priv = GARROW_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object);\n+\n+  priv->ipc_memory_handle = nullptr;\n+\n+  G_OBJECT_CLASS(garrow_cuda_ipc_memory_handle_parent_class)->finalize(object);\n+}\n+\n+static void\n+garrow_cuda_ipc_memory_handle_set_property(GObject *object,\n+                                           guint prop_id,\n+                                           const GValue *value,\n+                                           GParamSpec *pspec)\n+{\n+  auto priv = GARROW_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object);\n+\n+  switch (prop_id) {\n+  case PROP_IPC_MEMORY_HANDLE:\n+    priv->ipc_memory_handle =\n+      *static_cast<std::shared_ptr<arrow::cuda::CudaIpcMemHandle> *>(g_value_get_pointer(value));\n+    break;\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_cuda_ipc_memory_handle_get_property(GObject *object,\n+                                           guint prop_id,\n+                                           GValue *value,\n+                                           GParamSpec *pspec)\n+{\n+  switch (prop_id) {\n+  default:\n+    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n+    break;\n+  }\n+}\n+\n+static void\n+garrow_cuda_ipc_memory_handle_init(GArrowCUDAIPCMemoryHandle *object)\n+{\n+}\n+\n+static void\n+garrow_cuda_ipc_memory_handle_class_init(GArrowCUDAIPCMemoryHandleClass *klass)\n+{\n+  GParamSpec *spec;\n+\n+  auto gobject_class = G_OBJECT_CLASS(klass);\n+\n+  gobject_class->finalize     = garrow_cuda_ipc_memory_handle_finalize;\n+  gobject_class->set_property = garrow_cuda_ipc_memory_handle_set_property;\n+  gobject_class->get_property = garrow_cuda_ipc_memory_handle_get_property;\n+\n+  /**\n+   * GArrowCUDAIPCMemoryHandle:ipc-memory-handle:\n+   *\n+   * Since: 0.8.0\n+   */\n+  spec = g_param_spec_pointer(\"ipc-memory-handle\",\n+                              \"IPC Memory Handle\",\n+                              \"The raw std::shared_ptr<arrow::cuda::CudaIpcMemHandle>\",\n+                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n+                                                       G_PARAM_CONSTRUCT_ONLY));\n+  g_object_class_install_property(gobject_class, PROP_IPC_MEMORY_HANDLE, spec);\n+}\n+\n+/**\n+ * garrow_cuda_ipc_memory_handle_new:\n+ * @data: (array length=size): A serialized #GArrowCUDAIPCMemoryHandle.\n+ * @size: The size of data.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowCUDAIPCMemoryHandle\n+ *   on success, %NULL on error.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDAIPCMemoryHandle *\n+garrow_cuda_ipc_memory_handle_new(const guint8 *data,\n+                                  gsize size,\n+                                  GError **error)\n+{\n+  std::shared_ptr<arrow::cuda::CudaIpcMemHandle> arrow_handle;\n+  auto status = arrow::cuda::CudaIpcMemHandle::FromBuffer(data, &arrow_handle);\n+  if (garrow_error_check(error, status,\n+                         \"[cuda][ipc-memory-handle][new]\")) {\n+    return garrow_cuda_ipc_memory_handle_new_raw(&arrow_handle);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+/**\n+ * garrow_cuda_ipc_memory_handle_serialize:\n+ * @handle: A #GArrowCUDAIPCMemoryHandle.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: (transfer full): A newly created #GArrowBuffer on success,\n+ *   %NULL on error. The buffer has serialized @handle. The serialized\n+ *   @handle can be deserialized by garrow_gpu_cuda_ipc_memory_handle_new()\n+ *   in other process.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowBuffer *\n+garrow_cuda_ipc_memory_handle_serialize(GArrowCUDAIPCMemoryHandle *handle,\n+                                        GError **error)\n+{\n+  auto arrow_handle = garrow_cuda_ipc_memory_handle_get_raw(handle);\n+  std::shared_ptr<arrow::Buffer> arrow_buffer;\n+  auto status = arrow_handle->Serialize(arrow::default_memory_pool(),\n+                                        &arrow_buffer);\n+  if (garrow_error_check(error, status,\n+                         \"[cuda][ipc-memory-handle][serialize]\")) {\n+    return garrow_buffer_new_raw(&arrow_buffer);\n+  } else {\n+    return NULL;\n+  }\n+}\n+\n+GArrowBuffer *\n+garrow_cuda_buffer_input_stream_new_raw_readable_interface(std::shared_ptr<arrow::Buffer> *arrow_buffer)\n+{\n+  auto buffer = GARROW_BUFFER(g_object_new(GARROW_CUDA_TYPE_BUFFER,\n+                                           \"buffer\", arrow_buffer,\n+                                           NULL));\n+  return buffer;\n+}\n+\n+static std::shared_ptr<arrow::io::Readable>\n+garrow_cuda_buffer_input_stream_get_raw_readable_interface(GArrowReadable *readable)\n+{\n+  auto input_stream = GARROW_INPUT_STREAM(readable);\n+  auto arrow_input_stream = garrow_input_stream_get_raw(input_stream);\n+  return arrow_input_stream;\n+}\n+\n+static void\n+garrow_cuda_buffer_input_stream_readable_interface_init(GArrowReadableInterface *iface)\n+{\n+  iface->new_raw =\n+    garrow_cuda_buffer_input_stream_new_raw_readable_interface;\n+  iface->get_raw =\n+    garrow_cuda_buffer_input_stream_get_raw_readable_interface;\n+}\n+\n+G_DEFINE_TYPE_WITH_CODE(\n+  GArrowCUDABufferInputStream,\n+  garrow_cuda_buffer_input_stream,\n+  GARROW_TYPE_BUFFER_INPUT_STREAM,\n+  G_IMPLEMENT_INTERFACE(\n+    GARROW_TYPE_READABLE,\n+    garrow_cuda_buffer_input_stream_readable_interface_init))\n+\n+static void\n+garrow_cuda_buffer_input_stream_init(GArrowCUDABufferInputStream *object)\n+{\n+}\n+\n+static void\n+garrow_cuda_buffer_input_stream_class_init(GArrowCUDABufferInputStreamClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_cuda_buffer_input_stream_new:\n+ * @buffer: A #GArrowCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowCUDABufferInputStream.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDABufferInputStream *\n+garrow_cuda_buffer_input_stream_new(GArrowCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_cuda_buffer_get_raw(buffer);\n+  auto arrow_reader =\n+    std::make_shared<arrow::cuda::CudaBufferReader>(arrow_buffer);\n+  return garrow_cuda_buffer_input_stream_new_raw(&arrow_reader);\n+}\n+\n+\n+G_DEFINE_TYPE(GArrowCUDABufferOutputStream,\n+              garrow_cuda_buffer_output_stream,\n+              GARROW_TYPE_OUTPUT_STREAM)\n+\n+static void\n+garrow_cuda_buffer_output_stream_init(GArrowCUDABufferOutputStream *object)\n+{\n+}\n+\n+static void\n+garrow_cuda_buffer_output_stream_class_init(GArrowCUDABufferOutputStreamClass *klass)\n+{\n+}\n+\n+/**\n+ * garrow_cuda_buffer_output_stream_new:\n+ * @buffer: A #GArrowCUDABuffer.\n+ *\n+ * Returns: (transfer full): A newly created\n+ *   #GArrowCUDABufferOutputStream.\n+ *\n+ * Since: 0.8.0\n+ */\n+GArrowCUDABufferOutputStream *\n+garrow_cuda_buffer_output_stream_new(GArrowCUDABuffer *buffer)\n+{\n+  auto arrow_buffer = garrow_cuda_buffer_get_raw(buffer);\n+  auto arrow_writer =\n+    std::make_shared<arrow::cuda::CudaBufferWriter>(arrow_buffer);\n+  return garrow_cuda_buffer_output_stream_new_raw(&arrow_writer);\n+}\n+\n+/**\n+ * garrow_cuda_buffer_output_stream_set_buffer_size:\n+ * @stream: A #GArrowCUDABufferOutputStream.\n+ * @size: A size of CPU buffer in bytes.\n+ * @error: (nullable): Return location for a #GError or %NULL.\n+ *\n+ * Returns: %TRUE on success, %FALSE if there was an error.\n+ *\n+ * Sets CPU buffer size. to limit `cudaMemcpy()` calls. If CPU buffer\n+ * size is `0`, buffering is disabled.\n+ *\n+ * The default is `0`.\n+ *\n+ * Since: 0.8.0\n+ */\n+gboolean\n+garrow_cuda_buffer_output_stream_set_buffer_size(GArrowCUDABufferOutputStream *stream,\n+                                                 gint64 size,\n+                                                 GError **error)\n+{\n+  auto arrow_stream = garrow_cuda_buffer_output_stream_get_raw(stream);\n+  auto status = arrow_stream->SetBufferSize(size);\n+  return garrow_error_check(error,\n+                            status,\n+                            \"[cuda][buffer-output-stream][set-buffer-size]\");\n+}\n+\n+/**\n+ * garrow_cuda_buffer_output_stream_get_buffer_size:\n+ * @stream: A #GArrowCUDABufferOutputStream.\n+ *\n+ * Returns: The CPU buffer size in bytes.\n+ *\n+ * See garrow_cuda_buffer_output_stream_set_buffer_size() for CPU\n+ * buffer size details.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_cuda_buffer_output_stream_get_buffer_size(GArrowCUDABufferOutputStream *stream)\n+{\n+  auto arrow_stream = garrow_cuda_buffer_output_stream_get_raw(stream);\n+  return arrow_stream->buffer_size();\n+}\n+\n+/**\n+ * garrow_cuda_buffer_output_stream_get_buffered_size:\n+ * @stream: A #GArrowCUDABufferOutputStream.\n+ *\n+ * Returns: The size of buffered data in bytes.\n+ *\n+ * Since: 0.8.0\n+ */\n+gint64\n+garrow_cuda_buffer_output_stream_get_buffered_size(GArrowCUDABufferOutputStream *stream)\n+{\n+  auto arrow_stream = garrow_cuda_buffer_output_stream_get_raw(stream);\n+  return arrow_stream->num_bytes_buffered();\n+}\n+\n+\n+G_END_DECLS\n+\n+GArrowCUDAContext *\n+garrow_cuda_context_new_raw(std::shared_ptr<arrow::cuda::CudaContext> *arrow_context)\n+{\n+  return GARROW_CUDA_CONTEXT(g_object_new(GARROW_CUDA_TYPE_CONTEXT,\n+                                          \"context\", arrow_context,\n+                                          NULL));\n+}\n+\n+std::shared_ptr<arrow::cuda::CudaContext>\n+garrow_cuda_context_get_raw(GArrowCUDAContext *context)\n+{\n+  if (!context)\n+    return nullptr;\n+\n+  auto priv = GARROW_CUDA_CONTEXT_GET_PRIVATE(context);\n+  return priv->context;\n+}\n+\n+GArrowCUDAIPCMemoryHandle *\n+garrow_cuda_ipc_memory_handle_new_raw(std::shared_ptr<arrow::cuda::CudaIpcMemHandle> *arrow_handle)\n+{\n+  auto handle = g_object_new(GARROW_CUDA_TYPE_IPC_MEMORY_HANDLE,\n+                             \"ipc-memory-handle\", arrow_handle,\n+                             NULL);\n+  return GARROW_CUDA_IPC_MEMORY_HANDLE(handle);\n+}\n+\n+std::shared_ptr<arrow::cuda::CudaIpcMemHandle>\n+garrow_cuda_ipc_memory_handle_get_raw(GArrowCUDAIPCMemoryHandle *handle)\n+{\n+  if (!handle)\n+    return nullptr;\n+\n+  auto priv = GARROW_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(handle);\n+  return priv->ipc_memory_handle;\n+}\n+\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new_raw(std::shared_ptr<arrow::cuda::CudaBuffer> *arrow_buffer)\n+{\n+  return GARROW_CUDA_BUFFER(g_object_new(GARROW_CUDA_TYPE_BUFFER,\n+                                         \"buffer\", arrow_buffer,\n+                                         NULL));\n+}\n+\n+std::shared_ptr<arrow::cuda::CudaBuffer>\n+garrow_cuda_buffer_get_raw(GArrowCUDABuffer *buffer)\n+{\n+  if (!buffer)\n+    return nullptr;\n+\n+  auto arrow_buffer = garrow_buffer_get_raw(GARROW_BUFFER(buffer));\n+  return std::static_pointer_cast<arrow::cuda::CudaBuffer>(arrow_buffer);\n+}\n+\n+GArrowCUDAHostBuffer *\n+garrow_cuda_host_buffer_new_raw(std::shared_ptr<arrow::cuda::CudaHostBuffer> *arrow_buffer)\n+{\n+  auto buffer = g_object_new(GARROW_CUDA_TYPE_HOST_BUFFER,\n+                             \"buffer\", arrow_buffer,\n+                             NULL);\n+  return GARROW_CUDA_HOST_BUFFER(buffer);\n+}\n+\n+std::shared_ptr<arrow::cuda::CudaHostBuffer>\n+garrow_cuda_host_buffer_get_raw(GArrowCUDAHostBuffer *buffer)\n+{\n+  if (!buffer)\n+    return nullptr;\n+\n+  auto arrow_buffer = garrow_buffer_get_raw(GARROW_BUFFER(buffer));\n+  return std::static_pointer_cast<arrow::cuda::CudaHostBuffer>(arrow_buffer);\n+}\n+\n+GArrowCUDABufferInputStream *\n+garrow_cuda_buffer_input_stream_new_raw(std::shared_ptr<arrow::cuda::CudaBufferReader> *arrow_reader)\n+{\n+  auto input_stream = g_object_new(GARROW_CUDA_TYPE_BUFFER_INPUT_STREAM,\n+                                   \"input-stream\", arrow_reader,\n+                                   NULL);\n+  return GARROW_CUDA_BUFFER_INPUT_STREAM(input_stream);\n+}\n+\n+std::shared_ptr<arrow::cuda::CudaBufferReader>\n+garrow_cuda_buffer_input_stream_get_raw(GArrowCUDABufferInputStream *input_stream)\n+{\n+  if (!input_stream)\n+    return nullptr;\n+\n+  auto arrow_reader =\n+    garrow_input_stream_get_raw(GARROW_INPUT_STREAM(input_stream));\n+  return std::static_pointer_cast<arrow::cuda::CudaBufferReader>(arrow_reader);\n+}\n+\n+GArrowCUDABufferOutputStream *\n+garrow_cuda_buffer_output_stream_new_raw(std::shared_ptr<arrow::cuda::CudaBufferWriter> *arrow_writer)\n+{\n+  auto output_stream = g_object_new(GARROW_CUDA_TYPE_BUFFER_OUTPUT_STREAM,\n+                                    \"output-stream\", arrow_writer,\n+                                    NULL);\n+  return GARROW_CUDA_BUFFER_OUTPUT_STREAM(output_stream);\n+}\n+\n+std::shared_ptr<arrow::cuda::CudaBufferWriter>\n+garrow_cuda_buffer_output_stream_get_raw(GArrowCUDABufferOutputStream *output_stream)\n+{\n+  if (!output_stream)\n+    return nullptr;\n+\n+  auto arrow_writer =\n+    garrow_output_stream_get_raw(GARROW_OUTPUT_STREAM(output_stream));\n+  return std::static_pointer_cast<arrow::cuda::CudaBufferWriter>(arrow_writer);\n+}\ndiff --git a/c_glib/arrow-cuda-glib/cuda.h b/c_glib/arrow-cuda-glib/cuda.h\nnew file mode 100644\nindex 0000000000..6cdef99221\n--- /dev/null\n+++ b/c_glib/arrow-cuda-glib/cuda.h\n@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#pragma once\n+\n+#include <arrow-glib/arrow-glib.h>\n+\n+G_BEGIN_DECLS\n+\n+#define GARROW_CUDA_TYPE_DEVICE_MANAGER (garrow_cuda_device_manager_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowCUDADeviceManager,\n+                         garrow_cuda_device_manager,\n+                         GARROW_CUDA,\n+                         DEVICE_MANAGER,\n+                         GObject)\n+struct _GArrowCUDADeviceManagerClass\n+{\n+  GObjectClass parent_class;\n+};\n+\n+#define GARROW_CUDA_TYPE_CONTEXT (garrow_cuda_context_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowCUDAContext,\n+                         garrow_cuda_context,\n+                         GARROW_CUDA,\n+                         CONTEXT,\n+                         GObject)\n+struct _GArrowCUDAContextClass\n+{\n+  GObjectClass parent_class;\n+};\n+\n+#define GARROW_CUDA_TYPE_BUFFER (garrow_cuda_buffer_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowCUDABuffer,\n+                         garrow_cuda_buffer,\n+                         GARROW_CUDA,\n+                         BUFFER,\n+                         GArrowBuffer)\n+struct _GArrowCUDABufferClass\n+{\n+  GArrowBufferClass parent_class;\n+};\n+\n+#define GARROW_CUDA_TYPE_HOST_BUFFER (garrow_cuda_host_buffer_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowCUDAHostBuffer,\n+                         garrow_cuda_host_buffer,\n+                         GARROW_CUDA,\n+                         HOST_BUFFER,\n+                         GArrowMutableBuffer)\n+struct _GArrowCUDAHostBufferClass\n+{\n+  GArrowMutableBufferClass parent_class;\n+};\n+\n+#define GARROW_CUDA_TYPE_IPC_MEMORY_HANDLE      \\\n+  (garrow_cuda_ipc_memory_handle_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowCUDAIPCMemoryHandle,\n+                         garrow_cuda_ipc_memory_handle,\n+                         GARROW_CUDA,\n+                         IPC_MEMORY_HANDLE,\n+                         GObject)\n+struct _GArrowCUDAIPCMemoryHandleClass\n+{\n+  GObjectClass parent_class;\n+};\n+\n+#define GARROW_CUDA_TYPE_BUFFER_INPUT_STREAM    \\\n+  (garrow_cuda_buffer_input_stream_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowCUDABufferInputStream,\n+                         garrow_cuda_buffer_input_stream,\n+                         GARROW_CUDA,\n+                         BUFFER_INPUT_STREAM,\n+                         GArrowBufferInputStream)\n+struct _GArrowCUDABufferInputStreamClass\n+{\n+  GArrowBufferInputStreamClass parent_class;\n+};\n+\n+#define GARROW_CUDA_TYPE_BUFFER_OUTPUT_STREAM   \\\n+  (garrow_cuda_buffer_output_stream_get_type())\n+G_DECLARE_DERIVABLE_TYPE(GArrowCUDABufferOutputStream,\n+                         garrow_cuda_buffer_output_stream,\n+                         GARROW_CUDA,\n+                         BUFFER_OUTPUT_STREAM,\n+                         GArrowOutputStream)\n+struct _GArrowCUDABufferOutputStreamClass\n+{\n+  GArrowOutputStreamClass parent_class;\n+};\n+\n+GArrowCUDADeviceManager *\n+garrow_cuda_device_manager_new(GError **error);\n+\n+GArrowCUDAContext *\n+garrow_cuda_device_manager_get_context(GArrowCUDADeviceManager *manager,\n+                                       gint gpu_number,\n+                                       GError **error);\n+gsize\n+garrow_cuda_device_manager_get_n_devices(GArrowCUDADeviceManager *manager);\n+\n+gint64\n+garrow_cuda_context_get_allocated_size(GArrowCUDAContext *context);\n+\n+\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new(GArrowCUDAContext *context,\n+                       gint64 size,\n+                       GError **error);\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new_ipc(GArrowCUDAContext *context,\n+                           GArrowCUDAIPCMemoryHandle *handle,\n+                           GError **error);\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new_record_batch(GArrowCUDAContext *context,\n+                                    GArrowRecordBatch *record_batch,\n+                                    GError **error);\n+GBytes *\n+garrow_cuda_buffer_copy_to_host(GArrowCUDABuffer *buffer,\n+                                gint64 position,\n+                                gint64 size,\n+                                GError **error);\n+gboolean\n+garrow_cuda_buffer_copy_from_host(GArrowCUDABuffer *buffer,\n+                                  const guint8 *data,\n+                                  gint64 size,\n+                                  GError **error);\n+GArrowCUDAIPCMemoryHandle *\n+garrow_cuda_buffer_export(GArrowCUDABuffer *buffer,\n+                          GError **error);\n+GArrowCUDAContext *\n+garrow_cuda_buffer_get_context(GArrowCUDABuffer *buffer);\n+GArrowRecordBatch *\n+garrow_cuda_buffer_read_record_batch(GArrowCUDABuffer *buffer,\n+                                     GArrowSchema *schema,\n+                                     GError **error);\n+\n+\n+GArrowCUDAHostBuffer *\n+garrow_cuda_host_buffer_new(gint gpu_number,\n+                            gint64 size,\n+                            GError **error);\n+\n+GArrowCUDAIPCMemoryHandle *\n+garrow_cuda_ipc_memory_handle_new(const guint8 *data,\n+                                  gsize size,\n+                                  GError **error);\n+\n+GArrowBuffer *\n+garrow_cuda_ipc_memory_handle_serialize(GArrowCUDAIPCMemoryHandle *handle,\n+                                        GError **error);\n+\n+GArrowCUDABufferInputStream *\n+garrow_cuda_buffer_input_stream_new(GArrowCUDABuffer *buffer);\n+\n+GArrowCUDABufferOutputStream *\n+garrow_cuda_buffer_output_stream_new(GArrowCUDABuffer *buffer);\n+\n+gboolean\n+garrow_cuda_buffer_output_stream_set_buffer_size(GArrowCUDABufferOutputStream *stream,\n+                                                 gint64 size,\n+                                                 GError **error);\n+gint64\n+garrow_cuda_buffer_output_stream_get_buffer_size(GArrowCUDABufferOutputStream *stream);\n+gint64\n+garrow_cuda_buffer_output_stream_get_buffered_size(GArrowCUDABufferOutputStream *stream);\n+\n+G_END_DECLS\ndiff --git a/c_glib/arrow-cuda-glib/cuda.hpp b/c_glib/arrow-cuda-glib/cuda.hpp\nnew file mode 100644\nindex 0000000000..0f8985a9de\n--- /dev/null\n+++ b/c_glib/arrow-cuda-glib/cuda.hpp\n@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+#pragma once\n+\n+#include <arrow/gpu/cuda_api.h>\n+\n+#include <arrow-cuda-glib/cuda.h>\n+\n+GArrowCUDAContext *\n+garrow_cuda_context_new_raw(std::shared_ptr<arrow::cuda::CudaContext> *arrow_context);\n+std::shared_ptr<arrow::cuda::CudaContext>\n+garrow_cuda_context_get_raw(GArrowCUDAContext *context);\n+\n+GArrowCUDAIPCMemoryHandle *\n+garrow_cuda_ipc_memory_handle_new_raw(std::shared_ptr<arrow::cuda::CudaIpcMemHandle> *arrow_handle);\n+std::shared_ptr<arrow::cuda::CudaIpcMemHandle>\n+garrow_cuda_ipc_memory_handle_get_raw(GArrowCUDAIPCMemoryHandle *handle);\n+\n+GArrowCUDABuffer *\n+garrow_cuda_buffer_new_raw(std::shared_ptr<arrow::cuda::CudaBuffer> *arrow_buffer);\n+std::shared_ptr<arrow::cuda::CudaBuffer>\n+garrow_cuda_buffer_get_raw(GArrowCUDABuffer *buffer);\n+\n+GArrowCUDAHostBuffer *\n+garrow_cuda_host_buffer_new_raw(std::shared_ptr<arrow::cuda::CudaHostBuffer> *arrow_buffer);\n+std::shared_ptr<arrow::cuda::CudaHostBuffer>\n+garrow_cuda_host_buffer_get_raw(GArrowCUDAHostBuffer *buffer);\n+\n+GArrowCUDABufferInputStream *\n+garrow_cuda_buffer_input_stream_new_raw(std::shared_ptr<arrow::cuda::CudaBufferReader> *arrow_reader);\n+std::shared_ptr<arrow::cuda::CudaBufferReader>\n+garrow_cuda_buffer_input_stream_get_raw(GArrowCUDABufferInputStream *input_stream);\n+\n+GArrowCUDABufferOutputStream *\n+garrow_cuda_buffer_output_stream_new_raw(std::shared_ptr<arrow::cuda::CudaBufferWriter> *arrow_writer);\n+std::shared_ptr<arrow::cuda::CudaBufferWriter>\n+garrow_cuda_buffer_output_stream_get_raw(GArrowCUDABufferOutputStream *output_stream);\ndiff --git a/c_glib/arrow-cuda-glib/meson.build b/c_glib/arrow-cuda-glib/meson.build\nnew file mode 100644\nindex 0000000000..e5b9f477fc\n--- /dev/null\n+++ b/c_glib/arrow-cuda-glib/meson.build\n@@ -0,0 +1,79 @@\n+# -*- indent-tabs-mode: nil -*-\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one\n+# or more contributor license agreements.  See the NOTICE file\n+# distributed with this work for additional information\n+# regarding copyright ownership.  The ASF licenses this file\n+# to you under the Apache License, Version 2.0 (the\n+# \"License\"); you may not use this file except in compliance\n+# with the License.  You may obtain a copy of the License at\n+#\n+#   http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing,\n+# software distributed under the License is distributed on an\n+# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+# KIND, either express or implied.  See the License for the\n+# specific language governing permissions and limitations\n+# under the License.\n+\n+sources = files(\n+  'cuda.cpp',\n+)\n+\n+c_headers = files(\n+  'arrow-cuda-glib.h',\n+  'cuda.h',\n+)\n+\n+cpp_headers = files(\n+  'arrow-cuda-glib.hpp',\n+  'cuda.hpp',\n+)\n+\n+headers = c_headers + cpp_headers\n+install_headers(headers, subdir: 'arrow-cuda-glib')\n+\n+\n+dependencies = [\n+  arrow_cuda,\n+  arrow_glib,\n+]\n+libarrow_cuda_glib = library('arrow-cuda-glib',\n+                             sources: sources,\n+                             install: true,\n+                             dependencies: dependencies,\n+                             include_directories: base_include_directories,\n+                             soversion: so_version,\n+                             version: library_version)\n+arrow_cuda_glib = declare_dependency(link_with: libarrow_cuda_glib,\n+                                     include_directories: base_include_directories,\n+                                     dependencies: dependencies)\n+\n+pkgconfig.generate(filebase: 'arrow-cuda-glib',\n+                   name: 'Apache Arrow CUDA GLib',\n+                   description: 'C API for Apache Arrow CUDA based on GLib',\n+                   version: version,\n+                   requires: ['arrow-glib', 'arrow-cuda'],\n+                   libraries: [libarrow_cuda_glib])\n+\n+gir_dependencies = [\n+  declare_dependency(sources: arrow_glib_gir),\n+]\n+gir_extra_args = [\n+  '--warn-all',\n+  '--include-uninstalled=./arrow-glib/Arrow-1.0.gir',\n+]\n+arrow_cuda_glib_gir = gnome.generate_gir(libarrow_cuda_glib,\n+                                         dependencies: gir_dependencies,\n+                                         sources: sources + c_headers,\n+                                         namespace: 'ArrowCUDA',\n+                                         nsversion: api_version,\n+                                         identifier_prefix: 'GArrowCUDA',\n+                                         symbol_prefix: 'garrow_cuda',\n+                                         export_packages: 'arrow-cuda-glib',\n+                                         includes: [\n+                                           'Arrow-1.0',\n+                                         ],\n+                                         install: true,\n+                                         extra_args: gir_extra_args)\ndiff --git a/c_glib/arrow-gpu-glib/cuda.cpp b/c_glib/arrow-gpu-glib/cuda.cpp\ndeleted file mode 100644\nindex 6d2e48f351..0000000000\n--- a/c_glib/arrow-gpu-glib/cuda.cpp\n+++ /dev/null\n@@ -1,942 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-#ifdef HAVE_CONFIG_H\n-#  include <config.h>\n-#endif\n-\n-#include <arrow-glib/buffer.hpp>\n-#include <arrow-glib/error.hpp>\n-#include <arrow-glib/input-stream.hpp>\n-#include <arrow-glib/output-stream.hpp>\n-#include <arrow-glib/readable.hpp>\n-#include <arrow-glib/record-batch.hpp>\n-#include <arrow-glib/schema.hpp>\n-\n-#include <arrow-gpu-glib/cuda.hpp>\n-\n-G_BEGIN_DECLS\n-\n-/**\n- * SECTION: cuda\n- * @section_id: cuda-classes\n- * @title: CUDA related classes\n- * @include: arrow-gpu-glib/arrow-gpu-glib.h\n- *\n- * The following classes provide CUDA support for Apache Arrow data.\n- *\n- * #GArrowGPUCUDADeviceManager is the starting point. You need at\n- * least one #GArrowGPUCUDAContext to process Apache Arrow data on\n- * NVIDIA GPU.\n- *\n- * #GArrowGPUCUDAContext is a class to keep context for one GPU. You\n- * need to create #GArrowGPUCUDAContext for each GPU that you want to\n- * use. You can create #GArrowGPUCUDAContext by\n- * garrow_gpu_cuda_device_manager_get_context().\n- *\n- * #GArrowGPUCUDABuffer is a class for data on GPU. You can copy data\n- * on GPU to/from CPU by garrow_gpu_cuda_buffer_copy_to_host() and\n- * garrow_gpu_cuda_buffer_copy_from_host(). You can share data on GPU\n- * with other processes by garrow_gpu_cuda_buffer_export() and\n- * garrow_gpu_cuda_buffer_new_ipc().\n- *\n- * #GArrowGPUCUDAHostBuffer is a class for data on CPU that is\n- * directly accessible from GPU.\n- *\n- * #GArrowGPUCUDAIPCMemoryHandle is a class to share data on GPU with\n- * other processes. You can export your data on GPU to other processes\n- * by garrow_gpu_cuda_buffer_export() and\n- * garrow_gpu_cuda_ipc_memory_handle_new(). You can import other\n- * process data on GPU by garrow_gpu_cuda_ipc_memory_handle_new() and\n- * garrow_gpu_cuda_buffer_new_ipc().\n- *\n- * #GArrowGPUCUDABufferInputStream is a class to read data in\n- * #GArrowGPUCUDABuffer.\n- *\n- * #GArrowGPUCUDABufferOutputStream is a class to write data into\n- * #GArrowGPUCUDABuffer.\n- */\n-\n-G_DEFINE_TYPE(GArrowGPUCUDADeviceManager,\n-              garrow_gpu_cuda_device_manager,\n-              G_TYPE_OBJECT)\n-\n-static void\n-garrow_gpu_cuda_device_manager_init(GArrowGPUCUDADeviceManager *object)\n-{\n-}\n-\n-static void\n-garrow_gpu_cuda_device_manager_class_init(GArrowGPUCUDADeviceManagerClass *klass)\n-{\n-}\n-\n-/**\n- * garrow_gpu_cuda_device_manager_new:\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: A newly created #GArrowGPUCUDADeviceManager on success,\n- *   %NULL on error.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDADeviceManager *\n-garrow_gpu_cuda_device_manager_new(GError **error)\n-{\n-  arrow::gpu::CudaDeviceManager *manager;\n-  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n-  if (garrow_error_check(error, status, \"[gpu][cuda][device-manager][new]\")) {\n-    auto manager = g_object_new(GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER,\n-                                NULL);\n-    return GARROW_GPU_CUDA_DEVICE_MANAGER(manager);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_device_manager_get_context:\n- * @manager: A #GArrowGPUCUDADeviceManager.\n- * @gpu_number: A GPU device number for the target context.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created #GArrowGPUCUDAContext on\n- *   success, %NULL on error. Contexts for the same GPU device number\n- *   share the same data internally.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDAContext *\n-garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n-                                           gint gpu_number,\n-                                           GError **error)\n-{\n-  arrow::gpu::CudaDeviceManager *arrow_manager;\n-  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n-  std::shared_ptr<arrow::gpu::CudaContext> context;\n-  auto status = arrow_manager->GetContext(gpu_number, &context);\n-  if (garrow_error_check(error, status,\n-                         \"[gpu][cuda][device-manager][get-context]]\")) {\n-    return garrow_gpu_cuda_context_new_raw(&context);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_device_manager_get_n_devices:\n- * @manager: A #GArrowGPUCUDADeviceManager.\n- *\n- * Returns: The number of GPU devices.\n- *\n- * Since: 0.8.0\n- */\n-gsize\n-garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager)\n-{\n-  arrow::gpu::CudaDeviceManager *arrow_manager;\n-  arrow::gpu::CudaDeviceManager::GetInstance(&arrow_manager);\n-  return arrow_manager->num_devices();\n-}\n-\n-\n-typedef struct GArrowGPUCUDAContextPrivate_ {\n-  std::shared_ptr<arrow::gpu::CudaContext> context;\n-} GArrowGPUCUDAContextPrivate;\n-\n-enum {\n-  PROP_CONTEXT = 1\n-};\n-\n-G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAContext,\n-                           garrow_gpu_cuda_context,\n-                           G_TYPE_OBJECT)\n-\n-#define GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object)     \\\n-  static_cast<GArrowGPUCUDAContextPrivate *>(           \\\n-    garrow_gpu_cuda_context_get_instance_private(       \\\n-      GARROW_GPU_CUDA_CONTEXT(object)))\n-\n-static void\n-garrow_gpu_cuda_context_finalize(GObject *object)\n-{\n-  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n-\n-  priv->context = nullptr;\n-\n-  G_OBJECT_CLASS(garrow_gpu_cuda_context_parent_class)->finalize(object);\n-}\n-\n-static void\n-garrow_gpu_cuda_context_set_property(GObject *object,\n-                                     guint prop_id,\n-                                     const GValue *value,\n-                                     GParamSpec *pspec)\n-{\n-  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(object);\n-\n-  switch (prop_id) {\n-  case PROP_CONTEXT:\n-    priv->context =\n-      *static_cast<std::shared_ptr<arrow::gpu::CudaContext> *>(g_value_get_pointer(value));\n-    break;\n-  default:\n-    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n-    break;\n-  }\n-}\n-\n-static void\n-garrow_gpu_cuda_context_get_property(GObject *object,\n-                                     guint prop_id,\n-                                     GValue *value,\n-                                     GParamSpec *pspec)\n-{\n-  switch (prop_id) {\n-  default:\n-    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n-    break;\n-  }\n-}\n-\n-static void\n-garrow_gpu_cuda_context_init(GArrowGPUCUDAContext *object)\n-{\n-}\n-\n-static void\n-garrow_gpu_cuda_context_class_init(GArrowGPUCUDAContextClass *klass)\n-{\n-  GParamSpec *spec;\n-\n-  auto gobject_class = G_OBJECT_CLASS(klass);\n-\n-  gobject_class->finalize     = garrow_gpu_cuda_context_finalize;\n-  gobject_class->set_property = garrow_gpu_cuda_context_set_property;\n-  gobject_class->get_property = garrow_gpu_cuda_context_get_property;\n-\n-  /**\n-   * GArrowGPUCUDAContext:context:\n-   *\n-   * Since: 0.8.0\n-   */\n-  spec = g_param_spec_pointer(\"context\",\n-                              \"Context\",\n-                              \"The raw std::shared_ptr<arrow::gpu::CudaContext>\",\n-                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n-                                                       G_PARAM_CONSTRUCT_ONLY));\n-  g_object_class_install_property(gobject_class, PROP_CONTEXT, spec);\n-}\n-\n-/**\n- * garrow_gpu_cuda_context_get_allocated_size:\n- * @context: A #GArrowGPUCUDAContext.\n- *\n- * Returns: The allocated memory by this context in bytes.\n- *\n- * Since: 0.8.0\n- */\n-gint64\n-garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context)\n-{\n-  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n-  return arrow_context->bytes_allocated();\n-}\n-\n-\n-G_DEFINE_TYPE(GArrowGPUCUDABuffer,\n-              garrow_gpu_cuda_buffer,\n-              GARROW_TYPE_BUFFER)\n-\n-static void\n-garrow_gpu_cuda_buffer_init(GArrowGPUCUDABuffer *object)\n-{\n-}\n-\n-static void\n-garrow_gpu_cuda_buffer_class_init(GArrowGPUCUDABufferClass *klass)\n-{\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_new:\n- * @context: A #GArrowGPUCUDAContext.\n- * @size: The number of bytes to be allocated on GPU device for this context.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n- *   success, %NULL on error.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n-                           gint64 size,\n-                           GError **error)\n-{\n-  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n-  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n-  auto status = arrow_context->Allocate(size, &arrow_buffer);\n-  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][new]\")) {\n-    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_new_ipc:\n- * @context: A #GArrowGPUCUDAContext.\n- * @handle: A #GArrowGPUCUDAIPCMemoryHandle to be communicated.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n- *   success, %NULL on error. The buffer has data from the IPC target.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n-                               GArrowGPUCUDAIPCMemoryHandle *handle,\n-                               GError **error)\n-{\n-  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n-  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n-  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n-  auto status = arrow_context->OpenIpcBuffer(*arrow_handle, &arrow_buffer);\n-  if (garrow_error_check(error, status,\n-                         \"[gpu][cuda][buffer][new-ipc]\")) {\n-    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_new_record_batch:\n- * @context: A #GArrowGPUCUDAContext.\n- * @record_batch: A #GArrowRecordBatch to be serialized.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created #GArrowGPUCUDABuffer on\n- *   success, %NULL on error. The buffer has serialized record batch\n- *   data.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n-                                        GArrowRecordBatch *record_batch,\n-                                        GError **error)\n-{\n-  auto arrow_context = garrow_gpu_cuda_context_get_raw(context);\n-  auto arrow_record_batch = garrow_record_batch_get_raw(record_batch);\n-  std::shared_ptr<arrow::gpu::CudaBuffer> arrow_buffer;\n-  auto status = arrow::gpu::SerializeRecordBatch(*arrow_record_batch,\n-                                                 arrow_context.get(),\n-                                                 &arrow_buffer);\n-  if (garrow_error_check(error, status,\n-                         \"[gpu][cuda][buffer][new-record-batch]\")) {\n-    return garrow_gpu_cuda_buffer_new_raw(&arrow_buffer);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_copy_to_host:\n- * @buffer: A #GArrowGPUCUDABuffer.\n- * @position: The offset of memory on GPU device to be copied.\n- * @size: The size of memory on GPU device to be copied in bytes.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A #GBytes that have copied memory on CPU\n- *   host on success, %NULL on error.\n- *\n- * Since: 0.8.0\n- */\n-GBytes *\n-garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n-                                    gint64 position,\n-                                    gint64 size,\n-                                    GError **error)\n-{\n-  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n-  auto data = static_cast<uint8_t *>(g_malloc(size));\n-  auto status = arrow_buffer->CopyToHost(position, size, data);\n-  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][copy-to-host]\")) {\n-    return g_bytes_new_take(data, size);\n-  } else {\n-    g_free(data);\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_copy_from_host:\n- * @buffer: A #GArrowGPUCUDABuffer.\n- * @data: (array length=size): Data on CPU host to be copied.\n- * @size: The size of data on CPU host to be copied in bytes.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: %TRUE on success, %FALSE if there was an error.\n- *\n- * Since: 0.8.0\n- */\n-gboolean\n-garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n-                                      const guint8 *data,\n-                                      gint64 size,\n-                                      GError **error)\n-{\n-  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n-  auto status = arrow_buffer->CopyFromHost(0, data, size);\n-  return garrow_error_check(error,\n-                            status,\n-                            \"[gpu][cuda][buffer][copy-from-host]\");\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_export:\n- * @buffer: A #GArrowGPUCUDABuffer.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created\n- *   #GArrowGPUCUDAIPCMemoryHandle to handle the exported buffer on\n- *   success, %NULL on error\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDAIPCMemoryHandle *\n-garrow_gpu_cuda_buffer_export(GArrowGPUCUDABuffer *buffer, GError **error)\n-{\n-  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n-  std::shared_ptr<arrow::gpu::CudaIpcMemHandle> arrow_handle;\n-  auto status = arrow_buffer->ExportForIpc(&arrow_handle);\n-  if (garrow_error_check(error, status, \"[gpu][cuda][buffer][export-for-ipc]\")) {\n-    return garrow_gpu_cuda_ipc_memory_handle_new_raw(&arrow_handle);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_get_context:\n- * @buffer: A #GArrowGPUCUDABuffer.\n- *\n- * Returns: (transfer full): A newly created #GArrowGPUCUDAContext for the\n- *   buffer. Contexts for the same buffer share the same data internally.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDAContext *\n-garrow_gpu_cuda_buffer_get_context(GArrowGPUCUDABuffer *buffer)\n-{\n-  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n-  auto arrow_context = arrow_buffer->context();\n-  return garrow_gpu_cuda_context_new_raw(&arrow_context);\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_read_record_batch:\n- * @buffer: A #GArrowGPUCUDABuffer.\n- * @schema: A #GArrowSchema for record batch.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created #GArrowRecordBatch on\n- *   success, %NULL on error. The record batch data is located on GPU.\n- *\n- * Since: 0.8.0\n- */\n-GArrowRecordBatch *\n-garrow_gpu_cuda_buffer_read_record_batch(GArrowGPUCUDABuffer *buffer,\n-                                         GArrowSchema *schema,\n-                                         GError **error)\n-{\n-  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n-  auto arrow_schema = garrow_schema_get_raw(schema);\n-  auto pool = arrow::default_memory_pool();\n-  std::shared_ptr<arrow::RecordBatch> arrow_record_batch;\n-  auto status = arrow::gpu::ReadRecordBatch(arrow_schema,\n-                                            arrow_buffer,\n-                                            pool,\n-                                            &arrow_record_batch);\n-  if (garrow_error_check(error, status,\n-                         \"[gpu][cuda][buffer][read-record-batch]\")) {\n-    return garrow_record_batch_new_raw(&arrow_record_batch);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-\n-G_DEFINE_TYPE(GArrowGPUCUDAHostBuffer,\n-              garrow_gpu_cuda_host_buffer,\n-              GARROW_TYPE_MUTABLE_BUFFER)\n-\n-static void\n-garrow_gpu_cuda_host_buffer_init(GArrowGPUCUDAHostBuffer *object)\n-{\n-}\n-\n-static void\n-garrow_gpu_cuda_host_buffer_class_init(GArrowGPUCUDAHostBufferClass *klass)\n-{\n-}\n-\n-/**\n- * garrow_gpu_cuda_host_buffer_new:\n- * @gpu_number: A GPU device number for the target context.\n- * @size: The number of bytes to be allocated on CPU host.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: A newly created #GArrowGPUCUDAHostBuffer on success,\n- *   %NULL on error. The allocated memory is accessible from GPU\n- *   device for the @context.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDAHostBuffer *\n-garrow_gpu_cuda_host_buffer_new(gint gpu_number, gint64 size, GError **error)\n-{\n-  arrow::gpu::CudaDeviceManager *manager;\n-  auto status = arrow::gpu::CudaDeviceManager::GetInstance(&manager);\n-  std::shared_ptr<arrow::gpu::CudaHostBuffer> arrow_buffer;\n-  status = manager->AllocateHost(gpu_number, size, &arrow_buffer);\n-  if (garrow_error_check(error, status, \"[gpu][cuda][host-buffer][new]\")) {\n-    return garrow_gpu_cuda_host_buffer_new_raw(&arrow_buffer);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-\n-typedef struct GArrowGPUCUDAIPCMemoryHandlePrivate_ {\n-  std::shared_ptr<arrow::gpu::CudaIpcMemHandle> ipc_memory_handle;\n-} GArrowGPUCUDAIPCMemoryHandlePrivate;\n-\n-enum {\n-  PROP_IPC_MEMORY_HANDLE = 1\n-};\n-\n-G_DEFINE_TYPE_WITH_PRIVATE(GArrowGPUCUDAIPCMemoryHandle,\n-                           garrow_gpu_cuda_ipc_memory_handle,\n-                           G_TYPE_OBJECT)\n-\n-#define GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object)   \\\n-  static_cast<GArrowGPUCUDAIPCMemoryHandlePrivate *>(           \\\n-    garrow_gpu_cuda_ipc_memory_handle_get_instance_private(     \\\n-      GARROW_GPU_CUDA_IPC_MEMORY_HANDLE(object)))\n-\n-static void\n-garrow_gpu_cuda_ipc_memory_handle_finalize(GObject *object)\n-{\n-  auto priv = GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object);\n-\n-  priv->ipc_memory_handle = nullptr;\n-\n-  G_OBJECT_CLASS(garrow_gpu_cuda_ipc_memory_handle_parent_class)->finalize(object);\n-}\n-\n-static void\n-garrow_gpu_cuda_ipc_memory_handle_set_property(GObject *object,\n-                                               guint prop_id,\n-                                               const GValue *value,\n-                                               GParamSpec *pspec)\n-{\n-  auto priv = GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(object);\n-\n-  switch (prop_id) {\n-  case PROP_IPC_MEMORY_HANDLE:\n-    priv->ipc_memory_handle =\n-      *static_cast<std::shared_ptr<arrow::gpu::CudaIpcMemHandle> *>(g_value_get_pointer(value));\n-    break;\n-  default:\n-    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n-    break;\n-  }\n-}\n-\n-static void\n-garrow_gpu_cuda_ipc_memory_handle_get_property(GObject *object,\n-                                               guint prop_id,\n-                                               GValue *value,\n-                                               GParamSpec *pspec)\n-{\n-  switch (prop_id) {\n-  default:\n-    G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);\n-    break;\n-  }\n-}\n-\n-static void\n-garrow_gpu_cuda_ipc_memory_handle_init(GArrowGPUCUDAIPCMemoryHandle *object)\n-{\n-}\n-\n-static void\n-garrow_gpu_cuda_ipc_memory_handle_class_init(GArrowGPUCUDAIPCMemoryHandleClass *klass)\n-{\n-  GParamSpec *spec;\n-\n-  auto gobject_class = G_OBJECT_CLASS(klass);\n-\n-  gobject_class->finalize     = garrow_gpu_cuda_ipc_memory_handle_finalize;\n-  gobject_class->set_property = garrow_gpu_cuda_ipc_memory_handle_set_property;\n-  gobject_class->get_property = garrow_gpu_cuda_ipc_memory_handle_get_property;\n-\n-  /**\n-   * GArrowGPUCUDAIPCMemoryHandle:ipc-memory-handle:\n-   *\n-   * Since: 0.8.0\n-   */\n-  spec = g_param_spec_pointer(\"ipc-memory-handle\",\n-                              \"IPC Memory Handle\",\n-                              \"The raw std::shared_ptr<arrow::gpu::CudaIpcMemHandle>\",\n-                              static_cast<GParamFlags>(G_PARAM_WRITABLE |\n-                                                       G_PARAM_CONSTRUCT_ONLY));\n-  g_object_class_install_property(gobject_class, PROP_IPC_MEMORY_HANDLE, spec);\n-}\n-\n-/**\n- * garrow_gpu_cuda_ipc_memory_handle_new:\n- * @data: (array length=size): A serialized #GArrowGPUCUDAIPCMemoryHandle.\n- * @size: The size of data.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created #GArrowGPUCUDAIPCMemoryHandle\n- *   on success, %NULL on error.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDAIPCMemoryHandle *\n-garrow_gpu_cuda_ipc_memory_handle_new(const guint8 *data,\n-                                      gsize size,\n-                                      GError **error)\n-{\n-  std::shared_ptr<arrow::gpu::CudaIpcMemHandle> arrow_handle;\n-  auto status = arrow::gpu::CudaIpcMemHandle::FromBuffer(data, &arrow_handle);\n-  if (garrow_error_check(error, status,\n-                         \"[gpu][cuda][ipc-memory-handle][new]\")) {\n-    return garrow_gpu_cuda_ipc_memory_handle_new_raw(&arrow_handle);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-/**\n- * garrow_gpu_cuda_ipc_memory_handle_serialize:\n- * @handle: A #GArrowGPUCUDAIPCMemoryHandle.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: (transfer full): A newly created #GArrowBuffer on success,\n- *   %NULL on error. The buffer has serialized @handle. The serialized\n- *   @handle can be deserialized by garrow_gpu_cuda_ipc_memory_handle_new()\n- *   in other process.\n- *\n- * Since: 0.8.0\n- */\n-GArrowBuffer *\n-garrow_gpu_cuda_ipc_memory_handle_serialize(GArrowGPUCUDAIPCMemoryHandle *handle,\n-                                            GError **error)\n-{\n-  auto arrow_handle = garrow_gpu_cuda_ipc_memory_handle_get_raw(handle);\n-  std::shared_ptr<arrow::Buffer> arrow_buffer;\n-  auto status = arrow_handle->Serialize(arrow::default_memory_pool(),\n-                                        &arrow_buffer);\n-  if (garrow_error_check(error, status,\n-                         \"[gpu][cuda][ipc-memory-handle][serialize]\")) {\n-    return garrow_buffer_new_raw(&arrow_buffer);\n-  } else {\n-    return NULL;\n-  }\n-}\n-\n-GArrowBuffer *\n-garrow_gpu_cuda_buffer_input_stream_new_raw_readable_interface(std::shared_ptr<arrow::Buffer> *arrow_buffer)\n-{\n-  auto buffer = GARROW_BUFFER(g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER,\n-                                           \"buffer\", arrow_buffer,\n-                                           NULL));\n-  return buffer;\n-}\n-\n-static std::shared_ptr<arrow::io::Readable>\n-garrow_gpu_cuda_buffer_input_stream_get_raw_readable_interface(GArrowReadable *readable)\n-{\n-  auto input_stream = GARROW_INPUT_STREAM(readable);\n-  auto arrow_input_stream = garrow_input_stream_get_raw(input_stream);\n-  return arrow_input_stream;\n-}\n-\n-static void\n-garrow_gpu_cuda_buffer_input_stream_readable_interface_init(GArrowReadableInterface *iface)\n-{\n-  iface->new_raw =\n-    garrow_gpu_cuda_buffer_input_stream_new_raw_readable_interface;\n-  iface->get_raw =\n-    garrow_gpu_cuda_buffer_input_stream_get_raw_readable_interface;\n-}\n-\n-G_DEFINE_TYPE_WITH_CODE(\n-  GArrowGPUCUDABufferInputStream,\n-  garrow_gpu_cuda_buffer_input_stream,\n-  GARROW_TYPE_BUFFER_INPUT_STREAM,\n-  G_IMPLEMENT_INTERFACE(\n-    GARROW_TYPE_READABLE,\n-    garrow_gpu_cuda_buffer_input_stream_readable_interface_init))\n-\n-static void\n-garrow_gpu_cuda_buffer_input_stream_init(GArrowGPUCUDABufferInputStream *object)\n-{\n-}\n-\n-static void\n-garrow_gpu_cuda_buffer_input_stream_class_init(GArrowGPUCUDABufferInputStreamClass *klass)\n-{\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_input_stream_new:\n- * @buffer: A #GArrowGPUCUDABuffer.\n- *\n- * Returns: (transfer full): A newly created\n- *   #GArrowGPUCUDABufferInputStream.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDABufferInputStream *\n-garrow_gpu_cuda_buffer_input_stream_new(GArrowGPUCUDABuffer *buffer)\n-{\n-  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n-  auto arrow_reader =\n-    std::make_shared<arrow::gpu::CudaBufferReader>(arrow_buffer);\n-  return garrow_gpu_cuda_buffer_input_stream_new_raw(&arrow_reader);\n-}\n-\n-\n-G_DEFINE_TYPE(GArrowGPUCUDABufferOutputStream,\n-              garrow_gpu_cuda_buffer_output_stream,\n-              GARROW_TYPE_OUTPUT_STREAM)\n-\n-static void\n-garrow_gpu_cuda_buffer_output_stream_init(GArrowGPUCUDABufferOutputStream *object)\n-{\n-}\n-\n-static void\n-garrow_gpu_cuda_buffer_output_stream_class_init(GArrowGPUCUDABufferOutputStreamClass *klass)\n-{\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_output_stream_new:\n- * @buffer: A #GArrowGPUCUDABuffer.\n- *\n- * Returns: (transfer full): A newly created\n- *   #GArrowGPUCUDABufferOutputStream.\n- *\n- * Since: 0.8.0\n- */\n-GArrowGPUCUDABufferOutputStream *\n-garrow_gpu_cuda_buffer_output_stream_new(GArrowGPUCUDABuffer *buffer)\n-{\n-  auto arrow_buffer = garrow_gpu_cuda_buffer_get_raw(buffer);\n-  auto arrow_writer =\n-    std::make_shared<arrow::gpu::CudaBufferWriter>(arrow_buffer);\n-  return garrow_gpu_cuda_buffer_output_stream_new_raw(&arrow_writer);\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_output_stream_set_buffer_size:\n- * @stream: A #GArrowGPUCUDABufferOutputStream.\n- * @size: A size of CPU buffer in bytes.\n- * @error: (nullable): Return location for a #GError or %NULL.\n- *\n- * Returns: %TRUE on success, %FALSE if there was an error.\n- *\n- * Sets CPU buffer size. to limit `cudaMemcpy()` calls. If CPU buffer\n- * size is `0`, buffering is disabled.\n- *\n- * The default is `0`.\n- *\n- * Since: 0.8.0\n- */\n-gboolean\n-garrow_gpu_cuda_buffer_output_stream_set_buffer_size(GArrowGPUCUDABufferOutputStream *stream,\n-                                                     gint64 size,\n-                                                     GError **error)\n-{\n-  auto arrow_stream = garrow_gpu_cuda_buffer_output_stream_get_raw(stream);\n-  auto status = arrow_stream->SetBufferSize(size);\n-  return garrow_error_check(error,\n-                            status,\n-                            \"[gpu][cuda][buffer-output-stream][set-buffer-size]\");\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_output_stream_get_buffer_size:\n- * @stream: A #GArrowGPUCUDABufferOutputStream.\n- *\n- * Returns: The CPU buffer size in bytes.\n- *\n- * See garrow_gpu_cuda_buffer_output_stream_set_buffer_size() for CPU\n- * buffer size details.\n- *\n- * Since: 0.8.0\n- */\n-gint64\n-garrow_gpu_cuda_buffer_output_stream_get_buffer_size(GArrowGPUCUDABufferOutputStream *stream)\n-{\n-  auto arrow_stream = garrow_gpu_cuda_buffer_output_stream_get_raw(stream);\n-  return arrow_stream->buffer_size();\n-}\n-\n-/**\n- * garrow_gpu_cuda_buffer_output_stream_get_buffered_size:\n- * @stream: A #GArrowGPUCUDABufferOutputStream.\n- *\n- * Returns: The size of buffered data in bytes.\n- *\n- * Since: 0.8.0\n- */\n-gint64\n-garrow_gpu_cuda_buffer_output_stream_get_buffered_size(GArrowGPUCUDABufferOutputStream *stream)\n-{\n-  auto arrow_stream = garrow_gpu_cuda_buffer_output_stream_get_raw(stream);\n-  return arrow_stream->num_bytes_buffered();\n-}\n-\n-\n-G_END_DECLS\n-\n-GArrowGPUCUDAContext *\n-garrow_gpu_cuda_context_new_raw(std::shared_ptr<arrow::gpu::CudaContext> *arrow_context)\n-{\n-  return GARROW_GPU_CUDA_CONTEXT(g_object_new(GARROW_GPU_TYPE_CUDA_CONTEXT,\n-                                              \"context\", arrow_context,\n-                                              NULL));\n-}\n-\n-std::shared_ptr<arrow::gpu::CudaContext>\n-garrow_gpu_cuda_context_get_raw(GArrowGPUCUDAContext *context)\n-{\n-  if (!context)\n-    return nullptr;\n-\n-  auto priv = GARROW_GPU_CUDA_CONTEXT_GET_PRIVATE(context);\n-  return priv->context;\n-}\n-\n-GArrowGPUCUDAIPCMemoryHandle *\n-garrow_gpu_cuda_ipc_memory_handle_new_raw(std::shared_ptr<arrow::gpu::CudaIpcMemHandle> *arrow_handle)\n-{\n-  auto handle = g_object_new(GARROW_GPU_TYPE_CUDA_IPC_MEMORY_HANDLE,\n-                             \"ipc-memory-handle\", arrow_handle,\n-                             NULL);\n-  return GARROW_GPU_CUDA_IPC_MEMORY_HANDLE(handle);\n-}\n-\n-std::shared_ptr<arrow::gpu::CudaIpcMemHandle>\n-garrow_gpu_cuda_ipc_memory_handle_get_raw(GArrowGPUCUDAIPCMemoryHandle *handle)\n-{\n-  if (!handle)\n-    return nullptr;\n-\n-  auto priv = GARROW_GPU_CUDA_IPC_MEMORY_HANDLE_GET_PRIVATE(handle);\n-  return priv->ipc_memory_handle;\n-}\n-\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaBuffer> *arrow_buffer)\n-{\n-  return GARROW_GPU_CUDA_BUFFER(g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER,\n-                                             \"buffer\", arrow_buffer,\n-                                             NULL));\n-}\n-\n-std::shared_ptr<arrow::gpu::CudaBuffer>\n-garrow_gpu_cuda_buffer_get_raw(GArrowGPUCUDABuffer *buffer)\n-{\n-  if (!buffer)\n-    return nullptr;\n-\n-  auto arrow_buffer = garrow_buffer_get_raw(GARROW_BUFFER(buffer));\n-  return std::static_pointer_cast<arrow::gpu::CudaBuffer>(arrow_buffer);\n-}\n-\n-GArrowGPUCUDAHostBuffer *\n-garrow_gpu_cuda_host_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaHostBuffer> *arrow_buffer)\n-{\n-  auto buffer = g_object_new(GARROW_GPU_TYPE_CUDA_HOST_BUFFER,\n-                             \"buffer\", arrow_buffer,\n-                             NULL);\n-  return GARROW_GPU_CUDA_HOST_BUFFER(buffer);\n-}\n-\n-std::shared_ptr<arrow::gpu::CudaHostBuffer>\n-garrow_gpu_cuda_host_buffer_get_raw(GArrowGPUCUDAHostBuffer *buffer)\n-{\n-  if (!buffer)\n-    return nullptr;\n-\n-  auto arrow_buffer = garrow_buffer_get_raw(GARROW_BUFFER(buffer));\n-  return std::static_pointer_cast<arrow::gpu::CudaHostBuffer>(arrow_buffer);\n-}\n-\n-GArrowGPUCUDABufferInputStream *\n-garrow_gpu_cuda_buffer_input_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferReader> *arrow_reader)\n-{\n-  auto input_stream = g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER_INPUT_STREAM,\n-                                   \"input-stream\", arrow_reader,\n-                                   NULL);\n-  return GARROW_GPU_CUDA_BUFFER_INPUT_STREAM(input_stream);\n-}\n-\n-std::shared_ptr<arrow::gpu::CudaBufferReader>\n-garrow_gpu_cuda_buffer_input_stream_get_raw(GArrowGPUCUDABufferInputStream *input_stream)\n-{\n-  if (!input_stream)\n-    return nullptr;\n-\n-  auto arrow_reader =\n-    garrow_input_stream_get_raw(GARROW_INPUT_STREAM(input_stream));\n-  return std::static_pointer_cast<arrow::gpu::CudaBufferReader>(arrow_reader);\n-}\n-\n-GArrowGPUCUDABufferOutputStream *\n-garrow_gpu_cuda_buffer_output_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferWriter> *arrow_writer)\n-{\n-  auto output_stream = g_object_new(GARROW_GPU_TYPE_CUDA_BUFFER_OUTPUT_STREAM,\n-                                    \"output-stream\", arrow_writer,\n-                                    NULL);\n-  return GARROW_GPU_CUDA_BUFFER_OUTPUT_STREAM(output_stream);\n-}\n-\n-std::shared_ptr<arrow::gpu::CudaBufferWriter>\n-garrow_gpu_cuda_buffer_output_stream_get_raw(GArrowGPUCUDABufferOutputStream *output_stream)\n-{\n-  if (!output_stream)\n-    return nullptr;\n-\n-  auto arrow_writer =\n-    garrow_output_stream_get_raw(GARROW_OUTPUT_STREAM(output_stream));\n-  return std::static_pointer_cast<arrow::gpu::CudaBufferWriter>(arrow_writer);\n-}\ndiff --git a/c_glib/arrow-gpu-glib/cuda.h b/c_glib/arrow-gpu-glib/cuda.h\ndeleted file mode 100644\nindex f45a46a2de..0000000000\n--- a/c_glib/arrow-gpu-glib/cuda.h\n+++ /dev/null\n@@ -1,183 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-#pragma once\n-\n-#include <arrow-glib/arrow-glib.h>\n-\n-G_BEGIN_DECLS\n-\n-#define GARROW_GPU_TYPE_CUDA_DEVICE_MANAGER     \\\n-  (garrow_gpu_cuda_device_manager_get_type())\n-G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDADeviceManager,\n-                         garrow_gpu_cuda_device_manager,\n-                         GARROW_GPU,\n-                         CUDA_DEVICE_MANAGER,\n-                         GObject)\n-struct _GArrowGPUCUDADeviceManagerClass\n-{\n-  GObjectClass parent_class;\n-};\n-\n-#define GARROW_GPU_TYPE_CUDA_CONTEXT (garrow_gpu_cuda_context_get_type())\n-G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDAContext,\n-                         garrow_gpu_cuda_context,\n-                         GARROW_GPU,\n-                         CUDA_CONTEXT,\n-                         GObject)\n-struct _GArrowGPUCUDAContextClass\n-{\n-  GObjectClass parent_class;\n-};\n-\n-#define GARROW_GPU_TYPE_CUDA_BUFFER (garrow_gpu_cuda_buffer_get_type())\n-G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDABuffer,\n-                         garrow_gpu_cuda_buffer,\n-                         GARROW_GPU,\n-                         CUDA_BUFFER,\n-                         GArrowBuffer)\n-struct _GArrowGPUCUDABufferClass\n-{\n-  GArrowBufferClass parent_class;\n-};\n-\n-#define GARROW_GPU_TYPE_CUDA_HOST_BUFFER (garrow_gpu_cuda_host_buffer_get_type())\n-G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDAHostBuffer,\n-                         garrow_gpu_cuda_host_buffer,\n-                         GARROW_GPU,\n-                         CUDA_HOST_BUFFER,\n-                         GArrowMutableBuffer)\n-struct _GArrowGPUCUDAHostBufferClass\n-{\n-  GArrowMutableBufferClass parent_class;\n-};\n-\n-#define GARROW_GPU_TYPE_CUDA_IPC_MEMORY_HANDLE          \\\n-  (garrow_gpu_cuda_ipc_memory_handle_get_type())\n-G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDAIPCMemoryHandle,\n-                         garrow_gpu_cuda_ipc_memory_handle,\n-                         GARROW_GPU,\n-                         CUDA_IPC_MEMORY_HANDLE,\n-                         GObject)\n-struct _GArrowGPUCUDAIPCMemoryHandleClass\n-{\n-  GObjectClass parent_class;\n-};\n-\n-#define GARROW_GPU_TYPE_CUDA_BUFFER_INPUT_STREAM        \\\n-  (garrow_gpu_cuda_buffer_input_stream_get_type())\n-G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDABufferInputStream,\n-                         garrow_gpu_cuda_buffer_input_stream,\n-                         GARROW_GPU,\n-                         CUDA_BUFFER_INPUT_STREAM,\n-                         GArrowBufferInputStream)\n-struct _GArrowGPUCUDABufferInputStreamClass\n-{\n-  GArrowBufferInputStreamClass parent_class;\n-};\n-\n-#define GARROW_GPU_TYPE_CUDA_BUFFER_OUTPUT_STREAM               \\\n-  (garrow_gpu_cuda_buffer_output_stream_get_type())\n-G_DECLARE_DERIVABLE_TYPE(GArrowGPUCUDABufferOutputStream,\n-                         garrow_gpu_cuda_buffer_output_stream,\n-                         GARROW_GPU,\n-                         CUDA_BUFFER_OUTPUT_STREAM,\n-                         GArrowOutputStream)\n-struct _GArrowGPUCUDABufferOutputStreamClass\n-{\n-  GArrowOutputStreamClass parent_class;\n-};\n-\n-GArrowGPUCUDADeviceManager *\n-garrow_gpu_cuda_device_manager_new(GError **error);\n-\n-GArrowGPUCUDAContext *\n-garrow_gpu_cuda_device_manager_get_context(GArrowGPUCUDADeviceManager *manager,\n-                                           gint gpu_number,\n-                                           GError **error);\n-gsize\n-garrow_gpu_cuda_device_manager_get_n_devices(GArrowGPUCUDADeviceManager *manager);\n-\n-gint64\n-garrow_gpu_cuda_context_get_allocated_size(GArrowGPUCUDAContext *context);\n-\n-\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new(GArrowGPUCUDAContext *context,\n-                           gint64 size,\n-                           GError **error);\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new_ipc(GArrowGPUCUDAContext *context,\n-                               GArrowGPUCUDAIPCMemoryHandle *handle,\n-                               GError **error);\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new_record_batch(GArrowGPUCUDAContext *context,\n-                                        GArrowRecordBatch *record_batch,\n-                                        GError **error);\n-GBytes *\n-garrow_gpu_cuda_buffer_copy_to_host(GArrowGPUCUDABuffer *buffer,\n-                                    gint64 position,\n-                                    gint64 size,\n-                                    GError **error);\n-gboolean\n-garrow_gpu_cuda_buffer_copy_from_host(GArrowGPUCUDABuffer *buffer,\n-                                      const guint8 *data,\n-                                      gint64 size,\n-                                      GError **error);\n-GArrowGPUCUDAIPCMemoryHandle *\n-garrow_gpu_cuda_buffer_export(GArrowGPUCUDABuffer *buffer,\n-                              GError **error);\n-GArrowGPUCUDAContext *\n-garrow_gpu_cuda_buffer_get_context(GArrowGPUCUDABuffer *buffer);\n-GArrowRecordBatch *\n-garrow_gpu_cuda_buffer_read_record_batch(GArrowGPUCUDABuffer *buffer,\n-                                         GArrowSchema *schema,\n-                                         GError **error);\n-\n-\n-GArrowGPUCUDAHostBuffer *\n-garrow_gpu_cuda_host_buffer_new(gint gpu_number,\n-                                gint64 size,\n-                                GError **error);\n-\n-GArrowGPUCUDAIPCMemoryHandle *\n-garrow_gpu_cuda_ipc_memory_handle_new(const guint8 *data,\n-                                      gsize size,\n-                                      GError **error);\n-\n-GArrowBuffer *\n-garrow_gpu_cuda_ipc_memory_handle_serialize(GArrowGPUCUDAIPCMemoryHandle *handle,\n-                                            GError **error);\n-\n-GArrowGPUCUDABufferInputStream *\n-garrow_gpu_cuda_buffer_input_stream_new(GArrowGPUCUDABuffer *buffer);\n-\n-GArrowGPUCUDABufferOutputStream *\n-garrow_gpu_cuda_buffer_output_stream_new(GArrowGPUCUDABuffer *buffer);\n-\n-gboolean\n-garrow_gpu_cuda_buffer_output_stream_set_buffer_size(GArrowGPUCUDABufferOutputStream *stream,\n-                                                     gint64 size,\n-                                                     GError **error);\n-gint64\n-garrow_gpu_cuda_buffer_output_stream_get_buffer_size(GArrowGPUCUDABufferOutputStream *stream);\n-gint64\n-garrow_gpu_cuda_buffer_output_stream_get_buffered_size(GArrowGPUCUDABufferOutputStream *stream);\n-\n-G_END_DECLS\ndiff --git a/c_glib/arrow-gpu-glib/cuda.hpp b/c_glib/arrow-gpu-glib/cuda.hpp\ndeleted file mode 100644\nindex 4b5b03c8b4..0000000000\n--- a/c_glib/arrow-gpu-glib/cuda.hpp\n+++ /dev/null\n@@ -1,54 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-#pragma once\n-\n-#include <arrow/gpu/cuda_api.h>\n-\n-#include <arrow-gpu-glib/cuda.h>\n-\n-GArrowGPUCUDAContext *\n-garrow_gpu_cuda_context_new_raw(std::shared_ptr<arrow::gpu::CudaContext> *arrow_context);\n-std::shared_ptr<arrow::gpu::CudaContext>\n-garrow_gpu_cuda_context_get_raw(GArrowGPUCUDAContext *context);\n-\n-GArrowGPUCUDAIPCMemoryHandle *\n-garrow_gpu_cuda_ipc_memory_handle_new_raw(std::shared_ptr<arrow::gpu::CudaIpcMemHandle> *arrow_handle);\n-std::shared_ptr<arrow::gpu::CudaIpcMemHandle>\n-garrow_gpu_cuda_ipc_memory_handle_get_raw(GArrowGPUCUDAIPCMemoryHandle *handle);\n-\n-GArrowGPUCUDABuffer *\n-garrow_gpu_cuda_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaBuffer> *arrow_buffer);\n-std::shared_ptr<arrow::gpu::CudaBuffer>\n-garrow_gpu_cuda_buffer_get_raw(GArrowGPUCUDABuffer *buffer);\n-\n-GArrowGPUCUDAHostBuffer *\n-garrow_gpu_cuda_host_buffer_new_raw(std::shared_ptr<arrow::gpu::CudaHostBuffer> *arrow_buffer);\n-std::shared_ptr<arrow::gpu::CudaHostBuffer>\n-garrow_gpu_cuda_host_buffer_get_raw(GArrowGPUCUDAHostBuffer *buffer);\n-\n-GArrowGPUCUDABufferInputStream *\n-garrow_gpu_cuda_buffer_input_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferReader> *arrow_reader);\n-std::shared_ptr<arrow::gpu::CudaBufferReader>\n-garrow_gpu_cuda_buffer_input_stream_get_raw(GArrowGPUCUDABufferInputStream *input_stream);\n-\n-GArrowGPUCUDABufferOutputStream *\n-garrow_gpu_cuda_buffer_output_stream_new_raw(std::shared_ptr<arrow::gpu::CudaBufferWriter> *arrow_writer);\n-std::shared_ptr<arrow::gpu::CudaBufferWriter>\n-garrow_gpu_cuda_buffer_output_stream_get_raw(GArrowGPUCUDABufferOutputStream *output_stream);\ndiff --git a/c_glib/arrow-gpu-glib/meson.build b/c_glib/arrow-gpu-glib/meson.build\ndeleted file mode 100644\nindex 680982ef12..0000000000\n--- a/c_glib/arrow-gpu-glib/meson.build\n+++ /dev/null\n@@ -1,79 +0,0 @@\n-# -*- indent-tabs-mode: nil -*-\n-#\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#   http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-\n-sources = files(\n-  'cuda.cpp',\n-)\n-\n-c_headers = files(\n-  'arrow-gpu-glib.h',\n-  'cuda.h',\n-)\n-\n-cpp_headers = files(\n-  'arrow-gpu-glib.hpp',\n-  'cuda.hpp',\n-)\n-\n-headers = c_headers + cpp_headers\n-install_headers(headers, subdir: 'arrow-gpu-glib')\n-\n-\n-dependencies = [\n-  arrow_gpu,\n-  arrow_glib,\n-]\n-libarrow_gpu_glib = library('arrow-gpu-glib',\n-                            sources: sources,\n-                            install: true,\n-                            dependencies: dependencies,\n-                            include_directories: base_include_directories,\n-                            soversion: so_version,\n-                            version: library_version)\n-arrow_gpu_glib = declare_dependency(link_with: libarrow_gpu_glib,\n-                                    include_directories: base_include_directories,\n-                                    dependencies: dependencies)\n-\n-pkgconfig.generate(filebase: 'arrow-gpu-glib',\n-                   name: 'Apache Arrow GPU GLib',\n-                   description: 'C API for Apache Arrow GPU based on GLib',\n-                   version: version,\n-                   requires: ['arrow-glib', 'arrow-gpu'],\n-                   libraries: [libarrow_gpu_glib])\n-\n-gir_dependencies = [\n-  declare_dependency(sources: arrow_glib_gir),\n-]\n-gir_extra_args = [\n-  '--warn-all',\n-  '--include-uninstalled=./arrow-glib/Arrow-1.0.gir',\n-]\n-arrow_gpu_glib_gir = gnome.generate_gir(libarrow_gpu_glib,\n-                                        dependencies: gir_dependencies,\n-                                        sources: sources + c_headers,\n-                                        namespace: 'ArrowGPU',\n-                                        nsversion: api_version,\n-                                        identifier_prefix: 'GArrowGPU',\n-                                        symbol_prefix: 'garrow_gpu',\n-                                        export_packages: 'arrow-gpu-glib',\n-                                        includes: [\n-                                          'Arrow-1.0',\n-                                        ],\n-                                        install: true,\n-                                        extra_args: gir_extra_args)\ndiff --git a/c_glib/configure.ac b/c_glib/configure.ac\nindex b84e3d3a7a..a6d8ed8e1d 100644\n--- a/c_glib/configure.ac\n+++ b/c_glib/configure.ac\n@@ -115,6 +115,7 @@ AC_ARG_WITH(arrow-cpp-build-type,\n   [GARROW_ARROW_CPP_BUILD_TYPE=\"$withval\"],\n   [GARROW_ARROW_CPP_BUILD_TYPE=\"release\"])\n \n+ARROW_CUDA_PKG_CONFIG_PATH=\"\"\n AC_ARG_WITH(arrow-cpp-build-dir,\n   [AS_HELP_STRING([--with-arrow-cpp-build-dir=PATH],\n                   [Use this option to build with not installed Arrow C++])],\n@@ -130,10 +131,10 @@ if test \"x$GARROW_ARROW_CPP_BUILD_DIR\" = \"x\"; then\n                     [arrow-orc],\n                     [HAVE_ARROW_ORC=yes],\n                     [HAVE_ARROW_ORC=no])\n-  PKG_CHECK_MODULES([ARROW_GPU],\n-                    [arrow-gpu],\n-                    [HAVE_ARROW_GPU=yes],\n-                    [HAVE_ARROW_GPU=no])\n+  PKG_CHECK_MODULES([ARROW_CUDA],\n+                    [arrow-cuda],\n+                    [HAVE_ARROW_CUDA=yes],\n+                    [HAVE_ARROW_CUDA=no])\n   PKG_CHECK_MODULES([GANDIVA],\n                     [gandiva],\n                     [HAVE_GANDIVA=yes],\n@@ -168,16 +169,19 @@ else\n     HAVE_ARROW_ORC=no\n   fi\n \n-  ARROW_GPU_CFLAGS=\"\"\n-  if test -f \"${GARROW_ARROW_CPP_BUILD_DIR}/src/arrow/gpu/arrow-gpu.pc\"; then\n-    HAVE_ARROW_GPU=yes\n-    ARROW_GPU_LIBS=\"-larrow_gpu\"\n+  ARROW_CUDA_CFLAGS=\"\"\n+  if test -f \"${GARROW_ARROW_CPP_BUILD_DIR}/src/arrow/gpu/arrow-cuda.pc\"; then\n+    HAVE_ARROW_CUDA=yes\n+    ARROW_CUDA_LIBS=\"-larrow_cuda\"\n+    ARROW_CUDA_PKG_CONFIG_PATH=\"\\$(ARROW_BUILD_DIR)/src/arrow/gpu\"\n   else\n-    HAVE_ARROW_GPU=no\n-    ARROW_GPU_LIBS=\"\"\n+    HAVE_ARROW_CUDA=no\n+    ARROW_CUDA_LIBS=\"\"\n+    ARROW_CUDA_PKG_CONFIG_PATH=\"\"\n   fi\n-  AC_SUBST(ARROW_GPU_CFLAGS)\n-  AC_SUBST(ARROW_GPU_LIBS)\n+  AC_SUBST(ARROW_CUDA_CFLAGS)\n+  AC_SUBST(ARROW_CUDA_LIBS)\n+  AC_SUBST(ARROW_CUDA_PKG_CONFIG_PATH)\n \n   GANDIVA_CFLAGS=\"\"\n   if test -f \"${GARROW_ARROW_CPP_BUILD_DIR}/src/gandiva/gandiva.pc\"; then\n@@ -221,14 +225,20 @@ if test \"$HAVE_ARROW_ORC\" = \"yes\"; then\n   AC_DEFINE(HAVE_ARROW_ORC, [1], [Define to 1 if Apache Arrow supports ORC.])\n fi\n \n-AM_CONDITIONAL([HAVE_ARROW_GPU], [test \"$HAVE_ARROW_GPU\" = \"yes\"])\n-if test \"$HAVE_ARROW_GPU\" = \"yes\"; then\n-  ARROW_GPU_GLIB_PACKAGE=\"arrow-gpu-glib\"\n-  AC_DEFINE(HAVE_ARROW_GPU, [1], [Define to 1 if Apache Arrow supports GPU.])\n+AM_CONDITIONAL([HAVE_ARROW_CUDA], [test \"$HAVE_ARROW_CUDA\" = \"yes\"])\n+if test \"$HAVE_ARROW_CUDA\" = \"yes\"; then\n+  ARROW_CUDA_GLIB_PACKAGE=\"arrow-cuda-glib\"\n+  PLASMA_ARROW_CUDA_PKG_CONFIG_PATH=\":\\$(abs_top_builddir)/arrow-cuda-glib\"\n+  if test -n \"${ARROW_CUDA_PKG_CONFIG_PATH}\"; then\n+    PLASMA_ARROW_CUDA_PKG_CONFIG_PATH=\":${ARROW_CUDA_PKG_CONFIG_PATH}${PLASMA_ARROW_CUDA_PKG_CONFIG_PATH}\"\n+  fi\n+  AC_DEFINE(HAVE_ARROW_CUDA, [1], [Define to 1 if Apache Arrow supports CUDA.])\n else\n-  ARROW_GPU_GLIB_PACKAGE=\"\"\n+  ARROW_CUDA_GLIB_PACKAGE=\"\"\n+  PLASMA_ARROW_CUDA_PKG_CONFIG_PATH=\"\"\n fi\n-AC_SUBST(ARROW_GPU_GLIB_PACKAGE)\n+AC_SUBST(ARROW_CUDA_GLIB_PACKAGE)\n+AC_SUBST(PLASMA_ARROW_CUDA_PKG_CONFIG_PATH)\n \n AM_CONDITIONAL([HAVE_GANDIVA], [test \"$HAVE_GANDIVA\" = \"yes\"])\n if test \"$HAVE_GANDIVA\" = \"yes\"; then\n@@ -250,12 +260,12 @@ AC_SUBST(exampledir)\n \n AC_CONFIG_FILES([\n   Makefile\n+  arrow-cuda-glib/Makefile\n+  arrow-cuda-glib/arrow-cuda-glib.pc\n   arrow-glib/Makefile\n   arrow-glib/arrow-glib.pc\n   arrow-glib/arrow-orc-glib.pc\n   arrow-glib/version.h\n-  arrow-gpu-glib/Makefile\n-  arrow-gpu-glib/arrow-gpu-glib.pc\n   gandiva-glib/Makefile\n   gandiva-glib/gandiva-glib.pc\n   parquet-glib/Makefile\ndiff --git a/c_glib/doc/arrow-glib/Makefile.am b/c_glib/doc/arrow-glib/Makefile.am\nindex ad0c938219..db9f00f39f 100644\n--- a/c_glib/doc/arrow-glib/Makefile.am\n+++ b/c_glib/doc/arrow-glib/Makefile.am\n@@ -55,15 +55,15 @@ AM_CFLAGS =\t\t\t\t\t\\\n GTKDOC_LIBS =\t\t\t\t\t\t\\\n \t$(top_builddir)/arrow-glib/libarrow-glib.la\n \n-if HAVE_ARROW_GPU\n+if HAVE_ARROW_CUDA\n DOC_SOURCE_DIR +=\t\t\t\t\\\n-\t$(top_srcdir)/arrow-gpu-glib\n+\t$(top_srcdir)/arrow-cuda-glib\n HFILE_GLOB +=\t\t\t\t\t\\\n-\t$(top_srcdir)/arrow-gpu-glib/*.h\n+\t$(top_srcdir)/arrow-cuda-glib/*.h\n CFILE_GLOB +=\t\t\t\t\t\\\n-\t$(top_srcdir)/arrow-gpu-glib/*.cpp\n+\t$(top_srcdir)/arrow-cuda-glib/*.cpp\n GTKDOC_LIBS +=\t\t\t\t\t\t\t\\\n-\t$(top_builddir)/arrow-gpu-glib/libarrow-gpu-glib.la\n+\t$(top_builddir)/arrow-cuda-glib/libarrow-cuda-glib.la\n endif\n \n include $(top_srcdir)/gtk-doc.make\ndiff --git a/c_glib/doc/arrow-glib/meson.build b/c_glib/doc/arrow-glib/meson.build\nindex 68050aa879..d61a9747de 100644\n--- a/c_glib/doc/arrow-glib/meson.build\n+++ b/c_glib/doc/arrow-glib/meson.build\n@@ -50,13 +50,13 @@ source_directories = [\n dependencies = [\n   arrow_glib,\n ]\n-if arrow_gpu.found()\n+if arrow_cuda.found()\n   source_directories += [\n-    join_paths(meson.source_root(), 'arrow-gpu-glib'),\n-    join_paths(meson.build_root(), 'arrow-gpu-glib'),\n+    join_paths(meson.source_root(), 'arrow-cuda-glib'),\n+    join_paths(meson.build_root(), 'arrow-cuda-glib'),\n   ]\n   dependencies += [\n-    arrow_gpu_glib,\n+    arrow_cuda_glib,\n   ]\n endif\n ignore_headers = []\ndiff --git a/c_glib/doc/plasma-glib/Makefile.am b/c_glib/doc/plasma-glib/Makefile.am\nindex f4ef9e5ee8..df872d6ca3 100644\n--- a/c_glib/doc/plasma-glib/Makefile.am\n+++ b/c_glib/doc/plasma-glib/Makefile.am\n@@ -15,10 +15,10 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-PLASMA_ARROW_GPU_GTKDOC_LIBS =\n-if HAVE_ARROW_GPU\n-PLASMA_ARROW_GPU_GTKDOC_LIBS +=\t\t\t\t\t\\\n-\t$(top_builddir)/arrow-gpu-glib/libarrow-gpu-glib.la\n+PLASMA_ARROW_CUDA_GTKDOC_LIBS =\n+if HAVE_ARROW_CUDA\n+PLASMA_ARROW_CUDA_GTKDOC_LIBS +=\t\t\t\t\\\n+\t$(top_builddir)/arrow-cuda-glib/libarrow-cuda-glib.la\n endif\n \n if HAVE_PLASMA\n@@ -56,7 +56,7 @@ AM_CFLAGS =\t\t\t\t\t\\\n \n GTKDOC_LIBS =\t\t\t\t\t\t\\\n \t$(top_builddir)/arrow-glib/libarrow-glib.la\t\\\n-\t$(PLASMA_ARROW_GPU_GTKDOC_LIBS)\t\t\t\\\n+\t$(PLASMA_ARROW_CUDA_GTKDOC_LIBS)\t\t\\\n \t$(top_builddir)/plasma-glib/libplasma-glib.la\n \n include $(top_srcdir)/gtk-doc.make\ndiff --git a/c_glib/doc/plasma-glib/meson.build b/c_glib/doc/plasma-glib/meson.build\nindex 95d7db8bbb..9efc53b4b1 100644\n--- a/c_glib/doc/plasma-glib/meson.build\n+++ b/c_glib/doc/plasma-glib/meson.build\n@@ -56,8 +56,8 @@ dependencies = [\n   arrow_glib,\n   plasma_glib,\n ]\n-if arrow_gpu.found()\n-  dependencies += [arrow_gpu_glib]\n+if arrow_cuda.found()\n+  dependencies += [arrow_cuda_glib]\n endif\n ignore_headers = []\n gnome.gtkdoc(project_name,\ndiff --git a/c_glib/meson.build b/c_glib/meson.build\nindex 14136056d4..194421c13d 100644\n--- a/c_glib/meson.build\n+++ b/c_glib/meson.build\n@@ -64,7 +64,7 @@ endif\n if arrow_cpp_build_lib_dir == ''\n   arrow = dependency('arrow')\n   have_arrow_orc = dependency('arrow-orc', required: false).found()\n-  arrow_gpu = dependency('arrow-gpu', required: false)\n+  arrow_cuda = dependency('arrow-cuda', required: false)\n   gandiva = dependency('gandiva', required: false)\n   parquet = dependency('parquet', required: false)\n   plasma = dependency('plasma', required: false)\n@@ -89,9 +89,9 @@ main(void)\n   have_arrow_orc = cpp_compiler.links(arrow_orc_code,\n                                       include_directories: base_include_directories,\n                                       dependencies: [arrow])\n-  arrow_gpu = cpp_compiler.find_library('arrow_gpu',\n-                                        dirs: [arrow_cpp_build_lib_dir],\n-                                        required: false)\n+  arrow_cuda = cpp_compiler.find_library('arrow_cuda',\n+                                         dirs: [arrow_cpp_build_lib_dir],\n+                                         required: false)\n   gandiva = cpp_compiler.find_library('gandiva',\n                                       dirs: [arrow_cpp_build_lib_dir],\n                                       required: false)\n@@ -104,8 +104,8 @@ main(void)\n endif\n \n subdir('arrow-glib')\n-if arrow_gpu.found()\n-  subdir('arrow-gpu-glib')\n+if arrow_cuda.found()\n+  subdir('arrow-cuda-glib')\n endif\n if gandiva.found()\n   subdir('gandiva-glib')\n@@ -136,7 +136,7 @@ test('unit test',\n      run_test,\n      env: [\n        'ARROW_GLIB_TYPELIB_DIR=@0@/arrow-glib'.format(meson.build_root()),\n-       'ARROW_GPU_GLIB_TYPELIB_DIR=@0@/arrow-gpu-glib'.format(meson.build_root()),\n+       'ARROW_CUDA_GLIB_TYPELIB_DIR=@0@/arrow-cuda-glib'.format(meson.build_root()),\n        'GANDIVA_GLIB_TYPELIB_DIR=@0@/gandiva-glib'.format(meson.build_root()),\n        'PARQUET_GLIB_TYPELIB_DIR=@0@/parquet-glib'.format(meson.build_root()),\n        'PARQUET_GLIB_TYPELIB_DIR=@0@/plasma-glib'.format(meson.build_root()),\ndiff --git a/c_glib/plasma-glib/Makefile.am b/c_glib/plasma-glib/Makefile.am\nindex 2060472b01..d14638bc22 100644\n--- a/c_glib/plasma-glib/Makefile.am\n+++ b/c_glib/plasma-glib/Makefile.am\n@@ -31,32 +31,29 @@ AM_CFLAGS =\t\t\t\t\t\\\n \t$(GARROW_CFLAGS)\t\t\t\\\n \t$(GPLASMA_CFLAGS)\n \n-PLASMA_ARROW_GPU_LIBS =\n-PLASMA_ARROW_GPU_GLIB_PKG_CONFIG_PATH =\n-PLASMA_INTROSPECTION_COMPILER_ARROW_GPU_ARGS =\n-PLASMA_GIR_ARROW_GPU_PACKAGE =\n-PLASMA_GIR_ARROW_GPU_SCANNER_ADD_INCLUDE_PATH =\n-PLASMA_GIR_ARROW_GPU_LIBS_MACOS =\n-PLASMA_GIR_ARROW_GPU_SCANNER_LIBRARY_PATH_MACOS =\n-PLASMA_GIR_ARROW_GPU_LIBS =\n-if HAVE_ARROW_GPU\n-PLASMA_ARROW_GPU_LIBS +=\t\t\t\\\n-\t$(ARROW_GPU_LIBS)\t\t\t\\\n-\t../arrow-gpu-glib/libarrow-gpu-glib.la\n-PLASMA_ARROW_GPU_GLIB_PKG_CONFIG_PATH +=\t\\\n-\t:${abs_top_builddir}/arrow-gpu-glib\n-PLASMA_INTROSPECTION_COMPILER_ARROW_GPU_ARGS +=\t\\\n-\t--includedir=$(abs_top_builddir)/arrow-gpu-glib\n-PLASMA_GIR_ARROW_GPU_PACKAGE +=\t\t\t\\\n-\tarrow-gpu-glib\n-PLASMA_GIR_ARROW_GPU_SCANNER_ADD_INCLUDE_PATH +=\t\t\\\n-\t--add-include-path=$(abs_top_builddir)/arrow-gpu-glib\n-PLASMA_GIR_ARROW_GPU_LIBS_MACOS +=\t\t\t\\\n-\tarrow-gpu-glib\n-PLASMA_GIR_ARROW_GPU_SCANNER_LIBRARY_PATH_MACOS +=\t\t\\\n-\t--library-path=$(abs_top_builddir)/arrow-gpu-glib/.libs\n-PLASMA_GIR_ARROW_GPU_LIBS +=\t\t\t\t\t\\\n-\t$(abs_top_builddir)/arrow-gpu-glib/libarrow-gpu-glib.la\n+PLASMA_ARROW_CUDA_LIBS =\n+PLASMA_INTROSPECTION_COMPILER_ARROW_CUDA_ARGS =\n+PLASMA_GIR_ARROW_CUDA_PACKAGE =\n+PLASMA_GIR_ARROW_CUDA_SCANNER_ADD_INCLUDE_PATH =\n+PLASMA_GIR_ARROW_CUDA_LIBS_MACOS =\n+PLASMA_GIR_ARROW_CUDA_SCANNER_LIBRARY_PATH_MACOS =\n+PLASMA_GIR_ARROW_CUDA_LIBS =\n+if HAVE_ARROW_CUDA\n+PLASMA_ARROW_CUDA_LIBS +=\t\t\t\t\\\n+\t$(ARROW_CUDA_LIBS)\t\t\t\t\\\n+\t../arrow-cuda-glib/libarrow-cuda-glib.la\n+PLASMA_INTROSPECTION_COMPILER_ARROW_CUDA_ARGS +=\t\t\\\n+\t--includedir=$(abs_top_builddir)/arrow-cuda-glib\n+PLASMA_GIR_ARROW_CUDA_PACKAGE +=\t\t\\\n+\tarrow-cuda-glib\n+PLASMA_GIR_ARROW_CUDA_SCANNER_ADD_INCLUDE_PATH +=\t\t\\\n+\t--add-include-path=$(abs_top_builddir)/arrow-cuda-glib\n+PLASMA_GIR_ARROW_CUDA_LIBS_MACOS +=\t\t\\\n+\tarrow-cuda-glib\n+PLASMA_GIR_ARROW_CUDA_SCANNER_LIBRARY_PATH_MACOS +=\t\t\t\\\n+\t--library-path=$(abs_top_builddir)/arrow-cuda-glib/.libs\n+PLASMA_GIR_ARROW_CUDA_LIBS +=\t\t\t\t\t\t\\\n+\t$(abs_top_builddir)/arrow-cuda-glib/libarrow-cuda-glib.la\n endif\n \n if HAVE_PLASMA\n@@ -79,7 +76,7 @@ libplasma_glib_la_LIBADD =\t\t\t\\\n \t$(ARROW_LIBS)\t\t\t\t\\\n \t$(PLASMA_LIBS)\t\t\t\t\\\n \t../arrow-glib/libarrow-glib.la\t\t\\\n-\t$(PLASMA_ARROW_GPU_LIBS)\n+\t$(PLASMA_ARROW_CUDA_LIBS)\n \n libplasma_glib_la_headers =\t\t\t\\\n \tclient.h\t\t\t\t\\\n@@ -117,19 +114,19 @@ INTROSPECTION_SCANNER_ARGS =\n INTROSPECTION_SCANNER_ENV =\n if USE_ARROW_BUILD_DIR\n INTROSPECTION_SCANNER_ENV +=\t\t\t\\\n-\tPKG_CONFIG_PATH=${abs_top_builddir}/arrow-glib$(PLASMA_ARROW_GPU_GLIB_PKG_CONFIG_PATH):$(ARROW_BUILD_DIR)/src/arrow:$${PKG_CONFIG_PATH}\n+\tPKG_CONFIG_PATH=$(abs_top_builddir)/arrow-glib$(PLASMA_ARROW_CUDA_PKG_CONFIG_PATH):$(ARROW_BUILD_DIR)/src/arrow:$${PKG_CONFIG_PATH}\n else\n INTROSPECTION_SCANNER_ENV +=\t\t\t\\\n-\tPKG_CONFIG_PATH=${abs_top_builddir}/arrow-glib$(PLASMA_ARROW_GPU_GLIB_PKG_CONFIG_PATH):$${PKG_CONFIG_PATH}\n+\tPKG_CONFIG_PATH=$(abs_top_builddir)/arrow-glib$(PLASMA_ARROW_CUDA_PKG_CONFIG_PATH):$${PKG_CONFIG_PATH}\n endif\n INTROSPECTION_COMPILER_ARGS =\t\t\t\t\t\\\n \t--includedir=$(abs_top_builddir)/arrow-glib\t\t\\\n-\t$(PLASMA_INTROSPECTION_COMPILER_ARROW_GPU_INCLUDEDIR)\n+\t$(PLASMA_INTROSPECTION_COMPILER_ARROW_CUDA_INCLUDEDIR)\n \n Plasma-1.0.gir: libplasma-glib.la\n Plasma_1_0_gir_PACKAGES =\t\t\t\\\n \tarrow-glib\t\t\t\t\\\n-\t$(PLASMA_GIR_ARROW_GPU_PACKAGE)\n+\t$(PLASMA_GIR_ARROW_CUDA_PACKAGE)\n Plasma_1_0_gir_EXPORT_PACKAGES =\t\t\\\n \tplasma-glib\n Plasma_1_0_gir_INCLUDES =\t\t\t\\\n@@ -140,7 +137,7 @@ Plasma_1_0_gir_LIBS =\n Plasma_1_0_gir_FILES = $(libplasma_glib_la_sources)\n Plasma_1_0_gir_SCANNERFLAGS =\t\t\t\t\t\\\n \t--add-include-path=$(abs_top_builddir)/arrow-glib\t\\\n-\t$(PLASMA_GIR_ARROW_GPU_SCANNER_ADD_INCLUDE_PATH)\t\\\n+\t$(PLASMA_GIR_ARROW_CUDA_SCANNER_ADD_INCLUDE_PATH)\t\\\n \t--library-path=$(ARROW_LIB_DIR)\t\t\t\t\\\n \t--warn-all\t\t\t\t\t\t\\\n \t--identifier-prefix=GPlasma\t\t\t\t\\\n@@ -148,17 +145,17 @@ Plasma_1_0_gir_SCANNERFLAGS =\t\t\t\t\t\\\n if OS_MACOS\n Plasma_1_0_gir_LIBS +=\t\t\t\t\\\n \tarrow-glib\t\t\t\t\\\n-\t$(PLASMA_GIR_ARROW_GPU_LIBS_MACOS)\t\\\n+\t$(PLASMA_GIR_ARROW_CUDA_LIBS_MACOS)\t\\\n \tplasma-glib\n Plasma_1_0_gir_SCANNERFLAGS +=\t\t\t\t\t\\\n \t--no-libtool\t\t\t\t\t\t\\\n \t--library-path=$(abs_top_builddir)/arrow-glib/.libs\t\\\n-\t$(PLASMA_GIR_ARROW_GPU_SCANNER_LIBRARY_PATH_MACOS)\t\\\n+\t$(PLASMA_GIR_ARROW_CUDA_SCANNER_LIBRARY_PATH_MACOS)\t\\\n \t--library-path=$(abs_builddir)/.libs\n else\n Plasma_1_0_gir_LIBS +=\t\t\t\t\t\\\n \t$(abs_top_builddir)/arrow-glib/libarrow-glib.la\t\\\n-\t$(PLASMA_GIR_ARROW_GPU_LIBS)\t\t\t\\\n+\t$(PLASMA_GIR_ARROW_CUDA_LIBS)\t\t\t\\\n \tlibplasma-glib.la\n endif\n INTROSPECTION_GIRS += Plasma-1.0.gir\ndiff --git a/c_glib/plasma-glib/client.cpp b/c_glib/plasma-glib/client.cpp\nindex 6a2629b38c..e88cb13e83 100644\n--- a/c_glib/plasma-glib/client.cpp\n+++ b/c_glib/plasma-glib/client.cpp\n@@ -24,8 +24,8 @@\n #include <arrow-glib/buffer.hpp>\n #include <arrow-glib/error.hpp>\n \n-#ifdef HAVE_ARROW_GPU\n-#  include <arrow-gpu-glib/cuda.hpp>\n+#ifdef HAVE_ARROW_CUDA\n+#  include <arrow-cuda-glib/cuda.hpp>\n #endif\n \n #include <plasma-glib/client.hpp>\n@@ -311,11 +311,11 @@ gplasma_client_create(GPlasmaClient *client,\n     raw_metadata = options_priv->metadata;\n     raw_metadata_size = options_priv->metadata_size;\n     if (options_priv->gpu_device >= 0) {\n-#ifndef HAVE_ARROW_GPU\n+#ifndef HAVE_ARROW_CUDA\n       g_set_error(error,\n                   GARROW_ERROR,\n                   GARROW_ERROR_INVALID,\n-                  \"%s Arrow GPU GLib is needed to use GPU\",\n+                  \"%s Arrow CUDA GLib is needed to use GPU\",\n                   context);\n       return NULL;\n #endif\n@@ -335,11 +335,11 @@ gplasma_client_create(GPlasmaClient *client,\n       auto plasma_mutable_data =\n         std::static_pointer_cast<arrow::MutableBuffer>(plasma_data);\n       data = GARROW_BUFFER(garrow_mutable_buffer_new_raw(&plasma_mutable_data));\n-#ifdef HAVE_ARROW_GPU\n+#ifdef HAVE_ARROW_CUDA\n     } else {\n       auto plasma_cuda_data =\n-        std::static_pointer_cast<arrow::gpu::CudaBuffer>(plasma_data);\n-      data = GARROW_BUFFER(garrow_gpu_cuda_buffer_new_raw(&plasma_cuda_data));\n+        std::static_pointer_cast<arrow::cuda::CudaBuffer>(plasma_data);\n+      data = GARROW_BUFFER(garrow_cuda_buffer_new_raw(&plasma_cuda_data));\n #endif\n     }\n     GArrowBuffer *metadata = nullptr;\n@@ -392,28 +392,28 @@ gplasma_client_refer_object(GPlasmaClient *client,\n     GArrowBuffer *data = nullptr;\n     GArrowBuffer *metadata = nullptr;\n     if (plasma_object_buffer.device_num > 0) {\n-#ifdef HAVE_ARROW_GPU\n-      std::shared_ptr<arrow::gpu::CudaBuffer> plasma_cuda_data;\n-      status = arrow::gpu::CudaBuffer::FromBuffer(plasma_data,\n-                                                  &plasma_cuda_data);\n+#ifdef HAVE_ARROW_CUDA\n+      std::shared_ptr<arrow::cuda::CudaBuffer> plasma_cuda_data;\n+      status = arrow::cuda::CudaBuffer::FromBuffer(plasma_data,\n+                                                   &plasma_cuda_data);\n       if (!garrow_error_check(error, status, context)) {\n         return NULL;\n       }\n-      std::shared_ptr<arrow::gpu::CudaBuffer> plasma_cuda_metadata;\n-      status = arrow::gpu::CudaBuffer::FromBuffer(plasma_metadata,\n+      std::shared_ptr<arrow::cuda::CudaBuffer> plasma_cuda_metadata;\n+      status = arrow::cuda::CudaBuffer::FromBuffer(plasma_metadata,\n                                                   &plasma_cuda_metadata);\n       if (!garrow_error_check(error, status, context)) {\n         return NULL;\n       }\n \n-      data = GARROW_BUFFER(garrow_gpu_cuda_buffer_new_raw(&plasma_cuda_data));\n+      data = GARROW_BUFFER(garrow_cuda_buffer_new_raw(&plasma_cuda_data));\n       metadata =\n-        GARROW_BUFFER(garrow_gpu_cuda_buffer_new_raw(&plasma_cuda_metadata));\n+        GARROW_BUFFER(garrow_cuda_buffer_new_raw(&plasma_cuda_metadata));\n #else\n       g_set_error(error,\n                   GARROW_ERROR,\n                   GARROW_ERROR_INVALID,\n-                  \"%s Arrow GPU GLib is needed to use GPU\",\n+                  \"%s Arrow CUDA GLib is needed to use GPU\",\n                   context);\n       return NULL;\n #endif\ndiff --git a/c_glib/plasma-glib/meson.build b/c_glib/plasma-glib/meson.build\nindex 60a6978658..75ebce870d 100644\n--- a/c_glib/plasma-glib/meson.build\n+++ b/c_glib/plasma-glib/meson.build\n@@ -61,13 +61,13 @@ gir_extra_args = [\n   '--warn-all',\n   '--include-uninstalled=./arrow-glib/Arrow-1.0.gir',\n ]\n-if arrow_gpu.found()\n-  dependencies += [arrow_gpu_glib]\n-  cpp_args += ['-DHAVE_ARROW_GPU']\n-  pkg_config_requires += ['arrow-gpu-glib']\n-  gir_dependencies += [declare_dependency(sources: arrow_gpu_glib_gir)]\n-  gir_includes += ['ArrowGPU-1.0']\n-  gir_extra_args += ['--include-uninstalled=./arrow-gpu-glib/ArrowGPU-1.0.gir']\n+if arrow_cuda.found()\n+  dependencies += [arrow_cuda_glib]\n+  cpp_args += ['-DHAVE_ARROW_CUDA']\n+  pkg_config_requires += ['arrow-cuda-glib']\n+  gir_dependencies += [declare_dependency(sources: arrow_cuda_glib_gir)]\n+  gir_includes += ['ArrowCUDA-1.0']\n+  gir_extra_args += ['--include-uninstalled=./arrow-cuda-glib/ArrowCUDA-1.0.gir']\n endif\n libplasma_glib = library('plasma-glib',\n                          sources: sources,\ndiff --git a/c_glib/test/plasma/test-plasma-client.rb b/c_glib/test/plasma/test-plasma-client.rb\nindex 4bf9fa9b6d..cbdce865f0 100644\n--- a/c_glib/test/plasma/test-plasma-client.rb\n+++ b/c_glib/test/plasma/test-plasma-client.rb\n@@ -61,7 +61,7 @@ def setup\n     end\n \n     test(\"options: GPU device\") do\n-      omit(\"Arrow GPU is required\") unless defined?(::ArrowGPU)\n+      omit(\"Arrow CUDA is required\") unless defined?(::ArrowCUDA)\n \n       gpu_device = 0\n \ndiff --git a/c_glib/test/run-test.rb b/c_glib/test/run-test.rb\nindex 238bb2d68a..99d72f4289 100755\n--- a/c_glib/test/run-test.rb\n+++ b/c_glib/test/run-test.rb\n@@ -38,7 +38,7 @@ def initialize(data)\n end\n \n begin\n-  ArrowGPU = GI.load(\"ArrowGPU\")\n+  ArrowCUDA = GI.load(\"ArrowCUDA\")\n rescue GObjectIntrospection::RepositoryError::TypelibNotFound\n end\n \ndiff --git a/c_glib/test/run-test.sh b/c_glib/test/run-test.sh\nindex 96585ce653..d33555dd45 100755\n--- a/c_glib/test/run-test.sh\n+++ b/c_glib/test/run-test.sh\n@@ -20,7 +20,7 @@\n test_dir=\"$(cd $(dirname $0); pwd)\"\n build_dir=\"$(cd .; pwd)\"\n \n-modules=\"arrow-glib arrow-gpu-glib gandiva-glib parquet-glib plasma-glib\"\n+modules=\"arrow-glib arrow-cuda-glib gandiva-glib parquet-glib plasma-glib\"\n \n for module in ${modules}; do\n   module_build_dir=\"${build_dir}/${module}\"\ndiff --git a/c_glib/test/test-gpu-cuda.rb b/c_glib/test/test-cuda.rb\nsimilarity index 80%\nrename from c_glib/test/test-gpu-cuda.rb\nrename to c_glib/test/test-cuda.rb\nindex 66ec19d424..32d486ef8b 100644\n--- a/c_glib/test/test-gpu-cuda.rb\n+++ b/c_glib/test/test-cuda.rb\n@@ -15,12 +15,12 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-class TestGPUCUDA < Test::Unit::TestCase\n+class TestCUDA < Test::Unit::TestCase\n   include Helper::Buildable\n \n   def setup\n-    omit(\"Arrow GPU is required\") unless defined?(::ArrowGPU)\n-    @manager = ArrowGPU::CUDADeviceManager.new\n+    omit(\"Arrow CUDA is required\") unless defined?(::ArrowCUDA)\n+    @manager = ArrowCUDA::DeviceManager.new\n     omit(\"At least one GPU is required\") if @manager.n_devices.zero?\n     @context = @manager.get_context(0)\n   end\n@@ -29,7 +29,7 @@ def setup\n     def test_allocated_size\n       allocated_size_before = @context.allocated_size\n       size = 128\n-      buffer = ArrowGPU::CUDABuffer.new(@context, size)\n+      buffer = ArrowCUDA::Buffer.new(@context, size)\n       assert_equal(size,\n                    @context.allocated_size - allocated_size_before)\n     end\n@@ -38,7 +38,7 @@ def test_allocated_size\n   sub_test_case(\"Buffer\") do\n     def setup\n       super\n-      @buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+      @buffer = ArrowCUDA::Buffer.new(@context, 128)\n     end\n \n     def test_copy\n@@ -50,19 +50,19 @@ def test_export\n       @buffer.copy_from_host(\"Hello World\")\n       handle = @buffer.export\n       serialized_handle = handle.serialize.data\n-      Tempfile.open(\"arrow-gpu-cuda-export\") do |output|\n+      Tempfile.open(\"arrow-cuda-export\") do |output|\n         pid = spawn(RbConfig.ruby, \"-e\", <<-SCRIPT)\n require \"gi\"\n \n Gio = GI.load(\"Gio\")\n Arrow = GI.load(\"Arrow\")\n-ArrowGPU = GI.load(\"ArrowGPU\")\n+ArrowCUDA = GI.load(\"ArrowCUDA\")\n \n-manager = ArrowGPU::CUDADeviceManager.new\n+manager = ArrowCUDA::ADeviceManager.new\n context = manager.get_context(0)\n serialized_handle = #{serialized_handle.to_s.dump}\n-handle = ArrowGPU::CUDAIPCMemoryHandle.new(serialized_handle)\n-buffer = ArrowGPU::CUDABuffer.new(context, handle)\n+handle = ArrowCUDA::IPCMemoryHandle.new(serialized_handle)\n+buffer = ArrowCUDA::Buffer.new(context, handle)\n File.open(#{output.path.dump}, \"w\") do |output|\n   output.print(buffer.copy_to_host(0, 6).to_s)\n end\n@@ -85,7 +85,7 @@ def test_record_batch\n       ]\n       cpu_record_batch = Arrow::RecordBatch.new(schema, 1, columns)\n \n-      buffer = ArrowGPU::CUDABuffer.new(@context, cpu_record_batch)\n+      buffer = ArrowCUDA::Buffer.new(@context, cpu_record_batch)\n       gpu_record_batch = buffer.read_record_batch(schema)\n       assert_equal(cpu_record_batch.n_rows,\n                    gpu_record_batch.n_rows)\n@@ -94,16 +94,16 @@ def test_record_batch\n \n   sub_test_case(\"HostBuffer\") do\n     def test_new\n-      buffer = ArrowGPU::CUDAHostBuffer.new(0, 128)\n+      buffer = ArrowCUDA::HostBuffer.new(0, 128)\n       assert_equal(128, buffer.size)\n     end\n   end\n \n   sub_test_case(\"BufferInputStream\") do\n     def test_new\n-      buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+      buffer = ArrowCUDA::Buffer.new(@context, 128)\n       buffer.copy_from_host(\"Hello World\")\n-      stream = ArrowGPU::CUDABufferInputStream.new(buffer)\n+      stream = ArrowCUDA::BufferInputStream.new(buffer)\n       begin\n         assert_equal(\"Hello Worl\", stream.read(5).copy_to_host(0, 10).to_s)\n       ensure\n@@ -115,9 +115,9 @@ def test_new\n   sub_test_case(\"BufferOutputStream\") do\n     def setup\n       super\n-      @buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+      @buffer = ArrowCUDA::Buffer.new(@context, 128)\n       @buffer.copy_from_host(\"\\x00\" * @buffer.size)\n-      @stream = ArrowGPU::CUDABufferOutputStream.new(@buffer)\n+      @stream = ArrowCUDA::BufferOutputStream.new(@buffer)\n     end\n \n     def cleanup\ndiff --git a/cpp/CMakeLists.txt b/cpp/CMakeLists.txt\nindex 14621e4e30..6deb339f4c 100644\n--- a/cpp/CMakeLists.txt\n+++ b/cpp/CMakeLists.txt\n@@ -150,8 +150,8 @@ Pass multiple labels by dividing with semicolons\")\n     \"Build the Arrow IPC extensions\"\n     ON)\n \n-  option(ARROW_GPU\n-    \"Build the Arrow GPU extensions (requires CUDA installation)\"\n+  option(ARROW_CUDA\n+    \"Build the Arrow CUDA extensions (requires CUDA toolkit)\"\n     OFF)\n \n   option(ARROW_ORC\ndiff --git a/cpp/README.md b/cpp/README.md\nindex fcf9137239..394b23d69f 100644\n--- a/cpp/README.md\n+++ b/cpp/README.md\n@@ -204,13 +204,11 @@ The Python library must be built against the same Python version for which you\n are building pyarrow, e.g. Python 2.7 or Python 3.6. NumPy must also be\n installed.\n \n-### Building GPU extension library (optional)\n+### Building CUDA extension library (optional)\n \n-The optional `arrow_gpu` shared library can be built by passing\n-`-DARROW_GPU=on`. This requires a CUDA installation to build, and to use many\n-of the functions you must have a functioning GPU. Currently only CUDA\n-functionality is supported, though if there is demand we can also add OpenCL\n-interfaces in this library as needed.\n+The optional `arrow_cuda` shared library can be built by passing\n+`-DARROW_CUDA=on`. This requires a CUDA installation to build, and to use many\n+of the functions you must have a functioning CUDA-compatible GPU.\n \n The CUDA toolchain used to build the library can be customized by using the\n `$CUDA_HOME` environment variable.\ndiff --git a/cpp/cmake_modules/FindArrowCuda.cmake b/cpp/cmake_modules/FindArrowCuda.cmake\nindex 8733b61673..bac148fa3b 100644\n--- a/cpp/cmake_modules/FindArrowCuda.cmake\n+++ b/cpp/cmake_modules/FindArrowCuda.cmake\n@@ -15,7 +15,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-# - Find ARROW CUDA (arrow/gpu/cuda_api.h, libarrow_gpu.a, libarrow_gpu.so)\n+# - Find ARROW CUDA (arrow/gpu/cuda_api.h, libarrow_cuda.a, libarrow_cuda.so)\n #\n # This module requires Arrow from which it uses\n #   ARROW_FOUND\n@@ -31,10 +31,6 @@\n #  ARROW_CUDA_SHARED_IMP_LIB, path to libarrow's import library (MSVC only)\n #  ARROW_CUDA_FOUND, whether arrow has been found\n \n-#\n-# TODO(ARROW-3209): rename arrow/gpu to arrow/cuda, arrow_gpu to arrow_cuda\n-#\n-\n include(FindPkgConfig)\n include(GNUInstallDirs)\n \n@@ -63,14 +59,14 @@ if (NOT (ARROW_CUDA_INCLUDE_DIR STREQUAL ARROW_INCLUDE_DIR))\n   message(WARNING ${ARROW_CUDA_WARN_MSG})\n endif()\n \n-find_library(ARROW_CUDA_LIB_PATH NAMES arrow_gpu\n+find_library(ARROW_CUDA_LIB_PATH NAMES arrow_cuda\n   PATHS\n   ${ARROW_SEARCH_LIB_PATH}\n   NO_DEFAULT_PATH)\n get_filename_component(ARROW_CUDA_LIBS ${ARROW_CUDA_LIB_PATH} DIRECTORY)\n \n if (MSVC)\n-  find_library(ARROW_CUDA_SHARED_LIBRARIES NAMES arrow_gpu\n+  find_library(ARROW_CUDA_SHARED_LIBRARIES NAMES arrow_cuda\n     PATHS ${ARROW_HOME} NO_DEFAULT_PATH\n     PATH_SUFFIXES \"bin\" )\n   get_filename_component(ARROW_CUDA_SHARED_LIBS ${ARROW_CUDA_SHARED_LIBRARIES} PATH )\n@@ -79,7 +75,7 @@ endif()\n \n if (ARROW_CUDA_INCLUDE_DIR AND ARROW_CUDA_LIBS)\n   set(ARROW_CUDA_FOUND TRUE)\n-  set(ARROW_CUDA_LIB_NAME arrow_gpu)\n+  set(ARROW_CUDA_LIB_NAME arrow_cuda)\n   if (MSVC)\n     set(ARROW_CUDA_STATIC_LIB ${ARROW_CUDA_LIBS}/${ARROW_CUDA_LIB_NAME}${ARROW_MSVC_STATIC_LIB_SUFFIX}${CMAKE_STATIC_LIBRARY_SUFFIX})\n     set(ARROW_CUDA_SHARED_LIB ${ARROW_CUDA_SHARED_LIBS}/${ARROW_CUDA_LIB_NAME}${CMAKE_SHARED_LIBRARY_SUFFIX})\ndiff --git a/cpp/src/arrow/CMakeLists.txt b/cpp/src/arrow/CMakeLists.txt\nindex 336007d4de..6858f3c4c4 100644\n--- a/cpp/src/arrow/CMakeLists.txt\n+++ b/cpp/src/arrow/CMakeLists.txt\n@@ -78,8 +78,8 @@ if (ARROW_COMPUTE)\n   )\n endif()\n \n-if (ARROW_GPU)\n-  # IPC extensions required to build the GPU library\n+if (ARROW_CUDA)\n+  # IPC extensions required to build the CUDA library\n   set(ARROW_IPC ON)\n   add_subdirectory(gpu)\n endif()\ndiff --git a/cpp/src/arrow/gpu/CMakeLists.txt b/cpp/src/arrow/gpu/CMakeLists.txt\nindex ed4c125297..60407acb0a 100644\n--- a/cpp/src/arrow/gpu/CMakeLists.txt\n+++ b/cpp/src/arrow/gpu/CMakeLists.txt\n@@ -16,7 +16,7 @@\n # under the License.\n \n #######################################\n-# arrow_gpu\n+# arrow_cuda\n #######################################\n \n if (DEFINED ENV{CUDA_HOME})\n@@ -28,28 +28,28 @@ include_directories(SYSTEM ${CUDA_INCLUDE_DIRS})\n \n message(STATUS \"CUDA Libraries: ${CUDA_LIBRARIES}\")\n \n-set(ARROW_GPU_SRCS\n+set(ARROW_CUDA_SRCS\n   cuda_arrow_ipc.cc\n   cuda_context.cc\n   cuda_memory.cc\n )\n \n-set(ARROW_GPU_SHARED_LINK_LIBS\n+set(ARROW_CUDA_SHARED_LINK_LIBS\n   ${CUDA_LIBRARIES}\n   ${CUDA_CUDA_LIBRARY}\n )\n \n-ADD_ARROW_LIB(arrow_gpu\n-  SOURCES ${ARROW_GPU_SRCS}\n-  OUTPUTS ARROW_GPU_LIBRARIES\n+ADD_ARROW_LIB(arrow_cuda\n+  SOURCES ${ARROW_CUDA_SRCS}\n+  OUTPUTS ARROW_CUDA_LIBRARIES\n   DEPENDENCIES metadata_fbs\n   SHARED_LINK_FLAGS \"\"\n-  SHARED_LINK_LIBS arrow_shared ${ARROW_GPU_SHARED_LINK_LIBS}\n-  # Static arrow_gpu must also link against CUDA shared libs\n-  STATIC_LINK_LIBS ${ARROW_GPU_SHARED_LINK_LIBS}\n+  SHARED_LINK_LIBS arrow_shared ${ARROW_CUDA_SHARED_LINK_LIBS}\n+  # Static arrow_cuda must also link against CUDA shared libs\n+  STATIC_LINK_LIBS ${ARROW_CUDA_SHARED_LINK_LIBS}\n )\n \n-foreach(LIB_TARGET ${ARROW_GPU_LIBRARIES})\n+foreach(LIB_TARGET ${ARROW_CUDA_LIBRARIES})\n   target_compile_definitions(${LIB_TARGET}\n     PRIVATE ARROW_EXPORTING)\n endforeach()\n@@ -71,28 +71,28 @@ install(FILES\n   DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/arrow/gpu\")\n \n # pkg-config support\n-configure_file(arrow-gpu.pc.in\n-  \"${CMAKE_CURRENT_BINARY_DIR}/arrow-gpu.pc\"\n+configure_file(arrow-cuda.pc.in\n+  \"${CMAKE_CURRENT_BINARY_DIR}/arrow-cuda.pc\"\n   @ONLY)\n \n install(\n-  FILES \"${CMAKE_CURRENT_BINARY_DIR}/arrow-gpu.pc\"\n+  FILES \"${CMAKE_CURRENT_BINARY_DIR}/arrow-cuda.pc\"\n   DESTINATION \"${CMAKE_INSTALL_LIBDIR}/pkgconfig/\")\n \n-set(ARROW_GPU_TEST_LINK_LIBS\n-  arrow_gpu_shared\n+set(ARROW_CUDA_TEST_LINK_LIBS\n+  arrow_cuda_shared\n   ${ARROW_TEST_LINK_LIBS})\n \n if (ARROW_BUILD_TESTS)\n   ADD_ARROW_TEST(cuda-test\n-    STATIC_LINK_LIBS ${ARROW_GPU_TEST_LINK_LIBS}\n+    STATIC_LINK_LIBS ${ARROW_CUDA_TEST_LINK_LIBS}\n     NO_VALGRIND)\n endif()\n \n if (ARROW_BUILD_BENCHMARKS)\n   cuda_add_executable(cuda-benchmark cuda-benchmark.cc)\n   target_link_libraries(cuda-benchmark\n-    arrow_gpu_shared\n+    arrow_cuda_shared\n     gtest_static\n     ${ARROW_BENCHMARK_LINK_LIBS})\n endif()\ndiff --git a/cpp/src/arrow/gpu/arrow-gpu.pc.in b/cpp/src/arrow/gpu/arrow-cuda.pc.in\nsimilarity index 89%\nrename from cpp/src/arrow/gpu/arrow-gpu.pc.in\nrename to cpp/src/arrow/gpu/arrow-cuda.pc.in\nindex 3889d03b20..858096f892 100644\n--- a/cpp/src/arrow/gpu/arrow-gpu.pc.in\n+++ b/cpp/src/arrow/gpu/arrow-cuda.pc.in\n@@ -18,9 +18,9 @@\n libdir=@CMAKE_INSTALL_FULL_LIBDIR@\n includedir=@CMAKE_INSTALL_FULL_INCLUDEDIR@\n \n-Name: Apache Arrow GPU\n-Description: GPU integration library for Apache Arrow\n+Name: Apache Arrow CUDA\n+Description: CUDA integration library for Apache Arrow\n Version: @ARROW_VERSION@\n Requires: arrow\n-Libs: -L${libdir} -larrow_gpu\n+Libs: -L${libdir} -larrow_cuda\n Cflags: -I${includedir}\ndiff --git a/cpp/src/arrow/gpu/cuda-benchmark.cc b/cpp/src/arrow/gpu/cuda-benchmark.cc\nindex 8b3723d838..9889373d09 100644\n--- a/cpp/src/arrow/gpu/cuda-benchmark.cc\n+++ b/cpp/src/arrow/gpu/cuda-benchmark.cc\n@@ -28,7 +28,7 @@\n #include \"arrow/gpu/cuda_api.h\"\n \n namespace arrow {\n-namespace gpu {\n+namespace cuda {\n \n constexpr int64_t kGpuNumber = 0;\n \n@@ -94,5 +94,5 @@ BENCHMARK(BM_Writer_Unbuffered)\n     ->MinTime(1.0)\n     ->UseRealTime();\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/gpu/cuda-test.cc b/cpp/src/arrow/gpu/cuda-test.cc\nindex cb37545800..5d85a81a23 100644\n--- a/cpp/src/arrow/gpu/cuda-test.cc\n+++ b/cpp/src/arrow/gpu/cuda-test.cc\n@@ -29,7 +29,7 @@\n #include \"arrow/gpu/cuda_api.h\"\n \n namespace arrow {\n-namespace gpu {\n+namespace cuda {\n \n constexpr int kGpuNumber = 0;\n \n@@ -323,7 +323,7 @@ TEST_F(TestCudaArrowIpc, BasicWriteRead) {\n   ASSERT_OK(ipc::MakeIntRecordBatch(&batch));\n \n   std::shared_ptr<CudaBuffer> device_serialized;\n-  ASSERT_OK(arrow::gpu::SerializeRecordBatch(*batch, context_.get(), &device_serialized));\n+  ASSERT_OK(SerializeRecordBatch(*batch, context_.get(), &device_serialized));\n \n   // Test that ReadRecordBatch works properly\n   std::shared_ptr<RecordBatch> device_batch;\n@@ -343,5 +343,5 @@ TEST_F(TestCudaArrowIpc, BasicWriteRead) {\n   CompareBatch(*batch, *cpu_batch);\n }\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/gpu/cuda_arrow_ipc.cc b/cpp/src/arrow/gpu/cuda_arrow_ipc.cc\nindex a7262c8b4d..03256a1f52 100644\n--- a/cpp/src/arrow/gpu/cuda_arrow_ipc.cc\n+++ b/cpp/src/arrow/gpu/cuda_arrow_ipc.cc\n@@ -38,7 +38,7 @@ namespace arrow {\n \n namespace flatbuf = org::apache::arrow::flatbuf;\n \n-namespace gpu {\n+namespace cuda {\n \n Status SerializeRecordBatch(const RecordBatch& batch, CudaContext* ctx,\n                             std::shared_ptr<CudaBuffer>* out) {\n@@ -106,5 +106,5 @@ Status ReadRecordBatch(const std::shared_ptr<Schema>& schema,\n   return ipc::ReadRecordBatch(*message, schema, out);\n }\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/gpu/cuda_arrow_ipc.h b/cpp/src/arrow/gpu/cuda_arrow_ipc.h\nindex 52dd92473e..4eb85e797c 100644\n--- a/cpp/src/arrow/gpu/cuda_arrow_ipc.h\n+++ b/cpp/src/arrow/gpu/cuda_arrow_ipc.h\n@@ -39,7 +39,7 @@ class Message;\n \n }  // namespace ipc\n \n-namespace gpu {\n+namespace cuda {\n \n /// \\brief Write record batch message to GPU device memory\n /// \\param[in] batch record batch to write\n@@ -71,7 +71,7 @@ Status ReadRecordBatch(const std::shared_ptr<Schema>& schema,\n                        const std::shared_ptr<CudaBuffer>& buffer, MemoryPool* pool,\n                        std::shared_ptr<RecordBatch>* out);\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\n \n #endif  // ARROW_GPU_CUDA_ARROW_IPC_H\ndiff --git a/cpp/src/arrow/gpu/cuda_common.h b/cpp/src/arrow/gpu/cuda_common.h\nindex c06c1a21ff..a53dd220ad 100644\n--- a/cpp/src/arrow/gpu/cuda_common.h\n+++ b/cpp/src/arrow/gpu/cuda_common.h\n@@ -25,7 +25,7 @@\n #include <cuda.h>\n \n namespace arrow {\n-namespace gpu {\n+namespace cuda {\n \n #define CUDA_DCHECK(STMT) \\\n   do {                    \\\n@@ -45,7 +45,7 @@ namespace gpu {\n     }                                                                         \\\n   } while (0)\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\n \n #endif  // ARROW_GPU_CUDA_COMMON_H\ndiff --git a/cpp/src/arrow/gpu/cuda_context.cc b/cpp/src/arrow/gpu/cuda_context.cc\nindex 566ae6f878..9e95040837 100644\n--- a/cpp/src/arrow/gpu/cuda_context.cc\n+++ b/cpp/src/arrow/gpu/cuda_context.cc\n@@ -28,8 +28,9 @@\n \n #include \"arrow/gpu/cuda_common.h\"\n #include \"arrow/gpu/cuda_memory.h\"\n+\n namespace arrow {\n-namespace gpu {\n+namespace cuda {\n \n struct CudaDevice {\n   int device_num;\n@@ -342,5 +343,5 @@ void* CudaContext::handle() const { return impl_->context_handle(); }\n \n int CudaContext::device_number() const { return impl_->device().device_num; }\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/gpu/cuda_context.h b/cpp/src/arrow/gpu/cuda_context.h\nindex e59273e562..9a67cea897 100644\n--- a/cpp/src/arrow/gpu/cuda_context.h\n+++ b/cpp/src/arrow/gpu/cuda_context.h\n@@ -27,7 +27,7 @@\n #include \"arrow/gpu/cuda_memory.h\"\n \n namespace arrow {\n-namespace gpu {\n+namespace cuda {\n \n // Forward declaration\n class CudaContext;\n@@ -138,7 +138,7 @@ class ARROW_EXPORT CudaContext : public std::enable_shared_from_this<CudaContext\n   friend CudaDeviceManager::CudaDeviceManagerImpl;\n };\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\n \n #endif  // ARROW_GPU_CUDA_CONTEXT_H\ndiff --git a/cpp/src/arrow/gpu/cuda_memory.cc b/cpp/src/arrow/gpu/cuda_memory.cc\nindex e8cc4b5fe2..cf0c51c23a 100644\n--- a/cpp/src/arrow/gpu/cuda_memory.cc\n+++ b/cpp/src/arrow/gpu/cuda_memory.cc\n@@ -34,7 +34,7 @@\n #include \"arrow/gpu/cuda_context.h\"\n \n namespace arrow {\n-namespace gpu {\n+namespace cuda {\n \n // ----------------------------------------------------------------------\n // CUDA IPC memory handle\n@@ -365,5 +365,5 @@ Status AllocateCudaHostBuffer(int device_number, const int64_t size,\n   return manager->AllocateHost(device_number, size, out);\n }\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/gpu/cuda_memory.h b/cpp/src/arrow/gpu/cuda_memory.h\nindex 0da58c170f..c8f80837cd 100644\n--- a/cpp/src/arrow/gpu/cuda_memory.h\n+++ b/cpp/src/arrow/gpu/cuda_memory.h\n@@ -27,7 +27,7 @@\n #include \"arrow/status.h\"\n \n namespace arrow {\n-namespace gpu {\n+namespace cuda {\n \n class CudaContext;\n class CudaIpcMemHandle;\n@@ -215,7 +215,7 @@ ARROW_EXPORT\n Status AllocateCudaHostBuffer(int device_number, const int64_t size,\n                               std::shared_ptr<CudaHostBuffer>* out);\n \n-}  // namespace gpu\n+}  // namespace cuda\n }  // namespace arrow\n \n #endif  // ARROW_GPU_CUDA_MEMORY_H\ndiff --git a/cpp/src/plasma/CMakeLists.txt b/cpp/src/plasma/CMakeLists.txt\nindex f9ed4e3d4e..0f8916e6c4 100644\n--- a/cpp/src/plasma/CMakeLists.txt\n+++ b/cpp/src/plasma/CMakeLists.txt\n@@ -83,10 +83,10 @@ set(PLASMA_SRCS\n set(PLASMA_LINK_LIBS arrow_shared)\n set(PLASMA_STATIC_LINK_LIBS arrow_static)\n \n-if (ARROW_GPU)\n-  set(PLASMA_LINK_LIBS ${PLASMA_LINK_LIBS} arrow_gpu_shared)\n-  set(PLASMA_STATIC_LINK_LIBS arrow_gpu_static ${PLASMA_STATIC_LINK_LIBS})\n-  add_definitions(-DPLASMA_GPU)\n+if (ARROW_CUDA)\n+  set(PLASMA_LINK_LIBS ${PLASMA_LINK_LIBS} arrow_cuda_shared)\n+  set(PLASMA_STATIC_LINK_LIBS arrow_cuda_static ${PLASMA_STATIC_LINK_LIBS})\n+  add_definitions(-DPLASMA_CUDA)\n endif()\n \n ADD_ARROW_LIB(plasma\ndiff --git a/cpp/src/plasma/client.cc b/cpp/src/plasma/client.cc\nindex 20dc42181d..99cf00cab8 100644\n--- a/cpp/src/plasma/client.cc\n+++ b/cpp/src/plasma/client.cc\n@@ -53,13 +53,13 @@\n #include \"plasma/plasma.h\"\n #include \"plasma/protocol.h\"\n \n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n #include \"arrow/gpu/cuda_api.h\"\n \n-using arrow::gpu::CudaBuffer;\n-using arrow::gpu::CudaBufferWriter;\n-using arrow::gpu::CudaContext;\n-using arrow::gpu::CudaDeviceManager;\n+using arrow::cuda::CudaBuffer;\n+using arrow::cuda::CudaBufferWriter;\n+using arrow::cuda::CudaContext;\n+using arrow::cuda::CudaDeviceManager;\n #endif\n \n #define XXH_INLINE_ALL 1\n@@ -89,7 +89,7 @@ constexpr int64_t kL3CacheSizeBytes = 100000000;\n // ----------------------------------------------------------------------\n // GPU support\n \n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n struct GpuProcessHandle {\n   /// Pointer to CUDA buffer that is backing this GPU object.\n   std::shared_ptr<CudaBuffer> ptr;\n@@ -286,16 +286,16 @@ class PlasmaClient::Impl : public std::enable_shared_from_this<PlasmaClient::Imp\n   /// A hash set to record the ids that users want to delete but still in use.\n   std::unordered_set<ObjectID> deletion_cache_;\n \n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   /// Cuda Device Manager.\n-  arrow::gpu::CudaDeviceManager* manager_;\n+  arrow::cuda::CudaDeviceManager* manager_;\n #endif\n };\n \n PlasmaBuffer::~PlasmaBuffer() { ARROW_UNUSED(client_->Release(object_id_)); }\n \n PlasmaClient::Impl::Impl() {\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   DCHECK_OK(CudaDeviceManager::GetInstance(&manager_));\n #endif\n }\n@@ -413,7 +413,7 @@ Status PlasmaClient::Impl::Create(const ObjectID& object_id, int64_t data_size,\n       memcpy((*data)->mutable_data() + object.data_size, metadata, metadata_size);\n     }\n   } else {\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n     std::lock_guard<std::mutex> lock(gpu_mutex);\n     std::shared_ptr<CudaContext> context;\n     RETURN_NOT_OK(manager_->GetContext(device_num - 1, &context));\n@@ -497,7 +497,7 @@ Status PlasmaClient::Impl::GetBuffers(\n         physical_buf = std::make_shared<Buffer>(\n             data + object->data_offset, object->data_size + object->metadata_size);\n       } else {\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n         physical_buf = gpu_object_map.find(object_ids[i])->second->ptr;\n #else\n         ARROW_LOG(FATAL) << \"Arrow GPU library is not enabled.\";\n@@ -560,7 +560,7 @@ Status PlasmaClient::Impl::GetBuffers(\n         physical_buf = std::make_shared<Buffer>(\n             data + object->data_offset, object->data_size + object->metadata_size);\n       } else {\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n         std::lock_guard<std::mutex> lock(gpu_mutex);\n         auto handle = gpu_object_map.find(object_ids[i]);\n         if (handle == gpu_object_map.end()) {\ndiff --git a/cpp/src/plasma/common.h b/cpp/src/plasma/common.h\nindex f7cdaf5ff5..7090428ff4 100644\n--- a/cpp/src/plasma/common.h\n+++ b/cpp/src/plasma/common.h\n@@ -34,7 +34,7 @@\n \n #include \"arrow/status.h\"\n #include \"arrow/util/logging.h\"\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n #include \"arrow/gpu/cuda_api.h\"\n #endif\n \n@@ -118,9 +118,9 @@ struct ObjectTableEntry {\n   int64_t data_size;\n   /// Size of the object metadata in bytes.\n   int64_t metadata_size;\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   /// IPC GPU handle to share with clients.\n-  std::shared_ptr<::arrow::gpu::CudaIpcMemHandle> ipc_handle;\n+  std::shared_ptr<::arrow::cuda::CudaIpcMemHandle> ipc_handle;\n #endif\n   /// Number of clients currently using this object.\n   int ref_count;\ndiff --git a/cpp/src/plasma/plasma.h b/cpp/src/plasma/plasma.h\nindex e63d967676..83caec7ee4 100644\n--- a/cpp/src/plasma/plasma.h\n+++ b/cpp/src/plasma/plasma.h\n@@ -40,8 +40,8 @@\n #include \"plasma/common.h\"\n #include \"plasma/common_generated.h\"\n \n-#ifdef PLASMA_GPU\n-using arrow::gpu::CudaIpcMemHandle;\n+#ifdef PLASMA_CUDA\n+using arrow::cuda::CudaIpcMemHandle;\n #endif\n \n namespace plasma {\n@@ -73,7 +73,7 @@ typedef std::unordered_map<ObjectID, ObjectRequest> ObjectRequestMap;\n \n // TODO(pcm): Replace this by the flatbuffers message PlasmaObjectSpec.\n struct PlasmaObject {\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   // IPC handle for Cuda.\n   std::shared_ptr<CudaIpcMemHandle> ipc_handle;\n #endif\ndiff --git a/cpp/src/plasma/protocol.cc b/cpp/src/plasma/protocol.cc\nindex a74db66fde..c437840874 100644\n--- a/cpp/src/plasma/protocol.cc\n+++ b/cpp/src/plasma/protocol.cc\n@@ -25,7 +25,7 @@\n #include \"plasma/common.h\"\n #include \"plasma/io.h\"\n \n-#ifdef ARROW_GPU\n+#ifdef PLASMA_CUDA\n #include \"arrow/gpu/cuda_api.h\"\n #endif\n \n@@ -129,7 +129,7 @@ Status SendCreateReply(int sock, ObjectID object_id, PlasmaObject* object,\n                                  object->metadata_offset, object->metadata_size,\n                                  object->device_num);\n   auto object_string = fbb.CreateString(object_id.binary());\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   flatbuffers::Offset<fb::CudaHandle> ipc_handle;\n   if (object->device_num != 0) {\n     std::shared_ptr<arrow::Buffer> handle;\n@@ -145,7 +145,7 @@ Status SendCreateReply(int sock, ObjectID object_id, PlasmaObject* object,\n   crb.add_store_fd(object->store_fd);\n   crb.add_mmap_size(mmap_size);\n   if (object->device_num != 0) {\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n     crb.add_ipc_handle(ipc_handle);\n #else\n     ARROW_LOG(FATAL) << \"This should be unreachable.\";\n@@ -171,7 +171,7 @@ Status ReadCreateReply(uint8_t* data, size_t size, ObjectID* object_id,\n   *mmap_size = message->mmap_size();\n \n   object->device_num = message->plasma_object()->device_num();\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   if (object->device_num != 0) {\n     RETURN_NOT_OK(CudaIpcMemHandle::FromBuffer(message->ipc_handle()->handle()->data(),\n                                                &object->ipc_handle));\n@@ -588,7 +588,7 @@ Status SendGetReply(int sock, ObjectID object_ids[],\n     objects.push_back(PlasmaObjectSpec(object.store_fd, object.data_offset,\n                                        object.data_size, object.metadata_offset,\n                                        object.metadata_size, object.device_num));\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n     if (object.device_num != 0) {\n       std::shared_ptr<arrow::Buffer> handle;\n       RETURN_NOT_OK(object.ipc_handle->Serialize(arrow::default_memory_pool(), &handle));\n@@ -609,7 +609,7 @@ Status ReadGetReply(uint8_t* data, size_t size, ObjectID object_ids[],\n                     std::vector<int>& store_fds, std::vector<int64_t>& mmap_sizes) {\n   DCHECK(data);\n   auto message = flatbuffers::GetRoot<fb::PlasmaGetReply>(data);\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   int handle_pos = 0;\n #endif\n   DCHECK(VerifyFlatbuffer(message, data, size));\n@@ -624,7 +624,7 @@ Status ReadGetReply(uint8_t* data, size_t size, ObjectID object_ids[],\n     plasma_objects[i].metadata_offset = object->metadata_offset();\n     plasma_objects[i].metadata_size = object->metadata_size();\n     plasma_objects[i].device_num = object->device_num();\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n     if (object->device_num() != 0) {\n       const void* ipc_handle = message->handles()->Get(handle_pos)->handle()->data();\n       RETURN_NOT_OK(\ndiff --git a/cpp/src/plasma/store.cc b/cpp/src/plasma/store.cc\nindex bb99f599c5..ae658d757c 100644\n--- a/cpp/src/plasma/store.cc\n+++ b/cpp/src/plasma/store.cc\n@@ -58,12 +58,12 @@\n #include \"plasma/io.h\"\n #include \"plasma/malloc.h\"\n \n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n #include \"arrow/gpu/cuda_api.h\"\n \n-using arrow::gpu::CudaBuffer;\n-using arrow::gpu::CudaContext;\n-using arrow::gpu::CudaDeviceManager;\n+using arrow::cuda::CudaBuffer;\n+using arrow::cuda::CudaContext;\n+using arrow::cuda::CudaDeviceManager;\n #endif\n \n using arrow::util::ArrowLog;\n@@ -117,7 +117,7 @@ PlasmaStore::PlasmaStore(EventLoop* loop, int64_t system_memory, std::string dir\n   store_info_.memory_capacity = system_memory;\n   store_info_.directory = directory;\n   store_info_.hugepages_enabled = hugepages_enabled;\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   DCHECK_OK(CudaDeviceManager::GetInstance(&manager_));\n #endif\n }\n@@ -162,7 +162,7 @@ PlasmaError PlasmaStore::CreateObject(const ObjectID& object_id, int64_t data_si\n   }\n   // Try to evict objects until there is enough space.\n   uint8_t* pointer = nullptr;\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   std::shared_ptr<CudaBuffer> gpu_handle;\n   std::shared_ptr<CudaContext> context_;\n   if (device_num != 0) {\n@@ -195,7 +195,7 @@ PlasmaError PlasmaStore::CreateObject(const ObjectID& object_id, int64_t data_si\n         break;\n       }\n     } else {\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n       DCHECK_OK(context_->Allocate(data_size + metadata_size, &gpu_handle));\n       break;\n #endif\n@@ -220,7 +220,7 @@ PlasmaError PlasmaStore::CreateObject(const ObjectID& object_id, int64_t data_si\n   entry->device_num = device_num;\n   entry->create_time = std::time(nullptr);\n   entry->construct_duration = -1;\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   if (device_num != 0) {\n     DCHECK_OK(gpu_handle->ExportForIpc(&entry->ipc_handle));\n     result->ipc_handle = entry->ipc_handle;\n@@ -246,7 +246,7 @@ void PlasmaObject_init(PlasmaObject* object, ObjectTableEntry* entry) {\n   DCHECK(object != nullptr);\n   DCHECK(entry != nullptr);\n   DCHECK(entry->state == ObjectState::PLASMA_SEALED);\n-#ifdef PLASMA_GPU\n+#ifdef PLASMA_CUDA\n   if (entry->device_num != 0) {\n     object->ipc_handle = entry->ipc_handle;\n   }\ndiff --git a/cpp/src/plasma/store.h b/cpp/src/plasma/store.h\nindex 44fdf603f7..8d3facd733 100644\n--- a/cpp/src/plasma/store.h\n+++ b/cpp/src/plasma/store.h\n@@ -223,8 +223,8 @@ class PlasmaStore {\n   std::unordered_map<int, std::unique_ptr<Client>> connected_clients_;\n \n   std::unordered_set<ObjectID> deletion_cache_;\n-#ifdef PLASMA_GPU\n-  arrow::gpu::CudaDeviceManager* manager_;\n+#ifdef PLASMA_CUDA\n+  arrow::cuda::CudaDeviceManager* manager_;\n #endif\n };\n \ndiff --git a/cpp/src/plasma/test/client_tests.cc b/cpp/src/plasma/test/client_tests.cc\nindex 1ad60396af..f820303aba 100644\n--- a/cpp/src/plasma/test/client_tests.cc\n+++ b/cpp/src/plasma/test/client_tests.cc\n@@ -487,10 +487,10 @@ TEST_F(TestPlasmaStore, ManyObjectTest) {\n   }\n }\n \n-#ifdef PLASMA_GPU\n-using arrow::gpu::CudaBuffer;\n-using arrow::gpu::CudaBufferReader;\n-using arrow::gpu::CudaBufferWriter;\n+#ifdef PLASMA_CUDA\n+using arrow::cuda::CudaBuffer;\n+using arrow::cuda::CudaBufferReader;\n+using arrow::cuda::CudaBufferWriter;\n \n namespace {\n \n@@ -590,7 +590,7 @@ TEST_F(TestPlasmaStore, MultipleClientGPUTest) {\n   AssertCudaRead(object_buffers[0].metadata, {5});\n }\n \n-#endif  // PLASMA_GPU\n+#endif  // PLASMA_CUDA\n \n }  // namespace plasma\n \ndiff --git a/dev/release/rat_exclude_files.txt b/dev/release/rat_exclude_files.txt\nindex edf3b42513..39400b6ceb 100644\n--- a/dev/release/rat_exclude_files.txt\n+++ b/dev/release/rat_exclude_files.txt\n@@ -79,7 +79,7 @@ dev/tasks/linux-packages/debian.ubuntu-trusty/watch\n dev/tasks/linux-packages/debian/compat\n dev/tasks/linux-packages/debian/control\n dev/tasks/linux-packages/debian/gir1.2-arrow-1.0.install\n-dev/tasks/linux-packages/debian/gir1.2-arrow-gpu-1.0.install\n+dev/tasks/linux-packages/debian/gir1.2-arrow-cuda-1.0.install\n dev/tasks/linux-packages/debian/gir1.2-parquet-1.0.install\n dev/tasks/linux-packages/debian/gir1.2-plasma-1.0.install\n dev/tasks/linux-packages/debian/libarrow-dev.install\n@@ -88,10 +88,10 @@ dev/tasks/linux-packages/debian/libarrow-glib-doc.doc-base\n dev/tasks/linux-packages/debian/libarrow-glib-doc.install\n dev/tasks/linux-packages/debian/libarrow-glib-doc.links\n dev/tasks/linux-packages/debian/libarrow-glib12.install\n-dev/tasks/linux-packages/debian/libarrow-gpu-dev.install\n-dev/tasks/linux-packages/debian/libarrow-gpu-glib-dev.install\n-dev/tasks/linux-packages/debian/libarrow-gpu-glib12.install\n-dev/tasks/linux-packages/debian/libarrow-gpu12.install\n+dev/tasks/linux-packages/debian/libarrow-cuda-dev.install\n+dev/tasks/linux-packages/debian/libarrow-cuda-glib-dev.install\n+dev/tasks/linux-packages/debian/libarrow-cuda-glib12.install\n+dev/tasks/linux-packages/debian/libarrow-cuda12.install\n dev/tasks/linux-packages/debian/libarrow-python-dev.install\n dev/tasks/linux-packages/debian/libarrow-python12.install\n dev/tasks/linux-packages/debian/libarrow12.install\ndiff --git a/dev/tasks/linux-packages/debian/control b/dev/tasks/linux-packages/debian/control\nindex 3c6671426d..b5c6963637 100644\n--- a/dev/tasks/linux-packages/debian/control\n+++ b/dev/tasks/linux-packages/debian/control\n@@ -54,7 +54,7 @@ Description: Apache Arrow is a data processing library for analysis\n  .\n  This package provides C++ library files for Python support.\n \n-Package: libarrow-gpu12\n+Package: libarrow-cuda12\n Section: libs\n Architecture: any\n Multi-Arch: same\n@@ -65,7 +65,7 @@ Depends:\n   libarrow12 (= ${binary:Version})\n Description: Apache Arrow is a data processing library for analysis\n  .\n- This package provides C++ library files for GPU support.\n+ This package provides C++ library files for CUDA support.\n \n Package: libarrow-dev\n Section: libdevel\n@@ -90,17 +90,17 @@ Description: Apache Arrow is a data processing library for analysis\n  .\n  This package provides C++ header files for Python support.\n \n-Package: libarrow-gpu-dev\n+Package: libarrow-cuda-dev\n Section: libdevel\n Architecture: any\n Multi-Arch: same\n Depends:\n   ${misc:Depends},\n   libarrow-dev (= ${binary:Version}),\n-  libarrow-gpu12 (= ${binary:Version})\n+  libarrow-cuda12 (= ${binary:Version})\n Description: Apache Arrow is a data processing library for analysis\n  .\n- This package provides C++ header files for GPU support.\n+ This package provides C++ header files for CUDA support.\n \n Package: libplasma12\n Section: libs\n@@ -110,7 +110,7 @@ Pre-Depends: ${misc:Pre-Depends}\n Depends:\n   ${misc:Depends},\n   ${shlibs:Depends},\n-  libarrow-gpu12 (= ${binary:Version})\n+  libarrow-cuda12 (= ${binary:Version})\n Description: Plasma is an in-memory object store and cache for big data.\n  .\n  This package provides C++ library files to connect plasma_store_server.\n@@ -133,7 +133,7 @@ Architecture: any\n Multi-Arch: same\n Depends:\n   ${misc:Depends},\n-  libarrow-gpu-dev (= ${binary:Version}),\n+  libarrow-cuda-dev (= ${binary:Version}),\n   libplasma12 (= ${binary:Version})\n Description: Plasma is an in-memory object store and cache for big data.\n  .\n@@ -213,7 +213,7 @@ Description: Apache Arrow is a data processing library for analysis\n  .\n  This package provides documentations.\n \n-Package: libarrow-gpu-glib12\n+Package: libarrow-cuda-glib12\n Section: libs\n Architecture: any\n Multi-Arch: same\n@@ -222,12 +222,12 @@ Depends:\n   ${misc:Depends},\n   ${shlibs:Depends},\n   libarrow-glib12 (= ${binary:Version}),\n-  libarrow-gpu12 (= ${binary:Version})\n+  libarrow-cuda12 (= ${binary:Version})\n Description: Apache Arrow is a data processing library for analysis\n  .\n- This package provides GLib based library files for GPU support.\n+ This package provides GLib based library files for CUDA support.\n \n-Package: gir1.2-arrow-gpu-1.0\n+Package: gir1.2-arrow-cuda-1.0\n Section: introspection\n Architecture: any\n Multi-Arch: same\n@@ -236,21 +236,21 @@ Depends:\n   ${misc:Depends}\n Description: Apache Arrow is a data processing library for analysis\n  .\n- This package provides GObject Introspection typelib files for GPU support.\n+ This package provides GObject Introspection typelib files for CUDA support.\n \n-Package: libarrow-gpu-glib-dev\n+Package: libarrow-cuda-glib-dev\n Section: libdevel\n Architecture: any\n Multi-Arch: same\n Depends:\n   ${misc:Depends},\n-  libarrow-gpu-dev (= ${binary:Version}),\n+  libarrow-cuda-dev (= ${binary:Version}),\n   libarrow-glib-dev (= ${binary:Version}),\n-  libarrow-gpu-glib12 (= ${binary:Version}),\n-  gir1.2-arrow-gpu-1.0 (= ${binary:Version})\n+  libarrow-cuda-glib12 (= ${binary:Version}),\n+  gir1.2-arrow-cuda-1.0 (= ${binary:Version})\n Description: Apache Arrow is a data processing library for analysis\n  .\n- This package provides GLib based header files for GPU support.\n+ This package provides GLib based header files for CUDA support.\n \n Package: libplasma-glib12\n Section: libs\n@@ -260,7 +260,7 @@ Pre-Depends: ${misc:Pre-Depends}\n Depends:\n   ${misc:Depends},\n   ${shlibs:Depends},\n-  libarrow-gpu-glib12 (= ${binary:Version}),\n+  libarrow-cuda-glib12 (= ${binary:Version}),\n   libplasma12 (= ${binary:Version})\n Description: Plasma is an in-memory object store and cache for big data.\n  .\n@@ -284,7 +284,7 @@ Multi-Arch: same\n Depends:\n   ${misc:Depends},\n   libplasma-dev (= ${binary:Version}),\n-  libarrow-gpu-glib-dev (= ${binary:Version}),\n+  libarrow-cuda-glib-dev (= ${binary:Version}),\n   libplasma-glib12 (= ${binary:Version}),\n   gir1.2-plasma-1.0 (= ${binary:Version})\n Description: Plasma is an in-memory object store and cache for big data.\ndiff --git a/dev/tasks/linux-packages/debian/gir1.2-arrow-cuda-1.0.install b/dev/tasks/linux-packages/debian/gir1.2-arrow-cuda-1.0.install\nnew file mode 100644\nindex 0000000000..ef0d9f56f9\n--- /dev/null\n+++ b/dev/tasks/linux-packages/debian/gir1.2-arrow-cuda-1.0.install\n@@ -0,0 +1 @@\n+usr/lib/*/girepository-1.0/ArrowCUDA-1.0.typelib\ndiff --git a/dev/tasks/linux-packages/debian/gir1.2-arrow-gpu-1.0.install b/dev/tasks/linux-packages/debian/gir1.2-arrow-gpu-1.0.install\ndeleted file mode 100644\nindex 10e0ca983b..0000000000\n--- a/dev/tasks/linux-packages/debian/gir1.2-arrow-gpu-1.0.install\n+++ /dev/null\n@@ -1 +0,0 @@\n-usr/lib/*/girepository-1.0/ArrowGPU-1.0.typelib\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-cuda-dev.install b/dev/tasks/linux-packages/debian/libarrow-cuda-dev.install\nnew file mode 100644\nindex 0000000000..2270d92586\n--- /dev/null\n+++ b/dev/tasks/linux-packages/debian/libarrow-cuda-dev.install\n@@ -0,0 +1,3 @@\n+usr/lib/*/libarrow_cuda.a\n+usr/lib/*/libarrow_cuda.so\n+usr/lib/*/pkgconfig/arrow-cuda.pc\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-cuda-glib-dev.install b/dev/tasks/linux-packages/debian/libarrow-cuda-glib-dev.install\nnew file mode 100644\nindex 0000000000..7025fd2028\n--- /dev/null\n+++ b/dev/tasks/linux-packages/debian/libarrow-cuda-glib-dev.install\n@@ -0,0 +1,5 @@\n+usr/include/arrow-cuda-glib/\n+usr/lib/*/libarrow-cuda-glib.a\n+usr/lib/*/libarrow-cuda-glib.so\n+usr/lib/*/pkgconfig/arrow-cuda-glib.pc\n+usr/share/gir-1.0/ArrowCUDA-1.0.gir\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-cuda-glib12.install b/dev/tasks/linux-packages/debian/libarrow-cuda-glib12.install\nnew file mode 100644\nindex 0000000000..a6d6375268\n--- /dev/null\n+++ b/dev/tasks/linux-packages/debian/libarrow-cuda-glib12.install\n@@ -0,0 +1 @@\n+usr/lib/*/libarrow-cuda-glib.so.*\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-cuda12.install b/dev/tasks/linux-packages/debian/libarrow-cuda12.install\nnew file mode 100644\nindex 0000000000..5ae4646876\n--- /dev/null\n+++ b/dev/tasks/linux-packages/debian/libarrow-cuda12.install\n@@ -0,0 +1 @@\n+usr/lib/*/libarrow_cuda.so.*\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-gpu-dev.install b/dev/tasks/linux-packages/debian/libarrow-gpu-dev.install\ndeleted file mode 100644\nindex 1892fb8515..0000000000\n--- a/dev/tasks/linux-packages/debian/libarrow-gpu-dev.install\n+++ /dev/null\n@@ -1,3 +0,0 @@\n-usr/lib/*/libarrow_gpu.a\n-usr/lib/*/libarrow_gpu.so\n-usr/lib/*/pkgconfig/arrow-gpu.pc\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-gpu-glib-dev.install b/dev/tasks/linux-packages/debian/libarrow-gpu-glib-dev.install\ndeleted file mode 100644\nindex 9b3ef8fb25..0000000000\n--- a/dev/tasks/linux-packages/debian/libarrow-gpu-glib-dev.install\n+++ /dev/null\n@@ -1,5 +0,0 @@\n-usr/include/arrow-gpu-glib/\n-usr/lib/*/libarrow-gpu-glib.a\n-usr/lib/*/libarrow-gpu-glib.so\n-usr/lib/*/pkgconfig/arrow-gpu-glib.pc\n-usr/share/gir-1.0/ArrowGPU-1.0.gir\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-gpu-glib12.install b/dev/tasks/linux-packages/debian/libarrow-gpu-glib12.install\ndeleted file mode 100644\nindex 4d97e5a60e..0000000000\n--- a/dev/tasks/linux-packages/debian/libarrow-gpu-glib12.install\n+++ /dev/null\n@@ -1 +0,0 @@\n-usr/lib/*/libarrow-gpu-glib.so.*\ndiff --git a/dev/tasks/linux-packages/debian/libarrow-gpu12.install b/dev/tasks/linux-packages/debian/libarrow-gpu12.install\ndeleted file mode 100644\nindex cabd7e47d1..0000000000\n--- a/dev/tasks/linux-packages/debian/libarrow-gpu12.install\n+++ /dev/null\n@@ -1 +0,0 @@\n-usr/lib/*/libarrow_gpu.so.*\ndiff --git a/dev/tasks/linux-packages/debian/rules b/dev/tasks/linux-packages/debian/rules\nindex 8cc9fe2b73..f3cc2a045c 100755\n--- a/dev/tasks/linux-packages/debian/rules\n+++ b/dev/tasks/linux-packages/debian/rules\n@@ -34,7 +34,7 @@ override_dh_auto_configure:\n \t  -DARROW_PROTOBUF_USE_SHARED=ON \\\n \t  -DPythonInterp_FIND_VERSION=ON \\\n \t  -DPythonInterp_FIND_VERSION_MAJOR=3 \\\n-\t  -DARROW_GPU=ON\n+\t  -DARROW_CUDA=ON\n \tdh_auto_configure \\\n \t  --sourcedirectory=c_glib \\\n \t  --builddirectory=c_glib_build \\\ndiff --git a/dev/tasks/tasks.yml b/dev/tasks/tasks.yml\nindex d5d362a0b1..bd49616f6b 100644\n--- a/dev/tasks/tasks.yml\n+++ b/dev/tasks/tasks.yml\n@@ -293,7 +293,7 @@ tasks:\n       - apache-arrow_{no_rc_version}-1.dsc\n       - apache-arrow_{no_rc_version}.orig.tar.gz\n       - gir1.2-arrow-1.0_{no_rc_version}-1_amd64.deb\n-      - gir1.2-arrow-gpu-1.0_{no_rc_version}-1_amd64.deb\n+      - gir1.2-arrow-cuda-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-parquet-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-plasma-1.0_{no_rc_version}-1_amd64.deb\n       - libarrow-dev_{no_rc_version}-1_amd64.deb\n@@ -301,12 +301,12 @@ tasks:\n       - libarrow-glib-doc_{no_rc_version}-1_all.deb\n       - libarrow-glib12-dbgsym_{no_rc_version}-1_amd64.deb\n       - libarrow-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib12-dbgsym_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu12-dbgsym_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib12-dbgsym_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda12-dbgsym_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda12_{no_rc_version}-1_amd64.deb\n       - libarrow-python-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-python12-dbgsym_{no_rc_version}-1_amd64.deb\n       - libarrow-python12_{no_rc_version}-1_amd64.deb\n@@ -375,17 +375,17 @@ tasks:\n       - apache-arrow_{no_rc_version}-1.dsc\n       - apache-arrow_{no_rc_version}.orig.tar.gz\n       - gir1.2-arrow-1.0_{no_rc_version}-1_amd64.deb\n-      - gir1.2-arrow-gpu-1.0_{no_rc_version}-1_amd64.deb\n+      - gir1.2-arrow-cuda-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-parquet-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-plasma-1.0_{no_rc_version}-1_amd64.deb\n       - libarrow-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-glib-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-glib-doc_{no_rc_version}-1_all.deb\n       - libarrow-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda12_{no_rc_version}-1_amd64.deb\n       - libarrow-python-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-python12_{no_rc_version}-1_amd64.deb\n       - libarrow12_{no_rc_version}-1_amd64.deb\n@@ -415,17 +415,17 @@ tasks:\n       - apache-arrow_{no_rc_version}-1.dsc\n       - apache-arrow_{no_rc_version}.orig.tar.gz\n       - gir1.2-arrow-1.0_{no_rc_version}-1_amd64.deb\n-      - gir1.2-arrow-gpu-1.0_{no_rc_version}-1_amd64.deb\n+      - gir1.2-arrow-cuda-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-parquet-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-plasma-1.0_{no_rc_version}-1_amd64.deb\n       - libarrow-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-glib-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-glib-doc_{no_rc_version}-1_all.deb\n       - libarrow-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda12_{no_rc_version}-1_amd64.deb\n       - libarrow-python-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-python12_{no_rc_version}-1_amd64.deb\n       - libarrow12_{no_rc_version}-1_amd64.deb\n@@ -455,17 +455,17 @@ tasks:\n       - apache-arrow_{no_rc_version}-1.dsc\n       - apache-arrow_{no_rc_version}.orig.tar.gz\n       - gir1.2-arrow-1.0_{no_rc_version}-1_amd64.deb\n-      - gir1.2-arrow-gpu-1.0_{no_rc_version}-1_amd64.deb\n+      - gir1.2-arrow-cuda-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-parquet-1.0_{no_rc_version}-1_amd64.deb\n       - gir1.2-plasma-1.0_{no_rc_version}-1_amd64.deb\n       - libarrow-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-glib-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-glib-doc_{no_rc_version}-1_all.deb\n       - libarrow-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib-dev_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu-glib12_{no_rc_version}-1_amd64.deb\n-      - libarrow-gpu12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib-dev_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda-glib12_{no_rc_version}-1_amd64.deb\n+      - libarrow-cuda12_{no_rc_version}-1_amd64.deb\n       - libarrow-python-dev_{no_rc_version}-1_amd64.deb\n       - libarrow-python12_{no_rc_version}-1_amd64.deb\n       - libarrow12_{no_rc_version}-1_amd64.deb\ndiff --git a/python/CMakeLists.txt b/python/CMakeLists.txt\nindex 15a3479f63..1a874542c8 100644\n--- a/python/CMakeLists.txt\n+++ b/python/CMakeLists.txt\n@@ -17,9 +17,6 @@\n #\n # Includes code assembled from BSD/MIT/Apache-licensed code from some 3rd-party\n # projects, including Kudu, Impala, and libdynd. See python/LICENSE.txt\n-#\n-# TODO(ARROW-3209): rename arrow_gpu to arrow_cuda\n-#\n \n cmake_minimum_required(VERSION 2.7)\n project(pyarrow)\n@@ -393,13 +390,13 @@ if (PYARROW_BUILD_CUDA)\n       endif()\n     endif()\n     if (MSVC)\n-      ADD_THIRDPARTY_LIB(arrow_gpu\n+      ADD_THIRDPARTY_LIB(arrow_cuda\n         SHARED_LIB ${ARROW_CUDA_SHARED_IMP_LIB})\n     else()\n-      ADD_THIRDPARTY_LIB(arrow_gpu\n+      ADD_THIRDPARTY_LIB(arrow_cuda\n         SHARED_LIB ${ARROW_CUDA_SHARED_LIB})\n     endif()\n-    set(LINK_LIBS ${LINK_LIBS} arrow_gpu_shared)\n+    set(LINK_LIBS ${LINK_LIBS} arrow_cuda_shared)\n     set(CYTHON_EXTENSIONS ${CYTHON_EXTENSIONS} _cuda)\n   endif()\n endif()\ndiff --git a/python/pyarrow/includes/libarrow_cuda.pxd b/python/pyarrow/includes/libarrow_cuda.pxd\nindex 0e0d5e1ce0..cedc43263e 100644\n--- a/python/pyarrow/includes/libarrow_cuda.pxd\n+++ b/python/pyarrow/includes/libarrow_cuda.pxd\n@@ -19,9 +19,9 @@\n \n from pyarrow.includes.libarrow cimport *\n \n-cdef extern from \"arrow/gpu/cuda_api.h\" namespace \"arrow::gpu\" nogil:\n+cdef extern from \"arrow/gpu/cuda_api.h\" namespace \"arrow::cuda\" nogil:\n \n-    cdef cppclass CCudaDeviceManager\" arrow::gpu::CudaDeviceManager\":\n+    cdef cppclass CCudaDeviceManager\" arrow::cuda::CudaDeviceManager\":\n         @staticmethod\n         CStatus GetInstance(CCudaDeviceManager** manager)\n         CStatus GetContext(int gpu_number, shared_ptr[CCudaContext]* ctx)\n@@ -33,7 +33,7 @@ cdef extern from \"arrow/gpu/cuda_api.h\" namespace \"arrow::gpu\" nogil:\n         # CStatus FreeHost(void* data, int64_t nbytes)\n         int num_devices() const\n \n-    cdef cppclass CCudaContext\" arrow::gpu::CudaContext\":\n+    cdef cppclass CCudaContext\" arrow::cuda::CudaContext\":\n         shared_ptr[CCudaContext]  shared_from_this()\n         # CStatus Close()\n         CStatus Allocate(int64_t nbytes, shared_ptr[CCudaBuffer]* out)\n@@ -47,13 +47,13 @@ cdef extern from \"arrow/gpu/cuda_api.h\" namespace \"arrow::gpu\" nogil:\n         const void* handle() const\n         int device_number() const\n \n-    cdef cppclass CCudaIpcMemHandle\" arrow::gpu::CudaIpcMemHandle\":\n+    cdef cppclass CCudaIpcMemHandle\" arrow::cuda::CudaIpcMemHandle\":\n         @staticmethod\n         CStatus FromBuffer(const void* opaque_handle,\n                            shared_ptr[CCudaIpcMemHandle]* handle)\n         CStatus Serialize(CMemoryPool* pool, shared_ptr[CBuffer]* out) const\n \n-    cdef cppclass CCudaBuffer\" arrow::gpu::CudaBuffer\"(CBuffer):\n+    cdef cppclass CCudaBuffer\" arrow::cuda::CudaBuffer\"(CBuffer):\n         CCudaBuffer(uint8_t* data, int64_t size,\n                     const shared_ptr[CCudaContext]& context,\n                     c_bool own_data=false, c_bool is_ipc=false)\n@@ -73,17 +73,18 @@ cdef extern from \"arrow/gpu/cuda_api.h\" namespace \"arrow::gpu\" nogil:\n         CStatus ExportForIpc(shared_ptr[CCudaIpcMemHandle]* handle)\n         shared_ptr[CCudaContext] context() const\n \n-    cdef cppclass CCudaHostBuffer\" arrow::gpu::CudaHostBuffer\"(CMutableBuffer):\n+    cdef cppclass \\\n+            CCudaHostBuffer\" arrow::cuda::CudaHostBuffer\"(CMutableBuffer):\n         pass\n \n     cdef cppclass \\\n-            CCudaBufferReader\" arrow::gpu::CudaBufferReader\"(CBufferReader):\n+            CCudaBufferReader\" arrow::cuda::CudaBufferReader\"(CBufferReader):\n         CCudaBufferReader(const shared_ptr[CBuffer]& buffer)\n         CStatus Read(int64_t nbytes, int64_t* bytes_read, void* buffer)\n         CStatus Read(int64_t nbytes, shared_ptr[CBuffer]* out)\n \n     cdef cppclass \\\n-            CCudaBufferWriter\" arrow::gpu::CudaBufferWriter\"(WritableFile):\n+            CCudaBufferWriter\" arrow::cuda::CudaBufferWriter\"(WritableFile):\n         CCudaBufferWriter(const shared_ptr[CCudaBuffer]& buffer)\n         CStatus Close()\n         CStatus Flush()\n@@ -98,17 +99,17 @@ cdef extern from \"arrow/gpu/cuda_api.h\" namespace \"arrow::gpu\" nogil:\n     CStatus AllocateCudaHostBuffer(int device_number, const int64_t size,\n                                    shared_ptr[CCudaHostBuffer]* out)\n \n-    # Cuda prefix is added to avoid picking up arrow::gpu functions\n+    # Cuda prefix is added to avoid picking up arrow::cuda functions\n     # from arrow namespace.\n-    CStatus CudaSerializeRecordBatch\" arrow::gpu::SerializeRecordBatch\"\\\n+    CStatus CudaSerializeRecordBatch\" arrow::cuda::SerializeRecordBatch\"\\\n         (const CRecordBatch& batch,\n          CCudaContext* ctx,\n          shared_ptr[CCudaBuffer]* out)\n-    CStatus CudaReadMessage\" arrow::gpu::ReadMessage\"\\\n+    CStatus CudaReadMessage\" arrow::cuda::ReadMessage\"\\\n         (CCudaBufferReader* reader,\n          CMemoryPool* pool,\n          unique_ptr[CMessage]* message)\n-    CStatus CudaReadRecordBatch\" arrow::gpu::ReadRecordBatch\"\\\n+    CStatus CudaReadRecordBatch\" arrow::cuda::ReadRecordBatch\"\\\n         (const shared_ptr[CSchema]& schema,\n          const shared_ptr[CCudaBuffer]& buffer,\n          CMemoryPool* pool, shared_ptr[CRecordBatch]* out)\ndiff --git a/ruby/README.md b/ruby/README.md\nindex aac714e537..42486588cf 100644\n--- a/ruby/README.md\n+++ b/ruby/README.md\n@@ -23,4 +23,12 @@ There are the official Ruby bindings for Apache Arrow.\n \n [Red Arrow](https://github.com/apache/arrow/tree/master/ruby/red-arrow) is the base Apache Arrow bindings.\n \n-[Red Arrow GPU](https://github.com/apache/arrow/tree/master/ruby/red-arrow-gpu) is the Apache Arrow bindings of GPU part.\n+[Red Arrow CUDA](https://github.com/apache/arrow/tree/master/ruby/red-arrow-cuda) is the Apache Arrow bindings of CUDA part.\n+\n+[Red Gandiva](https://github.com/apache/arrow/tree/master/ruby/red-gandiva) is the Gandiva bindings.\n+\n+[Red Plasma](https://github.com/apache/arrow/tree/master/ruby/red-plasma) is the Plasma bindings.\n+\n+[Red Parquet](https://github.com/apache/arrow/tree/master/ruby/red-parquet) is the Parquet bindings.\n+\n+\ndiff --git a/ruby/red-arrow-gpu/.gitignore b/ruby/red-arrow-cuda/.gitignore\nsimilarity index 96%\nrename from ruby/red-arrow-gpu/.gitignore\nrename to ruby/red-arrow-cuda/.gitignore\nindex 161ac05535..3ec5511596 100644\n--- a/ruby/red-arrow-gpu/.gitignore\n+++ b/ruby/red-arrow-cuda/.gitignore\n@@ -15,6 +15,6 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-/lib/arrow-gpu/version.rb\n+/lib/arrow-cuda/version.rb\n \n /pkg/\ndiff --git a/ruby/red-arrow-gpu/Gemfile b/ruby/red-arrow-cuda/Gemfile\nsimilarity index 100%\nrename from ruby/red-arrow-gpu/Gemfile\nrename to ruby/red-arrow-cuda/Gemfile\ndiff --git a/ruby/red-arrow-gpu/LICENSE.txt b/ruby/red-arrow-cuda/LICENSE.txt\nsimilarity index 100%\nrename from ruby/red-arrow-gpu/LICENSE.txt\nrename to ruby/red-arrow-cuda/LICENSE.txt\ndiff --git a/ruby/red-arrow-gpu/NOTICE.txt b/ruby/red-arrow-cuda/NOTICE.txt\nsimilarity index 100%\nrename from ruby/red-arrow-gpu/NOTICE.txt\nrename to ruby/red-arrow-cuda/NOTICE.txt\ndiff --git a/ruby/red-arrow-cuda/README.md b/ruby/red-arrow-cuda/README.md\nnew file mode 100644\nindex 0000000000..76fa51c9b1\n--- /dev/null\n+++ b/ruby/red-arrow-cuda/README.md\n@@ -0,0 +1,62 @@\n+<!---\n+  Licensed to the Apache Software Foundation (ASF) under one\n+  or more contributor license agreements.  See the NOTICE file\n+  distributed with this work for additional information\n+  regarding copyright ownership.  The ASF licenses this file\n+  to you under the Apache License, Version 2.0 (the\n+  \"License\"); you may not use this file except in compliance\n+  with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+  Unless required by applicable law or agreed to in writing,\n+  software distributed under the License is distributed on an\n+  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+  KIND, either express or implied.  See the License for the\n+  specific language governing permissions and limitations\n+  under the License.\n+-->\n+\n+# Red Arrow CUDA - Apache Arrow CUDA Ruby\n+\n+Red Arrow CUDA is the Ruby bindings of Apache Arrow CUDA. Red Arrow CUDA is based on GObject Introspection.\n+\n+[Apache Arrow CUDA](https://arrow.apache.org/) is an in-memory columnar data store on GPU.\n+\n+[GObject Introspection](https://wiki.gnome.org/action/show/Projects/GObjectIntrospection) is a middleware for language bindings of C library. GObject Introspection can generate language bindings automatically at runtime.\n+\n+Red Arrow CUDA uses [Apache Arrow CUDA GLib](https://github.com/apache/arrow/tree/master/c_glib) and [gobject-introspection gem](https://rubygems.org/gems/gobject-introspection) to generate Ruby bindings of Apache Arrow CUDA.\n+\n+Apache Arrow CUDA GLib is a C wrapper for [Apache Arrow CUDA C++](https://github.com/apache/arrow/tree/master/cpp). GObject Introspection can't use Apache Arrow CUDA C++ directly. Apache Arrow CUDA GLib is a bridge between Apache Arrow CUDA C++ and GObject Introspection.\n+\n+gobject-introspection gem is a Ruby bindings of GObject Introspection. Red Arrow CUDA uses GObject Introspection via gobject-introspection gem.\n+\n+## Install\n+\n+Install Apache Arrow CUDA GLib before install Red Arrow CUDA. Use [packages.red-data-tools.org](https://github.com/red-data-tools/packages.red-data-tools.org) for installing Apache Arrow CUDA GLib.\n+\n+Note that the Apache Arrow CUDA GLib packages are \"unofficial\". \"Official\" packages will be released in the future.\n+\n+Install Red Arrow CUDA after you install Apache Arrow CUDA GLib:\n+\n+```text\n+% gem install red-arrow-cuda\n+```\n+\n+## Usage\n+\n+```ruby\n+require \"arrow-cuda\"\n+\n+manager = ArrowCUDA::DeviceManager.new\n+if manager.n_devices.zero?\n+  raise \"No GPU is found\"\n+end\n+\n+context = manager[0]\n+buffer = ArrowCUDA::Buffer.new(context, 128)\n+ArrowCUDA::BufferOutputStream.open(buffer) do |stream|\n+  stream.write(\"Hello World\")\n+end\n+puts buffer.copy_to_host(0, 11) # => \"Hello World\"\n+```\ndiff --git a/ruby/red-arrow-gpu/Rakefile b/ruby/red-arrow-cuda/Rakefile\nsimilarity index 100%\nrename from ruby/red-arrow-gpu/Rakefile\nrename to ruby/red-arrow-cuda/Rakefile\ndiff --git a/ruby/red-arrow-gpu/dependency-check/Rakefile b/ruby/red-arrow-cuda/dependency-check/Rakefile\nsimilarity index 88%\nrename from ruby/red-arrow-gpu/dependency-check/Rakefile\nrename to ruby/red-arrow-cuda/dependency-check/Rakefile\nindex 0c2284811d..c057a1df2c 100644\n--- a/ruby/red-arrow-gpu/dependency-check/Rakefile\n+++ b/ruby/red-arrow-cuda/dependency-check/Rakefile\n@@ -33,9 +33,9 @@ end\n namespace :dependency do\n   desc \"Check dependency\"\n   task :check do\n-    unless PKGConfig.check_version?(\"arrow-gpu-glib\")\n-      unless NativePackageInstaller.install(:debian => \"libarrow-gpu-glib-dev\",\n-                                            :redhat => \"arrow-gpu-glib-devel\")\n+    unless PKGConfig.check_version?(\"arrow-cuda-glib\")\n+      unless NativePackageInstaller.install(:debian => \"libarrow-cuda-glib-dev\",\n+                                            :redhat => \"arrow-cuda-glib-devel\")\n         exit(false)\n       end\n     end\ndiff --git a/ruby/red-arrow-gpu/lib/arrow-gpu.rb b/ruby/red-arrow-cuda/lib/arrow-cuda.rb\nsimilarity index 92%\nrename from ruby/red-arrow-gpu/lib/arrow-gpu.rb\nrename to ruby/red-arrow-cuda/lib/arrow-cuda.rb\nindex 10fdcc3c6c..1fc13d0a05 100644\n--- a/ruby/red-arrow-gpu/lib/arrow-gpu.rb\n+++ b/ruby/red-arrow-cuda/lib/arrow-cuda.rb\n@@ -17,11 +17,11 @@\n \n require \"arrow\"\n \n-require \"arrow-gpu/version\"\n+require \"arrow-cuda/version\"\n \n-require \"arrow-gpu/loader\"\n+require \"arrow-cuda/loader\"\n \n-module ArrowGPU\n+module ArrowCUDA\n   class Error < StandardError\n   end\n \ndiff --git a/ruby/red-arrow-gpu/lib/arrow-gpu/cuda-device-manager.rb b/ruby/red-arrow-cuda/lib/arrow-cuda/device-manager.rb\nsimilarity index 95%\nrename from ruby/red-arrow-gpu/lib/arrow-gpu/cuda-device-manager.rb\nrename to ruby/red-arrow-cuda/lib/arrow-cuda/device-manager.rb\nindex 163128b208..bbef749721 100644\n--- a/ruby/red-arrow-gpu/lib/arrow-gpu/cuda-device-manager.rb\n+++ b/ruby/red-arrow-cuda/lib/arrow-cuda/device-manager.rb\n@@ -15,8 +15,8 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-module ArrowGPU\n-  class CUDADeviceManager\n+module ArrowCUDA\n+  class DeviceManager\n     # Experimental.\n     #\n     # Can we think device manager is a container of contexts?\ndiff --git a/ruby/red-arrow-gpu/lib/arrow-gpu/loader.rb b/ruby/red-arrow-cuda/lib/arrow-cuda/loader.rb\nsimilarity index 91%\nrename from ruby/red-arrow-gpu/lib/arrow-gpu/loader.rb\nrename to ruby/red-arrow-cuda/lib/arrow-cuda/loader.rb\nindex b9dc57cc81..6b2afc4040 100644\n--- a/ruby/red-arrow-gpu/lib/arrow-gpu/loader.rb\n+++ b/ruby/red-arrow-cuda/lib/arrow-cuda/loader.rb\n@@ -15,11 +15,11 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-module ArrowGPU\n+module ArrowCUDA\n   class Loader < GObjectIntrospection::Loader\n     class << self\n       def load\n-        super(\"ArrowGPU\", ArrowGPU)\n+        super(\"ArrowCUDA\", ArrowCUDA)\n       end\n     end\n \n@@ -29,7 +29,7 @@ def post_load(repository, namespace)\n     end\n \n     def require_libraries\n-      require \"arrow-gpu/cuda-device-manager\"\n+      require \"arrow-cuda/device-manager\"\n     end\n   end\n end\ndiff --git a/ruby/red-arrow-gpu/red-arrow-gpu.gemspec b/ruby/red-arrow-cuda/red-arrow-cuda.gemspec\nsimilarity index 84%\nrename from ruby/red-arrow-gpu/red-arrow-gpu.gemspec\nrename to ruby/red-arrow-cuda/red-arrow-cuda.gemspec\nindex 340d41e8f7..b2ee982945 100644\n--- a/ruby/red-arrow-gpu/red-arrow-gpu.gemspec\n+++ b/ruby/red-arrow-cuda/red-arrow-cuda.gemspec\n@@ -20,11 +20,11 @@\n require_relative \"version\"\n \n Gem::Specification.new do |spec|\n-  spec.name = \"red-arrow-gpu\"\n+  spec.name = \"red-arrow-cuda\"\n   version_components = [\n-    ArrowGPU::Version::MAJOR.to_s,\n-    ArrowGPU::Version::MINOR.to_s,\n-    ArrowGPU::Version::MICRO.to_s,\n+    ArrowCUDA::Version::MAJOR.to_s,\n+    ArrowCUDA::Version::MINOR.to_s,\n+    ArrowCUDA::Version::MICRO.to_s,\n     # \"beta1\",\n   ]\n   spec.version = version_components.join(\".\")\n@@ -32,9 +32,9 @@ Gem::Specification.new do |spec|\n   spec.authors = [\"Apache Arrow Developers\"]\n   spec.email = [\"dev@arrow.apache.org\"]\n \n-  spec.summary = \"Red Arrow GPU is the Ruby bindings of Apache Arrow GPU\"\n+  spec.summary = \"Red Arrow CUDA is the Ruby bindings of Apache Arrow CUDA\"\n   spec.description =\n-    \"Apache Arrow GPU is a common in-memory columnar data store on GPU. \" +\n+    \"Apache Arrow CUDA is a common in-memory columnar data store on CUDA. \" +\n     \"It's useful to share and process large data.\"\n   spec.license = \"Apache-2.0\"\n   spec.files = [\"README.md\", \"Rakefile\", \"Gemfile\", \"#{spec.name}.gemspec\"]\ndiff --git a/ruby/red-arrow-gpu/test/helper.rb b/ruby/red-arrow-cuda/test/helper.rb\nsimilarity index 97%\nrename from ruby/red-arrow-gpu/test/helper.rb\nrename to ruby/red-arrow-cuda/test/helper.rb\nindex 772636ab3c..4d01833267 100644\n--- a/ruby/red-arrow-gpu/test/helper.rb\n+++ b/ruby/red-arrow-cuda/test/helper.rb\n@@ -18,6 +18,6 @@\n require_relative \"../../red-arrow/version\"\n require_relative \"../version\"\n \n-require \"arrow-gpu\"\n+require \"arrow-cuda\"\n \n require \"test-unit\"\ndiff --git a/ruby/red-arrow-gpu/test/run-test.rb b/ruby/red-arrow-cuda/test/run-test.rb\nsimilarity index 100%\nrename from ruby/red-arrow-gpu/test/run-test.rb\nrename to ruby/red-arrow-cuda/test/run-test.rb\ndiff --git a/ruby/red-arrow-gpu/test/test-cuda.rb b/ruby/red-arrow-cuda/test/test-cuda.rb\nsimilarity index 87%\nrename from ruby/red-arrow-gpu/test/test-cuda.rb\nrename to ruby/red-arrow-cuda/test/test-cuda.rb\nindex 05fd6cc155..a48b687d36 100644\n--- a/ruby/red-arrow-gpu/test/test-cuda.rb\n+++ b/ruby/red-arrow-cuda/test/test-cuda.rb\n@@ -17,7 +17,7 @@\n \n class TestCUDA < Test::Unit::TestCase\n   def setup\n-    @manager = ArrowGPU::CUDADeviceManager.new\n+    @manager = ArrowCUDA::DeviceManager.new\n     omit(\"At least one GPU is required\") if @manager.n_devices.zero?\n     @context = @manager[0]\n   end\n@@ -25,11 +25,11 @@ def setup\n   sub_test_case(\"BufferOutputStream\") do\n     def setup\n       super\n-      @buffer = ArrowGPU::CUDABuffer.new(@context, 128)\n+      @buffer = ArrowCUDA::Buffer.new(@context, 128)\n     end\n \n     def test_new\n-      ArrowGPU::CUDABufferOutputStream.open(@buffer) do |stream|\n+      ArrowCUDA::BufferOutputStream.open(@buffer) do |stream|\n         stream.write(\"Hello World\")\n       end\n       assert_equal(\"Hello World\", @buffer.copy_to_host(0, 11).to_s)\ndiff --git a/ruby/red-arrow-gpu/version.rb b/ruby/red-arrow-cuda/version.rb\nsimilarity index 94%\nrename from ruby/red-arrow-gpu/version.rb\nrename to ruby/red-arrow-cuda/version.rb\nindex fc0d37e6ba..c8bbbc7165 100644\n--- a/ruby/red-arrow-gpu/version.rb\n+++ b/ruby/red-arrow-cuda/version.rb\n@@ -20,7 +20,7 @@\n version_rb_path = Pathname.new(__FILE__)\n base_dir = version_rb_path.dirname\n pom_xml_path = base_dir.join(\"..\", \"..\", \"java\", \"pom.xml\")\n-lib_version_rb_path = base_dir.join(\"lib\", \"arrow-gpu\", \"version.rb\")\n+lib_version_rb_path = base_dir.join(\"lib\", \"arrow-cuda\", \"version.rb\")\n \n need_update = false\n if not lib_version_rb_path.exist?\n@@ -53,7 +53,7 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-module ArrowGPU\n+module ArrowCUDA\n   module Version\n     MAJOR = #{major}\n     MINOR = #{minor}\n@@ -68,4 +68,4 @@ module Version\n   end\n end\n \n-require_relative \"lib/arrow-gpu/version\"\n+require_relative \"lib/arrow-cuda/version\"\ndiff --git a/ruby/red-arrow-gpu/README.md b/ruby/red-arrow-gpu/README.md\ndeleted file mode 100644\nindex ad76c13011..0000000000\n--- a/ruby/red-arrow-gpu/README.md\n+++ /dev/null\n@@ -1,62 +0,0 @@\n-<!---\n-  Licensed to the Apache Software Foundation (ASF) under one\n-  or more contributor license agreements.  See the NOTICE file\n-  distributed with this work for additional information\n-  regarding copyright ownership.  The ASF licenses this file\n-  to you under the Apache License, Version 2.0 (the\n-  \"License\"); you may not use this file except in compliance\n-  with the License.  You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-  Unless required by applicable law or agreed to in writing,\n-  software distributed under the License is distributed on an\n-  \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-  KIND, either express or implied.  See the License for the\n-  specific language governing permissions and limitations\n-  under the License.\n--->\n-\n-# Red Arrow GPU - Apache Arrow GPU Ruby\n-\n-Red Arrow GPU is the Ruby bindings of Apache Arrow GPU. Red Arrow GPU is based on GObject Introspection.\n-\n-[Apache Arrow GPU](https://arrow.apache.org/) is an in-memory columnar data store on GPU.\n-\n-[GObject Introspection](https://wiki.gnome.org/action/show/Projects/GObjectIntrospection) is a middleware for language bindings of C library. GObject Introspection can generate language bindings automatically at runtime.\n-\n-Red Arrow GPU uses [Apache Arrow GPU GLib](https://github.com/apache/arrow/tree/master/c_glib) and [gobject-introspection gem](https://rubygems.org/gems/gobject-introspection) to generate Ruby bindings of Apache Arrow GPU.\n-\n-Apache Arrow GPU GLib is a C wrapper for [Apache Arrow GPU C++](https://github.com/apache/arrow/tree/master/cpp). GObject Introspection can't use Apache Arrow GPU C++ directly. Apache Arrow GPU GLib is a bridge between Apache Arrow GPU C++ and GObject Introspection.\n-\n-gobject-introspection gem is a Ruby bindings of GObject Introspection. Red Arrow GPU uses GObject Introspection via gobject-introspection gem.\n-\n-## Install\n-\n-Install Apache Arrow GPU GLib before install Red Arrow GPU. Use [packages.red-data-tools.org](https://github.com/red-data-tools/packages.red-data-tools.org) for installing Apache Arrow GPU GLib.\n-\n-Note that the Apache Arrow GPU GLib packages are \"unofficial\". \"Official\" packages will be released in the future.\n-\n-Install Red Arrow GPU after you install Apache Arrow GPU GLib:\n-\n-```text\n-% gem install red-arrow-gpu\n-```\n-\n-## Usage\n-\n-```ruby\n-require \"arrow-gpu\"\n-\n-manager = ArrowGPU::CUDADeviceManager.new\n-if manager.n_devices.zero?\n-  raise \"No GPU is found\"\n-end\n-\n-context = manager[0]\n-buffer = ArrowGPU::CUDABuffer.new(context, 128)\n-ArrowGPU::CUDABufferOutputStream.open(buffer) do |stream|\n-  stream.write(\"Hello World\")\n-end\n-puts buffer.copy_to_host(0, 11) # => \"Hello World\"\n-```\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-06T03:26:42.866+0000",
                    "updated": "2018-12-06T03:26:42.866+0000",
                    "started": "2018-12-06T03:26:42.865+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "172565",
                    "issueId": "13184141"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 8400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@7d425219[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@206abba2[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2719e638[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@525beed2[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@97d27[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@6dfdbb46[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5bdb8e7[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@81debfc[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@43365f9d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@4391fb36[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2b031923[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@4c2655b4[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 8400,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Dec 06 03:26:37 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-12-06T03:26:37.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3209/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2018-09-10T19:19:15.000+0000",
        "updated": "2018-12-06T03:26:42.000+0000",
        "timeoriginalestimate": null,
        "description": "I'm proposing to rename this library since we could conceivably have OpenCL bindings in the repository also",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "2h 20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 8400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Rename libarrow_gpu to libarrow_cuda",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/comment/16609695",
                    "id": "16609695",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Yes, I think that's a good idea.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2018-09-10T19:21:06.839+0000",
                    "updated": "2018-09-10T19:21:06.839+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/comment/16624062",
                    "id": "16624062",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I'm pushing this off to 0.12 since we aren't packaging this yet, and the change will require some work on updating the Linux package names",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-09-21T19:18:23.817+0000",
                    "updated": "2018-09-21T19:18:23.817+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/comment/16708890",
                    "id": "16708890",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "body": "Should we also rename the \"arrow/gpu\" directory and the {{arrow::gpu}} namespace?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
                        "name": "apitrou",
                        "key": "pitrou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
                        },
                        "displayName": "Antoine Pitrou",
                        "active": true,
                        "timeZone": "Europe/Paris"
                    },
                    "created": "2018-12-04T15:42:00.130+0000",
                    "updated": "2018-12-04T15:42:00.130+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/comment/16708897",
                    "id": "16708897",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "We should change the namespace; I'm not sure that changing the directory name is necessary as long as it's clear what files inside are cuda-related",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-12-04T15:43:26.484+0000",
                    "updated": "2018-12-04T15:43:26.484+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13184141/comment/16710935",
                    "id": "16710935",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kou",
                        "name": "kou",
                        "key": "kou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=kou&avatarId=30762",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kou&avatarId=30762",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kou&avatarId=30762",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kou&avatarId=30762"
                        },
                        "displayName": "Kouhei Sutou",
                        "active": true,
                        "timeZone": "Asia/Tokyo"
                    },
                    "body": "Issue resolved by pull request 3088\n[https://github.com/apache/arrow/pull/3088]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=kou",
                        "name": "kou",
                        "key": "kou",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=kou&avatarId=30762",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=kou&avatarId=30762",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=kou&avatarId=30762",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=kou&avatarId=30762"
                        },
                        "displayName": "Kouhei Sutou",
                        "active": true,
                        "timeZone": "Asia/Tokyo"
                    },
                    "created": "2018-12-06T03:26:37.929+0000",
                    "updated": "2018-12-06T03:26:37.929+0000"
                }
            ],
            "maxResults": 5,
            "total": 5,
            "startAt": 0
        },
        "customfield_12311820": "0|i3xxgf:",
        "customfield_12314139": null
    }
}