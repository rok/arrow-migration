{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13129964",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964",
    "key": "ARROW-1983",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12344925",
                "id": "12344925",
                "description": "",
                "name": "0.14.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-07-04"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "beginner",
            "parquet",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12541372",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12541372",
                "type": {
                    "id": "10032",
                    "name": "Blocker",
                    "inward": "is blocked by",
                    "outward": "blocks",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10032"
                },
                "outwardIssue": {
                    "id": "13170568",
                    "key": "ARROW-2801",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13170568",
                    "fields": {
                        "summary": "[Python][C++][Dataset] Implement split_row_groups for ParquetDataset",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
                            "name": "Minor",
                            "id": "4"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            },
            {
                "id": "12618808",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12618808",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13388023",
                    "key": "ARROW-13269",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13388023",
                    "fields": {
                        "summary": "[C++] [Dataset] Improve the _metadata example to show how to properly create _metadata if there is a partitioning",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12560902",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12560902",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13233778",
                    "key": "ARROW-5349",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13233778",
                    "fields": {
                        "summary": "[Python/C++] Provide a way to specify the file path in parquet ColumnChunkMetaData",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12560192",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12560192",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13231605",
                    "key": "ARROW-5258",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13231605",
                    "fields": {
                        "summary": "[C++/Python] Expose file metadata of dataset pieces to caller",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=rjzamora",
            "name": "rjzamora",
            "key": "rjzamora",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
            },
            "displayName": "Rick Zamora",
            "active": true,
            "timeZone": "America/Chicago"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jim.crist",
            "name": "jim.crist",
            "key": "jim.crist",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jim.crist&avatarId=33449",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jim.crist&avatarId=33449",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jim.crist&avatarId=33449",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jim.crist&avatarId=33449"
            },
            "displayName": "Jim Crist",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jim.crist",
            "name": "jim.crist",
            "key": "jim.crist",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=jim.crist&avatarId=33449",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=jim.crist&avatarId=33449",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=jim.crist&avatarId=33449",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=jim.crist&avatarId=33449"
            },
            "displayName": "Jim Crist",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 34200,
            "total": 34200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 34200,
            "total": 34200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1983/votes",
            "votes": 2,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 58,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/229366",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on pull request #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166\n \n \n   This PR adds another sink to parquet writers for collecting metadata of datasets.\r\n   \r\n   - [ ] Implement reader for a metadata file of a dataset\r\n   - [ ] Implement tests\r\n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-17T21:01:24.643+0000",
                    "updated": "2019-04-17T21:01:24.643+0000",
                    "started": "2019-04-17T21:01:24.642+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "229366",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/229552",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-484337217\n \n \n   I'm away until 4/22 but will look more closely at this then. \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-18T02:57:09.396+0000",
                    "updated": "2019-04-18T02:57:09.396+0000",
                    "started": "2019-04-18T02:57:09.396+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "229552",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/232923",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486707752\n \n \n   I think that the introduced boilerplate code is required because the dataset is created from a Python process which means that the in-progress _metadata file must be pasted through the python-arrow-parquet pipeline. It is possible that when the dataset is created from parquet-cpp level, less boilerplate code would be required.\r\n   \r\n   Could you also give a feedback on how the FileMetaData of dataset pieces is gathered into a single _metadata file? See the comment in https://github.com/apache/arrow/pull/4166/files#diff-efaecc290ac5f03c99886c3a94790d0dR266. \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T14:55:17.505+0000",
                    "updated": "2019-04-25T14:55:17.505+0000",
                    "started": "2019-04-25T14:55:17.505+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "232923",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/232924",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486709620\n \n \n   Right, I think the approach would be to add a method to `ParquetWriter` in `_parquet.pyx` that appends that file's metadata to an in-progress _metadata file.\r\n   \r\n   Where is the _metadata file format (with concatenated metadata like this) documented, or is it a convention of Hive and/or Spark? \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T14:59:29.176+0000",
                    "updated": "2019-04-25T14:59:29.176+0000",
                    "started": "2019-04-25T14:59:29.176+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "232924",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/232932",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486716104\n \n \n   Re concatenated metadata file format documentation: there is none to my knowledge (which may be limited on this matter).\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T15:13:40.075+0000",
                    "updated": "2019-04-25T15:13:40.075+0000",
                    "started": "2019-04-25T15:13:40.074+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "232932",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/232935",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "hatemhelal commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486717373\n \n \n   > Where is the _metadata file format (with concatenated metadata like this) documented, or is it a convention of Hive and/or Spark?\r\n   \r\n   I tried finding a document for this and eventually found my way to [ParquetFileWriter.java](https://github.com/apache/parquet-mr/blob/master/parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java#L933) which are marked as deprecated.  \r\n   \r\n   It would be helpful to know more about the background for that decision but I haven't been able to glean much from the git logs or the related JIRAs.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T15:16:52.426+0000",
                    "updated": "2019-04-25T15:16:52.426+0000",
                    "started": "2019-04-25T15:16:52.426+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "232935",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/232948",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "martindurant commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486726764\n \n \n   Commenting here, as on JIRA my comment seems to have been swallowed (please forgive if they pop back out again later)\r\n   \r\n   I don't know about deprecated, and I wouldn't hold my breath over a Parquet 2.0... the metadata file is very useful in the context of Dask, so that we can know what files exist in the dataset without doing a glob, and we can do simple filtering on max/min values without having to touch every file, which can be very slow on remote storage.\r\n   \r\n   The spec certainly allows for a metadata file even if it could be seen as more of a convention from Hive: a column chunk allows for a file_path attribute, indicating that the data itself is in another file (which, actually, doesn't need to be a proper parquet file, but in practice always is).\r\n   \r\n   You could indeed construct the metadata by repeatedly appending to a file, since you will know that everything in the file is the thrift footer block except for the PAR1 bytes. However, you will not preserve row-group order in general, which might be important, and writes had better be atomic. Furthermore, remote storage will usually *not allow* small appends from multiple processes in this way.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T15:40:53.961+0000",
                    "updated": "2019-04-25T15:40:53.961+0000",
                    "started": "2019-04-25T15:40:53.960+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "232948",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233029",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486789137\n \n \n   > Furthermore, remote storage will usually _not allow_ small appends from multiple processes in this way.\r\n   \r\n   The \"multiple processes\" part must be something that Dask does and is not directly relevant to Arrow that always writes a dataset from a single process. Do you have recommendations what the Arrow dataset creation interface should be? One approach would be that when datasets from multiple processes are written (say, by Arrow `write_to_dataset`) then at the end one would collect and merge the _metadata files (from different processes) to one?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T18:34:28.530+0000",
                    "updated": "2019-04-25T18:34:28.530+0000",
                    "started": "2019-04-25T18:34:28.530+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233029",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233032",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486791748\n \n \n   The deprecation notes to ParquetFileWriter.java were introduces in https://github.com/apache/parquet-mr/pull/429 . It's not clear to me what is are the alternatives to having metadata files.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T18:41:58.080+0000",
                    "updated": "2019-04-25T18:41:58.080+0000",
                    "started": "2019-04-25T18:41:58.079+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233032",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233033",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486791748\n \n \n   The deprecation notes to ParquetFileWriter.java were introduces in https://github.com/apache/parquet-mr/pull/429 . It's not clear to me what are the alternatives to not having metadata files.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T18:42:26.697+0000",
                    "updated": "2019-04-25T18:42:26.697+0000",
                    "started": "2019-04-25T18:42:26.696+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233033",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233037",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "martindurant commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486797974\n \n \n   I imagine just having the write-a-partition (i.e., dataframe or table to file) also return the piece object, and then a separate function that takes a set of piece objects and creates a metadata file from them. An arrow function can do the two steps in one, or Dask can collect the output pieces, depending on how this is called. The only wrinkle is, that the output piece objects will need to have the paths within them set to be relative to the root directory of the dataset.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-25T19:00:19.069+0000",
                    "updated": "2019-04-25T19:00:19.069+0000",
                    "started": "2019-04-25T19:00:19.069+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233037",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233218",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "mrocklin commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-486889081\n \n \n   To echo what @martindurant is saying, we definitely don't want a function that appends a bit of metadata to a metadata file.  We want to be able to get the metadata from a row group and pass that around as data.  We'd like to move all of those pieces of metadata to one process and then have that one process combine them and write the metadata file in one shot.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T01:05:26.566+0000",
                    "updated": "2019-04-26T01:05:26.566+0000",
                    "started": "2019-04-26T01:05:26.566+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233218",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233552",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487073132\n \n \n   Not sure how to proceed from here. Do you want me to take over this project?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T14:17:02.756+0000",
                    "updated": "2019-04-26T14:17:02.756+0000",
                    "started": "2019-04-26T14:17:02.755+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233552",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233556",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "mrocklin commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487075921\n \n \n   > Not sure how to proceed from here. Do you want me to take over this project?\r\n   \r\n   I'm not sure if that's directed to me.  If so, I have no preferences on who does this work (as long as it isn't me :) )\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T14:24:42.028+0000",
                    "updated": "2019-04-26T14:24:42.028+0000",
                    "started": "2019-04-26T14:24:42.028+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233556",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233600",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487102044\n \n \n   `FileMetaData` is already serializable: https://github.com/apache/arrow/blob/master/python/pyarrow/_parquet.pyx#L378. We could add a C++ function that takes a collection of `FileMetaData` and concatenates them to produce the `_metadata` file (this would save you from having to do this munging logic in Dask).\r\n   \r\n   One minor issue I see currently is that the `file_path` attribute in `ColumnChunk` is not being set. We'll have to add a method on `parquet::ParquetFileWriter` to add a path (since the file path is not part of any constructor) so that this field gets populated when the metadata is being built. \r\n   \r\n   I think I understand what is required so if @pearu can let me know what he wants to do we can go from there\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T15:37:03.427+0000",
                    "updated": "2019-04-26T15:37:03.427+0000",
                    "started": "2019-04-26T15:37:03.427+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233600",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233740",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487196076\n \n \n   I would be happy to finish this task but need some guidance to ensure that the implementation follows Arrows principles and be usable by Dask.\r\n   \r\n   When writing a table to parquet file (Python `write_table` function), I don't see how one can collect the `FileMetaData` instances as the FileMetaData instance is created in `FileSerializer::Close` as local variable and `Close` is called in the destructor. There is one way but that might be suboptimal: read the `FileMetaData` from the footer of the dataset piece.\r\n   @wesm , have you thought about where or how the collection of `FileMetaData` should be created?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T20:46:26.983+0000",
                    "updated": "2019-04-26T20:46:26.983+0000",
                    "started": "2019-04-26T20:46:26.982+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233740",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233741",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487196076\n \n \n   I would be happy to finish this task but need some guidance to ensure that the implementation follows Arrows principles and is usable by Dask.\r\n   \r\n   When writing a table to parquet file (Python `write_table` function), I don't see how one can collect the `FileMetaData` instances as the FileMetaData instance is created in `FileSerializer::Close` as local variable and `Close` is called in the destructor. There is one way but that might be suboptimal: read the `FileMetaData` from the footer of the dataset piece.\r\n   @wesm , have you thought about where or how the collection of `FileMetaData` should be created?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T20:46:53.324+0000",
                    "updated": "2019-04-26T20:46:53.324+0000",
                    "started": "2019-04-26T20:46:53.323+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233741",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233742",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "martindurant commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487196585\n \n \n   Reading back from the file certainly seems suboptimal, and with remote storage maybe not possible (because they may not promise immediate consistency)\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T20:48:17.371+0000",
                    "updated": "2019-04-26T20:48:17.371+0000",
                    "started": "2019-04-26T20:48:17.371+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233742",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233815",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487229423\n \n \n   @pearu I haven't looked closely yet but I would suggest an idempotent `Finalize` method and storing the finalized metadata in the writer object\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-26T23:18:54.615+0000",
                    "updated": "2019-04-26T23:18:54.615+0000",
                    "started": "2019-04-26T23:18:54.614+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233815",
                    "issueId": "13129964"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/worklog/233962",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pearu commented on issue #4166: ARROW-1983: [C++/Python][WIP] Implement metadata writing support\nURL: https://github.com/apache/arrow/pull/4166#issuecomment-487272782\n \n \n   https://github.com/apache/arrow/compare/master...Quansight:pearu/arrow-1983-2 introduces `ParquetFileWriter::metadata` that finalizes and returns file metadata instance (as `shared_ptr`).\r\n   \r\n   To get a hang of the file metadata after writing the table, I would introduce a new method (or alter the current method with the third argument)\r\n   ```\r\n   ::arrow::Status FileWriter::WriteTable(const ::arrow::Table& table,\r\n                                          int64_t chunk_size,\r\n                                          std::unique_ptr<FileMetaData>* file_metadata);\r\n   ```\r\n   \r\n   In Python, `ParquetWriter.write_table` would return the file metadata instance (or set the `ParquetWriter.metadata` attribute after writing).\r\n   \r\n   @wesm , does the above sound a reasonable approach?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2019-04-27T10:02:20.764+0000",
                    "updated": "2019-04-27T10:02:20.764+0000",
                    "started": "2019-04-27T10:02:20.763+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "233962",
                    "issueId": "13129964"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 34200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@7085021[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@40fcba22[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@792de34d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@5c256be0[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4b570743[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@7e2e37f4[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@680f84f7[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@1f02987d[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6c9ce9c1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@6302f231[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@773efa9a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@7cf45570[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 34200,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Jun 06 21:38:32 UTC 2019",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2019-06-06T21:38:32.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1983/watchers",
            "watchCount": 10,
            "isWatching": false
        },
        "created": "2018-01-10T20:48:14.000+0000",
        "updated": "2021-07-08T07:07:04.000+0000",
        "timeoriginalestimate": null,
        "description": "Currently {{pyarrow.parquet}} can only write the {{_common_metadata}} file (mostly just schema information). It would be useful to add the ability to write a {{_metadata}} file as well. This should include information about each row group in the dataset, including summary statistics. Having this summary file would allow filtering of row groups without needing to access each file beforehand.\r\n\r\nThis would require that the user is able to get the written RowGroups out of a {{pyarrow.parquet.write_table}} call and then give these objects as a list to new function that then passes them on as C++ objects to {{parquet-cpp}} that generates the respective {{_metadata}} file.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "9.5h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 34200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Add ability to write parquet `_metadata` file",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16540231",
                    "id": "16540231",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rgruener",
                        "name": "rgruener",
                        "key": "rgruener",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robbie Gruener",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "This looks like it\u00a0would\u00a0need changes in parquet-cpp as the [arrow writer only takes a Schema|https://github.com/apache/parquet-cpp/blob/master/src/parquet/arrow/writer.h#L116]\u00a0and not the FileMetaData object which contains the row group information.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rgruener",
                        "name": "rgruener",
                        "key": "rgruener",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robbie Gruener",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-07-11T15:16:36.851+0000",
                    "updated": "2018-07-11T15:16:36.851+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16541803",
                    "id": "16541803",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rgruener",
                        "name": "rgruener",
                        "key": "rgruener",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robbie Gruener",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "[~xhochy] I made this dependent task\u00a0PARQUET-1348",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rgruener",
                        "name": "rgruener",
                        "key": "rgruener",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Robbie Gruener",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-07-12T15:16:11.714+0000",
                    "updated": "2018-07-12T15:16:11.714+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16633762",
                    "id": "16633762",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "More work is needed here it seems. Moving to 0.12",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-10-01T09:27:22.799+0000",
                    "updated": "2018-10-01T09:27:22.799+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16687186",
                    "id": "16687186",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "If I understand correctly, we need to combine all of the row group metadata for all files in a directory. When a new file is written, does this file have to be updated?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-11-14T22:00:32.556+0000",
                    "updated": "2018-11-14T22:00:32.556+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16730844",
                    "id": "16730844",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "> If I understand correctly, we need to combine all of the row group metadata for all files in a directory.\r\n\r\nYes.\u00a0 Ideally when writing a row group we would get some metadata object in memory. We would then collect all of those objects and hand them to some `write_metadata` function afterwards.\r\n\r\n> When a new file is written, does this file have to be updated?\r\n\u00a0\r\nYes, or it can be removed/invalidated.\r\n\u00a0\r\nAs a side note, this is probably one of a small number of issues that stop Dask Dataframe from using PyArrow by default.\u00a0 Metadata files with full row group information are especially valuable for us, particularly with remote/cloud storage.  (I'm going through Dask's parquet handling now)",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-12-29T22:45:07.606+0000",
                    "updated": "2018-12-29T22:45:07.606+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16731464",
                    "id": "16731464",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Mechanically this isn't a huge change. On the C++ side we would expose an API to append row group metadata into a common file. This can be used from the Python side, then. I'm planning to move more of the multifile dataset handling into C++ because we also need it in Ruby and R, so would make sense to maintain one implementation for the 3 languages",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-12-31T22:12:45.628+0000",
                    "updated": "2018-12-31T22:12:45.628+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16731467",
                    "id": "16731467",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": ">  I'm planning to move more of the multifile dataset handling into C++ because we also need it in Ruby and R, so would make sense to maintain one implementation for the 3 languages\r\n\r\nMakes sense to me.  No pressure, but is there a time in particular when you're planning to do this?  This will help me with planning on the Dask side.  I'm also happy to help with things on the Python Arrow side near term if they come up.  \r\n\r\nFor context see https://github.com/dask/dask/pull/4336#issuecomment-450686100",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2018-12-31T22:23:03.446+0000",
                    "updated": "2018-12-31T22:23:03.446+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16731472",
                    "id": "16731472",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Velocity on these things should pick up in 2019 since the Ursa Labs team is growing. The \"Arrow Dataset\" project extends beyond Parquet (where Parquet is one storage format). Ideally this work will happen in Q1 2019. Handling the \"_metadata\" file is lower hanging fruit so that can likely get done a lot sooner",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-12-31T22:46:52.863+0000",
                    "updated": "2018-12-31T22:46:52.863+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16751500",
                    "id": "16751500",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "In https://github.com/dask/dask/issues/4410 we learn that metadata information can grow to be large in the case where there are many columns and many partitions.  There is some value to ensuring that the metadata results are somewhat compact in memory, though I also wouldn't spend a ton of effort optimizing here.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2019-01-24T20:10:26.721+0000",
                    "updated": "2019-01-24T20:10:26.721+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16782163",
                    "id": "16782163",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Hi all, thought I would check in here.  I'll likely start planning work around Dask Parquet reader/writer functionality soon, and am curious is there is any timeline on this issue.  \"Nope\" is a totally fine answer, just looking for information for planning purposes. ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2019-03-01T22:22:21.283+0000",
                    "updated": "2019-03-01T22:22:21.283+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16787367",
                    "id": "16787367",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "No timeline. I'm not sure who is going to do the work; I will not be able to in time for 0.13",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-03-08T00:34:33.127+0000",
                    "updated": "2019-03-08T00:34:33.127+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16792681",
                    "id": "16792681",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "This will have to get done for 0.14. We're basically out of time for 0.13 and only fixing bugs now",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-03-14T14:01:24.749+0000",
                    "updated": "2019-03-14T14:01:24.749+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16817308",
                    "id": "16817308",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "body": "Currently,\u00a0ParquetDataset metadata has the following approximate data structure (type-specs are shown only for the relevant attributes):\r\n{noformat}\r\nParquetDataset:\r\n  list<ParquetDatasetPiece> pieces\r\n  list<str> paths\r\n  fs\r\n  common_metadata, common_metadata_path\r\n  metadata, metadata_path\r\n\r\nParquetDatasetPiece:\r\n  sting path\r\n  get_metadata() -> FileMetaData\r\n  partition_keys\r\n\r\nFileMetaData:\r\n  list<RowGroupMetaData> row_groups\r\n  ParquetSchema schema\r\n  dict metadata = {b\u2018pandas\u2019: <pandas metadata in bytes>}\r\n  int num_rows, num_columns\r\n  str format_version, created_by\r\n\r\nRowGroupMetaData:\r\n  list<ColumnChunkMetaData> columns\r\n  int num_rows, total_byte_size\r\n\r\nColumnChunkMetaData:\r\n  str physical_type, encodings, path_in_schema, compression\r\n  int num_values, total_uncompressed_size, total_compressed_size, data_page_offset, index_page_offset, dictionary_page_offset\r\n  RowGroupStatistics statistics\r\n\r\nRowGroupStatistics:\r\n  bool has_min_max\r\n  int min, max, null_count, distinct_count, num_values\r\n  str physical_type{noformat}\r\nIf only the data in RowGroupStatistics is relevant for this issue (please confirm), then the statistics data could be collected into a single Parquet file, say `_statistics`, containing the following columns:\r\n{noformat}\r\n<Piece.path>, <RowGroup index>, <ColumnChunk index>, <RowGroupStatistics data>{noformat}\r\n[~mrocklin], would the information in `_statistics` sufficient for Dask needs?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "created": "2019-04-14T13:52:07.598+0000",
                    "updated": "2019-04-14T13:52:07.598+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16818319",
                    "id": "16818319",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "My understanding is that there is already a standard around using a \"_metadata\" file that presumably is expected to have certain data laid out in a certain way.  It may be that [~mdurant] can provide a nice reference to the expectations.\r\n\r\nIt also looks like PyArrow has a nice reader for this information.  If I open up a Parquet Dataset that has a `_metadata` file I find that my object has all of the right information, so that might also be a good place to look.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mrocklin",
                        "name": "mrocklin",
                        "key": "mrocklin",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Matthew Rocklin",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2019-04-15T19:32:06.303+0000",
                    "updated": "2019-04-15T19:32:06.303+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16818334",
                    "id": "16818334",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "body": "A convention, yes, but not in the parquet standard as such. I believe spark might have started this, although they producing them is now optional. You typically have `_metadata`, containing schema, references to all the row-groups and information about them such as column statistics, and `_common_metadata`, which contains only the schema (and is therefore much smaller).",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "created": "2019-04-15T19:47:38.860+0000",
                    "updated": "2019-04-15T19:47:38.860+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16818343",
                    "id": "16818343",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "body": "Note that the Parquet format has three different metadata structures, see [https://github.com/apache/parquet-format#metadata]\u00a0.\r\n\r\nThe \"_metadata\" corresponds to `FileMetaData.key_value_metadata` (in parquet-format specification) + schema while the \"statistics\" (that is of interest of Dask, if I understand it correctly) corresponds to `ColumnMetadata.key_value_metadata`.\r\n Yes, Arrow can read all this information and more. My basic questions are:\r\n # What information needs to be collected? Note that some information is internal to parquet files that one would never need, hence it would just a waste of space to collect it, especially when the Datasets become huge (as would be expected in Dask applications).\r\n # Where this information should be gathered for easy and efficient access?\r\n\r\n\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "created": "2019-04-15T20:02:48.373+0000",
                    "updated": "2019-04-15T20:06:44.613+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16818370",
                    "id": "16818370",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "body": "> Note that the Parquet format has three different metadata structures\r\n\r\nNo, this is incorrect, unfortunately the term \"metadata\" is used with multiple meanings here. \r\n\r\n- All parquet files contain FileMetaData in the file footer, which may include one or more key-value pairs, and includes other important things like the schema\r\n- If the file contains any row-groups or references to row-groups in other files, it will also contain ColumnMetaData (and possible more key-value pairs); this is all *within* the FileMetaData structure\r\n- the special file `_metadata` may exist, which contains *only* FileMetaData, and any row-groups have only links to other files and no data within the file.\r\n- the special file `_common_metadata` may exist, which also only contains a FileMetaData structure, but has no row group components at all. \r\n- ordinary data files should have the same common metadata (schema, key-values), so you can load any one of them, but they contain only the row-groups of that one file and no links to any others.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "created": "2019-04-15T20:40:34.854+0000",
                    "updated": "2019-04-15T20:40:51.114+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16820084",
                    "id": "16820084",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "body": "There seems to be two options to write a separate metadata file from Arrow:\r\n # Following Wes comment \"On the C++ side we would expose an API to append row group metadata into a common file.\", introduce the second sink argument to\u00a0ParquetFileWriter::Open that will be used for collecting FileMetaData content during the writing. [~wesmckinn], can you confirm that this would be the right approach?\r\n # Introduce a flag to\u00a0ParquetFileWriter that when enabled will cause skipping all data writes and would write only FileMetaData content. As a result, one would need to call the dataset write twice, one for writing data (and metadata) as currently, and the second time for writing metadata-only (writes would be collected to a single file).\r\n\r\nComparing the two approaches, the approach 2 is simpler but suboptimal as the writing process is executed twice. In both cases, the metadata would have duplicated storage (in data files as currently, and in the separate metadata file). If readers would be able to use metadata from a separate file (not sure if parquet format would allow it), duplicating metadata storage in both approaches could be avoided.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "created": "2019-04-17T13:26:42.432+0000",
                    "updated": "2019-04-17T13:26:42.432+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16820090",
                    "id": "16820090",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "body": "> If readers would be able to use metadata from a separate file (not sure if parquet format would allow it), duplicating metadata storage in both approaches could be avoided.\r\n\r\nYes, this is exactly what should happen: the metadata file contains all of the metadata (with paths pointing to the actual data files) and the data files contain the metadata with only their own row-groups specified. Each row group def appears thus in two places, and the schema is repeated many times. This duplication is desirable to allow viewing the data as a complete set, or each file independently.\r\n\r\nIf reading via the separate metadata file, the reader does not need to touch the footers of the data files at all, since it already has everything it needs.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "created": "2019-04-17T13:32:30.358+0000",
                    "updated": "2019-04-17T13:32:30.358+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16820504",
                    "id": "16820504",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "body": "Arrow [PR 4166|https://github.com/apache/arrow/pull/4166]\u00a0implements the approach 1 above.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "created": "2019-04-17T21:06:50.321+0000",
                    "updated": "2019-04-17T21:06:50.321+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16823112",
                    "id": "16823112",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I'm just returning from vacation and catching up on e-mail etc., this effort is a priority for me so I will review the discussion and PR and give feedback as soon as I can",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-04-22T13:45:58.367+0000",
                    "updated": "2019-04-22T13:45:58.367+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16826171",
                    "id": "16826171",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "body": "I don't know about \"deprecated\" (or whether a Parquet 2.0 is really a thing), but...\r\nIt is definitely useful for the Dask case of wanting to know what files exist and the max/mins for basic filtering, without having to touch all the files before makign that decision.\r\n\r\nThe metadata file was indeed taken on by Hive, and could be seen as a convention, but it is certainly allowed by the spec since the column_chunk structure allows for a path, and so for a row-group to have its data in another file. You can indeed just append to a file as you go, since in the case that there is no actual data, you know exactly how much space is taken up before the start of the thrift block (4 bytes: PAR1). However, the writes must be atomic, and will in general *not work* for remote storage, where small appends don't happen as you might assume.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "created": "2019-04-25T15:34:01.882+0000",
                    "updated": "2019-04-25T15:34:01.882+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16826178",
                    "id": "16826178",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "body": "I don't know about deprecated, and I wouldn't hold my breath over a Parquet 2.0... the metadata file is very useful in the context of Dask, so that we can know what files exist in the dataset without doing a glob, and we can do simple filtering on max/min values without having to touch every file, which can be very slow on remote storage.\r\n\r\nThe spec certainly allows for a metadata file even if it could be seen as more of a convention from Hive: a column chunk allows for a file_path attribute, indicating that the data itself is in another file (which, actually, doesn't need to be a proper parquet file, but in practice always is).\r\n\r\nYou could indeed construct the metadata by repeatedly appending to a file, since you will know that everything in the file is the thrift footer block except for the PAR1 bytes. However, you will not preserve row-group order in general, which might be important, and writes had better be atomic. Furthermore, remote storage will usually *not allow* small appends from multiple processes in this way.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "created": "2019-04-25T15:38:51.305+0000",
                    "updated": "2019-04-25T15:38:51.305+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16826179",
                    "id": "16826179",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "body": "I don't know about deprecated, and I wouldn't hold my breath over a Parquet 2.0... the metadata file is very useful in the context of Dask, so that we can know what files exist in the dataset without doing a glob, and we can do simple filtering on max/min values without having to touch every file, which can be very slow on remote storage.\r\n\r\nThe spec certainly allows for a metadata file even if it could be seen as more of a convention from Hive: a column chunk allows for a file_path attribute, indicating that the data itself is in another file (which, actually, doesn't need to be a proper parquet file, but in practice always is).\r\n\r\nYou could indeed construct the metadata by repeatedly appending to a file, since you will know that everything in the file is the thrift footer block except for the PAR1 bytes. However, you will not preserve row-group order in general, which might be important, and writes had better be atomic. Furthermore, remote storage will usually *not allow* small appends from multiple processes in this way.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=mdurant",
                        "name": "mdurant",
                        "key": "mdurant",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Martin Durant",
                        "active": true,
                        "timeZone": "America/Montreal"
                    },
                    "created": "2019-04-25T15:39:48.315+0000",
                    "updated": "2019-04-25T15:39:48.315+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16831195",
                    "id": "16831195",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "body": "Arrow [PR 4236|https://github.com/apache/arrow/pull/4236]\u00a0implements another approach for collecting the file metadata instances of dataset pieces: `write_to_dataset` can take a `metadata_collector` kw argument that list value will be filled with the file metadata instances.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "created": "2019-05-01T19:12:34.000+0000",
                    "updated": "2019-05-01T19:12:34.000+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16833140",
                    "id": "16833140",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "body": "ARROW-5258 provides a way to collect file metadata objects created by write_to_dataset function.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "created": "2019-05-04T18:50:56.972+0000",
                    "updated": "2019-05-04T18:50:56.972+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16833141",
                    "id": "16833141",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "body": "For this issue, questions raised in https://github.com/apache/arrow/pull/4236#issuecomment-489017226 needs to be addressed.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=pearu",
                        "name": "pearu",
                        "key": "pearu",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pearu&avatarId=35984",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pearu&avatarId=35984",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pearu&avatarId=35984",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pearu&avatarId=35984"
                        },
                        "displayName": "Pearu Peterson",
                        "active": true,
                        "timeZone": "Europe/Tallinn"
                    },
                    "created": "2019-05-04T18:53:06.527+0000",
                    "updated": "2019-05-04T18:53:06.527+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16841417",
                    "id": "16841417",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "Copying the questions that [~pearu] mentioned above / asked on github here:\r\n\r\n{quote}2. After collecting all file metadata of dataset pieces (possibly from different dask processes), what would be desired the interface for writing and reading the dataset metadata instances? Here's an initial proposal for Python:\r\n\r\n{code:python}\r\ndef write_dataset_metadata(metadata_list, where):\r\n    ...\r\n\r\ndef read_dataset_metadata(where, memory_map=False):\r\n    ...\r\n    return metadata_list\r\n{code}\r\n\r\n3. Clearly, each file metadata instance in `metadata_list` contains same information as in all metadata instances. Would it make sense and use to introduce a new `DatasetMetadata` class (in C++, also exposed to Python) that would collect the metadata information of dataset pieces in a more compact way as well as would provide I/O methods? (This also addresses the question 2.){quote}\r\n\r\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2019-05-16T14:33:33.167+0000",
                    "updated": "2019-05-16T14:33:33.167+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16841424",
                    "id": "16841424",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "> what would be desired the interface for writing and reading the dataset metadata instances?\r\n\r\nFor reading, I think the existing {{parquet.read_metadata}} is sufficient? (that already works with such metadata files generated by other libraries).\r\n\r\nFor writing, the current {{parquet.write_metadata}} expects a pyarrow schema, so for that we indeed need a new method, or adapt the existing one to also accept a parquet FileMetaData object.\r\n\r\n\u00a0\r\n\r\nBut for writing, I think the main part that is missing is a way to combined the list of metadata objects into a single FileMetaData object?\r\n\r\n\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2019-05-16T14:38:44.894+0000",
                    "updated": "2019-05-16T14:38:44.894+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16841625",
                    "id": "16841625",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Right. This is a relatively straightforward C++ function to write \u2013 Pearu actually already had partially implemented it in one of the patch iterations. The API would be something like\r\n{code:java}\r\nStatus WriteMultipleMetadata(const std::vector<std::shared_ptr<FileMetaData>>& metadatas,\r\n                             arrow::io::OutputStream* out);\r\n{code}\r\nDoes someone want to write it (I mean, I can do it, but it would be good for other people to get some experience with the Parquet codebase)? We also need to make sure that the file path is being set in the metadata, otherwise the {{_metadata}} file is useless",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-05-16T18:30:47.097+0000",
                    "updated": "2019-05-16T18:30:47.097+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16841668",
                    "id": "16841668",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "> We also need to make sure that the file path is being set in the metadata, otherwise the {{_metadata}} file is useless\r\n\r\nIndeed, I opened ARROW-5349 for that earlier today. I assume this is separate from the {{WriteMultipleMetadata}} you mention above, as it is the user (eg Dask) who knows where the files that correspond to the different metadata objects are put?\r\n\r\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2019-05-16T19:28:29.249+0000",
                    "updated": "2019-05-16T19:28:29.249+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16849106",
                    "id": "16849106",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Probably the most flexible thing for writing would be a function that appends a metadata to an OutputStream\r\n\r\n{code:java}\r\nStatus AppendFileMetaData(const FileMetaData& metadata, arrow::io::OutputStream* out);\r\n{code}\r\n\r\nCorrespondingly, please also write a function that parses a multiple-metadata file like\r\n\r\n{code}\r\nStatus ParseMetaDataFile(arrow::io::InputStream* input, std::vector<std::shared_ptr<FileMetaData>>* out);\r\n{code}\r\n\r\nLastly, AFAIK we are not able to instantiate {{ParquetFileReader}} given previously-read {{FileMetaData}} -- probably can do that in a separate JIRA",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-05-27T17:47:31.694+0000",
                    "updated": "2019-05-27T17:47:31.694+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16849118",
                    "id": "16849118",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "{quote}Correspondingly, please also write a function that parses a multiple-metadata file like{quote}\r\n\r\nWe already have {{read_metadata}} (on the python side, it actually uses the normal parquet file reading), that does read such {{_metadata}} files. Are you still looking for something else?\r\n\r\nTo my understanding, it is not really a \"multiple-metadata file\", but a file with a single FileMetadata where the row groups of all metadata objects are combined.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2019-05-27T18:17:25.006+0000",
                    "updated": "2019-05-27T18:17:25.006+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16849176",
                    "id": "16849176",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "I see, that was not clear to me. So what we actually need is a {{FileMetaData::AppendRowGroups}} method (that merges one metadata into another), is that correct?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-05-27T20:09:48.173+0000",
                    "updated": "2019-05-27T20:09:48.173+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16849187",
                    "id": "16849187",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "I think so yes (at least when reading, it returns a single FileMetadata instance with all row groups).\r\n\r\nBesides the \"append\" operation, we also need a \"write\" method for such FileMetadata instance (I suppose this only needs some work on the python/cython side, since this is just writing a parquet file without actual data, although didn't check C++). There is currently a {{write_metadata}}, but that requires an _arrow_ schema, and not a _parquet_ schema. \r\nRegarding the public API, I suppose we can modify {{write_metadata}} to also accept a parquet schema, to not have to add an extra function. But it will need some more changes under the hood in {{ParquetWriter}} to be able to accept a given FileMetadata object instead of creating one based on the data it is writing.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2019-05-27T20:29:17.134+0000",
                    "updated": "2019-05-27T20:33:21.875+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16853378",
                    "id": "16853378",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rjzamora",
                        "name": "rjzamora",
                        "key": "rjzamora",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
                        },
                        "displayName": "Rick Zamora",
                        "active": true,
                        "timeZone": "America/Chicago"
                    },
                    "body": "I submitted a PR to perform the metadata aggregation and metadata-only file write ([https://github.com/apache/arrow/pull/4405]).\u00a0 I just syncronized with the master branch, so hopefully I can address any suggestions/concerns people have relatively quickly.\r\n\r\nAre there any additional features that\u00a0we need for \"utilizing\"\u00a0the metadata file within arrow.parque itself?\u00a0 I believe the existing read_metadata function should be sufficient for the needs of dask.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rjzamora",
                        "name": "rjzamora",
                        "key": "rjzamora",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
                        },
                        "displayName": "Rick Zamora",
                        "active": true,
                        "timeZone": "America/Chicago"
                    },
                    "created": "2019-05-31T19:55:30.613+0000",
                    "updated": "2019-05-31T19:55:30.613+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16853383",
                    "id": "16853383",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Well, one issue is how to use the _metadata file to read data from the files it lists within without having to parse those files' respective metadata again. I think this may require a little bit of refactoring in the Parquet C++ library",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-05-31T20:03:26.240+0000",
                    "updated": "2019-05-31T20:03:26.240+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16853430",
                    "id": "16853430",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rjzamora",
                        "name": "rjzamora",
                        "key": "rjzamora",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
                        },
                        "displayName": "Rick Zamora",
                        "active": true,
                        "timeZone": "America/Chicago"
                    },
                    "body": "Right, I see what you are saying.\u00a0 You can pass in a list of files to\u00a0pq.ParquetDataset\u00a0(obtained by calling\u00a0read_metadata on the metadata file), but the footer metadata will be unecessarily parsed a second time.\u00a0\u00a0\u00a0For dask, this is probably not much of an issue, because each worker will only be dealing with a subset of the global dataset. In many other cases\u00a0this is clearly undesireable.\r\n\r\n\u00a0",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=rjzamora",
                        "name": "rjzamora",
                        "key": "rjzamora",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
                        },
                        "displayName": "Rick Zamora",
                        "active": true,
                        "timeZone": "America/Chicago"
                    },
                    "created": "2019-05-31T21:14:05.757+0000",
                    "updated": "2019-05-31T21:14:05.757+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16853433",
                    "id": "16853433",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Yes. I don't think it is necessary to resolve all of this in a single patch, so we can open a follow-up JIRA to implement the optimization to read a row group given a _metadata file. There is some other complexity there such as how to open the filepath (you need a FileSystem handle -- see the filesystem API work that is in process)",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-05-31T21:28:04.566+0000",
                    "updated": "2019-05-31T21:28:22.668+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13129964/comment/16858116",
                    "id": "16858116",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 4405\n[https://github.com/apache/arrow/pull/4405]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2019-06-06T21:38:32.663+0000",
                    "updated": "2019-06-06T21:38:32.663+0000"
                }
            ],
            "maxResults": 40,
            "total": 40,
            "startAt": 0
        },
        "customfield_12311820": "0|i3orcf:",
        "customfield_12314139": null
    }
}