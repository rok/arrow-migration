{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13323345",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345",
    "key": "ARROW-9782",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12345977",
                "id": "12345977",
                "description": "",
                "name": "2.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2020-10-19"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "dataset",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333008",
                "id": "12333008",
                "name": "R"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
            "name": "jorisvandenbossche",
            "key": "jorisvandenbossche",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Joris Van den Bossche",
            "active": true,
            "timeZone": "Europe/Brussels"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
            "name": "jorisvandenbossche",
            "key": "jorisvandenbossche",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Joris Van den Bossche",
            "active": true,
            "timeZone": "Europe/Brussels"
        },
        "aggregateprogress": {
            "progress": 28200,
            "total": 28200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 28200,
            "total": 28200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-9782/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 47,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/492680",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz opened a new pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305\n\n\n   Haven't fixed the R binding yet\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-29T21:15:19.100+0000",
                    "updated": "2020-09-29T21:15:19.100+0000",
                    "started": "2020-09-29T21:15:19.099+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492680",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/492683",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#issuecomment-700999150\n\n\n   https://issues.apache.org/jira/browse/ARROW-9782\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-29T21:24:17.752+0000",
                    "updated": "2020-09-29T21:24:17.752+0000",
                    "started": "2020-09-29T21:24:17.752+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492683",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/492938",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#issuecomment-701374837\n\n\n   @bkietz this removes the ability to specify format specific options? (or it's still WIP?)\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-30T13:00:31.894+0000",
                    "updated": "2020-09-30T13:00:31.894+0000",
                    "started": "2020-09-30T13:00:31.894+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492938",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/492951",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#issuecomment-701383490\n\n\n   @jorisvandenbossche yes, not ready for review yet. I will repair format specific write options as part of this PR\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-30T13:16:15.976+0000",
                    "updated": "2020-09-30T13:16:15.976+0000",
                    "started": "2020-09-30T13:16:15.975+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492951",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/492955",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#issuecomment-701387330\n\n\n   Okido, will wait a bit more then ;-)\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-09-30T13:23:07.845+0000",
                    "updated": "2020-09-30T13:23:07.845+0000",
                    "started": "2020-09-30T13:23:07.845+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "492955",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/493919",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r498758123\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n+    RETURN_NOT_OK(batches->ReadNext(&batch));\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n+\n+struct NextBasenameGenerator {\n+  static Result<NextBasenameGenerator> Make(const std::string& basename_template) {\n+    if (basename_template.find(fs::internal::kSep) != std::string::npos) {\n+      return Status::Invalid(\"basename_template contained '/'\");\n+    }\n+    size_t token_start = basename_template.find(token());\n+    if (token_start == std::string::npos) {\n+      return Status::Invalid(\"basename_template did not contain '{i}'\");\n+    }\n+    return NextBasenameGenerator{basename_template, 0, token_start,\n+                                 token_start + token().size()};\n+  }\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+  static const std::string& token() {\n+    static const std::string token = \"{i}\";\n+    return token;\n+  }\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+  const std::string& template_;\n+  size_t i_, token_start_, token_end_;\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+  std::string operator()() {\n+    return template_.substr(0, token_start_) + std::to_string(i_++) +\n+           template_.substr(token_end_);\n+  }\n+};\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+using MutexedWriter = util::Mutexed<std::shared_ptr<FileWriter>>;\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+struct WriterSet {\n+  WriterSet(NextBasenameGenerator next_basename,\n+            const FileSystemDatasetWriteOptions& write_options)\n+      : next_basename_(std::move(next_basename)),\n+        base_dir_(fs::internal::EnsureTrailingSlash(write_options.base_dir)),\n+        write_options_(write_options) {}\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  Result<std::shared_ptr<MutexedWriter>> Get(const Expression& partition_expression,\n+                                             const std::shared_ptr<Schema>& schema) {\n+    ARROW_ASSIGN_OR_RAISE(auto part_segments,\n+                          write_options_.partitioning->Format(partition_expression));\n+    std::string dir = base_dir_ + part_segments;\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n-    }\n-  }\n+    util::Mutex::Guard writer_lock;\n+\n+    auto set_lock = mutex_.Lock();\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto writer =\n\nReview comment:\n       I don't understand the logic here about dual locking (set_lock, writer_lock).\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n\nReview comment:\n       while-loop?\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n+    RETURN_NOT_OK(batches->ReadNext(&batch));\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n+\n+struct NextBasenameGenerator {\n+  static Result<NextBasenameGenerator> Make(const std::string& basename_template) {\n+    if (basename_template.find(fs::internal::kSep) != std::string::npos) {\n+      return Status::Invalid(\"basename_template contained '/'\");\n+    }\n+    size_t token_start = basename_template.find(token());\n+    if (token_start == std::string::npos) {\n+      return Status::Invalid(\"basename_template did not contain '{i}'\");\n+    }\n+    return NextBasenameGenerator{basename_template, 0, token_start,\n+                                 token_start + token().size()};\n+  }\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+  static const std::string& token() {\n+    static const std::string token = \"{i}\";\n+    return token;\n+  }\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+  const std::string& template_;\n+  size_t i_, token_start_, token_end_;\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+  std::string operator()() {\n+    return template_.substr(0, token_start_) + std::to_string(i_++) +\n+           template_.substr(token_end_);\n+  }\n+};\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+using MutexedWriter = util::Mutexed<std::shared_ptr<FileWriter>>;\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+struct WriterSet {\n+  WriterSet(NextBasenameGenerator next_basename,\n+            const FileSystemDatasetWriteOptions& write_options)\n+      : next_basename_(std::move(next_basename)),\n+        base_dir_(fs::internal::EnsureTrailingSlash(write_options.base_dir)),\n+        write_options_(write_options) {}\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  Result<std::shared_ptr<MutexedWriter>> Get(const Expression& partition_expression,\n+                                             const std::shared_ptr<Schema>& schema) {\n+    ARROW_ASSIGN_OR_RAISE(auto part_segments,\n+                          write_options_.partitioning->Format(partition_expression));\n+    std::string dir = base_dir_ + part_segments;\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n-    }\n-  }\n+    util::Mutex::Guard writer_lock;\n+\n+    auto set_lock = mutex_.Lock();\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto writer =\n+        internal::GetOrInsertGenerated(&dir_to_writer_, dir, [&](const std::string&) {\n+          auto writer = std::make_shared<MutexedWriter>();\n+          writer_lock = writer->Lock();\n+          return writer;\n+        })->second;\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    if (writer_lock) {\n+      // NB: next_basename_() must be invoked with the set_lock held\n+      auto path = fs::internal::ConcatAbstractPath(dir, next_basename_());\n+      set_lock.Unlock();\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+      RETURN_NOT_OK(write_options_.filesystem->CreateDir(dir));\n+\n+      ARROW_ASSIGN_OR_RAISE(auto destination,\n+                            write_options_.filesystem->OpenOutputStream(path));\n+\n+      ARROW_ASSIGN_OR_RAISE(**writer, write_options_.format()->MakeWriter(\n+                                          std::move(destination), schema,\n+                                          write_options_.file_write_options));\n+    }\n+\n+    return writer;\n   }\n \n-  return Status::OK();\n-}\n+  Status FinishAll(internal::TaskGroup* task_group) {\n+    for (const auto& dir_writer : dir_to_writer_) {\n+      task_group->Append([&] {\n+        std::shared_ptr<FileWriter> writer = **dir_writer.second;\n+        return writer->Finish();\n+      });\n+    }\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+    return Status::OK();\n+  }\n+\n+  // There should only be a single writer open for each partition directory at a time\n+  util::Mutex mutex_;\n+  std::unordered_map<std::string, std::shared_ptr<MutexedWriter>> dir_to_writer_;\n+  NextBasenameGenerator next_basename_;\n+  std::string base_dir_;\n+  const FileSystemDatasetWriteOptions& write_options_;\n+};\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  auto task_group = scanner->context()->TaskGroup();\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n-\n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n\nReview comment:\n       Since we know all fragments (and their expressions) already, can we avoid all the locking multi-threading in WriterSet (IIRC, you need them to create the writer once)? That would heavily simplify all of this.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-02T12:00:25.725+0000",
                    "updated": "2020-10-02T12:00:25.725+0000",
                    "started": "2020-10-02T12:00:25.725+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "493919",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/493946",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r498812732\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n+    RETURN_NOT_OK(batches->ReadNext(&batch));\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n+\n+struct NextBasenameGenerator {\n+  static Result<NextBasenameGenerator> Make(const std::string& basename_template) {\n+    if (basename_template.find(fs::internal::kSep) != std::string::npos) {\n+      return Status::Invalid(\"basename_template contained '/'\");\n+    }\n+    size_t token_start = basename_template.find(token());\n+    if (token_start == std::string::npos) {\n+      return Status::Invalid(\"basename_template did not contain '{i}'\");\n+    }\n+    return NextBasenameGenerator{basename_template, 0, token_start,\n+                                 token_start + token().size()};\n+  }\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+  static const std::string& token() {\n+    static const std::string token = \"{i}\";\n+    return token;\n+  }\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+  const std::string& template_;\n+  size_t i_, token_start_, token_end_;\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+  std::string operator()() {\n+    return template_.substr(0, token_start_) + std::to_string(i_++) +\n+           template_.substr(token_end_);\n+  }\n+};\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+using MutexedWriter = util::Mutexed<std::shared_ptr<FileWriter>>;\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+struct WriterSet {\n+  WriterSet(NextBasenameGenerator next_basename,\n+            const FileSystemDatasetWriteOptions& write_options)\n+      : next_basename_(std::move(next_basename)),\n+        base_dir_(fs::internal::EnsureTrailingSlash(write_options.base_dir)),\n+        write_options_(write_options) {}\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  Result<std::shared_ptr<MutexedWriter>> Get(const Expression& partition_expression,\n+                                             const std::shared_ptr<Schema>& schema) {\n+    ARROW_ASSIGN_OR_RAISE(auto part_segments,\n+                          write_options_.partitioning->Format(partition_expression));\n+    std::string dir = base_dir_ + part_segments;\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n-    }\n-  }\n+    util::Mutex::Guard writer_lock;\n+\n+    auto set_lock = mutex_.Lock();\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto writer =\n+        internal::GetOrInsertGenerated(&dir_to_writer_, dir, [&](const std::string&) {\n+          auto writer = std::make_shared<MutexedWriter>();\n+          writer_lock = writer->Lock();\n+          return writer;\n+        })->second;\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    if (writer_lock) {\n+      // NB: next_basename_() must be invoked with the set_lock held\n+      auto path = fs::internal::ConcatAbstractPath(dir, next_basename_());\n+      set_lock.Unlock();\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+      RETURN_NOT_OK(write_options_.filesystem->CreateDir(dir));\n+\n+      ARROW_ASSIGN_OR_RAISE(auto destination,\n+                            write_options_.filesystem->OpenOutputStream(path));\n+\n+      ARROW_ASSIGN_OR_RAISE(**writer, write_options_.format()->MakeWriter(\n+                                          std::move(destination), schema,\n+                                          write_options_.file_write_options));\n+    }\n+\n+    return writer;\n   }\n \n-  return Status::OK();\n-}\n+  Status FinishAll(internal::TaskGroup* task_group) {\n+    for (const auto& dir_writer : dir_to_writer_) {\n+      task_group->Append([&] {\n+        std::shared_ptr<FileWriter> writer = **dir_writer.second;\n+        return writer->Finish();\n+      });\n+    }\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+    return Status::OK();\n+  }\n+\n+  // There should only be a single writer open for each partition directory at a time\n+  util::Mutex mutex_;\n+  std::unordered_map<std::string, std::shared_ptr<MutexedWriter>> dir_to_writer_;\n+  NextBasenameGenerator next_basename_;\n+  std::string base_dir_;\n+  const FileSystemDatasetWriteOptions& write_options_;\n+};\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  auto task_group = scanner->context()->TaskGroup();\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n-\n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n\nReview comment:\n       In this context fragments are the object of writing rather than the target (so for example one might represent an in-memory table which is being copied to disk). Writers are *not* known ahead of time since they depend on the partitioning which depends on the set of unique values in a given column, which we discover only after running GroupBy on an input batch\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-02T13:14:05.413+0000",
                    "updated": "2020-10-02T13:14:05.413+0000",
                    "started": "2020-10-02T13:14:05.413+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "493946",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/493947",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r498813432\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n\nReview comment:\n       I personally prefer `for(;;)` to `while(true)` but if it'll be clearer then I'll rewrite it\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n+    RETURN_NOT_OK(batches->ReadNext(&batch));\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n+\n+struct NextBasenameGenerator {\n+  static Result<NextBasenameGenerator> Make(const std::string& basename_template) {\n+    if (basename_template.find(fs::internal::kSep) != std::string::npos) {\n+      return Status::Invalid(\"basename_template contained '/'\");\n+    }\n+    size_t token_start = basename_template.find(token());\n+    if (token_start == std::string::npos) {\n+      return Status::Invalid(\"basename_template did not contain '{i}'\");\n+    }\n+    return NextBasenameGenerator{basename_template, 0, token_start,\n+                                 token_start + token().size()};\n+  }\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+  static const std::string& token() {\n+    static const std::string token = \"{i}\";\n+    return token;\n+  }\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+  const std::string& template_;\n+  size_t i_, token_start_, token_end_;\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+  std::string operator()() {\n+    return template_.substr(0, token_start_) + std::to_string(i_++) +\n+           template_.substr(token_end_);\n+  }\n+};\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+using MutexedWriter = util::Mutexed<std::shared_ptr<FileWriter>>;\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+struct WriterSet {\n+  WriterSet(NextBasenameGenerator next_basename,\n+            const FileSystemDatasetWriteOptions& write_options)\n+      : next_basename_(std::move(next_basename)),\n+        base_dir_(fs::internal::EnsureTrailingSlash(write_options.base_dir)),\n+        write_options_(write_options) {}\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  Result<std::shared_ptr<MutexedWriter>> Get(const Expression& partition_expression,\n+                                             const std::shared_ptr<Schema>& schema) {\n+    ARROW_ASSIGN_OR_RAISE(auto part_segments,\n+                          write_options_.partitioning->Format(partition_expression));\n+    std::string dir = base_dir_ + part_segments;\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n-    }\n-  }\n+    util::Mutex::Guard writer_lock;\n+\n+    auto set_lock = mutex_.Lock();\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto writer =\n\nReview comment:\n       I'll add comments inline\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-02T13:15:32.699+0000",
                    "updated": "2020-10-02T13:15:32.699+0000",
                    "started": "2020-10-02T13:15:32.699+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "493947",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/493952",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r498818275\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n\nReview comment:\n       I have a preference for `while (true)` which is much more explicit. Just my 2 cents :-)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-02T13:23:54.250+0000",
                    "updated": "2020-10-02T13:23:54.250+0000",
                    "started": "2020-10-02T13:23:54.250+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "493952",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495343",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499628240\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +145,205 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  for (std::shared_ptr<RecordBatch> batch;;) {\n+    RETURN_NOT_OK(batches->ReadNext(&batch));\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n+\n+struct NextBasenameGenerator {\n+  static Result<NextBasenameGenerator> Make(const std::string& basename_template) {\n+    if (basename_template.find(fs::internal::kSep) != std::string::npos) {\n+      return Status::Invalid(\"basename_template contained '/'\");\n+    }\n+    size_t token_start = basename_template.find(token());\n+    if (token_start == std::string::npos) {\n+      return Status::Invalid(\"basename_template did not contain '{i}'\");\n+    }\n+    return NextBasenameGenerator{basename_template, 0, token_start,\n+                                 token_start + token().size()};\n+  }\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+  static const std::string& token() {\n+    static const std::string token = \"{i}\";\n+    return token;\n+  }\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+  const std::string& template_;\n+  size_t i_, token_start_, token_end_;\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+  std::string operator()() {\n+    return template_.substr(0, token_start_) + std::to_string(i_++) +\n+           template_.substr(token_end_);\n+  }\n+};\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+using MutexedWriter = util::Mutexed<std::shared_ptr<FileWriter>>;\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+struct WriterSet {\n+  WriterSet(NextBasenameGenerator next_basename,\n+            const FileSystemDatasetWriteOptions& write_options)\n+      : next_basename_(std::move(next_basename)),\n+        base_dir_(fs::internal::EnsureTrailingSlash(write_options.base_dir)),\n+        write_options_(write_options) {}\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  Result<std::shared_ptr<MutexedWriter>> Get(const Expression& partition_expression,\n+                                             const std::shared_ptr<Schema>& schema) {\n+    ARROW_ASSIGN_OR_RAISE(auto part_segments,\n+                          write_options_.partitioning->Format(partition_expression));\n+    std::string dir = base_dir_ + part_segments;\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n-    }\n-  }\n+    util::Mutex::Guard writer_lock;\n+\n+    auto set_lock = mutex_.Lock();\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto writer =\n+        internal::GetOrInsertGenerated(&dir_to_writer_, dir, [&](const std::string&) {\n+          auto writer = std::make_shared<MutexedWriter>();\n+          writer_lock = writer->Lock();\n+          return writer;\n+        })->second;\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    if (writer_lock) {\n+      // NB: next_basename_() must be invoked with the set_lock held\n+      auto path = fs::internal::ConcatAbstractPath(dir, next_basename_());\n+      set_lock.Unlock();\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+      RETURN_NOT_OK(write_options_.filesystem->CreateDir(dir));\n+\n+      ARROW_ASSIGN_OR_RAISE(auto destination,\n+                            write_options_.filesystem->OpenOutputStream(path));\n+\n+      ARROW_ASSIGN_OR_RAISE(**writer, write_options_.format()->MakeWriter(\n+                                          std::move(destination), schema,\n+                                          write_options_.file_write_options));\n+    }\n+\n+    return writer;\n   }\n \n-  return Status::OK();\n-}\n+  Status FinishAll(internal::TaskGroup* task_group) {\n+    for (const auto& dir_writer : dir_to_writer_) {\n+      task_group->Append([&] {\n+        std::shared_ptr<FileWriter> writer = **dir_writer.second;\n+        return writer->Finish();\n+      });\n+    }\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+    return Status::OK();\n+  }\n+\n+  // There should only be a single writer open for each partition directory at a time\n+  util::Mutex mutex_;\n+  std::unordered_map<std::string, std::shared_ptr<MutexedWriter>> dir_to_writer_;\n+  NextBasenameGenerator next_basename_;\n+  std::string base_dir_;\n+  const FileSystemDatasetWriteOptions& write_options_;\n+};\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  auto task_group = scanner->context()->TaskGroup();\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n-\n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n\nReview comment:\n       We *could* do two scans of the input data:\r\n   1. Assemble a list of all unique values in the partition columns of the data, from which we can determine the precise set of writers to open\r\n   2. Apply groupings to batches, passing the results to pre-opened writers\r\n   \r\n   This doesn't seem worthwhile to me; scanning the input is potentially expensive so we should avoid doing it twice. Furthermore we'll still need to coordinate between threads since two input batches might still contain rows bound for a single output writer.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T14:11:34.194+0000",
                    "updated": "2020-10-05T14:11:34.194+0000",
                    "started": "2020-10-05T14:11:34.194+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495343",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495495",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499788958\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n\nReview comment:\n       This is because `WriteQueue::Set` is an unordered_map, right? If you make it a `map<string, Queue>` instead, Queue pointers won't be invalidated on insert.\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T18:25:17.461+0000",
                    "updated": "2020-10-05T18:25:17.461+0000",
                    "started": "2020-10-05T18:25:17.461+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495495",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495504",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499799105\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n+\n+  // Store a mapping from partitions (represened by their formatted partition expressions)\n+  // to a WriteQueue which flushes batches into that partition's output file. In principle\n+  // any thread could produce a batch for any partition, so each task alternates between\n+  // pushing batches and flushing them to disk.\n+  util::Mutex queues_mutex;\n+  WriteQueue::Set queues;\n+\n+  auto fragment_for_task_it = fragment_for_task.begin();\n+  for (const auto& scan_task : scan_tasks) {\n+    const Fragment* fragment = *fragment_for_task_it++;\n+\n+    task_group->Append([&, scan_task, fragment] {\n+      ARROW_ASSIGN_OR_RAISE(auto batches, scan_task->Execute());\n+\n+      for (auto maybe_batch : batches) {\n+        ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n+        ARROW_ASSIGN_OR_RAISE(auto groups, write_options.partitioning->Partition(batch));\n+        batch.reset();  // drop to hopefully conserve memory\n+\n+        std::unordered_set<WriteQueue*> need_flushed;\n+        for (size_t i = 0; i < groups.batches.size(); ++i) {\n+          AndExpression partition_expression(std::move(groups.expressions[i]),\n+                                             fragment->partition_expression());\n+          auto batch = std::move(groups.batches[i]);\n+\n+          ARROW_ASSIGN_OR_RAISE(auto part,\n+                                write_options.partitioning->Format(partition_expression));\n+\n+          util::Mutex::Guard wait_for_opened_writer_lock;\n+\n+          WriteQueue* queue;\n+          {\n+            // lookup the queue to which batch should be appended\n+            auto queues_lock = queues_mutex.Lock();\n+\n+            queue = internal::GetOrInsertGenerated(\n+                        &queues, std::move(part),\n+                        [&](const std::string& emplaced_part) {\n+                          // lookup in `queues` also failed,\n+                          // generate a new WriteQueue\n+                          size_t queue_index = queues.size() - 1;\n+\n+                          queues_storage.emplace_back(emplaced_part, queue_index,\n+                                                      &wait_for_opened_writer_lock);\n\nReview comment:\n       This unorthodox thing with the `wait_for_opened_writer_lock` looks like it's because of two-phase initialization...?\r\n   \r\n   Let me suggest something else: make a `WriteQueuePromise` class:\r\n   ```c++\r\n   class WriteQueuePromise {\r\n    public:\r\n     WriteQueuePromise(std::string part, size_t queue_index,\r\n         std::shared_ptr<Schema> schema, const FileSystemDatasetWriteOptions& options)\r\n       : queue_(part, queue_index), schema_(schema), options_(options) {}\r\n   \r\n     Result<WriteQueue>* operator()() {\r\n       std::call_once(initialized_, [this]() { InitQueue(); });\r\n       RETURN_NOT_OK(status_);\r\n       return &queue_;\r\n     }\r\n   \r\n    protected:\r\n     void InitQueue() {\r\n       status_ = queue_->OpenWriter(options_, schema_);\r\n     }\r\n   \r\n     std::once_flag initialized_;\r\n     WriteQueue queue_;\r\n     std::shared_ptr<Schema> schema_;\r\n     const FileSystemDatasetWriteOptions& options_;\r\n     Status status_;\r\n   };\r\n   ```\r\n   \r\n   Also, make `queues` a `std::map<std::string, WriteQueuePromise>`.\r\n   Then do something like:\r\n   ```c++\r\n   WriteQueuePromise* queue_promise;\r\n   {\r\n     auto queues_lock = queues_mutex.Lock();\r\n     queue_promise = &queues.emplace(part, part, queue_index, batch->schema(), write_options)->second;\r\n   }\r\n   queue = (*queue_promise)();\r\n   ```\r\n   \n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T18:44:47.056+0000",
                    "updated": "2020-10-05T18:44:47.056+0000",
                    "started": "2020-10-05T18:44:47.055+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495504",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495506",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499803394\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n+\n+  // Store a mapping from partitions (represened by their formatted partition expressions)\n+  // to a WriteQueue which flushes batches into that partition's output file. In principle\n+  // any thread could produce a batch for any partition, so each task alternates between\n+  // pushing batches and flushing them to disk.\n+  util::Mutex queues_mutex;\n+  WriteQueue::Set queues;\n+\n+  auto fragment_for_task_it = fragment_for_task.begin();\n+  for (const auto& scan_task : scan_tasks) {\n+    const Fragment* fragment = *fragment_for_task_it++;\n+\n+    task_group->Append([&, scan_task, fragment] {\n+      ARROW_ASSIGN_OR_RAISE(auto batches, scan_task->Execute());\n+\n+      for (auto maybe_batch : batches) {\n+        ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n+        ARROW_ASSIGN_OR_RAISE(auto groups, write_options.partitioning->Partition(batch));\n+        batch.reset();  // drop to hopefully conserve memory\n+\n+        std::unordered_set<WriteQueue*> need_flushed;\n+        for (size_t i = 0; i < groups.batches.size(); ++i) {\n+          AndExpression partition_expression(std::move(groups.expressions[i]),\n+                                             fragment->partition_expression());\n+          auto batch = std::move(groups.batches[i]);\n+\n+          ARROW_ASSIGN_OR_RAISE(auto part,\n+                                write_options.partitioning->Format(partition_expression));\n+\n+          util::Mutex::Guard wait_for_opened_writer_lock;\n+\n+          WriteQueue* queue;\n+          {\n+            // lookup the queue to which batch should be appended\n+            auto queues_lock = queues_mutex.Lock();\n+\n+            queue = internal::GetOrInsertGenerated(\n+                        &queues, std::move(part),\n+                        [&](const std::string& emplaced_part) {\n+                          // lookup in `queues` also failed,\n+                          // generate a new WriteQueue\n+                          size_t queue_index = queues.size() - 1;\n+\n+                          queues_storage.emplace_back(emplaced_part, queue_index,\n+                                                      &wait_for_opened_writer_lock);\n\nReview comment:\n       It could also be a `DeferredInit` facility:\r\n   ```c++\r\n   template <typename T>\r\n   class DeferredInit<T> {\r\n    public:\r\n     template <typename... Args>\r\n     DeferredInit(Args&&... args)\r\n       : value_(std::forward<Args>(args)...) {}\r\n   \r\n     Result<T*> operator()() {\r\n       std::call_once(initialized_, [this]() { value_.Init(); });\r\n       RETURN_NOT_OK(status_);\r\n       return &value_;\r\n     }\r\n   \r\n    protected:\r\n     T value_;\r\n     Status status_;\r\n     std::once_flag initialized_;\r\n   };\r\n   ```\r\n   \n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T18:52:32.563+0000",
                    "updated": "2020-10-05T18:52:32.563+0000",
                    "started": "2020-10-05T18:52:32.563+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495506",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495507",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499803394\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n+\n+  // Store a mapping from partitions (represened by their formatted partition expressions)\n+  // to a WriteQueue which flushes batches into that partition's output file. In principle\n+  // any thread could produce a batch for any partition, so each task alternates between\n+  // pushing batches and flushing them to disk.\n+  util::Mutex queues_mutex;\n+  WriteQueue::Set queues;\n+\n+  auto fragment_for_task_it = fragment_for_task.begin();\n+  for (const auto& scan_task : scan_tasks) {\n+    const Fragment* fragment = *fragment_for_task_it++;\n+\n+    task_group->Append([&, scan_task, fragment] {\n+      ARROW_ASSIGN_OR_RAISE(auto batches, scan_task->Execute());\n+\n+      for (auto maybe_batch : batches) {\n+        ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n+        ARROW_ASSIGN_OR_RAISE(auto groups, write_options.partitioning->Partition(batch));\n+        batch.reset();  // drop to hopefully conserve memory\n+\n+        std::unordered_set<WriteQueue*> need_flushed;\n+        for (size_t i = 0; i < groups.batches.size(); ++i) {\n+          AndExpression partition_expression(std::move(groups.expressions[i]),\n+                                             fragment->partition_expression());\n+          auto batch = std::move(groups.batches[i]);\n+\n+          ARROW_ASSIGN_OR_RAISE(auto part,\n+                                write_options.partitioning->Format(partition_expression));\n+\n+          util::Mutex::Guard wait_for_opened_writer_lock;\n+\n+          WriteQueue* queue;\n+          {\n+            // lookup the queue to which batch should be appended\n+            auto queues_lock = queues_mutex.Lock();\n+\n+            queue = internal::GetOrInsertGenerated(\n+                        &queues, std::move(part),\n+                        [&](const std::string& emplaced_part) {\n+                          // lookup in `queues` also failed,\n+                          // generate a new WriteQueue\n+                          size_t queue_index = queues.size() - 1;\n+\n+                          queues_storage.emplace_back(emplaced_part, queue_index,\n+                                                      &wait_for_opened_writer_lock);\n\nReview comment:\n       It could also be a `DeferredInit` facility:\r\n   ```c++\r\n   // T needs to define a method `Status Init()`\r\n   template <typename T>\r\n   class DeferredInit<T> {\r\n    public:\r\n     template <typename... Args>\r\n     DeferredInit(Args&&... args)\r\n       : value_(std::forward<Args>(args)...) {}\r\n   \r\n     Result<T*> operator()() {\r\n       std::call_once(initialized_, [this]() { value_.Init(); });\r\n       RETURN_NOT_OK(status_);\r\n       return &value_;\r\n     }\r\n   \r\n    protected:\r\n     T value_;\r\n     Status status_;\r\n     std::once_flag initialized_;\r\n   };\r\n   ```\r\n   \n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T18:54:06.679+0000",
                    "updated": "2020-10-05T18:54:06.679+0000",
                    "started": "2020-10-05T18:54:06.679+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495507",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495508",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499804639\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n\nReview comment:\n       I was going with unordered_map due to O(1) lookup time; no threads can lookup queues for pushing while I'm holding `queues_lock`\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T18:55:01.696+0000",
                    "updated": "2020-10-05T18:55:01.696+0000",
                    "started": "2020-10-05T18:55:01.696+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495508",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495509",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499805082\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n+\n+  // Store a mapping from partitions (represened by their formatted partition expressions)\n+  // to a WriteQueue which flushes batches into that partition's output file. In principle\n+  // any thread could produce a batch for any partition, so each task alternates between\n+  // pushing batches and flushing them to disk.\n+  util::Mutex queues_mutex;\n+  WriteQueue::Set queues;\n+\n+  auto fragment_for_task_it = fragment_for_task.begin();\n+  for (const auto& scan_task : scan_tasks) {\n+    const Fragment* fragment = *fragment_for_task_it++;\n+\n+    task_group->Append([&, scan_task, fragment] {\n+      ARROW_ASSIGN_OR_RAISE(auto batches, scan_task->Execute());\n+\n+      for (auto maybe_batch : batches) {\n+        ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n+        ARROW_ASSIGN_OR_RAISE(auto groups, write_options.partitioning->Partition(batch));\n+        batch.reset();  // drop to hopefully conserve memory\n+\n+        std::unordered_set<WriteQueue*> need_flushed;\n+        for (size_t i = 0; i < groups.batches.size(); ++i) {\n+          AndExpression partition_expression(std::move(groups.expressions[i]),\n+                                             fragment->partition_expression());\n+          auto batch = std::move(groups.batches[i]);\n+\n+          ARROW_ASSIGN_OR_RAISE(auto part,\n+                                write_options.partitioning->Format(partition_expression));\n+\n+          util::Mutex::Guard wait_for_opened_writer_lock;\n+\n+          WriteQueue* queue;\n+          {\n+            // lookup the queue to which batch should be appended\n+            auto queues_lock = queues_mutex.Lock();\n+\n+            queue = internal::GetOrInsertGenerated(\n+                        &queues, std::move(part),\n+                        [&](const std::string& emplaced_part) {\n+                          // lookup in `queues` also failed,\n+                          // generate a new WriteQueue\n+                          size_t queue_index = queues.size() - 1;\n+\n+                          queues_storage.emplace_back(emplaced_part, queue_index,\n+                                                      &wait_for_opened_writer_lock);\n\nReview comment:\n       If I'm not mistaken, with this approach you don't need the embedded lock guard in `WriteQueue` anymore. Does that make sense?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T18:55:48.039+0000",
                    "updated": "2020-10-05T18:55:48.039+0000",
                    "started": "2020-10-05T18:55:48.039+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495509",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495531",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499831141\n\n\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -694,22 +697,23 @@ def _ensure_write_partitioning(scheme):\n     return scheme\n \n \n-def write_dataset(data, base_dir, format=None, partitioning=None, schema=None,\n-                  filesystem=None, use_threads=True):\n+def write_dataset(data, base_dir, basename_template, format=None,\n\nReview comment:\n       Should we provide a default template here? \r\n   Can eg the format object have a property with the default name to use? (or get the extension from there and use that in a default?)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T19:45:52.949+0000",
                    "updated": "2020-10-05T19:45:52.949+0000",
                    "started": "2020-10-05T19:45:52.948+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495531",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495570",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499859431\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n+\n+  // Store a mapping from partitions (represened by their formatted partition expressions)\n+  // to a WriteQueue which flushes batches into that partition's output file. In principle\n+  // any thread could produce a batch for any partition, so each task alternates between\n+  // pushing batches and flushing them to disk.\n+  util::Mutex queues_mutex;\n+  WriteQueue::Set queues;\n+\n+  auto fragment_for_task_it = fragment_for_task.begin();\n+  for (const auto& scan_task : scan_tasks) {\n+    const Fragment* fragment = *fragment_for_task_it++;\n+\n+    task_group->Append([&, scan_task, fragment] {\n+      ARROW_ASSIGN_OR_RAISE(auto batches, scan_task->Execute());\n+\n+      for (auto maybe_batch : batches) {\n+        ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n+        ARROW_ASSIGN_OR_RAISE(auto groups, write_options.partitioning->Partition(batch));\n+        batch.reset();  // drop to hopefully conserve memory\n+\n+        std::unordered_set<WriteQueue*> need_flushed;\n+        for (size_t i = 0; i < groups.batches.size(); ++i) {\n+          AndExpression partition_expression(std::move(groups.expressions[i]),\n+                                             fragment->partition_expression());\n+          auto batch = std::move(groups.batches[i]);\n+\n+          ARROW_ASSIGN_OR_RAISE(auto part,\n+                                write_options.partitioning->Format(partition_expression));\n+\n+          util::Mutex::Guard wait_for_opened_writer_lock;\n+\n+          WriteQueue* queue;\n+          {\n+            // lookup the queue to which batch should be appended\n+            auto queues_lock = queues_mutex.Lock();\n+\n+            queue = internal::GetOrInsertGenerated(\n+                        &queues, std::move(part),\n+                        [&](const std::string& emplaced_part) {\n+                          // lookup in `queues` also failed,\n+                          // generate a new WriteQueue\n+                          size_t queue_index = queues.size() - 1;\n+\n+                          queues_storage.emplace_back(emplaced_part, queue_index,\n+                                                      &wait_for_opened_writer_lock);\n\nReview comment:\n       > Let me suggest something else: make a `WriteQueuePromise` class\r\n   \r\n   That sounds doable and would certainly help with encapsulation of the locks.\r\n   \r\n   > If I'm not mistaken, with this approach you don't need the embedded lock guard in WriteQueue anymore. Does that make sense?\r\n   \r\n   `call_once` does guarantee that side effects of the first invocation are observed by all subsequent invocations, so the FileWriter would indeed be initialized for all threads. However we'd still need a `writer_lock` since `FileWriter::Write` is not thread safe\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T20:40:40.716+0000",
                    "updated": "2020-10-05T20:40:40.716+0000",
                    "started": "2020-10-05T20:40:40.716+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495570",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495571",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499859844\n\n\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -694,22 +697,23 @@ def _ensure_write_partitioning(scheme):\n     return scheme\n \n \n-def write_dataset(data, base_dir, format=None, partitioning=None, schema=None,\n-                  filesystem=None, use_threads=True):\n+def write_dataset(data, base_dir, basename_template, format=None,\n\nReview comment:\n       That sounds fine but I'd like to defer that to a follow up\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T20:41:23.755+0000",
                    "updated": "2020-10-05T20:41:23.755+0000",
                    "started": "2020-10-05T20:41:23.755+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495571",
                    "issueId": "13323345"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/worklog/495573",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #8305:\nURL: https://github.com/apache/arrow/pull/8305#discussion_r499860771\n\n\n\n##########\nFile path: cpp/src/arrow/dataset/file_base.cc\n##########\n@@ -143,97 +150,235 @@ FragmentIterator FileSystemDataset::GetFragmentsImpl(\n   return MakeVectorIterator(std::move(fragments));\n }\n \n-struct WriteTask {\n-  Status Execute();\n+Status FileWriter::Write(RecordBatchReader* batches) {\n+  while (true) {\n+    ARROW_ASSIGN_OR_RAISE(auto batch, batches->Next());\n+    if (batch == nullptr) break;\n+    RETURN_NOT_OK(Write(batch));\n+  }\n+  return Status::OK();\n+}\n \n-  /// The basename of files written by this WriteTask. Extensions\n-  /// are derived from format\n-  std::string basename;\n+constexpr util::string_view kIntegerToken = \"{i}\";\n \n-  /// The partitioning with which paths will be generated\n-  std::shared_ptr<Partitioning> partitioning;\n+Status ValidateBasenameTemplate(util::string_view basename_template) {\n+  if (basename_template.find(fs::internal::kSep) != util::string_view::npos) {\n+    return Status::Invalid(\"basename_template contained '/'\");\n+  }\n+  size_t token_start = basename_template.find(kIntegerToken);\n+  if (token_start == util::string_view::npos) {\n+    return Status::Invalid(\"basename_template did not contain '\", kIntegerToken, \"'\");\n+  }\n+  return Status::OK();\n+}\n \n-  /// The format in which fragments will be written\n-  std::shared_ptr<FileFormat> format;\n+/// WriteQueue allows batches to be pushed from multiple threads while another thread\n+/// flushes some to disk.\n+class WriteQueue {\n+ public:\n+  WriteQueue(std::string partition_expression, size_t index,\n+             util::Mutex::Guard* wait_for_opened_writer_lock)\n+      : partition_expression_(std::move(partition_expression)), index_(index) {\n+    *wait_for_opened_writer_lock = writer_mutex_.Lock();\n+  }\n \n-  /// The FileSystem and base directory into which fragments will be written\n-  std::shared_ptr<fs::FileSystem> filesystem;\n-  std::string base_dir;\n+  // Push a batch into the writer's queue of pending writes.\n+  void Push(std::shared_ptr<RecordBatch> batch) {\n+    auto push_lock = push_mutex_.Lock();\n+    pending_.push_back(std::move(batch));\n+  }\n \n-  /// Batches to be written\n-  std::shared_ptr<RecordBatchReader> batches;\n+  // Flush all pending batches, or return immediately if another thread is already\n+  // flushing this queue.\n+  Status Flush() {\n+    if (auto writer_lock = writer_mutex_.TryLock()) {\n+      while (true) {\n+        std::shared_ptr<RecordBatch> batch;\n+        {\n+          auto push_lock = push_mutex_.Lock();\n+          if (pending_.empty()) {\n+            // Ensure the writer_lock is released before the push_lock. Otherwise another\n+            // thread might successfully Push() a batch but then fail to Flush() it since\n+            // the writer_lock is still held, leaving an unflushed batch in pending_.\n+            writer_lock.Unlock();\n+            break;\n+          }\n+          batch = std::move(pending_.front());\n+          pending_.pop_front();\n+        }\n+        RETURN_NOT_OK(writer_->Write(batch));\n+      }\n+    }\n+    return Status::OK();\n+  }\n \n-  /// An Expression already satisfied by every batch to be written\n-  std::shared_ptr<Expression> partition_expression;\n-};\n+  const std::shared_ptr<FileWriter>& writer() const { return writer_; }\n \n-Status WriteTask::Execute() {\n-  std::unordered_map<std::string, RecordBatchVector> path_to_batches;\n-\n-  // TODO(bkietz) these calls to Partition() should be scattered across a TaskGroup\n-  for (auto maybe_batch : IteratorFromReader(batches)) {\n-    ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n-    ARROW_ASSIGN_OR_RAISE(auto partitioned_batches, partitioning->Partition(batch));\n-    for (auto&& partitioned_batch : partitioned_batches) {\n-      AndExpression expr(std::move(partitioned_batch.partition_expression),\n-                         partition_expression);\n-      ARROW_ASSIGN_OR_RAISE(std::string path, partitioning->Format(expr));\n-      path = fs::internal::EnsureLeadingSlash(path);\n-      path_to_batches[path].push_back(std::move(partitioned_batch.batch));\n+  Status OpenWriter(const FileSystemDatasetWriteOptions& write_options,\n+                    std::shared_ptr<Schema> schema) {\n+    auto dir =\n+        fs::internal::EnsureTrailingSlash(write_options.base_dir) + partition_expression_;\n+\n+    auto basename = internal::Replace(write_options.basename_template, kIntegerToken,\n+                                      std::to_string(index_));\n+    if (!basename) {\n+      return Status::Invalid(\"string interpolation of basename template failed\");\n     }\n-  }\n \n-  for (auto&& path_batches : path_to_batches) {\n-    auto dir = base_dir + path_batches.first;\n-    RETURN_NOT_OK(filesystem->CreateDir(dir, /*recursive=*/true));\n+    auto path = fs::internal::ConcatAbstractPath(dir, *basename);\n \n-    auto path = fs::internal::ConcatAbstractPath(dir, basename);\n-    ARROW_ASSIGN_OR_RAISE(auto destination, filesystem->OpenOutputStream(path));\n+    RETURN_NOT_OK(write_options.filesystem->CreateDir(dir));\n+    ARROW_ASSIGN_OR_RAISE(auto destination,\n+                          write_options.filesystem->OpenOutputStream(path));\n \n-    DCHECK(!path_batches.second.empty());\n-    ARROW_ASSIGN_OR_RAISE(auto reader,\n-                          RecordBatchReader::Make(std::move(path_batches.second)));\n-    RETURN_NOT_OK(format->WriteFragment(reader.get(), destination.get()));\n+    ARROW_ASSIGN_OR_RAISE(writer_, write_options.format()->MakeWriter(\n+                                       std::move(destination), std::move(schema),\n+                                       write_options.file_write_options));\n+    return Status::OK();\n   }\n \n-  return Status::OK();\n-}\n+  using Set = std::unordered_map<std::string, WriteQueue*>;\n+\n+ private:\n+  util::Mutex writer_mutex_;\n+  std::shared_ptr<FileWriter> writer_;\n \n-Status FileSystemDataset::Write(std::shared_ptr<Schema> schema,\n-                                std::shared_ptr<FileFormat> format,\n-                                std::shared_ptr<fs::FileSystem> filesystem,\n-                                std::string base_dir,\n-                                std::shared_ptr<Partitioning> partitioning,\n-                                std::shared_ptr<ScanContext> scan_context,\n-                                FragmentIterator fragment_it) {\n-  auto task_group = scan_context->TaskGroup();\n+  util::Mutex push_mutex_;\n+  std::deque<std::shared_ptr<RecordBatch>> pending_;\n \n-  base_dir = std::string(fs::internal::RemoveTrailingSlash(base_dir));\n+  // The (formatted) partition expression to which this queue corresponds\n+  std::string partition_expression_;\n \n-  for (const auto& f : partitioning->schema()->fields()) {\n+  size_t index_;\n+};\n+\n+Status FileSystemDataset::Write(const FileSystemDatasetWriteOptions& write_options,\n+                                std::shared_ptr<Scanner> scanner) {\n+  for (const auto& f : write_options.partitioning->schema()->fields()) {\n     if (f->type()->id() == Type::DICTIONARY) {\n       return Status::NotImplemented(\"writing with dictionary partitions\");\n     }\n   }\n \n-  int i = 0;\n-  for (auto maybe_fragment : fragment_it) {\n-    ARROW_ASSIGN_OR_RAISE(auto fragment, maybe_fragment);\n-    auto task = std::make_shared<WriteTask>();\n-\n-    task->basename = \"dat_\" + std::to_string(i++) + \".\" + format->type_name();\n-    task->partition_expression = fragment->partition_expression();\n-    task->format = format;\n-    task->filesystem = filesystem;\n-    task->base_dir = base_dir;\n-    task->partitioning = partitioning;\n+  RETURN_NOT_OK(ValidateBasenameTemplate(write_options.basename_template));\n+\n+  auto task_group = scanner->context()->TaskGroup();\n+\n+  // Things we'll un-lazy for the sake of simplicity, with the tradeoff they represent:\n+  //\n+  // - Fragment iteration. Keeping this lazy would allow us to start partitioning/writing\n+  //   any fragments we have before waiting for discovery to complete. This isn't\n+  //   currently implemented for FileSystemDataset anyway: ARROW-8613\n+  //\n+  // - ScanTask iteration. Keeping this lazy would save some unnecessary blocking when\n+  //   writing Fragments which produce scan tasks slowly. No Fragments do this.\n+  //\n+  // NB: neither of these will have any impact whatsoever on the common case of writing\n+  //     an in-memory table to disk.\n+  ARROW_ASSIGN_OR_RAISE(FragmentVector fragments, scanner->GetFragments().ToVector());\n+  ScanTaskVector scan_tasks;\n+  std::vector<const Fragment*> fragment_for_task;\n+\n+  // Avoid contention with multithreaded readers\n+  auto context = std::make_shared<ScanContext>(*scanner->context());\n+  context->use_threads = false;\n+\n+  for (const auto& fragment : fragments) {\n+    auto options = std::make_shared<ScanOptions>(*scanner->options());\n+    ARROW_ASSIGN_OR_RAISE(auto scan_task_it,\n+                          Scanner(fragment, std::move(options), context).Scan());\n+    for (auto maybe_scan_task : scan_task_it) {\n+      ARROW_ASSIGN_OR_RAISE(auto scan_task, maybe_scan_task);\n+      scan_tasks.push_back(std::move(scan_task));\n+      fragment_for_task.push_back(fragment.get());\n+    }\n+  }\n \n-    // make a record batch reader which yields from a fragment\n-    ARROW_ASSIGN_OR_RAISE(task->batches, FragmentRecordBatchReader::Make(\n-                                             std::move(fragment), schema, scan_context));\n-    task_group->Append([task] { return task->Execute(); });\n+  // WriteQueues are stored in this deque until writing is completed and are otherwise\n+  // referenced by non-owning pointers.\n+  std::deque<WriteQueue> queues_storage;\n+\n+  // Store a mapping from partitions (represened by their formatted partition expressions)\n+  // to a WriteQueue which flushes batches into that partition's output file. In principle\n+  // any thread could produce a batch for any partition, so each task alternates between\n+  // pushing batches and flushing them to disk.\n+  util::Mutex queues_mutex;\n+  WriteQueue::Set queues;\n+\n+  auto fragment_for_task_it = fragment_for_task.begin();\n+  for (const auto& scan_task : scan_tasks) {\n+    const Fragment* fragment = *fragment_for_task_it++;\n+\n+    task_group->Append([&, scan_task, fragment] {\n+      ARROW_ASSIGN_OR_RAISE(auto batches, scan_task->Execute());\n+\n+      for (auto maybe_batch : batches) {\n+        ARROW_ASSIGN_OR_RAISE(auto batch, maybe_batch);\n+        ARROW_ASSIGN_OR_RAISE(auto groups, write_options.partitioning->Partition(batch));\n+        batch.reset();  // drop to hopefully conserve memory\n+\n+        std::unordered_set<WriteQueue*> need_flushed;\n+        for (size_t i = 0; i < groups.batches.size(); ++i) {\n+          AndExpression partition_expression(std::move(groups.expressions[i]),\n+                                             fragment->partition_expression());\n+          auto batch = std::move(groups.batches[i]);\n+\n+          ARROW_ASSIGN_OR_RAISE(auto part,\n+                                write_options.partitioning->Format(partition_expression));\n+\n+          util::Mutex::Guard wait_for_opened_writer_lock;\n+\n+          WriteQueue* queue;\n+          {\n+            // lookup the queue to which batch should be appended\n+            auto queues_lock = queues_mutex.Lock();\n+\n+            queue = internal::GetOrInsertGenerated(\n+                        &queues, std::move(part),\n+                        [&](const std::string& emplaced_part) {\n+                          // lookup in `queues` also failed,\n+                          // generate a new WriteQueue\n+                          size_t queue_index = queues.size() - 1;\n+\n+                          queues_storage.emplace_back(emplaced_part, queue_index,\n+                                                      &wait_for_opened_writer_lock);\n\nReview comment:\n       Ah... does the `writer_lock` block inside the thread pool?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-10-05T20:43:22.104+0000",
                    "updated": "2020-10-05T20:43:22.104+0000",
                    "started": "2020-10-05T20:43:22.104+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "495573",
                    "issueId": "13323345"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 28200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2690f783[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@579cb3ba[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@73545c9f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@4167202c[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@37f14a20[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@299b6d23[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@787a6c2b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@e45548[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3d79bf3e[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@4ff93fc7[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@64c91927[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@46a54ee3[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 28200,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Oct 08 00:21:28 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-10-08T00:21:28.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-9782/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2020-08-18T12:06:54.000+0000",
        "updated": "2020-10-09T15:34:54.000+0000",
        "timeoriginalestimate": null,
        "description": "With the new dataset writing bindings, one can do {{ds.write_dataset(data, format=\"feather\")}} (Python) or {{write_dataset(data, format = \"feather\")}} (R) to write a dataset to feather files. \r\n\r\nHowever, because \"feather\" is just an alias for the IpcFileFormat, it will currently write all files with the {{.ipc}} extension.   \r\nI think this can be a bit confusing, since many people will be more familiar with \"feather\" and expect such an extension. \r\n\r\n(more generally, \".ipc\" is maybe not the best default, since it's not very descriptive extension. Something like \".arrow\" might be better?)\r\n\r\ncc [~npr] [~bkietz]\r\n",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "7h 50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 28200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Dataset] Ability to write \".feather\" files with IpcFileFormat",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/comment/17179650",
                    "id": "17179650",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "I agree, .feather or .arrow would be clearer. Nothing about \"ipc\" necessarily means Arrow. ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2020-08-18T14:23:25.977+0000",
                    "updated": "2020-08-18T14:23:25.977+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13323345/comment/17209941",
                    "id": "17209941",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 8305\n[https://github.com/apache/arrow/pull/8305]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-10-08T00:21:28.191+0000",
                    "updated": "2020-10-08T00:21:28.191+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z0hvpc:",
        "customfield_12314139": null
    }
}