{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13304783",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783",
    "key": "ARROW-8792",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12347769",
                "id": "12347769",
                "description": "",
                "name": "1.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2020-07-24"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12588224",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12588224",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13181653",
                    "key": "ARROW-3134",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13181653",
                    "fields": {
                        "summary": "[C++] Implement n-ary iterator for a collection of chunked arrays with possibly different chunking layouts",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            },
            {
                "id": "12589147",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12589147",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13306872",
                    "key": "ARROW-8894",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13306872",
                    "fields": {
                        "summary": "[C++] C++ array kernels framework and execution buildout (umbrella issue)",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            },
            {
                "id": "12588230",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12588230",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13204359",
                    "key": "ARROW-4022",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13204359",
                    "fields": {
                        "summary": "[C++] Promote Datum variant out of compute namespace",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 63600,
            "total": 63600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 63600,
            "total": 63600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8792/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 106,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/435837",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm opened a new pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240\n\n\n   This patch is a major reworking of our development strategy for implementing array-valued functions and applying them in a query processing setting. \r\n   \r\n   There are a ton of details, but one nice thing is that there is now a single API entry point for invoking any function by its name:\r\n   \r\n   ```c++\r\n   Result<Datum> CallFunction(ExecContext* ctx, const std::string& func_name,\r\n                              const std::vector<Datum>& args,\r\n                              const FunctionOptions* options = NULLPTR);\r\n   ```\r\n   \r\n   What occurs when you do this:\r\n   \r\n   * A `Function` instance is looked up in the global `FunctionRegistry`\r\n   * Given the descriptors of `args` (their types and shapes -- array or scalar), the Function searches for `Kernel` that is able to process those types and shapes. A kernel might be able to do `array[T0], array[T1]` or only `scalar[T0], scalar[T1]`, for example. This permits kernel specialization to treat different type and shape combinations\r\n   * The kernel is executed iteratively against `args` based on what `args` contains -- if there are ChunkedArrays, they will be split into contiguous pieces. Kernels never see ChunkedArray, only Array or Scalar\r\n   * The Executor implementation is able to split contiguous Array inputs into smaller chunks, which is important for parallel execution. See `ExecContext::set_exec_chunksize`\r\n   \r\n   To summarize: the REGISTRY contains FUNCTIONS. A FUNCTION contains KERNELS. A KERNEL is a specific implementation of a function that services a particular type combination. \r\n   \r\n   An additional effort in this patch is to radically simplify the process of creating kernels that are based on a scalar function. To do this, there is a growing collection of template-based kernel generation classes in compute/kernels/codegen_internal.h that will surely be the topic of much debate. I want to make it a lot easier for people to add new kernels.\r\n   \r\n   There are some other incidental changes in the PR, such as changing the convenience APIs like `Cast` to return `Result`. I'm afraid we may have to live with the API breakage unless someone else wants to add backward compatibility code for the old APIs. \r\n   \r\n   I have to apologize for making such a large PR. I've been working long hours on this for nearly a month and the process of porting all of our existing functionality and making the unit tests pass caused much iteration in the \"framework\" part of the code, such that it would have been a huge time drain to review incomplete iterations of the framework that had not been proven to capture the functionality that previously existed in the project.\r\n   \r\n   Given the size of this PR and that fact that it completely blocks any work into src/arrow/compute, I don't think we should let this sit unmerged for more than 4 or 5 days, tops. I'm committed to responding to all of your questions and working to address your feedback about the design and improving the documentation and code comments. I tried to leave copious comments to explain my thought process in various places. Feel free to make any and all comments in this PR or in whatever form you like. I don't think that merging should be blocked on stylistic issues. \r\n   \r\n   Current status viz-a-viz merge-readiness\r\n   \r\n   - [ ] Windows C++ issues\r\n   - [ ] Port Python bindings -- I have ported the code and the tests pass for me locally\r\n   - [ ] Port R bindings -- I have ported the C++ code and there is one test failure whose root cause I understand\r\n   - [ ] Port GLib bindings\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T04:50:43.645+0000",
                    "updated": "2020-05-21T04:50:43.645+0000",
                    "started": "2020-05-21T04:50:43.644+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "435837",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/435838",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#issuecomment-631878670\n\n\n   For code reviewers:\r\n   \r\n   * The code diff is a bit deceiving because many kernel files were renamed to make their taxonomy more clear\r\n   * I suggest focusing your energies on the files in the arrow/compute top level directory. This is almost entirely new code, what was there before is almost all gone\r\n   \r\n   I am aware that there are some obviously messy things that will need to be cleaned up a bit, but we have to start somewhere. \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T04:52:49.120+0000",
                    "updated": "2020-05-21T04:52:49.120+0000",
                    "started": "2020-05-21T04:52:49.119+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "435838",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/435841",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#issuecomment-631881573\n\n\n   https://issues.apache.org/jira/browse/ARROW-8792\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T05:02:10.547+0000",
                    "updated": "2020-05-21T05:02:10.547+0000",
                    "started": "2020-05-21T05:02:10.547+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "435841",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/435969",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428632802\n\n\n\n##########\nFile path: cpp/CMakeLists.txt\n##########\n@@ -309,6 +309,10 @@ if(ARROW_DATASET)\n   set(ARROW_FILESYSTEM ON)\n endif()\n \n+if(ARROW_GANDIVA)\n+  set(ARROW_COMPUTE ON)\n+endif()\n\nReview comment:\n       This is unneeded, will remove \n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T12:54:26.177+0000",
                    "updated": "2020-05-21T12:54:26.177+0000",
                    "started": "2020-05-21T12:54:26.177+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "435969",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436024",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#issuecomment-632131314\n\n\n   Aside from fixing the builds, I'm going to do a few things to help with this:\r\n   \r\n   * Add as many comments as possible to the new header files\r\n   * Add some high level explanation to compute/README.md about how kernels work and how to begin to develop a new one\r\n   * Add simple Python bindings for `FunctionRegistry`, `Function`, and `Kernel` so that we can inspect the contents of the registry and the available kernels (and their type signatures) for each function\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T14:54:20.449+0000",
                    "updated": "2020-05-21T14:54:20.449+0000",
                    "started": "2020-05-21T14:54:20.449+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436024",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436034",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428714912\n\n\n\n##########\nFile path: cpp/src/arrow/compute/cast.cc\n##########\n@@ -0,0 +1,193 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/cast.h\"\n+\n+#include <mutex>\n+#include <sstream>\n+#include <string>\n+#include <unordered_map>\n+#include <unordered_set>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/compute/cast_internal.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/compute/options.h\"\n+#include \"arrow/compute/registry.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+namespace internal {\n+\n+std::unordered_map<int, std::shared_ptr<const CastFunction>> g_cast_table;\n+static std::once_flag cast_table_initialized;\n+\n+void AddCastFunctions(const std::vector<std::shared_ptr<CastFunction>>& funcs) {\n+  for (const auto& func : funcs) {\n+    g_cast_table[static_cast<int>(func->out_type_id())] = func;\n+  }\n+}\n+\n+void InitCastTable() {\n+  AddCastFunctions(GetBooleanCasts());\n+  AddCastFunctions(GetBinaryLikeCasts());\n+  AddCastFunctions(GetNestedCasts());\n+  AddCastFunctions(GetNumericCasts());\n+  AddCastFunctions(GetTemporalCasts());\n+}\n+\n+void EnsureInitCastTable() { std::call_once(cast_table_initialized, InitCastTable); }\n+\n+void RegisterScalarCasts(FunctionRegistry* registry) {\n+  EnsureInitCastTable();\n+  for (auto it : g_cast_table) {\n+    DCHECK_OK(registry->AddFunction(it.second));\n+  }\n+}\n+\n+}  // namespace internal\n+\n+struct CastFunction::CastFunctionImpl {\n+  Type::type out_type;\n+  std::unordered_set<int> in_types;\n+};\n+\n+CastFunction::CastFunction(std::string name, Type::type out_type)\n+    : ScalarFunction(std::move(name), /*arity=*/1) {\n+  impl_.reset(new CastFunctionImpl());\n+  impl_->out_type = out_type;\n+}\n+\n+CastFunction::~CastFunction() {}\n+\n+Type::type CastFunction::out_type_id() const { return impl_->out_type; }\n+\n+std::unique_ptr<KernelState> CastInit(KernelContext* ctx, const KernelInitArgs& args) {\n+  // NOTE: TakeOptions are currently unused, but we pass it through anyway\n\nReview comment:\n       incorrect comment\n\n##########\nFile path: cpp/src/arrow/compute/exec_internal.h\n##########\n@@ -0,0 +1,137 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/buffer.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+class Function;\n+\n+namespace detail {\n+\n+/// \\brief Break std::vector<Datum> into a sequence of ExecBatch for kernel\n+/// execution\n+class ARROW_EXPORT ExecBatchIterator {\n+ public:\n+  /// \\brief Construct iterator and do basic argument validation\n+  ///\n+  /// \\param[in] args the Datum argument, must be all array-like or scalar\n+  /// \\param[in] max_chunksize the maximum length of each ExecBatch. Depending\n+  /// on the chunk layout of ChunkedArray. Default of -1 means no maximum, so\n+  /// as greedy as possible\n+  static Result<std::unique_ptr<ExecBatchIterator>> Make(std::vector<Datum> args,\n+                                                         int64_t max_chunksize = -1);\n+\n+  /// \\brief Compute the next batch. Always returns at least one batch. Return\n+  /// false if the iterator is exhausted\n+  bool Next(ExecBatch* batch);\n+\n+  int64_t length() const { return length_; }\n+\n+  int64_t position() const { return position_; }\n+\n+  int64_t max_chunksize() const { return max_chunksize_; }\n+\n+ private:\n+  ExecBatchIterator(std::vector<Datum> args, int64_t length, int64_t max_chunksize);\n+\n+  std::vector<Datum> args_;\n+  std::vector<int> chunk_indexes_;\n+  std::vector<int64_t> chunk_positions_;\n+  int64_t position_;\n+  int64_t length_;\n+  int64_t max_chunksize_;\n+};\n+\n+// \"Push\" / listener API like IPC reader so that consumers can receive\n+// processed chunks as soon as they're available.\n+\n+class ARROW_EXPORT ExecListener {\n+ public:\n+  virtual ~ExecListener() = default;\n+\n+  virtual Status OnResult(Datum) { return Status::NotImplemented(\"OnResult\"); }\n+};\n+\n+class DatumAccumulator : public ExecListener {\n+ public:\n+  DatumAccumulator() {}\n+\n+  Status OnResult(Datum value) override {\n+    values_.emplace_back(value);\n+    return Status::OK();\n+  }\n+\n+  std::vector<Datum> values() const { return values_; }\n+\n+ private:\n+  std::vector<Datum> values_;\n+};\n+\n+Status CheckAllValues(const std::vector<Datum>& values);\n+\n+class ARROW_EXPORT FunctionExecutor {\n+ public:\n+  virtual ~FunctionExecutor() = default;\n+\n+  /// XXX: Better configurability for listener\n+  /// Not thread-safe\n+  virtual Status Execute(const std::vector<Datum>& args, ExecListener* listener) = 0;\n+\n+  virtual ValueDescr output_descr() const = 0;\n+\n+  virtual Datum WrapResults(const std::vector<Datum>& args,\n+                            const std::vector<Datum>& outputs) = 0;\n+\n+  static Result<std::unique_ptr<FunctionExecutor>> Make(ExecContext* ctx,\n+                                                        const Function* func,\n+                                                        const FunctionOptions* options);\n+};\n+\n+ARROW_EXPORT\n+Status ExecuteFunction(ExecContext* ctx, const std::string& func_name,\n+                       const std::vector<Datum>& args, const FunctionOptions* options,\n+                       ValueDescr* out_descr, ExecListener* listener);\n\nReview comment:\n       This function no longer exists\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n\nReview comment:\n       add comment\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n\nReview comment:\n       cruft\n\n##########\nFile path: cpp/src/arrow/compute/kernels/CMakeLists.txt\n##########\n@@ -15,37 +15,41 @@\n # specific language governing permissions and limitations\n # under the License.\n\nReview comment:\n       TODO: clean up this module and compile all benchmarks\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n+  template <typename Op, typename OutType, typename Arg0Type>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0>(ctx, *arg0_data++);\n+      }\n+    }\n+  }\n+\n+  template <typename Op, typename OutType, typename Arg0Type, typename Arg1Type>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+    using ARG1 = typename Arg1Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      auto arg1_data = batch[1].array()->GetValues<ARG1>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0, ARG1>(ctx, *arg0_data++, *arg1_data++);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct OutputAdapter;\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_bitmap = out_arr->buffers[1]->mutable_data();\n+    GenerateBitsUnrolled(out_bitmap, out_arr->offset, out_arr->length,\n+                         std::forward<Generator>(generator));\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_data = out_arr->GetMutableValues<typename Type::c_type>(kPrimitiveData);\n+    // TODO: Is this as fast as a more explicitly inlined function?\n+    for (int64_t i = 0 ; i < out_arr->length; ++i) {\n+      *out_data++ = generator();\n+    }\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_base_binary<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext* ctx, Datum* out, Generator&& generator) {\n+    ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnary {\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  static void Array(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return Op::template Call<OUT, ARG0>(ctx, arg0());\n+    });\n+  }\n+\n+  static void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(Op::template Call<OUT, ARG0>(ctx, arg0),\n+                                               out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      return Array(ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+// Applies a scalar operation with state on the null-null values of a single\n+// array\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnaryNotNullStateful {\n\nReview comment:\n       more comments\n\n##########\nFile path: cpp/src/arrow/compute/exec.cc\n##########\n@@ -0,0 +1,932 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/exec.h\"\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/exec_internal.h\"\n+#include \"arrow/compute/function.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/compute/registry.h\"\n+#include \"arrow/datum.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/checked_cast.h\"\n+#include \"arrow/util/cpu_info.h\"\n+#include \"arrow/util/logging.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapAnd;\n+using internal::checked_cast;\n+using internal::CopyBitmap;\n+using internal::CpuInfo;\n+\n+namespace compute {\n+\n+namespace {\n+\n+Result<std::shared_ptr<Buffer>> AllocateDataBuffer(KernelContext* ctx, int64_t length,\n+                                                   int bit_width) {\n+  if (bit_width == 1) {\n+    return ctx->AllocateBitmap(length);\n+  } else {\n+    ARROW_CHECK_EQ(bit_width % 8, 0)\n+        << \"Only bit widths with multiple of 8 are currently supported\";\n+    int64_t buffer_size = length * bit_width / 8;\n+    return ctx->Allocate(buffer_size);\n+  }\n+  return Status::OK();\n+}\n+\n+bool CanPreallocate(const DataType& type) {\n+  // There are currently cases where NullType is the output type, so we disable\n+  // any preallocation logic when this occurs\n+  return is_fixed_width(type.id()) && type.id() != Type::NA;\n+}\n+\n+Status GetValueDescriptors(const std::vector<Datum>& args,\n+                           std::vector<ValueDescr>* descrs) {\n+  for (const auto& arg : args) {\n+    descrs->emplace_back(arg.descr());\n+  }\n+  return Status::OK();\n+}\n+\n+}  // namespace\n+\n+namespace detail {\n+\n+ExecBatchIterator::ExecBatchIterator(std::vector<Datum> args, int64_t length,\n+                                     int64_t max_chunksize)\n+    : args_(std::move(args)),\n+      position_(0),\n+      length_(length),\n+      max_chunksize_(max_chunksize) {\n+  chunk_indexes_.resize(args_.size(), 0);\n+  chunk_positions_.resize(args_.size(), 0);\n+}\n+\n+Result<std::unique_ptr<ExecBatchIterator>> ExecBatchIterator::Make(\n+    std::vector<Datum> args, int64_t max_chunksize) {\n+  for (const auto& arg : args) {\n+    if (!(arg.is_arraylike() || arg.is_scalar())) {\n+      return Status::Invalid(\n+          \"ExecBatchIterator only works with Scalar, Array, and \"\n+          \"ChunkedArray arguments\");\n+    }\n+  }\n+\n+  // If the arguments are all scalars, then the length is 1\n+  int64_t length = 1;\n+\n+  bool length_set = false;\n+  for (size_t i = 0; i < args.size(); ++i) {\n+    if (args[i].is_scalar()) {\n+      continue;\n+    }\n+    if (!length_set) {\n+      length = args[i].length();\n+      length_set = true;\n+    } else {\n+      if (args[i].length() != length) {\n+        return Status::Invalid(\"Array arguments must all be the same length\");\n+      }\n+    }\n+  }\n+\n+  // No maximum was indicated\n+  if (max_chunksize < 1) {\n+    max_chunksize = length;\n+  }\n+\n+  return std::unique_ptr<ExecBatchIterator>(\n+      new ExecBatchIterator(std::move(args), length, max_chunksize));\n+}\n+\n+bool ExecBatchIterator::Next(ExecBatch* batch) {\n+  if (position_ == length_) {\n+    return false;\n+  }\n+\n+  // Determine how large the common contiguous \"slice\" of all the arguments is\n+  int64_t iteration_size = std::min(length_ - position_, max_chunksize_);\n+\n+  // If length_ is 0, then this loop will never execute\n+  for (size_t i = 0; i < args_.size() && iteration_size > 0; ++i) {\n+    // If the argument is not a chunked array, it's either a Scalar or Array,\n+    // in which case it doesn't influence the size of this batch. Note that if\n+    // the args are all scalars the batch length is 1\n+    if (args_[i].kind() != Datum::CHUNKED_ARRAY) {\n+      continue;\n+    }\n+    const ChunkedArray& arg = *args_[i].chunked_array();\n+    std::shared_ptr<Array> current_chunk;\n+    while (true) {\n+      current_chunk = arg.chunk(chunk_indexes_[i]);\n+      if (chunk_positions_[i] == current_chunk->length()) {\n+        // Chunk is zero-length, or was exhausted in the previous iteration\n+        chunk_positions_[i] = 0;\n+        ++chunk_indexes_[i];\n+        continue;\n+      }\n+      break;\n+    }\n+    iteration_size =\n+        std::min(current_chunk->length() - chunk_positions_[i], iteration_size);\n+  }\n+\n+  // Now, fill the batch\n+  batch->values.resize(args_.size());\n+  batch->length = iteration_size;\n+  for (size_t i = 0; i < args_.size(); ++i) {\n+    if (args_[i].is_scalar()) {\n+      batch->values[i] = args_[i].scalar();\n+    } else if (args_[i].is_array()) {\n+      batch->values[i] = args_[i].array()->Slice(position_, iteration_size);\n+    } else {\n+      const ChunkedArray& carr = *args_[i].chunked_array();\n+      const auto& chunk = carr.chunk(chunk_indexes_[i]);\n+      batch->values[i] = chunk->data()->Slice(chunk_positions_[i], iteration_size);\n+      chunk_positions_[i] += iteration_size;\n+    }\n+  }\n+  position_ += iteration_size;\n+  DCHECK_LE(position_, length_);\n+  return true;\n+}\n+\n+bool ArrayHasNulls(const ArrayData& data) {\n+  // As discovered in ARROW-8863 (and not only for that reason)\n+  // ArrayData::null_count can -1 even when buffers[0] is nullptr. So we check\n+  // for both cases (nullptr means no nulls, or null_count already computed)\n+  if (data.type->id() == Type::NA) {\n+    return true;\n+  } else if (data.buffers[0] == nullptr) {\n+    return false;\n+  } else {\n+    // Do not count the bits if they haven't been counted already\n+    const int64_t known_null_count = data.null_count.load();\n+    return known_null_count == kUnknownNullCount || known_null_count > 0;\n+  }\n+}\n+\n+// Null propagation implementation that deals both with preallocated bitmaps\n+// and maybe-to-be allocated bitmaps\n+//\n+// If the bitmap is preallocated, it MUST be populated (since it might be a\n+// view of a much larger bitmap). If it isn't preallocated, then we have\n+// more flexibility.\n+//\n+// * If the batch has no nulls, then we do nothing\n+// * If only a single array has nulls, and its offset is a multiple of 8,\n+//   then we can zero-copy the bitmap into the output\n+// * Otherwise, we allocate the bitmap and populate it\n+class NullPropagator {\n+ public:\n+  NullPropagator(KernelContext* ctx, const ExecBatch& batch, ArrayData* output)\n+      : ctx_(ctx), batch_(batch), output_(output) {\n+    // At this point, the values in batch_.values must have been validated to\n+    // all be value-like\n+    for (const Datum& val : batch_.values) {\n+      if (val.kind() == Datum::ARRAY) {\n+        if (ArrayHasNulls(*val.array())) {\n+          values_with_nulls_.push_back(&val);\n+        }\n+      } else if (!val.scalar()->is_valid) {\n+        values_with_nulls_.push_back(&val);\n+      }\n+    }\n+\n+    if (output->buffers[0] != nullptr) {\n+      bitmap_preallocated_ = true;\n+      SetBitmap(output_->buffers[0].get());\n+    }\n+  }\n+\n+  void SetBitmap(Buffer* bitmap) { bitmap_ = bitmap->mutable_data(); }\n+\n+  Status EnsureAllocated() {\n+    if (bitmap_preallocated_) {\n+      return Status::OK();\n+    }\n+    ARROW_ASSIGN_OR_RAISE(output_->buffers[0], ctx_->AllocateBitmap(output_->length));\n+    SetBitmap(output_->buffers[0].get());\n+    return Status::OK();\n+  }\n+\n+  Result<bool> ShortCircuitIfAllNull() {\n+    // An all-null value (scalar null or all-null array) gives us a short\n+    // circuit opportunity\n+    bool is_all_null = false;\n+    std::shared_ptr<Buffer> all_null_bitmap;\n+\n+    // Walk all the values with nulls instead of breaking on the first in case\n+    // we find a bitmap that can be reused in the non-preallocated case\n+    for (const Datum* value : values_with_nulls_) {\n+      if (value->type()->id() == Type::NA) {\n+        // No bitmap\n+        is_all_null = true;\n+      } else if (value->kind() == Datum::ARRAY) {\n+        const ArrayData& arr = *value->array();\n+        if (arr.null_count.load() == arr.length) {\n+          // Pluck the all null bitmap so we can set it in the output if it was\n+          // not pre-allocated\n+          all_null_bitmap = arr.buffers[0];\n+          is_all_null = true;\n+        }\n+      } else {\n+        // Scalar\n+        is_all_null = true;\n+      }\n+    }\n+    if (!is_all_null) {\n+      return false;\n+    }\n+\n+    // OK, the output should be all null\n+    output_->null_count = output_->length;\n+\n+    if (!bitmap_preallocated_ && all_null_bitmap) {\n+      // If we did not pre-allocate memory, and we observed an all-null bitmap,\n+      // then we can zero-copy it into the output\n+      output_->buffers[0] = std::move(all_null_bitmap);\n+    } else {\n+      RETURN_NOT_OK(EnsureAllocated());\n+      BitUtil::SetBitsTo(bitmap_, output_->offset, output_->length, false);\n+    }\n+    return true;\n+  }\n+\n+  Status PropagateSingle() {\n+    // One array\n+    const ArrayData& arr = *values_with_nulls_[0]->array();\n+    const std::shared_ptr<Buffer>& arr_bitmap = arr.buffers[0];\n+\n+    // Reuse the null count if it's known\n+    output_->null_count = arr.null_count.load();\n+\n+    if (bitmap_preallocated_) {\n+      CopyBitmap(arr_bitmap->data(), arr.offset, arr.length, bitmap_, output_->offset);\n+    } else {\n+      // Two cases when memory was not pre-allocated:\n+      //\n+      // * Offset is zero: we reuse the bitmap as is\n+      // * Offset is nonzero but a multiple of 8: we can slice the bitmap\n+      // * Offset is not a multiple of 8: we must allocate and use CopyBitmap\n+      //\n+      // Keep in mind that output_->offset is not permitted to be nonzero when\n+      // the bitmap is not preallocated, and that precondition is asserted\n+      // higher in the call stack.\n+      if (arr.offset == 0) {\n+        output_->buffers[0] = arr_bitmap;\n+      } else if (arr.offset % 8 == 0) {\n+        output_->buffers[0] =\n+            SliceBuffer(arr_bitmap, arr.offset / 8, BitUtil::BytesForBits(arr.length));\n+      } else {\n+        RETURN_NOT_OK(EnsureAllocated());\n+        CopyBitmap(arr_bitmap->data(), arr.offset, arr.length, bitmap_,\n+                   /*dst_offset=*/0);\n+      }\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status PropagateMultiple() {\n+    // More than one array. We use BitmapAnd to intersect their bitmaps\n+\n+    // Do not compute the intersection null count until it's needed\n+    RETURN_NOT_OK(EnsureAllocated());\n+\n+    auto Accumulate = [&](const ArrayData& left, const ArrayData& right) {\n+      // This is a precondition of reaching this code path\n+      DCHECK(left.buffers[0]);\n+      DCHECK(right.buffers[0]);\n+      BitmapAnd(left.buffers[0]->data(), left.offset, right.buffers[0]->data(),\n+                right.offset, output_->length, output_->offset,\n+                output_->buffers[0]->mutable_data());\n+    };\n+\n+    DCHECK_GT(values_with_nulls_.size(), 1);\n+\n+    // Seed the output bitmap with the & of the first two bitmaps\n+    Accumulate(*values_with_nulls_[0]->array(), *values_with_nulls_[1]->array());\n+\n+    // Accumulate the rest\n+    for (size_t i = 2; i < values_with_nulls_.size(); ++i) {\n+      Accumulate(*output_, *values_with_nulls_[i]->array());\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status Execute() {\n+    bool finished = false;\n+    ARROW_ASSIGN_OR_RAISE(finished, ShortCircuitIfAllNull());\n+    if (finished) {\n+      return Status::OK();\n+    }\n+\n+    // At this point, by construction we know that all of the values in\n+    // values_with_nulls_ are arrays that are not all null. So there are a\n+    // few cases:\n+    //\n+    // * No arrays. This is a no-op w/o preallocation but when the bitmap is\n+    //   pre-allocated we have to fill it with 1's\n+    // * One array, whose bitmap can be zero-copied (w/o preallocation, and\n+    //   when no byte is split) or copied (split byte or w/ preallocation)\n+    // * More than one array, we must compute the intersection of all the\n+    //   bitmaps\n+    //\n+    // BUT, if the output offset is nonzero for some reason, we copy into the\n+    // output unconditionally\n+\n+    output_->null_count = kUnknownNullCount;\n+\n+    if (values_with_nulls_.size() == 0) {\n+      // No arrays with nulls case\n+      output_->null_count = 0;\n+      if (bitmap_preallocated_) {\n+        BitUtil::SetBitsTo(bitmap_, output_->offset, output_->length, true);\n+      }\n+      return Status::OK();\n+    } else if (values_with_nulls_.size() == 1) {\n+      return PropagateSingle();\n+    } else {\n+      return PropagateMultiple();\n+    }\n+  }\n+\n+ private:\n+  KernelContext* ctx_;\n+  const ExecBatch& batch_;\n+  std::vector<const Datum*> values_with_nulls_;\n+  ArrayData* output_;\n+  uint8_t* bitmap_;\n+  bool bitmap_preallocated_ = false;\n+};\n+\n+Status PropagateNulls(KernelContext* ctx, const ExecBatch& batch, ArrayData* output) {\n+  DCHECK_NE(nullptr, output);\n+  DCHECK_GT(output->buffers.size(), 0);\n+\n+  if (output->type->id() == Type::NA) {\n+    // Null output type is a no-op (rare when this would happen but we at least\n+    // will test for it)\n+    return Status::OK();\n+  }\n+\n+  // This function is ONLY able to write into output with non-zero offset\n+  // when the bitmap is preallocated. This could be a DCHECK but returning\n+  // error Status for now for emphasis\n+  if (output->offset != 0 && output->buffers[0] == nullptr) {\n+    return Status::Invalid(\n+        \"Can only propagate nulls into pre-allocated memory \"\n+        \"when the output offset is non-zero\");\n+  }\n+  NullPropagator propagator(ctx, batch, output);\n+  return propagator.Execute();\n+}\n+\n+std::shared_ptr<ChunkedArray> ToChunkedArray(const std::vector<Datum>& values,\n+                                             const std::shared_ptr<DataType>& type) {\n+  std::vector<std::shared_ptr<Array>> arrays;\n+  for (const auto& val : values) {\n+    auto boxed = val.make_array();\n+    if (boxed->length() == 0) {\n+      // Skip empty chunks\n+      continue;\n+    }\n+    arrays.emplace_back(std::move(boxed));\n+  }\n+  return std::make_shared<ChunkedArray>(arrays, type);\n+}\n+\n+bool HaveChunkedArray(const std::vector<Datum>& values) {\n+  for (const auto& value : values) {\n+    if (value.kind() == Datum::CHUNKED_ARRAY) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+Status CheckAllValues(const std::vector<Datum>& values) {\n+  for (const auto& value : values) {\n+    if (!value.is_value()) {\n+      return Status::Invalid(\"Tried executing function with non-value type: \",\n+                             value.ToString());\n+    }\n+  }\n+  return Status::OK();\n+}\n+\n+template <typename FunctionType>\n+class FunctionExecutorImpl : public FunctionExecutor {\n+ public:\n+  FunctionExecutorImpl(ExecContext* exec_ctx, const FunctionType* func,\n+                       const FunctionOptions* options)\n+      : exec_ctx_(exec_ctx), kernel_ctx_(exec_ctx), func_(func), options_(options) {}\n+\n+ protected:\n+  using KernelType = typename FunctionType::KernelType;\n+\n+  void Reset() {}\n+\n+  Status InitState() {\n+    // Some kernels require initialization of an opaque state object\n+    if (kernel_->init) {\n+      KernelInitArgs init_args{kernel_, input_descrs_, options_};\n+      state_ = kernel_->init(&kernel_ctx_, init_args);\n+      ARROW_CTX_RETURN_IF_ERROR(&kernel_ctx_);\n+      kernel_ctx_.SetState(state_.get());\n+    }\n+    return Status::OK();\n+  }\n+\n+  // This is overridden by the VectorExecutor\n+  virtual Status SetupArgIteration(const std::vector<Datum>& args) {\n+    ARROW_ASSIGN_OR_RAISE(batch_iterator_,\n+                          ExecBatchIterator::Make(args, exec_ctx_->exec_chunksize()));\n+    return Status::OK();\n+  }\n+\n+  Status BindArgs(const std::vector<Datum>& args) {\n+    RETURN_NOT_OK(GetValueDescriptors(args, &input_descrs_));\n+    ARROW_ASSIGN_OR_RAISE(kernel_, func_->DispatchExact(input_descrs_));\n+\n+    // Initialize kernel state, since type resolution may depend on this state\n+    RETURN_NOT_OK(this->InitState());\n+\n+    // Resolve the output descriptor for this kernel\n+    ARROW_ASSIGN_OR_RAISE(output_descr_, kernel_->signature->out_type().Resolve(\n+                                             &kernel_ctx_, input_descrs_));\n+\n+    return SetupArgIteration(args);\n+  }\n+\n+  Result<std::shared_ptr<ArrayData>> PrepareOutput(int64_t length) {\n+    auto out = std::make_shared<ArrayData>(output_descr_.type, length);\n+    out->buffers.resize(output_num_buffers_);\n+\n+    if (validity_preallocated_) {\n+      ARROW_ASSIGN_OR_RAISE(out->buffers[0], kernel_ctx_.AllocateBitmap(length));\n+    }\n+    if (data_preallocated_) {\n+      const auto& fw_type = checked_cast<const FixedWidthType&>(*out->type);\n+      ARROW_ASSIGN_OR_RAISE(\n+          out->buffers[1], AllocateDataBuffer(&kernel_ctx_, length, fw_type.bit_width()));\n+    }\n+    return out;\n+  }\n+\n+  ValueDescr output_descr() const override { return output_descr_; }\n+\n+  // Not all of these members are used for every executor type\n+\n+  ExecContext* exec_ctx_;\n+  KernelContext kernel_ctx_;\n+  const FunctionType* func_;\n+  const KernelType* kernel_;\n+  std::unique_ptr<ExecBatchIterator> batch_iterator_;\n+  std::unique_ptr<KernelState> state_;\n+  std::vector<ValueDescr> input_descrs_;\n+  ValueDescr output_descr_;\n+  const FunctionOptions* options_;\n+\n+  int output_num_buffers_;\n+\n+  // If true, then the kernel writes into a preallocated data buffer\n+  bool data_preallocated_ = false;\n+\n+  // If true, then memory is preallocated for the validity bitmap with the same\n+  // strategy as the data buffer(s).\n+  bool validity_preallocated_ = false;\n+};\n+\n+class ScalarExecutor : public FunctionExecutorImpl<ScalarFunction> {\n+ public:\n+  using FunctionType = ScalarFunction;\n+  static constexpr Function::Kind function_kind = Function::SCALAR;\n+  using BASE = FunctionExecutorImpl<ScalarFunction>;\n+  using BASE::BASE;\n+\n+  Status Execute(const std::vector<Datum>& args, ExecListener* listener) override {\n+    RETURN_NOT_OK(PrepareExecute(args));\n+    ExecBatch batch;\n+    while (batch_iterator_->Next(&batch)) {\n+      RETURN_NOT_OK(ExecuteBatch(batch, listener));\n+    }\n+    if (preallocate_contiguous_) {\n+      // If we preallocated one big chunk, since the kernel execution is\n+      // completed, we can now emit it\n+      RETURN_NOT_OK(listener->OnResult(std::move(preallocated_)));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Datum WrapResults(const std::vector<Datum>& inputs,\n+                    const std::vector<Datum>& outputs) override {\n+    if (output_descr_.shape == ValueDescr::SCALAR) {\n+      DCHECK_GT(outputs.size(), 0);\n+      if (outputs.size() == 1) {\n+        // Return as SCALAR\n+        return outputs[0];\n+      } else {\n+        // Return as COLLECTION\n+        return outputs;\n+      }\n+    } else {\n+      // If execution yielded multiple chunks (because large arrays were split\n+      // based on the ExecContext parameters, then the result is a ChunkedArray\n+      if (HaveChunkedArray(inputs) || outputs.size() > 1) {\n+        return ToChunkedArray(outputs, output_descr_.type);\n+      } else if (outputs.size() == 1) {\n+        // Outputs have just one element\n+        return outputs[0];\n+      } else {\n+        // XXX: In the case where no outputs are omitted, is returning a 0-length\n+        // array always the correct move?\n+        return MakeArrayOfNull(output_descr_.type, /*length=*/0).ValueOrDie();\n+      }\n+    }\n+  }\n+\n+ protected:\n+  Status ExecuteBatch(const ExecBatch& batch, ExecListener* listener) {\n+    Datum out;\n+    RETURN_NOT_OK(PrepareNextOutput(batch, &out));\n+\n+    if (kernel_->null_handling == NullHandling::INTERSECTION &&\n+        output_descr_.shape == ValueDescr::ARRAY) {\n+      RETURN_NOT_OK(PropagateNulls(&kernel_ctx_, batch, out.mutable_array()));\n+    }\n+\n+    kernel_->exec(&kernel_ctx_, batch, &out);\n+    ARROW_CTX_RETURN_IF_ERROR(&kernel_ctx_);\n+    if (!preallocate_contiguous_) {\n+      // If we are producing chunked output rather than one big array, then\n+      // emit each chunk as soon as it's available\n+      RETURN_NOT_OK(listener->OnResult(std::move(out)));\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status PrepareExecute(const std::vector<Datum>& args) {\n+    this->Reset();\n+    RETURN_NOT_OK(this->BindArgs(args));\n+\n+    if (output_descr_.shape == ValueDescr::ARRAY) {\n+      // If the executor is configured to produce a single large Array output for\n+      // kernels supporting preallocation, then we do so up front and then\n+      // iterate over slices of that large array. Otherwise, we preallocate prior\n+      // to processing each batch emitted from the ExecBatchIterator\n+      RETURN_NOT_OK(SetupPreallocation(batch_iterator_->length()));\n+    }\n+    return Status::OK();\n+  }\n+\n+  // We must accommodate two different modes of execution for preallocated\n+  // execution\n+  //\n+  // * A single large (\"contiguous\") allocation that we populate with results\n+  //   on a chunkwise basis according to the ExecBatchIterator. This permits\n+  //   parallelization even if the objective is to obtain a single Array or\n+  //   ChunkedArray at the end\n+  // * A standalone buffer preallocation for each chunk emitted from the\n+  //   ExecBatchIterator\n+  //\n+  // When data buffer preallocation is not possible (e.g. with BINARY / STRING\n+  // outputs), then contiguous results are only possible if the input is\n+  // contiguous.\n+\n+  Status PrepareNextOutput(const ExecBatch& batch, Datum* out) {\n+    if (output_descr_.shape == ValueDescr::ARRAY) {\n+      if (preallocate_contiguous_) {\n+        // The output is already fully preallocated\n+        const int64_t batch_start_position = batch_iterator_->position() - batch.length;\n+\n+        if (batch.length < batch_iterator_->length()) {\n+          // If this is a partial execution, then we write into a slice of\n+          // preallocated_\n+          //\n+          // XXX: ArrayData::Slice not returning std::shared_ptr<ArrayData> is\n+          // a nuisance\n+          out->value = std::make_shared<ArrayData>(\n+              preallocated_->Slice(batch_start_position, batch.length));\n+        } else {\n+          // Otherwise write directly into preallocated_. The main difference\n+          // computationally (versus the Slice approach) is that the null_count\n+          // may not need to be recomputed in the result\n+          out->value = preallocated_;\n+        }\n+      } else {\n+        // We preallocate (maybe) only for the output of processing the current\n+        // batch\n+        ARROW_ASSIGN_OR_RAISE(out->value, PrepareOutput(batch.length));\n+      }\n+    } else {\n+      // For scalar outputs, we set a null scalar of the correct type to\n+      // communicate the output type to the kernel if needed\n+      //\n+      // XXX: Is there some way to avoid this step?\n+      out->value = MakeNullScalar(output_descr_.type);\n+    }\n+    return Status::OK();\n+  }\n+\n+  Status SetupPreallocation(int64_t total_length) {\n+    output_num_buffers_ = static_cast<int>(output_descr_.type->layout().buffers.size());\n+\n+    // Decide if we need to preallocate memory for this kernel\n+    data_preallocated_ = ((kernel_->mem_allocation == MemAllocation::PREALLOCATE) &&\n+                          CanPreallocate(*output_descr_.type));\n+    validity_preallocated_ =\n+        (kernel_->null_handling != NullHandling::COMPUTED_NO_PREALLOCATE &&\n+         kernel_->null_handling != NullHandling::OUTPUT_NOT_NULL);\n+\n+    // Contiguous preallocation only possible if both the VALIDITY and DATA can\n+    // be preallocated. Otherwise, we must go chunk-by-chunk. Note that when\n+    // the DATA cannot be preallocated, the VALIDITY may still be preallocated\n+    // depending on the NullHandling of the kernel\n+    //\n+    // Some kernels are unable to write into sliced outputs, so we respect the\n+    // kernel's attributes\n+    preallocate_contiguous_ =\n+        (exec_ctx_->preallocate_contiguous() && kernel_->can_write_into_slices &&\n+         data_preallocated_ && validity_preallocated_);\n+    if (preallocate_contiguous_) {\n+      DCHECK_EQ(2, output_num_buffers_);\n+      ARROW_ASSIGN_OR_RAISE(preallocated_, PrepareOutput(total_length));\n+    }\n+    return Status::OK();\n+  }\n+\n+  // If true, and the kernel and output type supports preallocation (for both\n+  // the validity and data buffers), then we allocate one big array and then\n+  // iterate through it while executing the kernel in chunks\n+  bool preallocate_contiguous_ = false;\n+\n+  // For storing a contiguous preallocation per above. Unused otherwise\n+  std::shared_ptr<ArrayData> preallocated_;\n+};\n+\n+Status PackBatchNoChunks(const std::vector<Datum>& args, ExecBatch* out) {\n+  int64_t length = 0;\n+  for (size_t i = 0; i < args.size(); ++i) {\n+    switch (args[i].kind()) {\n+      case Datum::SCALAR:\n+      case Datum::ARRAY:\n+        length = std::max(args[i].length(), length);\n+        break;\n+      case Datum::CHUNKED_ARRAY:\n+        return Status::Invalid(\"Kernel does not support chunked array arguments\");\n+      default:\n+        DCHECK(false);\n+        break;\n+    }\n+  }\n+  out->length = length;\n+  out->values = args;\n+  return Status::OK();\n+}\n+\n+class VectorExecutor : public FunctionExecutorImpl<VectorFunction> {\n+ public:\n+  using FunctionType = VectorFunction;\n+  static constexpr Function::Kind function_kind = Function::VECTOR;\n+  using BASE = FunctionExecutorImpl<VectorFunction>;\n+  using BASE::BASE;\n+\n+  Status Execute(const std::vector<Datum>& args, ExecListener* listener) override {\n+    RETURN_NOT_OK(PrepareExecute(args));\n+    ExecBatch batch;\n+    if (kernel_->can_execute_chunkwise) {\n+      while (batch_iterator_->Next(&batch)) {\n+        RETURN_NOT_OK(ExecuteBatch(batch, listener));\n+      }\n+    } else {\n+      RETURN_NOT_OK(PackBatchNoChunks(args, &batch));\n+      RETURN_NOT_OK(ExecuteBatch(batch, listener));\n+    }\n+    return Finalize(listener);\n+  }\n+\n+  Datum WrapResults(const std::vector<Datum>& inputs,\n+                    const std::vector<Datum>& outputs) override {\n+    // If execution yielded multiple chunks (because large arrays were split\n+    // based on the ExecContext parameters, then the result is a ChunkedArray\n+    if (kernel_->output_chunked) {\n+      if (HaveChunkedArray(inputs) || outputs.size() > 1) {\n+        return ToChunkedArray(outputs, output_descr_.type);\n+      } else if (outputs.size() == 1) {\n+        // Outputs have just one element\n+        return outputs[0];\n+      } else {\n+        // XXX: In the case where no outputs are omitted, is returning a 0-length\n+        // array always the correct move?\n+        return MakeArrayOfNull(output_descr_.type, /*length=*/0).ValueOrDie();\n+      }\n+    } else {\n+      return outputs[0];\n+    }\n+  }\n+\n+ protected:\n+  Status ExecuteBatch(const ExecBatch& batch, ExecListener* listener) {\n+    if (batch.length == 0) {\n+      // Skip empty batches. This should only happen with zero-length inputs\n+      return Status::OK();\n+    }\n\nReview comment:\n       note to self: remove this\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n\nReview comment:\n       add comments\n\n##########\nFile path: cpp/src/arrow/compute/kernel.h\n##########\n@@ -15,295 +15,517 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+// NOTE: API is EXPERIMENTAL and will change without going through a\n+// deprecation cycle\n+\n #pragma once\n \n+#include <cstdint>\n+#include <functional>\n #include <memory>\n+#include <string>\n #include <utility>\n #include <vector>\n \n-#include \"arrow/array.h\"\n-#include \"arrow/record_batch.h\"\n-#include \"arrow/scalar.h\"\n-#include \"arrow/table.h\"\n-#include \"arrow/util/macros.h\"\n-#include \"arrow/util/memory.h\"\n-#include \"arrow/util/variant.h\"  // IWYU pragma: export\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/datum.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n #include \"arrow/util/visibility.h\"\n \n namespace arrow {\n+\n+class Buffer;\n+struct Datum;\n+\n namespace compute {\n \n-class FunctionContext;\n+struct FunctionOptions;\n \n-/// \\class OpKernel\n-/// \\brief Base class for operator kernels\n-///\n-/// Note to implementors:\n-/// Operator kernels are intended to be the lowest level of an analytics/compute\n-/// engine.  They will generally not be exposed directly to end-users.  Instead\n-/// they will be wrapped by higher level constructs (e.g. top-level functions\n-/// or physical execution plan nodes).  These higher level constructs are\n-/// responsible for user input validation and returning the appropriate\n-/// error Status.\n-///\n-/// Due to this design, implementations of Call (the execution\n-/// method on subclasses) should use assertions (i.e. DCHECK) to double-check\n-/// parameter arguments when in higher level components returning an\n-/// InvalidArgument error might be more appropriate.\n-///\n-class ARROW_EXPORT OpKernel {\n+/// \\brief Base class for opaque kernel-specific state. For example, if there\n+/// is some kind of initialization required\n+struct KernelState {\n+  virtual ~KernelState() = default;\n+};\n+\n+/// \\brief Context/state for the execution of a particular kernel\n+class ARROW_EXPORT KernelContext {\n  public:\n-  virtual ~OpKernel() = default;\n-  /// \\brief EXPERIMENTAL The output data type of the kernel\n-  /// \\return the output type\n-  virtual std::shared_ptr<DataType> out_type() const = 0;\n+  explicit KernelContext(ExecContext* exec_ctx) : exec_ctx_(exec_ctx) {}\n+\n+  /// \\brief Allocate buffer from the context's memory pool\n+  Result<std::shared_ptr<Buffer>> Allocate(int64_t nbytes);\n+\n+  /// \\brief Allocate buffer for bitmap from the context's memory pool\n+  Result<std::shared_ptr<Buffer>> AllocateBitmap(int64_t num_bits);\n+\n+  /// \\brief Indicate that an error has occurred, to be checked by a exec caller\n+  /// \\param[in] status a Status instance\n+  ///\n+  /// \\note Will not overwrite a prior set Status, so we will have the first\n+  /// error that occurred until ExecContext::ResetStatus is called\n+  void SetStatus(const Status& status);\n+\n+  /// \\brief Clear any error status\n+  void ResetStatus();\n+\n+  /// \\brief Return true if an error has occurred\n+  bool HasError() const { return !status_.ok(); }\n+\n+  /// \\brief Return the current status of the context\n+  const Status& status() const { return status_; }\n+\n+  // For passing kernel state to\n+  void SetState(KernelState* state) { state_ = state; }\n+\n+  KernelState* state() { return state_; }\n+\n+  /// \\brief Common state related to function execution\n+  ExecContext* exec_context() { return exec_ctx_; }\n+\n+  MemoryPool* memory_pool() { return exec_ctx_->memory_pool(); }\n+\n+ private:\n+  ExecContext* exec_ctx_;\n+  Status status_;\n+  KernelState* state_;\n };\n \n-struct Datum;\n-static inline bool CollectionEquals(const std::vector<Datum>& left,\n-                                    const std::vector<Datum>& right);\n-\n-// Datums variants may have a length. This special value indicate that the\n-// current variant does not have a length.\n-constexpr int64_t kUnknownLength = -1;\n-\n-/// \\class Datum\n-/// \\brief Variant type for various Arrow C++ data structures\n-struct ARROW_EXPORT Datum {\n-  enum type { NONE, SCALAR, ARRAY, CHUNKED_ARRAY, RECORD_BATCH, TABLE, COLLECTION };\n-\n-  util::variant<decltype(NULLPTR), std::shared_ptr<Scalar>, std::shared_ptr<ArrayData>,\n-                std::shared_ptr<ChunkedArray>, std::shared_ptr<RecordBatch>,\n-                std::shared_ptr<Table>, std::vector<Datum>>\n-      value;\n-\n-  /// \\brief Empty datum, to be populated elsewhere\n-  Datum() : value(NULLPTR) {}\n-\n-  Datum(const std::shared_ptr<Scalar>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::shared_ptr<ArrayData>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-\n-  Datum(const std::shared_ptr<Array>& value)  // NOLINT implicit conversion\n-      : Datum(value ? value->data() : NULLPTR) {}\n-\n-  Datum(const std::shared_ptr<ChunkedArray>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::shared_ptr<RecordBatch>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::shared_ptr<Table>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::vector<Datum>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-\n-  // Cast from subtypes of Array to Datum\n-  template <typename T, typename = enable_if_t<std::is_base_of<Array, T>::value>>\n-  Datum(const std::shared_ptr<T>& value)  // NOLINT implicit conversion\n-      : Datum(std::shared_ptr<Array>(value)) {}\n-\n-  // Convenience constructors\n-  explicit Datum(bool value) : value(std::make_shared<BooleanScalar>(value)) {}\n-  explicit Datum(int8_t value) : value(std::make_shared<Int8Scalar>(value)) {}\n-  explicit Datum(uint8_t value) : value(std::make_shared<UInt8Scalar>(value)) {}\n-  explicit Datum(int16_t value) : value(std::make_shared<Int16Scalar>(value)) {}\n-  explicit Datum(uint16_t value) : value(std::make_shared<UInt16Scalar>(value)) {}\n-  explicit Datum(int32_t value) : value(std::make_shared<Int32Scalar>(value)) {}\n-  explicit Datum(uint32_t value) : value(std::make_shared<UInt32Scalar>(value)) {}\n-  explicit Datum(int64_t value) : value(std::make_shared<Int64Scalar>(value)) {}\n-  explicit Datum(uint64_t value) : value(std::make_shared<UInt64Scalar>(value)) {}\n-  explicit Datum(float value) : value(std::make_shared<FloatScalar>(value)) {}\n-  explicit Datum(double value) : value(std::make_shared<DoubleScalar>(value)) {}\n-\n-  ~Datum() {}\n-\n-  Datum(const Datum& other) noexcept { this->value = other.value; }\n-\n-  Datum& operator=(const Datum& other) noexcept {\n-    value = other.value;\n-    return *this;\n-  }\n+#define ARROW_CTX_RETURN_IF_ERROR(CTX)            \\\n+  do {                                            \\\n+    if (ARROW_PREDICT_FALSE((CTX)->HasError())) { \\\n+      Status s = (CTX)->status();                 \\\n+      (CTX)->ResetStatus();                       \\\n+      return s;                                   \\\n+    }                                             \\\n+  } while (0)\n+\n+/// A standard function taking zero or more Array/Scalar values and returning\n+/// Array/Scalar output. May be used for SCALAR and VECTOR kernel kinds. Should\n+/// write into pre-allocated memory except in cases when a builder\n+/// (e.g. StringBuilder) must be employed\n+using ArrayKernelExec = std::function<void(KernelContext*, const ExecBatch&, Datum*)>;\n+\n+/// \\brief A container to express what kernel argument input types are accepted\n+class ARROW_EXPORT InputType {\n+ public:\n+  enum Kind {\n+    /// Accept any value type\n+    ANY_TYPE,\n \n-  // Define move constructor and move assignment, for better performance\n-  Datum(Datum&& other) noexcept : value(std::move(other.value)) {}\n+    /// A fixed arrow::DataType and will only exact match having this exact\n+    /// type (e.g. same TimestampType unit, same decimal scale and precision,\n+    /// or same nested child types\n+    EXACT_TYPE,\n \n-  Datum& operator=(Datum&& other) noexcept {\n-    value = std::move(other.value);\n-    return *this;\n-  }\n+    /// Any type having the indicated Type::type id. For example, accept\n+    /// any Type::LIST or any Type::TIMESTAMP\n+    SAME_TYPE_ID,\n+  };\n \n-  Datum::type kind() const {\n-    switch (this->value.index()) {\n-      case 0:\n-        return Datum::NONE;\n-      case 1:\n-        return Datum::SCALAR;\n-      case 2:\n-        return Datum::ARRAY;\n-      case 3:\n-        return Datum::CHUNKED_ARRAY;\n-      case 4:\n-        return Datum::RECORD_BATCH;\n-      case 5:\n-        return Datum::TABLE;\n-      case 6:\n-        return Datum::COLLECTION;\n-      default:\n-        return Datum::NONE;\n-    }\n-  }\n+  InputType(ValueDescr::Shape shape = ValueDescr::ANY)  // NOLINT implicit construction\n+      : kind_(ANY_TYPE), shape_(shape) {}\n \n-  std::shared_ptr<ArrayData> array() const {\n-    return util::get<std::shared_ptr<ArrayData>>(this->value);\n-  }\n+  InputType(std::shared_ptr<DataType> type,\n+            ValueDescr::Shape shape = ValueDescr::ANY)  // NOLINT implicit construction\n+      : kind_(EXACT_TYPE), shape_(shape), type_(std::move(type)), type_id_(type_->id()) {}\n \n-  std::shared_ptr<Array> make_array() const {\n-    return MakeArray(util::get<std::shared_ptr<ArrayData>>(this->value));\n-  }\n+  InputType(const ValueDescr& descr)  // NOLINT implicit construction\n+      : InputType(descr.type, descr.shape) {}\n \n-  std::shared_ptr<ChunkedArray> chunked_array() const {\n-    return util::get<std::shared_ptr<ChunkedArray>>(this->value);\n-  }\n+  InputType(Type::type type_id,\n+            ValueDescr::Shape shape = ValueDescr::ANY)  // NOLINT implicit construction\n+      : kind_(SAME_TYPE_ID), shape_(shape), type_id_(type_id) {}\n \n-  std::shared_ptr<RecordBatch> record_batch() const {\n-    return util::get<std::shared_ptr<RecordBatch>>(this->value);\n-  }\n+  InputType(const InputType& other) { CopyInto(other); }\n \n-  std::shared_ptr<Table> table() const {\n-    return util::get<std::shared_ptr<Table>>(this->value);\n+  // Convenience ctors\n+  static InputType Array(std::shared_ptr<DataType> type) {\n+    return InputType(std::move(type), ValueDescr::ARRAY);\n   }\n \n-  const std::vector<Datum> collection() const {\n-    return util::get<std::vector<Datum>>(this->value);\n+  static InputType Scalar(std::shared_ptr<DataType> type) {\n+    return InputType(std::move(type), ValueDescr::SCALAR);\n   }\n \n-  std::shared_ptr<Scalar> scalar() const {\n-    return util::get<std::shared_ptr<Scalar>>(this->value);\n-  }\n+  static InputType Array(Type::type id) { return InputType(id, ValueDescr::ARRAY); }\n \n-  bool is_array() const { return this->kind() == Datum::ARRAY; }\n+  static InputType Scalar(Type::type id) { return InputType(id, ValueDescr::SCALAR); }\n \n-  bool is_arraylike() const {\n-    return this->kind() == Datum::ARRAY || this->kind() == Datum::CHUNKED_ARRAY;\n-  }\n+  void operator=(const InputType& other) { CopyInto(other); }\n \n-  bool is_scalar() const { return this->kind() == Datum::SCALAR; }\n+  InputType(InputType&& other) { MoveInto(std::forward<InputType>(other)); }\n \n-  bool is_collection() const { return this->kind() == Datum::COLLECTION; }\n+  void operator=(InputType&& other) { MoveInto(std::forward<InputType>(other)); }\n \n-  /// \\brief The value type of the variant, if any\n-  ///\n-  /// \\return nullptr if no type\n-  std::shared_ptr<DataType> type() const {\n-    if (this->kind() == Datum::ARRAY) {\n-      return util::get<std::shared_ptr<ArrayData>>(this->value)->type;\n-    } else if (this->kind() == Datum::CHUNKED_ARRAY) {\n-      return util::get<std::shared_ptr<ChunkedArray>>(this->value)->type();\n-    } else if (this->kind() == Datum::SCALAR) {\n-      return util::get<std::shared_ptr<Scalar>>(this->value)->type;\n-    }\n-    return NULLPTR;\n+  /// \\brief Return true if this type exactly matches another\n+  bool Equals(const InputType& other) const;\n+\n+  bool operator==(const InputType& other) const { return this->Equals(other); }\n+\n+  bool operator!=(const InputType& other) const { return !(*this == other); }\n+\n+  /// \\brief Return hash code\n+  uint64_t Hash() const;\n+\n+  /// \\brief Render a human-readable string representation\n+  std::string ToString() const;\n+\n+  /// \\brief Return true if the value matches this argument kind in type\n+  /// and shape\n+  bool Matches(const Datum& value) const;\n+\n+  /// \\brief Return true if the value descriptor matches this argument kind in\n+  /// type and shape\n+  bool Matches(const ValueDescr& value) const;\n+\n+  /// \\brief The type matching rule that this InputType uses\n+  Kind kind() const { return kind_; }\n+\n+  ValueDescr::Shape shape() const { return shape_; }\n+\n+  /// \\brief For ArgKind::EXACT_TYPE, the exact type that this InputType must\n+  /// match. Otherwise this function should not be used\n+  const std::shared_ptr<DataType>& type() const;\n+\n+  /// \\brief For ArgKind::SAME_TYPE_ID, the Type::type that this InputType must\n+  /// match, Otherwise this function should not be used\n+  Type::type type_id() const;\n+\n+ private:\n+  void CopyInto(const InputType& other) {\n+    this->kind_ = other.kind_;\n+    this->shape_ = other.shape_;\n+    this->type_ = other.type_;\n+    this->type_id_ = other.type_id_;\n   }\n \n-  /// \\brief The value length of the variant, if any\n-  ///\n-  /// \\return kUnknownLength if no type\n-  int64_t length() const {\n-    if (this->kind() == Datum::ARRAY) {\n-      return util::get<std::shared_ptr<ArrayData>>(this->value)->length;\n-    } else if (this->kind() == Datum::CHUNKED_ARRAY) {\n-      return util::get<std::shared_ptr<ChunkedArray>>(this->value)->length();\n-    } else if (this->kind() == Datum::SCALAR) {\n-      return 1;\n-    }\n-    return kUnknownLength;\n+  void MoveInto(InputType&& other) {\n+    this->kind_ = other.kind_;\n+    this->shape_ = other.shape_;\n+    this->type_ = std::move(other.type_);\n+    this->type_id_ = other.type_id_;\n   }\n \n-  /// \\brief The array chunks of the variant, if any\n-  ///\n-  /// \\return empty if not arraylike\n-  ArrayVector chunks() const {\n-    if (!this->is_arraylike()) {\n-      return {};\n-    }\n-    if (this->is_array()) {\n-      return {this->make_array()};\n-    }\n-    return this->chunked_array()->chunks();\n+  Kind kind_;\n+\n+  ValueDescr::Shape shape_ = ValueDescr::ANY;\n+\n+  // For EXACT_TYPE ArgKind\n+  std::shared_ptr<DataType> type_;\n+\n+  // For SAME_TYPE_ID ArgKind\n+  Type::type type_id_ = Type::NA;\n+};\n+\n+/// \\brief Container to capture both exact and input-dependent output types\n+///\n+/// The value shape returned by Resolve will be determined by broadcasting the\n+/// shapes of the input arguments, otherwise this is handled by the\n+/// user-defined resolver function\n+///\n+/// * Any ARRAY shape -> output shape is ARRAY\n+/// * All SCALAR shapes -> output shape is SCALAR\n+class ARROW_EXPORT OutputType {\n+ public:\n+  /// \\brief An enum indicating whether the value type is an invariant fixed\n+  /// value or one that's computed by a kernel-defined resolver function\n+  enum ResolveKind { FIXED, COMPUTED };\n+\n+  /// Type resolution function. Given input types and shapes, return output\n+  /// type and shape. This function SHOULD _not_ be used to check for arity,\n+  /// that SHOULD be performed one or more layers above. May make use of kernel\n+  /// state to know what type to output\n+  using Resolver =\n+      std::function<Result<ValueDescr>(KernelContext*, const std::vector<ValueDescr>&)>;\n+\n+  OutputType(std::shared_ptr<DataType> type)  // NOLINT implicit construction\n+      : kind_(FIXED), type_(std::move(type)) {}\n+\n+  /// For outputting a particular type and shape\n+  OutputType(ValueDescr descr);  // NOLINT implicit construction\n+\n+  explicit OutputType(Resolver resolver) : kind_(COMPUTED), resolver_(resolver) {}\n+\n+  OutputType(const OutputType& other) {\n+    this->kind_ = other.kind_;\n+    this->shape_ = other.shape_;\n+    this->type_ = other.type_;\n+    this->resolver_ = other.resolver_;\n   }\n \n-  bool Equals(const Datum& other) const {\n-    if (this->kind() != other.kind()) return false;\n-\n-    switch (this->kind()) {\n-      case Datum::NONE:\n-        return true;\n-      case Datum::SCALAR:\n-        return internal::SharedPtrEquals(this->scalar(), other.scalar());\n-      case Datum::ARRAY:\n-        return internal::SharedPtrEquals(this->make_array(), other.make_array());\n-      case Datum::CHUNKED_ARRAY:\n-        return internal::SharedPtrEquals(this->chunked_array(), other.chunked_array());\n-      case Datum::RECORD_BATCH:\n-        return internal::SharedPtrEquals(this->record_batch(), other.record_batch());\n-      case Datum::TABLE:\n-        return internal::SharedPtrEquals(this->table(), other.table());\n-      case Datum::COLLECTION:\n-        return CollectionEquals(this->collection(), other.collection());\n-      default:\n-        return false;\n-    }\n+  OutputType(OutputType&& other) {\n+    this->kind_ = other.kind_;\n+    this->type_ = std::move(other.type_);\n+    this->shape_ = other.shape_;\n+    this->resolver_ = other.resolver_;\n   }\n+\n+  /// \\brief Return the shape and type of the expected output value of the\n+  /// kernel given the value descriptors (shapes and types). The resolver may\n+  /// make use of state information kept in the KernelContext\n+  Result<ValueDescr> Resolve(KernelContext* ctx,\n+                             const std::vector<ValueDescr>& args) const;\n+\n+  /// \\brief The value type for the FIXED kind rule\n+  const std::shared_ptr<DataType>& type() const;\n+\n+  /// \\brief For use with COMPUTED resolution strategy, the output type depends\n+  /// on the input type. It may be more convenient to invoke this with\n+  /// OutputType::Resolve returned from this method\n+  const Resolver& resolver() const;\n+\n+  /// \\brief Render a human-readable string representation\n+  std::string ToString() const;\n+\n+  /// \\brief Return the kind of type resolution of this output type, whether\n+  /// fixed/invariant or computed by a \"user\"-defined resolver\n+  ResolveKind kind() const { return kind_; }\n+\n+  /// \\brief If the shape is ANY, then Resolve will compute the shape based on\n+  /// the input arguments\n+  ValueDescr::Shape shape() const { return shape_; }\n+\n+ private:\n+  ResolveKind kind_;\n+\n+  // For FIXED resolution\n+  std::shared_ptr<DataType> type_;\n+\n+  ValueDescr::Shape shape_ = ValueDescr::ANY;\n+\n+  // For COMPUTED resolution\n+  Resolver resolver_;\n };\n \n-/// \\class UnaryKernel\n-/// \\brief An array-valued function of a single input argument.\n+/// \\brief Holds the input types and output type of the kernel\n ///\n-/// Note to implementors:  Try to avoid making kernels that allocate memory if\n-/// the output size is a deterministic function of the Input Datum's metadata.\n-/// Instead separate the logic of the kernel and allocations necessary into\n-/// two different kernels.  Some reusable kernels that allocate buffers\n-/// and delegate computation to another kernel are available in util-internal.h.\n-class ARROW_EXPORT UnaryKernel : public OpKernel {\n+/// Varargs functions should pass a single input type to be used to validate\n+/// the the input types of a function invocation\n+class ARROW_EXPORT KernelSignature {\n  public:\n-  /// \\brief Executes the kernel.\n-  ///\n-  /// \\param[in] ctx The function context for the kernel\n-  /// \\param[in] input The kernel input data\n-  /// \\param[out] out The output of the function. Each implementation of this\n-  /// function might assume different things about the existing contents of out\n-  /// (e.g. which buffers are preallocated).  In the future it is expected that\n-  /// there will be a more generic mechanism for understanding the necessary\n-  /// contracts.\n-  virtual Status Call(FunctionContext* ctx, const Datum& input, Datum* out) = 0;\n+  KernelSignature(std::vector<InputType> in_types, OutputType out_type,\n+                  bool is_varargs = false);\n+\n+  /// \\brief Convenience ctor since make_shared can be awkward\n+  static std::shared_ptr<KernelSignature> Make(std::vector<InputType> in_types,\n+                                               OutputType out_type,\n+                                               bool is_varargs = false);\n+\n+  /// \\brief Return true if the signature if compatible with the list of input\n+  /// value descriptors\n+  bool MatchesInputs(const std::vector<ValueDescr>& descriptors) const;\n+\n+  /// \\brief Returns true if the input types of each signature are\n+  /// equal. Well-formed functions should have a deterministic output type\n+  /// given input types, but currently it is the responsibility of the\n+  /// developer to ensure this\n+  bool Equals(const KernelSignature& other) const;\n+\n+  bool operator==(const KernelSignature& other) const { return this->Equals(other); }\n+\n+  bool operator!=(const KernelSignature& other) const { return !(*this == other); }\n+\n+  /// \\brief Compute a hash code for the signature\n+  int64_t Hash() const;\n+\n+  const std::vector<InputType>& in_types() const { return in_types_; }\n+\n+  const OutputType& out_type() const { return out_type_; }\n+\n+  /// \\brief Render a human-readable string representation\n+  std::string ToString() const;\n+\n+  bool is_varargs() const { return is_varargs_; }\n+\n+ private:\n+  std::vector<InputType> in_types_;\n+  OutputType out_type_;\n+  bool is_varargs_;\n+\n+  // For caching the hash code after it's computed the first time\n+  mutable int64_t hash_code_;\n };\n \n-/// \\class BinaryKernel\n-/// \\brief An array-valued function of a two input arguments\n-class ARROW_EXPORT BinaryKernel : public OpKernel {\n- public:\n-  virtual Status Call(FunctionContext* ctx, const Datum& left, const Datum& right,\n-                      Datum* out) = 0;\n+struct SimdLevel {\n+  enum type { NONE, SSE4_2, AVX, AVX2, AVX512, NEON };\n };\n \n-// TODO doxygen 1.8.16 does not like the following code\n-///@cond INTERNAL\n+struct NullHandling {\n+  enum type {\n+    /// Compute the output validity bitmap by intersecting the validity bitmaps\n+    /// of the arguments. Kernel does not do anything with the bitmap\n+    INTERSECTION,\n \n-static inline bool CollectionEquals(const std::vector<Datum>& left,\n-                                    const std::vector<Datum>& right) {\n-  if (left.size() != right.size()) {\n-    return false;\n-  }\n+    /// Kernel expects a pre-allocated buffer to write the result bitmap into\n+    COMPUTED_PREALLOCATE,\n \n-  for (size_t i = 0; i < left.size(); i++) {\n-    if (!left[i].Equals(right[i])) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n+    /// Kernel allocates and populates the validity bitmap of the output\n+    COMPUTED_NO_PREALLOCATE,\n+\n+    /// Output is never null\n+    OUTPUT_NOT_NULL\n+  };\n+};\n+\n+struct MemAllocation {\n+  enum type {\n+    // For data types that support pre-allocation (fixed-type), the kernel\n+    // expects to be provided pre-allocated memory to write\n+    // into. Non-fixed-width must always allocate their own memory but perhaps\n+    // not their validity bitmaps. The allocation made for the same length as\n+    // the execution batch, so vector kernels yielding differently sized output\n+    // should not use this\n+    PREALLOCATE,\n+\n+    // The kernel does its own memory allocation\n+    NO_PREALLOCATE\n+  };\n+};\n+\n+struct Kernel;\n+\n+struct KernelInitArgs {\n+  const Kernel* kernel;\n+  const std::vector<ValueDescr>& inputs;\n+  const FunctionOptions* options;\n+};\n+\n+// Kernel initializer (context, argument descriptors, options)\n+using KernelInit =\n+    std::function<std::unique_ptr<KernelState>(KernelContext*, const KernelInitArgs&)>;\n+\n+/// \\brief Base type for kernels. Contains the function signature and\n+/// optionally the state initialization function, along with some common\n+/// attributes\n+struct Kernel {\n+  Kernel() {}\n+\n+  Kernel(std::shared_ptr<KernelSignature> sig, KernelInit init)\n+      : signature(std::move(sig)), init(init) {}\n+\n+  Kernel(std::vector<InputType> in_types, OutputType out_type, KernelInit init)\n+      : Kernel(KernelSignature::Make(std::move(in_types), out_type), init) {}\n+\n+  std::shared_ptr<KernelSignature> signature;\n+\n+  /// \\brief Create a new KernelState for invocations of this kernel, e.g. to\n+  /// set up any options or state relevant for execution. May be nullptr\n+  KernelInit init;\n \n-///@endcond\n+  // Does execution benefit from parallelization (splitting large chunks into\n+  // smaller chunks and using multiple threads). Some vector kernels may\n+  // require single-threaded execution.\n+  bool parallelizable = true;\n+\n+  SimdLevel::type simd_level = SimdLevel::NONE;\n+};\n+\n+/// \\brief Descriptor to hold signature and execution function implementations\n+/// for a particular kernel\n+struct ArrayKernel : public Kernel {\n+  ArrayKernel() {}\n+\n+  ArrayKernel(std::shared_ptr<KernelSignature> sig, ArrayKernelExec exec,\n+              KernelInit init = NULLPTR)\n+      : Kernel(std::move(sig), init), exec(exec) {}\n+\n+  ArrayKernel(std::vector<InputType> in_types, OutputType out_type, ArrayKernelExec exec,\n+              KernelInit init = NULLPTR)\n+      : Kernel(std::move(in_types), std::move(out_type), init), exec(exec) {}\n+\n+  /// \\brief Perform a single invocation of this kernel. In general, this\n+  /// function must\n\nReview comment:\n       complete\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_cast.cc\n##########\n@@ -15,37 +15,40 @@\n // specific language governing permissions and limitations\n\nReview comment:\n       remove this file\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n+  template <typename Op, typename OutType, typename Arg0Type>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0>(ctx, *arg0_data++);\n+      }\n+    }\n+  }\n+\n+  template <typename Op, typename OutType, typename Arg0Type, typename Arg1Type>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+    using ARG1 = typename Arg1Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      auto arg1_data = batch[1].array()->GetValues<ARG1>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0, ARG1>(ctx, *arg0_data++, *arg1_data++);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct OutputAdapter;\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_bitmap = out_arr->buffers[1]->mutable_data();\n+    GenerateBitsUnrolled(out_bitmap, out_arr->offset, out_arr->length,\n+                         std::forward<Generator>(generator));\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_data = out_arr->GetMutableValues<typename Type::c_type>(kPrimitiveData);\n+    // TODO: Is this as fast as a more explicitly inlined function?\n+    for (int64_t i = 0 ; i < out_arr->length; ++i) {\n+      *out_data++ = generator();\n+    }\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_base_binary<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext* ctx, Datum* out, Generator&& generator) {\n+    ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnary {\n\nReview comment:\n       comments\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n+  template <typename Op, typename OutType, typename Arg0Type>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0>(ctx, *arg0_data++);\n+      }\n+    }\n+  }\n+\n+  template <typename Op, typename OutType, typename Arg0Type, typename Arg1Type>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+    using ARG1 = typename Arg1Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      auto arg1_data = batch[1].array()->GetValues<ARG1>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0, ARG1>(ctx, *arg0_data++, *arg1_data++);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct OutputAdapter;\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_bitmap = out_arr->buffers[1]->mutable_data();\n+    GenerateBitsUnrolled(out_bitmap, out_arr->offset, out_arr->length,\n+                         std::forward<Generator>(generator));\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_data = out_arr->GetMutableValues<typename Type::c_type>(kPrimitiveData);\n+    // TODO: Is this as fast as a more explicitly inlined function?\n+    for (int64_t i = 0 ; i < out_arr->length; ++i) {\n+      *out_data++ = generator();\n+    }\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_base_binary<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext* ctx, Datum* out, Generator&& generator) {\n+    ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnary {\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  static void Array(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return Op::template Call<OUT, ARG0>(ctx, arg0());\n+    });\n+  }\n+\n+  static void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(Op::template Call<OUT, ARG0>(ctx, arg0),\n+                                               out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      return Array(ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+// Applies a scalar operation with state on the null-null values of a single\n+// array\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnaryNotNullStateful {\n+  using ThisType = ScalarUnaryNotNullStateful<OutType, Arg0Type, Op>;\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  Op op;\n+  ScalarUnaryNotNullStateful(Op op) : op(std::move(op)) {}\n+\n+  template <typename Type, typename Enable = void>\n+  struct ArrayExec {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      DCHECK(false);\n+    }\n+  };\n+\n+  template <typename Type>\n+  struct ArrayExec<Type, enable_if_t<has_c_type<Type>::value &&\n+                                     !is_boolean_type<Type>::value>> {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      VisitArrayDataInline<Arg0Type>(*batch[0].array(), [&](util::optional<ARG0> v) {\n+          if (v.has_value()) {\n+            *out_data = functor.op.template Call<OUT, ARG0>(ctx, *v);\n+          }\n+          ++out_data;\n+        });\n+    }\n+  };\n+\n+  template <typename Type>\n+  struct ArrayExec<Type, enable_if_t<is_boolean_type<Type>::value>> {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      ArrayData* out_arr = out->mutable_array();\n+      FirstTimeBitmapWriter out_writer(out_arr->buffers[1]->mutable_data(),\n+                                       out_arr->offset, out_arr->length);\n+      VisitArrayDataInline<Arg0Type>(*batch[0].array(), [&](util::optional<ARG0> v) {\n+          if (v.has_value()) {\n+            if (functor.op.template Call<OUT, ARG0>(ctx, *v)) {\n+              out_writer.Set();\n+            }\n+          }\n+          out_writer.Next();\n+        });\n+      out_writer.Finish();\n+    }\n+  };\n+\n+  void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(\n+          this->op.template Call<OUT, ARG0>(ctx, arg0),\n+          out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      ArrayExec<OutType>::Exec(*this, ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnaryNotNull {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    // Seed kernel with dummy state\n+    ScalarUnaryNotNullStateful<OutType, Arg0Type, Op> kernel({});\n+    return kernel.Exec(ctx, batch, out);\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Arg1Type, typename Op,\n+          typename FlippedOp = Op>\n+struct ScalarBinary {\n+  using OutScalarType = typename TypeTraits<OutType>::ScalarType;\n+\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+  using ARG1 = typename CodegenTraits<Arg1Type>::value_type;\n+\n+  template <typename ChosenOp>\n+  static void ArrayArray(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    ArrayIterator<Arg1Type> arg1(*batch[1].array());\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return ChosenOp::template Call(ctx, arg0(), arg1());\n+    });\n+  }\n+\n+  template <typename ChosenOp>\n+  static void ArrayScalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    auto arg1 = UnboxScalar<Arg1Type>::Unbox(batch[1]);\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return ChosenOp::template Call(ctx, arg0(), arg1);\n+    });\n+  }\n+\n+  template <typename ChosenOp>\n+  static void ScalarScalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    auto arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+    auto arg1 = UnboxScalar<Arg1Type>::Unbox(batch[1]);\n+    out->value = std::make_shared<OutScalarType>(ChosenOp::template Call(ctx, arg0, arg1));\n+  }\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      if (batch[1].kind() == Datum::ARRAY) {\n+        return ArrayArray<Op>(ctx, batch, out);\n+      } else {\n+        return ArrayScalar<Op>(ctx, batch, out);\n+      }\n+    } else {\n+      if (batch[1].kind() == Datum::ARRAY) {\n+        // e.g. if we were doing scalar < array, we flip and do array >= scalar\n+        return BinaryExecFlipped(ctx, ArrayScalar<FlippedOp>, batch, out);\n+      } else {\n+        return ScalarScalar<Op>(ctx, batch, out);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename OutType, typename ArgType, typename Op,\n+          typename FlippedOp = Op>\n+using ScalarBinaryEqualTypes = ScalarBinary<OutType, ArgType, ArgType, Op, FlippedOp>;\n+\n+struct ScalarNumericEqualTypes {\n\nReview comment:\n       comments to explain what's going on from here through end of the file\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n+  template <typename Op, typename OutType, typename Arg0Type>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0>(ctx, *arg0_data++);\n+      }\n+    }\n+  }\n+\n+  template <typename Op, typename OutType, typename Arg0Type, typename Arg1Type>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+    using ARG1 = typename Arg1Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      auto arg1_data = batch[1].array()->GetValues<ARG1>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0, ARG1>(ctx, *arg0_data++, *arg1_data++);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct OutputAdapter;\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_bitmap = out_arr->buffers[1]->mutable_data();\n+    GenerateBitsUnrolled(out_bitmap, out_arr->offset, out_arr->length,\n+                         std::forward<Generator>(generator));\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_data = out_arr->GetMutableValues<typename Type::c_type>(kPrimitiveData);\n+    // TODO: Is this as fast as a more explicitly inlined function?\n+    for (int64_t i = 0 ; i < out_arr->length; ++i) {\n+      *out_data++ = generator();\n+    }\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_base_binary<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext* ctx, Datum* out, Generator&& generator) {\n+    ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnary {\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  static void Array(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return Op::template Call<OUT, ARG0>(ctx, arg0());\n+    });\n+  }\n+\n+  static void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(Op::template Call<OUT, ARG0>(ctx, arg0),\n+                                               out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      return Array(ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+// Applies a scalar operation with state on the null-null values of a single\n+// array\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnaryNotNullStateful {\n+  using ThisType = ScalarUnaryNotNullStateful<OutType, Arg0Type, Op>;\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  Op op;\n+  ScalarUnaryNotNullStateful(Op op) : op(std::move(op)) {}\n+\n+  template <typename Type, typename Enable = void>\n+  struct ArrayExec {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      DCHECK(false);\n+    }\n+  };\n+\n+  template <typename Type>\n+  struct ArrayExec<Type, enable_if_t<has_c_type<Type>::value &&\n+                                     !is_boolean_type<Type>::value>> {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      VisitArrayDataInline<Arg0Type>(*batch[0].array(), [&](util::optional<ARG0> v) {\n+          if (v.has_value()) {\n+            *out_data = functor.op.template Call<OUT, ARG0>(ctx, *v);\n+          }\n+          ++out_data;\n+        });\n+    }\n+  };\n+\n+  template <typename Type>\n+  struct ArrayExec<Type, enable_if_t<is_boolean_type<Type>::value>> {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      ArrayData* out_arr = out->mutable_array();\n+      FirstTimeBitmapWriter out_writer(out_arr->buffers[1]->mutable_data(),\n+                                       out_arr->offset, out_arr->length);\n+      VisitArrayDataInline<Arg0Type>(*batch[0].array(), [&](util::optional<ARG0> v) {\n+          if (v.has_value()) {\n+            if (functor.op.template Call<OUT, ARG0>(ctx, *v)) {\n+              out_writer.Set();\n+            }\n+          }\n+          out_writer.Next();\n+        });\n+      out_writer.Finish();\n+    }\n+  };\n+\n+  void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(\n+          this->op.template Call<OUT, ARG0>(ctx, arg0),\n+          out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      ArrayExec<OutType>::Exec(*this, ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnaryNotNull {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    // Seed kernel with dummy state\n+    ScalarUnaryNotNullStateful<OutType, Arg0Type, Op> kernel({});\n+    return kernel.Exec(ctx, batch, out);\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Arg1Type, typename Op,\n+          typename FlippedOp = Op>\n+struct ScalarBinary {\n\nReview comment:\n       more comments\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n+  template <typename Op, typename OutType, typename Arg0Type>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0>(ctx, *arg0_data++);\n+      }\n+    }\n+  }\n+\n+  template <typename Op, typename OutType, typename Arg0Type, typename Arg1Type>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+    using ARG1 = typename Arg1Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      auto arg1_data = batch[1].array()->GetValues<ARG1>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0, ARG1>(ctx, *arg0_data++, *arg1_data++);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct OutputAdapter;\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_bitmap = out_arr->buffers[1]->mutable_data();\n+    GenerateBitsUnrolled(out_bitmap, out_arr->offset, out_arr->length,\n+                         std::forward<Generator>(generator));\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_data = out_arr->GetMutableValues<typename Type::c_type>(kPrimitiveData);\n+    // TODO: Is this as fast as a more explicitly inlined function?\n+    for (int64_t i = 0 ; i < out_arr->length; ++i) {\n+      *out_data++ = generator();\n+    }\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_base_binary<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext* ctx, Datum* out, Generator&& generator) {\n+    ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnary {\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  static void Array(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return Op::template Call<OUT, ARG0>(ctx, arg0());\n+    });\n+  }\n+\n+  static void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(Op::template Call<OUT, ARG0>(ctx, arg0),\n+                                               out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      return Array(ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+// Applies a scalar operation with state on the null-null values of a single\n+// array\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnaryNotNullStateful {\n+  using ThisType = ScalarUnaryNotNullStateful<OutType, Arg0Type, Op>;\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  Op op;\n+  ScalarUnaryNotNullStateful(Op op) : op(std::move(op)) {}\n+\n+  template <typename Type, typename Enable = void>\n+  struct ArrayExec {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      DCHECK(false);\n+    }\n+  };\n+\n+  template <typename Type>\n+  struct ArrayExec<Type, enable_if_t<has_c_type<Type>::value &&\n+                                     !is_boolean_type<Type>::value>> {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      VisitArrayDataInline<Arg0Type>(*batch[0].array(), [&](util::optional<ARG0> v) {\n+          if (v.has_value()) {\n+            *out_data = functor.op.template Call<OUT, ARG0>(ctx, *v);\n+          }\n+          ++out_data;\n+        });\n+    }\n+  };\n+\n+  template <typename Type>\n+  struct ArrayExec<Type, enable_if_t<is_boolean_type<Type>::value>> {\n+    static void Exec(const ThisType& functor, KernelContext* ctx, const ExecBatch& batch,\n+                     Datum* out) {\n+      ArrayData* out_arr = out->mutable_array();\n+      FirstTimeBitmapWriter out_writer(out_arr->buffers[1]->mutable_data(),\n+                                       out_arr->offset, out_arr->length);\n+      VisitArrayDataInline<Arg0Type>(*batch[0].array(), [&](util::optional<ARG0> v) {\n+          if (v.has_value()) {\n+            if (functor.op.template Call<OUT, ARG0>(ctx, *v)) {\n+              out_writer.Set();\n+            }\n+          }\n+          out_writer.Next();\n+        });\n+      out_writer.Finish();\n+    }\n+  };\n+\n+  void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(\n+          this->op.template Call<OUT, ARG0>(ctx, arg0),\n+          out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      ArrayExec<OutType>::Exec(*this, ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnaryNotNull {\n\nReview comment:\n       more comments\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:24:29.469+0000",
                    "updated": "2020-05-21T15:24:29.469+0000",
                    "started": "2020-05-21T15:24:29.469+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436034",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436038",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428679922\n\n\n\n##########\nFile path: cpp/src/arrow/compute/registry.cc\n##########\n@@ -0,0 +1,127 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/registry.h\"\n+\n+#include <algorithm>\n+#include <memory>\n+#include <mutex>\n+#include <unordered_map>\n+\n+#include \"arrow/compute/function.h\"\n+#include \"arrow/compute/registry_internal.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/logging.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+class FunctionRegistry::FunctionRegistryImpl {\n+ public:\n+  Status AddFunction(std::shared_ptr<const Function> function, bool allow_overwrite) {\n+    std::lock_guard<std::mutex> mutation_guard(lock_);\n+\n+    const std::string& name = function->name();\n+    auto it = name_to_function_.find(name);\n+    if (it != name_to_function_.end() && !allow_overwrite) {\n+      return Status::KeyError(\"Already have a function registered with name: \", name);\n+    }\n+    name_to_function_[name] = std::move(function);\n+    return Status::OK();\n+  }\n+\n+  Result<std::shared_ptr<const Function>> GetFunction(const std::string& name) const {\n+    auto it = name_to_function_.find(name);\n+    if (it == name_to_function_.end()) {\n+      return Status::KeyError(\"No function registered with name: \", name);\n+    }\n+    return it->second;\n+  }\n+\n+  std::vector<std::string> GetFunctionNames() const {\n+    std::vector<std::string> results;\n+    for (auto it : name_to_function_) {\n+      results.push_back(it.first);\n+    }\n+    std::sort(results.begin(), results.end());\n+    return results;\n+  }\n+\n+  int num_functions() const { return static_cast<int>(name_to_function_.size()); }\n+\n+ private:\n+  std::mutex lock_;\n+  std::unordered_map<std::string, std::shared_ptr<const Function>> name_to_function_;\n+};\n+\n+std::unique_ptr<FunctionRegistry> FunctionRegistry::Make() {\n+  return std::unique_ptr<FunctionRegistry>(new FunctionRegistry());\n+}\n+\n+FunctionRegistry::FunctionRegistry() { impl_.reset(new FunctionRegistryImpl()); }\n+\n+FunctionRegistry::~FunctionRegistry() {}\n+\n+Status FunctionRegistry::AddFunction(std::shared_ptr<const Function> function,\n+                                     bool allow_overwrite) {\n+  return impl_->AddFunction(std::move(function), allow_overwrite);\n+}\n+\n+Result<std::shared_ptr<const Function>> FunctionRegistry::GetFunction(\n+    const std::string& name) const {\n+  return impl_->GetFunction(name);\n+}\n+\n+std::vector<std::string> FunctionRegistry::GetFunctionNames() const {\n+  return impl_->GetFunctionNames();\n+}\n+\n+int FunctionRegistry::num_functions() const { return impl_->num_functions(); }\n+\n+static std::unique_ptr<FunctionRegistry> g_registry;\n+static std::once_flag func_registry_initialized;\n+\n+namespace internal {\n+\n+static void CreateBuiltInRegistry() {\n+  g_registry = FunctionRegistry::Make();\n+\n+  // Scalar functions\n+  RegisterScalarArithmetic(g_registry.get());\n+  RegisterScalarBoolean(g_registry.get());\n+  RegisterScalarComparison(g_registry.get());\n+  RegisterScalarSetLookup(g_registry.get());\n+\n+  // Aggregate functions\n+  RegisterScalarAggregateBasic(g_registry.get());\n+\n+  // Vector functions\n+  RegisterVectorFilter(g_registry.get());\n+  RegisterVectorHash(g_registry.get());\n+  RegisterVectorSort(g_registry.get());\n+  RegisterVectorTake(g_registry.get());\n+}\n+\n+}  // namespace internal\n+\n+FunctionRegistry* GetFunctionRegistry() {\n+  std::call_once(func_registry_initialized, internal::CreateBuiltInRegistry);\n\nReview comment:\n       Or simply\r\n   ```c++\r\n   static auto g_registry = internal::CreateBuiltInRegistry();\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/options.h\n##########\n@@ -0,0 +1,155 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <utility>\n+\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class Array;\n+class DataType;\n+\n+namespace compute {\n+\n+struct ARROW_EXPORT FunctionOptions {};\n+\n+struct ARROW_EXPORT CastOptions : public FunctionOptions {\n\nReview comment:\n       I don't really understand why the various options classes are exposed here. Shouldn't they be in the respective `.h` files?\n\n##########\nFile path: cpp/src/arrow/compute/options.h\n##########\n@@ -0,0 +1,155 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <utility>\n+\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class Array;\n+class DataType;\n+\n+namespace compute {\n+\n+struct ARROW_EXPORT FunctionOptions {};\n+\n+struct ARROW_EXPORT CastOptions : public FunctionOptions {\n+  CastOptions()\n+      : allow_int_overflow(false),\n+        allow_time_truncate(false),\n+        allow_time_overflow(false),\n+        allow_decimal_truncate(false),\n+        allow_float_truncate(false),\n+        allow_invalid_utf8(false) {}\n+\n+  explicit CastOptions(bool safe)\n+      : allow_int_overflow(!safe),\n+        allow_time_truncate(!safe),\n+        allow_time_overflow(!safe),\n+        allow_decimal_truncate(!safe),\n+        allow_float_truncate(!safe),\n+        allow_invalid_utf8(!safe) {}\n+\n+  static CastOptions Safe() { return CastOptions(true); }\n+\n+  static CastOptions Unsafe() { return CastOptions(false); }\n+\n+  // Type being casted to. May be passed separate to eager function\n+  // compute::Cast\n+  std::shared_ptr<DataType> to_type;\n\nReview comment:\n       It's weird to have this as part of the cast options.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n\nReview comment:\n       It's difficult to understand why there's `ScalarPrimitiveExec` as well as `ScalarUnary` and other stuff.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_cast_internal.h\n##########\n@@ -0,0 +1,283 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/builder.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/cast_internal.h\"\n+#include \"arrow/compute/kernels/common.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+namespace internal {\n+\n+template <typename OutType, typename InType, typename Enable = void>\n+struct CastFunctor {};\n+\n+// No-op functor for identity casts\n+template <typename O, typename I>\n+struct CastFunctor<\n+    O, I, enable_if_t<std::is_same<O, I>::value && is_parameter_free_type<I>::value>> {\n+  static void Exec(KernelContext*, const ExecBatch&, Datum*) {}\n+};\n+\n+void CastFromExtension(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Dictionary to other things\n+\n+template <typename T, typename IndexType, typename Enable = void>\n+struct FromDictVisitor {};\n+\n+// Visitor for Dict<FixedSizeBinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_fixed_size_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary),\n+        byte_width_(dictionary.byte_width()),\n+        out_(output->buffers[1]->mutable_data() + byte_width_ * output->offset) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    memset(out_, 0, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    const uint8_t* value = dictionary_.Value(dict_index);\n+    memcpy(out_, value, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  int32_t byte_width_;\n+  uint8_t* out_;\n+};\n+\n+// Visitor for Dict<BinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_base_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : ctx_(ctx), dictionary_(dictionary), output_(output) {}\n+\n+  Status Init() {\n+    RETURN_NOT_OK(MakeBuilder(ctx_->memory_pool(), output_->type, &builder_));\n+    binary_builder_ = checked_cast<BinaryBuilder*>(builder_.get());\n+    return Status::OK();\n+  }\n+\n+  Status VisitNull() { return binary_builder_->AppendNull(); }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    return binary_builder_->Append(dictionary_.GetView(dict_index));\n+  }\n+\n+  Status Finish() {\n+    std::shared_ptr<Array> plain_array;\n+    RETURN_NOT_OK(binary_builder_->Finish(&plain_array));\n+    output_->buffers = plain_array->data()->buffers;\n+    return Status::OK();\n+  }\n+\n+  KernelContext* ctx_;\n+  const ArrayType& dictionary_;\n+  ArrayData* output_;\n+  std::unique_ptr<ArrayBuilder> builder_;\n+  BinaryBuilder* binary_builder_;\n+};\n+\n+// Visitor for Dict<NumericType | TemporalType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<\n+    T, IndexType, enable_if_t<is_number_type<T>::value || is_temporal_type<T>::value>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  using value_type = typename T::c_type;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary), out_(output->GetMutableValues<value_type>(1)) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    *out_++ = value_type{};  // Zero-initialize\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    *out_++ = dictionary_.Value(dict_index);\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  value_type* out_;\n+};\n+\n+template <typename T>\n+struct FromDictUnpackHelper {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  template <typename IndexType>\n+  void Unpack(KernelContext* ctx, const ArrayData& indices, const ArrayType& dictionary,\n+              ArrayData* output) {\n+    FromDictVisitor<T, IndexType> visitor{ctx, dictionary, output};\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Init());\n+    KERNEL_ABORT_IF_ERROR(ctx, ArrayDataVisitor<IndexType>::Visit(indices, &visitor));\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Finish());\n+  }\n+};\n+\n+// Dispatch dictionary casts to UnpackHelper\n+template <typename T>\n+struct FromDictionaryCast {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    const ArrayData& input = *batch[0].array();\n+    ArrayData* output = out->mutable_array();\n+\n+    const DictionaryType& type = checked_cast<const DictionaryType&>(*input.type);\n+    const Array& dictionary = *input.dictionary;\n+    const DataType& values_type = *dictionary.type();\n+\n+    // ARROW-7077\n+    if (!values_type.Equals(*output->type)) {\n+      ctx->SetStatus(Status::Invalid(\"Cannot unpack dictionary of type \", type.ToString(),\n+                                     \" to type \", output->type->ToString()));\n+      return;\n+    }\n+\n+    FromDictUnpackHelper<T> unpack_helper;\n+    switch (type.index_type()->id()) {\n+      case Type::INT8:\n+        unpack_helper.template Unpack<Int8Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT16:\n+        unpack_helper.template Unpack<Int16Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT32:\n+        unpack_helper.template Unpack<Int32Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT64:\n+        unpack_helper.template Unpack<Int64Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      default:\n+        ctx->SetStatus(\n+            Status::TypeError(\"Invalid index type: \", type.index_type()->ToString()));\n+        break;\n+    }\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<NullType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    output->buffers = {nullptr};\n+    output->null_count = batch.length;\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<BooleanType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {}\n+};\n+\n+template <typename T>\n+struct FromNullCast {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    std::shared_ptr<Array> nulls;\n+    Status s = MakeArrayOfNull(output->type, batch.length).Value(&nulls);\n+    KERNEL_ABORT_IF_ERROR(ctx, s);\n+    out->value = nulls->data();\n+  }\n+};\n+\n+// Adds a cast function where the functor is defined and the input and output\n+// types have a type_singleton\n+template <typename InType, typename OutType>\n+void AddSimpleCast(InputType in_ty, OutputType out_ty, CastFunction* func) {\n+  DCHECK_OK(func->AddKernel(InType::type_id, {in_ty}, out_ty,\n+                            CastFunctor<OutType, InType>::Exec));\n+}\n+\n+void ZeroCopyCastExec(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void AddZeroCopyCast(InputType in_type, OutputType out_type, CastFunction* func);\n+\n+// OutputType::Resolver that returns a descr with the shape of the input\n+// argument and the type from CastOptions\n+Result<ValueDescr> ResolveOutputFromOptions(KernelContext* ctx,\n+                                            const std::vector<ValueDescr>& args);\n+\n+template <typename T, typename Enable = void>\n+struct MaybeAddFromDictionary {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {}\n+};\n+\n+template <typename T>\n+struct MaybeAddFromDictionary<\n+    T, enable_if_t<!is_boolean_type<T>::value && !is_nested_type<T>::value &&\n+                   !std::is_same<DictionaryType, T>::value>> {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {\n+    // Dictionary unpacking not implemented for boolean or nested types\n\nReview comment:\n       High-level question: isn't `Cast<ValueType>(Dict(indices, dictionary))` the same as `Take(dictionary, indices)`? So the Take implementation could ideally be reused without additionally hassle.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_boolean.cc\n##########\n@@ -0,0 +1,189 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/common.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+namespace {\n+\n+enum class ResolveNull { KLEENE_LOGIC, PROPAGATE };\n\nReview comment:\n       Still used?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_cast_internal.h\n##########\n@@ -0,0 +1,283 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/builder.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/cast_internal.h\"\n+#include \"arrow/compute/kernels/common.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+namespace internal {\n+\n+template <typename OutType, typename InType, typename Enable = void>\n+struct CastFunctor {};\n+\n+// No-op functor for identity casts\n+template <typename O, typename I>\n+struct CastFunctor<\n+    O, I, enable_if_t<std::is_same<O, I>::value && is_parameter_free_type<I>::value>> {\n+  static void Exec(KernelContext*, const ExecBatch&, Datum*) {}\n+};\n+\n+void CastFromExtension(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Dictionary to other things\n+\n+template <typename T, typename IndexType, typename Enable = void>\n+struct FromDictVisitor {};\n+\n+// Visitor for Dict<FixedSizeBinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_fixed_size_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary),\n+        byte_width_(dictionary.byte_width()),\n+        out_(output->buffers[1]->mutable_data() + byte_width_ * output->offset) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    memset(out_, 0, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    const uint8_t* value = dictionary_.Value(dict_index);\n+    memcpy(out_, value, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  int32_t byte_width_;\n+  uint8_t* out_;\n+};\n+\n+// Visitor for Dict<BinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_base_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : ctx_(ctx), dictionary_(dictionary), output_(output) {}\n+\n+  Status Init() {\n+    RETURN_NOT_OK(MakeBuilder(ctx_->memory_pool(), output_->type, &builder_));\n+    binary_builder_ = checked_cast<BinaryBuilder*>(builder_.get());\n+    return Status::OK();\n+  }\n+\n+  Status VisitNull() { return binary_builder_->AppendNull(); }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    return binary_builder_->Append(dictionary_.GetView(dict_index));\n+  }\n+\n+  Status Finish() {\n+    std::shared_ptr<Array> plain_array;\n+    RETURN_NOT_OK(binary_builder_->Finish(&plain_array));\n+    output_->buffers = plain_array->data()->buffers;\n+    return Status::OK();\n+  }\n+\n+  KernelContext* ctx_;\n+  const ArrayType& dictionary_;\n+  ArrayData* output_;\n+  std::unique_ptr<ArrayBuilder> builder_;\n+  BinaryBuilder* binary_builder_;\n+};\n+\n+// Visitor for Dict<NumericType | TemporalType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<\n+    T, IndexType, enable_if_t<is_number_type<T>::value || is_temporal_type<T>::value>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  using value_type = typename T::c_type;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary), out_(output->GetMutableValues<value_type>(1)) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    *out_++ = value_type{};  // Zero-initialize\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    *out_++ = dictionary_.Value(dict_index);\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  value_type* out_;\n+};\n+\n+template <typename T>\n+struct FromDictUnpackHelper {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  template <typename IndexType>\n+  void Unpack(KernelContext* ctx, const ArrayData& indices, const ArrayType& dictionary,\n+              ArrayData* output) {\n+    FromDictVisitor<T, IndexType> visitor{ctx, dictionary, output};\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Init());\n+    KERNEL_ABORT_IF_ERROR(ctx, ArrayDataVisitor<IndexType>::Visit(indices, &visitor));\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Finish());\n+  }\n+};\n+\n+// Dispatch dictionary casts to UnpackHelper\n+template <typename T>\n+struct FromDictionaryCast {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    const ArrayData& input = *batch[0].array();\n+    ArrayData* output = out->mutable_array();\n+\n+    const DictionaryType& type = checked_cast<const DictionaryType&>(*input.type);\n+    const Array& dictionary = *input.dictionary;\n+    const DataType& values_type = *dictionary.type();\n+\n+    // ARROW-7077\n+    if (!values_type.Equals(*output->type)) {\n+      ctx->SetStatus(Status::Invalid(\"Cannot unpack dictionary of type \", type.ToString(),\n+                                     \" to type \", output->type->ToString()));\n+      return;\n+    }\n+\n+    FromDictUnpackHelper<T> unpack_helper;\n+    switch (type.index_type()->id()) {\n+      case Type::INT8:\n+        unpack_helper.template Unpack<Int8Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT16:\n+        unpack_helper.template Unpack<Int16Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT32:\n+        unpack_helper.template Unpack<Int32Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT64:\n+        unpack_helper.template Unpack<Int64Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      default:\n+        ctx->SetStatus(\n+            Status::TypeError(\"Invalid index type: \", type.index_type()->ToString()));\n+        break;\n+    }\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<NullType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    output->buffers = {nullptr};\n+    output->null_count = batch.length;\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<BooleanType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {}\n+};\n+\n+template <typename T>\n+struct FromNullCast {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    std::shared_ptr<Array> nulls;\n+    Status s = MakeArrayOfNull(output->type, batch.length).Value(&nulls);\n+    KERNEL_ABORT_IF_ERROR(ctx, s);\n+    out->value = nulls->data();\n+  }\n+};\n+\n+// Adds a cast function where the functor is defined and the input and output\n+// types have a type_singleton\n+template <typename InType, typename OutType>\n+void AddSimpleCast(InputType in_ty, OutputType out_ty, CastFunction* func) {\n+  DCHECK_OK(func->AddKernel(InType::type_id, {in_ty}, out_ty,\n+                            CastFunctor<OutType, InType>::Exec));\n+}\n+\n+void ZeroCopyCastExec(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void AddZeroCopyCast(InputType in_type, OutputType out_type, CastFunction* func);\n+\n+// OutputType::Resolver that returns a descr with the shape of the input\n+// argument and the type from CastOptions\n+Result<ValueDescr> ResolveOutputFromOptions(KernelContext* ctx,\n+                                            const std::vector<ValueDescr>& args);\n+\n+template <typename T, typename Enable = void>\n+struct MaybeAddFromDictionary {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {}\n+};\n+\n+template <typename T>\n+struct MaybeAddFromDictionary<\n+    T, enable_if_t<!is_boolean_type<T>::value && !is_nested_type<T>::value &&\n+                   !std::is_same<DictionaryType, T>::value>> {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {\n+    // Dictionary unpacking not implemented for boolean or nested types\n+    DCHECK_OK(func->AddKernel(Type::DICTIONARY, {InputType::Array(Type::DICTIONARY)},\n+                              out_ty, FromDictionaryCast<T>::Exec));\n+  }\n+};\n+\n+template <typename OutType>\n+void AddCommonCasts(OutputType out_ty, CastFunction* func) {\n+  // From null to this type\n+  DCHECK_OK(func->AddKernel(Type::NA, {InputType::Array(null())}, out_ty,\n\nReview comment:\n       If `AddKernel` can fail then we should propagate the errors everywhere, IMHO.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_arithmetic.cc\n##########\n@@ -0,0 +1,52 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/common.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+struct Add {\n+  template <typename OUT, typename ARG0, typename ARG1>\n+  static constexpr OUT Call(KernelContext*, ARG0 left, ARG1 right) {\n+    return left + right;\n+  }\n+};\n+\n+namespace codegen {\n+\n+template <typename Op>\n+void MakeBinaryFunction(std::string name, FunctionRegistry* registry) {\n+  auto func = std::make_shared<ScalarFunction>(name, /*arity=*/2);\n+  for (const std::shared_ptr<DataType>& ty : NumericTypes()) {\n+    DCHECK_OK(func->AddKernel({InputType::Array(ty), InputType::Array(ty)}, ty,\n+                              ScalarNumericEqualTypes::Binary<Op>(*ty)));\n+  }\n+  DCHECK_OK(registry->AddFunction(std::move(func)));\n\nReview comment:\n       We should really propagate errors...\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.cc\n##########\n@@ -0,0 +1,153 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/codegen_internal.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <mutex>\n+#include <vector>\n+\n+#include \"arrow/type_fwd.h\"\n+#include \"arrow/util/logging.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+  ctx->SetStatus(Status::NotImplemented(\"This kernel is malformed\"));\n+}\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out) {\n+  ExecBatch flipped_batch = batch;\n+  Datum tmp = flipped_batch.values[0];\n+  flipped_batch.values[0] = flipped_batch.values[1];\n+  flipped_batch.values[1] = tmp;\n+  exec(ctx, flipped_batch, out);\n+}\n+\n+std::vector<std::shared_ptr<DataType>> g_signed_int_types;\n+std::vector<std::shared_ptr<DataType>> g_unsigned_int_types;\n+std::vector<std::shared_ptr<DataType>> g_int_types;\n+std::vector<std::shared_ptr<DataType>> g_floating_types;\n+std::vector<std::shared_ptr<DataType>> g_numeric_types;\n+std::vector<std::shared_ptr<DataType>> g_base_binary_types;\n+std::vector<std::shared_ptr<DataType>> g_temporal_types;\n+std::vector<std::shared_ptr<DataType>> g_primitive_types;\n+static std::once_flag codegen_static_initialized;\n+\n+static void InitStaticData() {\n+  // Signed int types\n+  g_signed_int_types.push_back(int8());\n+  g_signed_int_types.push_back(int16());\n+  g_signed_int_types.push_back(int32());\n+  g_signed_int_types.push_back(int64());\n+\n+  // Unsigned int types\n+  g_unsigned_int_types.push_back(uint8());\n+  g_unsigned_int_types.push_back(uint16());\n+  g_unsigned_int_types.push_back(uint32());\n+  g_unsigned_int_types.push_back(uint64());\n+\n+  // All int types\n+  Extend(g_unsigned_int_types, &g_int_types);\n+  Extend(g_signed_int_types, &g_int_types);\n+\n+  // Floating point types\n+  g_floating_types.push_back(float32());\n+  g_floating_types.push_back(float64());\n+\n+  // Numeric types\n+  Extend(g_int_types, &g_numeric_types);\n+  Extend(g_floating_types, &g_numeric_types);\n+\n+  // Temporal types\n+  g_temporal_types.push_back(date32());\n+  g_temporal_types.push_back(date64());\n+  g_temporal_types.push_back(time32(TimeUnit::SECOND));\n+  g_temporal_types.push_back(time32(TimeUnit::MILLI));\n+  g_temporal_types.push_back(time64(TimeUnit::MICRO));\n+  g_temporal_types.push_back(time64(TimeUnit::NANO));\n+  g_temporal_types.push_back(timestamp(TimeUnit::SECOND));\n+  g_temporal_types.push_back(timestamp(TimeUnit::MILLI));\n+  g_temporal_types.push_back(timestamp(TimeUnit::MICRO));\n+  g_temporal_types.push_back(timestamp(TimeUnit::NANO));\n+\n+  // Base binary types (without FixedSizeBinary)\n+  g_base_binary_types.push_back(binary());\n+  g_base_binary_types.push_back(utf8());\n+  g_base_binary_types.push_back(large_binary());\n+  g_base_binary_types.push_back(large_utf8());\n+\n+  // Non-parametric, non-nested types. This also DOES NOT include\n+  //\n+  // * Decimal\n+  // * Fixed Size Binary\n+  g_primitive_types.push_back(null());\n+  g_primitive_types.push_back(boolean());\n+  Extend(g_numeric_types, &g_primitive_types);\n+  Extend(g_temporal_types, &g_primitive_types);\n+  Extend(g_base_binary_types, &g_primitive_types);\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes() {\n+  std::call_once(codegen_static_initialized, InitStaticData);\n+  return g_base_binary_types;\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes() {\n+  std::call_once(codegen_static_initialized, InitStaticData);\n\nReview comment:\n       How about:\r\n   ```c++\r\n   static std::vector<std::shared_ptr<DataType>> g_signed_int_types{int8(), int16(), int32(), int64()};\r\n   ```\n\n##########\nFile path: cpp/src/arrow/compute/function.h\n##########\n@@ -0,0 +1,203 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// NOTE: API is EXPERIMENTAL and will change without going through a\n+// deprecation cycle\n+\n+#pragma once\n+\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/compute/options.h\"  // IWYU pragma: keep\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+struct ValueDescr;\n+\n+namespace compute {\n+\n+/// \\brief Contains the number of required arguments for the function\n+struct ARROW_EXPORT FunctionArity {\n+  static FunctionArity Nullary() { return FunctionArity(0, false); }\n+  static FunctionArity Unary() { return FunctionArity(1, false); }\n+  static FunctionArity Binary() { return FunctionArity(2, false); }\n+  static FunctionArity Ternary() { return FunctionArity(3, false); }\n+  static FunctionArity Varargs(int min_args = 1) { return FunctionArity(min_args, true); }\n+\n+  FunctionArity(int num_args, bool is_varargs = false)  // NOLINT implicit conversion\n+      : num_args(num_args), is_varargs(is_varargs) {}\n+\n+  /// The number of required arguments (or the minimum number for varargs\n+  /// functions)\n+  int num_args;\n+\n+  /// If true, then the num_args is the minimum number of required arguments\n+  bool is_varargs = false;\n+};\n+\n+/// \\brief Base class for function containers that are capable of dispatch to\n+/// kernel implementations\n+class ARROW_EXPORT Function {\n+ public:\n+  /// \\brief The kind of function, which indicates in what contexts it is\n+  /// valid for use\n+  enum Kind {\n+    /// A function that performs scalar data operations on whole arrays of\n+    /// data. Can generally process Array or Scalar values. The size of the\n+    /// output will be the same as the size (or broadcasted size, in the case\n+    /// of mixing Array and Scalar inputs) of the input.\n+    SCALAR,\n+\n+    /// A function with array input and output whose behavior depends on the\n+    /// values of the entire arrays passed, rather than the value of each scalar\n+    /// value.\n+    VECTOR,\n+\n+    /// A function that computes scalar summary statistics from array input.\n+    SCALAR_AGGREGATE\n+  };\n+\n+  virtual ~Function() = default;\n+\n+  /// \\brief The name of the kernel. The registry enforces uniqueness of names\n+  const std::string& name() const { return name_; }\n+\n+  /// \\brief The kind of kernel, which indicates in what contexts it is valid\n+  /// for use\n+  Function::Kind kind() const { return kind_; }\n+\n+  /// \\brief Contains the number of arguments the function requires\n+  const FunctionArity& arity() const { return arity_; }\n+\n+  /// \\brief Returns the number of registered kernels for this function\n+  virtual int num_kernels() const = 0;\n+\n+  /// \\brief Convenience for invoking a function with kernel dispatch and\n+  /// memory allocation details taken care of\n+  Result<Datum> Execute(const std::vector<Datum>& args, const FunctionOptions* options,\n+                        ExecContext* ctx = NULLPTR) const;\n+\n+ protected:\n+  Function(std::string name, Function::Kind kind, const FunctionArity& arity)\n+      : name_(std::move(name)), kind_(kind), arity_(arity) {}\n+  std::string name_;\n+  Function::Kind kind_;\n+  FunctionArity arity_;\n+};\n+\n+namespace detail {\n+\n+template <typename KernelType>\n+class FunctionImpl : public Function {\n+ public:\n+  /// \\brief Return vector of all available kernels for this function\n+  const std::vector<KernelType>& kernels() const { return kernels_; }\n+\n+  int num_kernels() const override { return static_cast<int>(kernels_.size()); }\n+\n+ protected:\n+  FunctionImpl(std::string name, Function::Kind kind, const FunctionArity& arity)\n+      : Function(std::move(name), kind, arity) {}\n+\n+  std::vector<KernelType> kernels_;\n+};\n+\n+}  // namespace detail\n+\n+/// \\brief A function that executes elementwise operations on arrays or\n+/// scalars, and therefore whose results generally do not depend on the order\n+/// of the values in the arguments. Accepts and returns arrays that are all of\n+/// the same size. These functions roughly correspond to the functions used in\n+/// SQL expressions.\n+class ARROW_EXPORT ScalarFunction : public detail::FunctionImpl<ScalarKernel> {\n+ public:\n+  using KernelType = ScalarKernel;\n+\n+  ScalarFunction(std::string name, const FunctionArity& arity)\n+      : detail::FunctionImpl<ScalarKernel>(std::move(name), Function::SCALAR, arity) {}\n+\n+  /// \\brief Add a simple kernel (function implementation) with given\n+  /// input/output types, no required state initialization, preallocation for\n+  /// fixed-width types, and default null handling (intersect validity bitmaps\n+  /// of inputs)\n+  Status AddKernel(std::vector<InputType> in_types, OutputType out_type,\n+                   ArrayKernelExec exec, KernelInit init = NULLPTR);\n+\n+  /// \\brief Add a kernel (function implementation). Returns error if fails\n+  /// to match the other parameters of the function\n+  Status AddKernel(ScalarKernel kernel);\n+\n+  /// \\brief Return the first kernel that can execute the function given the\n+  /// exact argument types (without implicit type casts or scalar->array\n+  /// promotions)\n+  virtual Result<const ScalarKernel*> DispatchExact(\n\nReview comment:\n       Why `virtual`? Are there subclasses?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n\nReview comment:\n       `KERNEL_RETURN_IF_ERROR`? It doesn't abort...\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n\nReview comment:\n       Why the copy?\n\n##########\nFile path: cpp/src/arrow/compute/kernel.cc\n##########\n@@ -0,0 +1,308 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernel.h\"\n+\n+#include <cstddef>\n+#include <memory>\n+#include <sstream>\n+#include <string>\n+\n+#include \"arrow/buffer.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/hashing.h\"\n\nReview comment:\n       Required? This pulls a lot of stuff.\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n+  template <typename Op, typename OutType, typename Arg0Type>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0>(ctx, *arg0_data++);\n+      }\n+    }\n+  }\n+\n+  template <typename Op, typename OutType, typename Arg0Type, typename Arg1Type>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+    using ARG1 = typename Arg1Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      auto arg1_data = batch[1].array()->GetValues<ARG1>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0, ARG1>(ctx, *arg0_data++, *arg1_data++);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct OutputAdapter;\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_bitmap = out_arr->buffers[1]->mutable_data();\n+    GenerateBitsUnrolled(out_bitmap, out_arr->offset, out_arr->length,\n+                         std::forward<Generator>(generator));\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_data = out_arr->GetMutableValues<typename Type::c_type>(kPrimitiveData);\n+    // TODO: Is this as fast as a more explicitly inlined function?\n+    for (int64_t i = 0 ; i < out_arr->length; ++i) {\n+      *out_data++ = generator();\n+    }\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_base_binary<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext* ctx, Datum* out, Generator&& generator) {\n+    ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnary {\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  static void Array(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return Op::template Call<OUT, ARG0>(ctx, arg0());\n+    });\n+  }\n+\n+  static void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(Op::template Call<OUT, ARG0>(ctx, arg0),\n+                                               out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      return Array(ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+// Applies a scalar operation with state on the null-null values of a single\n\nReview comment:\n       \"non-null\"?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/CMakeLists.txt\n##########\n@@ -15,37 +15,41 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-arrow_install_all_headers(\"arrow/compute/kernels\")\n-\n-add_arrow_compute_test(boolean_test)\n-add_arrow_compute_test(cast_test)\n-add_arrow_compute_test(hash_test)\n-add_arrow_compute_test(isin_test)\n-add_arrow_compute_test(match_test)\n-add_arrow_compute_test(sort_to_indices_test)\n-add_arrow_compute_test(nth_to_indices_test)\n-add_arrow_compute_test(util_internal_test)\n-add_arrow_compute_test(add_test)\n+# ----------------------------------------------------------------------\n+# Scalar kernels\n \n-# Aggregates\n-add_arrow_compute_test(aggregate_test)\n+add_arrow_compute_test(scalar_test\n+                       SOURCES\n+                       scalar_arithmetic_test.cc\n+                       scalar_boolean_test.cc\n+                       scalar_cast_test.cc\n+                       scalar_compare_test.cc\n+                       scalar_set_lookup_test.cc)\n \n-# Comparison\n-add_arrow_compute_test(compare_test)\n+# add_arrow_compute_test(cast_test)\n \n-# Selection\n-add_arrow_compute_test(take_test)\n-add_arrow_compute_test(filter_test)\n+add_arrow_benchmark(scalar_compare_benchmark PREFIX \"arrow-compute\")\n \n-add_arrow_benchmark(sort_to_indices_benchmark PREFIX \"arrow-compute\")\n-add_arrow_benchmark(nth_to_indices_benchmark PREFIX \"arrow-compute\")\n+# ----------------------------------------------------------------------\n+# Vector kernels\n \n-# Aggregates\n-add_arrow_benchmark(aggregate_benchmark PREFIX \"arrow-compute\")\n+add_arrow_compute_test(vector_test\n+                       SOURCES\n+                       vector_filter_test.cc\n+                       vector_hash_test.cc\n+                       vector_take_test.cc\n+                       vector_sort_test.cc)\n+\n+# add_arrow_benchmark(vector_hash_benchmark PREFIX \"arrow-compute\")\n+# add_arrow_benchmark(vector_sort_benchmark PREFIX \"arrow-compute\")\n+# add_arrow_benchmark(vector_partition_benchmark PREFIX \"arrow-compute\")\n+# add_arrow_benchmark(vector_filter_benchmark PREFIX \"arrow-compute\")a\n+# add_arrow_benchmark(vector_take_benchmark PREFIX \"arrow-compute\")\n\nReview comment:\n       Should the benchmarks be re-enabled?\n\n##########\nFile path: cpp/src/arrow/compute/kernel.h\n##########\n@@ -15,295 +15,517 @@\n // specific language governing permissions and limitations\n // under the License.\n \n+// NOTE: API is EXPERIMENTAL and will change without going through a\n+// deprecation cycle\n+\n #pragma once\n \n+#include <cstdint>\n+#include <functional>\n #include <memory>\n+#include <string>\n #include <utility>\n #include <vector>\n \n-#include \"arrow/array.h\"\n-#include \"arrow/record_batch.h\"\n-#include \"arrow/scalar.h\"\n-#include \"arrow/table.h\"\n-#include \"arrow/util/macros.h\"\n-#include \"arrow/util/memory.h\"\n-#include \"arrow/util/variant.h\"  // IWYU pragma: export\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/datum.h\"\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/type.h\"\n #include \"arrow/util/visibility.h\"\n \n namespace arrow {\n+\n+class Buffer;\n+struct Datum;\n+\n namespace compute {\n \n-class FunctionContext;\n+struct FunctionOptions;\n \n-/// \\class OpKernel\n-/// \\brief Base class for operator kernels\n-///\n-/// Note to implementors:\n-/// Operator kernels are intended to be the lowest level of an analytics/compute\n-/// engine.  They will generally not be exposed directly to end-users.  Instead\n-/// they will be wrapped by higher level constructs (e.g. top-level functions\n-/// or physical execution plan nodes).  These higher level constructs are\n-/// responsible for user input validation and returning the appropriate\n-/// error Status.\n-///\n-/// Due to this design, implementations of Call (the execution\n-/// method on subclasses) should use assertions (i.e. DCHECK) to double-check\n-/// parameter arguments when in higher level components returning an\n-/// InvalidArgument error might be more appropriate.\n-///\n-class ARROW_EXPORT OpKernel {\n+/// \\brief Base class for opaque kernel-specific state. For example, if there\n+/// is some kind of initialization required\n+struct KernelState {\n+  virtual ~KernelState() = default;\n+};\n+\n+/// \\brief Context/state for the execution of a particular kernel\n+class ARROW_EXPORT KernelContext {\n  public:\n-  virtual ~OpKernel() = default;\n-  /// \\brief EXPERIMENTAL The output data type of the kernel\n-  /// \\return the output type\n-  virtual std::shared_ptr<DataType> out_type() const = 0;\n+  explicit KernelContext(ExecContext* exec_ctx) : exec_ctx_(exec_ctx) {}\n+\n+  /// \\brief Allocate buffer from the context's memory pool\n+  Result<std::shared_ptr<Buffer>> Allocate(int64_t nbytes);\n+\n+  /// \\brief Allocate buffer for bitmap from the context's memory pool\n+  Result<std::shared_ptr<Buffer>> AllocateBitmap(int64_t num_bits);\n+\n+  /// \\brief Indicate that an error has occurred, to be checked by a exec caller\n+  /// \\param[in] status a Status instance\n+  ///\n+  /// \\note Will not overwrite a prior set Status, so we will have the first\n+  /// error that occurred until ExecContext::ResetStatus is called\n+  void SetStatus(const Status& status);\n+\n+  /// \\brief Clear any error status\n+  void ResetStatus();\n+\n+  /// \\brief Return true if an error has occurred\n+  bool HasError() const { return !status_.ok(); }\n+\n+  /// \\brief Return the current status of the context\n+  const Status& status() const { return status_; }\n+\n+  // For passing kernel state to\n+  void SetState(KernelState* state) { state_ = state; }\n+\n+  KernelState* state() { return state_; }\n+\n+  /// \\brief Common state related to function execution\n+  ExecContext* exec_context() { return exec_ctx_; }\n+\n+  MemoryPool* memory_pool() { return exec_ctx_->memory_pool(); }\n+\n+ private:\n+  ExecContext* exec_ctx_;\n+  Status status_;\n+  KernelState* state_;\n };\n \n-struct Datum;\n-static inline bool CollectionEquals(const std::vector<Datum>& left,\n-                                    const std::vector<Datum>& right);\n-\n-// Datums variants may have a length. This special value indicate that the\n-// current variant does not have a length.\n-constexpr int64_t kUnknownLength = -1;\n-\n-/// \\class Datum\n-/// \\brief Variant type for various Arrow C++ data structures\n-struct ARROW_EXPORT Datum {\n-  enum type { NONE, SCALAR, ARRAY, CHUNKED_ARRAY, RECORD_BATCH, TABLE, COLLECTION };\n-\n-  util::variant<decltype(NULLPTR), std::shared_ptr<Scalar>, std::shared_ptr<ArrayData>,\n-                std::shared_ptr<ChunkedArray>, std::shared_ptr<RecordBatch>,\n-                std::shared_ptr<Table>, std::vector<Datum>>\n-      value;\n-\n-  /// \\brief Empty datum, to be populated elsewhere\n-  Datum() : value(NULLPTR) {}\n-\n-  Datum(const std::shared_ptr<Scalar>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::shared_ptr<ArrayData>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-\n-  Datum(const std::shared_ptr<Array>& value)  // NOLINT implicit conversion\n-      : Datum(value ? value->data() : NULLPTR) {}\n-\n-  Datum(const std::shared_ptr<ChunkedArray>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::shared_ptr<RecordBatch>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::shared_ptr<Table>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-  Datum(const std::vector<Datum>& value)  // NOLINT implicit conversion\n-      : value(value) {}\n-\n-  // Cast from subtypes of Array to Datum\n-  template <typename T, typename = enable_if_t<std::is_base_of<Array, T>::value>>\n-  Datum(const std::shared_ptr<T>& value)  // NOLINT implicit conversion\n-      : Datum(std::shared_ptr<Array>(value)) {}\n-\n-  // Convenience constructors\n-  explicit Datum(bool value) : value(std::make_shared<BooleanScalar>(value)) {}\n-  explicit Datum(int8_t value) : value(std::make_shared<Int8Scalar>(value)) {}\n-  explicit Datum(uint8_t value) : value(std::make_shared<UInt8Scalar>(value)) {}\n-  explicit Datum(int16_t value) : value(std::make_shared<Int16Scalar>(value)) {}\n-  explicit Datum(uint16_t value) : value(std::make_shared<UInt16Scalar>(value)) {}\n-  explicit Datum(int32_t value) : value(std::make_shared<Int32Scalar>(value)) {}\n-  explicit Datum(uint32_t value) : value(std::make_shared<UInt32Scalar>(value)) {}\n-  explicit Datum(int64_t value) : value(std::make_shared<Int64Scalar>(value)) {}\n-  explicit Datum(uint64_t value) : value(std::make_shared<UInt64Scalar>(value)) {}\n-  explicit Datum(float value) : value(std::make_shared<FloatScalar>(value)) {}\n-  explicit Datum(double value) : value(std::make_shared<DoubleScalar>(value)) {}\n-\n-  ~Datum() {}\n-\n-  Datum(const Datum& other) noexcept { this->value = other.value; }\n-\n-  Datum& operator=(const Datum& other) noexcept {\n-    value = other.value;\n-    return *this;\n-  }\n+#define ARROW_CTX_RETURN_IF_ERROR(CTX)            \\\n+  do {                                            \\\n+    if (ARROW_PREDICT_FALSE((CTX)->HasError())) { \\\n+      Status s = (CTX)->status();                 \\\n+      (CTX)->ResetStatus();                       \\\n+      return s;                                   \\\n+    }                                             \\\n+  } while (0)\n+\n+/// A standard function taking zero or more Array/Scalar values and returning\n+/// Array/Scalar output. May be used for SCALAR and VECTOR kernel kinds. Should\n+/// write into pre-allocated memory except in cases when a builder\n+/// (e.g. StringBuilder) must be employed\n+using ArrayKernelExec = std::function<void(KernelContext*, const ExecBatch&, Datum*)>;\n+\n+/// \\brief A container to express what kernel argument input types are accepted\n+class ARROW_EXPORT InputType {\n+ public:\n+  enum Kind {\n+    /// Accept any value type\n+    ANY_TYPE,\n \n-  // Define move constructor and move assignment, for better performance\n-  Datum(Datum&& other) noexcept : value(std::move(other.value)) {}\n+    /// A fixed arrow::DataType and will only exact match having this exact\n+    /// type (e.g. same TimestampType unit, same decimal scale and precision,\n+    /// or same nested child types\n+    EXACT_TYPE,\n \n-  Datum& operator=(Datum&& other) noexcept {\n-    value = std::move(other.value);\n-    return *this;\n-  }\n+    /// Any type having the indicated Type::type id. For example, accept\n+    /// any Type::LIST or any Type::TIMESTAMP\n+    SAME_TYPE_ID,\n+  };\n \n-  Datum::type kind() const {\n-    switch (this->value.index()) {\n-      case 0:\n-        return Datum::NONE;\n-      case 1:\n-        return Datum::SCALAR;\n-      case 2:\n-        return Datum::ARRAY;\n-      case 3:\n-        return Datum::CHUNKED_ARRAY;\n-      case 4:\n-        return Datum::RECORD_BATCH;\n-      case 5:\n-        return Datum::TABLE;\n-      case 6:\n-        return Datum::COLLECTION;\n-      default:\n-        return Datum::NONE;\n-    }\n-  }\n+  InputType(ValueDescr::Shape shape = ValueDescr::ANY)  // NOLINT implicit construction\n+      : kind_(ANY_TYPE), shape_(shape) {}\n \n-  std::shared_ptr<ArrayData> array() const {\n-    return util::get<std::shared_ptr<ArrayData>>(this->value);\n-  }\n+  InputType(std::shared_ptr<DataType> type,\n+            ValueDescr::Shape shape = ValueDescr::ANY)  // NOLINT implicit construction\n+      : kind_(EXACT_TYPE), shape_(shape), type_(std::move(type)), type_id_(type_->id()) {}\n \n-  std::shared_ptr<Array> make_array() const {\n-    return MakeArray(util::get<std::shared_ptr<ArrayData>>(this->value));\n-  }\n+  InputType(const ValueDescr& descr)  // NOLINT implicit construction\n+      : InputType(descr.type, descr.shape) {}\n \n-  std::shared_ptr<ChunkedArray> chunked_array() const {\n-    return util::get<std::shared_ptr<ChunkedArray>>(this->value);\n-  }\n+  InputType(Type::type type_id,\n+            ValueDescr::Shape shape = ValueDescr::ANY)  // NOLINT implicit construction\n+      : kind_(SAME_TYPE_ID), shape_(shape), type_id_(type_id) {}\n \n-  std::shared_ptr<RecordBatch> record_batch() const {\n-    return util::get<std::shared_ptr<RecordBatch>>(this->value);\n-  }\n+  InputType(const InputType& other) { CopyInto(other); }\n \n-  std::shared_ptr<Table> table() const {\n-    return util::get<std::shared_ptr<Table>>(this->value);\n+  // Convenience ctors\n+  static InputType Array(std::shared_ptr<DataType> type) {\n+    return InputType(std::move(type), ValueDescr::ARRAY);\n   }\n \n-  const std::vector<Datum> collection() const {\n-    return util::get<std::vector<Datum>>(this->value);\n+  static InputType Scalar(std::shared_ptr<DataType> type) {\n+    return InputType(std::move(type), ValueDescr::SCALAR);\n   }\n \n-  std::shared_ptr<Scalar> scalar() const {\n-    return util::get<std::shared_ptr<Scalar>>(this->value);\n-  }\n+  static InputType Array(Type::type id) { return InputType(id, ValueDescr::ARRAY); }\n \n-  bool is_array() const { return this->kind() == Datum::ARRAY; }\n+  static InputType Scalar(Type::type id) { return InputType(id, ValueDescr::SCALAR); }\n \n-  bool is_arraylike() const {\n-    return this->kind() == Datum::ARRAY || this->kind() == Datum::CHUNKED_ARRAY;\n-  }\n+  void operator=(const InputType& other) { CopyInto(other); }\n \n-  bool is_scalar() const { return this->kind() == Datum::SCALAR; }\n+  InputType(InputType&& other) { MoveInto(std::forward<InputType>(other)); }\n \n-  bool is_collection() const { return this->kind() == Datum::COLLECTION; }\n+  void operator=(InputType&& other) { MoveInto(std::forward<InputType>(other)); }\n \n-  /// \\brief The value type of the variant, if any\n-  ///\n-  /// \\return nullptr if no type\n-  std::shared_ptr<DataType> type() const {\n-    if (this->kind() == Datum::ARRAY) {\n-      return util::get<std::shared_ptr<ArrayData>>(this->value)->type;\n-    } else if (this->kind() == Datum::CHUNKED_ARRAY) {\n-      return util::get<std::shared_ptr<ChunkedArray>>(this->value)->type();\n-    } else if (this->kind() == Datum::SCALAR) {\n-      return util::get<std::shared_ptr<Scalar>>(this->value)->type;\n-    }\n-    return NULLPTR;\n+  /// \\brief Return true if this type exactly matches another\n+  bool Equals(const InputType& other) const;\n+\n+  bool operator==(const InputType& other) const { return this->Equals(other); }\n+\n+  bool operator!=(const InputType& other) const { return !(*this == other); }\n+\n+  /// \\brief Return hash code\n+  uint64_t Hash() const;\n+\n+  /// \\brief Render a human-readable string representation\n+  std::string ToString() const;\n+\n+  /// \\brief Return true if the value matches this argument kind in type\n+  /// and shape\n+  bool Matches(const Datum& value) const;\n+\n+  /// \\brief Return true if the value descriptor matches this argument kind in\n+  /// type and shape\n+  bool Matches(const ValueDescr& value) const;\n+\n+  /// \\brief The type matching rule that this InputType uses\n+  Kind kind() const { return kind_; }\n+\n+  ValueDescr::Shape shape() const { return shape_; }\n+\n+  /// \\brief For ArgKind::EXACT_TYPE, the exact type that this InputType must\n+  /// match. Otherwise this function should not be used\n+  const std::shared_ptr<DataType>& type() const;\n+\n+  /// \\brief For ArgKind::SAME_TYPE_ID, the Type::type that this InputType must\n+  /// match, Otherwise this function should not be used\n+  Type::type type_id() const;\n+\n+ private:\n+  void CopyInto(const InputType& other) {\n+    this->kind_ = other.kind_;\n+    this->shape_ = other.shape_;\n+    this->type_ = other.type_;\n+    this->type_id_ = other.type_id_;\n   }\n \n-  /// \\brief The value length of the variant, if any\n-  ///\n-  /// \\return kUnknownLength if no type\n-  int64_t length() const {\n-    if (this->kind() == Datum::ARRAY) {\n-      return util::get<std::shared_ptr<ArrayData>>(this->value)->length;\n-    } else if (this->kind() == Datum::CHUNKED_ARRAY) {\n-      return util::get<std::shared_ptr<ChunkedArray>>(this->value)->length();\n-    } else if (this->kind() == Datum::SCALAR) {\n-      return 1;\n-    }\n-    return kUnknownLength;\n+  void MoveInto(InputType&& other) {\n+    this->kind_ = other.kind_;\n+    this->shape_ = other.shape_;\n+    this->type_ = std::move(other.type_);\n+    this->type_id_ = other.type_id_;\n   }\n \n-  /// \\brief The array chunks of the variant, if any\n-  ///\n-  /// \\return empty if not arraylike\n-  ArrayVector chunks() const {\n-    if (!this->is_arraylike()) {\n-      return {};\n-    }\n-    if (this->is_array()) {\n-      return {this->make_array()};\n-    }\n-    return this->chunked_array()->chunks();\n+  Kind kind_;\n+\n+  ValueDescr::Shape shape_ = ValueDescr::ANY;\n+\n+  // For EXACT_TYPE ArgKind\n+  std::shared_ptr<DataType> type_;\n+\n+  // For SAME_TYPE_ID ArgKind\n+  Type::type type_id_ = Type::NA;\n+};\n+\n+/// \\brief Container to capture both exact and input-dependent output types\n+///\n+/// The value shape returned by Resolve will be determined by broadcasting the\n+/// shapes of the input arguments, otherwise this is handled by the\n+/// user-defined resolver function\n+///\n+/// * Any ARRAY shape -> output shape is ARRAY\n+/// * All SCALAR shapes -> output shape is SCALAR\n+class ARROW_EXPORT OutputType {\n+ public:\n+  /// \\brief An enum indicating whether the value type is an invariant fixed\n+  /// value or one that's computed by a kernel-defined resolver function\n+  enum ResolveKind { FIXED, COMPUTED };\n+\n+  /// Type resolution function. Given input types and shapes, return output\n+  /// type and shape. This function SHOULD _not_ be used to check for arity,\n+  /// that SHOULD be performed one or more layers above. May make use of kernel\n+  /// state to know what type to output\n+  using Resolver =\n+      std::function<Result<ValueDescr>(KernelContext*, const std::vector<ValueDescr>&)>;\n+\n+  OutputType(std::shared_ptr<DataType> type)  // NOLINT implicit construction\n+      : kind_(FIXED), type_(std::move(type)) {}\n+\n+  /// For outputting a particular type and shape\n+  OutputType(ValueDescr descr);  // NOLINT implicit construction\n+\n+  explicit OutputType(Resolver resolver) : kind_(COMPUTED), resolver_(resolver) {}\n+\n+  OutputType(const OutputType& other) {\n+    this->kind_ = other.kind_;\n+    this->shape_ = other.shape_;\n+    this->type_ = other.type_;\n+    this->resolver_ = other.resolver_;\n   }\n \n-  bool Equals(const Datum& other) const {\n-    if (this->kind() != other.kind()) return false;\n-\n-    switch (this->kind()) {\n-      case Datum::NONE:\n-        return true;\n-      case Datum::SCALAR:\n-        return internal::SharedPtrEquals(this->scalar(), other.scalar());\n-      case Datum::ARRAY:\n-        return internal::SharedPtrEquals(this->make_array(), other.make_array());\n-      case Datum::CHUNKED_ARRAY:\n-        return internal::SharedPtrEquals(this->chunked_array(), other.chunked_array());\n-      case Datum::RECORD_BATCH:\n-        return internal::SharedPtrEquals(this->record_batch(), other.record_batch());\n-      case Datum::TABLE:\n-        return internal::SharedPtrEquals(this->table(), other.table());\n-      case Datum::COLLECTION:\n-        return CollectionEquals(this->collection(), other.collection());\n-      default:\n-        return false;\n-    }\n+  OutputType(OutputType&& other) {\n+    this->kind_ = other.kind_;\n+    this->type_ = std::move(other.type_);\n+    this->shape_ = other.shape_;\n+    this->resolver_ = other.resolver_;\n   }\n+\n+  /// \\brief Return the shape and type of the expected output value of the\n+  /// kernel given the value descriptors (shapes and types). The resolver may\n+  /// make use of state information kept in the KernelContext\n+  Result<ValueDescr> Resolve(KernelContext* ctx,\n+                             const std::vector<ValueDescr>& args) const;\n+\n+  /// \\brief The value type for the FIXED kind rule\n+  const std::shared_ptr<DataType>& type() const;\n+\n+  /// \\brief For use with COMPUTED resolution strategy, the output type depends\n+  /// on the input type. It may be more convenient to invoke this with\n+  /// OutputType::Resolve returned from this method\n+  const Resolver& resolver() const;\n+\n+  /// \\brief Render a human-readable string representation\n+  std::string ToString() const;\n+\n+  /// \\brief Return the kind of type resolution of this output type, whether\n+  /// fixed/invariant or computed by a \"user\"-defined resolver\n+  ResolveKind kind() const { return kind_; }\n+\n+  /// \\brief If the shape is ANY, then Resolve will compute the shape based on\n+  /// the input arguments\n+  ValueDescr::Shape shape() const { return shape_; }\n+\n+ private:\n+  ResolveKind kind_;\n+\n+  // For FIXED resolution\n+  std::shared_ptr<DataType> type_;\n+\n+  ValueDescr::Shape shape_ = ValueDescr::ANY;\n+\n+  // For COMPUTED resolution\n+  Resolver resolver_;\n };\n \n-/// \\class UnaryKernel\n-/// \\brief An array-valued function of a single input argument.\n+/// \\brief Holds the input types and output type of the kernel\n ///\n-/// Note to implementors:  Try to avoid making kernels that allocate memory if\n-/// the output size is a deterministic function of the Input Datum's metadata.\n-/// Instead separate the logic of the kernel and allocations necessary into\n-/// two different kernels.  Some reusable kernels that allocate buffers\n-/// and delegate computation to another kernel are available in util-internal.h.\n-class ARROW_EXPORT UnaryKernel : public OpKernel {\n+/// Varargs functions should pass a single input type to be used to validate\n+/// the the input types of a function invocation\n+class ARROW_EXPORT KernelSignature {\n  public:\n-  /// \\brief Executes the kernel.\n-  ///\n-  /// \\param[in] ctx The function context for the kernel\n-  /// \\param[in] input The kernel input data\n-  /// \\param[out] out The output of the function. Each implementation of this\n-  /// function might assume different things about the existing contents of out\n-  /// (e.g. which buffers are preallocated).  In the future it is expected that\n-  /// there will be a more generic mechanism for understanding the necessary\n-  /// contracts.\n-  virtual Status Call(FunctionContext* ctx, const Datum& input, Datum* out) = 0;\n+  KernelSignature(std::vector<InputType> in_types, OutputType out_type,\n+                  bool is_varargs = false);\n+\n+  /// \\brief Convenience ctor since make_shared can be awkward\n+  static std::shared_ptr<KernelSignature> Make(std::vector<InputType> in_types,\n+                                               OutputType out_type,\n+                                               bool is_varargs = false);\n+\n+  /// \\brief Return true if the signature if compatible with the list of input\n+  /// value descriptors\n+  bool MatchesInputs(const std::vector<ValueDescr>& descriptors) const;\n+\n+  /// \\brief Returns true if the input types of each signature are\n+  /// equal. Well-formed functions should have a deterministic output type\n+  /// given input types, but currently it is the responsibility of the\n+  /// developer to ensure this\n+  bool Equals(const KernelSignature& other) const;\n+\n+  bool operator==(const KernelSignature& other) const { return this->Equals(other); }\n+\n+  bool operator!=(const KernelSignature& other) const { return !(*this == other); }\n+\n+  /// \\brief Compute a hash code for the signature\n+  int64_t Hash() const;\n+\n+  const std::vector<InputType>& in_types() const { return in_types_; }\n+\n+  const OutputType& out_type() const { return out_type_; }\n+\n+  /// \\brief Render a human-readable string representation\n+  std::string ToString() const;\n+\n+  bool is_varargs() const { return is_varargs_; }\n+\n+ private:\n+  std::vector<InputType> in_types_;\n+  OutputType out_type_;\n+  bool is_varargs_;\n+\n+  // For caching the hash code after it's computed the first time\n+  mutable int64_t hash_code_;\n };\n \n-/// \\class BinaryKernel\n-/// \\brief An array-valued function of a two input arguments\n-class ARROW_EXPORT BinaryKernel : public OpKernel {\n- public:\n-  virtual Status Call(FunctionContext* ctx, const Datum& left, const Datum& right,\n-                      Datum* out) = 0;\n+struct SimdLevel {\n+  enum type { NONE, SSE4_2, AVX, AVX2, AVX512, NEON };\n };\n \n-// TODO doxygen 1.8.16 does not like the following code\n-///@cond INTERNAL\n+struct NullHandling {\n+  enum type {\n+    /// Compute the output validity bitmap by intersecting the validity bitmaps\n+    /// of the arguments. Kernel does not do anything with the bitmap\n+    INTERSECTION,\n \n-static inline bool CollectionEquals(const std::vector<Datum>& left,\n-                                    const std::vector<Datum>& right) {\n-  if (left.size() != right.size()) {\n-    return false;\n-  }\n+    /// Kernel expects a pre-allocated buffer to write the result bitmap into\n+    COMPUTED_PREALLOCATE,\n \n-  for (size_t i = 0; i < left.size(); i++) {\n-    if (!left[i].Equals(right[i])) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n+    /// Kernel allocates and populates the validity bitmap of the output\n+    COMPUTED_NO_PREALLOCATE,\n+\n+    /// Output is never null\n+    OUTPUT_NOT_NULL\n+  };\n+};\n+\n+struct MemAllocation {\n+  enum type {\n+    // For data types that support pre-allocation (fixed-type), the kernel\n+    // expects to be provided pre-allocated memory to write\n+    // into. Non-fixed-width must always allocate their own memory but perhaps\n+    // not their validity bitmaps. The allocation made for the same length as\n+    // the execution batch, so vector kernels yielding differently sized output\n+    // should not use this\n+    PREALLOCATE,\n+\n+    // The kernel does its own memory allocation\n+    NO_PREALLOCATE\n+  };\n+};\n+\n+struct Kernel;\n+\n+struct KernelInitArgs {\n+  const Kernel* kernel;\n+  const std::vector<ValueDescr>& inputs;\n+  const FunctionOptions* options;\n+};\n+\n+// Kernel initializer (context, argument descriptors, options)\n+using KernelInit =\n+    std::function<std::unique_ptr<KernelState>(KernelContext*, const KernelInitArgs&)>;\n+\n+/// \\brief Base type for kernels. Contains the function signature and\n+/// optionally the state initialization function, along with some common\n+/// attributes\n+struct Kernel {\n+  Kernel() {}\n+\n+  Kernel(std::shared_ptr<KernelSignature> sig, KernelInit init)\n+      : signature(std::move(sig)), init(init) {}\n+\n+  Kernel(std::vector<InputType> in_types, OutputType out_type, KernelInit init)\n+      : Kernel(KernelSignature::Make(std::move(in_types), out_type), init) {}\n+\n+  std::shared_ptr<KernelSignature> signature;\n+\n+  /// \\brief Create a new KernelState for invocations of this kernel, e.g. to\n+  /// set up any options or state relevant for execution. May be nullptr\n+  KernelInit init;\n \n-///@endcond\n+  // Does execution benefit from parallelization (splitting large chunks into\n+  // smaller chunks and using multiple threads). Some vector kernels may\n+  // require single-threaded execution.\n+  bool parallelizable = true;\n+\n+  SimdLevel::type simd_level = SimdLevel::NONE;\n\nReview comment:\n       Is this actually used?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.cc\n##########\n@@ -0,0 +1,153 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/codegen_internal.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <mutex>\n+#include <vector>\n+\n+#include \"arrow/type_fwd.h\"\n+#include \"arrow/util/logging.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+  ctx->SetStatus(Status::NotImplemented(\"This kernel is malformed\"));\n+}\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out) {\n+  ExecBatch flipped_batch = batch;\n+  Datum tmp = flipped_batch.values[0];\n+  flipped_batch.values[0] = flipped_batch.values[1];\n+  flipped_batch.values[1] = tmp;\n\nReview comment:\n       `std::swap(flipped_batch.values[0], flipped_batch.values[1])`?\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n\nReview comment:\n       Is it different from `CodegenTraits::value_type`?\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:32:00.174+0000",
                    "updated": "2020-05-21T15:32:00.174+0000",
                    "started": "2020-05-21T15:32:00.174+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436038",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436041",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428734647\n\n\n\n##########\nFile path: cpp/src/arrow/compute/options.h\n##########\n@@ -0,0 +1,155 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <utility>\n+\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class Array;\n+class DataType;\n+\n+namespace compute {\n+\n+struct ARROW_EXPORT FunctionOptions {};\n+\n+struct ARROW_EXPORT CastOptions : public FunctionOptions {\n+  CastOptions()\n+      : allow_int_overflow(false),\n+        allow_time_truncate(false),\n+        allow_time_overflow(false),\n+        allow_decimal_truncate(false),\n+        allow_float_truncate(false),\n+        allow_invalid_utf8(false) {}\n+\n+  explicit CastOptions(bool safe)\n+      : allow_int_overflow(!safe),\n+        allow_time_truncate(!safe),\n+        allow_time_overflow(!safe),\n+        allow_decimal_truncate(!safe),\n+        allow_float_truncate(!safe),\n+        allow_invalid_utf8(!safe) {}\n+\n+  static CastOptions Safe() { return CastOptions(true); }\n+\n+  static CastOptions Unsafe() { return CastOptions(false); }\n+\n+  // Type being casted to. May be passed separate to eager function\n+  // compute::Cast\n+  std::shared_ptr<DataType> to_type;\n\nReview comment:\n       Yes, I'm aware, but I wasn't able to figure out another way to communicate the output type to the standard kernel APIs\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:39:32.083+0000",
                    "updated": "2020-05-21T15:39:32.083+0000",
                    "started": "2020-05-21T15:39:32.083+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436041",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436042",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428735084\n\n\n\n##########\nFile path: cpp/src/arrow/compute/options.h\n##########\n@@ -0,0 +1,155 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <utility>\n+\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+class Array;\n+class DataType;\n+\n+namespace compute {\n+\n+struct ARROW_EXPORT FunctionOptions {};\n+\n+struct ARROW_EXPORT CastOptions : public FunctionOptions {\n\nReview comment:\n       I don't want to have N headers files where N is the number of different kernels that have options\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:40:15.909+0000",
                    "updated": "2020-05-21T15:40:15.909+0000",
                    "started": "2020-05-21T15:40:15.909+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436042",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436045",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428736130\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_cast_internal.h\n##########\n@@ -0,0 +1,283 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/builder.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/cast_internal.h\"\n+#include \"arrow/compute/kernels/common.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+namespace internal {\n+\n+template <typename OutType, typename InType, typename Enable = void>\n+struct CastFunctor {};\n+\n+// No-op functor for identity casts\n+template <typename O, typename I>\n+struct CastFunctor<\n+    O, I, enable_if_t<std::is_same<O, I>::value && is_parameter_free_type<I>::value>> {\n+  static void Exec(KernelContext*, const ExecBatch&, Datum*) {}\n+};\n+\n+void CastFromExtension(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Dictionary to other things\n+\n+template <typename T, typename IndexType, typename Enable = void>\n+struct FromDictVisitor {};\n+\n+// Visitor for Dict<FixedSizeBinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_fixed_size_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary),\n+        byte_width_(dictionary.byte_width()),\n+        out_(output->buffers[1]->mutable_data() + byte_width_ * output->offset) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    memset(out_, 0, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    const uint8_t* value = dictionary_.Value(dict_index);\n+    memcpy(out_, value, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  int32_t byte_width_;\n+  uint8_t* out_;\n+};\n+\n+// Visitor for Dict<BinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_base_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : ctx_(ctx), dictionary_(dictionary), output_(output) {}\n+\n+  Status Init() {\n+    RETURN_NOT_OK(MakeBuilder(ctx_->memory_pool(), output_->type, &builder_));\n+    binary_builder_ = checked_cast<BinaryBuilder*>(builder_.get());\n+    return Status::OK();\n+  }\n+\n+  Status VisitNull() { return binary_builder_->AppendNull(); }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    return binary_builder_->Append(dictionary_.GetView(dict_index));\n+  }\n+\n+  Status Finish() {\n+    std::shared_ptr<Array> plain_array;\n+    RETURN_NOT_OK(binary_builder_->Finish(&plain_array));\n+    output_->buffers = plain_array->data()->buffers;\n+    return Status::OK();\n+  }\n+\n+  KernelContext* ctx_;\n+  const ArrayType& dictionary_;\n+  ArrayData* output_;\n+  std::unique_ptr<ArrayBuilder> builder_;\n+  BinaryBuilder* binary_builder_;\n+};\n+\n+// Visitor for Dict<NumericType | TemporalType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<\n+    T, IndexType, enable_if_t<is_number_type<T>::value || is_temporal_type<T>::value>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  using value_type = typename T::c_type;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary), out_(output->GetMutableValues<value_type>(1)) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    *out_++ = value_type{};  // Zero-initialize\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    *out_++ = dictionary_.Value(dict_index);\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  value_type* out_;\n+};\n+\n+template <typename T>\n+struct FromDictUnpackHelper {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  template <typename IndexType>\n+  void Unpack(KernelContext* ctx, const ArrayData& indices, const ArrayType& dictionary,\n+              ArrayData* output) {\n+    FromDictVisitor<T, IndexType> visitor{ctx, dictionary, output};\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Init());\n+    KERNEL_ABORT_IF_ERROR(ctx, ArrayDataVisitor<IndexType>::Visit(indices, &visitor));\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Finish());\n+  }\n+};\n+\n+// Dispatch dictionary casts to UnpackHelper\n+template <typename T>\n+struct FromDictionaryCast {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    const ArrayData& input = *batch[0].array();\n+    ArrayData* output = out->mutable_array();\n+\n+    const DictionaryType& type = checked_cast<const DictionaryType&>(*input.type);\n+    const Array& dictionary = *input.dictionary;\n+    const DataType& values_type = *dictionary.type();\n+\n+    // ARROW-7077\n+    if (!values_type.Equals(*output->type)) {\n+      ctx->SetStatus(Status::Invalid(\"Cannot unpack dictionary of type \", type.ToString(),\n+                                     \" to type \", output->type->ToString()));\n+      return;\n+    }\n+\n+    FromDictUnpackHelper<T> unpack_helper;\n+    switch (type.index_type()->id()) {\n+      case Type::INT8:\n+        unpack_helper.template Unpack<Int8Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT16:\n+        unpack_helper.template Unpack<Int16Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT32:\n+        unpack_helper.template Unpack<Int32Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT64:\n+        unpack_helper.template Unpack<Int64Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      default:\n+        ctx->SetStatus(\n+            Status::TypeError(\"Invalid index type: \", type.index_type()->ToString()));\n+        break;\n+    }\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<NullType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    output->buffers = {nullptr};\n+    output->null_count = batch.length;\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<BooleanType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {}\n+};\n+\n+template <typename T>\n+struct FromNullCast {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    std::shared_ptr<Array> nulls;\n+    Status s = MakeArrayOfNull(output->type, batch.length).Value(&nulls);\n+    KERNEL_ABORT_IF_ERROR(ctx, s);\n+    out->value = nulls->data();\n+  }\n+};\n+\n+// Adds a cast function where the functor is defined and the input and output\n+// types have a type_singleton\n+template <typename InType, typename OutType>\n+void AddSimpleCast(InputType in_ty, OutputType out_ty, CastFunction* func) {\n+  DCHECK_OK(func->AddKernel(InType::type_id, {in_ty}, out_ty,\n+                            CastFunctor<OutType, InType>::Exec));\n+}\n+\n+void ZeroCopyCastExec(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void AddZeroCopyCast(InputType in_type, OutputType out_type, CastFunction* func);\n+\n+// OutputType::Resolver that returns a descr with the shape of the input\n+// argument and the type from CastOptions\n+Result<ValueDescr> ResolveOutputFromOptions(KernelContext* ctx,\n+                                            const std::vector<ValueDescr>& args);\n+\n+template <typename T, typename Enable = void>\n+struct MaybeAddFromDictionary {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {}\n+};\n+\n+template <typename T>\n+struct MaybeAddFromDictionary<\n+    T, enable_if_t<!is_boolean_type<T>::value && !is_nested_type<T>::value &&\n+                   !std::is_same<DictionaryType, T>::value>> {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {\n+    // Dictionary unpacking not implemented for boolean or nested types\n+    DCHECK_OK(func->AddKernel(Type::DICTIONARY, {InputType::Array(Type::DICTIONARY)},\n+                              out_ty, FromDictionaryCast<T>::Exec));\n+  }\n+};\n+\n+template <typename OutType>\n+void AddCommonCasts(OutputType out_ty, CastFunction* func) {\n+  // From null to this type\n+  DCHECK_OK(func->AddKernel(Type::NA, {InputType::Array(null())}, out_ty,\n\nReview comment:\n       These failures would indicate a failure to initialize the built-in registry, which indicates that the library is broken. If you'd really like to propagate these errors at registry-init time I suggest we pursue this refactoring in follow up work\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:41:40.137+0000",
                    "updated": "2020-05-21T15:41:40.137+0000",
                    "started": "2020-05-21T15:41:40.137+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436045",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436047",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428736604\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_cast_internal.h\n##########\n@@ -0,0 +1,283 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#pragma once\n+\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/builder.h\"\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/cast_internal.h\"\n+#include \"arrow/compute/kernels/common.h\"\n+\n+namespace arrow {\n+\n+using internal::checked_cast;\n+\n+namespace compute {\n+namespace internal {\n+\n+template <typename OutType, typename InType, typename Enable = void>\n+struct CastFunctor {};\n+\n+// No-op functor for identity casts\n+template <typename O, typename I>\n+struct CastFunctor<\n+    O, I, enable_if_t<std::is_same<O, I>::value && is_parameter_free_type<I>::value>> {\n+  static void Exec(KernelContext*, const ExecBatch&, Datum*) {}\n+};\n+\n+void CastFromExtension(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Dictionary to other things\n+\n+template <typename T, typename IndexType, typename Enable = void>\n+struct FromDictVisitor {};\n+\n+// Visitor for Dict<FixedSizeBinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_fixed_size_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary),\n+        byte_width_(dictionary.byte_width()),\n+        out_(output->buffers[1]->mutable_data() + byte_width_ * output->offset) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    memset(out_, 0, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    const uint8_t* value = dictionary_.Value(dict_index);\n+    memcpy(out_, value, byte_width_);\n+    out_ += byte_width_;\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  int32_t byte_width_;\n+  uint8_t* out_;\n+};\n+\n+// Visitor for Dict<BinaryType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<T, IndexType, enable_if_base_binary<T>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : ctx_(ctx), dictionary_(dictionary), output_(output) {}\n+\n+  Status Init() {\n+    RETURN_NOT_OK(MakeBuilder(ctx_->memory_pool(), output_->type, &builder_));\n+    binary_builder_ = checked_cast<BinaryBuilder*>(builder_.get());\n+    return Status::OK();\n+  }\n+\n+  Status VisitNull() { return binary_builder_->AppendNull(); }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    return binary_builder_->Append(dictionary_.GetView(dict_index));\n+  }\n+\n+  Status Finish() {\n+    std::shared_ptr<Array> plain_array;\n+    RETURN_NOT_OK(binary_builder_->Finish(&plain_array));\n+    output_->buffers = plain_array->data()->buffers;\n+    return Status::OK();\n+  }\n+\n+  KernelContext* ctx_;\n+  const ArrayType& dictionary_;\n+  ArrayData* output_;\n+  std::unique_ptr<ArrayBuilder> builder_;\n+  BinaryBuilder* binary_builder_;\n+};\n+\n+// Visitor for Dict<NumericType | TemporalType>\n+template <typename T, typename IndexType>\n+struct FromDictVisitor<\n+    T, IndexType, enable_if_t<is_number_type<T>::value || is_temporal_type<T>::value>> {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  using value_type = typename T::c_type;\n+\n+  FromDictVisitor(KernelContext* ctx, const ArrayType& dictionary, ArrayData* output)\n+      : dictionary_(dictionary), out_(output->GetMutableValues<value_type>(1)) {}\n+\n+  Status Init() { return Status::OK(); }\n+\n+  Status VisitNull() {\n+    *out_++ = value_type{};  // Zero-initialize\n+    return Status::OK();\n+  }\n+\n+  Status VisitValue(typename IndexType::c_type dict_index) {\n+    *out_++ = dictionary_.Value(dict_index);\n+    return Status::OK();\n+  }\n+\n+  Status Finish() { return Status::OK(); }\n+\n+  const ArrayType& dictionary_;\n+  value_type* out_;\n+};\n+\n+template <typename T>\n+struct FromDictUnpackHelper {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  template <typename IndexType>\n+  void Unpack(KernelContext* ctx, const ArrayData& indices, const ArrayType& dictionary,\n+              ArrayData* output) {\n+    FromDictVisitor<T, IndexType> visitor{ctx, dictionary, output};\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Init());\n+    KERNEL_ABORT_IF_ERROR(ctx, ArrayDataVisitor<IndexType>::Visit(indices, &visitor));\n+    KERNEL_ABORT_IF_ERROR(ctx, visitor.Finish());\n+  }\n+};\n+\n+// Dispatch dictionary casts to UnpackHelper\n+template <typename T>\n+struct FromDictionaryCast {\n+  using ArrayType = typename TypeTraits<T>::ArrayType;\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    const ArrayData& input = *batch[0].array();\n+    ArrayData* output = out->mutable_array();\n+\n+    const DictionaryType& type = checked_cast<const DictionaryType&>(*input.type);\n+    const Array& dictionary = *input.dictionary;\n+    const DataType& values_type = *dictionary.type();\n+\n+    // ARROW-7077\n+    if (!values_type.Equals(*output->type)) {\n+      ctx->SetStatus(Status::Invalid(\"Cannot unpack dictionary of type \", type.ToString(),\n+                                     \" to type \", output->type->ToString()));\n+      return;\n+    }\n+\n+    FromDictUnpackHelper<T> unpack_helper;\n+    switch (type.index_type()->id()) {\n+      case Type::INT8:\n+        unpack_helper.template Unpack<Int8Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT16:\n+        unpack_helper.template Unpack<Int16Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT32:\n+        unpack_helper.template Unpack<Int32Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      case Type::INT64:\n+        unpack_helper.template Unpack<Int64Type>(\n+            ctx, input, static_cast<const ArrayType&>(dictionary), output);\n+        break;\n+      default:\n+        ctx->SetStatus(\n+            Status::TypeError(\"Invalid index type: \", type.index_type()->ToString()));\n+        break;\n+    }\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<NullType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    output->buffers = {nullptr};\n+    output->null_count = batch.length;\n+  }\n+};\n+\n+template <>\n+struct FromDictionaryCast<BooleanType> {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {}\n+};\n+\n+template <typename T>\n+struct FromNullCast {\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayData* output = out->mutable_array();\n+    std::shared_ptr<Array> nulls;\n+    Status s = MakeArrayOfNull(output->type, batch.length).Value(&nulls);\n+    KERNEL_ABORT_IF_ERROR(ctx, s);\n+    out->value = nulls->data();\n+  }\n+};\n+\n+// Adds a cast function where the functor is defined and the input and output\n+// types have a type_singleton\n+template <typename InType, typename OutType>\n+void AddSimpleCast(InputType in_ty, OutputType out_ty, CastFunction* func) {\n+  DCHECK_OK(func->AddKernel(InType::type_id, {in_ty}, out_ty,\n+                            CastFunctor<OutType, InType>::Exec));\n+}\n+\n+void ZeroCopyCastExec(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void AddZeroCopyCast(InputType in_type, OutputType out_type, CastFunction* func);\n+\n+// OutputType::Resolver that returns a descr with the shape of the input\n+// argument and the type from CastOptions\n+Result<ValueDescr> ResolveOutputFromOptions(KernelContext* ctx,\n+                                            const std::vector<ValueDescr>& args);\n+\n+template <typename T, typename Enable = void>\n+struct MaybeAddFromDictionary {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {}\n+};\n+\n+template <typename T>\n+struct MaybeAddFromDictionary<\n+    T, enable_if_t<!is_boolean_type<T>::value && !is_nested_type<T>::value &&\n+                   !std::is_same<DictionaryType, T>::value>> {\n+  static void Add(const OutputType& out_ty, CastFunction* func) {\n+    // Dictionary unpacking not implemented for boolean or nested types\n\nReview comment:\n       Yes, that would be better and make the code simpler\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_boolean.cc\n##########\n@@ -0,0 +1,189 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/common.h\"\n+#include \"arrow/util/bit_util.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+namespace {\n+\n+enum class ResolveNull { KLEENE_LOGIC, PROPAGATE };\n\nReview comment:\n       Will look\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:42:17.226+0000",
                    "updated": "2020-05-21T15:42:17.226+0000",
                    "started": "2020-05-21T15:42:17.226+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436047",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436048",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428737069\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/scalar_arithmetic.cc\n##########\n@@ -0,0 +1,52 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/common.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+struct Add {\n+  template <typename OUT, typename ARG0, typename ARG1>\n+  static constexpr OUT Call(KernelContext*, ARG0 left, ARG1 right) {\n+    return left + right;\n+  }\n+};\n+\n+namespace codegen {\n+\n+template <typename Op>\n+void MakeBinaryFunction(std::string name, FunctionRegistry* registry) {\n+  auto func = std::make_shared<ScalarFunction>(name, /*arity=*/2);\n+  for (const std::shared_ptr<DataType>& ty : NumericTypes()) {\n+    DCHECK_OK(func->AddKernel({InputType::Array(ty), InputType::Array(ty)}, ty,\n+                              ScalarNumericEqualTypes::Binary<Op>(*ty)));\n+  }\n+  DCHECK_OK(registry->AddFunction(std::move(func)));\n\nReview comment:\n       I am not sure I agree but we can deal with this later\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:42:42.524+0000",
                    "updated": "2020-05-21T15:42:42.524+0000",
                    "started": "2020-05-21T15:42:42.524+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436048",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436049",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428737228\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.cc\n##########\n@@ -0,0 +1,153 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/codegen_internal.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <mutex>\n+#include <vector>\n+\n+#include \"arrow/type_fwd.h\"\n+#include \"arrow/util/logging.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+  ctx->SetStatus(Status::NotImplemented(\"This kernel is malformed\"));\n+}\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out) {\n+  ExecBatch flipped_batch = batch;\n+  Datum tmp = flipped_batch.values[0];\n+  flipped_batch.values[0] = flipped_batch.values[1];\n+  flipped_batch.values[1] = tmp;\n\nReview comment:\n       will do\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:42:57.493+0000",
                    "updated": "2020-05-21T15:42:57.493+0000",
                    "started": "2020-05-21T15:42:57.493+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436049",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436050",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nealrichardson commented on pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#issuecomment-632166070\n\n\n   The R failure:\r\n   \r\n   ```\r\n     \u2500\u2500 1. Error: filter() on timestamp columns (@test-dataset.R#381)  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n     NotImplemented: Function >= has no kernel matching input types (array[timestamp[us, tz=UTC]], scalar[timestamp[us, tz=UTC]])\r\n     Backtrace:\r\n       1. arrow:::expect_equivalent(...)\r\n       2. dplyr::filter(., ts >= lubridate::ymd_hms(\"2015-05-04 03:12:39\"))\r\n       2. dplyr::filter(., part == 1)\r\n       2. dplyr::select(., ts)\r\n      10. dplyr::collect(.)\r\n      13. Scanner$create(x)$ToTable()\r\n      16. arrow:::dataset___Scanner__ToTable(self)\r\n   ```\r\n   \r\n   I'm happy to help debug but that sounds pretty straightforward.\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:43:11.685+0000",
                    "updated": "2020-05-21T15:43:11.685+0000",
                    "started": "2020-05-21T15:43:11.685+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436050",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436051",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428737652\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.cc\n##########\n@@ -0,0 +1,153 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/codegen_internal.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <mutex>\n+#include <vector>\n+\n+#include \"arrow/type_fwd.h\"\n+#include \"arrow/util/logging.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+  ctx->SetStatus(Status::NotImplemented(\"This kernel is malformed\"));\n+}\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out) {\n+  ExecBatch flipped_batch = batch;\n+  Datum tmp = flipped_batch.values[0];\n+  flipped_batch.values[0] = flipped_batch.values[1];\n+  flipped_batch.values[1] = tmp;\n+  exec(ctx, flipped_batch, out);\n+}\n+\n+std::vector<std::shared_ptr<DataType>> g_signed_int_types;\n+std::vector<std::shared_ptr<DataType>> g_unsigned_int_types;\n+std::vector<std::shared_ptr<DataType>> g_int_types;\n+std::vector<std::shared_ptr<DataType>> g_floating_types;\n+std::vector<std::shared_ptr<DataType>> g_numeric_types;\n+std::vector<std::shared_ptr<DataType>> g_base_binary_types;\n+std::vector<std::shared_ptr<DataType>> g_temporal_types;\n+std::vector<std::shared_ptr<DataType>> g_primitive_types;\n+static std::once_flag codegen_static_initialized;\n+\n+static void InitStaticData() {\n+  // Signed int types\n+  g_signed_int_types.push_back(int8());\n+  g_signed_int_types.push_back(int16());\n+  g_signed_int_types.push_back(int32());\n+  g_signed_int_types.push_back(int64());\n+\n+  // Unsigned int types\n+  g_unsigned_int_types.push_back(uint8());\n+  g_unsigned_int_types.push_back(uint16());\n+  g_unsigned_int_types.push_back(uint32());\n+  g_unsigned_int_types.push_back(uint64());\n+\n+  // All int types\n+  Extend(g_unsigned_int_types, &g_int_types);\n+  Extend(g_signed_int_types, &g_int_types);\n+\n+  // Floating point types\n+  g_floating_types.push_back(float32());\n+  g_floating_types.push_back(float64());\n+\n+  // Numeric types\n+  Extend(g_int_types, &g_numeric_types);\n+  Extend(g_floating_types, &g_numeric_types);\n+\n+  // Temporal types\n+  g_temporal_types.push_back(date32());\n+  g_temporal_types.push_back(date64());\n+  g_temporal_types.push_back(time32(TimeUnit::SECOND));\n+  g_temporal_types.push_back(time32(TimeUnit::MILLI));\n+  g_temporal_types.push_back(time64(TimeUnit::MICRO));\n+  g_temporal_types.push_back(time64(TimeUnit::NANO));\n+  g_temporal_types.push_back(timestamp(TimeUnit::SECOND));\n+  g_temporal_types.push_back(timestamp(TimeUnit::MILLI));\n+  g_temporal_types.push_back(timestamp(TimeUnit::MICRO));\n+  g_temporal_types.push_back(timestamp(TimeUnit::NANO));\n+\n+  // Base binary types (without FixedSizeBinary)\n+  g_base_binary_types.push_back(binary());\n+  g_base_binary_types.push_back(utf8());\n+  g_base_binary_types.push_back(large_binary());\n+  g_base_binary_types.push_back(large_utf8());\n+\n+  // Non-parametric, non-nested types. This also DOES NOT include\n+  //\n+  // * Decimal\n+  // * Fixed Size Binary\n+  g_primitive_types.push_back(null());\n+  g_primitive_types.push_back(boolean());\n+  Extend(g_numeric_types, &g_primitive_types);\n+  Extend(g_temporal_types, &g_primitive_types);\n+  Extend(g_base_binary_types, &g_primitive_types);\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes() {\n+  std::call_once(codegen_static_initialized, InitStaticData);\n+  return g_base_binary_types;\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes() {\n+  std::call_once(codegen_static_initialized, InitStaticData);\n\nReview comment:\n       Will look\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:43:17.503+0000",
                    "updated": "2020-05-21T15:43:17.503+0000",
                    "started": "2020-05-21T15:43:17.503+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436051",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436052",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428737652\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.cc\n##########\n@@ -0,0 +1,153 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include \"arrow/compute/kernels/codegen_internal.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <mutex>\n+#include <vector>\n+\n+#include \"arrow/type_fwd.h\"\n+#include \"arrow/util/logging.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+  ctx->SetStatus(Status::NotImplemented(\"This kernel is malformed\"));\n+}\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out) {\n+  ExecBatch flipped_batch = batch;\n+  Datum tmp = flipped_batch.values[0];\n+  flipped_batch.values[0] = flipped_batch.values[1];\n+  flipped_batch.values[1] = tmp;\n+  exec(ctx, flipped_batch, out);\n+}\n+\n+std::vector<std::shared_ptr<DataType>> g_signed_int_types;\n+std::vector<std::shared_ptr<DataType>> g_unsigned_int_types;\n+std::vector<std::shared_ptr<DataType>> g_int_types;\n+std::vector<std::shared_ptr<DataType>> g_floating_types;\n+std::vector<std::shared_ptr<DataType>> g_numeric_types;\n+std::vector<std::shared_ptr<DataType>> g_base_binary_types;\n+std::vector<std::shared_ptr<DataType>> g_temporal_types;\n+std::vector<std::shared_ptr<DataType>> g_primitive_types;\n+static std::once_flag codegen_static_initialized;\n+\n+static void InitStaticData() {\n+  // Signed int types\n+  g_signed_int_types.push_back(int8());\n+  g_signed_int_types.push_back(int16());\n+  g_signed_int_types.push_back(int32());\n+  g_signed_int_types.push_back(int64());\n+\n+  // Unsigned int types\n+  g_unsigned_int_types.push_back(uint8());\n+  g_unsigned_int_types.push_back(uint16());\n+  g_unsigned_int_types.push_back(uint32());\n+  g_unsigned_int_types.push_back(uint64());\n+\n+  // All int types\n+  Extend(g_unsigned_int_types, &g_int_types);\n+  Extend(g_signed_int_types, &g_int_types);\n+\n+  // Floating point types\n+  g_floating_types.push_back(float32());\n+  g_floating_types.push_back(float64());\n+\n+  // Numeric types\n+  Extend(g_int_types, &g_numeric_types);\n+  Extend(g_floating_types, &g_numeric_types);\n+\n+  // Temporal types\n+  g_temporal_types.push_back(date32());\n+  g_temporal_types.push_back(date64());\n+  g_temporal_types.push_back(time32(TimeUnit::SECOND));\n+  g_temporal_types.push_back(time32(TimeUnit::MILLI));\n+  g_temporal_types.push_back(time64(TimeUnit::MICRO));\n+  g_temporal_types.push_back(time64(TimeUnit::NANO));\n+  g_temporal_types.push_back(timestamp(TimeUnit::SECOND));\n+  g_temporal_types.push_back(timestamp(TimeUnit::MILLI));\n+  g_temporal_types.push_back(timestamp(TimeUnit::MICRO));\n+  g_temporal_types.push_back(timestamp(TimeUnit::NANO));\n+\n+  // Base binary types (without FixedSizeBinary)\n+  g_base_binary_types.push_back(binary());\n+  g_base_binary_types.push_back(utf8());\n+  g_base_binary_types.push_back(large_binary());\n+  g_base_binary_types.push_back(large_utf8());\n+\n+  // Non-parametric, non-nested types. This also DOES NOT include\n+  //\n+  // * Decimal\n+  // * Fixed Size Binary\n+  g_primitive_types.push_back(null());\n+  g_primitive_types.push_back(boolean());\n+  Extend(g_numeric_types, &g_primitive_types);\n+  Extend(g_temporal_types, &g_primitive_types);\n+  Extend(g_base_binary_types, &g_primitive_types);\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes() {\n+  std::call_once(codegen_static_initialized, InitStaticData);\n+  return g_base_binary_types;\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes() {\n+  std::call_once(codegen_static_initialized, InitStaticData);\n\nReview comment:\n       This is a stylistic issue so not sure how much codesmithing is valuable on this right now (can be follow up work)\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:43:41.127+0000",
                    "updated": "2020-05-21T15:43:41.127+0000",
                    "started": "2020-05-21T15:43:41.127+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436052",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436053",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428738220\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n\nReview comment:\n       Will fix\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:43:55.856+0000",
                    "updated": "2020-05-21T15:43:55.856+0000",
                    "started": "2020-05-21T15:43:55.856+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436053",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436054",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428738646\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n\nReview comment:\n       Array subclasses require a `shared_ptr<ArrayData>`\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:44:20.724+0000",
                    "updated": "2020-05-21T15:44:20.724+0000",
                    "started": "2020-05-21T15:44:20.724+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436054",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436056",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428738847\n\n\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n\nReview comment:\n       It may not be, I will look\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n+  template <typename Op, typename OutType, typename Arg0Type>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0>(ctx, *arg0_data++);\n+      }\n+    }\n+  }\n+\n+  template <typename Op, typename OutType, typename Arg0Type, typename Arg1Type>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    using OUT = typename OutType::c_type;\n+    using ARG0 = typename Arg0Type::c_type;\n+    using ARG1 = typename Arg1Type::c_type;\n+\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else {\n+      ArrayData* out_arr = out->mutable_array();\n+      auto out_data = out_arr->GetMutableValues<OUT>(kPrimitiveData);\n+      auto arg0_data = batch[0].array()->GetValues<ARG0>(kPrimitiveData);\n+      auto arg1_data = batch[1].array()->GetValues<ARG1>(kPrimitiveData);\n+      for (int64_t i = 0; i < batch.length; ++i) {\n+        *out_data++ = Op::template Call<OUT, ARG0, ARG1>(ctx, *arg0_data++, *arg1_data++);\n+      }\n+    }\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct OutputAdapter;\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_bitmap = out_arr->buffers[1]->mutable_data();\n+    GenerateBitsUnrolled(out_bitmap, out_arr->offset, out_arr->length,\n+                         std::forward<Generator>(generator));\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext*, Datum* out, Generator&& generator) {\n+    ArrayData* out_arr = out->mutable_array();\n+    auto out_data = out_arr->GetMutableValues<typename Type::c_type>(kPrimitiveData);\n+    // TODO: Is this as fast as a more explicitly inlined function?\n+    for (int64_t i = 0 ; i < out_arr->length; ++i) {\n+      *out_data++ = generator();\n+    }\n+  }\n+};\n+\n+template <typename Type>\n+struct OutputAdapter<Type, enable_if_base_binary<Type>> {\n+  template <typename Generator>\n+  static void Write(KernelContext* ctx, Datum* out, Generator&& generator) {\n+    ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+  }\n+};\n+\n+template <typename OutType, typename Arg0Type, typename Op>\n+struct ScalarUnary {\n+  using OutScalar = typename TypeTraits<OutType>::ScalarType;\n+\n+  using OUT = typename CodegenTraits<OutType>::value_type;\n+  using ARG0 = typename CodegenTraits<Arg0Type>::value_type;\n+\n+  static void Array(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    ArrayIterator<Arg0Type> arg0(*batch[0].array());\n+    OutputAdapter<OutType>::Write(ctx, out, [&]() -> OUT {\n+        return Op::template Call<OUT, ARG0>(ctx, arg0());\n+    });\n+  }\n+\n+  static void Scalar(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].scalar()->is_valid) {\n+      ARG0 arg0 = UnboxScalar<Arg0Type>::Unbox(batch[0]);\n+      out->value = std::make_shared<OutScalar>(Op::template Call<OUT, ARG0>(ctx, arg0),\n+                                               out->type());\n+    } else {\n+      out->value = MakeNullScalar(batch[0].type());\n+    }\n+  }\n+\n+  static void Exec(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::ARRAY) {\n+      return Array(ctx, batch, out);\n+    } else {\n+      return Scalar(ctx, batch, out);\n+    }\n+  }\n+};\n+\n+// Applies a scalar operation with state on the null-null values of a single\n\nReview comment:\n       yes\n\n##########\nFile path: cpp/src/arrow/compute/kernels/codegen_internal.h\n##########\n@@ -0,0 +1,648 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <cstdint>\n+#include <memory>\n+#include <vector>\n+\n+#include \"arrow/array.h\"\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/scalar.h\"\n+#include \"arrow/type_traits.h\"\n+#include \"arrow/util/bit_util.h\"\n+#include \"arrow/util/logging.h\"\n+#include \"arrow/util/optional.h\"\n+#include \"arrow/util/string_view.h\"\n+#include \"arrow/visitor_inline.h\"\n+\n+namespace arrow {\n+\n+using internal::BitmapReader;\n+using internal::FirstTimeBitmapWriter;\n+using internal::GenerateBitsUnrolled;\n+\n+namespace compute {\n+\n+#ifdef ARROW_EXTRA_ERROR_CONTEXT\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)                \\\n+  do {                                                  \\\n+    Status _st = (expr);                                \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {               \\\n+      _st.AddContextLine(__FILE__, __LINE__, #expr);    \\\n+      ctx->SetStatus(_st);                              \\\n+      return;                                           \\\n+    }                                                   \\\n+  } while (0)\n+\n+#else\n+\n+#define KERNEL_ABORT_IF_ERROR(ctx, expr)        \\\n+  do {                                          \\\n+    Status _st = (expr);                        \\\n+    if (ARROW_PREDICT_FALSE(!_st.ok())) {       \\\n+      ctx->SetStatus(_st);                      \\\n+      return;                                   \\\n+    }                                           \\\n+  } while (0)\n+\n+#endif  // ARROW_EXTRA_ERROR_CONTEXT\n+\n+// A kernel that exposes Call methods that handles iteration over ArrayData\n+// inputs itself\n+//\n+\n+constexpr int kValidity = 0;\n+constexpr int kBinaryOffsets = 1;\n+constexpr int kPrimitiveData = 1;\n+constexpr int kBinaryData = 2;\n+\n+// ----------------------------------------------------------------------\n+// Iteration / value access utilities\n+\n+template <typename T, typename R = void>\n+using enable_if_has_c_type_not_boolean = enable_if_t<has_c_type<T>::value &&\n+                                                     !is_boolean_type<T>::value, R>;\n+\n+template <typename T, typename Enable = void>\n+struct CodegenTraits;\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_has_c_type<T>> {\n+  using value_type = typename T::c_type;\n+};\n+\n+template <typename T>\n+struct CodegenTraits<T, enable_if_base_binary<T>> {\n+  using value_type = util::string_view;\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct ArrayIterator;\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_has_c_type_not_boolean<Type>> {\n+  using T = typename Type::c_type;\n+  const T* values;\n+  ArrayIterator(const ArrayData& data) : values(data.GetValues<T>(1)) {}\n+  T operator()() { return *values++; }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_boolean<Type>> {\n+  BitmapReader reader;\n+  ArrayIterator(const ArrayData& data)\n+      : reader(data.buffers[1]->data(), data.offset, data.length) {}\n+  bool operator()() {\n+    bool out = reader.IsSet();\n+    reader.Next();\n+    return out;\n+  }\n+};\n+\n+template <typename Type>\n+struct ArrayIterator<Type, enable_if_base_binary<Type>> {\n+  int64_t position = 0;\n+  typename TypeTraits<Type>::ArrayType arr;\n+  ArrayIterator(const ArrayData& data)\n+      : arr(data.Copy()) {}\n+  util::string_view operator()() { return arr.GetView(position++); }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct UnboxScalar;\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_has_c_type<Type>> {\n+  using ScalarType = typename TypeTraits<Type>::ScalarType;\n+  static typename Type::c_type Unbox(const Datum& datum) {\n+    return datum.scalar_as<ScalarType>().value;\n+  }\n+};\n+\n+template <typename Type>\n+struct UnboxScalar<Type, enable_if_base_binary<Type>> {\n+  static util::string_view Unbox(const Datum& datum) {\n+    return util::string_view(*datum.scalar_as<BaseBinaryScalar>().value);\n+  }\n+};\n+\n+template <typename Type, typename Enable = void>\n+struct GetValueType;\n+\n+template <typename Type>\n+struct GetValueType<Type, enable_if_has_c_type<Type>> {\n+  using T = typename Type::c_type;\n+};\n+\n+template <typename Type>\n+struct GetValueType<\n+    Type, enable_if_t<is_base_binary_type<Type>::value || is_decimal_type<Type>::value ||\n+                      is_fixed_size_binary_type<Type>::value>> {\n+  using T = util::string_view;\n+};\n+\n+// ----------------------------------------------------------------------\n+// Generate an array kernel given template classes\n+\n+void ExecFail(KernelContext* ctx, const ExecBatch& batch, Datum* out);\n+\n+void BinaryExecFlipped(KernelContext* ctx, ArrayKernelExec exec,\n+                       const ExecBatch& batch, Datum* out);\n+\n+// ----------------------------------------------------------------------\n+// Boolean data utilities\n+\n+// ----------------------------------------------------------------------\n+// Template kernel exec function generators\n+\n+template <typename T>\n+void Extend(const std::vector<T>& values, std::vector<T>* out) {\n+  for (const auto& t : values) {\n+    out->push_back(t);\n+  }\n+}\n+\n+const std::vector<std::shared_ptr<DataType>>& BaseBinaryTypes();\n+const std::vector<std::shared_ptr<DataType>>& SignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& UnsignedIntTypes();\n+const std::vector<std::shared_ptr<DataType>>& IntTypes();\n+const std::vector<std::shared_ptr<DataType>>& FloatingPointTypes();\n+\n+// Number types without boolean\n+const std::vector<std::shared_ptr<DataType>>& NumericTypes();\n+\n+// Temporal types including time and timestamps for each unit\n+const std::vector<std::shared_ptr<DataType>>& TemporalTypes();\n+\n+// Integer, floating point, base binary, and temporal\n+const std::vector<std::shared_ptr<DataType>>& PrimitiveTypes();\n+\n+namespace codegen {\n+\n+struct SimpleExec {\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& in, ArrayData* out)\n+  template <typename Operator>\n+  static void Unary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), out->mutable_array());\n+    }\n+  }\n+\n+  // Operator must implement\n+  //\n+  // static void Call(KernelContext*, const ArrayData& arg0, const ArrayData& arg1,\n+  //                  ArrayData* out)\n+  template <typename Operator>\n+  static void Binary(KernelContext* ctx, const ExecBatch& batch, Datum* out) {\n+    if (batch[0].kind() == Datum::SCALAR || batch[1].kind() == Datum::SCALAR) {\n+      ctx->SetStatus(Status::NotImplemented(\"NYI\"));\n+    } else if (batch.length > 0) {\n+      Operator::Call(ctx, *batch[0].array(), *batch[1].array(), out->mutable_array());\n+    }\n+  }\n+};\n+\n+// TODO: Run benchmarks to determine if OutputAdapter is a zero-cost abstraction\n+struct ScalarPrimitiveExec {\n\nReview comment:\n       I will add more comments\n\n##########\nFile path: cpp/src/arrow/compute/kernels/CMakeLists.txt\n##########\n@@ -15,37 +15,41 @@\n # specific language governing permissions and limitations\n # under the License.\n \n-arrow_install_all_headers(\"arrow/compute/kernels\")\n-\n-add_arrow_compute_test(boolean_test)\n-add_arrow_compute_test(cast_test)\n-add_arrow_compute_test(hash_test)\n-add_arrow_compute_test(isin_test)\n-add_arrow_compute_test(match_test)\n-add_arrow_compute_test(sort_to_indices_test)\n-add_arrow_compute_test(nth_to_indices_test)\n-add_arrow_compute_test(util_internal_test)\n-add_arrow_compute_test(add_test)\n+# ----------------------------------------------------------------------\n+# Scalar kernels\n \n-# Aggregates\n-add_arrow_compute_test(aggregate_test)\n+add_arrow_compute_test(scalar_test\n+                       SOURCES\n+                       scalar_arithmetic_test.cc\n+                       scalar_boolean_test.cc\n+                       scalar_cast_test.cc\n+                       scalar_compare_test.cc\n+                       scalar_set_lookup_test.cc)\n \n-# Comparison\n-add_arrow_compute_test(compare_test)\n+# add_arrow_compute_test(cast_test)\n \n-# Selection\n-add_arrow_compute_test(take_test)\n-add_arrow_compute_test(filter_test)\n+add_arrow_benchmark(scalar_compare_benchmark PREFIX \"arrow-compute\")\n \n-add_arrow_benchmark(sort_to_indices_benchmark PREFIX \"arrow-compute\")\n-add_arrow_benchmark(nth_to_indices_benchmark PREFIX \"arrow-compute\")\n+# ----------------------------------------------------------------------\n+# Vector kernels\n \n-# Aggregates\n-add_arrow_benchmark(aggregate_benchmark PREFIX \"arrow-compute\")\n+add_arrow_compute_test(vector_test\n+                       SOURCES\n+                       vector_filter_test.cc\n+                       vector_hash_test.cc\n+                       vector_take_test.cc\n+                       vector_sort_test.cc)\n+\n+# add_arrow_benchmark(vector_hash_benchmark PREFIX \"arrow-compute\")\n+# add_arrow_benchmark(vector_sort_benchmark PREFIX \"arrow-compute\")\n+# add_arrow_benchmark(vector_partition_benchmark PREFIX \"arrow-compute\")\n+# add_arrow_benchmark(vector_filter_benchmark PREFIX \"arrow-compute\")a\n+# add_arrow_benchmark(vector_take_benchmark PREFIX \"arrow-compute\")\n\nReview comment:\n       yes\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:45:02.868+0000",
                    "updated": "2020-05-21T15:45:02.868+0000",
                    "started": "2020-05-21T15:45:02.868+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436056",
                    "issueId": "13304783"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/worklog/436057",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #7240:\nURL: https://github.com/apache/arrow/pull/7240#discussion_r428739473\n\n\n\n##########\nFile path: cpp/src/arrow/compute/function.h\n##########\n@@ -0,0 +1,203 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+// NOTE: API is EXPERIMENTAL and will change without going through a\n+// deprecation cycle\n+\n+#pragma once\n+\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"arrow/compute/kernel.h\"\n+#include \"arrow/compute/options.h\"  // IWYU pragma: keep\n+#include \"arrow/result.h\"\n+#include \"arrow/status.h\"\n+#include \"arrow/util/visibility.h\"\n+\n+namespace arrow {\n+\n+struct ValueDescr;\n+\n+namespace compute {\n+\n+/// \\brief Contains the number of required arguments for the function\n+struct ARROW_EXPORT FunctionArity {\n+  static FunctionArity Nullary() { return FunctionArity(0, false); }\n+  static FunctionArity Unary() { return FunctionArity(1, false); }\n+  static FunctionArity Binary() { return FunctionArity(2, false); }\n+  static FunctionArity Ternary() { return FunctionArity(3, false); }\n+  static FunctionArity Varargs(int min_args = 1) { return FunctionArity(min_args, true); }\n+\n+  FunctionArity(int num_args, bool is_varargs = false)  // NOLINT implicit conversion\n+      : num_args(num_args), is_varargs(is_varargs) {}\n+\n+  /// The number of required arguments (or the minimum number for varargs\n+  /// functions)\n+  int num_args;\n+\n+  /// If true, then the num_args is the minimum number of required arguments\n+  bool is_varargs = false;\n+};\n+\n+/// \\brief Base class for function containers that are capable of dispatch to\n+/// kernel implementations\n+class ARROW_EXPORT Function {\n+ public:\n+  /// \\brief The kind of function, which indicates in what contexts it is\n+  /// valid for use\n+  enum Kind {\n+    /// A function that performs scalar data operations on whole arrays of\n+    /// data. Can generally process Array or Scalar values. The size of the\n+    /// output will be the same as the size (or broadcasted size, in the case\n+    /// of mixing Array and Scalar inputs) of the input.\n+    SCALAR,\n+\n+    /// A function with array input and output whose behavior depends on the\n+    /// values of the entire arrays passed, rather than the value of each scalar\n+    /// value.\n+    VECTOR,\n+\n+    /// A function that computes scalar summary statistics from array input.\n+    SCALAR_AGGREGATE\n+  };\n+\n+  virtual ~Function() = default;\n+\n+  /// \\brief The name of the kernel. The registry enforces uniqueness of names\n+  const std::string& name() const { return name_; }\n+\n+  /// \\brief The kind of kernel, which indicates in what contexts it is valid\n+  /// for use\n+  Function::Kind kind() const { return kind_; }\n+\n+  /// \\brief Contains the number of arguments the function requires\n+  const FunctionArity& arity() const { return arity_; }\n+\n+  /// \\brief Returns the number of registered kernels for this function\n+  virtual int num_kernels() const = 0;\n+\n+  /// \\brief Convenience for invoking a function with kernel dispatch and\n+  /// memory allocation details taken care of\n+  Result<Datum> Execute(const std::vector<Datum>& args, const FunctionOptions* options,\n+                        ExecContext* ctx = NULLPTR) const;\n+\n+ protected:\n+  Function(std::string name, Function::Kind kind, const FunctionArity& arity)\n+      : name_(std::move(name)), kind_(kind), arity_(arity) {}\n+  std::string name_;\n+  Function::Kind kind_;\n+  FunctionArity arity_;\n+};\n+\n+namespace detail {\n+\n+template <typename KernelType>\n+class FunctionImpl : public Function {\n+ public:\n+  /// \\brief Return vector of all available kernels for this function\n+  const std::vector<KernelType>& kernels() const { return kernels_; }\n+\n+  int num_kernels() const override { return static_cast<int>(kernels_.size()); }\n+\n+ protected:\n+  FunctionImpl(std::string name, Function::Kind kind, const FunctionArity& arity)\n+      : Function(std::move(name), kind, arity) {}\n+\n+  std::vector<KernelType> kernels_;\n+};\n+\n+}  // namespace detail\n+\n+/// \\brief A function that executes elementwise operations on arrays or\n+/// scalars, and therefore whose results generally do not depend on the order\n+/// of the values in the arguments. Accepts and returns arrays that are all of\n+/// the same size. These functions roughly correspond to the functions used in\n+/// SQL expressions.\n+class ARROW_EXPORT ScalarFunction : public detail::FunctionImpl<ScalarKernel> {\n+ public:\n+  using KernelType = ScalarKernel;\n+\n+  ScalarFunction(std::string name, const FunctionArity& arity)\n+      : detail::FunctionImpl<ScalarKernel>(std::move(name), Function::SCALAR, arity) {}\n+\n+  /// \\brief Add a simple kernel (function implementation) with given\n+  /// input/output types, no required state initialization, preallocation for\n+  /// fixed-width types, and default null handling (intersect validity bitmaps\n+  /// of inputs)\n+  Status AddKernel(std::vector<InputType> in_types, OutputType out_type,\n+                   ArrayKernelExec exec, KernelInit init = NULLPTR);\n+\n+  /// \\brief Add a kernel (function implementation). Returns error if fails\n+  /// to match the other parameters of the function\n+  Status AddKernel(ScalarKernel kernel);\n+\n+  /// \\brief Return the first kernel that can execute the function given the\n+  /// exact argument types (without implicit type casts or scalar->array\n+  /// promotions)\n+  virtual Result<const ScalarKernel*> DispatchExact(\n\nReview comment:\n       yes, `CastFunction` has some additional logic\n\n\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-05-21T15:45:18.892+0000",
                    "updated": "2020-05-21T15:45:18.892+0000",
                    "started": "2020-05-21T15:45:18.892+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "436057",
                    "issueId": "13304783"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 63600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@1ee2c0a8[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@133ceeef[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@e3787b7[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@7a884b08[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@473e5b9a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@625c9e9[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@341deca5[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@cf52125[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@392259aa[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@11e0a5e6[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4ac31bbb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@6f1ae7cf[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 63600,
        "customfield_12312520": null,
        "customfield_12312521": "Sun May 24 14:35:11 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-05-24T14:35:11.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8792/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2020-05-13T22:53:45.000+0000",
        "updated": "2020-06-07T17:13:41.000+0000",
        "timeoriginalestimate": null,
        "description": "I'm working on a significant revamp of the way that kernels are implemented in the project as discussed on the mailing list. PR to follow within the next week or sooner\r\n\r\nA brief list of features:\r\n\r\n* Kernel selection that takes into account the shape of inputs (whether Scalar or Array, so you can provide an implementation just for Arrays and a separate one just for Scalars if you want)\r\n* More customizable / less monolithic type-to-kernel dispatch\r\n* Standardized C++ function signature for kernel implementations (rather than every one being a little bit special)\r\n* Multiple implementations of the same function can coexist (e.g. with / without SIMD optimizations) so that you can choose the one you want at runtime\r\n* Browsable function registry (see all available kernels and their input type signatures)\r\n* Central code path for type-checking and argument validation\r\n* Central code path for kernel execution on ChunkedArray inputs\r\n\r\nThere's a lot of JIRAs in the backlog that will follow from this work so I will attach those to this issue for visibility but this issue will cover the initial refactoring work to port the existing code to the new framework without altering existing features.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "17h 40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 63600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Improved declarative compute function / kernel development framework, normalize calling conventions",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13304783/comment/17115325",
                    "id": "17115325",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 7240\n[https://github.com/apache/arrow/pull/7240]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-05-24T14:35:11.442+0000",
                    "updated": "2020-05-24T14:35:11.442+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0epn4:",
        "customfield_12314139": null
    }
}