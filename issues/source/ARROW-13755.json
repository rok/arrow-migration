{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13397204",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204",
    "key": "ARROW-13755",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12350323",
                "id": "12350323",
                "description": "",
                "name": "6.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2021-10-26"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=amol-",
            "name": "amol-",
            "key": "amol-",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=amol-&avatarId=46461",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=amol-&avatarId=46461",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=amol-&avatarId=46461",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=amol-&avatarId=46461"
            },
            "displayName": "Alessandro Molina",
            "active": true,
            "timeZone": "Europe/Rome"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=amol-",
            "name": "amol-",
            "key": "amol-",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=amol-&avatarId=46461",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=amol-&avatarId=46461",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=amol-&avatarId=46461",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=amol-&avatarId=46461"
            },
            "displayName": "Alessandro Molina",
            "active": true,
            "timeZone": "Europe/Rome"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=amol-",
            "name": "amol-",
            "key": "amol-",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=amol-&avatarId=46461",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=amol-&avatarId=46461",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=amol-&avatarId=46461",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=amol-&avatarId=46461"
            },
            "displayName": "Alessandro Molina",
            "active": true,
            "timeZone": "Europe/Rome"
        },
        "aggregateprogress": {
            "progress": 28800,
            "total": 28800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 28800,
            "total": 28800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13755/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 48,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/642337",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#issuecomment-906422384\n\n\n   https://issues.apache.org/jira/browse/ARROW-13755\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-26T13:38:34.171+0000",
                    "updated": "2021-08-26T13:38:34.171+0000",
                    "started": "2021-08-26T13:38:34.171+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "642337",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/642342",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r696652313\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       We can call this `finish` to align it with the C++ API?\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-26T13:52:26.633+0000",
                    "updated": "2021-08-26T13:52:26.633+0000",
                    "started": "2021-08-26T13:52:26.633+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "642342",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/642356",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r696666776\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       I originally named it `finish` as it was the same name it has the C++ method, but it occurred to me that it wasn't very clear from a user point of view. Finish what? It doesn't look like a multi step process that has a begin and end or something like that. I mean, if you saw \"finish\" in your autocomplete would you guess it creates a Partitioning given a schema?\r\n   \r\n   \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-26T14:07:44.624+0000",
                    "updated": "2021-08-26T14:07:44.624+0000",
                    "started": "2021-08-26T14:07:44.623+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "642356",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/642529",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r696893157\n\n\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -678,13 +678,24 @@ def dataset(source, schema=None, format=None, filesystem=None,\n         )\n \n \n-def _ensure_write_partitioning(scheme):\n-    if scheme is None:\n-        scheme = partitioning(pa.schema([]))\n-    if not isinstance(scheme, Partitioning):\n-        # TODO support passing field names, and get types from schema\n+def _ensure_write_partitioning(part, schema):\n+    if isinstance(part, (tuple, list)):\n+        # Name of fields were provided instead of a partitioning object.\n+        # Create a partitioning factory with those field names.\n+        part = partitioning(field_names=part)\n+\n+    if part is None:\n+        part = partitioning(pa.schema([]))\n+    elif isinstance(part, PartitioningFactory):\n+        # If a schema is provided, combine the factory with the schema\n+        # to build a real Partitioning object that the Writer can accept.\n+        if schema is not None:\n+            part = part.create_with_schema(schema)\n\nReview comment:\n       Perhaps raise a more specific error in an else case.  Something like \"PartitioningFactory provided but no schema, a schema must be provided.\"\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-26T18:48:32.249+0000",
                    "updated": "2021-08-26T18:48:32.249+0000",
                    "started": "2021-08-26T18:48:32.249+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "642529",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/642535",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r696898037\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       Well...in the C++ it is a multi-step method.  The PartitioningFactory is created, filenames are inspected, then it is finished.  Thinking about this more I am wondering if this is the correct approach.  It seems very odd that a partitioning factory should need to be used if you aren't actually inspecting any files.  The purpose of a partitioning factory to create a partitioning from a set of filenames while creating a dataset from a list of filenames.  So the use case is...\r\n   \r\n   Create partitioning factory\r\n   Run inspect on a datasetfactory\r\n   Dataset factory passes all filenames to partitioning factory (while also keeping them to create the dataset)\r\n   Finish called on partitioning factory to generate partitioning (which is then added to the created dataset)\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-26T18:55:12.268+0000",
                    "updated": "2021-08-26T18:55:12.268+0000",
                    "started": "2021-08-26T18:55:12.267+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "642535",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/642741",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r697272484\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       I agree that factories look specifically designed for reading, and the fact that `ds.partitioning()` returns a factory makes harder for a user to deal with writing. Mostly the multi-step process you described doesn't seem to exist in `pyarrow`, you invoke `write_dataset` or `read_dataset` and provide the partitioning that should be used for reading/writing to it. And while `read_dataset` deals with factories, `write_dataset` didn't.\r\n   \r\n   At the moment having `write_dataset` able to deal with factories when possible seemed to be the most reasonable solution that didn't require changes to our API and was convenient for users.\r\n   \r\n   The problem imho comes from the fact that building a partitioning requires a `schema`, but `ds.partitioning` allows you to omit it and in such case it will give you back a factory. I think that makes far more confusing and harder to use our api, I feel `ds.partitioning` should just have complained if it was unable to build a partitioning and we should have a dedicated \"partitioning detector\" or similar entity when you wanted to discover the partitioning from disk. In trying to make the API _more convenient_ it seems the final result is actually more confusing. \n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-27T08:56:42.205+0000",
                    "updated": "2021-08-27T08:56:42.205+0000",
                    "started": "2021-08-27T08:56:42.204+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "642741",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/643311",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r698255047\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       IMO it is fine that a Partitioning requires a schema to be constructed, at the low-level (C++/cython). Allowing users to pass just field names and not a full-blown Partitioning object from a schema, is something that we can also easily do in the high-level Python bindings, without needing extensive changes to the C++ code (https://github.com/apache/arrow/pull/11014)\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-30T07:26:14.804+0000",
                    "updated": "2021-08-30T07:26:14.804+0000",
                    "started": "2021-08-30T07:26:14.804+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643311",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/643312",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r698259018\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       And note that for *reading*, we already do this: as a user, you in theory never have to use a PartitioningFactory, as you can either pass `partitioning=\"hive\"` or `partitioning=[\"field\", \"names\"]` (for directory partitioning) to the `dataset(..)` function. Those are both shortcuts for using `ds.partitioning()` in the case it returns a factory. \r\n   But yes, we designed this API when there was only reading and not yet writing ..\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-30T07:32:23.059+0000",
                    "updated": "2021-08-30T07:32:23.059+0000",
                    "started": "2021-08-30T07:32:23.059+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643312",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/643675",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r698734107\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       I didn't quite understand what you were doing earlier.  Now that I understand I withdraw my comment although I'm happy to proceed with the C++ changes (Antoine's suggestion makes them much less extensive) if it would help.\r\n   \r\n   Maybe it would be simpler to just allow `write_dataset` to accept a \"list of column names + partitioning format\" or a partitioning object?  You could describe the `Partitioning` object as something that is used to represent the inferred partitioning created by dataset discovery mechanisms.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-30T19:04:37.781+0000",
                    "updated": "2021-08-30T19:04:37.781+0000",
                    "started": "2021-08-30T19:04:37.781+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643675",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/643682",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r698743892\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       > Maybe it would be simpler to just allow write_dataset to accept a \"list of column names + partitioning format\" or a partitioning object?\r\n   \r\n   I am personally +1 on this (that's what I also mentioned on Zulip, and then we don't need to \"misuse\" the factories to pass along the field names). \r\n   The main downside is that this requires another keyword to specify the type of partitioning, though, if we want to support hive-style this way (R solves that by having an extra keyword `hive_style`, https://arrow.apache.org/docs/r/reference/write_dataset.html, we could have a `partitioning_flavor=\"hive\"`, although that might get a bit long). Not fully sure what I would prefer in the end.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-30T19:20:14.319+0000",
                    "updated": "2021-08-30T19:20:14.319+0000",
                    "started": "2021-08-30T19:20:14.319+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643682",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/643942",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r699178589\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       I changed `write_dataset` to accept `partitioning + partitioning_flavor`, see \r\n   ```\r\n   ds.write_dataset(table, tempdir, format='parquet',\r\n                        partitioning=[\"b\"], partitioning_flavor=\"hive\")\r\n   ```\r\n   from the test\r\n   \r\n   So we are not using a factory anymore. I'll update the documentation if we are ok with this as the final api we want users to rely on.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T10:08:51.001+0000",
                    "updated": "2021-08-31T10:08:51.001+0000",
                    "started": "2021-08-31T10:08:51.000+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643942",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/643974",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r699226689\n\n\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -714,9 +729,11 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         and `format` is not specified, it defaults to the same format as the\n         specified FileSystemDataset. When writing a Table or RecordBatch, this\n         keyword is required.\n-    partitioning : Partitioning, optional\n+    partitioning : Partitioning or list[str], optional\n         The partitioning scheme specified with the ``partitioning()``\n-        function.\n+        function or as a list of field names.\n+    partitioning_flavor : One of the partitioning flavors supported by\n+        ``pyarrow.dataset.partitioning``.\n\nReview comment:\n       ```suggestion\r\n       partitioning_flavor : str, optional\r\n           One of the partitioning flavors supported by\r\n           ``pyarrow.dataset.partitioning``.\r\n   ```\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"])\n+\n+    load_back = ds.dataset(tempdir, partitioning=[\"b\"])\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"x\", \"y\", \"z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n\nReview comment:\n       ```suggestion\r\n       assert load_back_table.equals(table)\r\n   ```\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -678,17 +678,32 @@ def dataset(source, schema=None, format=None, filesystem=None,\n         )\n \n \n-def _ensure_write_partitioning(scheme):\n-    if scheme is None:\n-        scheme = partitioning(pa.schema([]))\n-    if not isinstance(scheme, Partitioning):\n-        # TODO support passing field names, and get types from schema\n-        raise ValueError(\"partitioning needs to be actual Partitioning object\")\n-    return scheme\n+def _ensure_write_partitioning(part, schema, flavor):\n+    if isinstance(part, Partitioning) and flavor:\n+        raise ValueError(\n+            \"Providing a partitioning_flavor with \"\n+            \"a Partitioning object is not supported\"\n+        )\n+    elif isinstance(part, (tuple, list)):\n+        # Name of fields were provided instead of a partitioning object.\n+        # Create a partitioning factory with those field names.\n+        part = partitioning(\n+            schema=pa.schema([schema.field_by_name(f) for f in part]),\n+            flavor=flavor\n+        )\n+    elif part is None:\n+        part = partitioning(pa.schema([]), flavor=flavor)\n+\n+    if not isinstance(part, Partitioning):\n+        raise ValueError(\n+            \"partitioning must be a Partitioning object with a schema\"\n\nReview comment:\n       ```suggestion\r\n               \"partitioning must be a Partitioning object constructed with a schema\"\r\n   ```\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -788,7 +805,8 @@ def file_visitor(written_file):\n     if max_partitions is None:\n         max_partitions = 1024\n \n-    partitioning = _ensure_write_partitioning(partitioning)\n+    partitioning = _ensure_write_partitioning(partitioning, schema=schema,\n\nReview comment:\n       It seems that schema can be None at this point, in which case `_ensure_write_partitioning` might error. It seems that when passing a Scanner `schema` must be None (or when constructing a Scanner from an iterable, the `schema` is set to None after constructing the scanner, see L781 above). But in those cases, we can get the `schema` from the scanner to pass here.\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"])\n+\n+    load_back = ds.dataset(tempdir, partitioning=[\"b\"])\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"x\", \"y\", \"z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n+\n+\n+def test_write_dataset_with_field_names_hive(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"], partitioning_flavor=\"hive\")\n+\n+    load_back = ds.dataset(tempdir, partitioning=\"hive\")\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"b=x\", \"b=y\", \"b=z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n\nReview comment:\n       same here\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n\nReview comment:\n       I know the file is not super well structured (and there is a test just above that uses write_dataset as well), but _most_ write_dataset tests are below (after line 3000). So I would put this test for example right after `test_write_dataset_partitioned_dict(tempdir)`\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T11:38:33.140+0000",
                    "updated": "2021-08-31T11:38:33.140+0000",
                    "started": "2021-08-31T11:38:33.140+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "643974",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/644022",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r699304695\n\n\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n\nReview comment:\n       :+1: moved the tests\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T13:07:54.459+0000",
                    "updated": "2021-08-31T13:07:54.459+0000",
                    "started": "2021-08-31T13:07:54.459+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644022",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/644043",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r699343989\n\n\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -788,7 +805,8 @@ def file_visitor(written_file):\n     if max_partitions is None:\n         max_partitions = 1024\n \n-    partitioning = _ensure_write_partitioning(partitioning)\n+    partitioning = _ensure_write_partitioning(partitioning, schema=schema,\n\nReview comment:\n       Should have addressed those cases and added tests for them\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T13:50:51.100+0000",
                    "updated": "2021-08-31T13:50:51.100+0000",
                    "started": "2021-08-31T13:50:51.100+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644043",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/644107",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r699178589\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       I changed `write_dataset` to accept `partitioning + partitioning_flavor`, see \r\n   ```\r\n   ds.write_dataset(table, tempdir, format='parquet',\r\n                        partitioning=[\"b\"], partitioning_flavor=\"hive\")\r\n   ```\r\n   from the test\r\n   \r\n   So we are not using a factory anymore. I'll update the documentation if we are ok with this as the final api we want users to rely on.\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n\nReview comment:\n       :+1: moved the tests\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -788,7 +805,8 @@ def file_visitor(written_file):\n     if max_partitions is None:\n         max_partitions = 1024\n \n-    partitioning = _ensure_write_partitioning(partitioning)\n+    partitioning = _ensure_write_partitioning(partitioning, schema=schema,\n\nReview comment:\n       Should have addressed those cases and added tests for them\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T14:48:43.757+0000",
                    "updated": "2021-08-31T14:48:43.757+0000",
                    "started": "2021-08-31T14:48:43.756+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644107",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/644308",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r698743892\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       > Maybe it would be simpler to just allow write_dataset to accept a \"list of column names + partitioning format\" or a partitioning object?\r\n   \r\n   I am personally +1 on this (that's what I also mentioned on Zulip, and then we don't need to \"misuse\" the factories to pass along the field names). \r\n   The main downside is that this requires another keyword to specify the type of partitioning, though, if we want to support hive-style this way (R solves that by having an extra keyword `hive_style`, https://arrow.apache.org/docs/r/reference/write_dataset.html, we could have a `partitioning_flavor=\"hive\"`, although that might get a bit long). Not fully sure what I would prefer in the end.\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -714,9 +729,11 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         and `format` is not specified, it defaults to the same format as the\n         specified FileSystemDataset. When writing a Table or RecordBatch, this\n         keyword is required.\n-    partitioning : Partitioning, optional\n+    partitioning : Partitioning or list[str], optional\n         The partitioning scheme specified with the ``partitioning()``\n-        function.\n+        function or as a list of field names.\n+    partitioning_flavor : One of the partitioning flavors supported by\n+        ``pyarrow.dataset.partitioning``.\n\nReview comment:\n       ```suggestion\r\n       partitioning_flavor : str, optional\r\n           One of the partitioning flavors supported by\r\n           ``pyarrow.dataset.partitioning``.\r\n   ```\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"])\n+\n+    load_back = ds.dataset(tempdir, partitioning=[\"b\"])\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"x\", \"y\", \"z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n\nReview comment:\n       ```suggestion\r\n       assert load_back_table.equals(table)\r\n   ```\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -678,17 +678,32 @@ def dataset(source, schema=None, format=None, filesystem=None,\n         )\n \n \n-def _ensure_write_partitioning(scheme):\n-    if scheme is None:\n-        scheme = partitioning(pa.schema([]))\n-    if not isinstance(scheme, Partitioning):\n-        # TODO support passing field names, and get types from schema\n-        raise ValueError(\"partitioning needs to be actual Partitioning object\")\n-    return scheme\n+def _ensure_write_partitioning(part, schema, flavor):\n+    if isinstance(part, Partitioning) and flavor:\n+        raise ValueError(\n+            \"Providing a partitioning_flavor with \"\n+            \"a Partitioning object is not supported\"\n+        )\n+    elif isinstance(part, (tuple, list)):\n+        # Name of fields were provided instead of a partitioning object.\n+        # Create a partitioning factory with those field names.\n+        part = partitioning(\n+            schema=pa.schema([schema.field_by_name(f) for f in part]),\n+            flavor=flavor\n+        )\n+    elif part is None:\n+        part = partitioning(pa.schema([]), flavor=flavor)\n+\n+    if not isinstance(part, Partitioning):\n+        raise ValueError(\n+            \"partitioning must be a Partitioning object with a schema\"\n\nReview comment:\n       ```suggestion\r\n               \"partitioning must be a Partitioning object constructed with a schema\"\r\n   ```\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -788,7 +805,8 @@ def file_visitor(written_file):\n     if max_partitions is None:\n         max_partitions = 1024\n \n-    partitioning = _ensure_write_partitioning(partitioning)\n+    partitioning = _ensure_write_partitioning(partitioning, schema=schema,\n\nReview comment:\n       It seems that schema can be None at this point, in which case `_ensure_write_partitioning` might error. It seems that when passing a Scanner `schema` must be None (or when constructing a Scanner from an iterable, the `schema` is set to None after constructing the scanner, see L781 above). But in those cases, we can get the `schema` from the scanner to pass here.\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"])\n+\n+    load_back = ds.dataset(tempdir, partitioning=[\"b\"])\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"x\", \"y\", \"z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n+\n+\n+def test_write_dataset_with_field_names_hive(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"], partitioning_flavor=\"hive\")\n+\n+    load_back = ds.dataset(tempdir, partitioning=\"hive\")\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"b=x\", \"b=y\", \"b=z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n\nReview comment:\n       same here\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n\nReview comment:\n       I know the file is not super well structured (and there is a test just above that uses write_dataset as well), but _most_ write_dataset tests are below (after line 3000). So I would put this test for example right after `test_write_dataset_partitioned_dict(tempdir)`\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T15:09:37.758+0000",
                    "updated": "2021-08-31T15:09:37.758+0000",
                    "started": "2021-08-31T15:09:37.758+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644308",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/644387",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r698734107\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       I didn't quite understand what you were doing earlier.  Now that I understand I withdraw my comment although I'm happy to proceed with the C++ changes (Antoine's suggestion makes them much less extensive) if it would help.\r\n   \r\n   Maybe it would be simpler to just allow `write_dataset` to accept a \"list of column names + partitioning format\" or a partitioning object?  You could describe the `Partitioning` object as something that is used to represent the inferred partitioning created by dataset discovery mechanisms.\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-08-31T15:18:19.483+0000",
                    "updated": "2021-08-31T15:18:19.483+0000",
                    "started": "2021-08-31T15:18:19.483+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644387",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/644857",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r699178589\n\n\n\n##########\nFile path: python/pyarrow/_dataset.pyx\n##########\n@@ -1998,6 +1998,41 @@ cdef class PartitioningFactory(_Weakrefable):\n     cdef inline shared_ptr[CPartitioningFactory] unwrap(self):\n         return self.wrapped\n \n+    @property\n+    def type_name(self):\n+        return frombytes(self.factory.type_name())\n+\n+    def create_with_schema(self, schema):\n\nReview comment:\n       I changed `write_dataset` to accept `partitioning + partitioning_flavor`, see \r\n   ```\r\n   ds.write_dataset(table, tempdir, format='parquet',\r\n                        partitioning=[\"b\"], partitioning_flavor=\"hive\")\r\n   ```\r\n   from the test\r\n   \r\n   So we are not using a factory anymore. I'll update the documentation if we are ok with this as the final api we want users to rely on.\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n\nReview comment:\n       :+1: moved the tests\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -788,7 +805,8 @@ def file_visitor(written_file):\n     if max_partitions is None:\n         max_partitions = 1024\n \n-    partitioning = _ensure_write_partitioning(partitioning)\n+    partitioning = _ensure_write_partitioning(partitioning, schema=schema,\n\nReview comment:\n       Should have addressed those cases and added tests for them\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-01T09:10:43.286+0000",
                    "updated": "2021-09-01T09:10:43.286+0000",
                    "started": "2021-09-01T09:10:43.285+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "644857",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/645055",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on a change in pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#discussion_r699226689\n\n\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -714,9 +729,11 @@ def write_dataset(data, base_dir, basename_template=None, format=None,\n         and `format` is not specified, it defaults to the same format as the\n         specified FileSystemDataset. When writing a Table or RecordBatch, this\n         keyword is required.\n-    partitioning : Partitioning, optional\n+    partitioning : Partitioning or list[str], optional\n         The partitioning scheme specified with the ``partitioning()``\n-        function.\n+        function or as a list of field names.\n+    partitioning_flavor : One of the partitioning flavors supported by\n+        ``pyarrow.dataset.partitioning``.\n\nReview comment:\n       ```suggestion\r\n       partitioning_flavor : str, optional\r\n           One of the partitioning flavors supported by\r\n           ``pyarrow.dataset.partitioning``.\r\n   ```\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"])\n+\n+    load_back = ds.dataset(tempdir, partitioning=[\"b\"])\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"x\", \"y\", \"z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n\nReview comment:\n       ```suggestion\r\n       assert load_back_table.equals(table)\r\n   ```\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -678,17 +678,32 @@ def dataset(source, schema=None, format=None, filesystem=None,\n         )\n \n \n-def _ensure_write_partitioning(scheme):\n-    if scheme is None:\n-        scheme = partitioning(pa.schema([]))\n-    if not isinstance(scheme, Partitioning):\n-        # TODO support passing field names, and get types from schema\n-        raise ValueError(\"partitioning needs to be actual Partitioning object\")\n-    return scheme\n+def _ensure_write_partitioning(part, schema, flavor):\n+    if isinstance(part, Partitioning) and flavor:\n+        raise ValueError(\n+            \"Providing a partitioning_flavor with \"\n+            \"a Partitioning object is not supported\"\n+        )\n+    elif isinstance(part, (tuple, list)):\n+        # Name of fields were provided instead of a partitioning object.\n+        # Create a partitioning factory with those field names.\n+        part = partitioning(\n+            schema=pa.schema([schema.field_by_name(f) for f in part]),\n+            flavor=flavor\n+        )\n+    elif part is None:\n+        part = partitioning(pa.schema([]), flavor=flavor)\n+\n+    if not isinstance(part, Partitioning):\n+        raise ValueError(\n+            \"partitioning must be a Partitioning object with a schema\"\n\nReview comment:\n       ```suggestion\r\n               \"partitioning must be a Partitioning object constructed with a schema\"\r\n   ```\n\n##########\nFile path: python/pyarrow/dataset.py\n##########\n@@ -788,7 +805,8 @@ def file_visitor(written_file):\n     if max_partitions is None:\n         max_partitions = 1024\n \n-    partitioning = _ensure_write_partitioning(partitioning)\n+    partitioning = _ensure_write_partitioning(partitioning, schema=schema,\n\nReview comment:\n       It seems that schema can be None at this point, in which case `_ensure_write_partitioning` might error. It seems that when passing a Scanner `schema` must be None (or when constructing a Scanner from an iterable, the `schema` is set to None after constructing the scanner, see L781 above). But in those cases, we can get the `schema` from the scanner to pass here.\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"])\n+\n+    load_back = ds.dataset(tempdir, partitioning=[\"b\"])\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"x\", \"y\", \"z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n+\n+\n+def test_write_dataset_with_field_names_hive(tempdir):\n+    table = pa.table({'a': ['x', 'y', None], 'b': ['x', 'y', 'z']})\n+\n+    ds.write_dataset(table, tempdir, format='parquet',\n+                     partitioning=[\"b\"], partitioning_flavor=\"hive\")\n+\n+    load_back = ds.dataset(tempdir, partitioning=\"hive\")\n+    partitioning_dirs = {\n+        str(pathlib.Path(f).relative_to(tempdir).parent) for f in load_back.files\n+    }\n+    assert partitioning_dirs == {\"b=x\", \"b=y\", \"b=z\"}\n+\n+    load_back_table = load_back.to_table()\n+    assert load_back_table.to_pydict() == table.to_pydict()\n\nReview comment:\n       same here\n\n##########\nFile path: python/pyarrow/tests/test_dataset.py\n##########\n@@ -1577,6 +1577,38 @@ def test_dictionary_partitioning_outer_nulls_raises(tempdir):\n         ds.write_dataset(table, tempdir, format='parquet', partitioning=part)\n \n \n+def test_write_dataset_with_field_names(tempdir):\n\nReview comment:\n       I know the file is not super well structured (and there is a test just above that uses write_dataset as well), but _most_ write_dataset tests are below (after line 3000). So I would put this test for example right after `test_write_dataset_partitioned_dict(tempdir)`\n\n\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-01T09:31:08.429+0000",
                    "updated": "2021-09-01T09:31:08.429+0000",
                    "started": "2021-09-01T09:31:08.428+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "645055",
                    "issueId": "13397204"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/worklog/645224",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "amol- commented on pull request #11008:\nURL: https://github.com/apache/arrow/pull/11008#issuecomment-910185363\n\n\n   @westonpace I think yours and @jorisvandenbossche feedback should have been addressed, it would be great if we can merge this one so that I can work on a PR for the documentation. I'd like to keep PR small and address docs update in its own PR\n\n\n-- \nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nTo unsubscribe, e-mail: github-unsubscribe@arrow.apache.org\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2021-09-01T11:18:35.414+0000",
                    "updated": "2021-09-01T11:18:35.414+0000",
                    "started": "2021-09-01T11:18:35.414+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "645224",
                    "issueId": "13397204"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "id": "1",
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "name": "Bug",
            "subtask": false,
            "avatarId": 21133
        },
        "timespent": 28800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@b359ede[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@79c6fe3a[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@51f4d5fb[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@1f8dc6d1[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@9263a39[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@7c77b1aa[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@bdbe8d2[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@7a110c36[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@425e16bf[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@36505bf[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@57acf079[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@25ae2606[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 28800,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Sep 21 15:50:04 UTC 2021",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2021-09-21T15:50:04.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-13755/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2021-08-25T14:42:03.000+0000",
        "updated": "2021-09-21T19:02:46.000+0000",
        "timeoriginalestimate": null,
        "description": "When loading back datasets, it's possible to quickly provide the name of the columns for which data was partitioned using\r\n\r\n{code}\r\npartitioning=pyarrow.dataset.partitioning(field_names=[\"year\"])\r\n{code}\r\n\r\nthis is convenient because it's easier and quicker than providing the whole schema, which can still be autodetected from the loaded data.\r\n\r\nOn the other side, we don't support this when _saving_ data. If you provide {{field_names}} instead of the {{schema}} you will get a crash\r\n\r\n{code}\r\npyarrow/dataset.py in _ensure_write_partitioning(scheme)\r\n    684     if not isinstance(scheme, Partitioning):\r\n    685         # TODO support passing field names, and get types from schema\r\n--> 686         raise ValueError(\"partitioning needs to be actual Partitioning object\")\r\n    687     return scheme\r\n    688 \r\n{code}\r\n\r\nIt would be convenient to allow to use {{field_names}} only even when saving as we can automatically detect the schema from the table itself that we are saving.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "8h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 28800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Allow usage of field_names in partitioning when saving datasets",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13397204/comment/17418190",
                    "id": "17418190",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "Issue resolved by pull request 11008\n[https://github.com/apache/arrow/pull/11008]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2021-09-21T15:50:04.851+0000",
                    "updated": "2021-09-21T15:50:04.851+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|z0u8r4:",
        "customfield_12314139": null
    }
}