{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13441015",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015",
    "key": "ARROW-16276",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351550",
                "id": "12351550",
                "name": "9.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-08-03"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=willjones127",
            "name": "willjones127",
            "key": "willjones127",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
            },
            "displayName": "Will Jones",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333008",
                "id": "12333008",
                "name": "R"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jonkeane",
            "name": "jonkeane",
            "key": "jonkeane",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34057",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34057",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34057",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34057"
            },
            "displayName": "Jonathan Keane",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jonkeane",
            "name": "jonkeane",
            "key": "jonkeane",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34057",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34057",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34057",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34057"
            },
            "displayName": "Jonathan Keane",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 15600,
            "total": 15600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 15600,
            "total": 15600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16276/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 26,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/762613",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#issuecomment-1110321977\n\n   https://issues.apache.org/jira/browse/ARROW-16276\n\n\n",
                    "created": "2022-04-26T22:48:26.366+0000",
                    "updated": "2022-04-26T22:48:26.366+0000",
                    "started": "2022-04-26T22:48:26.366+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "762613",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/762614",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#issuecomment-1110321990\n\n   :warning: Ticket **has no components in JIRA**, make sure you assign one.\n\n\n",
                    "created": "2022-04-26T22:48:28.376+0000",
                    "updated": "2022-04-26T22:48:28.376+0000",
                    "started": "2022-04-26T22:48:28.376+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "762614",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/762782",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "eitsupi commented on PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#issuecomment-1110835008\n\n   It might be better to describe function and package names as `` `{dplyr}` `` or `` `write_dataset()` `` so that pkgdown can create the links automatically.\r\n   \r\n   https://github.com/r-lib/pkgdown/blob/feb91bf46c3ea78f8a03aead9f9a4934e3965ba4/vignettes/linking.Rmd?rgh-link-date=2022-02-09T10%3A52%3A57Z#L20-L36\n\n\n",
                    "created": "2022-04-27T10:25:13.447+0000",
                    "updated": "2022-04-27T10:25:13.447+0000",
                    "started": "2022-04-27T10:25:13.447+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "762782",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764202",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "paleolimbot commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r861728055\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n\nReview Comment:\n   ```suggestion\r\n   * `write_dataset()` now has more options for controlling row group and file sizes when\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n+is to define a customized conversion between an an Arrow Array and an R object \n+when the default conversion is slow or looses metadata important to the interpretation\n+of values in the array. For most types, the built-in vctrs extension type is probably \n+sufficient. See description and an example with `?new_extension_type`.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can now be easily concatenated:\n+\n+ * Arrays can now be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * Chunked arrays can now be concatenated with `c()`.\n+ * Record batches and tables now support `cbind()`.\n+ * Arrow tables now support `rbind()`. `concat_tables()` is also provided to \n+   concatenate tables while unifying schemas.\n+\n+## S3 Conversion Generics\n+\n+Arrow now provides S3 generic conversion functions such as `as_arrow_array()`\n+and `as_chunked_array()` for main Arrow objects. This includes, Arrow tables,\n\nReview Comment:\n   ```suggestion\r\n   and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n\nReview Comment:\n   ```suggestion\r\n     [tzdb package](https://cran.r-project.org/package=tzdb) is also\r\n   ```\r\n   \r\n   (I know that's a weird URL, but not using the 'canonical version' triggers a check NOTE, or used to, on the CMD check)\n\n\n\n",
                    "created": "2022-04-29T11:58:27.337+0000",
                    "updated": "2022-04-29T11:58:27.337+0000",
                    "started": "2022-04-29T11:58:27.336+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764202",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764203",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "paleolimbot commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r861735606\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n+is to define a customized conversion between an an Arrow Array and an R object \n+when the default conversion is slow or looses metadata important to the interpretation\n+of values in the array. For most types, the built-in vctrs extension type is probably \n+sufficient. See description and an example with `?new_extension_type`.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can now be easily concatenated:\n+\n+ * Arrays can now be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * Chunked arrays can now be concatenated with `c()`.\n+ * Record batches and tables now support `cbind()`.\n+ * Arrow tables now support `rbind()`. `concat_tables()` is also provided to \n+   concatenate tables while unifying schemas.\n+\n+## S3 Conversion Generics\n+\n+Arrow now provides S3 generic conversion functions such as `as_arrow_array()`\n+and `as_chunked_array()` for main Arrow objects. This includes, Arrow tables,\n\nReview Comment:\n   (just because the array and table methods are the ones most likely to be used)\n\n\n\n",
                    "created": "2022-04-29T11:59:15.557+0000",
                    "updated": "2022-04-29T11:59:15.557+0000",
                    "started": "2022-04-29T11:59:15.556+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764203",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764238",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nealrichardson commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r861791774\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n\nReview Comment:\n   Should we link to the format docs on extension types? https://arrow.apache.org/docs/format/Columnar.html#extension-types\r\n   \r\n   There are also some use cases described there. \r\n   \r\n   Also, I'm not sure the use case here is correct. If it's just about custom serialization of R objects, isn't that what `as_arrow_array` is for? Extension types are about when you need to define a standard outside of just this implementation, like when you want to have Python and R both understand the semantics of the data. If you're just trying to round trip data with R, the regular R metadata mechanism works for you, and if you need to serialize/deserialize the data differently, define an S3 method. \r\n   \r\n   \n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n+is to define a customized conversion between an an Arrow Array and an R object \n+when the default conversion is slow or looses metadata important to the interpretation\n+of values in the array. For most types, the built-in vctrs extension type is probably \n+sufficient. See description and an example with `?new_extension_type`.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can now be easily concatenated:\n+\n+ * Arrays can now be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * Chunked arrays can now be concatenated with `c()`.\n+ * Record batches and tables now support `cbind()`.\n+ * Arrow tables now support `rbind()`. `concat_tables()` is also provided to \n\nReview Comment:\n   ```suggestion\r\n    * Tables support `rbind()`. `concat_tables()` is also provided to \r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n\nReview Comment:\n   This is just one example of use case, there are/will be others (for example, you can pass a RecordBatchReader over the C interface, so you can get one from wherever in pyarrow, including Flight, and do dplyr on it)\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n+is to define a customized conversion between an an Arrow Array and an R object \n+when the default conversion is slow or looses metadata important to the interpretation\n+of values in the array. For most types, the built-in vctrs extension type is probably \n+sufficient. See description and an example with `?new_extension_type`.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can now be easily concatenated:\n+\n+ * Arrays can now be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * Chunked arrays can now be concatenated with `c()`.\n+ * Record batches and tables now support `cbind()`.\n+ * Arrow tables now support `rbind()`. `concat_tables()` is also provided to \n+   concatenate tables while unifying schemas.\n+\n+## S3 Conversion Generics\n+\n+Arrow now provides S3 generic conversion functions such as `as_arrow_array()`\n+and `as_chunked_array()` for main Arrow objects. This includes, Arrow tables,\n+record batches, arrays, chunked arrays, record batch readers, schemas, and\n+data types. This allows other packages to define custom conversions from their\n+types to Arrow objects, including extension arrays.\n+\n+## Other improvements and fixes\n+\n+* Dictionary arrays now support using ALTREP when converting to R factors.\n+* Math group generics are now implemented for ArrowDatum. This means you can use\n+  base functions like `sqrt()`, `log()`, and `exp()` with Arrow arrays and scalars.\n+* `read_*` and `write_*` functions now support R Connection objects for reading\n+  and writing files.\n+* Parquet improvements:\n+  * Parquet writer now supports Duration type columns.\n+  * The dataset Parquet reader now consumes less memory.\n * `median()` and `quantile()` will warn once about approximate calculations regardless of interactivity.\n+* `Array$cast()` can now cast struct arrays into another struct type with the same field names\n+  and structure (or a subset of fields) but different field types.\n+* The CSV writer is now much faster when writing string columns.\n * Removed Solaris workarounds, libarrow is now required.\n\nReview Comment:\n   ```suggestion\r\n   * Remove special handling for Solaris\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n+is to define a customized conversion between an an Arrow Array and an R object \n+when the default conversion is slow or looses metadata important to the interpretation\n+of values in the array. For most types, the built-in vctrs extension type is probably \n+sufficient. See description and an example with `?new_extension_type`.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can now be easily concatenated:\n+\n+ * Arrays can now be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * Chunked arrays can now be concatenated with `c()`.\n\nReview Comment:\n   ```suggestion\r\n    * ChunkedArrays can be concatenated with `c()`.\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n\nReview Comment:\n   ```suggestion\r\n   * `write_csv_arrow()` can write a `Dataset` or an Arrow dplyr query to a single file.\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n+is to define a customized conversion between an an Arrow Array and an R object \n+when the default conversion is slow or looses metadata important to the interpretation\n\nReview Comment:\n   ```suggestion\r\n   when the default conversion is slow or loses metadata important to the interpretation\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n\nReview Comment:\n   ```suggestion\r\n   * `map_batches()` correctly accepts `Dataset` objects.\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n+is to define a customized conversion between an an Arrow Array and an R object \n+when the default conversion is slow or looses metadata important to the interpretation\n+of values in the array. For most types, the built-in vctrs extension type is probably \n+sufficient. See description and an example with `?new_extension_type`.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can now be easily concatenated:\n+\n+ * Arrays can now be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * Chunked arrays can now be concatenated with `c()`.\n+ * Record batches and tables now support `cbind()`.\n\nReview Comment:\n   ```suggestion\r\n    * RecordBatches and Tables support `cbind()`.\r\n   ```\n\n\n\n",
                    "created": "2022-04-29T13:33:32.780+0000",
                    "updated": "2022-04-29T13:33:32.780+0000",
                    "started": "2022-04-29T13:33:32.779+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764238",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764280",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wjones127 commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r861884265\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n\nReview Comment:\n   Good to know! Would `R CMD CHECK` show this thing? Or some other command?\r\n   \n\n\n\n",
                    "created": "2022-04-29T14:54:20.523+0000",
                    "updated": "2022-04-29T14:54:20.523+0000",
                    "started": "2022-04-29T14:54:20.523+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764280",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764300",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wjones127 commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r861908400\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n\nReview Comment:\n   Good point, and I think I agree with you. I borrowed this language from the extension types R docs:\r\n   \r\n   https://github.com/apache/arrow/blob/d6ca3e2e9e995ff42df2465484ebf86de853a136/r/R/extension.R#L262-L268\r\n   \r\n   @paleolimbot Any thoughts on that?\r\n   \r\n   I'm can simple cut that part out for now and link to the existing docs on extension types:\r\n   \r\n   > Custom [extension arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) can be created and registered, allowing other packages to define their own array types. Extension arrays wrap regular Arrow array types and provide customized behavior and/or storage. See further description and an example with `?new_extension_type`.\n\n\n\n",
                    "created": "2022-04-29T15:22:34.500+0000",
                    "updated": "2022-04-29T15:22:34.500+0000",
                    "started": "2022-04-29T15:22:34.499+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764300",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764358",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "paleolimbot commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r861982016\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n\nReview Comment:\n   The existing documentation is correct, although a little confusing: `as_arrow_array()` is about converting *to* an Arrow Array, but you need to use an `ExtensionType` subclass in order to customize converting *from* an Arrow Array. Another compelling use of `ExtensionType` is, as Neal mentioned, where the type is defined in a Python package as well.\r\n   \r\n   Perhaps a solution here is to group the S3 Generics heading and the ExtensionType heading, because they're both under the theme of extensibility? Maybe:\r\n   \r\n   ```\r\n   ### Extensibility\r\n   \r\n   - Added S3 generic methods to create the core Arrow object types. In particular, packages can define the `as_arrow_array()` generic to ensure that a custom vector type is converted to an Arrow Array in a particular way (e.g., when converting a `data.frame` to an Arrow Table). Packages can also define an `as_arrow_table()` method to customize conversion of a table-like object (e.g., when an object is passed to `write_parquet()` or `write_feather()`).\r\n   - Custom [ExtensionType](https://arrow.apache.org/docs/format/Columnar.html#extension-types)s can be created and registered, allowing other packages to define their own array types and/or conversions from Arrow Arrays to R vectors. Extension arrays wrap regular Arrow array types and provide customized behavior and/or storage. See documentation for `new_extension_type()` for details.\r\n   - Implemented a generic extension type and `as_arrow_array()` methods for all objects where `vctrs::vec_is()` returns `TRUE` (i.e., any object that can be used as a column in a `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted to an Arrow Array.\r\n   ```\r\n   \r\n   (feel free to mix/match/scramble/disregard this with what you've written already!)\n\n\n\n",
                    "created": "2022-04-29T16:53:27.477+0000",
                    "updated": "2022-04-29T16:53:27.477+0000",
                    "started": "2022-04-29T16:53:27.477+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764358",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764359",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "paleolimbot commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r861982016\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n\nReview Comment:\n   The existing documentation is correct, although a little confusing: `as_arrow_array()` is about converting *to* an Arrow Array, but you need to use an `ExtensionType` subclass in order to customize converting *from* an Arrow Array. Another compelling use of `ExtensionType` is, as Neal mentioned, where the type is defined in a Python package as well.\r\n   \r\n   Perhaps a solution here is to group the S3 Generics heading and the ExtensionType heading, because they're both under the theme of extensibility? Maybe:\r\n   \r\n   ### Extensibility\r\n   \r\n   - Added S3 generic methods to create the core Arrow object types. In particular, packages can define the `as_arrow_array()` generic to ensure that a custom vector type is converted to an Arrow Array in a particular way (e.g., when converting a `data.frame` to an Arrow Table). Packages can also define an `as_arrow_table()` method to customize conversion of a table-like object (e.g., when an object is passed to `write_parquet()` or `write_feather()`).\r\n   - Custom [ExtensionType](https://arrow.apache.org/docs/format/Columnar.html#extension-types)s can be created and registered, allowing other packages to define their own array types and/or conversions from Arrow Arrays to R vectors. Extension arrays wrap regular Arrow array types and provide customized behavior and/or storage. See documentation for `new_extension_type()` for details.\r\n   - Implemented a generic extension type and `as_arrow_array()` methods for all objects where `vctrs::vec_is()` returns `TRUE` (i.e., any object that can be used as a column in a `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted to an Arrow Array.\r\n   \r\n   (feel free to mix/match/scramble/disregard this with what you've written already!)\n\n\n\n",
                    "created": "2022-04-29T16:53:42.518+0000",
                    "updated": "2022-04-29T16:53:42.518+0000",
                    "started": "2022-04-29T16:53:42.515+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764359",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764437",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wjones127 commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r862093726\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,111 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - now correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - now can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are now supported on `RecordBatchReader`. This allows results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` now accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins now support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` no longer errors if passed a `Dataset` object.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` now works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays now support `base::format()`\n+  * `strptime()` now returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extension Array Support\n+\n+Custom extension arrays can be created and registered, allowing other packages to\n+define their own array types. Extension arrays wrap regular Arrow array types and\n+provide customized behavior and/or storage. A common use-case for extension types \n\nReview Comment:\n   Yeah agreed that combining the sections makes sense.\n\n\n\n",
                    "created": "2022-04-29T19:37:12.731+0000",
                    "updated": "2022-04-29T19:37:12.731+0000",
                    "started": "2022-04-29T19:37:12.731+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764437",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764623",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "eitsupi commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r862313809\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,123 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset()` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow()` can write a `Dataset` or an Arrow dplyr query to a single file.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/package=tzdb) is also\n+* Timezone operations are supported on Windows if the \n\nReview Comment:\n   These lines should be removed.\n\n\n\n",
                    "created": "2022-04-30T06:36:27.943+0000",
                    "updated": "2022-04-30T06:36:27.943+0000",
                    "started": "2022-04-30T06:36:27.943+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764623",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764633",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "eitsupi commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r862313809\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,123 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset()` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow()` can write a `Dataset` or an Arrow dplyr query to a single file.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/package=tzdb) is also\n+* Timezone operations are supported on Windows if the \n\nReview Comment:\n   These duplicate lines should be removed.\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,123 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset()` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow()` can write a `Dataset` or an Arrow dplyr query to a single file.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/package=tzdb) is also\n+* Timezone operations are supported on Windows if the \n\nReview Comment:\n   These duplicated lines should be removed.\n\n\n\n",
                    "created": "2022-04-30T08:12:54.272+0000",
                    "updated": "2022-04-30T08:12:54.272+0000",
                    "started": "2022-04-30T08:12:54.271+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764633",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764994",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nealrichardson commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r862955688\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,123 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset()` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow()` can write a `Dataset` or an Arrow dplyr query to a single file.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/package=tzdb) is also\n+* Timezone operations are supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extensibility\n+\n+* Added S3 generic conversion functions such as `as_arrow_array()`\n+  and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\n+  record batches, arrays, chunked arrays, record batch readers, schemas, and\n+  data types. This allows other packages to define custom conversions from their\n+  types to Arrow objects, including extension arrays.\n+* Custom [extension types and arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) \n+  can be created and registered, allowing other packages to\n+  define their own array types. Extension arrays wrap regular Arrow array types and\n+  provide customized behavior and/or storage. See description and an example with\n+  `?new_extension_type`.\n+* Implemented a generic extension type and as_arrow_array() methods for all objects where     \n+  `vctrs::vec_is()` returns TRUE (i.e., any object that can be used as a column in a \n+  `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted \n+  to an Arrow Array.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can be easily concatenated:\n+\n+ * Arrays can be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * ChunkedArrays can be concatenated with `c()`.\n+ * RecordBatches and Tables support `cbind()`.\n+ * Tables support `rbind()`. `concat_tables()` is also provided to \n+ * Chunked arrays can be concatenated with `c()`.\n+ * Record batches and tables support `cbind()`.\n+ * Arrow tables support `rbind()`. `concat_tables()` is also provided to \n+   concatenate tables while unifying schemas.\n+\n+## Other improvements and fixes\n+\n+* Dictionary arrays support using ALTREP when converting to R factors.\n+* Math group generics are implemented for ArrowDatum. This means you can use\n+  base functions like `sqrt()`, `log()`, and `exp()` with Arrow arrays and scalars.\n+* `read_*` and `write_*` functions support R Connection objects for reading\n+  and writing files.\n+* Parquet improvements:\n+  * Parquet writer supports Duration type columns.\n+  * The dataset Parquet reader consumes less memory.\n * `median()` and `quantile()` will warn once about approximate calculations regardless of interactivity.\n-* Removed Solaris workarounds, libarrow is now required.\n+* `Array$cast()` can cast struct arrays into another struct type with the same field names\n+  and structure (or a subset of fields) but different field types.\n+* The CSV writer is now much faster when writing string columns.\n\nReview Comment:\n   More duplicated lines\r\n   \r\n   ```suggestion\r\n   ```\n\n\n\n",
                    "created": "2022-05-02T15:40:42.150+0000",
                    "updated": "2022-05-02T15:40:42.150+0000",
                    "started": "2022-05-02T15:40:42.150+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764994",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/764996",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nealrichardson commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r862955886\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,123 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset()` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow()` can write a `Dataset` or an Arrow dplyr query to a single file.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/package=tzdb) is also\n+* Timezone operations are supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extensibility\n+\n+* Added S3 generic conversion functions such as `as_arrow_array()`\n+  and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\n+  record batches, arrays, chunked arrays, record batch readers, schemas, and\n+  data types. This allows other packages to define custom conversions from their\n+  types to Arrow objects, including extension arrays.\n+* Custom [extension types and arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) \n+  can be created and registered, allowing other packages to\n+  define their own array types. Extension arrays wrap regular Arrow array types and\n+  provide customized behavior and/or storage. See description and an example with\n+  `?new_extension_type`.\n+* Implemented a generic extension type and as_arrow_array() methods for all objects where     \n+  `vctrs::vec_is()` returns TRUE (i.e., any object that can be used as a column in a \n+  `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted \n+  to an Arrow Array.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can be easily concatenated:\n+\n+ * Arrays can be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * ChunkedArrays can be concatenated with `c()`.\n+ * RecordBatches and Tables support `cbind()`.\n+ * Tables support `rbind()`. `concat_tables()` is also provided to \n+ * Chunked arrays can be concatenated with `c()`.\n+ * Record batches and tables support `cbind()`.\n+ * Arrow tables support `rbind()`. `concat_tables()` is also provided to \n+   concatenate tables while unifying schemas.\n+\n+## Other improvements and fixes\n+\n+* Dictionary arrays support using ALTREP when converting to R factors.\n+* Math group generics are implemented for ArrowDatum. This means you can use\n+  base functions like `sqrt()`, `log()`, and `exp()` with Arrow arrays and scalars.\n+* `read_*` and `write_*` functions support R Connection objects for reading\n+  and writing files.\n+* Parquet improvements:\n+  * Parquet writer supports Duration type columns.\n+  * The dataset Parquet reader consumes less memory.\n * `median()` and `quantile()` will warn once about approximate calculations regardless of interactivity.\n-* Removed Solaris workarounds, libarrow is now required.\n+* `Array$cast()` can cast struct arrays into another struct type with the same field names\n+  and structure (or a subset of fields) but different field types.\n+* The CSV writer is now much faster when writing string columns.\n+* Remove special handling for Solaris\n+* The CSV writer is much faster when writing string columns.\n+* Removed Solaris workarounds, libarrow is required.\n\nReview Comment:\n   ```suggestion\r\n   ```\n\n\n\n",
                    "created": "2022-05-02T15:40:55.541+0000",
                    "updated": "2022-05-02T15:40:55.541+0000",
                    "started": "2022-05-02T15:40:55.540+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "764996",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/765001",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wjones127 commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r862965834\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,123 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - now supports `dplyr::rename_with()`.\n+  - `dplyr::count()` now returns an ungrouped dataframe.\n+* `write_dataset()` now has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow()` can write a `Dataset` or an Arrow dplyr query to a single file.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are now supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/package=tzdb) is also\n+* Timezone operations are supported on Windows if the \n\nReview Comment:\n   Thanks! I clearly need to do a better job of checking the diffs of git merges.\n\n\n\n",
                    "created": "2022-05-02T15:52:31.773+0000",
                    "updated": "2022-05-02T15:52:31.773+0000",
                    "started": "2022-05-02T15:52:31.772+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "765001",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/765532",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nealrichardson commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r863982366\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n\nReview Comment:\n   This is new? I thought this has been supported from the beginning.\n\n\n\n",
                    "created": "2022-05-03T16:48:45.146+0000",
                    "updated": "2022-05-03T16:48:45.146+0000",
                    "started": "2022-05-03T16:48:45.145+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "765532",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/765540",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "nealrichardson commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r863983260\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n\nReview Comment:\n   is this correct?\r\n   \r\n   ```suggestion\r\n       * `lubridate::date()` (extract date from timestamp), \r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n\nReview Comment:\n   what is epiyear? drop the parenthetical if we don't have anything to clarify\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n\nReview Comment:\n   ?\r\n   ```suggestion\r\n       * `lubridate::tz()` (string timezone),\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extensibility\n+\n+* Added S3 generic conversion functions such as `as_arrow_array()`\n+  and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\n+  record batches, arrays, chunked arrays, record batch readers, schemas, and\n+  data types. This allows other packages to define custom conversions from their\n+  types to Arrow objects, including extension arrays.\n+* Custom [extension types and arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) \n+  can be created and registered, allowing other packages to\n+  define their own array types. Extension arrays wrap regular Arrow array types and\n+  provide customized behavior and/or storage. See description and an example with\n+  `?new_extension_type`.\n+* Implemented a generic extension type and as_arrow_array() methods for all objects where     \n+  `vctrs::vec_is()` returns TRUE (i.e., any object that can be used as a column in a \n+  `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted \n+  to an Arrow Array.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can be easily concatenated:\n+\n+ * Arrays can be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * ChunkedArrays can be concatenated with `c()`.\n+ * RecordBatches and Tables support `cbind()`.\n+ * Tables support `rbind()`. `concat_tables()` is also provided to\n+   concatenate tables while unifying schemas.\n+\n+## Other improvements and fixes\n+\n+* Dictionary arrays support using ALTREP when converting to R factors.\n+* Math group generics are implemented for ArrowDatum. This means you can use\n+  base functions like `sqrt()`, `log()`, and `exp()` with Arrow arrays and scalars.\n+* `read_*` and `write_*` functions support R Connection objects for reading\n+  and writing files.\n+* Parquet improvements:\n+  * Parquet writer supports Duration type columns.\n+  * The dataset Parquet reader consumes less memory.\n * `median()` and `quantile()` will warn once about approximate calculations regardless of interactivity.\n-* Removed Solaris workarounds, libarrow is now required.\n+* `Array$cast()` can cast struct arrays into another struct type with the same field names\n\nReview Comment:\n   ```suggestion\r\n   * `Array$cast()` can cast StructArrays into another struct type with the same field names\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extensibility\n+\n+* Added S3 generic conversion functions such as `as_arrow_array()`\n+  and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\n+  record batches, arrays, chunked arrays, record batch readers, schemas, and\n+  data types. This allows other packages to define custom conversions from their\n+  types to Arrow objects, including extension arrays.\n+* Custom [extension types and arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) \n+  can be created and registered, allowing other packages to\n+  define their own array types. Extension arrays wrap regular Arrow array types and\n+  provide customized behavior and/or storage. See description and an example with\n+  `?new_extension_type`.\n+* Implemented a generic extension type and as_arrow_array() methods for all objects where     \n+  `vctrs::vec_is()` returns TRUE (i.e., any object that can be used as a column in a \n+  `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted \n+  to an Arrow Array.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can be easily concatenated:\n+\n+ * Arrays can be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * ChunkedArrays can be concatenated with `c()`.\n+ * RecordBatches and Tables support `cbind()`.\n+ * Tables support `rbind()`. `concat_tables()` is also provided to\n\nReview Comment:\n   This is correct, no rbind for RecordBatch? wasn't there some alternative to concatenate batches?\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extensibility\n+\n+* Added S3 generic conversion functions such as `as_arrow_array()`\n+  and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\n+  record batches, arrays, chunked arrays, record batch readers, schemas, and\n+  data types. This allows other packages to define custom conversions from their\n+  types to Arrow objects, including extension arrays.\n+* Custom [extension types and arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) \n+  can be created and registered, allowing other packages to\n+  define their own array types. Extension arrays wrap regular Arrow array types and\n+  provide customized behavior and/or storage. See description and an example with\n+  `?new_extension_type`.\n+* Implemented a generic extension type and as_arrow_array() methods for all objects where     \n+  `vctrs::vec_is()` returns TRUE (i.e., any object that can be used as a column in a \n+  `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted \n+  to an Arrow Array.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can be easily concatenated:\n+\n+ * Arrays can be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * ChunkedArrays can be concatenated with `c()`.\n+ * RecordBatches and Tables support `cbind()`.\n+ * Tables support `rbind()`. `concat_tables()` is also provided to\n+   concatenate tables while unifying schemas.\n+\n+## Other improvements and fixes\n+\n+* Dictionary arrays support using ALTREP when converting to R factors.\n+* Math group generics are implemented for ArrowDatum. This means you can use\n+  base functions like `sqrt()`, `log()`, and `exp()` with Arrow arrays and scalars.\n+* `read_*` and `write_*` functions support R Connection objects for reading\n+  and writing files.\n+* Parquet improvements:\n+  * Parquet writer supports Duration type columns.\n+  * The dataset Parquet reader consumes less memory.\n * `median()` and `quantile()` will warn once about approximate calculations regardless of interactivity.\n\nReview Comment:\n   ```suggestion\r\n   * `median()` and `quantile()` will warn only once about approximate calculations regardless of interactivity.\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extensibility\n+\n+* Added S3 generic conversion functions such as `as_arrow_array()`\n+  and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\n+  record batches, arrays, chunked arrays, record batch readers, schemas, and\n+  data types. This allows other packages to define custom conversions from their\n+  types to Arrow objects, including extension arrays.\n+* Custom [extension types and arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) \n+  can be created and registered, allowing other packages to\n+  define their own array types. Extension arrays wrap regular Arrow array types and\n+  provide customized behavior and/or storage. See description and an example with\n+  `?new_extension_type`.\n+* Implemented a generic extension type and as_arrow_array() methods for all objects where     \n+  `vctrs::vec_is()` returns TRUE (i.e., any object that can be used as a column in a \n+  `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted \n+  to an Arrow Array.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can be easily concatenated:\n+\n+ * Arrays can be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * ChunkedArrays can be concatenated with `c()`.\n+ * RecordBatches and Tables support `cbind()`.\n+ * Tables support `rbind()`. `concat_tables()` is also provided to\n+   concatenate tables while unifying schemas.\n+\n+## Other improvements and fixes\n+\n+* Dictionary arrays support using ALTREP when converting to R factors.\n+* Math group generics are implemented for ArrowDatum. This means you can use\n+  base functions like `sqrt()`, `log()`, and `exp()` with Arrow arrays and scalars.\n+* `read_*` and `write_*` functions support R Connection objects for reading\n+  and writing files.\n+* Parquet improvements:\n+  * Parquet writer supports Duration type columns.\n+  * The dataset Parquet reader consumes less memory.\n * `median()` and `quantile()` will warn once about approximate calculations regardless of interactivity.\n-* Removed Solaris workarounds, libarrow is now required.\n+* `Array$cast()` can cast struct arrays into another struct type with the same field names\n+  and structure (or a subset of fields) but different field types.\n+* Removed special handling for Solaris.\n+* The CSV writer is much faster when writing string columns.\n+* Fixed an issue where `set_io_thread_count()` would set the CPU count instead of\n+  the IO thread count.\n+* `RandomAccessFile` has a `$ReadMetadata()` method that provides useful\n+  metadata provided by the filesystem.\n+* `grepl` binding returns `FALSE` for `NA` inputs (previously it returned `NA`),\n+  which matches the behavior of `base::grepl`.\n\nReview Comment:\n   ```suggestion\r\n     to match the behavior of `base::grepl()`.\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n\nReview Comment:\n   this?\r\n   ```suggestion\r\n       * `lubridate::dst()` (daylight savings time indicator, logical/boolean),\r\n   ```\n\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n\nReview Comment:\n   Drop \"Added\" from all of these, seems inconsistent with the ones above\n\n\n\n",
                    "created": "2022-05-03T16:54:40.615+0000",
                    "updated": "2022-05-03T16:54:40.615+0000",
                    "started": "2022-05-03T16:54:40.615+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "765540",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/765562",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wjones127 commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r864022568\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n+    schemas to produce a `UnionDataset`.\n+* Arrow `{dplyr}` queries:\n+  - are supported on `RecordBatchReader`. This allows, for example, results from DuckDB\n+  to be streamed back into Arrow rather than materialized before continuing the pipeline.\n+  - no longer need to materialize the entire result table before writing to a dataset\n+    if the query contains contains aggregations or joins.\n+  - supports `dplyr::rename_with()`.\n+  - `dplyr::count()` returns an ungrouped dataframe.\n+* `write_dataset` has more options for controlling row group and file sizes when\n+  writing partitioned datasets, such as `max_open_files`, `max_rows_per_file`, \n+  `min_rows_per_group`, and `max_rows_per_group`.\n+* `write_csv_arrow` accepts a `Dataset` or an Arrow dplyr query.\n+* Joining one or more datasets while `option(use_threads = FALSE)` no longer\n+  crashes R. That option is set by default on Windows.\n+* `dplyr` joins support the `suffix` argument to handle overlap in column names.\n+* Filtering a Parquet dataset with `is.na()` no longer misses any rows.\n+* `map_batches()` correctly accepts `Dataset` objects.\n+\n+## Enhancements to date and time support\n+\n+* `read_csv_arrow()`'s readr-style type `T` is mapped to `timestamp(unit = \"ns\")` \n+  instead of `timestamp(unit = \"s\")`.\n+* For Arrow dplyr queries, added additional `{lubridate}` features and fixes:\n+  * New component extraction functions: \n+    * `lubridate::tz()` (timezone),\n+    * `lubridate::semester()` (semester), \n+    * `lubridate::dst()` (daylight savings time indicator),\n+    * `lubridate::date()` (extract date), \n+    * `lubridate::epiyear()` (epiyear),\n+  * `lubridate::month()` works with integer inputs.\n+  * Added `lubridate::make_date()` & `lubridate::make_datetime()` + \n+    `lubridate::ISOdatetime()` & `lubridate::ISOdate()` to \n+    create date-times from numeric representations. \n+  * Added `lubridate::decimal_date()` and `lubridate::date_decimal()`\n+  * Added `lubridate::make_difftime()` (duration constructor)\n+  * Added `?lubridate::duration` helper functions, such as `dyears()`, `dhours()`, `dseconds()`.\n+  * Added `lubridate::leap_year()`\n+  * Added `lubridate::as_date()` and `lubridate::as_datetime()`\n+* Also for Arrow dplyr queries, added support for base date and time functions:\n+  * Added `base::difftime` and `base::as.difftime()` \n+  * Added `base::as.Date()` to convert to date\n+  * Arrow timestamp and date arrays support `base::format()`\n+  * `strptime()` returns `NA` instead of erroring in case of format mismatch,\n+    just like `base::strptime()`.\n+* Timezone operations are supported on Windows if the \n+  [tzdb package](https://cran.r-project.org/web/packages/tzdb/index.html) is also\n+  installed.\n+\n+## Extensibility\n+\n+* Added S3 generic conversion functions such as `as_arrow_array()`\n+  and `as_arrow_table()` for main Arrow objects. This includes, Arrow tables,\n+  record batches, arrays, chunked arrays, record batch readers, schemas, and\n+  data types. This allows other packages to define custom conversions from their\n+  types to Arrow objects, including extension arrays.\n+* Custom [extension types and arrays](https://arrow.apache.org/docs/format/Columnar.html#extension-types) \n+  can be created and registered, allowing other packages to\n+  define their own array types. Extension arrays wrap regular Arrow array types and\n+  provide customized behavior and/or storage. See description and an example with\n+  `?new_extension_type`.\n+* Implemented a generic extension type and as_arrow_array() methods for all objects where     \n+  `vctrs::vec_is()` returns TRUE (i.e., any object that can be used as a column in a \n+  `tibble::tibble()`), provided that the underlying `vctrs::vec_data()` can be converted \n+  to an Arrow Array.\n+\n+## Concatenation Support\n+\n+Arrow arrays and tables can be easily concatenated:\n+\n+ * Arrays can be concatenated with `concat_arrays()` or, if zero-copy is desired\n+   and chunking is acceptable, using `ChunkedArray$create()`.\n+ * ChunkedArrays can be concatenated with `c()`.\n+ * RecordBatches and Tables support `cbind()`.\n+ * Tables support `rbind()`. `concat_tables()` is also provided to\n\nReview Comment:\n   The alternative is to make it a Table, but that's not really new IMO. https://github.com/apache/arrow/blob/master/r/R/record-batch.R#L195\n\n\n\n",
                    "created": "2022-05-03T17:32:33.385+0000",
                    "updated": "2022-05-03T17:32:33.385+0000",
                    "started": "2022-05-03T17:32:33.384+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "765562",
                    "issueId": "13441015"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/worklog/765569",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wjones127 commented on code in PR #13005:\nURL: https://github.com/apache/arrow/pull/13005#discussion_r864024451\n\n\n##########\nr/NEWS.md:\n##########\n@@ -19,19 +19,110 @@\n \n # arrow 7.0.0.9000\n \n-* `read_csv_arrow()`'s readr-style type `T` is now mapped to `timestamp(unit = \"ns\")` instead of `timestamp(unit = \"s\")`.\n-* `lubridate`:\n-  * component extraction functions: `tz()` (timezone), `semester()` (semester), `dst()` (daylight savings time indicator), `date()` (extract date), `epiyear()` (epiyear), improvements to `month()`, which now works with integer inputs.\n-  * Added `make_date()` & `make_datetime()` + `ISOdatetime()` & `ISOdate()` to create date-times from numeric representations. \n-  * Added `decimal_date()` and `date_decimal()`\n-  * Added `make_difftime()` (duration constructor)\n-  * Added duration helper functions: `dyears()`, `dmonths()`, `dweeks()`, `ddays()`, `dhours()`, `dminutes()`, `dseconds()`, `dmilliseconds()`, `dmicroseconds()`, `dnanoseconds()`.\n-* date-time functionality:\n-  * Added `as_date()` and `as_datetime()`\n-  * Added `difftime` and `as.difftime()` \n-  * Added `as.Date()` to convert to date\n+## Enhancements to dplyr and datasets\n+\n+* `open_dataset()`:\n+  - correctly supports the `skip` argument for skipping header rows in CSV datasets.\n+  - can take a list of datasets with differing schemas and attempt to unify the \n\nReview Comment:\n   It was originally intended to be supported, but wasn't tested and there was a regression that broke it, at least for the past few versions. It was fixed in https://github.com/apache/arrow/pull/12629.\n\n\n\n",
                    "created": "2022-05-03T17:35:08.608+0000",
                    "updated": "2022-05-03T17:35:08.608+0000",
                    "started": "2022-05-03T17:35:08.608+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "765569",
                    "issueId": "13441015"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 15600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@14d0fa46[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@124dcdfa[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4f04723c[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@33da543b[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5b765d33[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@2a9bfbde[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@46e2f923[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@27781648[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4e8e4851[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@3b3e0f55[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6ac4d2f0[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@de943b6[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 15600,
        "customfield_12312520": null,
        "customfield_12312521": "Tue May 03 19:30:33 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-05-03T19:30:33.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16276/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2022-04-21T22:11:19.000+0000",
        "updated": "2022-07-27T13:00:39.000+0000",
        "timeoriginalestimate": null,
        "description": "I typically use a command like:\r\n\r\n{code}\r\ngit log fcab481 --grep=\".*\\[R\\].*\" --format=\"%s\"\r\n{code}\r\n\r\nWhich will find all the commits with {{[R]}}, since commit fcab481. I found commit fcab481 by going to the 7.0.0 release branch and then finding the last commit that is in the master branch as well as the 7.0.0 release. \r\n\r\n",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "4h 20m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 15600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[R] Release News",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/comment/17528383",
                    "id": "17528383",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=willjones127",
                        "name": "willjones127",
                        "key": "willjones127",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
                        },
                        "displayName": "Will Jones",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "I think that command is changed up until that commit. Changes after that commit seems to be:\r\n\r\n{code:bash}\r\ngit log fcab481..HEAD --grep=\".*\\[R\\].*\" --format=\"%s\" > r-changes.txt\r\n{code}",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=willjones127",
                        "name": "willjones127",
                        "key": "willjones127",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34058",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34058",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34058",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34058"
                        },
                        "displayName": "Will Jones",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-04-26T20:08:12.096+0000",
                    "updated": "2022-04-26T20:08:12.096+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13441015/comment/17531376",
                    "id": "17531376",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 13005\n[https://github.com/apache/arrow/pull/13005]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-05-03T19:30:33.472+0000",
                    "updated": "2022-05-03T19:30:33.472+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z11oxk:",
        "customfield_12314139": null
    }
}