{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13427653",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653",
    "key": "ARROW-15641",
    "fields": {
        "parent": {
            "id": "13427619",
            "key": "ARROW-15635",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13427619",
            "fields": {
                "summary": "[C++][Python] UDF Integration ",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                    "description": "The issue is open and ready for the assignee to start work on it.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                    "name": "Open",
                    "id": "1",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                        "id": 2,
                        "key": "new",
                        "colorName": "blue-gray",
                        "name": "To Do"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
                    "id": "3",
                    "description": "A task that needs to be done.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
                    "name": "Task",
                    "subtask": false,
                    "avatarId": 21148
                }
            }
        },
        "fixVersions": [],
        "resolution": null,
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vibhatha",
            "name": "vibhatha",
            "key": "vibhatha",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
            },
            "displayName": "Vibhatha Lakmal Abeykoon",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/3",
            "description": "This issue is being actively worked on at the moment by the assignee.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/inprogress.png",
            "name": "In Progress",
            "id": "3",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/4",
                "id": 4,
                "key": "indeterminate",
                "colorName": "yellow",
                "name": "In Progress"
            }
        },
        "components": [],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vibhatha",
            "name": "vibhatha",
            "key": "vibhatha",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
            },
            "displayName": "Vibhatha Lakmal Abeykoon",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=vibhatha",
            "name": "vibhatha",
            "key": "vibhatha",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34044",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34044",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34044",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34044"
            },
            "displayName": "Vibhatha Lakmal Abeykoon",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 3600,
            "total": 3600,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 3600,
            "total": 3600,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15641/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 6,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/worklog/820866",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha opened a new pull request, #14527:\nURL: https://github.com/apache/arrow/pull/14527\n\n   Initial Draft of Aggregate UDFs for Python\r\n   \r\n   - [ ] Improve the existing logic with more tests\r\n   - [ ] Find out a missing aggregate function and try to apply it with the current API (check if the applied theory sustains)\r\n   - [ ] Improvement function docs and comments\r\n   - [ ] Self-review\n\n\n",
                    "created": "2022-10-27T08:14:04.765+0000",
                    "updated": "2022-10-27T08:14:04.765+0000",
                    "started": "2022-10-27T08:14:04.765+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "820866",
                    "issueId": "13427653"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/worklog/820867",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #14527:\nURL: https://github.com/apache/arrow/pull/14527#issuecomment-1293157353\n\n   https://issues.apache.org/jira/browse/ARROW-15641\n\n\n",
                    "created": "2022-10-27T08:14:26.022+0000",
                    "updated": "2022-10-27T08:14:26.022+0000",
                    "started": "2022-10-27T08:14:26.022+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "820867",
                    "issueId": "13427653"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/worklog/820868",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #14527:\nURL: https://github.com/apache/arrow/pull/14527#issuecomment-1293157386\n\n   :warning: Ticket **has no components in JIRA**, make sure you assign one.\n\n\n",
                    "created": "2022-10-27T08:14:27.727+0000",
                    "updated": "2022-10-27T08:14:27.727+0000",
                    "started": "2022-10-27T08:14:27.727+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "820868",
                    "issueId": "13427653"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/worklog/820869",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #14527:\nURL: https://github.com/apache/arrow/pull/14527#issuecomment-1293157416\n\n   :warning: Ticket **has not been started in JIRA**, please click 'Start Progress'.\n\n\n",
                    "created": "2022-10-27T08:14:29.496+0000",
                    "updated": "2022-10-27T08:14:29.496+0000",
                    "started": "2022-10-27T08:14:29.495+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "820869",
                    "issueId": "13427653"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/worklog/822601",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on PR #14527:\nURL: https://github.com/apache/arrow/pull/14527#issuecomment-1299935173\n\n   cc @westonpace appreciate an initial review on the draft PR. \n\n\n",
                    "created": "2022-11-02T09:30:43.527+0000",
                    "updated": "2022-11-02T09:30:43.527+0000",
                    "started": "2022-11-02T09:30:43.526+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "822601",
                    "issueId": "13427653"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/worklog/826416",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on code in PR #14527:\nURL: https://github.com/apache/arrow/pull/14527#discussion_r1023541046\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n\nReview Comment:\n   I'm not much of a python expert but getters and setters seem like overkill here.  Are they needed?\n\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"count: \" + str(self.non_null)\n+\n+    def init():\n+        state = State(0)\n+        return state\n\nReview Comment:\n   ```suggestion\r\n           return State(0)\r\n   ```\n\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"count: \" + str(self.non_null)\n+\n+    def init():\n+        state = State(0)\n+        return state\n+\n+    def consume(ctx, x):\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+        elif isinstance(x, pa.Scalar):\n+            if x.as_py():\n+                non_null = 1\n+        non_null = non_null + ctx.state.non_null\n+        return State(non_null)\n+\n+    def merge(ctx, other_state):\n+        merged_state_val = ctx.state.non_null + other_state.non_null\n+        return State(merged_state_val)\n+\n+    def finalize(ctx):\n+        return pa.array([ctx.state.non_null])\n+\n+    func_name = \"simple_count\"\n+    unary_doc = {\"summary\": \"count function\",\n+                 \"description\": \"test agg count function\"}\n+\n+    pc.register_scalar_aggregate_function(init,\n+                                          consume,\n+                                          merge,\n+                                          finalize,\n+                                          func_name,\n+                                          unary_doc,\n+                                          {\"array\": pa.int64()},\n+                                          pa.int64())\n+\n+    assert pc.call_function(func_name, [pa.array(\n+        [10, 20, None, 30, None, 40])]) == pa.array([4])\n+\n+\n+def test_aggregate_udf_with_custom_state_multi_attr():\n+    class State:\n+        def __init__(self, non_null=0, null=0):\n+            self._non_null = non_null\n+            self._null = null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        @property\n+        def null(self):\n+            return self._null\n+\n+        @null.setter\n+        def null(self, value):\n+            self._null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"non_null: \" + str(self.non_null) \\\n+                    + \", null: \" + str(self.null)\n+\n+    def init():\n+        state = State(0, 0)\n+        return state\n+\n+    def consume(ctx, x):\n+        null = 0\n+        non_null = 0\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+            null = len(x) - non_null\n+        elif isinstance(x, pa.Scalar):\n+            if x.as_py():\n+                non_null = 1\n+            else:\n+                null = 1\n+        non_null = non_null + ctx.state.non_null\n\nReview Comment:\n   ```suggestion\r\n           non_null = non_null + ctx.state.non_null\r\n           null = null + ctx.state.null\r\n   ```\n\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"count: \" + str(self.non_null)\n+\n+    def init():\n+        state = State(0)\n+        return state\n+\n+    def consume(ctx, x):\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+        elif isinstance(x, pa.Scalar):\n+            if x.as_py():\n+                non_null = 1\n+        non_null = non_null + ctx.state.non_null\n+        return State(non_null)\n+\n+    def merge(ctx, other_state):\n+        merged_state_val = ctx.state.non_null + other_state.non_null\n+        return State(merged_state_val)\n+\n+    def finalize(ctx):\n+        return pa.array([ctx.state.non_null])\n+\n+    func_name = \"simple_count\"\n+    unary_doc = {\"summary\": \"count function\",\n+                 \"description\": \"test agg count function\"}\n+\n+    pc.register_scalar_aggregate_function(init,\n+                                          consume,\n+                                          merge,\n+                                          finalize,\n+                                          func_name,\n+                                          unary_doc,\n+                                          {\"array\": pa.int64()},\n+                                          pa.int64())\n+\n+    assert pc.call_function(func_name, [pa.array(\n+        [10, 20, None, 30, None, 40])]) == pa.array([4])\n+\n+\n+def test_aggregate_udf_with_custom_state_multi_attr():\n+    class State:\n+        def __init__(self, non_null=0, null=0):\n+            self._non_null = non_null\n+            self._null = null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        @property\n+        def null(self):\n+            return self._null\n+\n+        @null.setter\n+        def null(self, value):\n+            self._null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"non_null: \" + str(self.non_null) \\\n+                    + \", null: \" + str(self.null)\n+\n+    def init():\n+        state = State(0, 0)\n+        return state\n+\n+    def consume(ctx, x):\n+        null = 0\n+        non_null = 0\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+            null = len(x) - non_null\n+        elif isinstance(x, pa.Scalar):\n+            if x.as_py():\n+                non_null = 1\n+            else:\n+                null = 1\n+        non_null = non_null + ctx.state.non_null\n+        return State(non_null, null)\n+\n+    def merge(ctx, other_state):\n+        merged_st_non_null = ctx.state.non_null + other_state.non_null\n+        merged_st_null = ctx.state.null + other_state.null\n+        return State(merged_st_non_null, merged_st_null)\n+\n+    def finalize(ctx):\n+        print(ctx.state)\n+        return pa.array([ctx.state.non_null, ctx.state.null])\n\nReview Comment:\n   An aggregate UDF must always return an array of length 1.  Do you perhaps want something like...\r\n   \r\n   ```\r\n   return pa.array([{\"non_null\": ctx.state.non_null, \"null\": ctx.state.null}])\r\n   ```\n\n\n\n##########\npython/pyarrow/src/arrow/python/udf.cc:\n##########\n@@ -120,6 +128,218 @@ Status RegisterScalarFunction(PyObject* user_function, ScalarUdfWrapperCallback\n   return Status::OK();\n }\n \n+// Scalar Aggregate Functions\n+\n+struct ScalarUdfAggregator : public compute::KernelState {\n+  virtual Status Consume(compute::KernelContext* ctx, const compute::ExecSpan& batch) = 0;\n+  virtual Status MergeFrom(compute::KernelContext* ctx, compute::KernelState&& src) = 0;\n+  virtual Status Finalize(compute::KernelContext* ctx, Datum* out) = 0;\n+};\n+\n+arrow::Status AggregateUdfConsume(compute::KernelContext* ctx, const compute::ExecSpan& batch) {\n+  return checked_cast<ScalarUdfAggregator*>(ctx->state())->Consume(ctx, batch);\n+}\n+\n+arrow::Status AggregateUdfMerge(compute::KernelContext* ctx, compute::KernelState&& src,\n+                                compute::KernelState* dst) {\n+  return checked_cast<ScalarUdfAggregator*>(dst)->MergeFrom(ctx, std::move(src));\n+}\n+\n+arrow::Status AggregateUdfFinalize(compute::KernelContext* ctx, arrow::Datum* out) {\n+  return checked_cast<ScalarUdfAggregator*>(ctx->state())->Finalize(ctx, out);\n+}\n+\n+ScalarAggregateUdfContext::~ScalarAggregateUdfContext() {\n+  if (_Py_IsFinalizing()) {\n+      Py_DECREF(this->state);\n+    }\n+}\n+\n+struct PythonScalarUdfAggregatorImpl : public ScalarUdfAggregator {\n+\n+  ScalarAggregateInitUdfWrapperCallback init_cb;\n+  ScalarAggregateConsumeUdfWrapperCallback consume_cb;\n+  ScalarAggregateMergeUdfWrapperCallback merge_cb;\n+  ScalarAggregateFinalizeUdfWrapperCallback finalize_cb;\n+  std::shared_ptr<OwnedRefNoGIL> init_function;\n+  std::shared_ptr<OwnedRefNoGIL> consume_function;\n+  std::shared_ptr<OwnedRefNoGIL> merge_function;\n+  std::shared_ptr<OwnedRefNoGIL> finalize_function;\n+  std::shared_ptr<DataType> output_type;\n+\n+\n+  PythonScalarUdfAggregatorImpl(ScalarAggregateInitUdfWrapperCallback init_cb,\n+   ScalarAggregateConsumeUdfWrapperCallback consume_cb,\n+   ScalarAggregateMergeUdfWrapperCallback merge_cb,\n+   ScalarAggregateFinalizeUdfWrapperCallback finalize_cb,\n+   std::shared_ptr<OwnedRefNoGIL> init_function,\n+   std::shared_ptr<OwnedRefNoGIL> consume_function,\n+   std::shared_ptr<OwnedRefNoGIL> merge_function,\n+   std::shared_ptr<OwnedRefNoGIL> finalize_function,\n+            const std::shared_ptr<DataType>& output_type) : init_cb(init_cb),\n+            consume_cb(consume_cb),\n+            merge_cb(merge_cb),\n+            finalize_cb(finalize_cb),\n+            init_function(init_function),\n+            consume_function(consume_function),\n+            merge_function(merge_function),\n+            finalize_function(finalize_function),\n+            output_type(output_type) {\n+              Init(init_cb, init_function);\n+            }\n+\n+  ~PythonScalarUdfAggregatorImpl() {\n+    if (_Py_IsFinalizing()) {\n+      init_function->detach();\n+      consume_function->detach();\n+      merge_function->detach();\n+      finalize_function->detach();\n+    }\n+  }\n+\n+  void Init(ScalarAggregateInitUdfWrapperCallback& init_cb , std::shared_ptr<OwnedRefNoGIL>& init_function) {\n+    auto st =  SafeCallIntoPython([&]() -> Status { \n+      OwnedRef result(init_cb(init_function->obj()));\n+      PyObject* init_res = result.obj();\n+      Py_INCREF(init_res);\n+      this->udf_context_ = ScalarAggregateUdfContext{default_memory_pool(), std::move(init_res)};\n+      this->owned_state_.reset(result.obj());\n+      RETURN_NOT_OK(CheckPyError());\n+      return Status::OK();\n+    });\n+    if (!st.ok()) {\n+      throw std::runtime_error(st.ToString());\n\nReview Comment:\n   Is throwing an error the right thing to do?\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n+\n+    Parameters\n+    ----------\n+    init_func : callable\n+        A callable implementing the user-defined initialization function.\n+        This function is used to set the state for the aggregate operation\n+        and returns the state object.\n+    consume_func : callable\n+        A callable implementing the user-defined consume function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, it must take arguments equal to the number of\n+        in_types defined.\n+        To define a varargs function, pass a callable that takes\n+        varargs. The last in_type will be the type of all varargs\n+        arguments.\n\nReview Comment:\n   How do varargs work?  Do I define a `*args`?\n\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"count: \" + str(self.non_null)\n+\n+    def init():\n+        state = State(0)\n+        return state\n+\n+    def consume(ctx, x):\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+        elif isinstance(x, pa.Scalar):\n\nReview Comment:\n   Can a unary aggregate ever be called with a scalar?\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n+\n+    Parameters\n+    ----------\n+    init_func : callable\n+        A callable implementing the user-defined initialization function.\n+        This function is used to set the state for the aggregate operation\n+        and returns the state object.\n+    consume_func : callable\n+        A callable implementing the user-defined consume function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, it must take arguments equal to the number of\n+        in_types defined.\n+        To define a varargs function, pass a callable that takes\n+        varargs. The last in_type will be the type of all varargs\n+        arguments.\n+\n+        This function returns the updated state after consuming the \n+        received data.\n+    merge_func: callable\n\nReview Comment:\n   The concept of a \"merge function\" is not going to be obvious to most users.  It is very possible for an engine to be defined that does not have to worry about the concept of a merge.  I think we need to describe some background here for why a merge is needed in the first place.  Something like:\r\n   \r\n   Aggregates may be calculated across many threads in parallel.  Each thread will call the init function once to generate a state for that thread.  Once all values have been consumed then the threads from each state will be merged together to get the final result state.  The merge function should take two states and combine them.\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n+\n+    Parameters\n+    ----------\n+    init_func : callable\n+        A callable implementing the user-defined initialization function.\n+        This function is used to set the state for the aggregate operation\n+        and returns the state object.\n+    consume_func : callable\n+        A callable implementing the user-defined consume function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, it must take arguments equal to the number of\n+        in_types defined.\n+        To define a varargs function, pass a callable that takes\n+        varargs. The last in_type will be the type of all varargs\n+        arguments.\n+\n+        This function returns the updated state after consuming the \n+        received data.\n+    merge_func: callable\n+        A callable implementing the user-defined merge function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, the second argument it takes is an state object. \n+        This object holds the state with which the current state\n+        must be merged with. The current state can be retrieved from\n+        the context object which can be acessed by `context.state`.\n+        The state doesn't need to be set in the Python side and it is\n+        autonomously handled in the C++ backend. The updated state must\n+        be returned from this function.\n+    finalize_func: callable\n+        A callable implementing the user-defined finalize function.\n+        The first argument is the context argument of type\n+        ScalarUdfContext.\n+        Using the context argument the state can be extracted and return\n\nReview Comment:\n   \"the state can be extracted\" is not very obvious.  Maybe something like:\r\n   \r\n   The purpose of the finalize function is to transform the state (which is available in the context argument) into an array.  This array will be the final result of the aggregation.\n\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"count: \" + str(self.non_null)\n+\n+    def init():\n+        state = State(0)\n+        return state\n+\n+    def consume(ctx, x):\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+        elif isinstance(x, pa.Scalar):\n+            if x.as_py():\n+                non_null = 1\n+        non_null = non_null + ctx.state.non_null\n+        return State(non_null)\n+\n+    def merge(ctx, other_state):\n+        merged_state_val = ctx.state.non_null + other_state.non_null\n+        return State(merged_state_val)\n+\n+    def finalize(ctx):\n+        return pa.array([ctx.state.non_null])\n+\n+    func_name = \"simple_count\"\n\nReview Comment:\n   Maybe `valid_count` or `non_null_count`?\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n\nReview Comment:\n   ```suggestion\r\n       A scalar aggregate function is a set of 4 functions which are\r\n       called at different times during the calculation of the aggregate.\r\n   ```\r\n   \r\n   I think we are missing a basic description first.  Something like:\r\n   \r\n   ```\r\n   An aggregate function reduces a column of values into a single aggregate result.\r\n   ```\n\n\n\n##########\ncpp/examples/arrow/udf_example.cc:\n##########\n@@ -83,15 +83,154 @@ arrow::Status Execute() {\n \n   ARROW_ASSIGN_OR_RAISE(auto res, cp::CallFunction(name, {x, y, z}));\n   auto res_array = res.make_array();\n-  std::cout << \"Result\" << std::endl;\n+  std::cout << \"Scalar UDF Result\" << std::endl;\n   std::cout << res_array->ToString() << std::endl;\n   return arrow::Status::OK();\n }\n \n+// User-defined Scalar Aggregate Function Example\n+struct ScalarUdfAggregator : public cp::KernelState {\n+  virtual arrow::Status Consume(cp::KernelContext* ctx, const cp::ExecSpan& batch) = 0;\n+  virtual arrow::Status MergeFrom(cp::KernelContext* ctx, cp::KernelState&& src) = 0;\n+  virtual arrow::Status Finalize(cp::KernelContext* ctx, arrow::Datum* out) = 0;\n+};\n+\n+class SimpleCountFunctionOptionsType : public cp::FunctionOptionsType {\n+  const char* type_name() const override { return \"SimpleCountFunctionOptionsType\"; }\n+  std::string Stringify(const cp::FunctionOptions&) const override {\n+    return \"SimpleCountFunctionOptionsType\";\n+  }\n+  bool Compare(const cp::FunctionOptions&, const cp::FunctionOptions&) const override {\n+    return true;\n+  }\n+  std::unique_ptr<cp::FunctionOptions> Copy(const cp::FunctionOptions&) const override;\n+};\n+\n+cp::FunctionOptionsType* GetSimpleCountFunctionOptionsType() {\n+  static SimpleCountFunctionOptionsType options_type;\n+  return &options_type;\n+}\n+\n+class SimpleCountOptions : public cp::FunctionOptions {\n+ public:\n+  SimpleCountOptions() : cp::FunctionOptions(GetSimpleCountFunctionOptionsType()) {}\n+  static constexpr char const kTypeName[] = \"SimpleCountOptions\";\n+  static SimpleCountOptions Defaults() { return SimpleCountOptions{}; }\n+};\n+\n+std::unique_ptr<cp::FunctionOptions> SimpleCountFunctionOptionsType::Copy(\n+    const cp::FunctionOptions&) const {\n+  return std::make_unique<SimpleCountOptions>();\n+}\n+\n+const cp::FunctionDoc simple_count_doc{\n+    \"SimpleCount the number of null / non-null values\",\n+    (\"By default, only non-null values are counted.\\n\"\n+     \"This can be changed through SimpleCountOptions.\"),\n\nReview Comment:\n   Well, this isn't true quite yet :)\n\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"count: \" + str(self.non_null)\n+\n+    def init():\n+        state = State(0)\n+        return state\n+\n+    def consume(ctx, x):\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+        elif isinstance(x, pa.Scalar):\n+            if x.as_py():\n+                non_null = 1\n+        non_null = non_null + ctx.state.non_null\n+        return State(non_null)\n+\n+    def merge(ctx, other_state):\n+        merged_state_val = ctx.state.non_null + other_state.non_null\n+        return State(merged_state_val)\n+\n+    def finalize(ctx):\n+        return pa.array([ctx.state.non_null])\n+\n+    func_name = \"simple_count\"\n+    unary_doc = {\"summary\": \"count function\",\n+                 \"description\": \"test agg count function\"}\n+\n+    pc.register_scalar_aggregate_function(init,\n+                                          consume,\n+                                          merge,\n+                                          finalize,\n+                                          func_name,\n+                                          unary_doc,\n+                                          {\"array\": pa.int64()},\n+                                          pa.int64())\n+\n+    assert pc.call_function(func_name, [pa.array(\n+        [10, 20, None, 30, None, 40])]) == pa.array([4])\n+\n+\n+def test_aggregate_udf_with_custom_state_multi_attr():\n+    class State:\n+        def __init__(self, non_null=0, null=0):\n+            self._non_null = non_null\n+            self._null = null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        @property\n+        def null(self):\n+            return self._null\n+\n+        @null.setter\n+        def null(self, value):\n+            self._null = value\n\nReview Comment:\n   Same comment on getters and setters\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n+\n+    Parameters\n+    ----------\n+    init_func : callable\n\nReview Comment:\n   Is `callable` the right word for python?  In python docs it refers to this kind of thing as `function` I think: https://docs.python.org/3/library/functions.html#map\n\n\n\n##########\npython/pyarrow/tests/test_udf.py:\n##########\n@@ -504,3 +504,132 @@ def test_input_lifetime(unary_func_fixture):\n     # Calling a UDF should not have kept `v` alive longer than required\n     v = None\n     assert proxy_pool.bytes_allocated() == 0\n+\n+\n+def test_aggregate_udf_with_custom_state():\n+    class State:\n+        def __init__(self, non_null=0):\n+            self._non_null = non_null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"count: \" + str(self.non_null)\n+\n+    def init():\n+        state = State(0)\n+        return state\n+\n+    def consume(ctx, x):\n+        if isinstance(x, pa.Array):\n+            non_null = pc.sum(pc.invert(pc.is_nan(x))).as_py()\n+        elif isinstance(x, pa.Scalar):\n+            if x.as_py():\n+                non_null = 1\n+        non_null = non_null + ctx.state.non_null\n+        return State(non_null)\n+\n+    def merge(ctx, other_state):\n+        merged_state_val = ctx.state.non_null + other_state.non_null\n+        return State(merged_state_val)\n+\n+    def finalize(ctx):\n+        return pa.array([ctx.state.non_null])\n+\n+    func_name = \"simple_count\"\n+    unary_doc = {\"summary\": \"count function\",\n+                 \"description\": \"test agg count function\"}\n+\n+    pc.register_scalar_aggregate_function(init,\n+                                          consume,\n+                                          merge,\n+                                          finalize,\n+                                          func_name,\n+                                          unary_doc,\n+                                          {\"array\": pa.int64()},\n+                                          pa.int64())\n+\n+    assert pc.call_function(func_name, [pa.array(\n+        [10, 20, None, 30, None, 40])]) == pa.array([4])\n+\n+\n+def test_aggregate_udf_with_custom_state_multi_attr():\n+    class State:\n+        def __init__(self, non_null=0, null=0):\n+            self._non_null = non_null\n+            self._null = null\n+\n+        @property\n+        def non_null(self):\n+            return self._non_null\n+\n+        @non_null.setter\n+        def non_null(self, value):\n+            self._non_null = value\n+\n+        @property\n+        def null(self):\n+            return self._null\n+\n+        @null.setter\n+        def null(self, value):\n+            self._null = value\n+\n+        def __repr__(self):\n+            if self._non_null is None:\n+                return \"no values stored\"\n+            else:\n+                return \"non_null: \" + str(self.non_null) \\\n+                    + \", null: \" + str(self.null)\n+\n+    def init():\n+        state = State(0, 0)\n+        return state\n\nReview Comment:\n   ```suggestion\r\n           return State(0, 0)\r\n   ```\n\n\n\n##########\npython/pyarrow/src/arrow/python/udf.cc:\n##########\n@@ -120,6 +128,218 @@ Status RegisterScalarFunction(PyObject* user_function, ScalarUdfWrapperCallback\n   return Status::OK();\n }\n \n+// Scalar Aggregate Functions\n+\n+struct ScalarUdfAggregator : public compute::KernelState {\n+  virtual Status Consume(compute::KernelContext* ctx, const compute::ExecSpan& batch) = 0;\n+  virtual Status MergeFrom(compute::KernelContext* ctx, compute::KernelState&& src) = 0;\n+  virtual Status Finalize(compute::KernelContext* ctx, Datum* out) = 0;\n+};\n+\n+arrow::Status AggregateUdfConsume(compute::KernelContext* ctx, const compute::ExecSpan& batch) {\n+  return checked_cast<ScalarUdfAggregator*>(ctx->state())->Consume(ctx, batch);\n+}\n+\n+arrow::Status AggregateUdfMerge(compute::KernelContext* ctx, compute::KernelState&& src,\n+                                compute::KernelState* dst) {\n+  return checked_cast<ScalarUdfAggregator*>(dst)->MergeFrom(ctx, std::move(src));\n+}\n+\n+arrow::Status AggregateUdfFinalize(compute::KernelContext* ctx, arrow::Datum* out) {\n+  return checked_cast<ScalarUdfAggregator*>(ctx->state())->Finalize(ctx, out);\n+}\n+\n+ScalarAggregateUdfContext::~ScalarAggregateUdfContext() {\n+  if (_Py_IsFinalizing()) {\n+      Py_DECREF(this->state);\n+    }\n+}\n+\n+struct PythonScalarUdfAggregatorImpl : public ScalarUdfAggregator {\n+\n+  ScalarAggregateInitUdfWrapperCallback init_cb;\n+  ScalarAggregateConsumeUdfWrapperCallback consume_cb;\n+  ScalarAggregateMergeUdfWrapperCallback merge_cb;\n+  ScalarAggregateFinalizeUdfWrapperCallback finalize_cb;\n+  std::shared_ptr<OwnedRefNoGIL> init_function;\n+  std::shared_ptr<OwnedRefNoGIL> consume_function;\n+  std::shared_ptr<OwnedRefNoGIL> merge_function;\n+  std::shared_ptr<OwnedRefNoGIL> finalize_function;\n+  std::shared_ptr<DataType> output_type;\n+\n+\n+  PythonScalarUdfAggregatorImpl(ScalarAggregateInitUdfWrapperCallback init_cb,\n+   ScalarAggregateConsumeUdfWrapperCallback consume_cb,\n+   ScalarAggregateMergeUdfWrapperCallback merge_cb,\n+   ScalarAggregateFinalizeUdfWrapperCallback finalize_cb,\n+   std::shared_ptr<OwnedRefNoGIL> init_function,\n+   std::shared_ptr<OwnedRefNoGIL> consume_function,\n+   std::shared_ptr<OwnedRefNoGIL> merge_function,\n+   std::shared_ptr<OwnedRefNoGIL> finalize_function,\n+            const std::shared_ptr<DataType>& output_type) : init_cb(init_cb),\n+            consume_cb(consume_cb),\n+            merge_cb(merge_cb),\n+            finalize_cb(finalize_cb),\n+            init_function(init_function),\n+            consume_function(consume_function),\n+            merge_function(merge_function),\n+            finalize_function(finalize_function),\n+            output_type(output_type) {\n+              Init(init_cb, init_function);\n+            }\n+\n+  ~PythonScalarUdfAggregatorImpl() {\n+    if (_Py_IsFinalizing()) {\n+      init_function->detach();\n+      consume_function->detach();\n+      merge_function->detach();\n+      finalize_function->detach();\n+    }\n+  }\n+\n+  void Init(ScalarAggregateInitUdfWrapperCallback& init_cb , std::shared_ptr<OwnedRefNoGIL>& init_function) {\n+    auto st =  SafeCallIntoPython([&]() -> Status { \n+      OwnedRef result(init_cb(init_function->obj()));\n+      PyObject* init_res = result.obj();\n\nReview Comment:\n   Probably need to do sanity checking (e.g. not null, etc.) on things returned from user callbacks.\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n+\n+    Parameters\n+    ----------\n+    init_func : callable\n+        A callable implementing the user-defined initialization function.\n+        This function is used to set the state for the aggregate operation\n\nReview Comment:\n   I'm not sure that \"set the state\" is correct.  Maybe \"create the initial state\"?\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n\nReview Comment:\n   Why \"scalar aggregate\"?  Is there a non-scalar aggregate?\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n+\n+    Parameters\n+    ----------\n+    init_func : callable\n+        A callable implementing the user-defined initialization function.\n+        This function is used to set the state for the aggregate operation\n+        and returns the state object.\n+    consume_func : callable\n+        A callable implementing the user-defined consume function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, it must take arguments equal to the number of\n+        in_types defined.\n+        To define a varargs function, pass a callable that takes\n+        varargs. The last in_type will be the type of all varargs\n+        arguments.\n+\n+        This function returns the updated state after consuming the \n+        received data.\n+    merge_func: callable\n+        A callable implementing the user-defined merge function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, the second argument it takes is an state object. \n+        This object holds the state with which the current state\n+        must be merged with. The current state can be retrieved from\n+        the context object which can be acessed by `context.state`.\n+        The state doesn't need to be set in the Python side and it is\n+        autonomously handled in the C++ backend. The updated state must\n\nReview Comment:\n   I'm not sure I understand the sentence that starts with \"The state doesn't need to be set...\"\n\n\n\n##########\npython/pyarrow/_compute.pyx:\n##########\n@@ -2641,3 +2722,200 @@ def register_scalar_function(func, function_name, function_doc, in_types,\n \n     check_status(RegisterScalarFunction(c_function,\n                                         <function[CallbackUdf]> &_scalar_udf_callback, c_options))\n+\n+\n+def register_scalar_aggregate_function(init_func, consume_func, merge_func, finalize_func,\n+                                       function_name, function_doc, in_types, out_type):\n+    \"\"\"\n+    Register a user-defined scalar aggregate function.\n+\n+    A scalar aggregate function is a set of 4 functions which formulates\n+    the operation pieces of an scalar aggregation. The base behavior in \n+    terms of computation is very much similar to scalar functions.\n+\n+    Parameters\n+    ----------\n+    init_func : callable\n+        A callable implementing the user-defined initialization function.\n+        This function is used to set the state for the aggregate operation\n+        and returns the state object.\n+    consume_func : callable\n+        A callable implementing the user-defined consume function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, it must take arguments equal to the number of\n+        in_types defined.\n+        To define a varargs function, pass a callable that takes\n+        varargs. The last in_type will be the type of all varargs\n+        arguments.\n+\n+        This function returns the updated state after consuming the \n+        received data.\n+    merge_func: callable\n+        A callable implementing the user-defined merge function.\n+        The first argument is the context argument of type\n+        ScalarAggregateUdfContext.\n+        Then, the second argument it takes is an state object. \n+        This object holds the state with which the current state\n+        must be merged with. The current state can be retrieved from\n+        the context object which can be acessed by `context.state`.\n+        The state doesn't need to be set in the Python side and it is\n+        autonomously handled in the C++ backend. The updated state must\n+        be returned from this function.\n+    finalize_func: callable\n+        A callable implementing the user-defined finalize function.\n+        The first argument is the context argument of type\n+        ScalarUdfContext.\n+        Using the context argument the state can be extracted and return\n+        type must be an array matching the `out_type`.\n\nReview Comment:\n   In your C++ example the return type is a scalar?\n\n\n\n",
                    "created": "2022-11-16T06:45:41.481+0000",
                    "updated": "2022-11-16T06:45:41.481+0000",
                    "started": "2022-11-16T06:45:41.481+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "826416",
                    "issueId": "13427653"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 3600,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@17ea43fc[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2148343c[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@26c7a56a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@46ce8c5a[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@479bead1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@1b4a48ce[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3d4238[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@32a3b239[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2af61bde[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@63333a76[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@9f598aa[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@26e8c1d7[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 3600,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Oct 20 17:51:36 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": null,
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-15641/watchers",
            "watchCount": 3,
            "isWatching": true
        },
        "created": "2022-02-10T06:03:40.000+0000",
        "updated": "2022-11-16T06:45:41.000+0000",
        "timeoriginalestimate": null,
        "description": "Here we will be implementing the UDF support for aggregate functions.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "1h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 3600
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Python] UDF Aggregate Function Implementation",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/comment/17565639",
                    "id": "17565639",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "body": "This issue was last updated over 90 days ago, which may be an indication it is no longer being actively worked. To better reflect the current state, the issue is being unassigned. Please feel free to re-take assignment of the issue if it is being actively worked, or if you plan to start that work soon.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=toddfarmer",
                        "name": "toddfarmer",
                        "key": "JIRAUSER288796",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=39935",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=39935",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=39935",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=39935"
                        },
                        "displayName": "Todd Farmer",
                        "active": true,
                        "timeZone": "America/Boise"
                    },
                    "created": "2022-07-12T14:04:28.627+0000",
                    "updated": "2022-07-12T14:04:28.627+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13427653/comment/17621290",
                    "id": "17621290",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=arrowjira",
                        "name": "arrowjira",
                        "key": "arrowjira",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Apache Arrow JIRA Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "This issue was last updated over 90 days ago, which may be an indication it is no longer being actively worked. To better reflect the current state, the issue is being unassigned per [project policy|https://arrow.apache.org/docs/dev/developers/bug_reports.html#issue-assignment]. Please feel free to re-take assignment of the issue if it is being actively worked, or if you plan to start that work soon.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=arrowjira",
                        "name": "arrowjira",
                        "key": "arrowjira",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Apache Arrow JIRA Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-10-20T17:51:36.372+0000",
                    "updated": "2022-10-20T17:51:36.372+0000"
                }
            ],
            "maxResults": 2,
            "total": 2,
            "startAt": 0
        },
        "customfield_12311820": "0|z0zfoo:",
        "customfield_12314139": null
    }
}