{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13188884",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188884",
    "key": "ARROW-3404",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343066",
                "id": "12343066",
                "description": "",
                "name": "0.11.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-10-08"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343066",
                "id": "12343066",
                "description": "",
                "name": "0.11.0",
                "archived": false,
                "released": true,
                "releaseDate": "2018-10-08"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=apitrou",
            "name": "apitrou",
            "key": "pitrou",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=pitrou&avatarId=35049",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=pitrou&avatarId=35049",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=pitrou&avatarId=35049",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=pitrou&avatarId=35049"
            },
            "displayName": "Antoine Pitrou",
            "active": true,
            "timeZone": "Europe/Paris"
        },
        "aggregateprogress": {
            "progress": 3000,
            "total": 3000,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 3000,
            "total": 3000,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3404/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 5,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188884/worklog/150413",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou opened a new pull request #2684: ARROW-3404: [C++] Make CSV chunker faster\nURL: https://github.com/apache/arrow/pull/2684\n \n \n   This speeds up multi-threaded CSV reads by removing the serial bottleneck of detecting newlines when no newlines can be present in CSV values.\r\n   \r\n   On this machine (8-core AMD processor), the speed of reading a CSV file of text column data goes from 600 MB/s (before this patch) to 1.2 GB/s.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-02T15:20:04.077+0000",
                    "updated": "2018-10-02T15:20:04.077+0000",
                    "started": "2018-10-02T15:20:04.076+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "150413",
                    "issueId": "13188884"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188884/worklog/150477",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #2684: ARROW-3404: [C++] Make CSV chunker faster\nURL: https://github.com/apache/arrow/pull/2684#discussion_r222050206\n \n \n\n ##########\n File path: cpp/src/arrow/csv/options.h\n ##########\n @@ -40,6 +40,8 @@ struct ARROW_EXPORT ParseOptions {\n   bool escaping = false;\n   // Escaping character (if `escaping` is true)\n   char escape_char = '\\\\';\n+  // Whether values are allowed to contain CR (0x0d) and LF (0x0a) characters\n+  bool newlines_in_values = false;\n \n Review comment:\n   I was initially thinking the default for this should be \"true\", but I would wager > 90% of CSV files do not have embedded newlines and so when someone has such a \"special\" file they can opt in to this additional logic\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-02T17:54:38.875+0000",
                    "updated": "2018-10-02T17:54:38.875+0000",
                    "started": "2018-10-02T17:54:38.874+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "150477",
                    "issueId": "13188884"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188884/worklog/150478",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #2684: ARROW-3404: [C++] Make CSV chunker faster\nURL: https://github.com/apache/arrow/pull/2684#issuecomment-426370165\n \n \n   Very nice speedup!\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-02T17:55:07.062+0000",
                    "updated": "2018-10-02T17:55:07.062+0000",
                    "started": "2018-10-02T17:55:07.061+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "150478",
                    "issueId": "13188884"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188884/worklog/150492",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "pitrou commented on a change in pull request #2684: ARROW-3404: [C++] Make CSV chunker faster\nURL: https://github.com/apache/arrow/pull/2684#discussion_r222063762\n \n \n\n ##########\n File path: cpp/src/arrow/csv/options.h\n ##########\n @@ -40,6 +40,8 @@ struct ARROW_EXPORT ParseOptions {\n   bool escaping = false;\n   // Escaping character (if `escaping` is true)\n   char escape_char = '\\\\';\n+  // Whether values are allowed to contain CR (0x0d) and LF (0x0a) characters\n+  bool newlines_in_values = false;\n \n Review comment:\n   We can change the default anyway, I just thought it would be nice to have nice numbers out of the box :-)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-02T18:31:35.071+0000",
                    "updated": "2018-10-02T18:31:35.071+0000",
                    "started": "2018-10-02T18:31:35.070+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "150492",
                    "issueId": "13188884"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188884/worklog/150505",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm closed pull request #2684: ARROW-3404: [C++] Make CSV chunker faster\nURL: https://github.com/apache/arrow/pull/2684\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/cpp/src/arrow/csv/chunker.cc b/cpp/src/arrow/csv/chunker.cc\nindex 37d2effb6a..2394ce26eb 100644\n--- a/cpp/src/arrow/csv/chunker.cc\n+++ b/cpp/src/arrow/csv/chunker.cc\n@@ -25,8 +25,28 @@\n namespace arrow {\n namespace csv {\n \n-Chunker::Chunker(ParseOptions options, int32_t max_num_rows)\n-    : options_(options), max_num_rows_(max_num_rows) {}\n+namespace {\n+\n+// Find the last newline character in the given data block.\n+// nullptr is returned if not found (like memchr()).\n+const char* FindNewlineReverse(const char* data, uint32_t size) {\n+  if (size == 0) {\n+    return nullptr;\n+  }\n+  const char* s = data + size - 1;\n+  while (size > 0) {\n+    if (*s == '\\r' || *s == '\\n') {\n+      return s;\n+    }\n+    --s;\n+    --size;\n+  }\n+  return nullptr;\n+}\n+\n+}  // namespace\n+\n+Chunker::Chunker(ParseOptions options) : options_(options) {}\n \n // NOTE: cvsmonkey (https://github.com/dw/csvmonkey) has optimization ideas\n \n@@ -104,10 +124,6 @@ inline const char* Chunker::ReadLine(const char* data, const char* data_end) {\n   goto FieldStart;\n \n LineEnd:\n-  // At the end of line, possibly in the middle of the newline separator\n-  //   if (ARROW_PREDICT_TRUE(data < data_end) && data[-1] == '\\r' && *data == '\\n') {\n-  //     data++;\n-  //   }\n   return data;\n \n AbortLine:\n@@ -120,24 +136,37 @@ Status Chunker::ProcessSpecialized(const char* start, uint32_t size, uint32_t* o\n   DCHECK_EQ(quoting, options_.quoting);\n   DCHECK_EQ(escaping, options_.escaping);\n \n-  num_rows_ = 0;\n   const char* data = start;\n   const char* data_end = start + size;\n \n-  while (data < data_end && num_rows_ < max_num_rows_) {\n+  while (data < data_end) {\n     const char* line_end = ReadLine<quoting, escaping>(data, data_end);\n     if (line_end == nullptr) {\n       // Cannot read any further\n       break;\n     }\n     data = line_end;\n-    ++num_rows_;\n   }\n   *out_size = static_cast<uint32_t>(data - start);\n   return Status::OK();\n }\n \n Status Chunker::Process(const char* start, uint32_t size, uint32_t* out_size) {\n+  if (!options_.newlines_in_values) {\n+    // In newlines are not accepted in CSV values, we can simply search for\n+    // the last newline character.\n+    // For common block sizes and CSV row sizes, this avoids reading\n+    // most of the data block, making the chunker extremely fast compared\n+    // to the rest of the CSV reading pipeline.\n+    const char* nl = FindNewlineReverse(start, size);\n+    if (nl == nullptr) {\n+      *out_size = 0;\n+    } else {\n+      *out_size = static_cast<uint32_t>(nl - start + 1);\n+    }\n+    return Status::OK();\n+  }\n+\n   if (options_.quoting) {\n     if (options_.escaping) {\n       return ProcessSpecialized<true, true>(start, size, out_size);\ndiff --git a/cpp/src/arrow/csv/chunker.h b/cpp/src/arrow/csv/chunker.h\nindex 983ecc74f9..7d5ba3a538 100644\n--- a/cpp/src/arrow/csv/chunker.h\n+++ b/cpp/src/arrow/csv/chunker.h\n@@ -28,8 +28,6 @@\n namespace arrow {\n namespace csv {\n \n-constexpr int32_t kMaxChunkerNumRows = 100000;\n-\n /// \\class Chunker\n /// \\brief A reusable block-based chunker for CSV data\n ///\n@@ -42,16 +40,14 @@ constexpr int32_t kMaxChunkerNumRows = 100000;\n /// with LF (0x0a), the chunker will consider the leading newline as an empty line.\n class ARROW_EXPORT Chunker {\n  public:\n-  explicit Chunker(ParseOptions options, int32_t max_num_rows = kMaxChunkerNumRows);\n+  explicit Chunker(ParseOptions options);\n \n   /// \\brief Carve up a chunk in a block of data\n   ///\n-  /// Process a block of CSV data, reading up to max_num_rows rows.\n+  /// Process a block of CSV data, reading up to size bytes.\n   /// The number of bytes in the chunk is returned in out_size.\n   Status Process(const char* data, uint32_t size, uint32_t* out_size);\n \n-  int32_t num_rows() const { return num_rows_; }\n-\n  protected:\n   ARROW_DISALLOW_COPY_AND_ASSIGN(Chunker);\n \n@@ -65,10 +61,6 @@ class ARROW_EXPORT Chunker {\n   inline const char* ReadLine(const char* data, const char* data_end);\n \n   ParseOptions options_;\n-  // The number of rows chunked from the block\n-  int32_t num_rows_;\n-  // The maximum number of rows to chunk from this block\n-  int32_t max_num_rows_;\n };\n \n }  // namespace csv\ndiff --git a/cpp/src/arrow/csv/csv-chunker-test.cc b/cpp/src/arrow/csv/csv-chunker-test.cc\nindex 2cad094cdd..1fb419957b 100644\n--- a/cpp/src/arrow/csv/csv-chunker-test.cc\n+++ b/cpp/src/arrow/csv/csv-chunker-test.cc\n@@ -30,51 +30,58 @@\n namespace arrow {\n namespace csv {\n \n-void AssertChunkSize(Chunker& chunker, const std::string& str, uint32_t chunk_size,\n-                     uint32_t num_rows) {\n+void AssertChunkSize(Chunker& chunker, const std::string& str, uint32_t chunk_size) {\n   uint32_t actual_chunk_size;\n   ASSERT_OK(\n       chunker.Process(str.data(), static_cast<uint32_t>(str.size()), &actual_chunk_size));\n   ASSERT_EQ(actual_chunk_size, chunk_size);\n-  ASSERT_EQ(chunker.num_rows(), num_rows);\n }\n \n template <typename IntContainer>\n void AssertChunking(Chunker& chunker, const std::string& str,\n                     const IntContainer& lengths) {\n   uint32_t expected_chunk_size;\n-  uint32_t num_rows =\n-      static_cast<uint32_t>(std::distance(lengths.begin(), lengths.end()));\n \n   // First chunkize whole CSV block\n   expected_chunk_size =\n       static_cast<uint32_t>(std::accumulate(lengths.begin(), lengths.end(), 0ULL));\n-  AssertChunkSize(chunker, str, expected_chunk_size, num_rows);\n+  AssertChunkSize(chunker, str, expected_chunk_size);\n \n   // Then chunkize incomplete substrings of the block\n   expected_chunk_size = 0;\n-  num_rows = 0;\n   for (const auto length : lengths) {\n     AssertChunkSize(chunker, str.substr(0, expected_chunk_size + length - 1),\n-                    expected_chunk_size, num_rows);\n+                    expected_chunk_size);\n \n-    ++num_rows;\n     expected_chunk_size += static_cast<uint32_t>(length);\n-    AssertChunkSize(chunker, str.substr(0, expected_chunk_size), expected_chunk_size,\n-                    num_rows);\n+    AssertChunkSize(chunker, str.substr(0, expected_chunk_size), expected_chunk_size);\n   }\n }\n \n-TEST(Chunker, Basics) {\n+class BaseChunkerTest : public ::testing::TestWithParam<bool> {\n+ protected:\n+  void SetUp() override {\n+    options_ = ParseOptions::Defaults();\n+    options_.newlines_in_values = GetParam();\n+  }\n+\n+  ParseOptions options_;\n+};\n+\n+INSTANTIATE_TEST_CASE_P(ChunkerTest, BaseChunkerTest, ::testing::Values(true));\n+\n+INSTANTIATE_TEST_CASE_P(NoNewlineChunkerTest, BaseChunkerTest, ::testing::Values(false));\n+\n+TEST_P(BaseChunkerTest, Basics) {\n   auto csv = MakeCSVData({\"ab,c,\\n\", \"def,,gh\\n\", \",ij,kl\\n\"});\n   auto lengths = {6, 8, 7};\n-  Chunker chunker(ParseOptions::Defaults());\n+  Chunker chunker(options_);\n \n   AssertChunking(chunker, csv, lengths);\n }\n \n-TEST(Chunker, Empty) {\n-  Chunker chunker(ParseOptions::Defaults());\n+TEST_P(BaseChunkerTest, Empty) {\n+  Chunker chunker(options_);\n   {\n     auto csv = MakeCSVData({\"\\n\"});\n     auto lengths = {1};\n@@ -97,75 +104,65 @@ TEST(Chunker, Empty) {\n   }\n }\n \n-TEST(Chunker, Newlines) {\n-  Chunker chunker(ParseOptions::Defaults());\n+TEST_P(BaseChunkerTest, Newlines) {\n+  Chunker chunker(options_);\n   {\n     auto csv = MakeCSVData({\"a\\n\", \"b\\r\", \"c,d\\r\\n\"});\n-    AssertChunkSize(chunker, csv, static_cast<uint32_t>(csv.size()), 3);\n+    AssertChunkSize(chunker, csv, static_cast<uint32_t>(csv.size()));\n     // Trailing \\n after \\r is optional\n     AssertChunkSize(chunker, csv.substr(0, csv.size() - 1),\n-                    static_cast<uint32_t>(csv.size() - 1), 3);\n+                    static_cast<uint32_t>(csv.size() - 1));\n   }\n }\n \n-TEST(Chunker, MaxNumRows) {\n-  Chunker chunker(ParseOptions::Defaults(), 3 /* max_num_rows */);\n-  auto csv = MakeCSVData({\"ab\\n\", \"c\\n\", \"def\\n\", \"g\\n\"});\n-  auto lengths = {3, 2, 4};\n-  AssertChunking(chunker, csv, lengths);\n-}\n-\n-TEST(Chunker, QuotingSimple) {\n+TEST_P(BaseChunkerTest, QuotingSimple) {\n   auto csv = MakeCSVData({\"1,\\\",3,\\\",5\\n\"});\n   {\n-    Chunker chunker(ParseOptions::Defaults());\n+    Chunker chunker(options_);\n     auto lengths = {csv.size()};\n     AssertChunking(chunker, csv, lengths);\n   }\n   {\n-    auto options = ParseOptions::Defaults();\n-    options.quoting = false;\n-    Chunker chunker(options);\n+    options_.quoting = false;\n+    Chunker chunker(options_);\n     auto lengths = {csv.size()};\n     AssertChunking(chunker, csv, lengths);\n   }\n }\n \n-TEST(Chunker, QuotingNewline) {\n+TEST_P(BaseChunkerTest, QuotingNewline) {\n   auto csv = MakeCSVData({\"a,\\\"c \\n d\\\",e\\n\"});\n-  {\n-    Chunker chunker(ParseOptions::Defaults());\n+  if (options_.newlines_in_values) {\n+    Chunker chunker(options_);\n     auto lengths = {12};\n     AssertChunking(chunker, csv, lengths);\n   }\n   {\n-    auto options = ParseOptions::Defaults();\n-    options.quoting = false;\n-    Chunker chunker(options);\n+    options_.quoting = false;\n+    Chunker chunker(options_);\n     auto lengths = {6, 6};\n     AssertChunking(chunker, csv, lengths);\n   }\n }\n \n-TEST(Chunker, QuotingUnbalanced) {\n+TEST_P(BaseChunkerTest, QuotingUnbalanced) {\n   // Quote introduces a quoted field that doesn't end\n   auto csv = MakeCSVData({\"a,b\\n\", \"1,\\\",3,,5\\n\", \"c,d\\n\"});\n-  {\n-    Chunker chunker(ParseOptions::Defaults());\n+  if (options_.newlines_in_values) {\n+    Chunker chunker(options_);\n     auto lengths = {4};\n     AssertChunking(chunker, csv, lengths);\n   }\n   {\n-    auto options = ParseOptions::Defaults();\n-    options.quoting = false;\n-    Chunker chunker(options);\n+    options_.quoting = false;\n+    Chunker chunker(options_);\n     auto lengths = {4, 9, 4};\n     AssertChunking(chunker, csv, lengths);\n   }\n }\n \n-TEST(Chunker, QuotingEmpty) {\n-  Chunker chunker(ParseOptions::Defaults());\n+TEST_P(BaseChunkerTest, QuotingEmpty) {\n+  Chunker chunker(options_);\n   {\n     auto csv = MakeCSVData({\"\\\"\\\"\\n\", \"a\\n\"});\n     auto lengths = {3, 2};\n@@ -183,9 +180,9 @@ TEST(Chunker, QuotingEmpty) {\n   }\n }\n \n-TEST(Chunker, QuotingDouble) {\n+TEST_P(BaseChunkerTest, QuotingDouble) {\n   {\n-    Chunker chunker(ParseOptions::Defaults());\n+    Chunker chunker(options_);\n     // 4 quotes is a quoted quote\n     auto csv = MakeCSVData({\"\\\"\\\"\\\"\\\"\\n\", \"a\\n\"});\n     auto lengths = {5, 2};\n@@ -193,34 +190,34 @@ TEST(Chunker, QuotingDouble) {\n   }\n }\n \n-TEST(Chunker, QuotesSpecial) {\n+TEST_P(BaseChunkerTest, QuotesSpecial) {\n   // Some non-trivial cases\n   {\n-    Chunker chunker(ParseOptions::Defaults());\n+    Chunker chunker(options_);\n     auto csv = MakeCSVData({\"a,b\\\"c,d\\n\", \"e\\n\"});\n     auto lengths = {8, 2};\n     AssertChunking(chunker, csv, lengths);\n   }\n   {\n-    Chunker chunker(ParseOptions::Defaults());\n+    Chunker chunker(options_);\n     auto csv = MakeCSVData({\"a,\\\"b\\\" \\\"c\\\",d\\n\", \"e\\n\"});\n     auto lengths = {12, 2};\n     AssertChunking(chunker, csv, lengths);\n   }\n }\n \n-TEST(Chunker, Escaping) {\n-  auto options = ParseOptions::Defaults();\n-  options.escaping = true;\n+TEST_P(BaseChunkerTest, Escaping) {\n   {\n     auto csv = MakeCSVData({\"a\\\\b,c\\n\", \"d\\n\"});\n     auto lengths = {6, 2};\n     {\n-      Chunker chunker(ParseOptions::Defaults());\n+      options_.escaping = false;\n+      Chunker chunker(options_);\n       AssertChunking(chunker, csv, lengths);\n     }\n     {\n-      Chunker chunker(options);\n+      options_.escaping = true;\n+      Chunker chunker(options_);\n       AssertChunking(chunker, csv, lengths);\n     }\n   }\n@@ -228,25 +225,30 @@ TEST(Chunker, Escaping) {\n     auto csv = MakeCSVData({\"a\\\\,b,c\\n\", \"d\\n\"});\n     auto lengths = {7, 2};\n     {\n-      Chunker chunker(ParseOptions::Defaults());\n+      options_.escaping = false;\n+      Chunker chunker(options_);\n       AssertChunking(chunker, csv, lengths);\n     }\n     {\n-      Chunker chunker(options);\n+      options_.escaping = true;\n+      Chunker chunker(options_);\n       AssertChunking(chunker, csv, lengths);\n     }\n   }\n-  {\n-    // Escaped newline\n+}\n+\n+TEST_P(BaseChunkerTest, EscapingNewline) {\n+  if (options_.newlines_in_values) {\n     auto csv = MakeCSVData({\"a\\\\\\nb\\n\", \"c\\n\"});\n     {\n       auto lengths = {3, 2, 2};\n-      Chunker chunker(ParseOptions::Defaults());\n+      Chunker chunker(options_);\n       AssertChunking(chunker, csv, lengths);\n     }\n+    options_.escaping = true;\n     {\n       auto lengths = {5, 2};\n-      Chunker chunker(options);\n+      Chunker chunker(options_);\n       AssertChunking(chunker, csv, lengths);\n     }\n   }\ndiff --git a/cpp/src/arrow/csv/csv-parser-benchmark.cc b/cpp/src/arrow/csv/csv-parser-benchmark.cc\nindex 4a79274f0d..f61102d4cb 100644\n--- a/cpp/src/arrow/csv/csv-parser-benchmark.cc\n+++ b/cpp/src/arrow/csv/csv-parser-benchmark.cc\n@@ -47,15 +47,14 @@ static std::string BuildEscapedData(int32_t num_rows = 10000) {\n }\n \n static void BenchmarkCSVChunking(benchmark::State& state,  // NOLINT non-const reference\n-                                 const std::string& csv, int32_t num_rows,\n-                                 ParseOptions options) {\n-  Chunker chunker(options, num_rows + 1);\n+                                 const std::string& csv, ParseOptions options) {\n+  Chunker chunker(options);\n \n   while (state.KeepRunning()) {\n     uint32_t chunk_size;\n     ABORT_NOT_OK(\n         chunker.Process(csv.data(), static_cast<uint32_t>(csv.size()), &chunk_size));\n-    if (chunk_size != csv.size() || chunker.num_rows() != num_rows) {\n+    if (chunk_size != csv.size()) {\n       std::cerr << \"Parsing incomplete\\n\";\n       std::abort();\n     }\n@@ -70,8 +69,9 @@ static void BM_ChunkCSVQuotedBlock(\n   auto options = ParseOptions::Defaults();\n   options.quoting = true;\n   options.escaping = false;\n+  options.newlines_in_values = true;\n \n-  BenchmarkCSVChunking(state, csv, num_rows, options);\n+  BenchmarkCSVChunking(state, csv, options);\n }\n \n static void BM_ChunkCSVEscapedBlock(\n@@ -81,8 +81,21 @@ static void BM_ChunkCSVEscapedBlock(\n   auto options = ParseOptions::Defaults();\n   options.quoting = false;\n   options.escaping = true;\n+  options.newlines_in_values = true;\n \n-  BenchmarkCSVChunking(state, csv, num_rows, options);\n+  BenchmarkCSVChunking(state, csv, options);\n+}\n+\n+static void BM_ChunkCSVNoNewlinesBlock(\n+    benchmark::State& state) {  // NOLINT non-const reference\n+  const int32_t num_rows = 5000;\n+  auto csv = BuildEscapedData(num_rows);\n+  auto options = ParseOptions::Defaults();\n+  options.quoting = true;\n+  options.escaping = false;\n+  options.newlines_in_values = false;\n+\n+  BenchmarkCSVChunking(state, csv, options);\n }\n \n static void BenchmarkCSVParsing(benchmark::State& state,  // NOLINT non-const reference\n@@ -140,6 +153,7 @@ static void BM_ParseCSVEscapedBlock(\n \n BENCHMARK(BM_ChunkCSVQuotedBlock)->Repetitions(3)->Unit(benchmark::kMicrosecond);\n BENCHMARK(BM_ChunkCSVEscapedBlock)->Repetitions(3)->Unit(benchmark::kMicrosecond);\n+BENCHMARK(BM_ChunkCSVNoNewlinesBlock)->Repetitions(3)->Unit(benchmark::kMicrosecond);\n BENCHMARK(BM_ParseCSVQuotedBlock)->Repetitions(3)->Unit(benchmark::kMicrosecond);\n BENCHMARK(BM_ParseCSVEscapedBlock)->Repetitions(3)->Unit(benchmark::kMicrosecond);\n \ndiff --git a/cpp/src/arrow/csv/options.h b/cpp/src/arrow/csv/options.h\nindex 5276720821..6119786301 100644\n--- a/cpp/src/arrow/csv/options.h\n+++ b/cpp/src/arrow/csv/options.h\n@@ -40,6 +40,8 @@ struct ARROW_EXPORT ParseOptions {\n   bool escaping = false;\n   // Escaping character (if `escaping` is true)\n   char escape_char = '\\\\';\n+  // Whether values are allowed to contain CR (0x0d) and LF (0x0a) characters\n+  bool newlines_in_values = false;\n \n   // XXX Should this be in ReadOptions?\n   // Number of header rows to skip\n@@ -57,10 +59,9 @@ struct ARROW_EXPORT ReadOptions {\n \n   // Whether to use the global CPU thread pool\n   bool use_threads = true;\n-  // Block size we request from the IO layer\n+  // Block size we request from the IO layer; also determines the size of\n+  // chunks when use_threads is true\n   int32_t block_size = 1 << 20;  // 1 MB\n-  // Max num rows per array chunk\n-  int32_t num_rows = 100000;\n \n   static ReadOptions Defaults();\n };\ndiff --git a/cpp/src/arrow/csv/reader.cc b/cpp/src/arrow/csv/reader.cc\nindex b4cb3d7d92..6cbda753f9 100644\n--- a/cpp/src/arrow/csv/reader.cc\n+++ b/cpp/src/arrow/csv/reader.cc\n@@ -16,6 +16,8 @@\n // under the License.\n \n #include <cstring>\n+#include <limits>\n+#include <sstream>\n #include <string>\n #include <vector>\n \n@@ -235,8 +237,8 @@ class SerialTableReader : public BaseTableReader {\n     }\n     RETURN_NOT_OK(ProcessHeader());\n \n-    auto parser =\n-        std::make_shared<BlockParser>(parse_options_, num_cols_, read_options_.num_rows);\n+    static constexpr int32_t max_num_rows = std::numeric_limits<int32_t>::max();\n+    auto parser = std::make_shared<BlockParser>(parse_options_, num_cols_, max_num_rows);\n     while (!eof_) {\n       // Consume current block\n       uint32_t parsed_size = 0;\n@@ -300,7 +302,8 @@ class ThreadedTableReader : public BaseTableReader {\n \n   Status Read(std::shared_ptr<Table>* out) {\n     task_group_ = internal::TaskGroup::MakeThreaded(thread_pool_);\n-    Chunker chunker(parse_options_, static_cast<int32_t>(read_options_.num_rows));\n+    static constexpr int32_t max_num_rows = std::numeric_limits<int32_t>::max();\n+    Chunker chunker(parse_options_);\n \n     // Get first block and process header serially\n     RETURN_NOT_OK(ReadNextBlock());\n@@ -314,8 +317,7 @@ class ThreadedTableReader : public BaseTableReader {\n       uint32_t chunk_size = 0;\n       RETURN_NOT_OK(chunker.Process(reinterpret_cast<const char*>(cur_data_),\n                                     static_cast<uint32_t>(cur_size_), &chunk_size));\n-      int32_t chunk_rows = chunker.num_rows();\n-      if (chunk_rows > 0) {\n+      if (chunk_size > 0) {\n         // Got a chunk of rows\n         const uint8_t* chunk_data = cur_data_;\n         std::shared_ptr<Buffer> chunk_buffer = cur_block_;\n@@ -324,12 +326,16 @@ class ThreadedTableReader : public BaseTableReader {\n         // \"mutable\" allows to modify captured by-copy chunk_buffer\n         task_group_->Append([=]() mutable -> Status {\n           auto parser =\n-              std::make_shared<BlockParser>(parse_options_, num_cols_, chunk_rows);\n+              std::make_shared<BlockParser>(parse_options_, num_cols_, max_num_rows);\n           uint32_t parsed_size = 0;\n           RETURN_NOT_OK(parser->Parse(reinterpret_cast<const char*>(chunk_data),\n                                       chunk_size, &parsed_size));\n-          if (parsed_size != chunk_size || chunk_rows != parser->num_rows()) {\n-            return Status::Invalid(\"Chunker and parser disagree on block size\");\n+          if (parsed_size != chunk_size) {\n+            DCHECK_EQ(parsed_size, chunk_size);\n+            std::stringstream ss;\n+            ss << \"Chunker and parser disagree on block size: \" << chunk_size << \" vs \"\n+               << parsed_size;\n+            return Status::Invalid(ss.str());\n           }\n           RETURN_NOT_OK(ProcessData(parser, chunk_index));\n           // Keep chunk buffer alive within closure and release it at the end\n@@ -354,8 +360,8 @@ class ThreadedTableReader : public BaseTableReader {\n       for (auto& builder : column_builders_) {\n         builder->SetTaskGroup(task_group_);\n       }\n-      auto parser = std::make_shared<BlockParser>(parse_options_, num_cols_,\n-                                                  read_options_.num_rows);\n+      auto parser =\n+          std::make_shared<BlockParser>(parse_options_, num_cols_, max_num_rows);\n       uint32_t parsed_size = 0;\n       RETURN_NOT_OK(parser->ParseFinal(reinterpret_cast<const char*>(cur_data_),\n                                        static_cast<uint32_t>(cur_size_), &parsed_size));\ndiff --git a/python/pyarrow/_csv.pyx b/python/pyarrow/_csv.pyx\nindex 9e720366b3..cc69862594 100644\n--- a/python/pyarrow/_csv.pyx\n+++ b/python/pyarrow/_csv.pyx\n@@ -39,14 +39,12 @@ cdef class ReadOptions:\n     # Avoid mistakingly creating attributes\n     __slots__ = ()\n \n-    def __init__(self, use_threads=None, block_size=None, num_rows=None):\n+    def __init__(self, use_threads=None, block_size=None):\n         self.options = CCSVReadOptions.Defaults()\n         if use_threads is not None:\n             self.use_threads = use_threads\n         if block_size is not None:\n             self.block_size = block_size\n-        if num_rows is not None:\n-            self.num_rows = num_rows\n \n     @property\n     def use_threads(self):\n@@ -64,14 +62,6 @@ cdef class ReadOptions:\n     def block_size(self, value):\n         self.options.block_size = value\n \n-    @property\n-    def num_rows(self):\n-        return self.options.num_rows\n-\n-    @num_rows.setter\n-    def num_rows(self, value):\n-        self.options.num_rows = value\n-\n \n cdef class ParseOptions:\n     cdef:\n@@ -80,7 +70,7 @@ cdef class ParseOptions:\n     __slots__ = ()\n \n     def __init__(self, delimiter=None, quote_char=None, double_quote=None,\n-                 escape_char=None, header_rows=None):\n+                 escape_char=None, header_rows=None, newlines_in_values=None):\n         self.options = CCSVParseOptions.Defaults()\n         if delimiter is not None:\n             self.delimiter = delimiter\n@@ -92,6 +82,8 @@ cdef class ParseOptions:\n             self.escape_char = escape_char\n         if header_rows is not None:\n             self.header_rows = header_rows\n+        if newlines_in_values is not None:\n+            self.newlines_in_values = newlines_in_values\n \n     @property\n     def delimiter(self):\n@@ -147,6 +139,14 @@ cdef class ParseOptions:\n     def header_rows(self, value):\n         self.options.header_rows = value\n \n+    @property\n+    def newlines_in_values(self):\n+        return self.options.newlines_in_values\n+\n+    @newlines_in_values.setter\n+    def newlines_in_values(self, value):\n+        self.options.newlines_in_values = value\n+\n \n cdef _get_reader(input_file, shared_ptr[InputStream]* out):\n     cdef shared_ptr[RandomAccessFile] result\ndiff --git a/python/pyarrow/includes/libarrow.pxd b/python/pyarrow/includes/libarrow.pxd\nindex 6b9937d48a..94aa41d908 100644\n--- a/python/pyarrow/includes/libarrow.pxd\n+++ b/python/pyarrow/includes/libarrow.pxd\n@@ -909,6 +909,7 @@ cdef extern from \"arrow/csv/api.h\" namespace \"arrow::csv\" nogil:\n         c_bool escaping\n         unsigned char escape_char\n         int32_t header_rows\n+        c_bool newlines_in_values\n \n         @staticmethod\n         CCSVParseOptions Defaults()\n@@ -920,7 +921,6 @@ cdef extern from \"arrow/csv/api.h\" namespace \"arrow::csv\" nogil:\n     cdef cppclass CCSVReadOptions\" arrow::csv::ReadOptions\":\n         c_bool use_threads\n         int32_t block_size\n-        int32_t num_rows\n \n         @staticmethod\n         CCSVReadOptions Defaults()\ndiff --git a/python/pyarrow/tests/test_csv.py b/python/pyarrow/tests/test_csv.py\nindex 2755e3de0a..1a69fb9878 100644\n--- a/python/pyarrow/tests/test_csv.py\n+++ b/python/pyarrow/tests/test_csv.py\n@@ -65,14 +65,9 @@ def test_read_options():\n     opts.use_threads = False\n     assert opts.use_threads is False\n \n-    assert opts.num_rows > 0\n-    opts.num_rows = 456789\n-    assert opts.num_rows == 456789\n-\n-    opts = cls(block_size=1234, use_threads=False, num_rows=42)\n+    opts = cls(block_size=1234, use_threads=False)\n     assert opts.block_size == 1234\n     assert opts.use_threads is False\n-    assert opts.num_rows == 42\n \n \n def test_parse_options():\n@@ -83,6 +78,7 @@ def test_parse_options():\n     assert opts.double_quote is True\n     assert opts.escape_char is False\n     assert opts.header_rows == 1\n+    assert opts.newlines_in_values is False\n \n     opts.delimiter = 'x'\n     assert opts.delimiter == 'x'\n@@ -100,16 +96,20 @@ def test_parse_options():\n     assert opts.escape_char is False\n     assert opts.quote_char is False\n \n+    opts.newlines_in_values = True\n+    assert opts.newlines_in_values is True\n+\n     opts.header_rows = 2\n     assert opts.header_rows == 2\n \n     opts = cls(delimiter=';', quote_char='%', double_quote=False,\n-               escape_char='\\\\', header_rows=2)\n+               escape_char='\\\\', header_rows=2, newlines_in_values=True)\n     assert opts.delimiter == ';'\n     assert opts.quote_char == '%'\n     assert opts.double_quote is False\n     assert opts.escape_char == '\\\\'\n     assert opts.header_rows == 2\n+    assert opts.newlines_in_values is True\n \n \n class BaseTestCSVRead:\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-10-02T19:34:06.776+0000",
                    "updated": "2018-10-02T19:34:06.776+0000",
                    "started": "2018-10-02T19:34:06.775+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "150505",
                    "issueId": "13188884"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 3000,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@c3d349b[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5da76073[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7ef90cf3[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@18bb4fa7[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@9bfdf93[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@395dc60a[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@ff5db46[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@4df17b68[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@3a457602[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@6d7f9ad6[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4c7143d4[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@a9d4b09[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 3000,
        "customfield_12312520": null,
        "customfield_12312521": "Tue Oct 02 19:33:25 UTC 2018",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2018-10-02T19:33:25.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-3404/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2018-10-02T15:13:49.000+0000",
        "updated": "2018-10-02T19:34:06.000+0000",
        "timeoriginalestimate": null,
        "description": "Currently the CSV chunker can be the bottleneck in multi-threaded reads (starting from 6 threads, according to my experiments). One way to make it faster is to consider by default that CSV values cannot contain newline characters (overridable via a setting), and then simply search for the last newline character in each block of data.",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "50m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 3000
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++] Make CSV chunker faster",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188884/comment/16636010",
                    "id": "16636010",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 2684\n[https://github.com/apache/arrow/pull/2684]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2018-10-02T19:33:25.536+0000",
                    "updated": "2018-10-02T19:33:25.536+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|i3yql3:",
        "customfield_12314139": null
    }
}