{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13290584",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584",
    "key": "ARROW-8039",
    "fields": {
        "parent": {
            "id": "13197668",
            "key": "ARROW-3764",
            "self": "https://issues.apache.org/jira/rest/api/2/issue/13197668",
            "fields": {
                "summary": "[C++] Port Python \"ParquetDataset\" business logic to C++",
                "status": {
                    "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                    "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                    "name": "Resolved",
                    "id": "5",
                    "statusCategory": {
                        "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                        "id": 3,
                        "key": "done",
                        "colorName": "green",
                        "name": "Done"
                    }
                },
                "priority": {
                    "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                    "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                    "name": "Major",
                    "id": "3"
                },
                "issuetype": {
                    "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                    "id": "4",
                    "description": "An improvement or enhancement to an existing feature or task.",
                    "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                    "name": "Improvement",
                    "subtask": false,
                    "avatarId": 21140
                }
            }
        },
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12346687",
                "id": "12346687",
                "description": "",
                "name": "0.17.0",
                "archived": false,
                "released": true,
                "releaseDate": "2020-04-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "dataset",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12340948",
                "id": "12340948",
                "description": "",
                "name": "0.16.0",
                "archived": false,
                "released": true,
                "releaseDate": "2020-02-07"
            }
        ],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12584616",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12584616",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13163375",
                    "key": "ARROW-2659",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13163375",
                    "fields": {
                        "summary": "[Python] More graceful reading of empty String columns in ParquetDataset",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12584615",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12584615",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13172520",
                    "key": "ARROW-2860",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13172520",
                    "fields": {
                        "summary": "[Python][Parquet][C++] Null values in a single partition of Parquet dataset, results in invalid schema on read",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12586996",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12586996",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13248488",
                    "key": "ARROW-6114",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13248488",
                    "fields": {
                        "summary": "[Python] Datatypes not preserved for partition fields in roundtrip to partitioned parquet dataset",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12583381",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12583381",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13200232",
                    "key": "ARROW-3861",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13200232",
                    "fields": {
                        "summary": "[Python] ParquetDataset().read columns argument always returns partition column",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12583375",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12583375",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13240633",
                    "key": "ARROW-5666",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13240633",
                    "fields": {
                        "summary": "[Python] Underscores in partition (string) values are dropped when reading dataset",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12583377",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12583377",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13232999",
                    "key": "ARROW-5310",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13232999",
                    "fields": {
                        "summary": "[Python] better error message on creating ParquetDataset from empty directory",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
                            "name": "Minor",
                            "id": "4"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12583482",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12583482",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13239020",
                    "key": "ARROW-5572",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13239020",
                    "fields": {
                        "summary": "[Python] raise error message when passing invalid filter in parquet reading",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
                            "name": "Minor",
                            "id": "4"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
                            "id": "1",
                            "description": "A problem which impairs or prevents the functions of the product.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
                            "name": "Bug",
                            "subtask": false,
                            "avatarId": 21133
                        }
                    }
                }
            },
            {
                "id": "12585752",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12585752",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13173193",
                    "key": "ARROW-2882",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13173193",
                    "fields": {
                        "summary": "[C++][Python] Support AWS Firehose partition_scheme implementation for Parquet datasets",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            },
            {
                "id": "12586995",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12586995",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13188569",
                    "key": "ARROW-3388",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13188569",
                    "fields": {
                        "summary": "[C++][Dataset] Automatically detect\u00a0boolean partition columns",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/1",
                            "description": "The issue is open and ready for the assignee to start work on it.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/open.png",
                            "name": "Open",
                            "id": "1",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/2",
                                "id": 2,
                                "key": "new",
                                "colorName": "blue-gray",
                                "name": "To Do"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12584617",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12584617",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13148952",
                    "key": "ARROW-2366",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13148952",
                    "fields": {
                        "summary": "[Python][C++][Parquet] Support reading Parquet files having a permutation of column order",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12585751",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12585751",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13189148",
                    "key": "ARROW-3424",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13189148",
                    "fields": {
                        "summary": "[Python] Improved workflow for loading an arbitrary collection of Parquet files",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12583479",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12583479",
                "type": {
                    "id": "10001",
                    "name": "dependent",
                    "inward": "is depended upon by",
                    "outward": "depends upon",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10001"
                },
                "inwardIssue": {
                    "id": "13117616",
                    "key": "ARROW-1796",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117616",
                    "fields": {
                        "summary": "[Python] RowGroup filtering on file level",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
            "name": "jorisvandenbossche",
            "key": "jorisvandenbossche",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Joris Van den Bossche",
            "active": true,
            "timeZone": "Europe/Brussels"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            },
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 31200,
            "total": 31200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 31200,
            "total": 31200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8039/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 72,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408951",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397315399\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -1238,6 +1312,52 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1,\n     return pieces, partitions, common_metadata_path, metadata_path\n \n \n+class ParquetDatasetV2:\n+    \"\"\"\n+    ParquetDataset shim using the Dataset API under the hood.\n+    \"\"\"\n+    def __init__(self, path_or_paths, filesystem=None, filters=None,\n+                 read_dictionary=None, buffer_size=None):\n+        import pyarrow.dataset as ds\n+        import pyarrow.fs\n+\n+        # map old filesystems to new one\n+        if isinstance(filesystem, LocalFileSystem):\n+            filesystem = pyarrow.fs.LocalFileSystem()\n+\n+        reader_options = {}\n+        if buffer_size:\n+            reader_options.update(use_buffered_stream=True,\n+                                  buffer_size=buffer_size)\n+        if read_dictionary is not None:\n+            reader_options.update(dict_columns=read_dictionary)\n+        parquat_format = ds.ParquetFileFormat(reader_options=reader_options)\n \n Review comment:\n   ```suggestion\r\n           parquet_format = ds.ParquetFileFormat(reader_options=reader_options)\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:33:16.740+0000",
                    "updated": "2020-03-24T17:33:16.740+0000",
                    "started": "2020-03-24T17:33:16.740+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408951",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408952",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397314921\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -1238,6 +1312,52 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1,\n     return pieces, partitions, common_metadata_path, metadata_path\n \n \n+class ParquetDatasetV2:\n+    \"\"\"\n+    ParquetDataset shim using the Dataset API under the hood.\n+    \"\"\"\n+    def __init__(self, path_or_paths, filesystem=None, filters=None,\n+                 read_dictionary=None, buffer_size=None):\n+        import pyarrow.dataset as ds\n+        import pyarrow.fs\n+\n+        # map old filesystems to new one\n+        if isinstance(filesystem, LocalFileSystem):\n+            filesystem = pyarrow.fs.LocalFileSystem()\n+\n+        reader_options = {}\n+        if buffer_size:\n \n Review comment:\n   ```suggestion\r\n           if buffer_size is not None:\r\n   ```\r\n   ?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:33:16.884+0000",
                    "updated": "2020-03-24T17:33:16.884+0000",
                    "started": "2020-03-24T17:33:16.884+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408952",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408953",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397323111\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -417,26 +470,29 @@ def test_pandas_parquet_1_0_roundtrip(tempdir):\n \n \n @pytest.mark.pandas\n-def test_multiple_path_types(tempdir):\n+@parametrize_use_dataset\n+def test_multiple_path_types(tempdir, use_dataset):\n     # Test compatibility with PEP 519 path-like objects\n     path = tempdir / 'zzz.parquet'\n     df = pd.DataFrame({'x': np.arange(10, dtype=np.int64)})\n     _write_table(df, path)\n-    table_read = _read_table(path)\n+    table_read = _read_table(path, use_dataset=use_dataset)\n     df_read = table_read.to_pandas()\n     tm.assert_frame_equal(df, df_read)\n \n     # Test compatibility with plain string paths\n     path = str(tempdir) + 'zzz.parquet'\n     df = pd.DataFrame({'x': np.arange(10, dtype=np.int64)})\n     _write_table(df, path)\n-    table_read = _read_table(path)\n+    table_read = _read_table(path, use_dataset=use_dataset)\n     df_read = table_read.to_pandas()\n     tm.assert_frame_equal(df, df_read)\n \n \n+# TODO(dataset) duplicate column selection actually gives duplicate columns now\n \n Review comment:\n   This seems like it could be fixed just for ParquetDatasetV2 by uniqueing the column names, is that unfavorable?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:33:16.975+0000",
                    "updated": "2020-03-24T17:33:16.975+0000",
                    "started": "2020-03-24T17:33:16.975+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408953",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408954",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397336791\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -2107,8 +2221,33 @@ def _filter_partition(df, part_keys):\n     return df[predicate].drop(to_drop, axis=1)\n \n \n-@pytest.mark.pandas\n-def test_read_multiple_files(tempdir):\n+def assert_table_equal(left, right, check_metadata=False):\n+    if left.equals(right, check_metadata=check_metadata):\n+        return\n+    \n+    if not left.schema.equals(right.schema):\n+        raise AssertionError(\"Schema not equal\\nLeft:\\n{0}\\nRight:\\n{1}\".format(left.schema, right.schema))\n+        \n+    if check_metadata:\n+        if not left.schema.equals(right.schema, check_metadata=True):\n \n Review comment:\n   Is this necessary? If you've reached this point then the schemas must be equal (modulo metadata)\r\n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:33:17.103+0000",
                    "updated": "2020-03-24T17:33:17.103+0000",
                    "started": "2020-03-24T17:33:17.103+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408954",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408955",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397335585\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -1958,8 +2069,11 @@ def _partition_test_for_filesystem(fs, base_path):\n     expected_df = (df.sort_values(by='index')\n                    .reset_index(drop=True)\n                    .reindex(columns=result_df.columns))\n-    expected_df['foo'] = pd.Categorical(df['foo'], categories=foo_keys)\n-    expected_df['bar'] = pd.Categorical(df['bar'], categories=bar_keys)\n+    if not use_dataset:\n+        # TODO(dataset) Dataset API does not create categorical columns\n+        # for partition keys\n \n Review comment:\n   Is this critical? This would be fairly easy to recover with an option like `discover_dictionaries` in partition schema discovery\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:33:17.162+0000",
                    "updated": "2020-03-24T17:33:17.162+0000",
                    "started": "2020-03-24T17:33:17.161+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408955",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408956",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397317674\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -1271,7 +1391,41 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1,\n def read_table(source, columns=None, use_threads=True, metadata=None,\n                use_pandas_metadata=False, memory_map=False,\n                read_dictionary=None, filesystem=None, filters=None,\n-               buffer_size=0):\n+               buffer_size=0, use_dataset=False):\n+    if use_dataset:\n+        import pyarrow.dataset as ds\n+        import pyarrow.fs\n+\n+        # map old filesystems to new one\n+        if isinstance(filesystem, LocalFileSystem):\n+            filesystem = pyarrow.fs.LocalFileSystem()\n+\n+        # map additional arguments\n+        # TODO raise warning when unsupported arguments are passed\n+        reader_options = {}\n+        if buffer_size:\n+            reader_options.update(use_buffered_stream=True,\n+                                  buffer_size=buffer_size)\n+        if read_dictionary is not None:\n+            reader_options.update(dict_columns=read_dictionary)\n+        parquat_format = ds.ParquetFileFormat(reader_options=reader_options)\n+\n+        dataset = ds.dataset(source, filesystem=filesystem,\n+                             format=parquat_format, partitioning=\"hive\")\n+        if filters is not None and not isinstance(filters, ds.Expression):\n+            filters = _filters_to_expression(filters)\n \n Review comment:\n   This seems to be duplicated in ParquetDatasetV2.__init__, maybe extract _dataset_from_legacy_args()?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:33:17.174+0000",
                    "updated": "2020-03-24T17:33:17.174+0000",
                    "started": "2020-03-24T17:33:17.174+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408956",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408957",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397330565\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -1826,23 +1920,39 @@ def test_invalid_pred_op(tempdir):\n     with pytest.raises(ValueError):\n         pq.ParquetDataset(base_path,\n                           filesystem=fs,\n-                          filters=[\n-                            ('integers', '=<', 3),\n-                          ])\n+                          filters=[('integers', '=<', 3), ],\n+                          use_dataset=use_dataset)\n \n-    with pytest.raises(ValueError):\n-        pq.ParquetDataset(base_path,\n-                          filesystem=fs,\n-                          filters=[\n-                            ('integers', 'in', set()),\n-                          ])\n-\n-    with pytest.raises(ValueError):\n-        pq.ParquetDataset(base_path,\n-                          filesystem=fs,\n-                          filters=[\n-                            ('integers', '!=', {3}),\n-                          ])\n+    if not use_dataset:\n+        with pytest.raises(ValueError):\n+            pq.ParquetDataset(base_path,\n+                              filesystem=fs,\n+                              filters=[('integers', 'in', set()), ],\n+                              use_dataset=use_dataset)\n+    else:\n+        # Dataset API returns empty table instead\n+        dataset = pq.ParquetDataset(base_path,\n+                                    filesystem=fs,\n+                                    filters=[('integers', 'in', set()), ],\n+                                    use_dataset=use_dataset)\n+        assert dataset.read().num_rows == 0\n+\n+    if not use_dataset:\n+        with pytest.raises(ValueError):\n+            pq.ParquetDataset(base_path,\n+                              filesystem=fs,\n+                              filters=[('integers', '!=', {3})],\n+                              use_dataset=use_dataset)\n+    else:\n+        # TODO(dataset) ARROW-8186:\n+        #  `ds.field('int') != {3}` returns bool instead of expression\n \n Review comment:\n   https://github.com/apache/arrow/pull/6700\r\n   ```suggestion\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:33:17.205+0000",
                    "updated": "2020-03-24T17:33:17.205+0000",
                    "started": "2020-03-24T17:33:17.205+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408957",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408961",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397339452\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -1238,6 +1312,52 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1,\n     return pieces, partitions, common_metadata_path, metadata_path\n \n \n+class ParquetDatasetV2:\n+    \"\"\"\n+    ParquetDataset shim using the Dataset API under the hood.\n+    \"\"\"\n+    def __init__(self, path_or_paths, filesystem=None, filters=None,\n+                 read_dictionary=None, buffer_size=None):\n+        import pyarrow.dataset as ds\n+        import pyarrow.fs\n+\n+        # map old filesystems to new one\n+        if isinstance(filesystem, LocalFileSystem):\n+            filesystem = pyarrow.fs.LocalFileSystem()\n+\n+        reader_options = {}\n+        if buffer_size:\n \n Review comment:\n   In ParquetDataset, `buffer_size` has a default of 0 (which I assume meas the default), so this way this catches both None and 0\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:36:08.522+0000",
                    "updated": "2020-03-24T17:36:08.522+0000",
                    "started": "2020-03-24T17:36:08.522+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408961",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408962",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397341542\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -417,26 +470,29 @@ def test_pandas_parquet_1_0_roundtrip(tempdir):\n \n \n @pytest.mark.pandas\n-def test_multiple_path_types(tempdir):\n+@parametrize_use_dataset\n+def test_multiple_path_types(tempdir, use_dataset):\n     # Test compatibility with PEP 519 path-like objects\n     path = tempdir / 'zzz.parquet'\n     df = pd.DataFrame({'x': np.arange(10, dtype=np.int64)})\n     _write_table(df, path)\n-    table_read = _read_table(path)\n+    table_read = _read_table(path, use_dataset=use_dataset)\n     df_read = table_read.to_pandas()\n     tm.assert_frame_equal(df, df_read)\n \n     # Test compatibility with plain string paths\n     path = str(tempdir) + 'zzz.parquet'\n     df = pd.DataFrame({'x': np.arange(10, dtype=np.int64)})\n     _write_table(df, path)\n-    table_read = _read_table(path)\n+    table_read = _read_table(path, use_dataset=use_dataset)\n     df_read = table_read.to_pandas()\n     tm.assert_frame_equal(df, df_read)\n \n \n+# TODO(dataset) duplicate column selection actually gives duplicate columns now\n \n Review comment:\n   Yes, that should be easy to do. \r\n   But, I would prefer that we decide on this for the new Datasets API what we want (deduplicating the passed columns, or returning duplicated columns), and follow that here. Otherwise it creates an inconsistency between this and the `pyarrow.dataset` API. So therefore I left it as a TODO for now (with the TODO being the need to bring this up / take a decision).\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:39:17.754+0000",
                    "updated": "2020-03-24T17:39:17.754+0000",
                    "started": "2020-03-24T17:39:17.754+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408962",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408970",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397342735\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -1958,8 +2069,11 @@ def _partition_test_for_filesystem(fs, base_path):\n     expected_df = (df.sort_values(by='index')\n                    .reset_index(drop=True)\n                    .reindex(columns=result_df.columns))\n-    expected_df['foo'] = pd.Categorical(df['foo'], categories=foo_keys)\n-    expected_df['bar'] = pd.Categorical(df['bar'], categories=bar_keys)\n+    if not use_dataset:\n+        # TODO(dataset) Dataset API does not create categorical columns\n+        # for partition keys\n \n Review comment:\n   Similar as above: I would prefer that we first decice what we want long term, rather than exactly mimicking the old API (certainly given it is opt-in for now). \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:41:10.323+0000",
                    "updated": "2020-03-24T17:41:10.323+0000",
                    "started": "2020-03-24T17:41:10.323+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408970",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408971",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397343412\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -2107,8 +2221,33 @@ def _filter_partition(df, part_keys):\n     return df[predicate].drop(to_drop, axis=1)\n \n \n-@pytest.mark.pandas\n-def test_read_multiple_files(tempdir):\n+def assert_table_equal(left, right, check_metadata=False):\n+    if left.equals(right, check_metadata=check_metadata):\n+        return\n+    \n+    if not left.schema.equals(right.schema):\n+        raise AssertionError(\"Schema not equal\\nLeft:\\n{0}\\nRight:\\n{1}\".format(left.schema, right.schema))\n+        \n+    if check_metadata:\n+        if not left.schema.equals(right.schema, check_metadata=True):\n \n Review comment:\n   I just put this function here temporarily for debugging, there is a JIRA about adding this properly -> https://issues.apache.org/jira/browse/ARROW-2647\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:42:07.221+0000",
                    "updated": "2020-03-24T17:42:07.221+0000",
                    "started": "2020-03-24T17:42:07.221+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408971",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/408981",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397350410\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -417,26 +470,29 @@ def test_pandas_parquet_1_0_roundtrip(tempdir):\n \n \n @pytest.mark.pandas\n-def test_multiple_path_types(tempdir):\n+@parametrize_use_dataset\n+def test_multiple_path_types(tempdir, use_dataset):\n     # Test compatibility with PEP 519 path-like objects\n     path = tempdir / 'zzz.parquet'\n     df = pd.DataFrame({'x': np.arange(10, dtype=np.int64)})\n     _write_table(df, path)\n-    table_read = _read_table(path)\n+    table_read = _read_table(path, use_dataset=use_dataset)\n     df_read = table_read.to_pandas()\n     tm.assert_frame_equal(df, df_read)\n \n     # Test compatibility with plain string paths\n     path = str(tempdir) + 'zzz.parquet'\n     df = pd.DataFrame({'x': np.arange(10, dtype=np.int64)})\n     _write_table(df, path)\n-    table_read = _read_table(path)\n+    table_read = _read_table(path, use_dataset=use_dataset)\n     df_read = table_read.to_pandas()\n     tm.assert_frame_equal(df, df_read)\n \n \n+# TODO(dataset) duplicate column selection actually gives duplicate columns now\n \n Review comment:\n   I think we will not deduplicate the column names in C++ @fsaintjacques \r\n   \r\n   Fields within a schema may have duplicated field names so it seems unlikely that we'll move amenities like deduplication to the lowest level.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T17:52:45.462+0000",
                    "updated": "2020-03-24T17:52:45.462+0000",
                    "started": "2020-03-24T17:52:45.461+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "408981",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/409048",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r397413293\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -1271,7 +1391,41 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1,\n def read_table(source, columns=None, use_threads=True, metadata=None,\n                use_pandas_metadata=False, memory_map=False,\n                read_dictionary=None, filesystem=None, filters=None,\n-               buffer_size=0):\n+               buffer_size=0, use_dataset=False):\n+    if use_dataset:\n+        import pyarrow.dataset as ds\n+        import pyarrow.fs\n+\n+        # map old filesystems to new one\n+        if isinstance(filesystem, LocalFileSystem):\n+            filesystem = pyarrow.fs.LocalFileSystem()\n+\n+        # map additional arguments\n+        # TODO raise warning when unsupported arguments are passed\n+        reader_options = {}\n+        if buffer_size:\n+            reader_options.update(use_buffered_stream=True,\n+                                  buffer_size=buffer_size)\n+        if read_dictionary is not None:\n+            reader_options.update(dict_columns=read_dictionary)\n+        parquat_format = ds.ParquetFileFormat(reader_options=reader_options)\n+\n+        dataset = ds.dataset(source, filesystem=filesystem,\n+                             format=parquat_format, partitioning=\"hive\")\n+        if filters is not None and not isinstance(filters, ds.Expression):\n+            filters = _filters_to_expression(filters)\n \n Review comment:\n   Moved this into a function to deduplicate\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-24T19:39:00.580+0000",
                    "updated": "2020-03-24T19:39:00.580+0000",
                    "started": "2020-03-24T19:39:00.579+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "409048",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/410263",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on issue #6303: ARROW-8039: [Python] Use dataset API in existing parquet readers and tests\nURL: https://github.com/apache/arrow/pull/6303#issuecomment-604436958\n \n \n   > Personally, I'd prefer to flip the condition from `use_dataset=False` to `use_legacy_dataset=True`\r\n   \r\n   I like that suggestion\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-26T13:40:15.372+0000",
                    "updated": "2020-03-26T13:40:15.372+0000",
                    "started": "2020-03-26T13:40:15.372+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "410263",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/412614",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on issue #6303: ARROW-8039: [Python] Use dataset API in existing parquet readers and tests\nURL: https://github.com/apache/arrow/pull/6303#issuecomment-606272922\n \n \n   Working on reviewing this, will get you feedback as soon as I can\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T21:57:33.517+0000",
                    "updated": "2020-03-30T21:57:33.517+0000",
                    "started": "2020-03-30T21:57:33.517+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412614",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/412626",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet readers and tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r400521318\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -491,20 +561,24 @@ def _test_dataframe(size=10000, seed=0):\n     return df\n \n \n+# TODO NativeFile support\n \n Review comment:\n   ```suggestion\r\n   # TODO(ARROW-8074) NativeFile support\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T22:17:52.381+0000",
                    "updated": "2020-03-30T22:17:52.381+0000",
                    "started": "2020-03-30T22:17:52.380+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412626",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/412627",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet readers and tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r400512728\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -2271,12 +2416,22 @@ def test_dataset_enable_buffered_stream(tempdir):\n     table = pa.Table.from_pandas(df)\n     _write_table(table, path, version='2.0')\n \n-    with pytest.raises(ValueError):\n-        pq.ParquetDataset(dirpath, buffer_size=-64)\n+    # TODO(dataset) raises an OSError instead of ValueError\n \n Review comment:\n   It'd probably be easiest to recover this by validating in the constructor of `ds.ParquetReadOptions`\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T22:17:52.384+0000",
                    "updated": "2020-03-30T22:17:52.384+0000",
                    "started": "2020-03-30T22:17:52.384+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412627",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/412628",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet readers and tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r400460229\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -1252,6 +1341,95 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1,\n     return pieces, partitions, common_metadata_path, metadata_path\n \n \n+class _ParquetDatasetV2:\n+    \"\"\"\n+    ParquetDataset shim using the Dataset API under the hood.\n+    \"\"\"\n+    def __init__(self, path_or_paths, filesystem=None, filters=None,\n+                 read_dictionary=None, buffer_size=None, **kwargs):\n+        import pyarrow.dataset as ds\n+        import pyarrow.fs\n+\n+        # Raise error for not supported keywords\n+        for keyword, default in [\n+                (\"schema\", None), (\"metadata\", None),\n+                (\"split_row_groups\", False), (\"validate_schema\", True),\n+                (\"metadata_nthreads\", 1), (\"memory_map\", False)]:\n+            if keyword in kwargs and kwargs[keyword] is not default:\n+                raise ValueError(\n+                    \"Keyword '{0}' is not yet supported with the new \"\n+                    \"Dataset API\".format(keyword))\n+\n+        # map old filesystems to new one\n+        # TODO(dataset) deal with other file systems\n+        if isinstance(filesystem, LocalFileSystem):\n+            filesystem = pyarrow.fs.LocalFileSystem()\n+\n+        # map additional arguments\n+        reader_options = {}\n+        if buffer_size:\n+            reader_options.update(use_buffered_stream=True,\n+                                  buffer_size=buffer_size)\n+        if read_dictionary is not None:\n+            reader_options.update(dict_columns=read_dictionary)\n+        parquet_format = ds.ParquetFileFormat(reader_options=reader_options)\n+\n+        dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n+                             format=parquet_format, partitioning=\"hive\")\n+\n+        self._dataset = dataset\n+        self._filters = filters\n+        if filters is not None:\n+            self._filter_expression = _filters_to_expression(filters)\n+        else:\n+            self._filter_expression = None\n+\n+    @property\n+    def schema(self):\n+        return self._dataset.schema\n+\n+    def read(self, columns=None, use_threads=True, use_pandas_metadata=False):\n+\n+        # if use_pandas_metadata, we need to include index columns in the\n+        # column selection, to be able to restore those in the pandas DataFrame\n+        metadata = self._dataset.schema.metadata\n+        if columns is not None and use_pandas_metadata:\n+            if metadata and b'pandas' in metadata:\n+                index_columns = _get_pandas_index_columns(metadata)\n+\n+            columns = list(columns)\n+            for index_col in index_columns:\n+                if index_col not in columns:\n+                    columns += [index_col]\n \n Review comment:\n   Maybe I'm missing something but it seems that `index_columns` won't be defined on L1401. Is this path tested?\r\n   \r\n   In any case, this would be clearer using `set()`\r\n   ```suggestion\r\n               if metadata and b'pandas' in metadata:\r\n                   index_columns = set(_get_pandas_index_columns(metadata))\r\n                   columns = columns + list(index_columns - set(columns))\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T22:17:52.388+0000",
                    "updated": "2020-03-30T22:17:52.388+0000",
                    "started": "2020-03-30T22:17:52.388+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412628",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/412629",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet readers and tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r400495071\n \n \n\n ##########\n File path: python/pyarrow/tests/test_parquet.py\n ##########\n @@ -2504,12 +2682,21 @@ def _test_write_to_dataset_with_partitions(base_path,\n     # partitioned dataset\n     dataset = pq.ParquetDataset(base_path,\n                                 filesystem=filesystem,\n-                                validate_schema=True)\n+                                validate_schema=True,\n+                                use_legacy_dataset=use_legacy_dataset)\n     # ARROW-2209: Ensure the dataset schema also includes the partition columns\n-    dataset_cols = set(dataset.schema.to_arrow_schema().names)\n+    if use_legacy_dataset:\n+        dataset_cols = set(dataset.schema.to_arrow_schema().names)\n+    else:\n+        # TODO(dataset) schema property is an arrow and not parquet schema\n \n Review comment:\n   It isn't clear to me why this is a problem here, since you're just getting the field names of the dataset's schema. Do you need a property accessor for the parquet schema on `parquet.dataset.Dataset` or `..Fragment`?\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T22:17:52.404+0000",
                    "updated": "2020-03-30T22:17:52.404+0000",
                    "started": "2020-03-30T22:17:52.404+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412629",
                    "issueId": "13290584"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/worklog/412630",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6303: ARROW-8039: [Python] Use dataset API in existing parquet readers and tests\nURL: https://github.com/apache/arrow/pull/6303#discussion_r400526345\n \n \n\n ##########\n File path: python/pyarrow/parquet.py\n ##########\n @@ -1252,6 +1341,95 @@ def _make_manifest(path_or_paths, fs, pathsep='/', metadata_nthreads=1,\n     return pieces, partitions, common_metadata_path, metadata_path\n \n \n+class _ParquetDatasetV2:\n+    \"\"\"\n+    ParquetDataset shim using the Dataset API under the hood.\n+    \"\"\"\n+    def __init__(self, path_or_paths, filesystem=None, filters=None,\n+                 read_dictionary=None, buffer_size=None, **kwargs):\n+        import pyarrow.dataset as ds\n+        import pyarrow.fs\n+\n+        # Raise error for not supported keywords\n+        for keyword, default in [\n+                (\"schema\", None), (\"metadata\", None),\n+                (\"split_row_groups\", False), (\"validate_schema\", True),\n+                (\"metadata_nthreads\", 1), (\"memory_map\", False)]:\n+            if keyword in kwargs and kwargs[keyword] is not default:\n+                raise ValueError(\n+                    \"Keyword '{0}' is not yet supported with the new \"\n+                    \"Dataset API\".format(keyword))\n+\n+        # map old filesystems to new one\n+        # TODO(dataset) deal with other file systems\n+        if isinstance(filesystem, LocalFileSystem):\n+            filesystem = pyarrow.fs.LocalFileSystem()\n \n Review comment:\n   In `pyarrow.dataset` memory mapping is deferred to the filesystem which opens the files, so `memory_map` should probably be supported with:\r\n   ```suggestion\r\n           if isinstance(filesystem, LocalFileSystem):\r\n               filesystem = pyarrow.fs.LocalFileSystem(use_mmap=memory_map)\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T22:17:52.495+0000",
                    "updated": "2020-03-30T22:17:52.495+0000",
                    "started": "2020-03-30T22:17:52.495+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412630",
                    "issueId": "13290584"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
            "id": "7",
            "description": "The sub-task of the issue",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
            "name": "Sub-task",
            "subtask": true,
            "avatarId": 21146
        },
        "timespent": 31200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@75586f26[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@39a16210[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5be43a59[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@696772d7[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7ada6b21[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@d1272cd[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@77deb7c4[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@25fd9222[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@c5776df[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@124de982[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@102f0c98[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@598af03d[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 31200,
        "customfield_12312520": null,
        "customfield_12312521": "Thu Apr 09 13:58:11 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-04-09T13:58:11.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8039/watchers",
            "watchCount": 6,
            "isWatching": false
        },
        "created": "2020-03-09T16:43:34.000+0000",
        "updated": "2020-12-22T11:25:06.000+0000",
        "timeoriginalestimate": null,
        "description": "Assemble a minimal ParquetDataset shim backed by {{pyarrow.dataset.*}}. Replace the existing ParquetDataset with the shim by default, allow opt-out for users who need the current ParquetDataset\r\n\r\nThis is mostly exploratory to see which of the python tests fail",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "8h 40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 31200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python][Dataset] Support using dataset API in pyarrow.parquet with a minimal ParquetDataset shim",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17055470",
                    "id": "17055470",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "We might focus this by saying that the objective is to satisfy the {{.read()}} method of ParquetDataset and to at least support the {{filters}} argument to the init method (with the bonus feature that you can filter on any column, not just partition keys, as an incentive to use the new code). This would exclude supporting object attributes like \"pieces\", which we could address separately for dask et al..\r\n\r\nSee https://arrow.apache.org/docs/python/generated/pyarrow.parquet.ParquetDataset.html and https://arrow.apache.org/docs/python/parquet.html#partitioned-datasets-multiple-files. ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2020-03-10T00:09:19.862+0000",
                    "updated": "2020-03-10T00:09:19.862+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17056284",
                    "id": "17056284",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "> We might focus this by saying that the objective is to satisfy the .read() method of ParquetDataset and to at least support the filters argument to the init method (with the bonus feature that you can filter on any column, not just partition keys, as an incentive to use the new code).\r\n\r\nIf that is the goal, I think this should be trivial. Which isn't to say it's not useful! Being able to run part of the tests with might discover issues. I did something similar for the read_table function at https://github.com/apache/arrow/pull/6303 (the utility code to convert old-format filters to the new expressions might be useful here as well). In case this issue is not yet started, I could also add this to that PR tomorrow.   \r\nThis would also stress test the manifest / dataset discovery part (which has a custom python implementation, so that would be useful to compare to what the datasets API does), but not sure the tests for this are very extensive.\r\n\r\n> This would exclude supporting object attributes like \"pieces\", which we could address separately for dask et al..\r\n\r\nYes, but this are the hard parts (and the parts that dask extensively uses). So it's mostly for those parts that we will need to decide whether we want to try to create an API-compatible shim, or rather try to provide the necessary features to be able to migrate to the new API.\r\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2020-03-10T18:59:31.071+0000",
                    "updated": "2020-03-10T18:59:31.071+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17056289",
                    "id": "17056289",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Right, my thought was that we'd solve the Dask problem a different way, like you already started exploring.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2020-03-10T19:05:29.356+0000",
                    "updated": "2020-03-10T19:05:29.356+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17056479",
                    "id": "17056479",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "So a more specific comment here: if basically the only thing that such a ParquetDataset would support is a \"read()\" function, I am not sure what the benefit of such a ParquetDataset class would be compared to the  {{parquet.read_table}} function (which also supports reading with column selection / row filter) (when designing a new API).\r\n\r\nAnd supporting this in {{read_table}} I actually already did in https://github.com/apache/arrow/pull/6303",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2020-03-10T22:33:21.342+0000",
                    "updated": "2020-03-10T22:50:27.954+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17056487",
                    "id": "17056487",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Ah, good call. That sounds reasonable to me (as someone who is not a user). And it looks like it is trivial enough to promote only read_table and not mention ParquetDataset in https://arrow.apache.org/docs/python/parquet.html#partitioned-datasets-multiple-files. \r\n\r\nSo the idea would be that read_table would be the function that gets the new Dataset option, and ParquetDataset would be unchanged (just no longer encouraged for use). \r\n\r\n[~wesm] thoughts?",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=npr",
                        "name": "npr",
                        "key": "npr",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Neal Richardson",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2020-03-10T22:47:06.524+0000",
                    "updated": "2020-03-10T22:47:06.524+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17056496",
                    "id": "17056496",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "> So the idea would be that read_table would be the function that gets the new Dataset option, and ParquetDataset would be unchanged (just no longer encouraged for use).\r\n\r\nThat would be an option, yes.\r\n\r\nTo give some context from dask's usage: they actually do _not_ use the ParquetDataset.read() method. They use a lot of other things of the class: get the partitioning information, the pieces, the metadata, etc, but not read the full dataset. For reading, they use ParquetDatasetPiece.read().\r\n\r\nNow, dask's usage is maybe not typical, so it would be good to check some other places on how ParquetDataset gets used.\r\n\r\nFor example on StackOverflow:\r\n * Top answer on reading partitioned dataset on S3 uses ParquetDataset().reade().to_pandas(): [https://stackoverflow.com/questions/45043554/how-to-read-a-list-of-parquet-files-from-s3-as-a-pandas-dataframe-using-pyarrow/48809552#48809552]\r\n * Some other, less popular S3 related questions that also mention ParquetDataset with basically the same usage pattern\r\n\r\nNow, there might still be value in having a two-step way (creating the dataset, and reading) instead of a 1 step {{read_table}}, since the former allows to do some inspection of the dataset before reading it. \r\nBut this is what the {{pyarrow.dataset.Dataset}} already provides. So the question is if a ParquetDataset then is needed? \r\n\r\nI suppose such a subclass might be useful to directly expose the parquet specific things (eg without needing to specify {{format=\"parquet\"}}, or by exposing ParquetFileFormatOptions directly in the constructor of ParquetDataset, etc). I think something like this _is_ useful, but then I would rather model it after dataset.Dataset, to make it consistent with that new API, rather than model it after parquet.ParquetDataset (which would introduce an inconsistencies with the new API), maybe just with a {{read()}} method for basic backwards compatibility (but for the rest following the API of dataset.Dataset)",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2020-03-10T23:07:12.014+0000",
                    "updated": "2020-03-10T23:07:12.014+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17056510",
                    "id": "17056510",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "If it were possible to maintain backward compatibility for simple use cases (with a FutureWarning) for a period of time that would seem ideal. As long we're on a path to address the use cases with the new code. It seems fine if {{ParquetDataset}} eventually goes away entirely",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-03-10T23:14:07.829+0000",
                    "updated": "2020-03-10T23:14:07.829+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17064894",
                    "id": "17064894",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "I expanded my existing PR for {{read_table}} (https://github.com/apache/arrow/pull/6303) with a small ParquetDataset shim, that at least should have the basic {{ParquetDataset(..).read()}} work. \r\n\r\nRight now I added a {{use_dataset=False/True}} keyword (with a default of False), so you can opt in to use the new dataset API under the hood (and to allow me to use this in the tests). But the final end user API we want to provide for this should still be discussed.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2020-03-23T15:52:57.288+0000",
                    "updated": "2020-03-23T15:52:57.288+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13290584/comment/17079369",
                    "id": "17079369",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 6303\n[https://github.com/apache/arrow/pull/6303]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-04-09T13:58:11.624+0000",
                    "updated": "2020-04-09T13:58:11.624+0000"
                }
            ],
            "maxResults": 9,
            "total": 9,
            "startAt": 0
        },
        "customfield_12311820": "0|z0cc4w:",
        "customfield_12314139": null
    }
}