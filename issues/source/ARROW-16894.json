{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13462985",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985",
    "key": "ARROW-16894",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12351947",
                "id": "12351947",
                "description": "",
                "name": "10.0.0",
                "archived": false,
                "released": true,
                "releaseDate": "2022-10-26"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ichauster",
            "name": "ichauster",
            "key": "JIRAUSER290345",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
            },
            "displayName": "Ivan Chau",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ichauster",
            "name": "ichauster",
            "key": "JIRAUSER290345",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
            },
            "displayName": "Ivan Chau",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=ichauster",
            "name": "ichauster",
            "key": "JIRAUSER290345",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
            },
            "displayName": "Ivan Chau",
            "active": true,
            "timeZone": "Etc/UTC"
        },
        "aggregateprogress": {
            "progress": 49200,
            "total": 49200,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 49200,
            "total": 49200,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16894/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 82,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/784216",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster opened a new pull request, #13426:\nURL: https://github.com/apache/arrow/pull/13426\n\n   **Currently a draft, please disregard asof join implementations which have yet to be merged**\n\n\n",
                    "created": "2022-06-23T13:23:51.939+0000",
                    "updated": "2022-06-23T13:23:51.939+0000",
                    "started": "2022-06-23T13:23:51.938+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "784216",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/784222",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1164421433\n\n   <!--\n     Licensed to the Apache Software Foundation (ASF) under one\n     or more contributor license agreements.  See the NOTICE file\n     distributed with this work for additional information\n     regarding copyright ownership.  The ASF licenses this file\n     to you under the Apache License, Version 2.0 (the\n     \"License\"); you may not use this file except in compliance\n     with the License.  You may obtain a copy of the License at\n   \n       http://www.apache.org/licenses/LICENSE-2.0\n   \n     Unless required by applicable law or agreed to in writing,\n     software distributed under the License is distributed on an\n     \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n     KIND, either express or implied.  See the License for the\n     specific language governing permissions and limitations\n     under the License.\n   -->\n   \n   Thanks for opening a pull request!\n   \n   If this is not a [minor PR](https://github.com/apache/arrow/blob/master/CONTRIBUTING.md#Minor-Fixes). Could you open an issue for this pull request on JIRA? https://issues.apache.org/jira/browse/ARROW\n   \n   Opening JIRAs ahead of time contributes to the [Openness](http://theapacheway.com/open/#:~:text=Openness%20allows%20new%20users%20the,must%20happen%20in%20the%20open.) of the Apache Arrow project.\n   \n   Then could you also rename pull request title in the following format?\n   \n       ARROW-${JIRA_ID}: [${COMPONENT}] ${SUMMARY}\n   \n   or\n   \n       MINOR: [${COMPONENT}] ${SUMMARY}\n   \n   See also:\n   \n     * [Other pull requests](https://github.com/apache/arrow/pulls/)\n     * [Contribution Guidelines - How to contribute patches](https://arrow.apache.org/docs/developers/contributing.html#how-to-contribute-patches)\n   \n\n\n",
                    "created": "2022-06-23T13:39:31.808+0000",
                    "updated": "2022-06-23T13:39:31.808+0000",
                    "started": "2022-06-23T13:39:31.808+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "784222",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/786161",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1170324395\n\n   Hi @westonpace, let me know if you can take a look at a few of the questions above I had about merging this into arrow.\r\n   \r\n   I was also wondering if you could clarify how the arrow threading engine would work for a node that has multiple inputs (an asof join / hash join ingesting from multiple source nodes, for example).\r\n   \r\n   While being processed, is a single source node dedicated a single thread?\r\n   How many threads can call `InputReceived` of the following node at once? \r\n   \n\n\n",
                    "created": "2022-06-29T18:09:06.971+0000",
                    "updated": "2022-06-29T18:09:06.971+0000",
                    "started": "2022-06-29T18:09:06.971+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "786161",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/786346",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1170685688\n\n   Some initial questions and I'll take a more detailed look soon.\r\n   \r\n   > Here is a very primitive version of our Asof Join Benchmarks (asof_join_benchmark.cc). Our main goal is to benchmark on four qualities: the effect of table density (the frequency of rows, e.g a row every 2s as opposed to every 1h over some time range), table width (# of columns), tids (# of keys), and multi-table joins. We also have a baseline comparison benchmark with hash joins (which is currently in this file).\r\n   \r\n   * Does the table density get applied uniformly over all input columns?  In other words, do you worry about cases where one input is very dense and the others are not so dense?\r\n   * When you say multi-table joins how many tables are you testing?  Or is that a parameter?\r\n   * # of columns and # of keys is good.  Eventually you will need to worry about data types I would think (probably more for payload columns than for key columns)\r\n   \r\n   > I think this needs some work before it goes into arrow. We currently run this benchmark by generating .feather files with Python via bamboo-streaming's datagen.py to represent each table, and then reading them in through cpp (see make_arrow_ipc_reader_node). We perhaps want to write a utility that allows us to do this in cpp, while varying many of the metrics I've mentioned above, or finding a way to generate those files as part of the benchmark.\r\n   \r\n   Another potential approach is to create a custom source node that generates data.  We do something like this for our tpc-h benchmark.  This allows us to isolate the scanning from the actual compute operations.  However, this kind of requires you to write the data generator in C++ which is probably not ideal.\r\n   \r\n   > There are also quite a large number of BENCHMARK_CAPTURE statements, as an immediate workaround to some limitations in Google Benchmarks. I haven't found a great non-verbose way to pass in the parameters needed (strings and vectors) while also having readable titles and details about the benchmark being written to the output file. Let me know if you have any advice about this / know some one who does.\r\n   \r\n   I'll think about this when I take a closer look.  Google benchmark is not necessarily the perfect tool for every situation.  But maybe there is something we can do.\r\n   \r\n   > While being processed, is a single source node dedicated a single thread?\r\n   \r\n   No.\r\n   \r\n   > How many threads can call InputReceived of the following node at once?\r\n   \r\n   That is mostly determined by the capacity of the executor which defaults to std::hardware_concurrency (e.g. one per core or two per core if you have hyperthreading) for the CPU thread pool.  At the moment it can be even greater than this number but this is an issue we are hoping to fix soon (limiting these calls to only CPU thread pool calls).\r\n   \r\n   > I was also wondering if you could clarify how the arrow threading engine would work for a node that has multiple inputs (an asof join / hash join ingesting from multiple source nodes, for example).\r\n   \r\n   Even if the asof join node had a single source node it could still be called many times.  You can think of a source node as a parallel while loop across all the batches:\r\n   \r\n   ```\r\n   while (!source.empty()) {\r\n     exec_context->executor->Spawn([this] {\r\n       ExecBatch next_batch = ReadNext();\r\n       output->InputReceived(next_batch);\r\n     }\r\n   }\r\n   ```\r\n   \r\n   If there are multiple sources then they are still all submitting tasks to the same common thread pool so you won't see any more threads.  Also, in many unit tests and small use cases the source doesn't have enough data for more than one task so you often don't see the full scale of parallelism until you are testing larger datasets.\r\n   \r\n   There are some changes planned for the scheduler but most of what I said already will remain more or less true.  The future scheduler could potentially prioritize one source above others (for example, it often makes sense with a hash-join node to prioritize the build side input) so that is something to consider (for the as-of join node you probably want to read from all sources evenly I think).\n\n\n",
                    "created": "2022-06-30T02:39:42.347+0000",
                    "updated": "2022-06-30T02:39:42.347+0000",
                    "started": "2022-06-30T02:39:42.346+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "786346",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/786621",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "icexelloss commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1171297967\n\n   @westonpace Thanks for the detailed reply. I remember when I use \r\n   \r\n   ```\r\n   ExecContext ctx(default_memory_pool(), arrow::internal::GetCpuThreadPool());\r\n   ```\r\n   \r\n   in asof_join test, I got wrong results and see data coming in out of order and therefore, having to use\r\n   \r\n   ```\r\n   ExecContext ctx(default_memory_pool(), nullptr);\r\n   ```\r\n   \r\n   - I wonder what's the threading model for the latter? Is it just one thread doing everything?\n\n\n",
                    "created": "2022-06-30T14:33:52.227+0000",
                    "updated": "2022-06-30T14:33:52.227+0000",
                    "started": "2022-06-30T14:33:52.227+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "786621",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/786626",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "icexelloss commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1171307092\n\n   Side topic: Is there an example to use a \"write node\" in Acero? We had some code a few month ago but it seems it no longer works (probably due to some API changes):\r\n   https://github.com/twosigma/bamboo-streaming/blob/master/experiments/msw_fulltest/writernode.cpp#L26\r\n   \r\n   And I couldn't find an example/test in Acero that uses a write node - if there is, can you perhaps point me to one?\n\n\n",
                    "created": "2022-06-30T14:41:25.146+0000",
                    "updated": "2022-06-30T14:41:25.146+0000",
                    "started": "2022-06-30T14:41:25.146+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "786626",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/786666",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1171363759\n\n   Thanks for the help so far, @westonpace !\r\n   > Does the table density get applied uniformly over all input columns? In other words, do you worry about cases where one input is very dense and the others are not so dense?\r\n   If what you're referring to multi-table joins (a left hand table joined with one or multiple right hand tables), all right hand tables share the same properties. I think it would be interesting to write a few benchmarks where the right hand tables have a bit more variation amongst themselves.\r\n   \r\n   If you're referring to within the same table, I think our benchmarking approach currently doesn't test case joins with high time freq and low id density (and vice versa). We currently have set some 'baselines' and try to only vary one property at a time. For example, if we are interested in time frequency, we set the remaining properties to the baseline, and test time frequency in the symmetric case (LH table and RH table have the same time frequency for various values), and the asymmetric case.\r\n   \r\n   Since it seems performance varies mostly from time frequency and key density, I can see a few benchmarks written where we vary both at the same time.\r\n   \r\n   > When you say multi-table joins how many tables are you testing? Or is that a parameter?\r\n   This is a parameter. We currently are testing 1 table to 51 table joins for `AsOf` (the number of inputs to the `AsOfJoin` node).\r\n   \r\n   > number of columns and number of keys is good. Eventually you will need to worry about data types I would think (probably more for payload columns than for key columns)\r\n   Yes ",
                    "created": "2022-06-30T15:29:48.674+0000",
                    "updated": "2022-06-30T15:29:48.674+0000",
                    "started": "2022-06-30T15:29:48.674+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "786666",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/786795",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1171616294\n\n   > If what you're referring to multi-table joins (a left hand table joined with one or multiple right hand tables), all right hand tables share the same properties. I think it would be interesting to write a few benchmarks where the right hand tables have a bit more variation amongst themselves.\r\n   \r\n   I think I was mostly curious about differences in density between the left table and the right table(s).  For example, a dense left table and a sparse right table or a sparse left table and a dense right table.  The left table roughly defines the keyframes so I would expect the density of the left table to be more significant to performance than the density of the right table.\n\n\n",
                    "created": "2022-06-30T19:52:44.383+0000",
                    "updated": "2022-06-30T19:52:44.383+0000",
                    "started": "2022-06-30T19:52:44.383+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "786795",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/786918",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1171880413\n\n   > I think I was mostly curious about differences in density between the left table and the right table(s). For example, a dense left table and a sparse right table or a sparse left table and a dense right table. The left table roughly defines the keyframes so I would expect the density of the left table to be more significant to performance than the density of the right table.\r\n   \r\n   Ah yes, we did try this as part of our asymmetric case. The left table definitely impacts performance the most, with clear separations in time. We also observed another interesting property, which suggests that the time frequency of the right tables does not matter as long as they are >= the left hand table time frequency.\r\n   \r\n   That is, if the left hand table has a time frequency of 10 minutes, we see an increase in real_time when joining tables with 1d, 1h, 30m, etc, but the time it takes to join with right hand tables with 10m, 5m, 1m, is the same.\n\n\n",
                    "created": "2022-07-01T03:07:35.107+0000",
                    "updated": "2022-07-01T03:07:35.107+0000",
                    "started": "2022-07-01T03:07:35.106+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "786918",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/787266",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1172799266\n\n   > \r\n   \r\n   @icexelloss You can find a simple `write` operator example here: https://github.com/apache/arrow/blob/998cca30c70a7e0bbc3f83957923f2e3019b314b/cpp/examples/arrow/execution_plan_documentation_examples.cc#L795\r\n   \r\n   Is this helpful? Let me know I can help out with a better example if required. \n\n\n",
                    "created": "2022-07-02T00:41:10.710+0000",
                    "updated": "2022-07-02T00:41:10.710+0000",
                    "started": "2022-07-02T00:41:10.709+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "787266",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/787269",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "vibhatha commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r912299882\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n\nReview Comment:\n   May be? \r\n   \r\n   ```suggestion\r\n     std::vector<std::string> right_hand_tables;\r\n     right_hand_tables.reserve(num_tables);\r\n     \r\n     for (int j = 1; j <= num_tables; j++) {\r\n       right_hand_tables.push_back(\r\n           generate_file_name(freq, width_table[width_index], num_ids_table[num_ids_index],\r\n             std::to_string(j)));\r\n     }\r\n   ```\n\n\n\n",
                    "created": "2022-07-02T00:55:18.462+0000",
                    "updated": "2022-07-02T00:55:18.462+0000",
                    "started": "2022-07-02T00:55:18.461+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "787269",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/787991",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#issuecomment-1175361521\n\n   > > \r\n   > \r\n   > @icexelloss You can find a simple `write` operator example here:\r\n   > \r\n   > https://github.com/apache/arrow/blob/998cca30c70a7e0bbc3f83957923f2e3019b314b/cpp/examples/arrow/execution_plan_documentation_examples.cc#L795\r\n   > \r\n   > Is this helpful? Let me know I can help out with a better example if required.\r\n   \r\n   Thanks for this! Unfortunately I couldn't get my version to compile. I did find a workaround though ",
                    "created": "2022-07-05T18:24:44.216+0000",
                    "updated": "2022-07-05T18:24:44.216+0000",
                    "started": "2022-07-05T18:24:44.216+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "787991",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788075",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r914289950\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> _reader;\n+  int _next;\n+\n+ public:\n+  virtual ~RecordBatchFileReaderWrapper() {}\n+  explicit RecordBatchFileReaderWrapper(\n+      std::shared_ptr<arrow::ipc::RecordBatchFileReader> reader)\n+      : _reader(reader), _next(0) {}\n+\n+  virtual arrow::Status ReadNext(std::shared_ptr<arrow::RecordBatch>* batch) {\n+    // cout << \"ReadNext _next=\" << _next << \"\\n\";\n+    if (_next < _reader->num_record_batches()) {\n+      ARROW_ASSIGN_OR_RAISE(*batch, _reader->ReadRecordBatch(_next++));\n+      // cout << \"\\t --> \" << (*batch)->num_rows() << \"\\n\";\n+    } else {\n+      batch->reset();\n+      // cout << \"\\t --> EOF\\n\";\n+    }\n+\n+    return arrow::Status::OK();\n+  }\n+\n+  virtual std::shared_ptr<arrow::Schema> schema() const { return _reader->schema(); }\n+};\n+\n+static std::tuple<arrow::compute::ExecNode*, int64_t, int, size_t>\n+make_arrow_ipc_reader_node(std::shared_ptr<arrow::compute::ExecPlan>& plan,\n+                           std::shared_ptr<arrow::fs::FileSystem>& fs,\n+                           const std::string& filename) {\n+  // TODO: error checking\n+  std::shared_ptr<arrow::io::RandomAccessFile> input = *fs->OpenInputFile(filename);\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> in_reader =\n+      *arrow::ipc::RecordBatchFileReader::Open(input);\n+  std::shared_ptr<RecordBatchFileReaderWrapper> reader(\n+      new RecordBatchFileReaderWrapper(in_reader));\n+\n+  auto schema = reader->schema();\n+  // we assume there is a time field represented in uint64, a key field of int32, and the\n+  // remaining fields are float64.\n+  size_t row_size =\n+      sizeof(_Float64) * (schema->num_fields() - 2) + sizeof(int64_t) + sizeof(int32_t);\n+  auto batch_gen = *arrow::compute::MakeReaderGenerator(\n+      std::move(reader), arrow::internal::GetCpuThreadPool());\n+  int64_t rows = in_reader->CountRows().ValueOrDie();\n+  // cout << \"create source(\"<<filename<<\")\\n\";\n+  return {*arrow::compute::MakeExecNode(\n+              \"source\",    // registered type\n+              plan.get(),  // execution plan\n+              {},          // inputs\n+              arrow::compute::SourceNodeOptions(\n+                  std::make_shared<arrow::Schema>(*schema),  // options, )\n+                  batch_gen)),\n+          rows, in_reader->num_record_batches(), row_size * rows};\n+}\n+\n+static void TableJoinOverhead(benchmark::State& state, std::string left_table,\n+                              std::vector<std::string> right_tables,\n+                              std::string factory_name, ExecNodeOptions& options) {\n+  const std::string data_directory = \"./benchmark_data/\";\n+  DoSetup();\n+  ExecContext ctx(default_memory_pool(), arrow::internal::GetCpuThreadPool());\n+  // std::cout << \"beginning test for \" << left_table << \" and \" << right_tables[0] << \" \"\n+  // << factory_name << std::endl; std::cout << \"starting with \" <<\n+  // ctx.memory_pool()->bytes_allocated() << std::endl;\n+  int64_t rows;\n+  int64_t bytes;\n+  for (auto _ : state) {\n+    state.PauseTiming();\n+\n+    ASSERT_OK_AND_ASSIGN(std::shared_ptr<arrow::compute::ExecPlan> plan,\n+                         ExecPlan::Make(&ctx));\n+    std::shared_ptr<arrow::fs::FileSystem> fs =\n+        std::make_shared<arrow::fs::LocalFileSystem>();\n+    arrow::compute::ExecNode* left_table_source;\n+    int64_t left_table_rows;\n+    int left_table_batches;\n+    size_t left_table_bytes;\n+    tie(left_table_source, left_table_rows, left_table_batches, left_table_bytes) =\n+        make_arrow_ipc_reader_node(plan, fs, data_directory + left_table);\n+    std::vector<ExecNode*> inputs = {left_table_source};\n+    int right_hand_rows = 0;\n+    int64_t right_hand_bytes = 0;\n+    for (std::string right_table : right_tables) {\n+      arrow::compute::ExecNode* right_table_source;\n+      int64_t right_table_rows;\n+      int right_table_batches;\n+      size_t right_table_bytes;\n+      tie(right_table_source, right_table_rows, right_table_batches, right_table_bytes) =\n+          make_arrow_ipc_reader_node(plan, fs, data_directory + right_table);\n+      inputs.push_back(right_table_source);\n+      right_hand_rows += right_table_rows;\n+      right_hand_bytes += right_table_bytes;\n+    }\n+    rows = left_table_rows + right_hand_rows;\n+    bytes = left_table_bytes + right_hand_bytes;\n+    ASSERT_OK_AND_ASSIGN(arrow::compute::ExecNode * asof_join_node,\n+                         MakeExecNode(factory_name, plan.get(), inputs, options));\n+\n+    AsyncGenerator<util::optional<ExecBatch>> sink_gen;\n+    MakeExecNode(\"sink\", plan.get(), {asof_join_node}, SinkNodeOptions{&sink_gen});\n+    state.ResumeTiming();\n+    // std::cout << \"starting and collecting with \" <<\n+    // ctx.memory_pool()->bytes_allocated() << std::endl;\n+    ASSERT_FINISHES_OK(StartAndCollect(plan.get(), sink_gen));\n+    // std::cout << \"finishing with \" << ctx.memory_pool()->bytes_allocated() <<\n+    // std::endl;\n+  }\n+  // std::cout << \"reporting with \" << ctx.memory_pool()->bytes_allocated() << std::endl;\n+  state.counters[\"total_rows_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * rows), benchmark::Counter::kIsRate);\n+\n+  state.counters[\"total_bytes_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * bytes), benchmark::Counter::kIsRate);\n+}\n+\n+static void AsOfJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  int64_t tolerance = 0;\n+  AsofJoinNodeOptions options = AsofJoinNodeOptions(time_col, key_col, tolerance);\n+  TableJoinOverhead(state, left_table, right_tables, \"asofjoin\", options);\n+}\n+\n+static void HashJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  HashJoinNodeOptions options =\n+      HashJoinNodeOptions({time_col, key_col}, {time_col, key_col});\n+  TableJoinOverhead(state, left_table, right_tables, \"hashjoin\", options);\n+}\n+\n+// this generates the set of right hand tables to test on.\n+void SetArgs(benchmark::internal::Benchmark* bench) { bench->UseRealTime(); }\n+\n+BENCHMARK_CAPTURE(AsOfJoinOverhead,\n\nReview Comment:\n   This is a lot of possible combinations.  How long does it take to run the full suite?  Are all of these combinations informative?\n\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> _reader;\n+  int _next;\n+\n+ public:\n+  virtual ~RecordBatchFileReaderWrapper() {}\n+  explicit RecordBatchFileReaderWrapper(\n+      std::shared_ptr<arrow::ipc::RecordBatchFileReader> reader)\n+      : _reader(reader), _next(0) {}\n+\n+  virtual arrow::Status ReadNext(std::shared_ptr<arrow::RecordBatch>* batch) {\n+    // cout << \"ReadNext _next=\" << _next << \"\\n\";\n+    if (_next < _reader->num_record_batches()) {\n+      ARROW_ASSIGN_OR_RAISE(*batch, _reader->ReadRecordBatch(_next++));\n+      // cout << \"\\t --> \" << (*batch)->num_rows() << \"\\n\";\n+    } else {\n+      batch->reset();\n+      // cout << \"\\t --> EOF\\n\";\n+    }\n+\n+    return arrow::Status::OK();\n+  }\n+\n+  virtual std::shared_ptr<arrow::Schema> schema() const { return _reader->schema(); }\n+};\n+\n+static std::tuple<arrow::compute::ExecNode*, int64_t, int, size_t>\n+make_arrow_ipc_reader_node(std::shared_ptr<arrow::compute::ExecPlan>& plan,\n+                           std::shared_ptr<arrow::fs::FileSystem>& fs,\n+                           const std::string& filename) {\n+  // TODO: error checking\n+  std::shared_ptr<arrow::io::RandomAccessFile> input = *fs->OpenInputFile(filename);\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> in_reader =\n+      *arrow::ipc::RecordBatchFileReader::Open(input);\n+  std::shared_ptr<RecordBatchFileReaderWrapper> reader(\n+      new RecordBatchFileReaderWrapper(in_reader));\n+\n+  auto schema = reader->schema();\n+  // we assume there is a time field represented in uint64, a key field of int32, and the\n+  // remaining fields are float64.\n+  size_t row_size =\n+      sizeof(_Float64) * (schema->num_fields() - 2) + sizeof(int64_t) + sizeof(int32_t);\n+  auto batch_gen = *arrow::compute::MakeReaderGenerator(\n+      std::move(reader), arrow::internal::GetCpuThreadPool());\n+  int64_t rows = in_reader->CountRows().ValueOrDie();\n+  // cout << \"create source(\"<<filename<<\")\\n\";\n+  return {*arrow::compute::MakeExecNode(\n+              \"source\",    // registered type\n+              plan.get(),  // execution plan\n+              {},          // inputs\n+              arrow::compute::SourceNodeOptions(\n+                  std::make_shared<arrow::Schema>(*schema),  // options, )\n+                  batch_gen)),\n+          rows, in_reader->num_record_batches(), row_size * rows};\n+}\n+\n+static void TableJoinOverhead(benchmark::State& state, std::string left_table,\n+                              std::vector<std::string> right_tables,\n+                              std::string factory_name, ExecNodeOptions& options) {\n+  const std::string data_directory = \"./benchmark_data/\";\n+  DoSetup();\n+  ExecContext ctx(default_memory_pool(), arrow::internal::GetCpuThreadPool());\n+  // std::cout << \"beginning test for \" << left_table << \" and \" << right_tables[0] << \" \"\n+  // << factory_name << std::endl; std::cout << \"starting with \" <<\n+  // ctx.memory_pool()->bytes_allocated() << std::endl;\n+  int64_t rows;\n+  int64_t bytes;\n+  for (auto _ : state) {\n+    state.PauseTiming();\n+\n+    ASSERT_OK_AND_ASSIGN(std::shared_ptr<arrow::compute::ExecPlan> plan,\n+                         ExecPlan::Make(&ctx));\n+    std::shared_ptr<arrow::fs::FileSystem> fs =\n+        std::make_shared<arrow::fs::LocalFileSystem>();\n+    arrow::compute::ExecNode* left_table_source;\n+    int64_t left_table_rows;\n+    int left_table_batches;\n+    size_t left_table_bytes;\n+    tie(left_table_source, left_table_rows, left_table_batches, left_table_bytes) =\n+        make_arrow_ipc_reader_node(plan, fs, data_directory + left_table);\n+    std::vector<ExecNode*> inputs = {left_table_source};\n+    int right_hand_rows = 0;\n+    int64_t right_hand_bytes = 0;\n+    for (std::string right_table : right_tables) {\n+      arrow::compute::ExecNode* right_table_source;\n+      int64_t right_table_rows;\n+      int right_table_batches;\n+      size_t right_table_bytes;\n+      tie(right_table_source, right_table_rows, right_table_batches, right_table_bytes) =\n+          make_arrow_ipc_reader_node(plan, fs, data_directory + right_table);\n+      inputs.push_back(right_table_source);\n+      right_hand_rows += right_table_rows;\n+      right_hand_bytes += right_table_bytes;\n+    }\n+    rows = left_table_rows + right_hand_rows;\n+    bytes = left_table_bytes + right_hand_bytes;\n+    ASSERT_OK_AND_ASSIGN(arrow::compute::ExecNode * asof_join_node,\n\nReview Comment:\n   Minor nit: `join_node` instead of `asof_join_node` since this function is used in both paths?\n\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> _reader;\n+  int _next;\n+\n+ public:\n+  virtual ~RecordBatchFileReaderWrapper() {}\n+  explicit RecordBatchFileReaderWrapper(\n+      std::shared_ptr<arrow::ipc::RecordBatchFileReader> reader)\n+      : _reader(reader), _next(0) {}\n+\n+  virtual arrow::Status ReadNext(std::shared_ptr<arrow::RecordBatch>* batch) {\n+    // cout << \"ReadNext _next=\" << _next << \"\\n\";\n+    if (_next < _reader->num_record_batches()) {\n+      ARROW_ASSIGN_OR_RAISE(*batch, _reader->ReadRecordBatch(_next++));\n+      // cout << \"\\t --> \" << (*batch)->num_rows() << \"\\n\";\n+    } else {\n+      batch->reset();\n+      // cout << \"\\t --> EOF\\n\";\n+    }\n+\n+    return arrow::Status::OK();\n+  }\n+\n+  virtual std::shared_ptr<arrow::Schema> schema() const { return _reader->schema(); }\n+};\n+\n+static std::tuple<arrow::compute::ExecNode*, int64_t, int, size_t>\n\nReview Comment:\n   I'm not a big fan of using tuple as a return type here as it is rather opaque what these ints are representing.  Could you just create a simple struct?\n\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n\nReview Comment:\n   A benchmark can't really depend on an external generation tool.  I think when I looked through this the first time I figured this was a python file you would be adding to the arrow repo.  Is that planned?  Or will this somehow go away?\n\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n\nReview Comment:\n   This seems rather unsafe.  Can you use `arrow::internal::TemporaryDir` in `src/arrow/util/io_util.h` instead?\n\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n\nReview Comment:\n   It would be good to keep I/O out of the benchmark if at all possible.  Otherwise your benchmark ends up being rather jittery and can end up simply reflecting the performance of the I/O and not the actual compute.\n\n\n\n",
                    "created": "2022-07-05T23:53:54.805+0000",
                    "updated": "2022-07-05T23:53:54.805+0000",
                    "started": "2022-07-05T23:53:54.805+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788075",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788277",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r914920503\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n\nReview Comment:\n   Yeah, I think we would prefer to move some of the python bamboo streaming data generation scripts over into arrow. Do you have any advice on where to put them? (it seems slightly odd to be putting python in a folder under cpp)...\n\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n\nReview Comment:\n   Yeah, I think we would prefer to move some of the python bamboo streaming data generation scripts over into arrow than writing a table generator in cpp. Do you have any advice on where to put them? (it seems slightly odd to be putting python in a folder under cpp)...\n\n\n\n",
                    "created": "2022-07-06T14:37:36.266+0000",
                    "updated": "2022-07-06T14:37:36.266+0000",
                    "started": "2022-07-06T14:37:36.266+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788277",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788281",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r914923850\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n\nReview Comment:\n   I see. One alternative I can think of is reading in the files in memory through a table object, and using a `TableSourceNode` in the preparation stage. I'm assuming that would be less I/O intensive?\n\n\n\n",
                    "created": "2022-07-06T14:40:26.575+0000",
                    "updated": "2022-07-06T14:40:26.575+0000",
                    "started": "2022-07-06T14:40:26.574+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788281",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788282",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r914923850\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n\nReview Comment:\n   I see. One alternative I can think of is reading in the files in memory through a table object, and using a `TableSourceNode` in the preparation stage. I think this would assure everything is in-memory during `StartAndCollect`. I'm assuming that would be less I/O intensive?\n\n\n\n",
                    "created": "2022-07-06T14:41:21.914+0000",
                    "updated": "2022-07-06T14:41:21.914+0000",
                    "started": "2022-07-06T14:41:21.914+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788282",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788314",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r915004294\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> _reader;\n+  int _next;\n+\n+ public:\n+  virtual ~RecordBatchFileReaderWrapper() {}\n+  explicit RecordBatchFileReaderWrapper(\n+      std::shared_ptr<arrow::ipc::RecordBatchFileReader> reader)\n+      : _reader(reader), _next(0) {}\n+\n+  virtual arrow::Status ReadNext(std::shared_ptr<arrow::RecordBatch>* batch) {\n+    // cout << \"ReadNext _next=\" << _next << \"\\n\";\n+    if (_next < _reader->num_record_batches()) {\n+      ARROW_ASSIGN_OR_RAISE(*batch, _reader->ReadRecordBatch(_next++));\n+      // cout << \"\\t --> \" << (*batch)->num_rows() << \"\\n\";\n+    } else {\n+      batch->reset();\n+      // cout << \"\\t --> EOF\\n\";\n+    }\n+\n+    return arrow::Status::OK();\n+  }\n+\n+  virtual std::shared_ptr<arrow::Schema> schema() const { return _reader->schema(); }\n+};\n+\n+static std::tuple<arrow::compute::ExecNode*, int64_t, int, size_t>\n+make_arrow_ipc_reader_node(std::shared_ptr<arrow::compute::ExecPlan>& plan,\n+                           std::shared_ptr<arrow::fs::FileSystem>& fs,\n+                           const std::string& filename) {\n+  // TODO: error checking\n+  std::shared_ptr<arrow::io::RandomAccessFile> input = *fs->OpenInputFile(filename);\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> in_reader =\n+      *arrow::ipc::RecordBatchFileReader::Open(input);\n+  std::shared_ptr<RecordBatchFileReaderWrapper> reader(\n+      new RecordBatchFileReaderWrapper(in_reader));\n+\n+  auto schema = reader->schema();\n+  // we assume there is a time field represented in uint64, a key field of int32, and the\n+  // remaining fields are float64.\n+  size_t row_size =\n+      sizeof(_Float64) * (schema->num_fields() - 2) + sizeof(int64_t) + sizeof(int32_t);\n+  auto batch_gen = *arrow::compute::MakeReaderGenerator(\n+      std::move(reader), arrow::internal::GetCpuThreadPool());\n+  int64_t rows = in_reader->CountRows().ValueOrDie();\n+  // cout << \"create source(\"<<filename<<\")\\n\";\n+  return {*arrow::compute::MakeExecNode(\n+              \"source\",    // registered type\n+              plan.get(),  // execution plan\n+              {},          // inputs\n+              arrow::compute::SourceNodeOptions(\n+                  std::make_shared<arrow::Schema>(*schema),  // options, )\n+                  batch_gen)),\n+          rows, in_reader->num_record_batches(), row_size * rows};\n+}\n+\n+static void TableJoinOverhead(benchmark::State& state, std::string left_table,\n+                              std::vector<std::string> right_tables,\n+                              std::string factory_name, ExecNodeOptions& options) {\n+  const std::string data_directory = \"./benchmark_data/\";\n+  DoSetup();\n+  ExecContext ctx(default_memory_pool(), arrow::internal::GetCpuThreadPool());\n+  // std::cout << \"beginning test for \" << left_table << \" and \" << right_tables[0] << \" \"\n+  // << factory_name << std::endl; std::cout << \"starting with \" <<\n+  // ctx.memory_pool()->bytes_allocated() << std::endl;\n+  int64_t rows;\n+  int64_t bytes;\n+  for (auto _ : state) {\n+    state.PauseTiming();\n+\n+    ASSERT_OK_AND_ASSIGN(std::shared_ptr<arrow::compute::ExecPlan> plan,\n+                         ExecPlan::Make(&ctx));\n+    std::shared_ptr<arrow::fs::FileSystem> fs =\n+        std::make_shared<arrow::fs::LocalFileSystem>();\n+    arrow::compute::ExecNode* left_table_source;\n+    int64_t left_table_rows;\n+    int left_table_batches;\n+    size_t left_table_bytes;\n+    tie(left_table_source, left_table_rows, left_table_batches, left_table_bytes) =\n+        make_arrow_ipc_reader_node(plan, fs, data_directory + left_table);\n+    std::vector<ExecNode*> inputs = {left_table_source};\n+    int right_hand_rows = 0;\n+    int64_t right_hand_bytes = 0;\n+    for (std::string right_table : right_tables) {\n+      arrow::compute::ExecNode* right_table_source;\n+      int64_t right_table_rows;\n+      int right_table_batches;\n+      size_t right_table_bytes;\n+      tie(right_table_source, right_table_rows, right_table_batches, right_table_bytes) =\n+          make_arrow_ipc_reader_node(plan, fs, data_directory + right_table);\n+      inputs.push_back(right_table_source);\n+      right_hand_rows += right_table_rows;\n+      right_hand_bytes += right_table_bytes;\n+    }\n+    rows = left_table_rows + right_hand_rows;\n+    bytes = left_table_bytes + right_hand_bytes;\n+    ASSERT_OK_AND_ASSIGN(arrow::compute::ExecNode * asof_join_node,\n+                         MakeExecNode(factory_name, plan.get(), inputs, options));\n+\n+    AsyncGenerator<util::optional<ExecBatch>> sink_gen;\n+    MakeExecNode(\"sink\", plan.get(), {asof_join_node}, SinkNodeOptions{&sink_gen});\n+    state.ResumeTiming();\n+    // std::cout << \"starting and collecting with \" <<\n+    // ctx.memory_pool()->bytes_allocated() << std::endl;\n+    ASSERT_FINISHES_OK(StartAndCollect(plan.get(), sink_gen));\n+    // std::cout << \"finishing with \" << ctx.memory_pool()->bytes_allocated() <<\n+    // std::endl;\n+  }\n+  // std::cout << \"reporting with \" << ctx.memory_pool()->bytes_allocated() << std::endl;\n+  state.counters[\"total_rows_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * rows), benchmark::Counter::kIsRate);\n+\n+  state.counters[\"total_bytes_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * bytes), benchmark::Counter::kIsRate);\n+}\n+\n+static void AsOfJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  int64_t tolerance = 0;\n+  AsofJoinNodeOptions options = AsofJoinNodeOptions(time_col, key_col, tolerance);\n+  TableJoinOverhead(state, left_table, right_tables, \"asofjoin\", options);\n+}\n+\n+static void HashJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  HashJoinNodeOptions options =\n+      HashJoinNodeOptions({time_col, key_col}, {time_col, key_col});\n+  TableJoinOverhead(state, left_table, right_tables, \"hashjoin\", options);\n+}\n+\n+// this generates the set of right hand tables to test on.\n+void SetArgs(benchmark::internal::Benchmark* bench) { bench->UseRealTime(); }\n+\n+BENCHMARK_CAPTURE(AsOfJoinOverhead,\n\nReview Comment:\n   Yes, I agree ",
                    "created": "2022-07-06T15:52:19.497+0000",
                    "updated": "2022-07-06T15:52:19.497+0000",
                    "started": "2022-07-06T15:52:19.497+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788314",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788316",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r915004294\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> _reader;\n+  int _next;\n+\n+ public:\n+  virtual ~RecordBatchFileReaderWrapper() {}\n+  explicit RecordBatchFileReaderWrapper(\n+      std::shared_ptr<arrow::ipc::RecordBatchFileReader> reader)\n+      : _reader(reader), _next(0) {}\n+\n+  virtual arrow::Status ReadNext(std::shared_ptr<arrow::RecordBatch>* batch) {\n+    // cout << \"ReadNext _next=\" << _next << \"\\n\";\n+    if (_next < _reader->num_record_batches()) {\n+      ARROW_ASSIGN_OR_RAISE(*batch, _reader->ReadRecordBatch(_next++));\n+      // cout << \"\\t --> \" << (*batch)->num_rows() << \"\\n\";\n+    } else {\n+      batch->reset();\n+      // cout << \"\\t --> EOF\\n\";\n+    }\n+\n+    return arrow::Status::OK();\n+  }\n+\n+  virtual std::shared_ptr<arrow::Schema> schema() const { return _reader->schema(); }\n+};\n+\n+static std::tuple<arrow::compute::ExecNode*, int64_t, int, size_t>\n+make_arrow_ipc_reader_node(std::shared_ptr<arrow::compute::ExecPlan>& plan,\n+                           std::shared_ptr<arrow::fs::FileSystem>& fs,\n+                           const std::string& filename) {\n+  // TODO: error checking\n+  std::shared_ptr<arrow::io::RandomAccessFile> input = *fs->OpenInputFile(filename);\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> in_reader =\n+      *arrow::ipc::RecordBatchFileReader::Open(input);\n+  std::shared_ptr<RecordBatchFileReaderWrapper> reader(\n+      new RecordBatchFileReaderWrapper(in_reader));\n+\n+  auto schema = reader->schema();\n+  // we assume there is a time field represented in uint64, a key field of int32, and the\n+  // remaining fields are float64.\n+  size_t row_size =\n+      sizeof(_Float64) * (schema->num_fields() - 2) + sizeof(int64_t) + sizeof(int32_t);\n+  auto batch_gen = *arrow::compute::MakeReaderGenerator(\n+      std::move(reader), arrow::internal::GetCpuThreadPool());\n+  int64_t rows = in_reader->CountRows().ValueOrDie();\n+  // cout << \"create source(\"<<filename<<\")\\n\";\n+  return {*arrow::compute::MakeExecNode(\n+              \"source\",    // registered type\n+              plan.get(),  // execution plan\n+              {},          // inputs\n+              arrow::compute::SourceNodeOptions(\n+                  std::make_shared<arrow::Schema>(*schema),  // options, )\n+                  batch_gen)),\n+          rows, in_reader->num_record_batches(), row_size * rows};\n+}\n+\n+static void TableJoinOverhead(benchmark::State& state, std::string left_table,\n+                              std::vector<std::string> right_tables,\n+                              std::string factory_name, ExecNodeOptions& options) {\n+  const std::string data_directory = \"./benchmark_data/\";\n+  DoSetup();\n+  ExecContext ctx(default_memory_pool(), arrow::internal::GetCpuThreadPool());\n+  // std::cout << \"beginning test for \" << left_table << \" and \" << right_tables[0] << \" \"\n+  // << factory_name << std::endl; std::cout << \"starting with \" <<\n+  // ctx.memory_pool()->bytes_allocated() << std::endl;\n+  int64_t rows;\n+  int64_t bytes;\n+  for (auto _ : state) {\n+    state.PauseTiming();\n+\n+    ASSERT_OK_AND_ASSIGN(std::shared_ptr<arrow::compute::ExecPlan> plan,\n+                         ExecPlan::Make(&ctx));\n+    std::shared_ptr<arrow::fs::FileSystem> fs =\n+        std::make_shared<arrow::fs::LocalFileSystem>();\n+    arrow::compute::ExecNode* left_table_source;\n+    int64_t left_table_rows;\n+    int left_table_batches;\n+    size_t left_table_bytes;\n+    tie(left_table_source, left_table_rows, left_table_batches, left_table_bytes) =\n+        make_arrow_ipc_reader_node(plan, fs, data_directory + left_table);\n+    std::vector<ExecNode*> inputs = {left_table_source};\n+    int right_hand_rows = 0;\n+    int64_t right_hand_bytes = 0;\n+    for (std::string right_table : right_tables) {\n+      arrow::compute::ExecNode* right_table_source;\n+      int64_t right_table_rows;\n+      int right_table_batches;\n+      size_t right_table_bytes;\n+      tie(right_table_source, right_table_rows, right_table_batches, right_table_bytes) =\n+          make_arrow_ipc_reader_node(plan, fs, data_directory + right_table);\n+      inputs.push_back(right_table_source);\n+      right_hand_rows += right_table_rows;\n+      right_hand_bytes += right_table_bytes;\n+    }\n+    rows = left_table_rows + right_hand_rows;\n+    bytes = left_table_bytes + right_hand_bytes;\n+    ASSERT_OK_AND_ASSIGN(arrow::compute::ExecNode * asof_join_node,\n+                         MakeExecNode(factory_name, plan.get(), inputs, options));\n+\n+    AsyncGenerator<util::optional<ExecBatch>> sink_gen;\n+    MakeExecNode(\"sink\", plan.get(), {asof_join_node}, SinkNodeOptions{&sink_gen});\n+    state.ResumeTiming();\n+    // std::cout << \"starting and collecting with \" <<\n+    // ctx.memory_pool()->bytes_allocated() << std::endl;\n+    ASSERT_FINISHES_OK(StartAndCollect(plan.get(), sink_gen));\n+    // std::cout << \"finishing with \" << ctx.memory_pool()->bytes_allocated() <<\n+    // std::endl;\n+  }\n+  // std::cout << \"reporting with \" << ctx.memory_pool()->bytes_allocated() << std::endl;\n+  state.counters[\"total_rows_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * rows), benchmark::Counter::kIsRate);\n+\n+  state.counters[\"total_bytes_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * bytes), benchmark::Counter::kIsRate);\n+}\n+\n+static void AsOfJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  int64_t tolerance = 0;\n+  AsofJoinNodeOptions options = AsofJoinNodeOptions(time_col, key_col, tolerance);\n+  TableJoinOverhead(state, left_table, right_tables, \"asofjoin\", options);\n+}\n+\n+static void HashJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  HashJoinNodeOptions options =\n+      HashJoinNodeOptions({time_col, key_col}, {time_col, key_col});\n+  TableJoinOverhead(state, left_table, right_tables, \"hashjoin\", options);\n+}\n+\n+// this generates the set of right hand tables to test on.\n+void SetArgs(benchmark::internal::Benchmark* bench) { bench->UseRealTime(); }\n+\n+BENCHMARK_CAPTURE(AsOfJoinOverhead,\n\nReview Comment:\n   Yes, I agree ",
                    "created": "2022-07-06T15:52:54.541+0000",
                    "updated": "2022-07-06T15:52:54.541+0000",
                    "started": "2022-07-06T15:52:54.541+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788316",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788356",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "iChauster commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r915004294\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n+\n+static void DoTeardown() { system(\"rm -rf benchmark_data/\"); }\n+\n+static std::vector<std::string> generateRightHandTables(std::string freq, int width_index,\n+                                                        int num_tables,\n+                                                        int num_ids_index) {\n+  auto const generate_file_name = [](std::string freq, std::string is_wide,\n+                                     std::string num_ids, std::string num) {\n+    return freq + \"_\" + is_wide + \"_\" + num_ids + num + \".feather\";\n+  };\n+\n+  std::string width_table[] = {\"1_cols\",  \"10_cols\", \"20_cols\",\n+                               \"40_cols\", \"80_cols\", \"100_cols\"};   // 0 - 5\n+  std::string num_ids_table[] = {\"100_ids\", \"2000_ids\", \"5k_ids\"};  // 0 - 2\n+\n+  std::string wide_string = width_table[width_index];\n+  std::string ids = num_ids_table[num_ids_index];\n+\n+  std::vector<std::string> right_hand_tables;\n+  for (int j = 1; j <= num_tables; j++) {\n+    right_hand_tables.push_back(\n+        generate_file_name(freq, wide_string, ids, std::to_string(j)));\n+  }\n+  return right_hand_tables;\n+}\n+\n+// Wrapper to enable the use of RecordBatchFileReaders as RecordBatchReaders\n+class RecordBatchFileReaderWrapper : public arrow::ipc::RecordBatchReader {\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> _reader;\n+  int _next;\n+\n+ public:\n+  virtual ~RecordBatchFileReaderWrapper() {}\n+  explicit RecordBatchFileReaderWrapper(\n+      std::shared_ptr<arrow::ipc::RecordBatchFileReader> reader)\n+      : _reader(reader), _next(0) {}\n+\n+  virtual arrow::Status ReadNext(std::shared_ptr<arrow::RecordBatch>* batch) {\n+    // cout << \"ReadNext _next=\" << _next << \"\\n\";\n+    if (_next < _reader->num_record_batches()) {\n+      ARROW_ASSIGN_OR_RAISE(*batch, _reader->ReadRecordBatch(_next++));\n+      // cout << \"\\t --> \" << (*batch)->num_rows() << \"\\n\";\n+    } else {\n+      batch->reset();\n+      // cout << \"\\t --> EOF\\n\";\n+    }\n+\n+    return arrow::Status::OK();\n+  }\n+\n+  virtual std::shared_ptr<arrow::Schema> schema() const { return _reader->schema(); }\n+};\n+\n+static std::tuple<arrow::compute::ExecNode*, int64_t, int, size_t>\n+make_arrow_ipc_reader_node(std::shared_ptr<arrow::compute::ExecPlan>& plan,\n+                           std::shared_ptr<arrow::fs::FileSystem>& fs,\n+                           const std::string& filename) {\n+  // TODO: error checking\n+  std::shared_ptr<arrow::io::RandomAccessFile> input = *fs->OpenInputFile(filename);\n+  std::shared_ptr<arrow::ipc::RecordBatchFileReader> in_reader =\n+      *arrow::ipc::RecordBatchFileReader::Open(input);\n+  std::shared_ptr<RecordBatchFileReaderWrapper> reader(\n+      new RecordBatchFileReaderWrapper(in_reader));\n+\n+  auto schema = reader->schema();\n+  // we assume there is a time field represented in uint64, a key field of int32, and the\n+  // remaining fields are float64.\n+  size_t row_size =\n+      sizeof(_Float64) * (schema->num_fields() - 2) + sizeof(int64_t) + sizeof(int32_t);\n+  auto batch_gen = *arrow::compute::MakeReaderGenerator(\n+      std::move(reader), arrow::internal::GetCpuThreadPool());\n+  int64_t rows = in_reader->CountRows().ValueOrDie();\n+  // cout << \"create source(\"<<filename<<\")\\n\";\n+  return {*arrow::compute::MakeExecNode(\n+              \"source\",    // registered type\n+              plan.get(),  // execution plan\n+              {},          // inputs\n+              arrow::compute::SourceNodeOptions(\n+                  std::make_shared<arrow::Schema>(*schema),  // options, )\n+                  batch_gen)),\n+          rows, in_reader->num_record_batches(), row_size * rows};\n+}\n+\n+static void TableJoinOverhead(benchmark::State& state, std::string left_table,\n+                              std::vector<std::string> right_tables,\n+                              std::string factory_name, ExecNodeOptions& options) {\n+  const std::string data_directory = \"./benchmark_data/\";\n+  DoSetup();\n+  ExecContext ctx(default_memory_pool(), arrow::internal::GetCpuThreadPool());\n+  // std::cout << \"beginning test for \" << left_table << \" and \" << right_tables[0] << \" \"\n+  // << factory_name << std::endl; std::cout << \"starting with \" <<\n+  // ctx.memory_pool()->bytes_allocated() << std::endl;\n+  int64_t rows;\n+  int64_t bytes;\n+  for (auto _ : state) {\n+    state.PauseTiming();\n+\n+    ASSERT_OK_AND_ASSIGN(std::shared_ptr<arrow::compute::ExecPlan> plan,\n+                         ExecPlan::Make(&ctx));\n+    std::shared_ptr<arrow::fs::FileSystem> fs =\n+        std::make_shared<arrow::fs::LocalFileSystem>();\n+    arrow::compute::ExecNode* left_table_source;\n+    int64_t left_table_rows;\n+    int left_table_batches;\n+    size_t left_table_bytes;\n+    tie(left_table_source, left_table_rows, left_table_batches, left_table_bytes) =\n+        make_arrow_ipc_reader_node(plan, fs, data_directory + left_table);\n+    std::vector<ExecNode*> inputs = {left_table_source};\n+    int right_hand_rows = 0;\n+    int64_t right_hand_bytes = 0;\n+    for (std::string right_table : right_tables) {\n+      arrow::compute::ExecNode* right_table_source;\n+      int64_t right_table_rows;\n+      int right_table_batches;\n+      size_t right_table_bytes;\n+      tie(right_table_source, right_table_rows, right_table_batches, right_table_bytes) =\n+          make_arrow_ipc_reader_node(plan, fs, data_directory + right_table);\n+      inputs.push_back(right_table_source);\n+      right_hand_rows += right_table_rows;\n+      right_hand_bytes += right_table_bytes;\n+    }\n+    rows = left_table_rows + right_hand_rows;\n+    bytes = left_table_bytes + right_hand_bytes;\n+    ASSERT_OK_AND_ASSIGN(arrow::compute::ExecNode * asof_join_node,\n+                         MakeExecNode(factory_name, plan.get(), inputs, options));\n+\n+    AsyncGenerator<util::optional<ExecBatch>> sink_gen;\n+    MakeExecNode(\"sink\", plan.get(), {asof_join_node}, SinkNodeOptions{&sink_gen});\n+    state.ResumeTiming();\n+    // std::cout << \"starting and collecting with \" <<\n+    // ctx.memory_pool()->bytes_allocated() << std::endl;\n+    ASSERT_FINISHES_OK(StartAndCollect(plan.get(), sink_gen));\n+    // std::cout << \"finishing with \" << ctx.memory_pool()->bytes_allocated() <<\n+    // std::endl;\n+  }\n+  // std::cout << \"reporting with \" << ctx.memory_pool()->bytes_allocated() << std::endl;\n+  state.counters[\"total_rows_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * rows), benchmark::Counter::kIsRate);\n+\n+  state.counters[\"total_bytes_per_second\"] = benchmark::Counter(\n+      static_cast<double>(state.iterations() * bytes), benchmark::Counter::kIsRate);\n+}\n+\n+static void AsOfJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  int64_t tolerance = 0;\n+  AsofJoinNodeOptions options = AsofJoinNodeOptions(time_col, key_col, tolerance);\n+  TableJoinOverhead(state, left_table, right_tables, \"asofjoin\", options);\n+}\n+\n+static void HashJoinOverhead(benchmark::State& state, std::string left_table,\n+                             std::vector<std::string> right_tables) {\n+  HashJoinNodeOptions options =\n+      HashJoinNodeOptions({time_col, key_col}, {time_col, key_col});\n+  TableJoinOverhead(state, left_table, right_tables, \"hashjoin\", options);\n+}\n+\n+// this generates the set of right hand tables to test on.\n+void SetArgs(benchmark::internal::Benchmark* bench) { bench->UseRealTime(); }\n+\n+BENCHMARK_CAPTURE(AsOfJoinOverhead,\n\nReview Comment:\n   Yes, I agree ",
                    "created": "2022-07-06T17:43:19.957+0000",
                    "updated": "2022-07-06T17:43:19.957+0000",
                    "started": "2022-07-06T17:43:19.956+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788356",
                    "issueId": "13462985"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/worklog/788424",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "westonpace commented on code in PR #13426:\nURL: https://github.com/apache/arrow/pull/13426#discussion_r915308962\n\n\n##########\ncpp/src/arrow/compute/exec/asof_join_benchmark.cc:\n##########\n@@ -0,0 +1,1023 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <condition_variable>\n+#include <mutex>\n+#include <string>\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#include \"arrow/compute/cast.h\"\n+#include \"arrow/compute/exec.h\"\n+#include \"arrow/compute/exec/expression.h\"\n+#include \"arrow/compute/exec/options.h\"\n+#include \"arrow/compute/exec/task_util.h\"\n+#include \"arrow/compute/exec/test_util.h\"\n+#include \"arrow/dataset/partition.h\"\n+#include \"arrow/filesystem/api.h\"\n+#include \"arrow/ipc/api.h\"\n+#include \"arrow/testing/future_util.h\"\n+#include \"arrow/testing/generator.h\"\n+#include \"arrow/testing/gtest_util.h\"\n+#include \"arrow/type.h\"\n+\n+namespace arrow {\n+namespace compute {\n+\n+static const char* time_col = \"time\";\n+static const char* key_col = \"id\";\n+static bool createdBenchmarkFiles = false;\n+\n+// requires export PYTHONPATH=/path/to/bamboo-streaming\n+// calls generate_benchmark_files to create tables (feather files) varying in frequency,\n+// width, key density for benchmarks. places generated files in benchmark/data. This\n+// operation runs once at the beginning of benchmarking.\n+static void DoSetup() {\n+  if (!createdBenchmarkFiles) {\n+    system(\n+        \"mkdir benchmark_data/ && python3 \"\n+        \"~/summer/bamboo-streaming/bamboo/generate_benchmark_files.py\");\n+    createdBenchmarkFiles = true;\n+  }\n+}\n\nReview Comment:\n   Hmm...we don't have much precedent yet but we do have a few python files scattered amongst the C++ sources.  `src/arrow/compute/exec/hash_join_graphs.py` is intended for making graphs from the hash_join benchmarks.  However, if you wanted to create a test data directory or scripts directory somewhere in the cpp tree that would probably be ok too.  Maybe @pitrou has an opinion here?\r\n   \r\n   Rather than using `system()` which is Linux-specific it would be nicer to use something like `boost::process`.  You can see an example of this in `s3_test_util.cc` where we launch minio.  We should gracefully handle the following:\r\n   \r\n    * Python not installed\r\n    * Python installed but needed dependencies are not\r\n    \r\n   We should probably also create a benchmarking.md document or something like that in the `cpp/src/arrow/compute/exec` that explains the tool, what is needed to run it, and what purpose it serves.\n\n\n\n",
                    "created": "2022-07-06T22:39:05.725+0000",
                    "updated": "2022-07-06T22:39:05.725+0000",
                    "started": "2022-07-06T22:39:05.725+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "788424",
                    "issueId": "13462985"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 49200,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@73b26fcb[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7e2bd299[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@40094860[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@6096f5e2[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7184da0f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@7c102ad0[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@76d0377a[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@21bee5a7[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@763d173d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@b06e580[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7c9a787d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@2adf3994[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 49200,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Aug 10 23:21:31 UTC 2022",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2022-07-28T21:35:53.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-16894/watchers",
            "watchCount": 3,
            "isWatching": false
        },
        "created": "2022-06-23T13:16:24.000+0000",
        "updated": "2022-08-10T23:21:31.000+0000",
        "timeoriginalestimate": null,
        "description": null,
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "13h 40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 49200
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Benchmarks] Create Asof Join Benchmark for Acero",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/comment/17558105",
                    "id": "17558105",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=ichauster",
                        "name": "ichauster",
                        "key": "JIRAUSER290345",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
                        },
                        "displayName": "Ivan Chau",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "Hi [~westonpace],\r\n\r\nLeft some questions for you on the [PR|https://github.com/apache/arrow/pull/13426], would love to hear your advice!\r\n\r\nThanks for the help!",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=ichauster",
                        "name": "ichauster",
                        "key": "JIRAUSER290345",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34055",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34055",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34055",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34055"
                        },
                        "displayName": "Ivan Chau",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2022-06-23T14:09:08.502+0000",
                    "updated": "2022-06-23T14:10:01.354+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/comment/17572665",
                    "id": "17572665",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "Issue resolved by pull request 13426\n[https://github.com/apache/arrow/pull/13426]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=westonpace",
                        "name": "westonpace",
                        "key": "westonpace",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=34045",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=34045",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=34045",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=34045"
                        },
                        "displayName": "Weston Pace",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-07-28T21:35:53.866+0000",
                    "updated": "2022-07-28T21:35:53.866+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13462985/comment/17578180",
                    "id": "17578180",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=octalene",
                        "name": "octalene",
                        "key": "octalene",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=octalene&avatarId=51083",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=octalene&avatarId=51083",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=octalene&avatarId=51083",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=octalene&avatarId=51083"
                        },
                        "displayName": "Aldrin Montana",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "body": "[~ichauster], I tried to run this benchmark but I see this error:\r\n\r\n{code:bash}\r\n./debug/arrow-compute-asof-join-benchmark\r\n/Users/octalene/builds/arrow-dev/dev/gbenchmark_ep-prefix/src/gbenchmark_ep/src/benchmark_register.cc:314: Args: Check `ArgsCnt() == -1 || ArgsCnt() == static_cast<int>(args.size())' failed.\r\nfish: Job 1, './debug/arrow-compute-asof-join\u2026' terminated by signal SIGABRT (Abort)\r\n{code}\r\n\r\nAfter I make the following change:\r\n{code:c++}\r\n--- a/cpp/src/arrow/compute/exec/asof_join_benchmark.cc\r\n+++ b/cpp/src/arrow/compute/exec/asof_join_benchmark.cc\r\n@@ -157,7 +157,7 @@ void SetArgs(benchmark::internal::Benchmark* bench) {\r\n   }\r\n }\r\n\r\n-BENCHMARK(AsOfJoinOverhead)->Apply(SetArgs);\r\n+BENCHMARK(AsOfJoinOverhead);\r\n\r\n }  // namespace compute\r\n }  // namespace arrow\r\n{code}\r\n\r\nI see this error:\r\n{code:bash}\r\n***WARNING*** Library was built as DEBUG. Timings may be affected.\r\nAssertion failed: (range_.size() > pos), function range, file benchmark.h, line 664.\r\nfish: Job 1, './debug/arrow-compute-asof-join\u2026' terminated by signal SIGABRT (Abort)\r\n{code}\r\n\r\nI didn't read through the PR, but I just wanted to drop this note here in case it's not just a me thing. I'm on an M1 mac mini, haven't tried on anything else. And this should be on master branch. I suspect there's an extra thing to do to run the benchmark (I assume there's a reason the *->Apply* breaks for me), I just don't know what it is.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=octalene",
                        "name": "octalene",
                        "key": "octalene",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=octalene&avatarId=51083",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=octalene&avatarId=51083",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=octalene&avatarId=51083",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=octalene&avatarId=51083"
                        },
                        "displayName": "Aldrin Montana",
                        "active": true,
                        "timeZone": "America/Los_Angeles"
                    },
                    "created": "2022-08-10T23:21:31.528+0000",
                    "updated": "2022-08-10T23:21:31.528+0000"
                }
            ],
            "maxResults": 3,
            "total": 3,
            "startAt": 0
        },
        "customfield_12311820": "0|z15feo:",
        "customfield_12314139": null
    }
}