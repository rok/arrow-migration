{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13295048",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048",
    "key": "ARROW-8276",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12346687",
                "id": "12346687",
                "description": "",
                "name": "0.17.0",
                "archived": false,
                "released": true,
                "releaseDate": "2020-04-20"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "dataset",
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
            "name": "bkietz",
            "key": "bkietz",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
            },
            "displayName": "Ben Kietzman",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328935",
                "id": "12328935",
                "name": "C++"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
            "name": "jorisvandenbossche",
            "key": "jorisvandenbossche",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Joris Van den Bossche",
            "active": true,
            "timeZone": "Europe/Brussels"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
            "name": "jorisvandenbossche",
            "key": "jorisvandenbossche",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
            },
            "displayName": "Joris Van den Bossche",
            "active": true,
            "timeZone": "Europe/Brussels"
        },
        "aggregateprogress": {
            "progress": 10800,
            "total": 10800,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 10800,
            "total": 10800,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8276/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 19,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/412491",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765\n \n \n   This way batches yielded by Fragment.Scan are projected and filtered.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T18:15:53.634+0000",
                    "updated": "2020-03-30T18:15:53.634+0000",
                    "started": "2020-03-30T18:15:53.634+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412491",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/412493",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "github-actions[bot] commented on issue #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#issuecomment-606159554\n \n \n   https://issues.apache.org/jira/browse/ARROW-8276\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T18:16:36.344+0000",
                    "updated": "2020-03-30T18:16:36.344+0000",
                    "started": "2020-03-30T18:16:36.344+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412493",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/412523",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on issue #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#issuecomment-606203076\n \n \n   Thanks for the quick PR! \r\n   \r\n   I didn't look in detail (can only do that tomorrow), but for the cython side of it, it would also be an option to update the Scanner constructor allow to pass a Fragment there in addition to a Dataset (which would be similar to the change you did in C++ to create a Scanner from a fragment instead?) \r\n   And then the Fragment.scan/to_table methods could just create this Scanner and use its scan/to_table method (similar to how Dataset.scan/to_table are implemented)\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-30T19:37:32.455+0000",
                    "updated": "2020-03-30T19:37:32.455+0000",
                    "started": "2020-03-30T19:37:32.454+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412523",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/412767",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "fsaintjacques commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r400596374\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/scanner.h\n ##########\n @@ -188,6 +185,7 @@ class ARROW_DS_EXPORT Scanner {\n \n  protected:\n   std::shared_ptr<Dataset> dataset_;\n+  std::shared_ptr<Fragment> fragment_;\n \n Review comment:\n   Can you add a comment explaining that this is a temporary solution until ARROW-8065 is resolved so it doesn't confuse reader.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T01:52:50.647+0000",
                    "updated": "2020-03-31T01:52:50.647+0000",
                    "started": "2020-03-31T01:52:50.647+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412767",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/412916",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on issue #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#issuecomment-606456743\n \n \n   I fixed the cython compilation issues, and also added some more python tests. \r\n   \r\n   Doing this I ran into the following issue: the original fragment now converts to a table correctly, but if we manually re-construct a fragment, there are still problems with the partition column / expression. So by default, the partition column is not included. But when I specify the dataset's full schema (which included the partition column), then calling `to_table()` has the partition column but with all nulls (so not using the value from the partition expression that is passed to the fragment's construction).\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T07:41:42.233+0000",
                    "updated": "2020-03-31T07:41:42.233+0000",
                    "started": "2020-03-31T07:41:42.232+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412916",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/412917",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r400704748\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -622,28 +622,116 @@ def test_make_fragment(multisourcefs):\n \n \n @pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+@pytest.mark.parquet\n+def test_parquet_fragments(tempdir):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'a': ['a'] * 4 + ['b'] * 4, 'b': range(8), 'c': [1] * 8}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"a\"], chunk_size=2)\n \n-    import pyarrow.dataset as ds\n+    # open dataset\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 4\n+    assert result.column('a').chunk(0).to_pylist() == ['a', 'a']\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['a', 'b']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('b') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+    # manually re-construct a fragment\n+    fragment = list(dataset.get_fragments())[0]\n+    parquet_format = fragment.format\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        partition_expression=fragment.partition_expression)\n+    # TODO this fails, because either the new fragment does not include the\n+    # partition column, or if the schema above is passed, it is filled with\n+    # nulls instead of the value from the partition expression\n+    # assert new_fragment.to_table().equals(fragment.to_table())\n \n Review comment:\n   So this assert is failing due to the explained issue with the partition column\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T07:42:09.116+0000",
                    "updated": "2020-03-31T07:42:09.116+0000",
                    "started": "2020-03-31T07:42:09.115+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "412917",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/413155",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r400911516\n \n \n\n ##########\n File path: cpp/src/arrow/dataset/scanner.h\n ##########\n @@ -188,6 +185,7 @@ class ARROW_DS_EXPORT Scanner {\n \n  protected:\n   std::shared_ptr<Dataset> dataset_;\n+  std::shared_ptr<Fragment> fragment_;\n \n Review comment:\n   done\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T13:26:27.181+0000",
                    "updated": "2020-03-31T13:26:27.181+0000",
                    "started": "2020-03-31T13:26:27.181+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "413155",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/413211",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r400968668\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -622,28 +622,116 @@ def test_make_fragment(multisourcefs):\n \n \n @pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+@pytest.mark.parquet\n+def test_parquet_fragments(tempdir):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'a': ['a'] * 4 + ['b'] * 4, 'b': range(8), 'c': [1] * 8}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"a\"], chunk_size=2)\n \n-    import pyarrow.dataset as ds\n+    # open dataset\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 4\n+    assert result.column('a').chunk(0).to_pylist() == ['a', 'a']\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['a', 'b']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('b') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+    # manually re-construct a fragment\n+    fragment = list(dataset.get_fragments())[0]\n+    parquet_format = fragment.format\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        partition_expression=fragment.partition_expression)\n+    # TODO this fails, because either the new fragment does not include the\n+    # partition column, or if the schema above is passed, it is filled with\n+    # nulls instead of the value from the partition expression\n+    # assert new_fragment.to_table().equals(fragment.to_table())\n \n Review comment:\n   @jorisvandenbossche thanks for the tests! In C++ it's possible to set values for materialized columns independent of the partition expression, but this isn't exposed in Python. I've rewritten `make_fragment()` to inject materialized columns derived from the partition expression and re-enabled this test\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T14:41:16.963+0000",
                    "updated": "2020-03-31T14:41:16.963+0000",
                    "started": "2020-03-31T14:41:16.963+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "413211",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/413222",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r400982217\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -622,28 +622,113 @@ def test_make_fragment(multisourcefs):\n \n \n @pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+@pytest.mark.parquet\n+def test_parquet_fragments(tempdir):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'a': ['a'] * 4 + ['b'] * 4, 'b': range(8), 'c': [1] * 8}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"a\"], chunk_size=2)\n \n-    import pyarrow.dataset as ds\n+    # open dataset\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 4\n+    assert result.column('a').chunk(0).to_pylist() == ['a', 'a']\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['a', 'b']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('b') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+    # manually re-construct a fragment\n+    fragment = list(dataset.get_fragments())[0]\n+    parquet_format = fragment.format\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem, schema=dataset.schema,\n+        partition_expression=fragment.partition_expression)\n+    assert new_fragment.to_table().equals(fragment.to_table())\n+    new_fragment.to_table()\n+\n+    # manually re-construct a fragment with filter / column projection\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        columns=['b'], filter=ds.field('b') < 2,\n+        partition_expression=fragment.partition_expression)\n+    result = new_fragment.to_table()\n+    assert result.column_names == ['b']\n+    assert len(result) == 2\n+\n+    # list and scan row group fragments\n+    fragment = list(dataset.get_fragments())[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    assert len(row_group_fragments) == 2\n+    result = row_group_fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+\n+    # scanning row group fragment follows column projection / filter predicate\n+    fragment = list(dataset.get_fragments(\n+        columns=['a', 'b'], filter=ds.field('b') < 1))[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    assert len(row_group_fragments) == 1\n+    result = row_group_fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 1\n+\n+    # manually re-construct row group fragments\n+    fragment = list(dataset.get_fragments())[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        partition_expression=fragment.partition_expression,\n+        row_groups=[0])\n+    result = new_fragment.to_table()\n+    # TODO needs to include partition column\n+    # assert result.equals(row_group_fragments[0].to_table())\n+    assert result.column_names == ['b', 'c']\n+    assert len(result) == 2\n \n Review comment:\n   ```suggestion\r\n       new_fragment = parquet_format.make_fragment(\r\n           fragment.path, fragment.filesystem, schema=dataset.schema,\r\n           partition_expression=fragment.partition_expression,\r\n           row_groups=[0])\r\n       result = new_fragment.to_table()\r\n       assert result.equals(row_group_fragments[0].to_table())\r\n   ```\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T14:58:55.043+0000",
                    "updated": "2020-03-31T14:58:55.043+0000",
                    "started": "2020-03-31T14:58:55.043+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "413222",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/413223",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r400983801\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -622,28 +622,113 @@ def test_make_fragment(multisourcefs):\n \n \n @pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+@pytest.mark.parquet\n+def test_parquet_fragments(tempdir):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'a': ['a'] * 4 + ['b'] * 4, 'b': range(8), 'c': [1] * 8}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"a\"], chunk_size=2)\n \n-    import pyarrow.dataset as ds\n+    # open dataset\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 4\n+    assert result.column('a').chunk(0).to_pylist() == ['a', 'a']\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['a', 'b']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('b') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+    # manually re-construct a fragment\n+    fragment = list(dataset.get_fragments())[0]\n+    parquet_format = fragment.format\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem, schema=dataset.schema,\n+        partition_expression=fragment.partition_expression)\n+    assert new_fragment.to_table().equals(fragment.to_table())\n+    new_fragment.to_table()\n+\n+    # manually re-construct a fragment with filter / column projection\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        columns=['b'], filter=ds.field('b') < 2,\n+        partition_expression=fragment.partition_expression)\n+    result = new_fragment.to_table()\n+    assert result.column_names == ['b']\n+    assert len(result) == 2\n+\n+    # list and scan row group fragments\n+    fragment = list(dataset.get_fragments())[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    assert len(row_group_fragments) == 2\n+    result = row_group_fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+\n+    # scanning row group fragment follows column projection / filter predicate\n+    fragment = list(dataset.get_fragments(\n+        columns=['a', 'b'], filter=ds.field('b') < 1))[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    assert len(row_group_fragments) == 1\n+    result = row_group_fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 1\n+\n+    # manually re-construct row group fragments\n+    fragment = list(dataset.get_fragments())[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        partition_expression=fragment.partition_expression,\n+        row_groups=[0])\n+    result = new_fragment.to_table()\n+    # TODO needs to include partition column\n+    # assert result.equals(row_group_fragments[0].to_table())\n+    assert result.column_names == ['b', 'c']\n+    assert len(result) == 2\n \n Review comment:\n   this updates the other case now the partition columns is correctly included\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T14:59:58.361+0000",
                    "updated": "2020-03-31T14:59:58.361+0000",
                    "started": "2020-03-31T14:59:58.361+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "413223",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/413225",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r400984762\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -622,28 +622,113 @@ def test_make_fragment(multisourcefs):\n \n \n @pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+@pytest.mark.parquet\n+def test_parquet_fragments(tempdir):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'a': ['a'] * 4 + ['b'] * 4, 'b': range(8), 'c': [1] * 8}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"a\"], chunk_size=2)\n \n-    import pyarrow.dataset as ds\n+    # open dataset\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 4\n+    assert result.column('a').chunk(0).to_pylist() == ['a', 'a']\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['a', 'b']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('b') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+    # manually re-construct a fragment\n+    fragment = list(dataset.get_fragments())[0]\n+    parquet_format = fragment.format\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem, schema=dataset.schema,\n+        partition_expression=fragment.partition_expression)\n+    assert new_fragment.to_table().equals(fragment.to_table())\n+    new_fragment.to_table()\n+\n+    # manually re-construct a fragment with filter / column projection\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        columns=['b'], filter=ds.field('b') < 2,\n+        partition_expression=fragment.partition_expression)\n+    result = new_fragment.to_table()\n+    assert result.column_names == ['b']\n+    assert len(result) == 2\n+\n+    # list and scan row group fragments\n+    fragment = list(dataset.get_fragments())[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    assert len(row_group_fragments) == 2\n+    result = row_group_fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+\n+    # scanning row group fragment follows column projection / filter predicate\n+    fragment = list(dataset.get_fragments(\n+        columns=['a', 'b'], filter=ds.field('b') < 1))[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    assert len(row_group_fragments) == 1\n+    result = row_group_fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 1\n+\n+    # manually re-construct row group fragments\n+    fragment = list(dataset.get_fragments())[0]\n+    row_group_fragments = list(fragment.get_row_group_fragments())\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        partition_expression=fragment.partition_expression,\n+        row_groups=[0])\n+    result = new_fragment.to_table()\n+    # TODO needs to include partition column\n+    # assert result.equals(row_group_fragments[0].to_table())\n+    assert result.column_names == ['b', 'c']\n+    assert len(result) == 2\n+\n+    # manually re-construct a row group fragment with filter/column projection\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem,  # schema=dataset.schema,\n+        columns=['b'], filter=ds.field('b') < 3,\n+        partition_expression=fragment.partition_expression,\n         row_groups={1})\n+    result = new_fragment.to_table()\n+    assert result.column_names == ['b']\n+    assert len(result) == 1\n \n Review comment:\n   ```suggestion\r\n       new_fragment = parquet_format.make_fragment(\r\n           fragment.path, fragment.filesystem, schema=dataset.schema,\r\n           columns=['a', 'b'], filter=ds.field('b') < 3,\r\n           partition_expression=fragment.partition_expression,\r\n           row_groups={1})\r\n       result = new_fragment.to_table()\r\n       assert result.column_names == ['a', 'b']\r\n       assert len(result) == 1\r\n   ```\r\n   \r\n   (to ensure we can also select the partition column here)\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-03-31T15:01:16.251+0000",
                    "updated": "2020-03-31T15:01:16.251+0000",
                    "started": "2020-03-31T15:01:16.251+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "413225",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/413934",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r401494558\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -622,28 +622,110 @@ def test_make_fragment(multisourcefs):\n \n \n @pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+@pytest.mark.parquet\n+def test_parquet_fragments(tempdir):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'a': ['a'] * 4 + ['b'] * 4, 'b': range(8), 'c': [1] * 8}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"a\"], chunk_size=2)\n \n-    import pyarrow.dataset as ds\n+    # open dataset\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 4\n+    assert result.column('a').chunk(0).to_pylist() == ['a', 'a']\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['a', 'b']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['a', 'b']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('b') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['b', 'c', 'a']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+    # manually re-construct a fragment\n+    fragment = list(dataset.get_fragments())[0]\n+    parquet_format = fragment.format\n+    new_fragment = parquet_format.make_fragment(\n+        fragment.path, fragment.filesystem, schema=dataset.schema,\n+        partition_expression=fragment.partition_expression)\n+    assert new_fragment.to_table().equals(fragment.to_table())\n+    new_fragment.to_table()\n \n Review comment:\n   ```suggestion\r\n       assert new_fragment.to_table(use_threads=False).equals(\r\n           fragment.to_table(use_threads=False))\r\n   ```\r\n   \r\n   (the failure is due to undeterministic row order ..)\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-01T09:55:26.362+0000",
                    "updated": "2020-04-01T09:55:26.362+0000",
                    "started": "2020-04-01T09:55:26.361+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "413934",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/414245",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on issue #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#issuecomment-607436816\n \n \n   Unfortunately, now I get a crash with my taxi example: \r\n   \r\n   ../src/arrow/result.cc:28: ValueOrDie called on an error: Type error: Cannot compare scalars of differing type: int64 vs int32\r\n   \r\n   So I suppose there needs to be added an implicit cast somewhere (the `Scanner.__init__` now does, but that path is not taken for fragments)\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-01T19:07:20.650+0000",
                    "updated": "2020-04-01T19:07:20.650+0000",
                    "started": "2020-04-01T19:07:20.650+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "414245",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/414518",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on issue #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#issuecomment-607684538\n \n \n   My taxi data example seems to work now!\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-02T07:57:40.142+0000",
                    "updated": "2020-04-02T07:57:40.142+0000",
                    "started": "2020-04-02T07:57:40.142+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "414518",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/414640",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r402254416\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -621,29 +621,174 @@ def test_make_fragment(multisourcefs):\n         assert row_group_fragment.row_groups == {0}\n \n \n-@pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+def _create_dataset_for_fragments(tempdir, chunk_size=None):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'f1': range(8), 'f2': [1] * 8, 'part': ['a'] * 4 + ['b'] * 4}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"part\"], chunk_size=chunk_size)\n \n-    import pyarrow.dataset as ds\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n+    return table, dataset\n+\n+\n+@pytest.mark.pandas\n+@pytest.mark.parquet\n+def test_fragments(tempdir):\n+    table, dataset = _create_dataset_for_fragments(tempdir)\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # file's schema does not include partition column\n+    phys_schema = f.schema.remove(f.schema.get_field_index('part'))\n+    assert f.format.inspect(f.path, f.filesystem) == phys_schema\n+    assert f.partition_expression.equals(ds.field('part') == 'a')\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert f.schema == result.schema\n+    assert result.column_names == ['f1', 'f2', 'part']\n+    assert len(result) == 4\n+    assert result.equals(table.slice(0, 4))\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['f1', 'part']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['f1', 'part']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('f1') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['f1', 'f2', 'part']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+\n+@pytest.mark.pandas\n+@pytest.mark.parquet\n+def test_fragments_reconstruct(tempdir):\n+    table, dataset = _create_dataset_for_fragments(tempdir)\n+\n+    def assert_yields_projected(fragment, row_slice, columns):\n+        actual = fragment.to_table()\n+        assert actual.column_names == columns\n+\n+        expected = table.slice(*row_slice).to_pandas()[[*columns]]\n+        if not actual.equals(pa.Table.from_pandas(expected)):\n+            print('-' * 90)\n+            print(expected)\n+            print(actual.to_pandas())\n \n Review comment:\n   some left-overt prints\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-02T11:54:23.906+0000",
                    "updated": "2020-04-02T11:54:23.906+0000",
                    "started": "2020-04-02T11:54:23.906+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "414640",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/414641",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "jorisvandenbossche commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r402252805\n \n \n\n ##########\n File path: python/pyarrow/_dataset.pyx\n ##########\n @@ -436,6 +474,14 @@ cdef class Fragment:\n         self.init(sp)\n         return self\n \n+    cdef inline shared_ptr[CFragment] unwrap(self):\n+        return self.wrapped\n+\n+    @property\n+    def schema(self):\n+        \"\"\"Return the schema of batches scanned from this Fragment.\"\"\"\n \n Review comment:\n   I am bit hesitant about adding a `schema` property, giving our discussion about \"physical\" schema vs \"reader\" schema, and it is not directly clear which of the two this would be (the docstring explains it, but just from the name)\r\n   \r\n   But let's deal with that in a possible follow-up\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-02T11:54:23.909+0000",
                    "updated": "2020-04-02T11:54:23.909+0000",
                    "started": "2020-04-02T11:54:23.909+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "414641",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/414707",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r402347016\n \n \n\n ##########\n File path: python/pyarrow/_dataset.pyx\n ##########\n @@ -436,6 +474,14 @@ cdef class Fragment:\n         self.init(sp)\n         return self\n \n+    cdef inline shared_ptr[CFragment] unwrap(self):\n+        return self.wrapped\n+\n+    @property\n+    def schema(self):\n+        \"\"\"Return the schema of batches scanned from this Fragment.\"\"\"\n \n Review comment:\n   Yes, this ambiguity will be addressed in ARROW-8065\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-02T14:15:24.672+0000",
                    "updated": "2020-04-02T14:15:24.672+0000",
                    "started": "2020-04-02T14:15:24.671+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "414707",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/414708",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765#discussion_r402347081\n \n \n\n ##########\n File path: python/pyarrow/tests/test_dataset.py\n ##########\n @@ -621,29 +621,174 @@ def test_make_fragment(multisourcefs):\n         assert row_group_fragment.row_groups == {0}\n \n \n-@pytest.mark.pandas\n-def test_parquet_row_group_fragments(tempdir):\n-    import pyarrow as pa\n+def _create_dataset_for_fragments(tempdir, chunk_size=None):\n     import pyarrow.parquet as pq\n \n-    table = pa.table({'a': ['a', 'a', 'b', 'b'], 'b': [1, 2, 3, 4]})\n-\n+    table = pa.table(\n+        {'f1': range(8), 'f2': [1] * 8, 'part': ['a'] * 4 + ['b'] * 4}\n+    )\n     # write_to_dataset currently requires pandas\n     pq.write_to_dataset(table, str(tempdir / \"test_parquet_dataset\"),\n-                        partition_cols=[\"a\"])\n+                        partition_cols=[\"part\"], chunk_size=chunk_size)\n \n-    import pyarrow.dataset as ds\n     dataset = ds.dataset(str(tempdir / \"test_parquet_dataset/\"),\n                          format=\"parquet\", partitioning=\"hive\")\n+    return table, dataset\n+\n+\n+@pytest.mark.pandas\n+@pytest.mark.parquet\n+def test_fragments(tempdir):\n+    table, dataset = _create_dataset_for_fragments(tempdir)\n \n+    # list fragments\n     fragments = list(dataset.get_fragments())\n+    assert len(fragments) == 2\n     f = fragments[0]\n-    parquet_format = f.format\n-    parquet_format.make_fragment(f.path, f.filesystem,\n-                                 partition_expression=f.partition_expression)\n-    parquet_format.make_fragment(\n-        f.path, f.filesystem, partition_expression=f.partition_expression,\n+\n+    # file's schema does not include partition column\n+    phys_schema = f.schema.remove(f.schema.get_field_index('part'))\n+    assert f.format.inspect(f.path, f.filesystem) == phys_schema\n+    assert f.partition_expression.equals(ds.field('part') == 'a')\n+\n+    # scanning fragment includes partition columns\n+    result = f.to_table()\n+    assert f.schema == result.schema\n+    assert result.column_names == ['f1', 'f2', 'part']\n+    assert len(result) == 4\n+    assert result.equals(table.slice(0, 4))\n+\n+    # scanning fragments follow column projection\n+    fragments = list(dataset.get_fragments(columns=['f1', 'part']))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['f1', 'part']\n+    assert len(result) == 4\n+\n+    # scanning fragments follow filter predicate\n+    fragments = list(dataset.get_fragments(filter=ds.field('f1') < 2))\n+    assert len(fragments) == 2\n+    result = fragments[0].to_table()\n+    assert result.column_names == ['f1', 'f2', 'part']\n+    assert len(result) == 2\n+    result = fragments[1].to_table()\n+    assert len(result) == 0\n+\n+\n+@pytest.mark.pandas\n+@pytest.mark.parquet\n+def test_fragments_reconstruct(tempdir):\n+    table, dataset = _create_dataset_for_fragments(tempdir)\n+\n+    def assert_yields_projected(fragment, row_slice, columns):\n+        actual = fragment.to_table()\n+        assert actual.column_names == columns\n+\n+        expected = table.slice(*row_slice).to_pandas()[[*columns]]\n+        if not actual.equals(pa.Table.from_pandas(expected)):\n+            print('-' * 90)\n+            print(expected)\n+            print(actual.to_pandas())\n \n Review comment:\n   will delete\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-02T14:15:30.372+0000",
                    "updated": "2020-04-02T14:15:30.372+0000",
                    "started": "2020-04-02T14:15:30.372+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "414708",
                    "issueId": "13295048"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/worklog/414773",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "bkietz commented on pull request #6765: ARROW-8276: [C++][Dataset] Use Scanner for Fragment.to_table\nURL: https://github.com/apache/arrow/pull/6765\n \n \n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2020-04-02T15:33:11.109+0000",
                    "updated": "2020-04-02T15:33:11.109+0000",
                    "started": "2020-04-02T15:33:11.109+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "414773",
                    "issueId": "13295048"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
            "id": "1",
            "description": "A problem which impairs or prevents the functions of the product.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
            "name": "Bug",
            "subtask": false,
            "avatarId": 21133
        },
        "timespent": 10800,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@2bd3bb42[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4384db10[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@660fa290[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@3b6b91a[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6d6096e1[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@3dd38ad0[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2653a4d8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@109bb761[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@79a5ec0d[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@58016ce3[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@63cf765f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@2ea2f5f8[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 10800,
        "customfield_12312520": null,
        "customfield_12312521": "Wed Apr 15 19:36:33 UTC 2020",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2020-04-02T15:33:12.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-8276/watchers",
            "watchCount": 2,
            "isWatching": false
        },
        "created": "2020-03-30T16:35:55.000+0000",
        "updated": "2020-04-15T19:36:33.000+0000",
        "timeoriginalestimate": null,
        "description": "Follow-up on ARROW-8061, the {{to_table}} method doesn't work for fragments created from a partitioned dataset.\r\n\r\n(will add a reproducer later)\r\n\r\ncc [~bkietz]",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "3h",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 10800
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[C++][Dataset] Scanning a Fragment does not take into account the partition columns",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/comment/17071140",
                    "id": "17071140",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "Reproducer in python:\r\n\r\n{code}\r\nimport pyarrow as pa\r\nimport pyarrow.parquet as pq\r\nimport pyarrow.dataset as ds\r\n\r\nimport pathlib\r\n\r\n\r\n# create small partitioned dataset\r\ntable = pa.table({'col1': [1, 2, 3]})\r\n\r\nbasedir = pathlib.Path(\".\")\r\ndataset_dir = basedir / \"test_partitioned_fragment\"\r\ndataset_dir.mkdir(exist_ok=True)\r\n\r\n(dataset_dir / \"A=0\").mkdir(exist_ok=True)\r\n(dataset_dir / \"A=1\").mkdir(exist_ok=True)\r\npq.write_table(table, dataset_dir / \"A=0\" / \"data.parquet\")\r\npq.write_table(table, dataset_dir / \"A=1\" / \"data.parquet\")\r\n\r\n# read it with the datasets API\r\ndataset = ds.dataset(str(dataset_dir), format=\"parquet\", partitioning=\"hive\")\r\n\r\ndataset.schema\r\ndataset.to_table()\r\n\r\n# reading one fragment fails\r\nfragments = list(dataset.get_fragments())\r\nfragments[0].to_table()\r\n{code}\r\n\r\ngives:\r\n\r\n{code}\r\nArrowInvalid: Schema at index 0 was different: \r\ncol1: int64\r\nA: int32\r\nvs\r\ncol1: int64\r\n{code}",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2020-03-30T16:51:52.536+0000",
                    "updated": "2020-03-30T16:52:28.224+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/comment/17073828",
                    "id": "17073828",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 6765\n[https://github.com/apache/arrow/pull/6765]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=bkietz",
                        "name": "bkietz",
                        "key": "bkietz",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=bkietz&avatarId=37277",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=bkietz&avatarId=37277",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=bkietz&avatarId=37277",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=bkietz&avatarId=37277"
                        },
                        "displayName": "Ben Kietzman",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-04-02T15:33:12.163+0000",
                    "updated": "2020-04-02T15:33:12.163+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/comment/17084327",
                    "id": "17084327",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fsaintjacques",
                        "name": "fsaintjacques",
                        "key": "fsaintjacques",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=fsaintjacques&avatarId=37276",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fsaintjacques&avatarId=37276",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fsaintjacques&avatarId=37276",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fsaintjacques&avatarId=37276"
                        },
                        "displayName": "Francois Saint-Jacques",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "[~jorisvandenbossche]\u00a0 I'm refactoring this part with ARROW-8065, I don't think `get_fragments` should do any column projection. It should just return fragments from a dataset. On the other side, `dataset.scan` and `dataset.to_table` should do said transformation.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=fsaintjacques",
                        "name": "fsaintjacques",
                        "key": "fsaintjacques",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=fsaintjacques&avatarId=37276",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fsaintjacques&avatarId=37276",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fsaintjacques&avatarId=37276",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fsaintjacques&avatarId=37276"
                        },
                        "displayName": "Francois Saint-Jacques",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2020-04-15T19:20:21.179+0000",
                    "updated": "2020-04-15T19:20:21.179+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13295048/comment/17084332",
                    "id": "17084332",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "body": "Fully agreed. \r\nIn my mind, all the `columns`/ `filters` keywords in constructing fragments right now were temporary hacks to get the desired functionality because fragments were still tied to the scan context. \r\n\r\n(But the partition column should still be included in the schema of the fragment, which was the original issue here, right? The above snippet is supposed to work?).  ",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=jorisvandenbossche",
                        "name": "jorisvandenbossche",
                        "key": "jorisvandenbossche",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "Joris Van den Bossche",
                        "active": true,
                        "timeZone": "Europe/Brussels"
                    },
                    "created": "2020-04-15T19:36:33.907+0000",
                    "updated": "2020-04-15T19:36:33.907+0000"
                }
            ],
            "maxResults": 4,
            "total": 4,
            "startAt": 0
        },
        "customfield_12311820": "0|z0d30o:",
        "customfield_12314139": null
    }
}