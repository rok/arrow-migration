{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13205836",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13205836",
    "key": "ARROW-4092",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12343937",
                "id": "12343937",
                "description": "",
                "name": "0.13.0",
                "archived": false,
                "released": true,
                "releaseDate": "2019-04-01"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": 0,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
            "name": "andygrove",
            "key": "andygrove",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
            },
            "displayName": "Andy Grove",
            "active": true,
            "timeZone": "America/Denver"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
            "name": "Closed",
            "id": "6",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12333773",
                "id": "12333773",
                "name": "Rust"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": 0,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
            "name": "andygrove",
            "key": "andygrove",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
            },
            "displayName": "Andy Grove",
            "active": true,
            "timeZone": "America/Denver"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
            "name": "andygrove",
            "key": "andygrove",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
            },
            "displayName": "Andy Grove",
            "active": true,
            "timeZone": "America/Denver"
        },
        "aggregateprogress": {
            "progress": 2400,
            "total": 2400,
            "percent": 100
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 2400,
            "total": 2400,
            "percent": 100
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-4092/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 4,
            "worklogs": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13205836/worklog/177800",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove opened a new pull request #3237: ARROW-4092: [Rust] [WIP] Implement common DataSource trait for CSV and Parquet\nURL: https://github.com/apache/arrow/pull/3237\n \n \n   I have created this PR based on code I had in my original DataFusion POC. \r\n   \r\n   I wanted to get some feedback before I put more effort into this.\r\n   \r\n   @sunchao particularly, let me know what you think about this approach. I expect it might overlap with other efforts?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-20T23:36:04.457+0000",
                    "updated": "2018-12-20T23:36:04.457+0000",
                    "started": "2018-12-20T23:36:04.456+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "177800",
                    "issueId": "13205836"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13205836/worklog/177827",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "wesm commented on a change in pull request #3237: ARROW-4092: [Rust] [WIP] Implement common DataSource trait for CSV and Parquet\nURL: https://github.com/apache/arrow/pull/3237#discussion_r243459204\n \n \n\n ##########\n File path: rust/src/parquet/reader.rs\n ##########\n @@ -0,0 +1,355 @@\n+// Copyright 2018 Grove Enterprises LLC\n \n Review comment:\n   Maybe remove this? Do take care about documenting IP lineage for code that originates outside of the community\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-21T00:25:45.904+0000",
                    "updated": "2018-12-21T00:25:45.904+0000",
                    "started": "2018-12-21T00:25:45.903+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "177827",
                    "issueId": "13205836"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13205836/worklog/177960",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove commented on issue #3237: ARROW-4092: [Rust] [WIP] Implement common DataSource trait for CSV and Parquet\nURL: https://github.com/apache/arrow/pull/3237#issuecomment-449385784\n \n \n   I'll start this fresh after the holidays. It probably makes sense to work on smaller pieces first like the separate JIRA for converting Parquet schema to Arrow schema\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-21T13:16:14.985+0000",
                    "updated": "2018-12-21T13:16:14.985+0000",
                    "started": "2018-12-21T13:16:14.985+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "177960",
                    "issueId": "13205836"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13205836/worklog/177961",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "comment": "andygrove closed pull request #3237: ARROW-4092: [Rust] [WIP] Implement common DataSource trait for CSV and Parquet\nURL: https://github.com/apache/arrow/pull/3237\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/rust/examples/read_csv.rs b/rust/examples/read_csv.rs\nindex 147d2f9c23..5ad70e5538 100644\n--- a/rust/examples/read_csv.rs\n+++ b/rust/examples/read_csv.rs\n@@ -22,6 +22,7 @@ use std::sync::Arc;\n \n use arrow::array::{BinaryArray, Float64Array};\n use arrow::csv;\n+use arrow::datasource::DataSource;\n use arrow::datatypes::{DataType, Field, Schema};\n \n fn main() {\ndiff --git a/rust/src/csv/reader.rs b/rust/src/csv/reader.rs\nindex b9c46fc321..04cc190178 100644\n--- a/rust/src/csv/reader.rs\n+++ b/rust/src/csv/reader.rs\n@@ -24,6 +24,7 @@\n //!\n //! ```\n //! use arrow::csv;\n+//! use arrow::datasource::DataSource;\n //! use arrow::datatypes::{DataType, Field, Schema};\n //! use std::fs::File;\n //! use std::sync::Arc;\n@@ -48,6 +49,7 @@ use csv as csv_crate;\n \n use crate::array::{ArrayRef, BinaryArray};\n use crate::builder::*;\n+use crate::datasource::DataSource;\n use crate::datatypes::*;\n use crate::error::{ArrowError, Result};\n use crate::record_batch::RecordBatch;\n@@ -88,8 +90,43 @@ impl Reader {\n         }\n     }\n \n+    fn build_primitive_array<T: ArrowPrimitiveType>(\n+        &self,\n+        rows: &[StringRecord],\n+        col_idx: &usize,\n+    ) -> Result<ArrayRef> {\n+        let mut builder = PrimitiveArrayBuilder::<T>::new(rows.len());\n+        let is_boolean_type = *self.schema.field(*col_idx).data_type() == DataType::Boolean;\n+        for row_index in 0..rows.len() {\n+            match rows[row_index].get(*col_idx) {\n+                Some(s) if s.len() > 0 => {\n+                    let t = if is_boolean_type {\n+                        s.to_lowercase().parse::<T::Native>()\n+                    } else {\n+                        s.parse::<T::Native>()\n+                    };\n+                    match t {\n+                        Ok(v) => builder.push(v)?,\n+                        Err(_) => {\n+                            // TODO: we should surface the underlying error here.\n+                            return Err(ArrowError::ParseError(format!(\n+                                \"Error while parsing value {}\",\n+                                s\n+                            )));\n+                        }\n+                    }\n+                }\n+                _ => builder.push_null()?,\n+            }\n+        }\n+        Ok(Arc::new(builder.finish()) as ArrayRef)\n+    }\n+}\n+\n+impl DataSource for Reader {\n+\n     /// Read the next batch of rows\n-    pub fn next(&mut self) -> Result<Option<RecordBatch>> {\n+    fn next(&mut self) -> Result<Option<RecordBatch>> {\n         // read a batch of rows into memory\n         let mut rows: Vec<StringRecord> = Vec::with_capacity(self.batch_size);\n         for _ in 0..self.batch_size {\n@@ -167,37 +204,6 @@ impl Reader {\n         }\n     }\n \n-    fn build_primitive_array<T: ArrowPrimitiveType>(\n-        &self,\n-        rows: &[StringRecord],\n-        col_idx: &usize,\n-    ) -> Result<ArrayRef> {\n-        let mut builder = PrimitiveArrayBuilder::<T>::new(rows.len());\n-        let is_boolean_type = *self.schema.field(*col_idx).data_type() == DataType::Boolean;\n-        for row_index in 0..rows.len() {\n-            match rows[row_index].get(*col_idx) {\n-                Some(s) if s.len() > 0 => {\n-                    let t = if is_boolean_type {\n-                        s.to_lowercase().parse::<T::Native>()\n-                    } else {\n-                        s.parse::<T::Native>()\n-                    };\n-                    match t {\n-                        Ok(v) => builder.push(v)?,\n-                        Err(_) => {\n-                            // TODO: we should surface the underlying error here.\n-                            return Err(ArrowError::ParseError(format!(\n-                                \"Error while parsing value {}\",\n-                                s\n-                            )));\n-                        }\n-                    }\n-                }\n-                _ => builder.push_null()?,\n-            }\n-        }\n-        Ok(Arc::new(builder.finish()) as ArrayRef)\n-    }\n }\n \n #[cfg(test)]\ndiff --git a/rust/src/datasource.rs b/rust/src/datasource.rs\nnew file mode 100644\nindex 0000000000..2ecf75c0d1\n--- /dev/null\n+++ b/rust/src/datasource.rs\n@@ -0,0 +1,25 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+use crate::error::Result;\n+use crate::record_batch::RecordBatch;\n+\n+pub trait DataSource {\n+    fn next(&mut self) -> Result<Option<RecordBatch>>;\n+}\n+\n+\ndiff --git a/rust/src/error.rs b/rust/src/error.rs\nindex 559b2d7205..914e24faab 100644\n--- a/rust/src/error.rs\n+++ b/rust/src/error.rs\n@@ -18,6 +18,7 @@\n #[derive(Debug, Clone, PartialEq)]\n pub enum ArrowError {\n     MemoryError(String),\n+    IOError(String),\n     ParseError(String),\n     ComputeError(String),\n     DivideByZero,\ndiff --git a/rust/src/lib.rs b/rust/src/lib.rs\nindex d5708b1050..0a4b294809 100644\n--- a/rust/src/lib.rs\n+++ b/rust/src/lib.rs\n@@ -29,6 +29,7 @@ pub mod bitmap;\n pub mod buffer;\n pub mod builder;\n pub mod csv;\n+pub mod datasource;\n pub mod datatypes;\n pub mod error;\n pub mod memory;\ndiff --git a/rust/src/parquet/mod.rs b/rust/src/parquet/mod.rs\nindex 58cc7b13df..56445ee0b2 100644\n--- a/rust/src/parquet/mod.rs\n+++ b/rust/src/parquet/mod.rs\n@@ -30,5 +30,6 @@ pub mod column;\n pub mod compression;\n mod encodings;\n pub mod file;\n+pub mod reader;\n pub mod record;\n pub mod schema;\ndiff --git a/rust/src/parquet/reader.rs b/rust/src/parquet/reader.rs\nnew file mode 100644\nindex 0000000000..099642616b\n--- /dev/null\n+++ b/rust/src/parquet/reader.rs\n@@ -0,0 +1,358 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+//! Parquet DataSource\n+\n+use std::fs::File;\n+use std::rc::Rc;\n+\n+use crate::array::ListArray;\n+use crate::builder::*;\n+use crate::datasource::DataSource;\n+use crate::datatypes::*;\n+use crate::error::{ArrowError, Result};\n+use crate::record_batch::RecordBatch;\n+\n+use crate::parquet::basic;\n+use crate::parquet::column::reader::*;\n+use crate::parquet::data_type::{ByteArray, Int96};\n+use crate::parquet::file::reader::*;\n+use crate::parquet::schema::types::Type;\n+\n+pub struct ParquetFile {\n+    reader: SerializedFileReader<File>,\n+    row_group_index: usize,\n+    schema: Rc<Schema>,\n+    projection: Option<Vec<usize>>,\n+    batch_size: usize,\n+    current_row_group: Option<Box<RowGroupReader>>,\n+    column_readers: Vec<Option<ColumnReader>>,\n+}\n+\n+impl ParquetFile {\n+    pub fn open(file: File, projection: Option<Vec<usize>>) -> Result<Self> {\n+        let reader = SerializedFileReader::new(file).unwrap();\n+\n+        let metadata = reader.metadata();\n+        let file_type = to_arrow(metadata.file_metadata().schema());\n+\n+        match file_type.data_type() {\n+            DataType::Struct(fields) => {\n+                let schema = Schema::new(fields.clone());\n+                //println!(\"Parquet schema: {:?}\", schema);\n+                Ok(ParquetFile {\n+                    reader: reader,\n+                    row_group_index: 0,\n+                    schema: Rc::new(schema),\n+                    projection,\n+                    batch_size: 64 * 1024,\n+                    current_row_group: None,\n+                    column_readers: vec![],\n+                })\n+            }\n+            _ => Err(ArrowError::IOError(\n+                \"Failed to read Parquet schema\".to_string(),\n+            )),\n+        }\n+    }\n+\n+    pub fn set_batch_size(&mut self, batch_size: usize) {\n+        self.batch_size = batch_size\n+    }\n+\n+    fn load_next_row_group(&mut self) {\n+        if self.row_group_index < self.reader.num_row_groups() {\n+            //println!(\"Loading row group {} of {}\", self.row_group_index, self.reader.num_row_groups());\n+            let reader = self.reader.get_row_group(self.row_group_index).unwrap();\n+\n+            self.column_readers = vec![];\n+\n+            match &self.projection {\n+                None => {\n+                    for i in 0..reader.num_columns() {\n+                        self.column_readers\n+                            .push(Some(reader.get_column_reader(i).unwrap()));\n+                    }\n+                }\n+                Some(proj) => {\n+                    for i in 0..reader.num_columns() {\n+                        if proj.contains(&i) {\n+                            self.column_readers\n+                                .push(Some(reader.get_column_reader(i).unwrap()));\n+                        } else {\n+                            //println!(\"Parquet NOT LOADING COLUMN\");\n+                            self.column_readers.push(None);\n+                        }\n+                    }\n+                }\n+            }\n+\n+            self.current_row_group = Some(reader);\n+            self.row_group_index += 1;\n+        } else {\n+            panic!()\n+        }\n+    }\n+\n+    fn load_batch(&mut self) -> Result<Option<RecordBatch>> {\n+//        match &self.current_row_group {\n+//            Some(reader) => {\n+//                let mut batch: Vec<Value> = Vec::with_capacity(reader.num_columns());\n+//                let mut row_count = 0;\n+//                for i in 0..self.column_readers.len() {\n+//                    let array = match self.column_readers[i] {\n+//                        Some(ColumnReader::ByteArrayColumnReader(ref mut r)) => {\n+//                            let mut b: Vec<ByteArray> = Vec::with_capacity(self.batch_size);\n+//                            for _ in 0..self.batch_size {\n+//                                b.push(ByteArray::default());\n+//                            }\n+//                            match r.read_batch(self.batch_size, None, None, &mut b) {\n+//                                Ok((count, _)) => {\n+//                                    row_count = count;\n+//\n+//                                    let mut builder: ListBuilder<u8> =\n+//                                        ListBuilder::with_capacity(count);\n+//                                    for j in 0..row_count {\n+//                                        builder.push(b[j].slice(0, b[j].len()).data());\n+//                                    }\n+//                                    Array::new(\n+//                                        count,\n+//                                        ArrayData::Utf8(ListArray::from(builder.finish())),\n+//                                    )\n+//                                }\n+//                                _ => panic!(\"Error reading parquet batch (column {})\", i),\n+//                            }\n+//                        }\n+//                        Some(ColumnReader::BoolColumnReader(ref mut r)) => {\n+//                            let mut builder: BoolArrayBuilder =\n+//                                Builder::with_capacity(self.batch_size);\n+//                            match r.read_batch(\n+//                                self.batch_size,\n+//                                None,\n+//                                None,\n+//                                builder.slice_mut(0, self.batch_size),\n+//                            ) {\n+//                                Ok((count, _)) => {\n+//                                    row_count = count;\n+//                                    builder.set_len(count);\n+//                                    Array::from(builder.finish())\n+//                                }\n+//                                _ => panic!(\"Error reading parquet batch (column {})\", i),\n+//                            }\n+//                        }\n+//                        Some(ColumnReader::Int32ColumnReader(ref mut r)) => {\n+//                            let mut builder: Builder<i32> = Builder::with_capacity(self.batch_size);\n+//                            match r.read_batch(\n+//                                self.batch_size,\n+//                                None,\n+//                                None,\n+//                                builder.slice_mut(0, self.batch_size),\n+//                            ) {\n+//                                Ok((count, _)) => {\n+//                                    row_count = count;\n+//                                    builder.set_len(count);\n+//                                    Array::from(builder.finish())\n+//                                }\n+//                                _ => panic!(\"Error reading parquet batch (column {})\", i),\n+//                            }\n+//                        }\n+//                        Some(ColumnReader::Int64ColumnReader(ref mut r)) => {\n+//                            let mut builder: Builder<i64> = Builder::with_capacity(self.batch_size);\n+//                            match r.read_batch(\n+//                                self.batch_size,\n+//                                None,\n+//                                None,\n+//                                builder.slice_mut(0, self.batch_size),\n+//                            ) {\n+//                                Ok((count, _)) => {\n+//                                    row_count = count;\n+//                                    builder.set_len(count);\n+//                                    Array::from(builder.finish())\n+//                                }\n+//                                _ => panic!(\"Error reading parquet batch (column {})\", i),\n+//                            }\n+//                        }\n+//                        Some(ColumnReader::Int96ColumnReader(ref mut r)) => {\n+//                            let mut temp: Vec<Int96> = Vec::with_capacity(self.batch_size);\n+//                            for _ in 0..self.batch_size {\n+//                                temp.push(Int96::new());\n+//                            }\n+//                            // let mut slice: &[Int96] = &temp;\n+//\n+//                            match r.read_batch(self.batch_size, None, None, &mut temp) {\n+//                                Ok((count, _)) => {\n+//                                    row_count = count;\n+//                                    //                                        builder.set_len(count);\n+//\n+//                                    let mut builder: Builder<\n+//                                        i64,\n+//                                    > = Builder::with_capacity(self.batch_size);\n+//                                    for i in 0..count {\n+//                                        let v = temp[i].data();\n+//                                        let value: u128 = (v[0] as u128) << 64\n+//                                            | (v[1] as u128) << 32\n+//                                            | (v[2] as u128);\n+//                                        //println!(\"value: {}\", value);\n+//\n+//                                        let ms: i64 = (value / 1000000) as i64;\n+//                                        builder.push(ms);\n+//                                    }\n+//\n+//                                    Array::from(builder.finish())\n+//                                }\n+//                                _ => panic!(\"Error reading parquet batch (column {})\", i),\n+//                            }\n+//                        }\n+//                        Some(ColumnReader::FloatColumnReader(ref mut r)) => {\n+//                            let mut builder: Builder<f32> = Builder::with_capacity(self.batch_size);\n+//                            match r.read_batch(\n+//                                self.batch_size,\n+//                                None,\n+//                                None,\n+//                                builder.slice_mut(0, self.batch_size),\n+//                            ) {\n+//                                Ok((count, _)) => {\n+//                                    row_count = count;\n+//                                    builder.set_len(count);\n+//                                    Array::from(builder.finish())\n+//                                }\n+//                                _ => panic!(\"Error reading parquet batch (column {})\", i),\n+//                            }\n+//                        }\n+//                        Some(ColumnReader::DoubleColumnReader(ref mut r)) => {\n+//                            let mut builder: Builder<f64> = Builder::with_capacity(self.batch_size);\n+//                            match r.read_batch(\n+//                                self.batch_size,\n+//                                None,\n+//                                None,\n+//                                builder.slice_mut(0, self.batch_size),\n+//                            ) {\n+//                                Ok((count, _)) => {\n+//                                    row_count = count;\n+//                                    builder.set_len(count);\n+//                                    Array::from(builder.finish())\n+//                                }\n+//                                _ => panic!(\"Error reading parquet batch (column {})\", i),\n+//                            }\n+//                        }\n+//                        Some(ColumnReader::FixedLenByteArrayColumnReader(_)) => unimplemented!(),\n+//                        None => {\n+//                            Array::from(vec![0_i32]) //TODO: really want to return scalar null\n+//                        }\n+//                    };\n+//\n+//                    batch.push(Value::Column(Rc::new(array)));\n+//                }\n+//\n+//                //                println!(\"Loaded batch of {} rows\", row_count);\n+//\n+//                if row_count == 0 {\n+//                    None\n+//                } else {\n+//                    Some(Ok(Rc::new(DefaultRecordBatch {\n+//                        schema: self.schema.clone(),\n+//                        data: batch,\n+//                        row_count,\n+//                    })))\n+//                }\n+//            }\n+//            _ => None,\n+//        }\n+        panic!();\n+    }\n+}\n+\n+impl DataSource for ParquetFile {\n+    fn next(&mut self) -> Result<Option<RecordBatch>> {\n+        // advance the row group reader if necessary\n+        if self.current_row_group.is_none() {\n+            self.load_next_row_group();\n+            self.load_batch()\n+        } else {\n+            match self.load_batch()? {\n+                Some(b) => Ok(Some(b)),\n+                None => if self.row_group_index < self.reader.num_row_groups() {\n+                    self.load_next_row_group();\n+                    self.load_batch()\n+                } else {\n+                    Ok(None)\n+                },\n+            }\n+        }\n+    }\n+\n+//    fn schema(&self) -> &Rc<Schema> {\n+//        &self.schema\n+//    }\n+}\n+\n+fn to_arrow(t: &Type) -> Field {\n+    match t {\n+        Type::PrimitiveType {\n+            basic_info,\n+            physical_type,\n+            ..\n+            //type_length,\n+            //scale,\n+            //precision,\n+        } => {\n+//                println!(\"basic_info: {:?}\", basic_info);\n+\n+            let arrow_type = match physical_type {\n+                basic::Type::BOOLEAN => DataType::Boolean,\n+                basic::Type::INT32 => DataType::Int32,\n+                basic::Type::INT64 => DataType::Int64,\n+                basic::Type::INT96 => DataType::Int64, //TODO ???\n+                basic::Type::FLOAT => DataType::Float32,\n+                basic::Type::DOUBLE => DataType::Float64,\n+                basic::Type::BYTE_ARRAY => match basic_info.logical_type() {\n+                    basic::LogicalType::UTF8 => DataType::Utf8,\n+                    _ => unimplemented!(\"No support for Parquet BYTE_ARRAY yet\"),\n+                }\n+                basic::Type::FIXED_LEN_BYTE_ARRAY => unimplemented!(\"No support for Parquet FIXED_LEN_BYTE_ARRAY yet\")\n+            };\n+\n+            Field::new(basic_info.name(), arrow_type, false)\n+        }\n+        Type::GroupType { basic_info, fields } => {\n+            Field::new(\n+                basic_info.name(),\n+                DataType::Struct(\n+                    fields.iter().map(|f| to_arrow(f)).collect()\n+                ),\n+                false)\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+\n+    use super::*;\n+    use std::cell::RefCell;\n+    use std::rc::Rc;\n+\n+    #[test]\n+    fn test_parquet() {\n+        let file = File::open(\"test/data/uk_cities.parquet\").unwrap();\n+        let mut parquet = ParquetFile::open(file, None).unwrap();\n+        let batch = parquet.next().unwrap().unwrap();\n+        println!(\"Schema: {:?}\", batch.schema());\n+        println!(\"rows: {}; cols: {}\", batch.num_rows(), batch.num_columns());\n+    }\n+\n+}\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "created": "2018-12-21T13:16:15.725+0000",
                    "updated": "2018-12-21T13:16:15.725+0000",
                    "started": "2018-12-21T13:16:15.724+0000",
                    "timeSpent": "10m",
                    "timeSpentSeconds": 600,
                    "id": "177961",
                    "issueId": "13205836"
                }
            ]
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
            "id": "4",
            "description": "An improvement or enhancement to an existing feature or task.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
            "name": "Improvement",
            "subtask": false,
            "avatarId": 21140
        },
        "timespent": 2400,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@3a6ba630[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@6f37669f[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1713341f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@43c4abfc[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5cf539cc[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@5e699af8[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5054fee6[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@3629245b[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@43e7500b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@51cbbcd5[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@269fcbc4[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@596b38b0[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": 2400,
        "customfield_12312520": null,
        "customfield_12312521": "Sat Mar 09 18:06:22 UTC 2019",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2019-03-09T18:06:21.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-4092/watchers",
            "watchCount": 1,
            "isWatching": false
        },
        "created": "2018-12-20T23:33:26.000+0000",
        "updated": "2019-03-09T18:06:22.000+0000",
        "timeoriginalestimate": null,
        "description": "As a developer, I would like to be able to execute queries against Arrow data sources using a common trait.\r\n\r\n\u00a0",
        "customfield_10010": null,
        "timetracking": {
            "remainingEstimate": "0h",
            "timeSpent": "40m",
            "remainingEstimateSeconds": 0,
            "timeSpentSeconds": 2400
        },
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Rust] Implement common Reader / DataSource trait for CSV and Parquet",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13205836/comment/16788765",
                    "id": "16788765",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "body": "This was done some time ago.",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=andygrove",
                        "name": "andygrove",
                        "key": "andygrove",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=andygrove&avatarId=28239",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=andygrove&avatarId=28239",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=andygrove&avatarId=28239",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=andygrove&avatarId=28239"
                        },
                        "displayName": "Andy Grove",
                        "active": true,
                        "timeZone": "America/Denver"
                    },
                    "created": "2019-03-09T18:06:22.021+0000",
                    "updated": "2019-03-09T18:06:22.021+0000"
                }
            ],
            "maxResults": 1,
            "total": 1,
            "startAt": 0
        },
        "customfield_12311820": "0|u007kw:",
        "customfield_12314139": null
    }
}