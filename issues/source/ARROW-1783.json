{
    "expand": "operations,versionedRepresentations,editmeta,changelog,renderedFields",
    "id": "13117344",
    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344",
    "key": "ARROW-1783",
    "fields": {
        "fixVersions": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/version/12341352",
                "id": "12341352",
                "name": "0.8.0",
                "archived": false,
                "released": true,
                "releaseDate": "2017-12-18"
            }
        ],
        "resolution": {
            "self": "https://issues.apache.org/jira/rest/api/2/resolution/1",
            "id": "1",
            "description": "A fix for this issue is checked into the tree and tested.",
            "name": "Fixed"
        },
        "customfield_12312322": null,
        "customfield_12312323": null,
        "customfield_12312320": null,
        "customfield_12310420": "9223372036854775807",
        "customfield_12312321": null,
        "customfield_12312328": null,
        "customfield_12312329": null,
        "customfield_12312326": null,
        "customfield_12310300": null,
        "customfield_12312327": null,
        "customfield_12312324": null,
        "customfield_12312720": null,
        "customfield_12312325": null,
        "lastViewed": null,
        "priority": {
            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
            "name": "Major",
            "id": "3"
        },
        "labels": [
            "pull-request-available"
        ],
        "customfield_12312333": null,
        "customfield_12312334": null,
        "customfield_12313422": "false",
        "customfield_12310310": "0.0",
        "customfield_12312331": null,
        "customfield_12312332": null,
        "aggregatetimeoriginalestimate": null,
        "timeestimate": null,
        "customfield_12312330": null,
        "versions": [],
        "customfield_12311120": null,
        "customfield_12313826": null,
        "customfield_12312339": null,
        "issuelinks": [
            {
                "id": "12519696",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12519696",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "outwardIssue": {
                    "id": "13101058",
                    "key": "ARROW-1509",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13101058",
                    "fields": {
                        "summary": "[Python] Write serialized object as a stream of encapsulated IPC messages",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/6",
                            "description": "The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/closed.png",
                            "name": "Closed",
                            "id": "6",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
                            "id": "4",
                            "description": "An improvement or enhancement to an existing feature or task.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
                            "name": "Improvement",
                            "subtask": false,
                            "avatarId": 21140
                        }
                    }
                }
            },
            {
                "id": "12519697",
                "self": "https://issues.apache.org/jira/rest/api/2/issueLink/12519697",
                "type": {
                    "id": "10030",
                    "name": "Reference",
                    "inward": "is related to",
                    "outward": "relates to",
                    "self": "https://issues.apache.org/jira/rest/api/2/issueLinkType/10030"
                },
                "inwardIssue": {
                    "id": "13117346",
                    "key": "ARROW-1784",
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117346",
                    "fields": {
                        "summary": "[Python] Read and write pandas.DataFrame in pyarrow.serialize by decomposing the BlockManager rather than coercing to Arrow format",
                        "status": {
                            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
                            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
                            "name": "Resolved",
                            "id": "5",
                            "statusCategory": {
                                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                                "id": 3,
                                "key": "done",
                                "colorName": "green",
                                "name": "Done"
                            }
                        },
                        "priority": {
                            "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
                            "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
                            "name": "Major",
                            "id": "3"
                        },
                        "issuetype": {
                            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
                            "id": "2",
                            "description": "A new feature of the product, which has yet to be developed.",
                            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
                            "name": "New Feature",
                            "subtask": false,
                            "avatarId": 21141
                        }
                    }
                }
            }
        ],
        "customfield_12313825": null,
        "assignee": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "customfield_12312337": null,
        "customfield_12313823": null,
        "customfield_12312338": null,
        "customfield_12311920": null,
        "customfield_12313822": null,
        "customfield_12312335": null,
        "customfield_12313821": null,
        "customfield_12312336": null,
        "customfield_12313820": null,
        "status": {
            "self": "https://issues.apache.org/jira/rest/api/2/status/5",
            "description": "A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.",
            "iconUrl": "https://issues.apache.org/jira/images/icons/statuses/resolved.png",
            "name": "Resolved",
            "id": "5",
            "statusCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/statuscategory/3",
                "id": 3,
                "key": "done",
                "colorName": "green",
                "name": "Done"
            }
        },
        "components": [
            {
                "self": "https://issues.apache.org/jira/rest/api/2/component/12328936",
                "id": "12328936",
                "name": "Python"
            }
        ],
        "customfield_12312026": null,
        "customfield_12312023": null,
        "customfield_12312024": null,
        "aggregatetimeestimate": null,
        "customfield_12312022": null,
        "customfield_12310921": null,
        "customfield_12310920": "9223372036854775807",
        "customfield_12312823": null,
        "creator": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "subtasks": [],
        "reporter": {
            "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
            "name": "wesm",
            "key": "wesmckinn",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
            },
            "displayName": "Wes McKinney",
            "active": true,
            "timeZone": "America/New_York"
        },
        "aggregateprogress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313520": null,
        "customfield_12310250": null,
        "progress": {
            "progress": 0,
            "total": 0
        },
        "customfield_12313924": null,
        "votes": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1783/votes",
            "votes": 0,
            "hasVoted": false
        },
        "worklog": {
            "startAt": 0,
            "maxResults": 20,
            "total": 0,
            "worklogs": []
        },
        "customfield_12313920": null,
        "issuetype": {
            "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
            "id": "2",
            "description": "A new feature of the product, which has yet to be developed.",
            "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
            "name": "New Feature",
            "subtask": false,
            "avatarId": 21141
        },
        "timespent": null,
        "customfield_12314020": "{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@14003098[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@33702acf[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@32dd6f67[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@c90da1[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@4091dfb8[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@7e54bf3[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@5e1aba3f[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@16761058[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@58d47131[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@7543130b[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@7e0394de[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@58d1af96[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}",
        "customfield_12314141": null,
        "customfield_12314140": null,
        "project": {
            "self": "https://issues.apache.org/jira/rest/api/2/project/12319525",
            "id": "12319525",
            "key": "ARROW",
            "name": "Apache Arrow",
            "projectTypeKey": "software",
            "avatarUrls": {
                "48x48": "https://issues.apache.org/jira/secure/projectavatar?pid=12319525&avatarId=10011",
                "24x24": "https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12319525&avatarId=10011",
                "16x16": "https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12319525&avatarId=10011",
                "32x32": "https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12319525&avatarId=10011"
            },
            "projectCategory": {
                "self": "https://issues.apache.org/jira/rest/api/2/projectCategory/13960",
                "id": "13960",
                "description": "Apache Arrow",
                "name": "Arrow"
            }
        },
        "aggregatetimespent": null,
        "customfield_12312520": null,
        "customfield_12312521": "Mon Nov 27 21:15:27 UTC 2017",
        "customfield_12314422": null,
        "customfield_12314421": null,
        "customfield_12314146": null,
        "customfield_12314420": null,
        "customfield_12314145": null,
        "customfield_12314144": null,
        "customfield_12314143": null,
        "resolutiondate": "2017-11-27T21:15:27.000+0000",
        "workratio": -1,
        "customfield_12312923": null,
        "customfield_12312920": null,
        "customfield_12312921": null,
        "watches": {
            "self": "https://issues.apache.org/jira/rest/api/2/issue/ARROW-1783/watchers",
            "watchCount": 5,
            "isWatching": false
        },
        "created": "2017-11-09T17:33:23.000+0000",
        "updated": "2017-11-27T21:15:27.000+0000",
        "timeoriginalestimate": null,
        "description": "See discussion on Dask org:\r\n\r\nhttps://github.com/dask/distributed/pull/931\r\n\r\nIt would be valuable for downstream users to compute the serialized payload as a sequence of memoryview-compatible objects without having to allocate new memory on write. This means that the component tensor messages must have their metadata and bodies in separate buffers. This will require a bit of work internally reassemble the object from a collection of {{pyarrow.Buffer}} objects\r\n\r\nsee also ARROW-1509",
        "customfield_10010": null,
        "timetracking": {},
        "customfield_12314523": null,
        "customfield_12314127": null,
        "customfield_12314522": null,
        "customfield_12314126": null,
        "customfield_12314521": null,
        "customfield_12314125": null,
        "customfield_12314520": null,
        "customfield_12314124": null,
        "attachment": [],
        "customfield_12312340": null,
        "customfield_12314123": null,
        "customfield_12312341": null,
        "customfield_12312220": null,
        "customfield_12314122": null,
        "customfield_12314121": null,
        "customfield_12314120": null,
        "customfield_12314129": null,
        "customfield_12314524": null,
        "customfield_12314128": null,
        "summary": "[Python] Convert SerializedPyObject to/from sequence of component buffers with minimal memory allocation / copying",
        "customfield_12314130": null,
        "customfield_12310291": null,
        "customfield_12310290": null,
        "customfield_12314138": null,
        "customfield_12314137": null,
        "environment": null,
        "customfield_12314136": null,
        "customfield_12314135": null,
        "customfield_12311020": null,
        "customfield_12314134": null,
        "duedate": null,
        "customfield_12314132": null,
        "customfield_12314131": null,
        "comment": {
            "comments": [
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266124",
                    "id": "16266124",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm opened a new pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362\n \n \n   For systems (like Dask) that prefer to handle their own framed buffer transport, this provides a list of memoryview-compatible objects with minimal copying / allocation from the input data structure, which can similarly be zero-copy reconstructed to the original object.\r\n   \r\n   To motivate the use case, consider a dict of ndarrays:\r\n   \r\n   ```\r\n   data = {i: np.random.randn(1000, 1000) for i in range(50)}\r\n   ```\r\n   \r\n   Here, we have:\r\n   \r\n   ```\r\n   >>> %timeit serialized = pa.serialize(data)\r\n   52.7 \u00b5s \u00b1 1.01 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n   ```\r\n   \r\n   This is about 400MB of data. Some systems may not want to double memory by assembling this into a single large buffer, like with the `to_buffer` method:\r\n   \r\n   ```\r\n   >>> written = serialized.to_buffer()\r\n   >>> written.size\r\n   400015456\r\n   ```\r\n   \r\n   We provide a `to_components` method which contains a dict with a `'data'` field containing a list of `pyarrow.Buffer` objects. This can be converted back to the original Python object using `pyarrow.deserialize_components`:\r\n   \r\n   ```\r\n   >>> %timeit components = serialized.to_components()\r\n   73.8 \u00b5s \u00b1 812 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\r\n   \r\n   >>> list(components.keys())\r\n   ['num_buffers', 'data', 'num_tensors']\r\n   \r\n   >>> len(components['data'])\r\n   101\r\n   \r\n   >>> type(components['data'][0])\r\n   pyarrow.lib.Buffer\r\n   ```\r\n   \r\n   The reason there are 101 data components (1 + 2 * 50) is that:\r\n   \r\n   * 1 buffer for the serialized Union stream representing the object\r\n   * 2 buffers for each of the tensors: 1 for the metadata and 1 for the tensor body. The body is separate so that this is zero-copy from the input\r\n   \r\n   Next step after this is ARROW-1784 which is to transport a pandas.DataFrame using this mechanism\r\n   \r\n   cc @pitrou @jcrist @mrocklin\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T18:21:34.946+0000",
                    "updated": "2017-11-26T18:21:34.946+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266127",
                    "id": "16266127",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#discussion_r153078038\n \n \n\n ##########\n File path: cpp/src/arrow/ipc/message.h\n ##########\n @@ -144,33 +144,20 @@ class ARROW_EXPORT MessageReader {\n  public:\n   virtual ~MessageReader() = default;\n \n+  /// \\brief Create MessageReader that reads from InputStream\n+  static std::unique_ptr<MessageReader> Open(io::InputStream* stream);\n+\n+  /// \\brief Create MessageReader that reads from owned InputStream\n+  static std::unique_ptr<MessageReader> Open(\n+      const std::shared_ptr<io::InputStream>& owned_stream);\n+\n   /// \\brief Read next Message from the interface\n   ///\n   /// \\param[out] message an arrow::ipc::Message instance\n   /// \\return Status\n   virtual Status ReadNextMessage(std::unique_ptr<Message>* message) = 0;\n };\n \n-/// \\brief Implementation of MessageReader that reads from InputStream\n-/// \\since 0.5.0\n-class ARROW_EXPORT InputStreamMessageReader : public MessageReader {\n \n Review comment:\n   It was never necessary to export this class\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T18:22:49.431+0000",
                    "updated": "2017-11-26T18:22:49.431+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266155",
                    "id": "16266155",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "mrocklin commented on issue #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#issuecomment-347033537\n \n \n   At first glance the `to_components`/`deserialize_components` structure seems good to me.  This is definitely something that we can work with on the Dask side.  Is it possible to easily turn each of the elements of `to_components()['data']` into a `memoryview` without significant cost?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T19:52:19.820+0000",
                    "updated": "2017-11-26T19:52:19.820+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266156",
                    "id": "16266156",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "mrocklin commented on issue #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#issuecomment-347033589\n \n \n   ```python\r\n   >>> list(components.keys())\r\n   ['num_buffers', 'data', 'num_tensors']\r\n   ```\r\n   \r\n   I'm curious what the metadata here is supposed to mean and how it relates to `data`.  Just curious though.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T19:53:11.426+0000",
                    "updated": "2017-11-26T19:53:11.426+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266163",
                    "id": "16266163",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#issuecomment-347034490\n \n \n   Yeah, you just call `memoryview` on the objects in `to_components()['data']` -- the support the the buffer/memoryview protocol.\r\n   \r\n   The serialized payload consists of an Arrow data structure describing the whole object, and the ndarrays / buffers are sent as \"sidecars\". So if `num_buffers` and `num_tensors` are both 0, then there will only be one buffer in `data`. In general there are `1 + num_buffers + 2 * num_tensors`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T20:07:00.390+0000",
                    "updated": "2017-11-26T20:07:00.390+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266165",
                    "id": "16266165",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#issuecomment-347034490\n \n \n   Yeah, you just call `memoryview` on the objects in `to_components()['data']` -- the Buffer objects support the buffer/memoryview protocol.\r\n   \r\n   The serialized payload consists of an Arrow data structure describing the whole object, and the ndarrays / buffers are sent as \"sidecars\". So if `num_buffers` and `num_tensors` are both 0, then there will only be one buffer in `data`. In general there are `1 + num_buffers + 2 * num_tensors`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T20:07:50.728+0000",
                    "updated": "2017-11-26T20:07:50.728+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266196",
                    "id": "16266196",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#issuecomment-347040201\n \n \n   I could possibly add an argument to `to_components` that returns buffers as memoryviews, if that would help. Might be nice to encapsulate this detail somewhat (though Dask must have knowledge of the additional metadata anyhow)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T21:34:38.659+0000",
                    "updated": "2017-11-26T21:34:38.659+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266219",
                    "id": "16266219",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "mrocklin commented on issue #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#issuecomment-347042853\n \n \n   From a Dask perspective I'm more than happy to handle the memoryview conversion.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-26T22:13:43.636+0000",
                    "updated": "2017-11-26T22:13:43.636+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266515",
                    "id": "16266515",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "pitrou commented on a change in pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#discussion_r153132683\n \n \n\n ##########\n File path: cpp/src/arrow/python/python_to_arrow.cc\n ##########\n @@ -710,27 +712,88 @@ Status SerializeObject(PyObject* context, PyObject* sequence, SerializedPyObject\n   return Status::OK();\n }\n \n-Status WriteSerializedObject(const SerializedPyObject& obj, io::OutputStream* dst) {\n-  int32_t num_tensors = static_cast<int32_t>(obj.tensors.size());\n-  int32_t num_buffers = static_cast<int32_t>(obj.buffers.size());\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_tensors), sizeof(int32_t)));\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_buffers), sizeof(int32_t)));\n-  RETURN_NOT_OK(ipc::WriteRecordBatchStream({obj.batch}, dst));\n+Status SerializedPyObject::WriteTo(io::OutputStream* dst) {\n+  int32_t num_tensors = static_cast<int32_t>(this->tensors.size());\n+  int32_t num_buffers = static_cast<int32_t>(this->buffers.size());\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_tensors), sizeof(int32_t)));\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_buffers), sizeof(int32_t)));\n+  RETURN_NOT_OK(ipc::WriteRecordBatchStream({this->batch}, dst));\n \n   int32_t metadata_length;\n   int64_t body_length;\n-  for (const auto& tensor : obj.tensors) {\n+  for (const auto& tensor : this->tensors) {\n     RETURN_NOT_OK(ipc::WriteTensor(*tensor, dst, &metadata_length, &body_length));\n   }\n \n-  for (const auto& buffer : obj.buffers) {\n+  for (const auto& buffer : this->buffers) {\n     int64_t size = buffer->size();\n-    RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&size), sizeof(int64_t)));\n+    RETURN_NOT_OK(dst->Write(reinterpret_cast<const uint8_t*>(&size), sizeof(int64_t)));\n     RETURN_NOT_OK(dst->Write(buffer->data(), size));\n   }\n \n   return Status::OK();\n }\n \n+Status SerializedPyObject::GetComponents(MemoryPool* memory_pool, PyObject** out) {\n+  PyAcquireGIL py_gil;\n+\n+  ScopedRef result(PyDict_New());\n+  PyObject* buffers = PyList_New(0);\n+\n+  // TODO(wesm): Not sure how pedantic we need to be about checking the return\n+  // values of these functions. There are other places where we do not check\n+  // PyDict_SetItem/SetItemString return value, but these failures would be\n+  // quite esoteric\n \n Review comment:\n   The main failure mode would be MemoryError when growing the dict to make place for the new key.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T08:42:46.520+0000",
                    "updated": "2017-11-27T08:42:46.520+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266519",
                    "id": "16266519",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "pitrou commented on a change in pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#discussion_r153133685\n \n \n\n ##########\n File path: cpp/src/arrow/python/python_to_arrow.cc\n ##########\n @@ -710,27 +712,88 @@ Status SerializeObject(PyObject* context, PyObject* sequence, SerializedPyObject\n   return Status::OK();\n }\n \n-Status WriteSerializedObject(const SerializedPyObject& obj, io::OutputStream* dst) {\n-  int32_t num_tensors = static_cast<int32_t>(obj.tensors.size());\n-  int32_t num_buffers = static_cast<int32_t>(obj.buffers.size());\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_tensors), sizeof(int32_t)));\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_buffers), sizeof(int32_t)));\n-  RETURN_NOT_OK(ipc::WriteRecordBatchStream({obj.batch}, dst));\n+Status SerializedPyObject::WriteTo(io::OutputStream* dst) {\n+  int32_t num_tensors = static_cast<int32_t>(this->tensors.size());\n+  int32_t num_buffers = static_cast<int32_t>(this->buffers.size());\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_tensors), sizeof(int32_t)));\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_buffers), sizeof(int32_t)));\n+  RETURN_NOT_OK(ipc::WriteRecordBatchStream({this->batch}, dst));\n \n   int32_t metadata_length;\n   int64_t body_length;\n-  for (const auto& tensor : obj.tensors) {\n+  for (const auto& tensor : this->tensors) {\n     RETURN_NOT_OK(ipc::WriteTensor(*tensor, dst, &metadata_length, &body_length));\n   }\n \n-  for (const auto& buffer : obj.buffers) {\n+  for (const auto& buffer : this->buffers) {\n     int64_t size = buffer->size();\n-    RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&size), sizeof(int64_t)));\n+    RETURN_NOT_OK(dst->Write(reinterpret_cast<const uint8_t*>(&size), sizeof(int64_t)));\n     RETURN_NOT_OK(dst->Write(buffer->data(), size));\n   }\n \n   return Status::OK();\n }\n \n+Status SerializedPyObject::GetComponents(MemoryPool* memory_pool, PyObject** out) {\n+  PyAcquireGIL py_gil;\n+\n+  ScopedRef result(PyDict_New());\n+  PyObject* buffers = PyList_New(0);\n+\n+  // TODO(wesm): Not sure how pedantic we need to be about checking the return\n+  // values of these functions. There are other places where we do not check\n+  // PyDict_SetItem/SetItemString return value, but these failures would be\n+  // quite esoteric\n+  PyDict_SetItemString(result.get(), \"num_tensors\",\n+                       PyLong_FromSize_t(this->tensors.size()));\n+  PyDict_SetItemString(result.get(), \"num_buffers\",\n+                       PyLong_FromSize_t(this->buffers.size()));\n+  PyDict_SetItemString(result.get(), \"data\", buffers);\n+  RETURN_IF_PYERROR();\n+\n+  Py_DECREF(buffers);\n+\n+  auto PushBuffer = [&buffers](const std::shared_ptr<Buffer>& buffer) {\n+    PyObject* wrapped_buffer = wrap_buffer(buffer);\n+    RETURN_IF_PYERROR();\n+    if (PyList_Append(buffers, wrapped_buffer) < 0) {\n+      RETURN_IF_PYERROR();\n \n Review comment:\n   You probably need `Py_DECREF(wrapper_buffer)` here as well.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T08:48:26.594+0000",
                    "updated": "2017-11-27T08:48:26.594+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16266525",
                    "id": "16266525",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "pitrou commented on a change in pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#discussion_r153134345\n \n \n\n ##########\n File path: cpp/src/arrow/ipc/message.h\n ##########\n @@ -144,33 +144,20 @@ class ARROW_EXPORT MessageReader {\n  public:\n   virtual ~MessageReader() = default;\n \n+  /// \\brief Create MessageReader that reads from InputStream\n+  static std::unique_ptr<MessageReader> Open(io::InputStream* stream);\n+\n+  /// \\brief Create MessageReader that reads from owned InputStream\n+  static std::unique_ptr<MessageReader> Open(\n \n Review comment:\n   For the record, is there a rationale or convention for the use of unique_ptr vs shared_ptr here? :-)\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T08:51:41.370+0000",
                    "updated": "2017-11-27T08:51:41.370+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16267038",
                    "id": "16267038",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#discussion_r153254562\n \n \n\n ##########\n File path: cpp/src/arrow/python/python_to_arrow.cc\n ##########\n @@ -710,27 +712,88 @@ Status SerializeObject(PyObject* context, PyObject* sequence, SerializedPyObject\n   return Status::OK();\n }\n \n-Status WriteSerializedObject(const SerializedPyObject& obj, io::OutputStream* dst) {\n-  int32_t num_tensors = static_cast<int32_t>(obj.tensors.size());\n-  int32_t num_buffers = static_cast<int32_t>(obj.buffers.size());\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_tensors), sizeof(int32_t)));\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_buffers), sizeof(int32_t)));\n-  RETURN_NOT_OK(ipc::WriteRecordBatchStream({obj.batch}, dst));\n+Status SerializedPyObject::WriteTo(io::OutputStream* dst) {\n+  int32_t num_tensors = static_cast<int32_t>(this->tensors.size());\n+  int32_t num_buffers = static_cast<int32_t>(this->buffers.size());\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_tensors), sizeof(int32_t)));\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_buffers), sizeof(int32_t)));\n+  RETURN_NOT_OK(ipc::WriteRecordBatchStream({this->batch}, dst));\n \n   int32_t metadata_length;\n   int64_t body_length;\n-  for (const auto& tensor : obj.tensors) {\n+  for (const auto& tensor : this->tensors) {\n     RETURN_NOT_OK(ipc::WriteTensor(*tensor, dst, &metadata_length, &body_length));\n   }\n \n-  for (const auto& buffer : obj.buffers) {\n+  for (const auto& buffer : this->buffers) {\n     int64_t size = buffer->size();\n-    RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&size), sizeof(int64_t)));\n+    RETURN_NOT_OK(dst->Write(reinterpret_cast<const uint8_t*>(&size), sizeof(int64_t)));\n     RETURN_NOT_OK(dst->Write(buffer->data(), size));\n   }\n \n   return Status::OK();\n }\n \n+Status SerializedPyObject::GetComponents(MemoryPool* memory_pool, PyObject** out) {\n+  PyAcquireGIL py_gil;\n+\n+  ScopedRef result(PyDict_New());\n+  PyObject* buffers = PyList_New(0);\n+\n+  // TODO(wesm): Not sure how pedantic we need to be about checking the return\n+  // values of these functions. There are other places where we do not check\n+  // PyDict_SetItem/SetItemString return value, but these failures would be\n+  // quite esoteric\n+  PyDict_SetItemString(result.get(), \"num_tensors\",\n+                       PyLong_FromSize_t(this->tensors.size()));\n+  PyDict_SetItemString(result.get(), \"num_buffers\",\n+                       PyLong_FromSize_t(this->buffers.size()));\n+  PyDict_SetItemString(result.get(), \"data\", buffers);\n+  RETURN_IF_PYERROR();\n+\n+  Py_DECREF(buffers);\n+\n+  auto PushBuffer = [&buffers](const std::shared_ptr<Buffer>& buffer) {\n+    PyObject* wrapped_buffer = wrap_buffer(buffer);\n+    RETURN_IF_PYERROR();\n+    if (PyList_Append(buffers, wrapped_buffer) < 0) {\n+      RETURN_IF_PYERROR();\n \n Review comment:\n   done\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T16:47:55.000+0000",
                    "updated": "2017-11-27T16:47:55.000+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16267043",
                    "id": "16267043",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on a change in pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#discussion_r153255447\n \n \n\n ##########\n File path: cpp/src/arrow/ipc/message.h\n ##########\n @@ -144,33 +144,20 @@ class ARROW_EXPORT MessageReader {\n  public:\n   virtual ~MessageReader() = default;\n \n+  /// \\brief Create MessageReader that reads from InputStream\n+  static std::unique_ptr<MessageReader> Open(io::InputStream* stream);\n+\n+  /// \\brief Create MessageReader that reads from owned InputStream\n+  static std::unique_ptr<MessageReader> Open(\n \n Review comment:\n   I try to only use shared_ptr when there is some reasonable expectation that shared ownership may be frequently needed (of course one can always transfer the pointer to a shared_ptr if needed). There are some other places in the library where `shared_ptr` is returned (or an out-variable) that would be better as `unique_ptr`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T16:50:44.702+0000",
                    "updated": "2017-11-27T16:50:44.702+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16267571",
                    "id": "16267571",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm commented on issue #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362#issuecomment-347330237\n \n \n   +1\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T21:15:05.329+0000",
                    "updated": "2017-11-27T21:15:05.329+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16267572",
                    "id": "16267572",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "body": "wesm closed pull request #1362: ARROW-1783: [Python] Provide a \"component\" dict representation of a serialized Python object with minimal allocation\nURL: https://github.com/apache/arrow/pull/1362\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/cpp/src/arrow/io/memory.cc b/cpp/src/arrow/io/memory.cc\nindex d9c84b495..d52b6dc5d 100644\n--- a/cpp/src/arrow/io/memory.cc\n+++ b/cpp/src/arrow/io/memory.cc\n@@ -240,6 +240,9 @@ BufferReader::BufferReader(const std::shared_ptr<Buffer>& buffer)\n BufferReader::BufferReader(const uint8_t* data, int64_t size)\n     : buffer_(nullptr), data_(data), size_(size), position_(0) {}\n \n+BufferReader::BufferReader(const Buffer& buffer)\n+    : BufferReader(buffer.data(), buffer.size()) {}\n+\n Status BufferReader::Close() {\n   // no-op\n   return Status::OK();\ndiff --git a/cpp/src/arrow/io/memory.h b/cpp/src/arrow/io/memory.h\nindex 3aec91f72..51471a25a 100644\n--- a/cpp/src/arrow/io/memory.h\n+++ b/cpp/src/arrow/io/memory.h\n@@ -107,6 +107,7 @@ class ARROW_EXPORT FixedSizeBufferWriter : public WriteableFile {\n class ARROW_EXPORT BufferReader : public RandomAccessFile {\n  public:\n   explicit BufferReader(const std::shared_ptr<Buffer>& buffer);\n+  explicit BufferReader(const Buffer& buffer);\n   BufferReader(const uint8_t* data, int64_t size);\n \n   Status Close() override;\ndiff --git a/cpp/src/arrow/ipc/message.cc b/cpp/src/arrow/ipc/message.cc\nindex 21d6a69a2..1835cefde 100644\n--- a/cpp/src/arrow/ipc/message.cc\n+++ b/cpp/src/arrow/ipc/message.cc\n@@ -236,11 +236,35 @@ Status ReadMessage(io::InputStream* file, std::unique_ptr<Message>* message) {\n // ----------------------------------------------------------------------\n // Implement InputStream message reader\n \n-Status InputStreamMessageReader::ReadNextMessage(std::unique_ptr<Message>* message) {\n-  return ReadMessage(stream_, message);\n+/// \\brief Implementation of MessageReader that reads from InputStream\n+class InputStreamMessageReader : public MessageReader {\n+ public:\n+  explicit InputStreamMessageReader(io::InputStream* stream) : stream_(stream) {}\n+\n+  explicit InputStreamMessageReader(const std::shared_ptr<io::InputStream>& owned_stream)\n+      : InputStreamMessageReader(owned_stream.get()) {\n+    owned_stream_ = owned_stream;\n+  }\n+\n+  ~InputStreamMessageReader() {}\n+\n+  Status ReadNextMessage(std::unique_ptr<Message>* message) {\n+    return ReadMessage(stream_, message);\n+  }\n+\n+ private:\n+  io::InputStream* stream_;\n+  std::shared_ptr<io::InputStream> owned_stream_;\n+};\n+\n+std::unique_ptr<MessageReader> MessageReader::Open(io::InputStream* stream) {\n+  return std::unique_ptr<MessageReader>(new InputStreamMessageReader(stream));\n }\n \n-InputStreamMessageReader::~InputStreamMessageReader() {}\n+std::unique_ptr<MessageReader> MessageReader::Open(\n+    const std::shared_ptr<io::InputStream>& owned_stream) {\n+  return std::unique_ptr<MessageReader>(new InputStreamMessageReader(owned_stream));\n+}\n \n }  // namespace ipc\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/ipc/message.h b/cpp/src/arrow/ipc/message.h\nindex 495474e50..159b39a81 100644\n--- a/cpp/src/arrow/ipc/message.h\n+++ b/cpp/src/arrow/ipc/message.h\n@@ -144,6 +144,13 @@ class ARROW_EXPORT MessageReader {\n  public:\n   virtual ~MessageReader() = default;\n \n+  /// \\brief Create MessageReader that reads from InputStream\n+  static std::unique_ptr<MessageReader> Open(io::InputStream* stream);\n+\n+  /// \\brief Create MessageReader that reads from owned InputStream\n+  static std::unique_ptr<MessageReader> Open(\n+      const std::shared_ptr<io::InputStream>& owned_stream);\n+\n   /// \\brief Read next Message from the interface\n   ///\n   /// \\param[out] message an arrow::ipc::Message instance\n@@ -151,26 +158,6 @@ class ARROW_EXPORT MessageReader {\n   virtual Status ReadNextMessage(std::unique_ptr<Message>* message) = 0;\n };\n \n-/// \\brief Implementation of MessageReader that reads from InputStream\n-/// \\since 0.5.0\n-class ARROW_EXPORT InputStreamMessageReader : public MessageReader {\n- public:\n-  explicit InputStreamMessageReader(io::InputStream* stream) : stream_(stream) {}\n-\n-  explicit InputStreamMessageReader(const std::shared_ptr<io::InputStream>& owned_stream)\n-      : InputStreamMessageReader(owned_stream.get()) {\n-    owned_stream_ = owned_stream;\n-  }\n-\n-  ~InputStreamMessageReader();\n-\n-  Status ReadNextMessage(std::unique_ptr<Message>* message) override;\n-\n- private:\n-  io::InputStream* stream_;\n-  std::shared_ptr<io::InputStream> owned_stream_;\n-};\n-\n /// \\brief Read encapulated RPC message from position in file\n ///\n /// Read a length-prefixed message flatbuffer starting at the indicated file\ndiff --git a/cpp/src/arrow/ipc/reader.cc b/cpp/src/arrow/ipc/reader.cc\nindex 5960e8188..ae0f8f398 100644\n--- a/cpp/src/arrow/ipc/reader.cc\n+++ b/cpp/src/arrow/ipc/reader.cc\n@@ -480,14 +480,12 @@ Status RecordBatchStreamReader::Open(std::unique_ptr<MessageReader> message_read\n \n Status RecordBatchStreamReader::Open(io::InputStream* stream,\n                                      std::shared_ptr<RecordBatchReader>* out) {\n-  std::unique_ptr<MessageReader> message_reader(new InputStreamMessageReader(stream));\n-  return Open(std::move(message_reader), out);\n+  return Open(MessageReader::Open(stream), out);\n }\n \n Status RecordBatchStreamReader::Open(const std::shared_ptr<io::InputStream>& stream,\n                                      std::shared_ptr<RecordBatchReader>* out) {\n-  std::unique_ptr<MessageReader> message_reader(new InputStreamMessageReader(stream));\n-  return Open(std::move(message_reader), out);\n+  return Open(MessageReader::Open(stream), out);\n }\n \n std::shared_ptr<Schema> RecordBatchStreamReader::schema() const {\n@@ -717,14 +715,17 @@ Status ReadTensor(int64_t offset, io::RandomAccessFile* file,\n \n   std::unique_ptr<Message> message;\n   RETURN_NOT_OK(ReadContiguousPayload(file, &message));\n+  return ReadTensor(*message, out);\n+}\n \n+Status ReadTensor(const Message& message, std::shared_ptr<Tensor>* out) {\n   std::shared_ptr<DataType> type;\n   std::vector<int64_t> shape;\n   std::vector<int64_t> strides;\n   std::vector<std::string> dim_names;\n-  RETURN_NOT_OK(internal::GetTensorMetadata(*message->metadata(), &type, &shape, &strides,\n+  RETURN_NOT_OK(internal::GetTensorMetadata(*message.metadata(), &type, &shape, &strides,\n                                             &dim_names));\n-  *out = std::make_shared<Tensor>(type, message->body(), shape, strides, dim_names);\n+  *out = std::make_shared<Tensor>(type, message.body(), shape, strides, dim_names);\n   return Status::OK();\n }\n \ndiff --git a/cpp/src/arrow/ipc/reader.h b/cpp/src/arrow/ipc/reader.h\nindex 627f67e25..019c9bc1f 100644\n--- a/cpp/src/arrow/ipc/reader.h\n+++ b/cpp/src/arrow/ipc/reader.h\n@@ -219,7 +219,7 @@ Status ReadRecordBatch(const Buffer& metadata, const std::shared_ptr<Schema>& sc\n                        int max_recursion_depth, io::RandomAccessFile* file,\n                        std::shared_ptr<RecordBatch>* out);\n \n-/// EXPERIMENTAL: Read arrow::Tensor as encapsulated IPC message in file\n+/// \\brief EXPERIMENTAL: Read arrow::Tensor as encapsulated IPC message in file\n ///\n /// \\param[in] offset the file location of the start of the message\n /// \\param[in] file the file where the batch is located\n@@ -229,6 +229,14 @@ ARROW_EXPORT\n Status ReadTensor(int64_t offset, io::RandomAccessFile* file,\n                   std::shared_ptr<Tensor>* out);\n \n+/// \\brief EXPERIMENTAL: Read arrow::Tensor from IPC message\n+///\n+/// \\param[in] message a Message containing the tensor metadata and body\n+/// \\param[out] out the read tensor\n+/// \\return Status\n+ARROW_EXPORT\n+Status ReadTensor(const Message& message, std::shared_ptr<Tensor>* out);\n+\n }  // namespace ipc\n }  // namespace arrow\n \ndiff --git a/cpp/src/arrow/ipc/writer.cc b/cpp/src/arrow/ipc/writer.cc\nindex 3c1db0615..3aacabaef 100644\n--- a/cpp/src/arrow/ipc/writer.cc\n+++ b/cpp/src/arrow/ipc/writer.cc\n@@ -560,9 +560,18 @@ Status WriteLargeRecordBatch(const RecordBatch& batch, int64_t buffer_start_offs\n                           pool, kMaxNestingDepth, true);\n }\n \n-static Status WriteStridedTensorData(int dim_index, int64_t offset, int elem_size,\n-                                     const Tensor& tensor, uint8_t* scratch_space,\n-                                     io::OutputStream* dst) {\n+namespace {\n+\n+Status WriteTensorHeader(const Tensor& tensor, io::OutputStream* dst,\n+                         int32_t* metadata_length, int64_t* body_length) {\n+  std::shared_ptr<Buffer> metadata;\n+  RETURN_NOT_OK(internal::WriteTensorMessage(tensor, 0, &metadata));\n+  return internal::WriteMessage(*metadata, dst, metadata_length);\n+}\n+\n+Status WriteStridedTensorData(int dim_index, int64_t offset, int elem_size,\n+                              const Tensor& tensor, uint8_t* scratch_space,\n+                              io::OutputStream* dst) {\n   if (dim_index == tensor.ndim() - 1) {\n     const uint8_t* data_ptr = tensor.raw_data() + offset;\n     const int64_t stride = tensor.strides()[dim_index];\n@@ -580,16 +589,37 @@ static Status WriteStridedTensorData(int dim_index, int64_t offset, int elem_siz\n   return Status::OK();\n }\n \n-Status WriteTensorHeader(const Tensor& tensor, io::OutputStream* dst,\n-                         int32_t* metadata_length, int64_t* body_length) {\n-  RETURN_NOT_OK(AlignStreamPosition(dst));\n-  std::shared_ptr<Buffer> metadata;\n-  RETURN_NOT_OK(internal::WriteTensorMessage(tensor, 0, &metadata));\n-  return internal::WriteMessage(*metadata, dst, metadata_length);\n+Status GetContiguousTensor(const Tensor& tensor, MemoryPool* pool,\n+                           std::unique_ptr<Tensor>* out) {\n+  const auto& type = static_cast<const FixedWidthType&>(*tensor.type());\n+  const int elem_size = type.bit_width() / 8;\n+\n+  // TODO(wesm): Do we care enough about this temporary allocation to pass in\n+  // a MemoryPool to this function?\n+  std::shared_ptr<Buffer> scratch_space;\n+  RETURN_NOT_OK(AllocateBuffer(default_memory_pool(),\n+                               tensor.shape()[tensor.ndim() - 1] * elem_size,\n+                               &scratch_space));\n+\n+  std::shared_ptr<ResizableBuffer> contiguous_data;\n+  RETURN_NOT_OK(\n+      AllocateResizableBuffer(pool, tensor.size() * elem_size, &contiguous_data));\n+\n+  io::BufferOutputStream stream(contiguous_data);\n+  RETURN_NOT_OK(WriteStridedTensorData(0, 0, elem_size, tensor,\n+                                       scratch_space->mutable_data(), &stream));\n+\n+  out->reset(new Tensor(tensor.type(), contiguous_data, tensor.shape()));\n+\n+  return Status::OK();\n }\n \n+}  // namespace\n+\n Status WriteTensor(const Tensor& tensor, io::OutputStream* dst, int32_t* metadata_length,\n                    int64_t* body_length) {\n+  RETURN_NOT_OK(AlignStreamPosition(dst));\n+\n   if (tensor.is_contiguous()) {\n     RETURN_NOT_OK(WriteTensorHeader(tensor, dst, metadata_length, body_length));\n     auto data = tensor.data();\n@@ -619,6 +649,22 @@ Status WriteTensor(const Tensor& tensor, io::OutputStream* dst, int32_t* metadat\n   }\n }\n \n+Status GetTensorMessage(const Tensor& tensor, MemoryPool* pool,\n+                        std::unique_ptr<Message>* out) {\n+  const Tensor* tensor_to_write = &tensor;\n+  std::unique_ptr<Tensor> temp_tensor;\n+\n+  if (!tensor.is_contiguous()) {\n+    RETURN_NOT_OK(GetContiguousTensor(tensor, pool, &temp_tensor));\n+    tensor_to_write = temp_tensor.get();\n+  }\n+\n+  std::shared_ptr<Buffer> metadata;\n+  RETURN_NOT_OK(internal::WriteTensorMessage(*tensor_to_write, 0, &metadata));\n+  out->reset(new Message(metadata, tensor_to_write->data()));\n+  return Status::OK();\n+}\n+\n Status WriteDictionary(int64_t dictionary_id, const std::shared_ptr<Array>& dictionary,\n                        int64_t buffer_start_offset, io::OutputStream* dst,\n                        int32_t* metadata_length, int64_t* body_length, MemoryPool* pool) {\ndiff --git a/cpp/src/arrow/ipc/writer.h b/cpp/src/arrow/ipc/writer.h\nindex cedac45e7..11c01db8b 100644\n--- a/cpp/src/arrow/ipc/writer.h\n+++ b/cpp/src/arrow/ipc/writer.h\n@@ -239,6 +239,17 @@ Status GetRecordBatchSize(const RecordBatch& batch, int64_t* size);\n ARROW_EXPORT\n Status GetTensorSize(const Tensor& tensor, int64_t* size);\n \n+/// \\brief EXPERIMENTAL: Convert arrow::Tensor to a Message with minimal memory\n+/// allocation\n+///\n+/// \\param[in] tensor the Tensor to write\n+/// \\param[in] pool MemoryPool to allocate space for metadata\n+/// \\param[out] out the resulting Message\n+/// \\return Status\n+ARROW_EXPORT\n+Status GetTensorMessage(const Tensor& tensor, MemoryPool* pool,\n+                        std::unique_ptr<Message>* out);\n+\n /// \\brief EXPERIMENTAL: Write arrow::Tensor as a contiguous message\n ///\n /// \\param[in] tensor the Tensor to write\ndiff --git a/cpp/src/arrow/python/arrow_to_pandas.cc b/cpp/src/arrow/python/arrow_to_pandas.cc\nindex 8814fc190..096bbd55c 100644\n--- a/cpp/src/arrow/python/arrow_to_pandas.cc\n+++ b/cpp/src/arrow/python/arrow_to_pandas.cc\n@@ -480,7 +480,7 @@ inline Status ConvertStruct(PandasOptions options, const ChunkedArray& data,\n             Py_INCREF(Py_None);\n             field_value.reset(Py_None);\n           }\n-          // PyDict_SetItemString does not steal the value reference\n+          // PyDict_SetItemString increments reference count\n           auto setitem_result =\n               PyDict_SetItemString(dict_item.obj(), name.c_str(), field_value.obj());\n           RETURN_IF_PYERROR();\ndiff --git a/cpp/src/arrow/python/arrow_to_python.cc b/cpp/src/arrow/python/arrow_to_python.cc\nindex 9686050b9..ce539a597 100644\n--- a/cpp/src/arrow/python/arrow_to_python.cc\n+++ b/cpp/src/arrow/python/arrow_to_python.cc\n@@ -29,15 +29,17 @@\n \n #include \"arrow/array.h\"\n #include \"arrow/io/interfaces.h\"\n+#include \"arrow/io/memory.h\"\n #include \"arrow/ipc/reader.h\"\n+#include \"arrow/table.h\"\n+#include \"arrow/util/logging.h\"\n+\n #include \"arrow/python/common.h\"\n #include \"arrow/python/helpers.h\"\n #include \"arrow/python/numpy_convert.h\"\n #include \"arrow/python/pyarrow.h\"\n #include \"arrow/python/python_to_arrow.h\"\n #include \"arrow/python/util/datetime.h\"\n-#include \"arrow/table.h\"\n-#include \"arrow/util/logging.h\"\n \n namespace arrow {\n namespace py {\n@@ -286,5 +288,59 @@ Status DeserializeObject(PyObject* context, const SerializedPyObject& obj, PyObj\n                          obj, out);\n }\n \n+Status GetSerializedFromComponents(int num_tensors, int num_buffers, PyObject* data,\n+                                   SerializedPyObject* out) {\n+  PyAcquireGIL gil;\n+  const Py_ssize_t data_length = PyList_Size(data);\n+  RETURN_IF_PYERROR();\n+\n+  const Py_ssize_t expected_data_length = 1 + num_tensors * 2 + num_buffers;\n+  if (data_length != expected_data_length) {\n+    return Status::Invalid(\"Invalid number of buffers in data\");\n+  }\n+\n+  auto GetBuffer = [&data](Py_ssize_t index, std::shared_ptr<Buffer>* out) {\n+    PyObject* py_buf = PyList_GET_ITEM(data, index);\n+    return unwrap_buffer(py_buf, out);\n+  };\n+\n+  Py_ssize_t buffer_index = 0;\n+\n+  // Read the union batch describing object structure\n+  {\n+    std::shared_ptr<Buffer> data_buffer;\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &data_buffer));\n+    gil.release();\n+    io::BufferReader buf_reader(data_buffer);\n+    std::shared_ptr<RecordBatchReader> reader;\n+    RETURN_NOT_OK(ipc::RecordBatchStreamReader::Open(&buf_reader, &reader));\n+    RETURN_NOT_OK(reader->ReadNext(&out->batch));\n+    gil.acquire();\n+  }\n+\n+  // Zero-copy reconstruct tensors\n+  for (int i = 0; i < num_tensors; ++i) {\n+    std::shared_ptr<Buffer> metadata;\n+    std::shared_ptr<Buffer> body;\n+    std::shared_ptr<Tensor> tensor;\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &metadata));\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &body));\n+\n+    ipc::Message message(metadata, body);\n+\n+    RETURN_NOT_OK(ReadTensor(message, &tensor));\n+    out->tensors.emplace_back(std::move(tensor));\n+  }\n+\n+  // Unwrap and append buffers\n+  for (int i = 0; i < num_buffers; ++i) {\n+    std::shared_ptr<Buffer> buffer;\n+    RETURN_NOT_OK(GetBuffer(buffer_index++, &buffer));\n+    out->buffers.emplace_back(std::move(buffer));\n+  }\n+\n+  return Status::OK();\n+}\n+\n }  // namespace py\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/python/arrow_to_python.h b/cpp/src/arrow/python/arrow_to_python.h\nindex 7509f30eb..9440ffb32 100644\n--- a/cpp/src/arrow/python/arrow_to_python.h\n+++ b/cpp/src/arrow/python/arrow_to_python.h\n@@ -48,6 +48,19 @@ namespace py {\n ARROW_EXPORT\n Status ReadSerializedObject(io::RandomAccessFile* src, SerializedPyObject* out);\n \n+/// \\brief Reconstruct SerializedPyObject from representation produced by\n+/// SerializedPyObject::GetComponents.\n+///\n+/// \\param[in] num_tensors\n+/// \\param[in] num_buffers\n+/// \\param[in] data a list containing pyarrow.Buffer instances. Must be 1 +\n+/// num_tensors * 2 + num_buffers in length\n+/// \\param[out] out the reconstructed object\n+/// \\return Status\n+ARROW_EXPORT\n+Status GetSerializedFromComponents(int num_tensors, int num_buffers, PyObject* data,\n+                                   SerializedPyObject* out);\n+\n /// \\brief Reconstruct Python object from Arrow-serialized representation\n /// \\param[in] context Serialization context which contains custom serialization\n /// and deserialization callbacks. Can be any Python object with a\ndiff --git a/cpp/src/arrow/python/python_to_arrow.cc b/cpp/src/arrow/python/python_to_arrow.cc\nindex 72cc5b6e1..253e9d9a7 100644\n--- a/cpp/src/arrow/python/python_to_arrow.cc\n+++ b/cpp/src/arrow/python/python_to_arrow.cc\n@@ -31,7 +31,9 @@\n #include \"arrow/array.h\"\n #include \"arrow/builder.h\"\n #include \"arrow/io/interfaces.h\"\n+#include \"arrow/io/memory.h\"\n #include \"arrow/ipc/writer.h\"\n+#include \"arrow/memory_pool.h\"\n #include \"arrow/record_batch.h\"\n #include \"arrow/tensor.h\"\n #include \"arrow/util/logging.h\"\n@@ -710,27 +712,89 @@ Status SerializeObject(PyObject* context, PyObject* sequence, SerializedPyObject\n   return Status::OK();\n }\n \n-Status WriteSerializedObject(const SerializedPyObject& obj, io::OutputStream* dst) {\n-  int32_t num_tensors = static_cast<int32_t>(obj.tensors.size());\n-  int32_t num_buffers = static_cast<int32_t>(obj.buffers.size());\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_tensors), sizeof(int32_t)));\n-  RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&num_buffers), sizeof(int32_t)));\n-  RETURN_NOT_OK(ipc::WriteRecordBatchStream({obj.batch}, dst));\n+Status SerializedPyObject::WriteTo(io::OutputStream* dst) {\n+  int32_t num_tensors = static_cast<int32_t>(this->tensors.size());\n+  int32_t num_buffers = static_cast<int32_t>(this->buffers.size());\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_tensors), sizeof(int32_t)));\n+  RETURN_NOT_OK(\n+      dst->Write(reinterpret_cast<const uint8_t*>(&num_buffers), sizeof(int32_t)));\n+  RETURN_NOT_OK(ipc::WriteRecordBatchStream({this->batch}, dst));\n \n   int32_t metadata_length;\n   int64_t body_length;\n-  for (const auto& tensor : obj.tensors) {\n+  for (const auto& tensor : this->tensors) {\n     RETURN_NOT_OK(ipc::WriteTensor(*tensor, dst, &metadata_length, &body_length));\n   }\n \n-  for (const auto& buffer : obj.buffers) {\n+  for (const auto& buffer : this->buffers) {\n     int64_t size = buffer->size();\n-    RETURN_NOT_OK(dst->Write(reinterpret_cast<uint8_t*>(&size), sizeof(int64_t)));\n+    RETURN_NOT_OK(dst->Write(reinterpret_cast<const uint8_t*>(&size), sizeof(int64_t)));\n     RETURN_NOT_OK(dst->Write(buffer->data(), size));\n   }\n \n   return Status::OK();\n }\n \n+Status SerializedPyObject::GetComponents(MemoryPool* memory_pool, PyObject** out) {\n+  PyAcquireGIL py_gil;\n+\n+  ScopedRef result(PyDict_New());\n+  PyObject* buffers = PyList_New(0);\n+\n+  // TODO(wesm): Not sure how pedantic we need to be about checking the return\n+  // values of these functions. There are other places where we do not check\n+  // PyDict_SetItem/SetItemString return value, but these failures would be\n+  // quite esoteric\n+  PyDict_SetItemString(result.get(), \"num_tensors\",\n+                       PyLong_FromSize_t(this->tensors.size()));\n+  PyDict_SetItemString(result.get(), \"num_buffers\",\n+                       PyLong_FromSize_t(this->buffers.size()));\n+  PyDict_SetItemString(result.get(), \"data\", buffers);\n+  RETURN_IF_PYERROR();\n+\n+  Py_DECREF(buffers);\n+\n+  auto PushBuffer = [&buffers](const std::shared_ptr<Buffer>& buffer) {\n+    PyObject* wrapped_buffer = wrap_buffer(buffer);\n+    RETURN_IF_PYERROR();\n+    if (PyList_Append(buffers, wrapped_buffer) < 0) {\n+      Py_DECREF(wrapped_buffer);\n+      RETURN_IF_PYERROR();\n+    }\n+    Py_DECREF(wrapped_buffer);\n+    return Status::OK();\n+  };\n+\n+  constexpr int64_t kInitialCapacity = 1024;\n+\n+  // Write the record batch describing the object structure\n+  std::shared_ptr<io::BufferOutputStream> stream;\n+  std::shared_ptr<Buffer> buffer;\n+\n+  py_gil.release();\n+  RETURN_NOT_OK(io::BufferOutputStream::Create(kInitialCapacity, memory_pool, &stream));\n+  RETURN_NOT_OK(ipc::WriteRecordBatchStream({this->batch}, stream.get()));\n+  RETURN_NOT_OK(stream->Finish(&buffer));\n+  py_gil.acquire();\n+\n+  RETURN_NOT_OK(PushBuffer(buffer));\n+\n+  // For each tensor, get a metadata buffer and a buffer for the body\n+  for (const auto& tensor : this->tensors) {\n+    std::unique_ptr<ipc::Message> message;\n+    RETURN_NOT_OK(ipc::GetTensorMessage(*tensor, memory_pool, &message));\n+    RETURN_NOT_OK(PushBuffer(message->metadata()));\n+    RETURN_NOT_OK(PushBuffer(message->body()));\n+  }\n+\n+  for (const auto& buf : this->buffers) {\n+    RETURN_NOT_OK(PushBuffer(buf));\n+  }\n+\n+  *out = result.release();\n+  return Status::OK();\n+}\n+\n }  // namespace py\n }  // namespace arrow\ndiff --git a/cpp/src/arrow/python/python_to_arrow.h b/cpp/src/arrow/python/python_to_arrow.h\nindex c5b639614..ce7aefa0e 100644\n--- a/cpp/src/arrow/python/python_to_arrow.h\n+++ b/cpp/src/arrow/python/python_to_arrow.h\n@@ -30,6 +30,7 @@\n \n namespace arrow {\n \n+class MemoryPool;\n class RecordBatch;\n class Tensor;\n \n@@ -45,6 +46,26 @@ struct ARROW_EXPORT SerializedPyObject {\n   std::shared_ptr<RecordBatch> batch;\n   std::vector<std::shared_ptr<Tensor>> tensors;\n   std::vector<std::shared_ptr<Buffer>> buffers;\n+\n+  /// \\brief Write serialized Python object to OutputStream\n+  /// \\param[in,out] dst an OutputStream\n+  /// \\return Status\n+  Status WriteTo(io::OutputStream* dst);\n+\n+  /// \\brief Convert SerializedPyObject to a dict containing the message\n+  /// components as Buffer instances with minimal memory allocation\n+  ///\n+  /// {\n+  ///   'num_tensors': N,\n+  ///   'num_buffers': K,\n+  ///   'data': [Buffer]\n+  /// }\n+  ///\n+  /// Each tensor is written as two buffers, one for the metadata and one for\n+  /// the body. Therefore, the number of buffers in 'data' is 2 * N + K + 1,\n+  /// with the first buffer containing the serialized record batch containing\n+  /// the UnionArray that describes the whole object\n+  Status GetComponents(MemoryPool* pool, PyObject** out);\n };\n \n /// \\brief Serialize Python sequence as a RecordBatch plus\n@@ -62,13 +83,6 @@ struct ARROW_EXPORT SerializedPyObject {\n ARROW_EXPORT\n Status SerializeObject(PyObject* context, PyObject* sequence, SerializedPyObject* out);\n \n-/// \\brief Write serialized Python object to OutputStream\n-/// \\param[in] object a serialized Python object to write out\n-/// \\param[out] dst an OutputStream\n-/// \\return Status\n-ARROW_EXPORT\n-Status WriteSerializedObject(const SerializedPyObject& object, io::OutputStream* dst);\n-\n }  // namespace py\n }  // namespace arrow\n \ndiff --git a/python/doc/source/api.rst b/python/doc/source/api.rst\nindex bb2a0420b..636f41d67 100644\n--- a/python/doc/source/api.rst\n+++ b/python/doc/source/api.rst\n@@ -245,6 +245,7 @@ Serialization and IPC\n    serialize\n    serialize_to\n    deserialize\n+   deserialize_components\n    deserialize_from\n    read_serialized\n    SerializedPyObject\ndiff --git a/python/pyarrow/__init__.py b/python/pyarrow/__init__.py\nindex 0456a658f..bd31b21c1 100644\n--- a/python/pyarrow/__init__.py\n+++ b/python/pyarrow/__init__.py\n@@ -101,6 +101,7 @@\n \n # Serialization\n from pyarrow.lib import (deserialize_from, deserialize,\n+                         deserialize_components,\n                          serialize, serialize_to, read_serialized,\n                          SerializedPyObject, SerializationContext,\n                          SerializationCallbackError,\ndiff --git a/python/pyarrow/includes/libarrow.pxd b/python/pyarrow/includes/libarrow.pxd\nindex 5d68607ef..024d1475d 100644\n--- a/python/pyarrow/includes/libarrow.pxd\n+++ b/python/pyarrow/includes/libarrow.pxd\n@@ -682,11 +682,10 @@ cdef extern from \"arrow/ipc/api.h\" namespace \"arrow::ipc\" nogil:\n     c_string FormatMessageType(MessageType type)\n \n     cdef cppclass CMessageReader\" arrow::ipc::MessageReader\":\n-        CStatus ReadNextMessage(unique_ptr[CMessage]* out)\n+        @staticmethod\n+        unique_ptr[CMessageReader] Open(const shared_ptr[InputStream]& stream)\n \n-    cdef cppclass CInputStreamMessageReader \\\n-            \" arrow::ipc::InputStreamMessageReader\":\n-        CInputStreamMessageReader(const shared_ptr[InputStream]& stream)\n+        CStatus ReadNextMessage(unique_ptr[CMessage]* out)\n \n     cdef cppclass CRecordBatchWriter\" arrow::ipc::RecordBatchWriter\":\n         CStatus Close()\n@@ -908,12 +907,12 @@ cdef extern from \"arrow/python/api.h\" namespace 'arrow::py' nogil:\n         shared_ptr[CRecordBatch] batch\n         vector[shared_ptr[CTensor]] tensors\n \n+        CStatus WriteTo(OutputStream* dst)\n+        CStatus GetComponents(CMemoryPool* pool, PyObject** dst)\n+\n     CStatus SerializeObject(object context, object sequence,\n                             CSerializedPyObject* out)\n \n-    CStatus WriteSerializedObject(const CSerializedPyObject& obj,\n-                                  OutputStream* dst)\n-\n     CStatus DeserializeObject(object context,\n                               const CSerializedPyObject& obj,\n                               PyObject* base, PyObject** out)\n@@ -921,6 +920,10 @@ cdef extern from \"arrow/python/api.h\" namespace 'arrow::py' nogil:\n     CStatus ReadSerializedObject(RandomAccessFile* src,\n                                  CSerializedPyObject* out)\n \n+    CStatus GetSerializedFromComponents(int num_tensors, int num_buffers,\n+                                        object buffers,\n+                                        CSerializedPyObject* out)\n+\n \n cdef extern from 'arrow/python/init.h':\n     int arrow_init_numpy() except -1\ndiff --git a/python/pyarrow/ipc.pxi b/python/pyarrow/ipc.pxi\nindex 27e916775..b568cd46d 100644\n--- a/python/pyarrow/ipc.pxi\n+++ b/python/pyarrow/ipc.pxi\n@@ -125,9 +125,11 @@ cdef class MessageReader:\n     def open_stream(source):\n         cdef MessageReader result = MessageReader()\n         cdef shared_ptr[InputStream] in_stream\n+        cdef unique_ptr[CMessageReader] reader\n         get_input_stream(source, &in_stream)\n         with nogil:\n-            result.reader.reset(new CInputStreamMessageReader(in_stream))\n+            reader = CMessageReader.Open(in_stream)\n+            result.reader.reset(reader.release())\n \n         return result\n \ndiff --git a/python/pyarrow/public-api.pxi b/python/pyarrow/public-api.pxi\nindex 9776f2ad7..2fdb606a7 100644\n--- a/python/pyarrow/public-api.pxi\n+++ b/python/pyarrow/public-api.pxi\n@@ -44,7 +44,7 @@ cdef public api object pyarrow_wrap_buffer(const shared_ptr[CBuffer]& buf):\n \n \n cdef public api object pyarrow_wrap_resizable_buffer(\n-    const shared_ptr[CResizableBuffer]& buf):\n+        const shared_ptr[CResizableBuffer]& buf):\n     cdef ResizableBuffer result = ResizableBuffer()\n     result.init_rz(buf)\n     return result\ndiff --git a/python/pyarrow/serialization.pxi b/python/pyarrow/serialization.pxi\nindex 6b7227797..c8bd6daec 100644\n--- a/python/pyarrow/serialization.pxi\n+++ b/python/pyarrow/serialization.pxi\n@@ -165,7 +165,7 @@ cdef class SerializedPyObject:\n         def __get__(self):\n             cdef CMockOutputStream mock_stream\n             with nogil:\n-                check_status(WriteSerializedObject(self.data, &mock_stream))\n+                check_status(self.data.WriteTo(&mock_stream))\n \n             return mock_stream.GetExtentBytesWritten()\n \n@@ -179,7 +179,7 @@ cdef class SerializedPyObject:\n \n     cdef _write_to(self, OutputStream* stream):\n         with nogil:\n-            check_status(WriteSerializedObject(self.data, stream))\n+            check_status(self.data.WriteTo(stream))\n \n     def deserialize(self, SerializationContext context=None):\n         \"\"\"\n@@ -209,6 +209,46 @@ cdef class SerializedPyObject:\n         self.write_to(sink)\n         return output\n \n+    @staticmethod\n+    def from_components(components):\n+        \"\"\"\n+        Reconstruct SerializedPyObject from output of\n+        SerializedPyObject.to_components\n+        \"\"\"\n+        cdef:\n+            int num_tensors = components['num_tensors']\n+            int num_buffers = components['num_buffers']\n+            list buffers = components['data']\n+            SerializedPyObject result = SerializedPyObject()\n+\n+        with nogil:\n+            check_status(GetSerializedFromComponents(num_tensors, num_buffers,\n+                                                     buffers, &result.data))\n+\n+        return result\n+\n+    def to_components(self, memory_pool=None):\n+        \"\"\"\n+        Return the decomposed dict representation of the serialized object\n+        containing a collection of Buffer objects which maximize opportunities\n+        for zero-copy\n+\n+        Parameters\n+        ----------\n+        memory_pool : MemoryPool default None\n+            Pool to use for necessary allocations\n+\n+        Returns\n+\n+        \"\"\"\n+        cdef PyObject* result\n+        cdef CMemoryPool* c_pool = maybe_unbox_memory_pool(memory_pool)\n+\n+        with nogil:\n+            check_status(self.data.GetComponents(c_pool, &result))\n+\n+        return PyObject_to_object(result)\n+\n \n def serialize(object value, SerializationContext context=None):\n     \"\"\"EXPERIMENTAL: Serialize a Python sequence\n@@ -301,6 +341,24 @@ def deserialize_from(source, object base, SerializationContext context=None):\n     return serialized.deserialize(context)\n \n \n+def deserialize_components(components, SerializationContext context=None):\n+    \"\"\"\n+    Reconstruct Python object from output of SerializedPyObject.to_components\n+\n+    Parameters\n+    ----------\n+    components : dict\n+        Output of SerializedPyObject.to_components\n+    context : SerializationContext, default None\n+\n+    Returns\n+    -------\n+    object : the Python object that was originally serialized\n+    \"\"\"\n+    serialized = SerializedPyObject.from_components(components)\n+    return serialized.deserialize(context)\n+\n+\n def deserialize(obj, SerializationContext context=None):\n     \"\"\"\n     EXPERIMENTAL: Deserialize Python object from Buffer or other Python object\ndiff --git a/python/pyarrow/tests/test_serialization.py b/python/pyarrow/tests/test_serialization.py\nindex b0c5bc49e..cda7a5565 100644\n--- a/python/pyarrow/tests/test_serialization.py\n+++ b/python/pyarrow/tests/test_serialization.py\n@@ -216,6 +216,17 @@ def serialization_roundtrip(value, f):\n     result = pa.deserialize_from(f, None, serialization_context)\n     assert_equal(value, result)\n \n+    _check_component_roundtrip(value)\n+\n+\n+def _check_component_roundtrip(value):\n+    # Test to/from components\n+    serialized = pa.serialize(value)\n+    components = serialized.to_components()\n+    from_comp = pa.SerializedPyObject.from_components(components)\n+    recons = from_comp.deserialize()\n+    assert_equal(value, recons)\n+\n \n @pytest.yield_fixture(scope='session')\n def large_memory_map(tmpdir_factory, size=100*1024*1024):\n@@ -482,3 +493,25 @@ def test_serialize_subclasses():\n     deserialized = serialized.deserialize()\n     assert type(deserialized).__name__ == SerializableClass.__name__\n     assert deserialized.value == 3\n+\n+\n+def test_serialize_to_components_invalid_cases():\n+    buf = pa.frombuffer(b'hello')\n+\n+    components = {\n+        'num_tensors': 0,\n+        'num_buffers': 1,\n+        'data': [buf]\n+    }\n+\n+    with pytest.raises(pa.ArrowException):\n+        pa.deserialize_components(components)\n+\n+    components = {\n+        'num_tensors': 1,\n+        'num_buffers': 0,\n+        'data': [buf, buf]\n+    }\n+\n+    with pytest.raises(pa.ArrowException):\n+        pa.deserialize_components(components)\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=githubbot",
                        "name": "githubbot",
                        "key": "githubbot",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?avatarId=10452",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"
                        },
                        "displayName": "ASF GitHub Bot",
                        "active": true,
                        "timeZone": "Etc/UTC"
                    },
                    "created": "2017-11-27T21:15:27.353+0000",
                    "updated": "2017-11-27T21:15:27.353+0000"
                },
                {
                    "self": "https://issues.apache.org/jira/rest/api/2/issue/13117344/comment/16267573",
                    "id": "16267573",
                    "author": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "body": "Issue resolved by pull request 1362\n[https://github.com/apache/arrow/pull/1362]",
                    "updateAuthor": {
                        "self": "https://issues.apache.org/jira/rest/api/2/user?username=wesm",
                        "name": "wesm",
                        "key": "wesmckinn",
                        "avatarUrls": {
                            "48x48": "https://issues.apache.org/jira/secure/useravatar?ownerId=wesmckinn&avatarId=29931",
                            "24x24": "https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=wesmckinn&avatarId=29931",
                            "16x16": "https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=wesmckinn&avatarId=29931",
                            "32x32": "https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=wesmckinn&avatarId=29931"
                        },
                        "displayName": "Wes McKinney",
                        "active": true,
                        "timeZone": "America/New_York"
                    },
                    "created": "2017-11-27T21:15:27.887+0000",
                    "updated": "2017-11-27T21:15:27.887+0000"
                }
            ],
            "maxResults": 16,
            "total": 16,
            "startAt": 0
        },
        "customfield_12311820": "0|i3mltj:",
        "customfield_12314139": null
    }
}